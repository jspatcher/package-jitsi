/******/ (() => { // webpackBootstrap
/******/ 	var __webpack_modules__ = ({

/***/ "./node_modules/@jitsi/logger/lib/LogCollector.js":
/*!********************************************************!*\
  !*** ./node_modules/@jitsi/logger/lib/LogCollector.js ***!
  \********************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

/* Copyright @ 2016-present 8x8, Inc.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
var Logger = __webpack_require__(/*! ./Logger.js */ "./node_modules/@jitsi/logger/lib/Logger.js");

/**
 * Creates new <tt>LogCollector</tt>. Class implements <tt>LoggerTransport</tt>
 * and thus can be added as global transport in order to capture all the logs.
 *
 * It captures subsequent log lines created whenever <tt>Logger</tt> logs
 * a message and stores them in a queue in order to batch log entries. There are
 * time and size limit constraints which determine how often batch entries are
 * stored. Whenever one of these limits is exceeded the <tt>LogCollector</tt>
 * will use the <tt>logStorage</tt> object given as an argument to save
 * the batch log entry.
 *
 * @param {Object} logStorage an object which allows to store the logs collected
 * @param {function(string|object[])} logStorage.storeLogs a method called when
 * this <tt>LogCollector</tt> requests log entry storage. The method's argument
 * is an array which can contain <tt>string</tt>s and <tt>object</tt>s. If given
 * item is an object it means that it's an aggregated message. That is a message
 * which is the same as the previous one and it's representation has
 * the following format:
 * {
 *   {string} text: 'the text of some duplicated message'
 *   {number} count: 3 // how many times the message appeared in a row
 * }
 * If a message "B" after an aggregated message "A" is different, then it breaks
 * the sequence of "A". Which means that even if the next message "C" is
 * the same as "A" it will start a new aggregated message "C".
 * @param {function()} logStorage.isReady a method which should return
 * a <tt>boolean</tt> to tell the collector that it's ready to store. During the
 * time storage is not ready log batches will be cached and stored on the next
 * occasion (flush or interval timeout).
 *
 * @param {Object} options the <tt>LogCollector</tt> configuration options.
 * @param {number} options.maxEntryLength the size limit for a single log entry
 * to be stored. The <tt>LogCollector</tt> will push the entry as soon as it
 * reaches or exceeds this limit given that <tt>logStorage.isReady</tt>
 * returns <tt>true</tt>. Otherwise the log entry will be cached until the log
 * storage becomes ready. Note that the "is ready" condition is checked every
 * <tt>options.storeInterval</tt> milliseconds.
 * @param {number} options.storeInterval how often the logs should be stored in
 * case <tt>maxEntryLength</tt> was not exceeded.
 * @param {boolean} options.stringifyObjects indicates whether or not object
 * arguments should be "stringified" with <tt>JSON.stringify</tt> when a log
 * message is composed. Note that objects logged on the error log level are
 * always stringified.
 *
 * @constructor
 */
function LogCollector(logStorage, options) {
    this.logStorage = logStorage;
    this.stringifyObjects = options && options.stringifyObjects ? options.stringifyObjects : false;
    this.storeInterval = options && options.storeInterval ? options.storeInterval: 30000;
    this.maxEntryLength = options && options.maxEntryLength ? options.maxEntryLength : 10000;
    // Bind the log method for each level to the corresponding method name
    // in order to implement "global log transport" object.
    Object.keys(Logger.levels).forEach(
    function (logLevel) {
        var methodName = Logger.levels[logLevel];
        this[methodName] = function () {
            this._log.apply(this, arguments);
        }.bind(this, logLevel);
    }.bind(this));
    /**
     * The ID of store logs interval if one is currently scheduled or
     * <tt>null</tt> otherwise.
     * @type {number|null}
     */
    this.storeLogsIntervalID = null;
    /**
     * The log messages that are to be batched into log entry when
     * {@link LogCollector._flush} method is called.
     * @type {string[]}
     */
    this.queue = [];
    /**
     * The total length of all messages currently stored in the {@link queue}.
     * @type {number}
     */
    this.totalLen = 0;
    /**
     * An array used to temporarily store log batches, before the storage gets
     * ready.
     * @type {string[]}
     */
    this.outputCache = [];
}

/**
 * Method called inside of {@link formatLogMessage} in order to covert an
 * <tt>Object</tt> argument to string. The conversion will happen when either
 * 'stringifyObjects' option is enabled or on the {@link Logger.levels.ERROR}
 * log level. The default implementation uses <tt>JSON.stringify</tt> and
 * returns "[object with circular refs?]" instead of an object if it fails.
 *
 * @param {object} someObject the <tt>object</tt> to be stringified.
 *
 * @return {string} the result of <tt>JSON.stringify</tt> or
 * "[object with circular refs?]" if any error occurs during "stringification".
 *
 * @protected
 */
LogCollector.prototype.stringify = function (someObject) {
    try {
        return JSON.stringify(someObject);
    } catch (error) {
        return '[object with circular refs?]';
    }
};

/**
 * Formats log entry for the given logging level and arguments passed to the
 * <tt>Logger</tt>'s log method. The first argument is log level and the next
 * arguments have to be captured using JS built-in 'arguments' variable.
 *
 * @param {Logger.levels} logLevel provides the logging level of the message to
 * be logged.
 * @param {Date} timestamp - The {@code Date} when a message has been logged.
 *
 * @return {string|null} a non-empty string representation of the log entry
 * crafted from the log arguments. If the return value is <tt>null</tt> then
 * the message wil be discarded by this <tt>LogCollector</tt>.
 *
 * @protected
 */
LogCollector.prototype.formatLogMessage = function (
logLevel /* timestamp, arg2, arg3, arg4... */) {
    var msg = '';
    for (var i = 1, len = arguments.length; i < len; i++) {
        var arg = arguments[i];
        // objects logged on error level are always converted to JSON
        if ((this.stringifyObjects || logLevel === Logger.levels.ERROR) &&
            typeof arg === 'object') {
            arg = this.stringify(arg);
        }
        msg += arg;
        if (i !== len - 1) {
            msg += ' ';
        }
    }
    return msg.length ? msg : null;
};

/**
 * The log method bound to each of the logging levels in order to implement
 * "global log transport" object.
 *
 * @private
 */
LogCollector.prototype._log = function() {

    // var logLevel = arguments[0]; first argument is the log level
    var timestamp = arguments[1];
    var msg = this.formatLogMessage.apply(this, arguments);
    if (msg) {
        // The same as the previous message aggregation logic
        var prevMessage = this.queue[this.queue.length - 1];
        var prevMessageText = prevMessage && prevMessage.text;
        if (prevMessageText === msg) {
            prevMessage.count += 1;
        } else {
            this.queue.push({
                text: msg,
                timestamp: timestamp,
                count: 1
            });
            this.totalLen += msg.length;
        }
    }

    if (this.totalLen >= this.maxEntryLength) {
        this._flush(true /* force */, true /* reschedule */);
    }
};

/**
 * Starts periodical "store logs" task which will be triggered at the interval
 * specified in the constructor options.
 */
LogCollector.prototype.start = function () {
    this._reschedulePublishInterval();
};

/**
 * Reschedules the periodical "store logs" task which will store the next batch
 * log entry in the storage.
 * @private
 */
LogCollector.prototype._reschedulePublishInterval = function () {
    if (this.storeLogsIntervalID) {
        window.clearTimeout(this.storeLogsIntervalID);
        this.storeLogsIntervalID = null;
    }
    // It's actually a timeout, because it is rescheduled on every flush
    this.storeLogsIntervalID = window.setTimeout(
        this._flush.bind(
            this, false /* do not force */, true /* reschedule */),
        this.storeInterval);
};

/**
 * Call this method to flush the log entry buffer and store it in the log
 * storage immediately (given that the storage is ready).
 */
LogCollector.prototype.flush = function() {
    this._flush(
        false /* do not force, as it will not be stored anyway */,
        true /* reschedule next update */ );
};

/**
 * Stores the next batch log entry in the log storage.
 * @param {boolean} force enforce current logs batch to be stored or cached if
 * there is anything to be logged, but the storage is not ready yet. One of
 * legitimate reasons to force is when the logs length exceeds size limit which
 * could result in truncation.
 * @param {boolean} reschedule <tt>true</tt> if the next periodic task should be
 * scheduled after the log entry is stored. <tt>false</tt> will end the periodic
 * task cycle.
 * @private
 */
LogCollector.prototype._flush = function(force, reschedule) {
    // Publish only if there's anything to be logged
    if (this.totalLen > 0 && (this.logStorage.isReady() || force)) {
        //FIXME avoid truncating
        // right now we don't care if the message size is "slightly" exceeded
        if (this.logStorage.isReady()) {
            // Sends all cached logs
            if (this.outputCache.length) {
                this.outputCache.forEach(
                    function (cachedQueue) {
                        this.logStorage.storeLogs(cachedQueue);
                    }.bind(this)
                );
                // Clear the cache
                this.outputCache = [];
            }
            // Send current batch
            this.logStorage.storeLogs(this.queue);
        } else {
            this.outputCache.push(this.queue);
        }

        this.queue = [];
        this.totalLen = 0;
    }

    if (reschedule) {
        this._reschedulePublishInterval();
    }
};

/**
 * Stops the periodical "store logs" task and immediately stores any pending
 * log entries as a batch.
 */
LogCollector.prototype.stop = function() {
    // Flush and stop publishing logs
    this._flush(false /* do not force */, false /* do not reschedule */);
};

module.exports = LogCollector;


/***/ }),

/***/ "./node_modules/@jitsi/logger/lib/Logger.js":
/*!**************************************************!*\
  !*** ./node_modules/@jitsi/logger/lib/Logger.js ***!
  \**************************************************/
/***/ ((module) => {

/* Copyright @ 2015-present 8x8, Inc.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
/*jslint latedef:false*/

/**
 * Ordered log levels.
 */
var levels = {
    "trace": 0,
    "debug": 1,
    "info": 2,
    "log": 3,
    "warn": 4,
    "error": 5
};

/**
 * The default transport - console
 * @type LoggerTransport
 */
Logger.consoleTransport = console;

/**
 * The array which stores currently registered global transports.
 * @type {[LoggerTransport]}
 */
var globalTransports = [ Logger.consoleTransport ];

/**
 * Adds given {@link LoggerTransport} instance to the list of global
 * transports which means that it'll be used by all {@link Logger}s
 * @param {LoggerTransport} transport
 */
Logger.addGlobalTransport = function(transport) {
    if (globalTransports.indexOf(transport) === -1) {
        globalTransports.push(transport);
    }
};

/**
 * Removes given {@link LoggerTransport} instance from the list of global
 * transports
 * @param {LoggerTransport} transport
 */
Logger.removeGlobalTransport = function(transport) {
    var transportIdx = globalTransports.indexOf(transport);
    if (transportIdx !== -1) {
        globalTransports.splice(transportIdx, 1);
    }
};

/**
 * The global configuration options.
 */
var globalOptions = {};

/**
 * Sets global options which will be used by all loggers. Changing these works
 * even after other loggers are created.
 */
Logger.setGlobalOptions = function(options) {
    globalOptions = options || {};
};

/**
 * Parses Error's object stack trace and extracts information about the last
 * caller before the log method was called.
 * @returns JS object with info about the caller - method name, file location,
 * line and column.
 */
function getCallerInfo() {
    var callerInfo = {
        methodName: "",
        fileLocation: "",
        line: null,
        column: null
    };
    //gets the part of the stack without the logger wrappers
    var error = new Error();
    var stack = error.stack? error.stack.split("\n") : [];
    if(!stack || stack.length < 3) {
        return callerInfo;
    }
    var m = null;
    if(stack[3]) {
        m = stack[3].match(/\s*at\s*(.+?)\s*\((\S*)\s*:(\d*)\s*:(\d*)\)/);
    }
    if(!m || m.length <= 4) {
        //Firefox && Safari
        if(stack[2].indexOf("log@") === 0){
            //Safari
            callerInfo.methodName = stack[3].substr(0, stack[3].indexOf("@"));
        } else {
            //Firefox
            callerInfo.methodName = stack[2].substr(0, stack[2].indexOf("@"));
        }
        return callerInfo;
    }

    callerInfo.methodName = m[1];
    callerInfo.fileLocation = m[2];
    callerInfo.line = m[3];
    callerInfo.column = m[4];
    return callerInfo;
}

/**
 * Logs messages using the transports and level from the logger.
 * @param logger a logger instance.
 * @param level the log level of the message. See the levels variable.
 * @param arguments array with arguments that will be logged.
 */
function log() {
    var logger = arguments[0], level = arguments[1],
        args = Array.prototype.slice.call(arguments, 2);
    if(levels[level] < logger.level) {
        return;
    }

    var callerInfo
        = !(logger.options.disableCallerInfo || globalOptions.disableCallerInfo) &&
            getCallerInfo();
    var transports = globalTransports.concat(logger.transports);
    for(var i = 0; i < transports.length; i++) {
        var t = transports[i];
        var l = t[level];
        if(l && typeof(l) === "function") {
            var logPrefixes = [];

            logPrefixes.push(new Date().toISOString());

            if (logger.id) {
                logPrefixes.push("[" + logger.id + "]");
            }

            if (callerInfo && callerInfo.methodName.length > 1) {
                logPrefixes.push("<" + callerInfo.methodName + ">: ");
            }

            var fullLogParts = logPrefixes.concat(args);

            l.bind(t).apply(t, fullLogParts);
        }
    }
}

/**
 *
 * Constructs new logger object.
 * @param level the logging level for the new logger
 * @param id optional identifier for the logger instance.
 * @param {LoggerTransport} transports optional list of handlers(objects) for
 * the logs. The handlers must support - log, warn, error, debug, info, trace.
 * @param options optional configuration file for how the logger should behave.
 * @param {boolean} options.disableCallerInfo Whether the call site of a logger
 * method invocation should be included in the log. Defaults to false, so the
 * call site will be included.
 */
function Logger(level, id, transports, options) {
    this.id = id;
    this.options = options || {};
    this.transports = transports;
    if(!this.transports) {
        this.transports = [];
    }
    this.level = levels[level];
    var methods = Object.keys(levels);
    for(var i = 0; i < methods.length; i++){
        this[methods[i]] =
            log.bind(null, this, methods[i]);
    }
}

/**
 * Sets the log level for the logger.
 * @param level the new log level.
 */
Logger.prototype.setLevel = function (level) {
    this.level = levels[level];
};
module.exports = Logger;

/**
 * Enum for the supported log levels.
 */
Logger.levels = {
    TRACE: "trace",
    DEBUG: "debug",
    INFO: "info",
    LOG: "log",
    WARN: "warn",
    ERROR: "error"
};


/***/ }),

/***/ "./node_modules/@jitsi/logger/lib/index.js":
/*!*************************************************!*\
  !*** ./node_modules/@jitsi/logger/lib/index.js ***!
  \*************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

/* Copyright @ 2015-present 8x8, Inc.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
var Logger = __webpack_require__(/*! ./Logger */ "./node_modules/@jitsi/logger/lib/Logger.js");
var LogCollector = __webpack_require__(/*! ./LogCollector */ "./node_modules/@jitsi/logger/lib/LogCollector.js");

/**
 * Definition of the log method
 * @name log_method
 * @function
 * @param {...*} log_args the arguments to be logged
 */
/**
 * The logger's transport type definition.
 *
 * @typedef {object} LoggerTransport
 *
 * @property {log_method} trace method called to log on {@link Logger.levels.TRACE} logging level
 * @property {log_method} debug method called to log on {@link Logger.levels.DEBUG} logging level
 * @property {log_method} info method called to log on {@link Logger.levels.INFO} logging level
 * @property {log_method} log method called to log on {@link Logger.levels.LOG} logging level
 * @property {log_method} warn method called to log on {@link Logger.levels.WARN} logging level
 * @property {log_method} error method called to log on {@link Logger.levels.ERROR} logging level
 */

/**
 * Map with the created loggers with ID.
 */
var idLoggers = {};

/**
 * Array with the loggers without id.
 */
var loggers = [];

/**
 * Log level for the lbrary.
 */
var curLevel = Logger.levels.TRACE;


module.exports = {
    /**
     * Adds given {@link LoggerTransport} instance to the list of global
     * transports which means that it'll be used by all {@link Logger}s
     * @param {LoggerTransport} transport
     */
    addGlobalTransport: function(transport) {
        Logger.addGlobalTransport(transport);
    },
    /**
     * Removes given {@link LoggerTransport} instance from the list of global
     * transports
     * @param {LoggerTransport} transport
     */
    removeGlobalTransport: function(transport) {
        Logger.removeGlobalTransport(transport);
    },
    /**
    * Sets global options which will be used by all loggers. Changing these
    * works even after other loggers are created.
    */
    setGlobalOptions: function(options) {
        Logger.setGlobalOptions(options);
    },
    /**
     * Creates new logger.
     * @arguments the same as Logger constructor
     */
    getLogger: function(id, transports, options) {
        var logger = new Logger(curLevel, id, transports, options);
        if(id) {
            idLoggers[id] = idLoggers[id] || [];
            idLoggers[id].push(logger);
        } else {
            loggers.push(logger);
        }
        return logger;
    },
    /**
     * Changes the log level for the existing loggers by id.
     * @param level the new log level.
     * @param id if specified the level will be changed only for loggers with the
     * same id. Otherwise the operation will affect all loggers that don't
     * have id.
     */
    setLogLevelById: function(level, id) {
        var l = id? (idLoggers[id] || []) : loggers;
        for(var i = 0; i < l.length; i++) {
            l[i].setLevel(level);
        }
    },
    /**
     * Changes the log level for all existing loggers.
     * @param level the new log level.
     */
    setLogLevel: function (level) {
        curLevel = level;
        var i = 0;
        for(; i < loggers.length; i++) {
            loggers[i].setLevel(level);
        }

        for(var id in idLoggers) {
            var l = idLoggers[id] || [];
            for(i = 0; i < l.length; i++) {
                l[i].setLevel(level);
            }
        }
    },
    /**
     * The supported log levels.
     */
    levels: Logger.levels,
    /**
     * Exports the <tt>LogCollector</tt>.
     */
    LogCollector: LogCollector
};


/***/ }),

/***/ "./node_modules/@jitsi/sdp-interop/node_modules/sdp-transform/lib/grammar.js":
/*!***********************************************************************************!*\
  !*** ./node_modules/@jitsi/sdp-interop/node_modules/sdp-transform/lib/grammar.js ***!
  \***********************************************************************************/
/***/ ((module) => {

var grammar = module.exports = {
  v: [{
    name: 'version',
    reg: /^(\d*)$/
  }],
  o: [{
    // o=- 20518 0 IN IP4 203.0.113.1
    // NB: sessionId will be a String in most cases because it is huge
    name: 'origin',
    reg: /^(\S*) (\d*) (\d*) (\S*) IP(\d) (\S*)/,
    names: ['username', 'sessionId', 'sessionVersion', 'netType', 'ipVer', 'address'],
    format: '%s %s %d %s IP%d %s'
  }],
  // default parsing of these only (though some of these feel outdated)
  s: [{ name: 'name' }],
  i: [{ name: 'description' }],
  u: [{ name: 'uri' }],
  e: [{ name: 'email' }],
  p: [{ name: 'phone' }],
  z: [{ name: 'timezones' }], // TODO: this one can actually be parsed properly...
  r: [{ name: 'repeats' }],   // TODO: this one can also be parsed properly
  // k: [{}], // outdated thing ignored
  t: [{
    // t=0 0
    name: 'timing',
    reg: /^(\d*) (\d*)/,
    names: ['start', 'stop'],
    format: '%d %d'
  }],
  c: [{
    // c=IN IP4 10.47.197.26
    name: 'connection',
    reg: /^IN IP(\d) (\S*)/,
    names: ['version', 'ip'],
    format: 'IN IP%d %s'
  }],
  b: [{
    // b=AS:4000
    push: 'bandwidth',
    reg: /^(TIAS|AS|CT|RR|RS):(\d*)/,
    names: ['type', 'limit'],
    format: '%s:%s'
  }],
  m: [{
    // m=video 51744 RTP/AVP 126 97 98 34 31
    // NB: special - pushes to session
    // TODO: rtp/fmtp should be filtered by the payloads found here?
    reg: /^(\w*) (\d*) ([\w/]*)(?: (.*))?/,
    names: ['type', 'port', 'protocol', 'payloads'],
    format: '%s %d %s %s'
  }],
  a: [
    {
      // a=rtpmap:110 opus/48000/2
      push: 'rtp',
      reg: /^rtpmap:(\d*) ([\w\-.]*)(?:\s*\/(\d*)(?:\s*\/(\S*))?)?/,
      names: ['payload', 'codec', 'rate', 'encoding'],
      format: function (o) {
        return (o.encoding)
          ? 'rtpmap:%d %s/%s/%s'
          : o.rate
            ? 'rtpmap:%d %s/%s'
            : 'rtpmap:%d %s';
      }
    },
    {
      // a=fmtp:108 profile-level-id=24;object=23;bitrate=64000
      // a=fmtp:111 minptime=10; useinbandfec=1
      push: 'fmtp',
      reg: /^fmtp:(\d*) ([\S| ]*)/,
      names: ['payload', 'config'],
      format: 'fmtp:%d %s'
    },
    {
      // a=control:streamid=0
      name: 'control',
      reg: /^control:(.*)/,
      format: 'control:%s'
    },
    {
      // a=rtcp:65179 IN IP4 193.84.77.194
      name: 'rtcp',
      reg: /^rtcp:(\d*)(?: (\S*) IP(\d) (\S*))?/,
      names: ['port', 'netType', 'ipVer', 'address'],
      format: function (o) {
        return (o.address != null)
          ? 'rtcp:%d %s IP%d %s'
          : 'rtcp:%d';
      }
    },
    {
      // a=rtcp-fb:98 trr-int 100
      push: 'rtcpFbTrrInt',
      reg: /^rtcp-fb:(\*|\d*) trr-int (\d*)/,
      names: ['payload', 'value'],
      format: 'rtcp-fb:%s trr-int %d'
    },
    {
      // a=rtcp-fb:98 nack rpsi
      push: 'rtcpFb',
      reg: /^rtcp-fb:(\*|\d*) ([\w-_]*)(?: ([\w-_]*))?/,
      names: ['payload', 'type', 'subtype'],
      format: function (o) {
        return (o.subtype != null)
          ? 'rtcp-fb:%s %s %s'
          : 'rtcp-fb:%s %s';
      }
    },
    {
      // a=extmap:2 urn:ietf:params:rtp-hdrext:toffset
      // a=extmap:1/recvonly URI-gps-string
      // a=extmap:3 urn:ietf:params:rtp-hdrext:encrypt urn:ietf:params:rtp-hdrext:smpte-tc 25@600/24
      push: 'ext',
      reg: /^extmap:(\d+)(?:\/(\w+))?(?: (urn:ietf:params:rtp-hdrext:encrypt))? (\S*)(?: (\S*))?/,
      names: ['value', 'direction', 'encrypt-uri', 'uri', 'config'],
      format: function (o) {
        return (
          'extmap:%d' +
          (o.direction ? '/%s' : '%v') +
          (o['encrypt-uri'] ? ' %s' : '%v') +
          ' %s' +
          (o.config ? ' %s' : '')
        );
      }
    },
    {
      // a=extmap-allow-mixed
      name: 'extmapAllowMixed',
      reg: /^(extmap-allow-mixed)/
    },
    {
      // a=crypto:1 AES_CM_128_HMAC_SHA1_80 inline:PS1uQCVeeCFCanVmcjkpPywjNWhcYD0mXXtxaVBR|2^20|1:32
      push: 'crypto',
      reg: /^crypto:(\d*) ([\w_]*) (\S*)(?: (\S*))?/,
      names: ['id', 'suite', 'config', 'sessionConfig'],
      format: function (o) {
        return (o.sessionConfig != null)
          ? 'crypto:%d %s %s %s'
          : 'crypto:%d %s %s';
      }
    },
    {
      // a=setup:actpass
      name: 'setup',
      reg: /^setup:(\w*)/,
      format: 'setup:%s'
    },
    {
      // a=connection:new
      name: 'connectionType',
      reg: /^connection:(new|existing)/,
      format: 'connection:%s'
    },
    {
      // a=mid:1
      name: 'mid',
      reg: /^mid:([^\s]*)/,
      format: 'mid:%s'
    },
    {
      // a=msid:0c8b064d-d807-43b4-b434-f92a889d8587 98178685-d409-46e0-8e16-7ef0db0db64a
      name: 'msid',
      reg: /^msid:(.*)/,
      format: 'msid:%s'
    },
    {
      // a=ptime:20
      name: 'ptime',
      reg: /^ptime:(\d*(?:\.\d*)*)/,
      format: 'ptime:%d'
    },
    {
      // a=maxptime:60
      name: 'maxptime',
      reg: /^maxptime:(\d*(?:\.\d*)*)/,
      format: 'maxptime:%d'
    },
    {
      // a=sendrecv
      name: 'direction',
      reg: /^(sendrecv|recvonly|sendonly|inactive)/
    },
    {
      // a=ice-lite
      name: 'icelite',
      reg: /^(ice-lite)/
    },
    {
      // a=ice-ufrag:F7gI
      name: 'iceUfrag',
      reg: /^ice-ufrag:(\S*)/,
      format: 'ice-ufrag:%s'
    },
    {
      // a=ice-pwd:x9cml/YzichV2+XlhiMu8g
      name: 'icePwd',
      reg: /^ice-pwd:(\S*)/,
      format: 'ice-pwd:%s'
    },
    {
      // a=fingerprint:SHA-1 00:11:22:33:44:55:66:77:88:99:AA:BB:CC:DD:EE:FF:00:11:22:33
      name: 'fingerprint',
      reg: /^fingerprint:(\S*) (\S*)/,
      names: ['type', 'hash'],
      format: 'fingerprint:%s %s'
    },
    {
      // a=candidate:0 1 UDP 2113667327 203.0.113.1 54400 typ host
      // a=candidate:1162875081 1 udp 2113937151 192.168.34.75 60017 typ host generation 0 network-id 3 network-cost 10
      // a=candidate:3289912957 2 udp 1845501695 193.84.77.194 60017 typ srflx raddr 192.168.34.75 rport 60017 generation 0 network-id 3 network-cost 10
      // a=candidate:229815620 1 tcp 1518280447 192.168.150.19 60017 typ host tcptype active generation 0 network-id 3 network-cost 10
      // a=candidate:3289912957 2 tcp 1845501695 193.84.77.194 60017 typ srflx raddr 192.168.34.75 rport 60017 tcptype passive generation 0 network-id 3 network-cost 10
      push:'candidates',
      reg: /^candidate:(\S*) (\d*) (\S*) (\d*) (\S*) (\d*) typ (\S*)(?: raddr (\S*) rport (\d*))?(?: tcptype (\S*))?(?: generation (\d*))?(?: network-id (\d*))?(?: network-cost (\d*))?/,
      names: ['foundation', 'component', 'transport', 'priority', 'ip', 'port', 'type', 'raddr', 'rport', 'tcptype', 'generation', 'network-id', 'network-cost'],
      format: function (o) {
        var str = 'candidate:%s %d %s %d %s %d typ %s';

        str += (o.raddr != null) ? ' raddr %s rport %d' : '%v%v';

        // NB: candidate has three optional chunks, so %void middles one if it's missing
        str += (o.tcptype != null) ? ' tcptype %s' : '%v';

        if (o.generation != null) {
          str += ' generation %d';
        }

        str += (o['network-id'] != null) ? ' network-id %d' : '%v';
        str += (o['network-cost'] != null) ? ' network-cost %d' : '%v';
        return str;
      }
    },
    {
      // a=end-of-candidates (keep after the candidates line for readability)
      name: 'endOfCandidates',
      reg: /^(end-of-candidates)/
    },
    {
      // a=remote-candidates:1 203.0.113.1 54400 2 203.0.113.1 54401 ...
      name: 'remoteCandidates',
      reg: /^remote-candidates:(.*)/,
      format: 'remote-candidates:%s'
    },
    {
      // a=ice-options:google-ice
      name: 'iceOptions',
      reg: /^ice-options:(\S*)/,
      format: 'ice-options:%s'
    },
    {
      // a=ssrc:2566107569 cname:t9YU8M1UxTF8Y1A1
      push: 'ssrcs',
      reg: /^ssrc:(\d*) ([\w_-]*)(?::(.*))?/,
      names: ['id', 'attribute', 'value'],
      format: function (o) {
        var str = 'ssrc:%d';
        if (o.attribute != null) {
          str += ' %s';
          if (o.value != null) {
            str += ':%s';
          }
        }
        return str;
      }
    },
    {
      // a=ssrc-group:FEC 1 2
      // a=ssrc-group:FEC-FR 3004364195 1080772241
      push: 'ssrcGroups',
      // token-char = %x21 / %x23-27 / %x2A-2B / %x2D-2E / %x30-39 / %x41-5A / %x5E-7E
      reg: /^ssrc-group:([\x21\x23\x24\x25\x26\x27\x2A\x2B\x2D\x2E\w]*) (.*)/,
      names: ['semantics', 'ssrcs'],
      format: 'ssrc-group:%s %s'
    },
    {
      // a=msid-semantic: WMS Jvlam5X3SX1OP6pn20zWogvaKJz5Hjf9OnlV
      name: 'msidSemantic',
      reg: /^msid-semantic:\s?(\w*) (\S*)/,
      names: ['semantic', 'token'],
      format: 'msid-semantic: %s %s' // space after ':' is not accidental
    },
    {
      // a=group:BUNDLE audio video
      push: 'groups',
      reg: /^group:(\w*) (.*)/,
      names: ['type', 'mids'],
      format: 'group:%s %s'
    },
    {
      // a=rtcp-mux
      name: 'rtcpMux',
      reg: /^(rtcp-mux)/
    },
    {
      // a=rtcp-rsize
      name: 'rtcpRsize',
      reg: /^(rtcp-rsize)/
    },
    {
      // a=sctpmap:5000 webrtc-datachannel 1024
      name: 'sctpmap',
      reg: /^sctpmap:([\w_/]*) (\S*)(?: (\S*))?/,
      names: ['sctpmapNumber', 'app', 'maxMessageSize'],
      format: function (o) {
        return (o.maxMessageSize != null)
          ? 'sctpmap:%s %s %s'
          : 'sctpmap:%s %s';
      }
    },
    {
      // a=x-google-flag:conference
      name: 'xGoogleFlag',
      reg: /^x-google-flag:([^\s]*)/,
      format: 'x-google-flag:%s'
    },
    {
      // a=rid:1 send max-width=1280;max-height=720;max-fps=30;depend=0
      push: 'rids',
      reg: /^rid:([\d\w]+) (\w+)(?: ([\S| ]*))?/,
      names: ['id', 'direction', 'params'],
      format: function (o) {
        return (o.params) ? 'rid:%s %s %s' : 'rid:%s %s';
      }
    },
    {
      // a=imageattr:97 send [x=800,y=640,sar=1.1,q=0.6] [x=480,y=320] recv [x=330,y=250]
      // a=imageattr:* send [x=800,y=640] recv *
      // a=imageattr:100 recv [x=320,y=240]
      push: 'imageattrs',
      reg: new RegExp(
        // a=imageattr:97
        '^imageattr:(\\d+|\\*)' +
        // send [x=800,y=640,sar=1.1,q=0.6] [x=480,y=320]
        '[\\s\\t]+(send|recv)[\\s\\t]+(\\*|\\[\\S+\\](?:[\\s\\t]+\\[\\S+\\])*)' +
        // recv [x=330,y=250]
        '(?:[\\s\\t]+(recv|send)[\\s\\t]+(\\*|\\[\\S+\\](?:[\\s\\t]+\\[\\S+\\])*))?'
      ),
      names: ['pt', 'dir1', 'attrs1', 'dir2', 'attrs2'],
      format: function (o) {
        return 'imageattr:%s %s %s' + (o.dir2 ? ' %s %s' : '');
      }
    },
    {
      // a=simulcast:send 1,2,3;~4,~5 recv 6;~7,~8
      // a=simulcast:recv 1;4,5 send 6;7
      name: 'simulcast',
      reg: new RegExp(
        // a=simulcast:
        '^simulcast:' +
        // send 1,2,3;~4,~5
        '(send|recv) ([a-zA-Z0-9\\-_~;,]+)' +
        // space + recv 6;~7,~8
        '(?:\\s?(send|recv) ([a-zA-Z0-9\\-_~;,]+))?' +
        // end
        '$'
      ),
      names: ['dir1', 'list1', 'dir2', 'list2'],
      format: function (o) {
        return 'simulcast:%s %s' + (o.dir2 ? ' %s %s' : '');
      }
    },
    {
      // old simulcast draft 03 (implemented by Firefox)
      //   https://tools.ietf.org/html/draft-ietf-mmusic-sdp-simulcast-03
      // a=simulcast: recv pt=97;98 send pt=97
      // a=simulcast: send rid=5;6;7 paused=6,7
      name: 'simulcast_03',
      reg: /^simulcast:[\s\t]+([\S+\s\t]+)$/,
      names: ['value'],
      format: 'simulcast: %s'
    },
    {
      // a=framerate:25
      // a=framerate:29.97
      name: 'framerate',
      reg: /^framerate:(\d+(?:$|\.\d+))/,
      format: 'framerate:%s'
    },
    {
      // RFC4570
      // a=source-filter: incl IN IP4 239.5.2.31 10.1.15.5
      name: 'sourceFilter',
      reg: /^source-filter: *(excl|incl) (\S*) (IP4|IP6|\*) (\S*) (.*)/,
      names: ['filterMode', 'netType', 'addressTypes', 'destAddress', 'srcList'],
      format: 'source-filter: %s %s %s %s %s'
    },
    {
      // a=bundle-only
      name: 'bundleOnly',
      reg: /^(bundle-only)/
    },
    {
      // a=label:1
      name: 'label',
      reg: /^label:(.+)/,
      format: 'label:%s'
    },
    {
      // RFC version 26 for SCTP over DTLS
      // https://tools.ietf.org/html/draft-ietf-mmusic-sctp-sdp-26#section-5
      name: 'sctpPort',
      reg: /^sctp-port:(\d+)$/,
      format: 'sctp-port:%s'
    },
    {
      // RFC version 26 for SCTP over DTLS
      // https://tools.ietf.org/html/draft-ietf-mmusic-sctp-sdp-26#section-6
      name: 'maxMessageSize',
      reg: /^max-message-size:(\d+)$/,
      format: 'max-message-size:%s'
    },
    {
      // RFC7273
      // a=ts-refclk:ptp=IEEE1588-2008:39-A7-94-FF-FE-07-CB-D0:37
      push:'tsRefClocks',
      reg: /^ts-refclk:([^\s=]*)(?:=(\S*))?/,
      names: ['clksrc', 'clksrcExt'],
      format: function (o) {
        return 'ts-refclk:%s' + (o.clksrcExt != null ? '=%s' : '');
      }
    },
    {
      // RFC7273
      // a=mediaclk:direct=963214424
      name:'mediaClk',
      reg: /^mediaclk:(?:id=(\S*))? *([^\s=]*)(?:=(\S*))?(?: *rate=(\d+)\/(\d+))?/,
      names: ['id', 'mediaClockName', 'mediaClockValue', 'rateNumerator', 'rateDenominator'],
      format: function (o) {
        var str = 'mediaclk:';
        str += (o.id != null ? 'id=%s %s' : '%v%s');
        str += (o.mediaClockValue != null ? '=%s' : '');
        str += (o.rateNumerator != null ? ' rate=%s' : '');
        str += (o.rateDenominator != null ? '/%s' : '');
        return str;
      }
    },
    {
      // a=keywds:keywords
      name: 'keywords',
      reg: /^keywds:(.+)$/,
      format: 'keywds:%s'
    },
    {
      // a=content:main
      name: 'content',
      reg: /^content:(.+)/,
      format: 'content:%s'
    },
    // BFCP https://tools.ietf.org/html/rfc4583
    {
      // a=floorctrl:c-s
      name: 'bfcpFloorCtrl',
      reg: /^floorctrl:(c-only|s-only|c-s)/,
      format: 'floorctrl:%s'
    },
    {
      // a=confid:1
      name: 'bfcpConfId',
      reg: /^confid:(\d+)/,
      format: 'confid:%s'
    },
    {
      // a=userid:1
      name: 'bfcpUserId',
      reg: /^userid:(\d+)/,
      format: 'userid:%s'
    },
    {
      // a=floorid:1
      name: 'bfcpFloorId',
      reg: /^floorid:(.+) (?:m-stream|mstrm):(.+)/,
      names: ['id', 'mStream'],
      format: 'floorid:%s mstrm:%s'
    },
    {
      // any a= that we don't understand is kept verbatim on media.invalid
      push: 'invalid',
      names: ['value']
    }
  ]
};

// set sensible defaults to avoid polluting the grammar with boring details
Object.keys(grammar).forEach(function (key) {
  var objs = grammar[key];
  objs.forEach(function (obj) {
    if (!obj.reg) {
      obj.reg = /(.*)/;
    }
    if (!obj.format) {
      obj.format = '%s';
    }
  });
});


/***/ }),

/***/ "./node_modules/@jitsi/sdp-interop/node_modules/sdp-transform/lib/index.js":
/*!*********************************************************************************!*\
  !*** ./node_modules/@jitsi/sdp-interop/node_modules/sdp-transform/lib/index.js ***!
  \*********************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

var parser = __webpack_require__(/*! ./parser */ "./node_modules/@jitsi/sdp-interop/node_modules/sdp-transform/lib/parser.js");
var writer = __webpack_require__(/*! ./writer */ "./node_modules/@jitsi/sdp-interop/node_modules/sdp-transform/lib/writer.js");

exports.write = writer;
exports.parse = parser.parse;
exports.parseParams = parser.parseParams;
exports.parseFmtpConfig = parser.parseFmtpConfig; // Alias of parseParams().
exports.parsePayloads = parser.parsePayloads;
exports.parseRemoteCandidates = parser.parseRemoteCandidates;
exports.parseImageAttributes = parser.parseImageAttributes;
exports.parseSimulcastStreamList = parser.parseSimulcastStreamList;


/***/ }),

/***/ "./node_modules/@jitsi/sdp-interop/node_modules/sdp-transform/lib/parser.js":
/*!**********************************************************************************!*\
  !*** ./node_modules/@jitsi/sdp-interop/node_modules/sdp-transform/lib/parser.js ***!
  \**********************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

var toIntIfInt = function (v) {
  return String(Number(v)) === v ? Number(v) : v;
};

var attachProperties = function (match, location, names, rawName) {
  if (rawName && !names) {
    location[rawName] = toIntIfInt(match[1]);
  }
  else {
    for (var i = 0; i < names.length; i += 1) {
      if (match[i+1] != null) {
        location[names[i]] = toIntIfInt(match[i+1]);
      }
    }
  }
};

var parseReg = function (obj, location, content) {
  var needsBlank = obj.name && obj.names;
  if (obj.push && !location[obj.push]) {
    location[obj.push] = [];
  }
  else if (needsBlank && !location[obj.name]) {
    location[obj.name] = {};
  }
  var keyLocation = obj.push ?
    {} :  // blank object that will be pushed
    needsBlank ? location[obj.name] : location; // otherwise, named location or root

  attachProperties(content.match(obj.reg), keyLocation, obj.names, obj.name);

  if (obj.push) {
    location[obj.push].push(keyLocation);
  }
};

var grammar = __webpack_require__(/*! ./grammar */ "./node_modules/@jitsi/sdp-interop/node_modules/sdp-transform/lib/grammar.js");
var validLine = RegExp.prototype.test.bind(/^([a-z])=(.*)/);

exports.parse = function (sdp) {
  var session = {}
    , media = []
    , location = session; // points at where properties go under (one of the above)

  // parse lines we understand
  sdp.split(/(\r\n|\r|\n)/).filter(validLine).forEach(function (l) {
    var type = l[0];
    var content = l.slice(2);
    if (type === 'm') {
      media.push({rtp: [], fmtp: []});
      location = media[media.length-1]; // point at latest media line
    }

    for (var j = 0; j < (grammar[type] || []).length; j += 1) {
      var obj = grammar[type][j];
      if (obj.reg.test(content)) {
        return parseReg(obj, location, content);
      }
    }
  });

  session.media = media; // link it up
  return session;
};

var paramReducer = function (acc, expr) {
  var s = expr.split(/=(.+)/, 2);
  if (s.length === 2) {
    acc[s[0]] = toIntIfInt(s[1]);
  } else if (s.length === 1 && expr.length > 1) {
    acc[s[0]] = undefined;
  }
  return acc;
};

exports.parseParams = function (str) {
  return str.split(/;\s?/).reduce(paramReducer, {});
};

// For backward compatibility - alias will be removed in 3.0.0
exports.parseFmtpConfig = exports.parseParams;

exports.parsePayloads = function (str) {
  return str.toString().split(' ').map(Number);
};

exports.parseRemoteCandidates = function (str) {
  var candidates = [];
  var parts = str.split(' ').map(toIntIfInt);
  for (var i = 0; i < parts.length; i += 3) {
    candidates.push({
      component: parts[i],
      ip: parts[i + 1],
      port: parts[i + 2]
    });
  }
  return candidates;
};

exports.parseImageAttributes = function (str) {
  return str.split(' ').map(function (item) {
    return item.substring(1, item.length-1).split(',').reduce(paramReducer, {});
  });
};

exports.parseSimulcastStreamList = function (str) {
  return str.split(';').map(function (stream) {
    return stream.split(',').map(function (format) {
      var scid, paused = false;

      if (format[0] !== '~') {
        scid = toIntIfInt(format);
      } else {
        scid = toIntIfInt(format.substring(1, format.length));
        paused = true;
      }

      return {
        scid: scid,
        paused: paused
      };
    });
  });
};


/***/ }),

/***/ "./node_modules/@jitsi/sdp-interop/node_modules/sdp-transform/lib/writer.js":
/*!**********************************************************************************!*\
  !*** ./node_modules/@jitsi/sdp-interop/node_modules/sdp-transform/lib/writer.js ***!
  \**********************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

var grammar = __webpack_require__(/*! ./grammar */ "./node_modules/@jitsi/sdp-interop/node_modules/sdp-transform/lib/grammar.js");

// customized util.format - discards excess arguments and can void middle ones
var formatRegExp = /%[sdv%]/g;
var format = function (formatStr) {
  var i = 1;
  var args = arguments;
  var len = args.length;
  return formatStr.replace(formatRegExp, function (x) {
    if (i >= len) {
      return x; // missing argument
    }
    var arg = args[i];
    i += 1;
    switch (x) {
    case '%%':
      return '%';
    case '%s':
      return String(arg);
    case '%d':
      return Number(arg);
    case '%v':
      return '';
    }
  });
  // NB: we discard excess arguments - they are typically undefined from makeLine
};

var makeLine = function (type, obj, location) {
  var str = obj.format instanceof Function ?
    (obj.format(obj.push ? location : location[obj.name])) :
    obj.format;

  var args = [type + '=' + str];
  if (obj.names) {
    for (var i = 0; i < obj.names.length; i += 1) {
      var n = obj.names[i];
      if (obj.name) {
        args.push(location[obj.name][n]);
      }
      else { // for mLine and push attributes
        args.push(location[obj.names[i]]);
      }
    }
  }
  else {
    args.push(location[obj.name]);
  }
  return format.apply(null, args);
};

// RFC specified order
// TODO: extend this with all the rest
var defaultOuterOrder = [
  'v', 'o', 's', 'i',
  'u', 'e', 'p', 'c',
  'b', 't', 'r', 'z', 'a'
];
var defaultInnerOrder = ['i', 'c', 'b', 'a'];


module.exports = function (session, opts) {
  opts = opts || {};
  // ensure certain properties exist
  if (session.version == null) {
    session.version = 0; // 'v=0' must be there (only defined version atm)
  }
  if (session.name == null) {
    session.name = ' '; // 's= ' must be there if no meaningful name set
  }
  session.media.forEach(function (mLine) {
    if (mLine.payloads == null) {
      mLine.payloads = '';
    }
  });

  var outerOrder = opts.outerOrder || defaultOuterOrder;
  var innerOrder = opts.innerOrder || defaultInnerOrder;
  var sdp = [];

  // loop through outerOrder for matching properties on session
  outerOrder.forEach(function (type) {
    grammar[type].forEach(function (obj) {
      if (obj.name in session && session[obj.name] != null) {
        sdp.push(makeLine(type, obj, session));
      }
      else if (obj.push in session && session[obj.push] != null) {
        session[obj.push].forEach(function (el) {
          sdp.push(makeLine(type, obj, el));
        });
      }
    });
  });

  // then for each media line, follow the innerOrder
  session.media.forEach(function (mLine) {
    sdp.push(makeLine('m', grammar.m[0], mLine));

    innerOrder.forEach(function (type) {
      grammar[type].forEach(function (obj) {
        if (obj.name in mLine && mLine[obj.name] != null) {
          sdp.push(makeLine(type, obj, mLine));
        }
        else if (obj.push in mLine && mLine[obj.push] != null) {
          mLine[obj.push].forEach(function (el) {
            sdp.push(makeLine(type, obj, el));
          });
        }
      });
    });
  });

  return sdp.join('\r\n') + '\r\n';
};


/***/ }),

/***/ "./node_modules/@jitsi/sdp-simulcast/lib/index.js":
/*!********************************************************!*\
  !*** ./node_modules/@jitsi/sdp-simulcast/lib/index.js ***!
  \********************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

/* Copyright @ 2016 Atlassian Pty Ltd
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

var transform = __webpack_require__(/*! sdp-transform */ "./node_modules/sdp-transform/lib/index.js");
var transformUtils = __webpack_require__(/*! ./transform-utils */ "./node_modules/@jitsi/sdp-simulcast/lib/transform-utils.js");
var parseSsrcs = transformUtils.parseSsrcs;
var writeSsrcs = transformUtils.writeSsrcs;

//region Constants

var DEFAULT_NUM_OF_LAYERS = 3;

//endregion

function getSsrcAttribute (mLine, ssrc, attributeName) {
    return mLine
        .ssrcs
        .filter(function(ssrcInfo) { return ssrcInfo.id === ssrc; })
        .filter(function(ssrcInfo) { return ssrcInfo.attribute === attributeName; })
        .map(function(ssrcInfo) { return ssrcInfo.value; })[0];
}

//region Ctor

function Simulcast(options) {

    this.options = options ? options : {};

    if (!this.options.numOfLayers) {
        this.options.numOfLayers = DEFAULT_NUM_OF_LAYERS;
    }
    console.log("SdpSimulcast: using " + this.options.numOfLayers + " layers");

    /**
     * An IN-ORDER list of the simulcast ssrcs
     * @type {list<number>}
     */
    this.ssrcCache = [];
}

//endregion

//region Stateless private utility functions

/**
 * Returns a random integer between min (included) and max (excluded)
 * Using Math.round() gives a non-uniform distribution!
 * @returns {number}
 */
function generateSSRC() {
    var min = 0, max = 0xffffffff;
    return Math.floor(Math.random() * (max - min)) + min;
};

function processVideo(session, action) {
    if (session == null || !Array.isArray(session.media)) {
        return;
    }

    session.media.forEach(function (mLine) {
        if (mLine.type === 'video') {
            action(mLine);
        }
    });
};

function validateDescription(desc)
{
    return desc && desc != null
        && desc.type && desc.type != ''
        && desc.sdp && desc.sdp != '';
}

function explodeRemoteSimulcast(mLine) {

    if (!mLine || !Array.isArray(mLine.ssrcGroups)) {
        return;
    }

    var sources = parseSsrcs(mLine);
    var order = [];

    // Find the SIM group and explode its sources.
    var j = mLine.ssrcGroups.length;
    while (j--) {

        if (mLine.ssrcGroups[j].semantics !== 'SIM') {
            continue;
        }

        var simulcastSsrcs = mLine.ssrcGroups[j].ssrcs.split(' ');

        for (var i = 0; i < simulcastSsrcs.length; i++) {

            var ssrc = simulcastSsrcs[i];
            order.push(ssrc);

            var parts = sources[ssrc].msid.split(' ');
            sources[ssrc].msid = [parts[0], '/', i, ' ', parts[1], '/', i].join('');
            sources[ssrc].cname = [sources[ssrc].cname, '/', i].join('');

            // Remove all the groups that this SSRC participates in.
            mLine.ssrcGroups.forEach(function (relatedGroup) {
                if (relatedGroup.semantics === 'SIM') {
                    return;
                }

                var relatedSsrcs = relatedGroup.ssrcs.split(' ');
                if (relatedSsrcs.indexOf(ssrc) === -1) {
                    return;
                }

                // Nuke all the related SSRCs.
                relatedSsrcs.forEach(function (relatedSSRC) {
                    sources[relatedSSRC].msid = sources[ssrc].msid;
                    sources[relatedSSRC].cname = sources[ssrc].cname;
                    if (relatedSSRC !== ssrc) {
                        order.push(relatedSSRC);
                    }
                });

                // Schedule the related group for nuking.
            })
        }

        mLine.ssrcs = writeSsrcs(sources, order);
        mLine.ssrcGroups.splice(j, 1);
    };
}

function implodeRemoteSimulcast(mLine) {

    if (!mLine || !Array.isArray(mLine.ssrcGroups)) {
        console.info('Halt: There are no SSRC groups in the remote ' +
                'description.');
        return;
    }

    var sources = parseSsrcs(mLine);

    // Find the SIM group and nuke it.
    mLine.ssrcGroups.forEach(function (simulcastGroup) {
        if (simulcastGroup.semantics !== 'SIM') {
            return;
        }

        console.info("Imploding SIM group: " + simulcastGroup.ssrcs);
        // Schedule the SIM group for nuking.
        simulcastGroup.nuke = true;

        var simulcastSsrcs = simulcastGroup.ssrcs.split(' ');

        // Nuke all the higher layer SSRCs.
        for (var i = 1; i < simulcastSsrcs.length; i++) {

            var ssrc = simulcastSsrcs[i];
            delete sources[ssrc];

            // Remove all the groups that this SSRC participates in.
            mLine.ssrcGroups.forEach(function (relatedGroup) {
                if (relatedGroup.semantics === 'SIM') {
                    return;
                }

                var relatedSsrcs = relatedGroup.ssrcs.split(' ');
                if (relatedSsrcs.indexOf(ssrc) === -1) {
                    return;
                }

                // Nuke all the related SSRCs.
                relatedSsrcs.forEach(function (relatedSSRC) {
                    delete sources[relatedSSRC];
                });

                // Schedule the related group for nuking.
                relatedGroup.nuke = true;
            })
        }

        return;
    });

    mLine.ssrcs = writeSsrcs(sources);

    // Nuke all the scheduled groups.
    var i = mLine.ssrcGroups.length;
    while (i--) {
        if (mLine.ssrcGroups[i].nuke) {
            mLine.ssrcGroups.splice(i, 1);
        }
    }
}

function removeGoogConference(mLine) {
    if (!mLine || typeof mLine.xGoogleFlag === 'undefined') {
        return;
    }

    mLine.xGoogleFlag = undefined;
}

function assertGoogConference(mLine) {
    if (!mLine) {
        return;
    }

    if (!Array.isArray(mLine.invalid)) {
        mLine.invalid = [];
    }

    if (!mLine.invalid.some(
            function (i) { return i.value === 'x-google-flag:conference' })) {
        mLine.invalid.push({'value': 'x-google-flag:conference'});
    }
}

Simulcast.prototype.clearSsrcCache = function() {
    this.ssrcCache = [];
}

/**
 * When we start as video muted, all of the video
 *  ssrcs get generated so we can include them as part
 *  of the original session-accept.  That means we
 *  need this library to restore to those same ssrcs
 *  the first time we unmute, so we need the ability to
 *  force its cache
 */
Simulcast.prototype.setSsrcCache = function(ssrcs) {
    this.ssrcCache = ssrcs;
}

//endregion

//region "Private" functions

/**
 * Given a video mLine, return a list of the video ssrcs
 *  in simulcast layer order (returns a list of just
 *  the primary ssrc if there are no simulcast layers)
 */
Simulcast.prototype._parseSimLayers = function (mLine) {
    var simGroup = mLine.ssrcGroups &&
        mLine.ssrcGroups.find(function(group) { return group.semantics === "SIM"; });
    if (simGroup) {
        return simGroup.ssrcs
            .split(" ")
            .map(function(ssrcStr) { return parseInt(ssrcStr) });
    } else {
        return [mLine.ssrcs[0].id];
    }
}

Simulcast.prototype._buildNewToOldSsrcMap = function (newSsrcList, oldSsrcList) {
    var ssrcMap = {};
    for (var i = 0; i < newSsrcList.length; ++i) {
        var newSsrc = newSsrcList[i];
        var oldSsrc = oldSsrcList[i] || null;
        ssrcMap[newSsrc] = oldSsrc;
    }
    return ssrcMap;
}

Simulcast.prototype._fillInSourceDataFromCache = function(mLine) {
    console.log("SdpSimulcast restoring from cache: ", this.ssrcCache);
    var newSimSsrcs = this._parseSimLayers(mLine);
    console.log("SdpSimulcast Parsed new sim ssrcs: ", newSimSsrcs);
    var newMsid = getSsrcAttribute(mLine, newSimSsrcs[0], "msid");
    var newCname = getSsrcAttribute(mLine, newSimSsrcs[0], "cname");
    var ssrcsToReplace = this._buildNewToOldSsrcMap(newSimSsrcs, this.ssrcCache);
    console.log("SdpSimulcast built replacement map: ", ssrcsToReplace);
    // New sdp might only have 1 layer, so not every cached ssrc will have a new one
    //  to replace directly
    var ssrcsToAdd = this.ssrcCache
        .filter(function(ssrc) { return Object.values(ssrcsToReplace).indexOf(ssrc) === -1; });
    console.log("SdpSimulcast built ssrcs to add: ", ssrcsToAdd);

    // First do the replacements
    mLine.ssrcs.forEach(function(ssrc) {
        if (ssrcsToReplace[ssrc.id]) {
            ssrc.id = ssrcsToReplace[ssrc.id];
        }
    });
    // Now the adds
    ssrcsToAdd.forEach(function(ssrc) {
        mLine.ssrcs.push({
            id: ssrc,
            attribute: "msid",
            value: newMsid
        });
        mLine.ssrcs.push({
            id: ssrc,
            attribute: "cname",
            value: newCname
        });
    });
    mLine.ssrcGroups = mLine.ssrcGroups || [];
    mLine.ssrcGroups.push({
        semantics: "SIM",
        ssrcs: this.ssrcCache.join(" ")
    });
    return mLine;
}

Simulcast.prototype._generateSourceData = function(mLine, primarySsrc) {
    var addAssociatedStream = function(mLine, ssrc) {
        mLine.ssrcs.push({
            id: ssrc,
            attribute: "cname",
            value: primarySsrcCname
        });
        mLine.ssrcs.push({
            id: ssrc,
            attribute: "msid",
            value: primarySsrcMsid
        });
    }
    var primarySsrcMsid = getSsrcAttribute(mLine, primarySsrc, "msid");
    var primarySsrcCname = getSsrcAttribute(mLine, primarySsrc, "cname");

    // In Unified-plan mode, the a=ssrc lines with the msid attribute are not present
    // in the answers that Chrome and Safari generate for an offer received from Jicofo.
    // Generate these a=ssrc lines using the msid values from the a=msid line.
    if (this.options.usesUnifiedPlan && !primarySsrcMsid) {
        primarySsrcMsid = mLine.msid;
        var primarySsrcs = mLine.ssrcs;
        primarySsrcs.forEach(ssrc => {
            mLine.ssrcs.push({
                id: ssrc.id,
                attribute: "msid",
                value: primarySsrcMsid
            });
        });
    }

    // Generate sim layers
    var simSsrcs = [];
    for (var i = 0; i < this.options.numOfLayers - 1; ++i) {
        var simSsrc = generateSSRC();
        addAssociatedStream(mLine, simSsrc);
        simSsrcs.push(simSsrc);
    }
    mLine.ssrcGroups = mLine.ssrcGroups || [];
    mLine.ssrcGroups.push({
        semantics: "SIM",
        ssrcs: primarySsrc + " " + simSsrcs.join(" ")
    });
    return mLine;
}



// Assumptions:
//  1) 'mLine' contains only a single primary video source
//   (i.e. it will not already have simulcast streams inserted)
//  2) 'mLine' MAY already contain an RTX stream for its video source
//  3) 'mLine' is in sendrecv or sendonly state
// Guarantees:
//  1) return mLine will contain 2 additional simulcast layers
//   generated
//  2) if the base video ssrc in mLine has been seen before,
//   then the same generated simulcast streams from before will
//   be used again
//  3) if rtx is enabled for the mLine, all generated simulcast
//   streams will have rtx streams generated as well
//  4) if rtx has been generated for a src before, we will generate
//   the same rtx stream again
Simulcast.prototype._restoreSimulcast = function(mLine) {
    // First, find the primary video source in the given
    // mLine and see if we've seen it before.
    var primarySsrc;
    var numSsrcs = mLine.ssrcs && mLine.ssrcs
        .map(function(ssrcInfo) { return ssrcInfo.id; })
        .filter(function(ssrc, index, array) {
            return array.indexOf(ssrc) === index;
        })
        .length || 0;
    var numGroups = (mLine.ssrcGroups && mLine.ssrcGroups.length) || 0;

    if (numSsrcs === 0 || numSsrcs > 2) {
        // Unsupported scenario
        return mLine;
    }
    if (numSsrcs == 2 && numGroups === 0) {
        // Unsupported scenario
        return mLine;
    }

    if (numSsrcs === 1) {
        primarySsrc = mLine.ssrcs[0].id;
    } else {
        // There must be an FID group, so parse
        //  that and pull the primary ssrc from there
        var fidGroup = mLine.ssrcGroups.filter(function(group) { return group.semantics === "FID"; })[0];
        if (fidGroup) {
            primarySsrc = parseInt(fidGroup.ssrcs.split(" ")[0]);
        } else {
            // Unsupported scenario
            return mLine;
        }
    }
    console.log("SdpSimulcast: current ssrc cache: ", this.ssrcCache);
    console.log("SdpSimulcast: parsed primary ssrc " + primarySsrc);

    var seenPrimarySsrc = this.ssrcCache.indexOf(primarySsrc) !== -1;

    if (seenPrimarySsrc) {
        console.log("SdpSimulcast: Have seen primary ssrc before, " +
            "filling in data from cache");
        mLine = this._fillInSourceDataFromCache(mLine);
    } else {
        console.log("SdpSimulcast: Have not seen primary ssrc before, " +
            "generating source data");
        mLine = this._generateSourceData(mLine, primarySsrc);
    }
    // Now update the cache to match whatever we've just put into this sdp
    this.ssrcCache = this._parseSimLayers(mLine);
    return mLine;
}

//endregion

//region "Public" functions

/**
 *
 * @param desc
 * @param enableConferenceFlag
 * @returns {RTCSessionDescription}
 */
Simulcast.prototype.mungeRemoteDescription = function (desc, enableConferenceFlag) {

    if (!validateDescription(desc)) {
        return desc;
    }

    var session = transform.parse(desc.sdp);

    var self = this;
    processVideo(session, function (mLine) {

        // Handle simulcast reception.
        if (self.options.explodeRemoteSimulcast) {
            explodeRemoteSimulcast(mLine);
        } else {
            implodeRemoteSimulcast(mLine);
        }

        // Add or remove "x-google-conference" from the remote description based on whether the client
        // has enabled simulcast for the local video source. For cases where we disable simulcast for desktop share,
        // it is necessary to remove the flag so that Chrome stops sending T1 temporal layers. It also fixes other
        // issues related to screensharing like https://bugs.chromium.org/p/chromium/issues/detail?id=1093819.
        if (!self.options.usesUnifiedPlan && enableConferenceFlag) {
            assertGoogConference(mLine);
        } else {
            removeGoogConference(mLine);
        }
    });

    return new RTCSessionDescription({
        type: desc.type,
        sdp: transform.write(session)
    });
};

/**
 *
 * NOTE this method should be called only if simulcast is supported by
 * the current browser, otherwise local SDP should not be munged.
 * @param desc
 * @returns {RTCSessionDescription}
 */
Simulcast.prototype.mungeLocalDescription = function (desc) {

    if (!validateDescription(desc)) {
        return desc;
    }

    var session = transform.parse(desc.sdp);

    var self = this;
    processVideo(session, function (mLine) {
        if (mLine.direction == 'recvonly' || mLine.direction == 'inactive')
        {
            return;
        }
        self._restoreSimulcast(mLine);
    });

    return new RTCSessionDescription({
        type: desc.type,
        sdp: transform.write(session)
    });
};

//endregion

module.exports = Simulcast;


/***/ }),

/***/ "./node_modules/@jitsi/sdp-simulcast/lib/transform-utils.js":
/*!******************************************************************!*\
  !*** ./node_modules/@jitsi/sdp-simulcast/lib/transform-utils.js ***!
  \******************************************************************/
/***/ ((__unused_webpack_module, exports) => {

/* Copyright @ 2015 Atlassian Pty Ltd
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

/**
 * FIXME
 * @param sources FIXME
 * @param order An array of SSRCs which will be used to order the entries in
 * the returned array. Sources whose SSRC appears in 'order' will be added first,
 * in the specified order, and all other sources will be added afterwards (in
 * no specific order).
 * @returns {Array} FIXME
 */
exports.writeSsrcs = function(sources, order) {
  var ssrcs = [];

  // expand sources to ssrcs
  if (typeof sources !== 'undefined' &&
      Object.keys(sources).length !== 0) {

    if (!Array.isArray(order)) {
      order = []
    }

    // Add the sources that appear in 'order' first.
    for (var i = 0; i < order.length; i++) {
      var ssrc = order[i];
      var source = sources[ssrc];
      Object.keys(source).forEach(function (attribute) {
        ssrcs.push({
          id: ssrc,
          attribute: attribute,
          value: source[attribute]
        });
      });
    }

    // Now add the rest of the sources.
    Object.keys(sources).forEach(function (ssrc) {
      ssrc = parseInt(ssrc); // Object.keys() returns string
      if (order.indexOf(ssrc) >= 0) {
        // Already added.
        return;
      }

      var source = sources[ssrc];
      Object.keys(source).forEach(function (attribute) {
        ssrcs.push({
          id: ssrc,
          attribute: attribute,
          value: source[attribute]
        });
      });
    });
  }

  return ssrcs;
};

exports.parseSsrcs = function (mLine) {
  var sources = {};
  // group sources attributes by ssrc.
  if (typeof mLine.ssrcs !== 'undefined' && Array.isArray(mLine.ssrcs)) {
    mLine.ssrcs.forEach(function (ssrc) {
      if (!sources[ssrc.id])
        sources[ssrc.id] = {};
      sources[ssrc.id][ssrc.attribute] = ssrc.value;
    });
  }
  return sources;
};



/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/JitsiConference.js":
/*!************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/JitsiConference.js ***!
  \************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
var __filename = "/index.js";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (/* binding */ JitsiConference)
/* harmony export */ });
/* harmony import */ var _jitsi_logger__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @jitsi/logger */ "./node_modules/@jitsi/logger/lib/index.js");
/* harmony import */ var _jitsi_logger__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(_jitsi_logger__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var events__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! events */ "./node_modules/events/events.js");
/* harmony import */ var events__WEBPACK_IMPORTED_MODULE_1___default = /*#__PURE__*/__webpack_require__.n(events__WEBPACK_IMPORTED_MODULE_1__);
/* harmony import */ var jquery__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! jquery */ "./node_modules/jquery/dist/jquery.js");
/* harmony import */ var jquery__WEBPACK_IMPORTED_MODULE_2___default = /*#__PURE__*/__webpack_require__.n(jquery__WEBPACK_IMPORTED_MODULE_2__);
/* harmony import */ var lodash_isequal__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! lodash.isequal */ "./node_modules/lodash.isequal/index.js");
/* harmony import */ var lodash_isequal__WEBPACK_IMPORTED_MODULE_3___default = /*#__PURE__*/__webpack_require__.n(lodash_isequal__WEBPACK_IMPORTED_MODULE_3__);
/* harmony import */ var strophe_js__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! strophe.js */ "./node_modules/strophe.js/dist/strophe.umd.js");
/* harmony import */ var strophe_js__WEBPACK_IMPORTED_MODULE_4___default = /*#__PURE__*/__webpack_require__.n(strophe_js__WEBPACK_IMPORTED_MODULE_4__);
/* harmony import */ var _JitsiConferenceErrors__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./JitsiConferenceErrors */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/JitsiConferenceErrors.js");
/* harmony import */ var _JitsiConferenceEventManager__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./JitsiConferenceEventManager */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/JitsiConferenceEventManager.js");
/* harmony import */ var _JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./JitsiConferenceEvents */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/JitsiConferenceEvents.js");
/* harmony import */ var _JitsiParticipant__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ./JitsiParticipant */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/JitsiParticipant.js");
/* harmony import */ var _JitsiTrackError__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ./JitsiTrackError */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/JitsiTrackError.js");
/* harmony import */ var _JitsiTrackErrors__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ./JitsiTrackErrors */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/JitsiTrackErrors.js");
/* harmony import */ var _JitsiTrackEvents__WEBPACK_IMPORTED_MODULE_11__ = __webpack_require__(/*! ./JitsiTrackEvents */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/JitsiTrackEvents.js");
/* harmony import */ var _authenticateAndUpgradeRole__WEBPACK_IMPORTED_MODULE_12__ = __webpack_require__(/*! ./authenticateAndUpgradeRole */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/authenticateAndUpgradeRole.js");
/* harmony import */ var _modules_RTC_CodecSelection__WEBPACK_IMPORTED_MODULE_13__ = __webpack_require__(/*! ./modules/RTC/CodecSelection */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/RTC/CodecSelection.js");
/* harmony import */ var _modules_RTC_RTC__WEBPACK_IMPORTED_MODULE_14__ = __webpack_require__(/*! ./modules/RTC/RTC */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/RTC/RTC.js");
/* harmony import */ var _modules_RTC_ScreenObtainer__WEBPACK_IMPORTED_MODULE_15__ = __webpack_require__(/*! ./modules/RTC/ScreenObtainer */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/RTC/ScreenObtainer.js");
/* harmony import */ var _modules_browser__WEBPACK_IMPORTED_MODULE_16__ = __webpack_require__(/*! ./modules/browser */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/browser/index.js");
/* harmony import */ var _modules_connectivity_ConnectionQuality__WEBPACK_IMPORTED_MODULE_17__ = __webpack_require__(/*! ./modules/connectivity/ConnectionQuality */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/connectivity/ConnectionQuality.js");
/* harmony import */ var _modules_connectivity_IceFailedHandling__WEBPACK_IMPORTED_MODULE_18__ = __webpack_require__(/*! ./modules/connectivity/IceFailedHandling */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/connectivity/IceFailedHandling.js");
/* harmony import */ var _modules_detection_DetectionEvents__WEBPACK_IMPORTED_MODULE_19__ = __webpack_require__(/*! ./modules/detection/DetectionEvents */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/detection/DetectionEvents.js");
/* harmony import */ var _modules_detection_NoAudioSignalDetection__WEBPACK_IMPORTED_MODULE_20__ = __webpack_require__(/*! ./modules/detection/NoAudioSignalDetection */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/detection/NoAudioSignalDetection.js");
/* harmony import */ var _modules_detection_P2PDominantSpeakerDetection__WEBPACK_IMPORTED_MODULE_21__ = __webpack_require__(/*! ./modules/detection/P2PDominantSpeakerDetection */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/detection/P2PDominantSpeakerDetection.js");
/* harmony import */ var _modules_detection_VADAudioAnalyser__WEBPACK_IMPORTED_MODULE_22__ = __webpack_require__(/*! ./modules/detection/VADAudioAnalyser */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/detection/VADAudioAnalyser.js");
/* harmony import */ var _modules_detection_VADNoiseDetection__WEBPACK_IMPORTED_MODULE_23__ = __webpack_require__(/*! ./modules/detection/VADNoiseDetection */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/detection/VADNoiseDetection.js");
/* harmony import */ var _modules_detection_VADTalkMutedDetection__WEBPACK_IMPORTED_MODULE_24__ = __webpack_require__(/*! ./modules/detection/VADTalkMutedDetection */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/detection/VADTalkMutedDetection.js");
/* harmony import */ var _modules_e2ee_E2EEncryption__WEBPACK_IMPORTED_MODULE_25__ = __webpack_require__(/*! ./modules/e2ee/E2EEncryption */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/e2ee/E2EEncryption.js");
/* harmony import */ var _modules_e2eping_e2eping__WEBPACK_IMPORTED_MODULE_26__ = __webpack_require__(/*! ./modules/e2eping/e2eping */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/e2eping/e2eping.js");
/* harmony import */ var _modules_event_Jvb121EventGenerator__WEBPACK_IMPORTED_MODULE_27__ = __webpack_require__(/*! ./modules/event/Jvb121EventGenerator */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/event/Jvb121EventGenerator.js");
/* harmony import */ var _modules_flags_FeatureFlags__WEBPACK_IMPORTED_MODULE_28__ = __webpack_require__(/*! ./modules/flags/FeatureFlags */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/flags/FeatureFlags.js");
/* harmony import */ var _modules_litemode_LiteModeContext__WEBPACK_IMPORTED_MODULE_29__ = __webpack_require__(/*! ./modules/litemode/LiteModeContext */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/litemode/LiteModeContext.js");
/* harmony import */ var _modules_qualitycontrol_ReceiveVideoController__WEBPACK_IMPORTED_MODULE_30__ = __webpack_require__(/*! ./modules/qualitycontrol/ReceiveVideoController */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/qualitycontrol/ReceiveVideoController.js");
/* harmony import */ var _modules_qualitycontrol_SendVideoController__WEBPACK_IMPORTED_MODULE_31__ = __webpack_require__(/*! ./modules/qualitycontrol/SendVideoController */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/qualitycontrol/SendVideoController.js");
/* harmony import */ var _modules_recording_RecordingManager__WEBPACK_IMPORTED_MODULE_32__ = __webpack_require__(/*! ./modules/recording/RecordingManager */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/recording/RecordingManager.js");
/* harmony import */ var _modules_settings_Settings__WEBPACK_IMPORTED_MODULE_33__ = __webpack_require__(/*! ./modules/settings/Settings */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/settings/Settings.js");
/* harmony import */ var _modules_statistics_AudioOutputProblemDetector__WEBPACK_IMPORTED_MODULE_34__ = __webpack_require__(/*! ./modules/statistics/AudioOutputProblemDetector */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/statistics/AudioOutputProblemDetector.js");
/* harmony import */ var _modules_statistics_AvgRTPStatsReporter__WEBPACK_IMPORTED_MODULE_35__ = __webpack_require__(/*! ./modules/statistics/AvgRTPStatsReporter */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/statistics/AvgRTPStatsReporter.js");
/* harmony import */ var _modules_statistics_LocalStatsCollector__WEBPACK_IMPORTED_MODULE_36__ = __webpack_require__(/*! ./modules/statistics/LocalStatsCollector */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/statistics/LocalStatsCollector.js");
/* harmony import */ var _modules_statistics_SpeakerStatsCollector__WEBPACK_IMPORTED_MODULE_37__ = __webpack_require__(/*! ./modules/statistics/SpeakerStatsCollector */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/statistics/SpeakerStatsCollector.js");
/* harmony import */ var _modules_statistics_statistics__WEBPACK_IMPORTED_MODULE_38__ = __webpack_require__(/*! ./modules/statistics/statistics */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/statistics/statistics.js");
/* harmony import */ var _modules_transcription_transcriber__WEBPACK_IMPORTED_MODULE_39__ = __webpack_require__(/*! ./modules/transcription/transcriber */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/transcription/transcriber.js");
/* harmony import */ var _modules_util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_40__ = __webpack_require__(/*! ./modules/util/GlobalOnErrorHandler */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/util/GlobalOnErrorHandler.js");
/* harmony import */ var _modules_util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_40___default = /*#__PURE__*/__webpack_require__.n(_modules_util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_40__);
/* harmony import */ var _modules_util_RandomUtil__WEBPACK_IMPORTED_MODULE_41__ = __webpack_require__(/*! ./modules/util/RandomUtil */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/util/RandomUtil.js");
/* harmony import */ var _modules_util_RandomUtil__WEBPACK_IMPORTED_MODULE_41___default = /*#__PURE__*/__webpack_require__.n(_modules_util_RandomUtil__WEBPACK_IMPORTED_MODULE_41__);
/* harmony import */ var _modules_version_ComponentsVersions__WEBPACK_IMPORTED_MODULE_42__ = __webpack_require__(/*! ./modules/version/ComponentsVersions */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/version/ComponentsVersions.js");
/* harmony import */ var _modules_videosipgw_VideoSIPGW__WEBPACK_IMPORTED_MODULE_43__ = __webpack_require__(/*! ./modules/videosipgw/VideoSIPGW */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/videosipgw/VideoSIPGW.js");
/* harmony import */ var _modules_videosipgw_VideoSIPGWConstants__WEBPACK_IMPORTED_MODULE_44__ = __webpack_require__(/*! ./modules/videosipgw/VideoSIPGWConstants */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/videosipgw/VideoSIPGWConstants.js");
/* harmony import */ var _modules_xmpp_SignalingLayerImpl__WEBPACK_IMPORTED_MODULE_45__ = __webpack_require__(/*! ./modules/xmpp/SignalingLayerImpl */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/xmpp/SignalingLayerImpl.js");
/* harmony import */ var _modules_xmpp_xmpp__WEBPACK_IMPORTED_MODULE_46__ = __webpack_require__(/*! ./modules/xmpp/xmpp */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/xmpp/xmpp.js");
/* harmony import */ var _service_RTC_BridgeVideoType__WEBPACK_IMPORTED_MODULE_47__ = __webpack_require__(/*! ./service/RTC/BridgeVideoType */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/RTC/BridgeVideoType.js");
/* harmony import */ var _service_RTC_BridgeVideoType__WEBPACK_IMPORTED_MODULE_47___default = /*#__PURE__*/__webpack_require__.n(_service_RTC_BridgeVideoType__WEBPACK_IMPORTED_MODULE_47__);
/* harmony import */ var _service_RTC_CodecMimeType__WEBPACK_IMPORTED_MODULE_48__ = __webpack_require__(/*! ./service/RTC/CodecMimeType */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/RTC/CodecMimeType.js");
/* harmony import */ var _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_49__ = __webpack_require__(/*! ./service/RTC/MediaType */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/RTC/MediaType.js");
/* harmony import */ var _service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_50__ = __webpack_require__(/*! ./service/RTC/RTCEvents */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/RTC/RTCEvents.js");
/* harmony import */ var _service_RTC_SignalingEvents__WEBPACK_IMPORTED_MODULE_51__ = __webpack_require__(/*! ./service/RTC/SignalingEvents */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/RTC/SignalingEvents.js");
/* harmony import */ var _service_RTC_SignalingLayer__WEBPACK_IMPORTED_MODULE_52__ = __webpack_require__(/*! ./service/RTC/SignalingLayer */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/RTC/SignalingLayer.js");
/* harmony import */ var _service_RTC_VideoType__WEBPACK_IMPORTED_MODULE_53__ = __webpack_require__(/*! ./service/RTC/VideoType */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/RTC/VideoType.js");
/* harmony import */ var _service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_54__ = __webpack_require__(/*! ./service/statistics/AnalyticsEvents */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/statistics/AnalyticsEvents.js");
/* harmony import */ var _service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_55__ = __webpack_require__(/*! ./service/xmpp/XMPPEvents */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/xmpp/XMPPEvents.js");
var __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {
    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};
























































const logger = (0,_jitsi_logger__WEBPACK_IMPORTED_MODULE_0__.getLogger)(__filename);
/**
 * How long since Jicofo is supposed to send a session-initiate, before
 * {@link ACTION_JINGLE_SI_TIMEOUT} analytics event is sent (in ms).
 * @type {number}
 */
const JINGLE_SI_TIMEOUT = 5000;
/**
 * Checks if a given string is a valid video codec mime type.
 *
 * @param {string} codec the codec string that needs to be validated.
 * @returns {CodecMimeType|null} mime type if valid, null otherwise.
 * @private
 */
function _getCodecMimeType(codec) {
    if (typeof codec === 'string') {
        return Object.values(_service_RTC_CodecMimeType__WEBPACK_IMPORTED_MODULE_48__["default"]).find(value => value === codec.toLowerCase());
    }
    return null;
}
/**
 * Creates a JitsiConference object with the given name and properties.
 * Note: this constructor is not a part of the public API (objects should be
 * created using JitsiConnection.createConference).
 * @param options.config properties / settings related to the conference that
 * will be created.
 * @param options.name the name of the conference
 * @param options.connection the JitsiConnection object for this
 * JitsiConference.
 * @param {number} [options.config.avgRtpStatsN=15] how many samples are to be
 * collected by {@link AvgRTPStatsReporter}, before arithmetic mean is
 * calculated and submitted to the analytics module.
 * @param {boolean} [options.config.enableIceRestart=false] - enables the ICE
 * restart logic.
 * @param {boolean} [options.config.p2p.enabled] when set to <tt>true</tt>
 * the peer to peer mode will be enabled. It means that when there are only 2
 * participants in the conference an attempt to make direct connection will be
 * made. If the connection succeeds the conference will stop sending data
 * through the JVB connection and will use the direct one instead.
 * @param {number} [options.config.p2p.backToP2PDelay=5] a delay given in
 * seconds, before the conference switches back to P2P, after the 3rd
 * participant has left the room.
 * @param {number} [options.config.channelLastN=-1] The requested amount of
 * videos are going to be delivered after the value is in effect. Set to -1 for
 * unlimited or all available videos.
 * @param {number} [options.config.forceJVB121Ratio]
 * "Math.random() < forceJVB121Ratio" will determine whether a 2 people
 * conference should be moved to the JVB instead of P2P. The decision is made on
 * the responder side, after ICE succeeds on the P2P connection.
 * @constructor
 *
 * FIXME Make all methods which are called from lib-internal classes
 *       to non-public (use _). To name a few:
 *       {@link JitsiConference.onLocalRoleChanged}
 *       {@link JitsiConference.onUserRoleChanged}
 *       {@link JitsiConference.onMemberLeft}
 *       and so on...
 */
function JitsiConference(options) {
    var _a, _b, _c;
    if (!options.name || options.name.toLowerCase() !== options.name.toString()) {
        const errmsg = 'Invalid conference name (no conference name passed or it '
            + 'contains invalid characters like capital letters)!';
        logger.error(errmsg);
        throw new Error(errmsg);
    }
    this.connection = options.connection;
    this.xmpp = (_a = this.connection) === null || _a === void 0 ? void 0 : _a.xmpp;
    if (this.xmpp.isRoomCreated(options.name, options.customDomain)) {
        const errmsg = 'A conference with the same name has already been created!';
        delete this.connection;
        delete this.xmpp;
        logger.error(errmsg);
        throw new Error(errmsg);
    }
    this.eventEmitter = new (events__WEBPACK_IMPORTED_MODULE_1___default())();
    this.options = options;
    this.eventManager = new _JitsiConferenceEventManager__WEBPACK_IMPORTED_MODULE_6__["default"](this);
    /**
     * List of all the participants in the conference.
     * @type {Map<string, JitsiParticipant>};
     */
    this.participants = new Map();
    /**
     * The signaling layer instance.
     * @type {SignalingLayerImpl}
     * @private
     */
    this._signalingLayer = new _modules_xmpp_SignalingLayerImpl__WEBPACK_IMPORTED_MODULE_45__["default"]();
    this._init(options);
    this.componentsVersions = new _modules_version_ComponentsVersions__WEBPACK_IMPORTED_MODULE_42__["default"](this);
    /**
     * Jingle session instance for the JVB connection.
     * @type {JingleSessionPC}
     */
    this.jvbJingleSession = null;
    this.lastDominantSpeaker = null;
    this.dtmfManager = null;
    this.somebodySupportsDTMF = false;
    this.authEnabled = false;
    this.startAudioMuted = false;
    this.startVideoMuted = false;
    this.startMutedPolicy = {
        audio: false,
        video: false
    };
    this.isMutedByFocus = false;
    // when muted by focus we receive the jid of the initiator of the mute
    this.mutedByFocusActor = null;
    this.isVideoMutedByFocus = false;
    // when video muted by focus we receive the jid of the initiator of the mute
    this.mutedVideoByFocusActor = null;
    // Flag indicates if the 'onCallEnded' method was ever called on this
    // instance. Used to log extra analytics event for debugging purpose.
    // We need to know if the potential issue happened before or after
    // the restart.
    this.wasStopped = false;
    // Conference properties, maintained by jicofo.
    this.properties = {};
    /**
     * The object which monitors local and remote connection statistics (e.g.
     * sending bitrate) and calculates a number which represents the connection
     * quality.
     */
    this.connectionQuality
        = new _modules_connectivity_ConnectionQuality__WEBPACK_IMPORTED_MODULE_17__["default"](this, this.eventEmitter, options);
    /**
     * Reports average RTP statistics to the analytics module.
     * @type {AvgRTPStatsReporter}
     */
    this.avgRtpStatsReporter
        = new _modules_statistics_AvgRTPStatsReporter__WEBPACK_IMPORTED_MODULE_35__["default"](this, options.config.avgRtpStatsN || 15);
    /**
     * Detects issues with the audio of remote participants.
     * @type {AudioOutputProblemDetector}
     */
    if (!options.config.disableAudioLevels) {
        this._audioOutputProblemDetector = new _modules_statistics_AudioOutputProblemDetector__WEBPACK_IMPORTED_MODULE_34__["default"](this);
    }
    /**
     * Indicates whether the connection is interrupted or not.
     */
    this.isJvbConnectionInterrupted = false;
    /**
     * The object which tracks active speaker times
     */
    this.speakerStatsCollector = new _modules_statistics_SpeakerStatsCollector__WEBPACK_IMPORTED_MODULE_37__["default"](this);
    /* P2P related fields below: */
    /**
     * Stores reference to deferred start P2P task. It's created when 3rd
     * participant leaves the room in order to avoid ping pong effect (it
     * could be just a page reload).
     * @type {number|null}
     */
    this.deferredStartP2PTask = null;
    const delay = parseInt(options.config.p2p && options.config.p2p.backToP2PDelay, 10);
    /**
     * A delay given in seconds, before the conference switches back to P2P
     * after the 3rd participant has left.
     * @type {number}
     */
    this.backToP2PDelay = isNaN(delay) ? 5 : delay;
    logger.info(`backToP2PDelay: ${this.backToP2PDelay}`);
    /**
     * If set to <tt>true</tt> it means the P2P ICE is no longer connected.
     * When <tt>false</tt> it means that P2P ICE (media) connection is up
     * and running.
     * @type {boolean}
     */
    this.isP2PConnectionInterrupted = false;
    /**
     * Flag set to <tt>true</tt> when P2P session has been established
     * (ICE has been connected) and this conference is currently in the peer to
     * peer mode (P2P connection is the active one).
     * @type {boolean}
     */
    this.p2p = false;
    /**
     * A JingleSession for the direct peer to peer connection.
     * @type {JingleSessionPC}
     */
    this.p2pJingleSession = null;
    this.videoSIPGWHandler = new _modules_videosipgw_VideoSIPGW__WEBPACK_IMPORTED_MODULE_43__["default"](this.room);
    this.recordingManager = new _modules_recording_RecordingManager__WEBPACK_IMPORTED_MODULE_32__["default"](this.room);
    /**
     * If the conference.joined event has been sent this will store the timestamp when it happened.
     *
     * @type {undefined|number}
     * @private
     */
    this._conferenceJoinAnalyticsEventSent = undefined;
    /**
     * End-to-End Encryption. Make it available if supported.
     */
    if (this.isE2EESupported()) {
        logger.info('End-to-End Encryption is supported');
        this._e2eEncryption = new _modules_e2ee_E2EEncryption__WEBPACK_IMPORTED_MODULE_25__.E2EEncryption(this);
    }
    if (_modules_flags_FeatureFlags__WEBPACK_IMPORTED_MODULE_28__["default"].isRunInLiteModeEnabled()) {
        logger.info('Lite mode enabled');
        this._liteModeContext = new _modules_litemode_LiteModeContext__WEBPACK_IMPORTED_MODULE_29__.LiteModeContext(this);
    }
    /**
     * Flag set to <tt>true</tt> when Jicofo sends a presence message indicating that the max audio sender limit has
     * been reached for the call. Once this is set, unmuting audio will be disabled from the client until it gets reset
     * again by Jicofo.
     */
    this._audioSenderLimitReached = undefined;
    /**
     * Flag set to <tt>true</tt> when Jicofo sends a presence message indicating that the max video sender limit has
     * been reached for the call. Once this is set, unmuting video will be disabled from the client until it gets reset
     * again by Jicofo.
     */
    this._videoSenderLimitReached = undefined;
    this._firefoxP2pEnabled = _modules_browser__WEBPACK_IMPORTED_MODULE_16__["default"].isVersionGreaterThan(109)
        && ((_c = (_b = this.options.config.testing) === null || _b === void 0 ? void 0 : _b.enableFirefoxP2p) !== null && _c !== void 0 ? _c : true);
}
// FIXME convert JitsiConference to ES6 - ASAP !
JitsiConference.prototype.constructor = JitsiConference;
/**
 * Create a resource for the a jid. We use the room nickname (the resource part
 * of the occupant JID, see XEP-0045) as the endpoint ID in colibri. We require
 * endpoint IDs to be 8 hex digits because in some cases they get serialized
 * into a 32bit field.
 *
 * @param {string} jid - The id set onto the XMPP connection.
 * @param {boolean} isAuthenticatedUser - Whether or not the user has connected
 * to the XMPP service with a password.
 * @returns {string}
 * @static
 */
JitsiConference.resourceCreator = function (jid, isAuthenticatedUser) {
    var _a;
    let mucNickname;
    if (isAuthenticatedUser) {
        // For authenticated users generate a random ID.
        mucNickname = _modules_util_RandomUtil__WEBPACK_IMPORTED_MODULE_41___default().randomHexString(8).toLowerCase();
    }
    else {
        // We try to use the first part of the node (which for anonymous users
        // on prosody is a UUID) to match the previous behavior (and maybe make
        // debugging easier).
        mucNickname = (_a = strophe_js__WEBPACK_IMPORTED_MODULE_4__.Strophe.getNodeFromJid(jid)) === null || _a === void 0 ? void 0 : _a.substr(0, 8).toLowerCase();
        // But if this doesn't have the required format we just generate a new
        // random nickname.
        const re = /[0-9a-f]{8}/g;
        if (!mucNickname || !re.test(mucNickname)) {
            mucNickname = _modules_util_RandomUtil__WEBPACK_IMPORTED_MODULE_41___default().randomHexString(8).toLowerCase();
        }
    }
    return mucNickname;
};
/**
 * Initializes the conference object properties
 * @param options {object}
 * @param options.connection {JitsiConnection} overrides this.connection
 */
JitsiConference.prototype._init = function (options = {}) {
    var _a, _b, _c, _d, _e, _f, _g, _h, _j;
    this.eventManager.setupXMPPListeners();
    const { config } = this.options;
    // Get the codec preference settings from config.js.
    const codecSettings = {
        jvb: {
            preferenceOrder: _modules_browser__WEBPACK_IMPORTED_MODULE_16__["default"].isMobileDevice() && ((_a = config.videoQuality) === null || _a === void 0 ? void 0 : _a.mobileCodecPreferenceOrder)
                ? config.videoQuality.mobileCodecPreferenceOrder
                : (_b = config.videoQuality) === null || _b === void 0 ? void 0 : _b.codecPreferenceOrder,
            disabledCodec: _getCodecMimeType((_c = config.videoQuality) === null || _c === void 0 ? void 0 : _c.disabledCodec),
            preferredCodec: _getCodecMimeType((_d = config.videoQuality) === null || _d === void 0 ? void 0 : _d.preferredCodec)
        },
        p2p: {
            preferenceOrder: _modules_browser__WEBPACK_IMPORTED_MODULE_16__["default"].isMobileDevice() && ((_e = config.p2p) === null || _e === void 0 ? void 0 : _e.mobileCodecPreferenceOrder)
                ? config.p2p.mobileCodecPreferenceOrder
                : (_f = config.p2p) === null || _f === void 0 ? void 0 : _f.codecPreferenceOrder,
            disabledCodec: _getCodecMimeType((_g = config.p2p) === null || _g === void 0 ? void 0 : _g.disabledCodec),
            preferredCodec: _getCodecMimeType((_h = config.p2p) === null || _h === void 0 ? void 0 : _h.preferredCodec)
        }
    };
    this.codecSelection = new _modules_RTC_CodecSelection__WEBPACK_IMPORTED_MODULE_13__.CodecSelection(this, codecSettings);
    this._statsCurrentId = config.statisticsId ? config.statisticsId : _modules_settings_Settings__WEBPACK_IMPORTED_MODULE_33__["default"].callStatsUserName;
    this.room = this.xmpp.createRoom(this.options.name, Object.assign(Object.assign({}, config), { statsId: this._statsCurrentId }), JitsiConference.resourceCreator);
    this._signalingLayer.setChatRoom(this.room);
    this._signalingLayer.on(_service_RTC_SignalingEvents__WEBPACK_IMPORTED_MODULE_51__.SignalingEvents.SOURCE_UPDATED, (sourceName, endpointId, muted, videoType) => {
        const participant = this.participants.get(endpointId);
        const mediaType = (0,_service_RTC_SignalingLayer__WEBPACK_IMPORTED_MODULE_52__.getMediaTypeFromSourceName)(sourceName);
        if (participant) {
            participant._setSources(mediaType, muted, sourceName, videoType);
            this.eventEmitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_7__.PARTICIPANT_SOURCE_UPDATED, participant);
        }
    });
    // Connection interrupted/restored listeners
    this._onIceConnectionInterrupted
        = this._onIceConnectionInterrupted.bind(this);
    this.room.addListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_55__.XMPPEvents.CONNECTION_INTERRUPTED, this._onIceConnectionInterrupted);
    this._onIceConnectionRestored = this._onIceConnectionRestored.bind(this);
    this.room.addListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_55__.XMPPEvents.CONNECTION_RESTORED, this._onIceConnectionRestored);
    this._onIceConnectionEstablished
        = this._onIceConnectionEstablished.bind(this);
    this.room.addListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_55__.XMPPEvents.CONNECTION_ESTABLISHED, this._onIceConnectionEstablished);
    this._updateProperties = this._updateProperties.bind(this);
    this.room.addListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_55__.XMPPEvents.CONFERENCE_PROPERTIES_CHANGED, this._updateProperties);
    this._sendConferenceJoinAnalyticsEvent = this._sendConferenceJoinAnalyticsEvent.bind(this);
    this.room.addListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_55__.XMPPEvents.MEETING_ID_SET, this._sendConferenceJoinAnalyticsEvent);
    this._removeLocalSourceOnReject = this._removeLocalSourceOnReject.bind(this);
    this._updateRoomPresence = this._updateRoomPresence.bind(this);
    this.room.addListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_55__.XMPPEvents.SESSION_ACCEPT, this._updateRoomPresence);
    this.room.addListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_55__.XMPPEvents.SOURCE_ADD, this._updateRoomPresence);
    this.room.addListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_55__.XMPPEvents.SOURCE_ADD_ERROR, this._removeLocalSourceOnReject);
    this.room.addListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_55__.XMPPEvents.SOURCE_REMOVE, this._updateRoomPresence);
    if ((_j = config.e2eping) === null || _j === void 0 ? void 0 : _j.enabled) {
        this.e2eping = new _modules_e2eping_e2eping__WEBPACK_IMPORTED_MODULE_26__["default"](this, config, (message, to) => {
            try {
                this.sendMessage(message, to, true /* sendThroughVideobridge */);
            }
            catch (error) {
                logger.warn('Failed to send E2E ping request or response.', error && error.msg);
            }
        });
    }
    if (!this.rtc) {
        this.rtc = new _modules_RTC_RTC__WEBPACK_IMPORTED_MODULE_14__["default"](this, options);
        this.eventManager.setupRTCListeners();
        this._registerRtcListeners(this.rtc);
    }
    this.receiveVideoController = new _modules_qualitycontrol_ReceiveVideoController__WEBPACK_IMPORTED_MODULE_30__["default"](this, this.rtc);
    this.sendVideoController = new _modules_qualitycontrol_SendVideoController__WEBPACK_IMPORTED_MODULE_31__["default"](this, this.rtc);
    if (!this.statistics) {
        this.statistics = new _modules_statistics_statistics__WEBPACK_IMPORTED_MODULE_38__["default"](this.xmpp, {
            aliasName: this._statsCurrentId,
            userName: config.statisticsDisplayName ? config.statisticsDisplayName : this.myUserId(),
            confID: config.confID || `${this.connection.options.hosts.domain}/${this.options.name}`,
            siteID: config.siteID,
            customScriptUrl: config.callStatsCustomScriptUrl,
            callStatsID: config.callStatsID,
            callStatsSecret: config.callStatsSecret,
            callStatsApplicationLogsDisabled: config.callStatsApplicationLogsDisabled,
            roomName: this.options.name,
            applicationName: config.applicationName,
            configParams: config.callStatsConfigParams
        });
        _modules_statistics_statistics__WEBPACK_IMPORTED_MODULE_38__["default"].analytics.addPermanentProperties({
            'callstats_name': this._statsCurrentId
        });
        // Start performance observer for monitoring long tasks
        if (config.longTasksStatsInterval) {
            this.statistics.attachLongTasksStats(this);
        }
    }
    this.eventManager.setupChatRoomListeners();
    // Always add listeners because on reload we are executing leave and the
    // listeners are removed from statistics module.
    this.eventManager.setupStatisticsListeners();
    // Disable VAD processing on Safari since it causes audio input to
    // fail on some of the mobile devices.
    if (config.enableTalkWhileMuted && _modules_browser__WEBPACK_IMPORTED_MODULE_16__["default"].supportsVADDetection()) {
        // If VAD processor factory method is provided uses VAD based detection, otherwise fallback to audio level
        // based detection.
        if (config.createVADProcessor) {
            logger.info('Using VAD detection for generating talk while muted events');
            if (!this._audioAnalyser) {
                this._audioAnalyser = new _modules_detection_VADAudioAnalyser__WEBPACK_IMPORTED_MODULE_22__["default"](this, config.createVADProcessor);
            }
            const vadTalkMutedDetection = new _modules_detection_VADTalkMutedDetection__WEBPACK_IMPORTED_MODULE_24__["default"]();
            vadTalkMutedDetection.on(_modules_detection_DetectionEvents__WEBPACK_IMPORTED_MODULE_19__.VAD_TALK_WHILE_MUTED, () => this.eventEmitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_7__.TALK_WHILE_MUTED));
            this._audioAnalyser.addVADDetectionService(vadTalkMutedDetection);
        }
        else {
            logger.warn('No VAD Processor was provided. Talk while muted detection service was not initialized!');
        }
    }
    // Disable noisy mic detection on safari since it causes the audio input to
    // fail on Safari on iPadOS.
    if (config.enableNoisyMicDetection && _modules_browser__WEBPACK_IMPORTED_MODULE_16__["default"].supportsVADDetection()) {
        if (config.createVADProcessor) {
            if (!this._audioAnalyser) {
                this._audioAnalyser = new _modules_detection_VADAudioAnalyser__WEBPACK_IMPORTED_MODULE_22__["default"](this, config.createVADProcessor);
            }
            const vadNoiseDetection = new _modules_detection_VADNoiseDetection__WEBPACK_IMPORTED_MODULE_23__["default"]();
            vadNoiseDetection.on(_modules_detection_DetectionEvents__WEBPACK_IMPORTED_MODULE_19__.VAD_NOISY_DEVICE, () => this.eventEmitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_7__.NOISY_MIC));
            this._audioAnalyser.addVADDetectionService(vadNoiseDetection);
        }
        else {
            logger.warn('No VAD Processor was provided. Noisy microphone detection service was not initialized!');
        }
    }
    // Generates events based on no audio input detector.
    if (config.enableNoAudioDetection && !config.disableAudioLevels && _modules_statistics_LocalStatsCollector__WEBPACK_IMPORTED_MODULE_36__["default"].isLocalStatsSupported()) {
        this._noAudioSignalDetection = new _modules_detection_NoAudioSignalDetection__WEBPACK_IMPORTED_MODULE_20__["default"](this);
        this._noAudioSignalDetection.on(_modules_detection_DetectionEvents__WEBPACK_IMPORTED_MODULE_19__.NO_AUDIO_INPUT, () => {
            this.eventEmitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_7__.NO_AUDIO_INPUT);
        });
        this._noAudioSignalDetection.on(_modules_detection_DetectionEvents__WEBPACK_IMPORTED_MODULE_19__.AUDIO_INPUT_STATE_CHANGE, hasAudioSignal => {
            this.eventEmitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_7__.AUDIO_INPUT_STATE_CHANGE, hasAudioSignal);
        });
    }
    if ('channelLastN' in config) {
        this.setLastN(config.channelLastN);
    }
    /**
     * Emits {@link JitsiConferenceEvents.JVB121_STATUS}.
     * @type {Jvb121EventGenerator}
     */
    this.jvb121Status = new _modules_event_Jvb121EventGenerator__WEBPACK_IMPORTED_MODULE_27__["default"](this);
    // creates dominant speaker detection that works only in p2p mode
    this.p2pDominantSpeakerDetection = new _modules_detection_P2PDominantSpeakerDetection__WEBPACK_IMPORTED_MODULE_21__["default"](this);
    if (config && config.deploymentInfo && config.deploymentInfo.userRegion) {
        this.setLocalParticipantProperty('region', config.deploymentInfo.userRegion);
    }
    // Publish the codec preference to presence.
    this.setLocalParticipantProperty('codecList', this.codecSelection.getCodecPreferenceList('jvb'));
    // Set transcription language presence extension.
    // In case the language config is undefined or has the default value that the transcriber uses
    // (in our case Jigasi uses 'en-US'), don't set the participant property in order to avoid
    // needlessly polluting the presence stanza.
    if (config && config.transcriptionLanguage && config.transcriptionLanguage !== 'en-US') {
        this.setLocalParticipantProperty('transcription_language', config.transcriptionLanguage);
    }
};
/**
 * Joins the conference.
 * @param password {string} the password
 * @param replaceParticipant {boolean} whether the current join replaces
 * an existing participant with same jwt from the meeting.
 */
JitsiConference.prototype.join = function (password, replaceParticipant = false) {
    if (this.room) {
        this.room.join(password, replaceParticipant).then(() => this._maybeSetSITimeout());
    }
};
/**
 * Authenticates and upgrades the role of the local participant/user.
 *
 * @returns {Object} A <tt>thenable</tt> which (1) settles when the process of
 * authenticating and upgrading the role of the local participant/user finishes
 * and (2) has a <tt>cancel</tt> method that allows the caller to interrupt the
 * process.
 */
JitsiConference.prototype.authenticateAndUpgradeRole = function (options) {
    return _authenticateAndUpgradeRole__WEBPACK_IMPORTED_MODULE_12__["default"].call(this, Object.assign(Object.assign({}, options), { onCreateResource: JitsiConference.resourceCreator }));
};
/**
 * Check if joined to the conference.
 */
JitsiConference.prototype.isJoined = function () {
    return this.room && this.room.joined;
};
/**
 * Tells whether or not the P2P mode is enabled in the configuration.
 * @return {boolean}
 */
JitsiConference.prototype.isP2PEnabled = function () {
    return Boolean(this.options.config.p2p && this.options.config.p2p.enabled)
        // FIXME: remove once we have a default config template. -saghul
        || typeof this.options.config.p2p === 'undefined';
};
/**
 * When in P2P test mode, the conference will not automatically switch to P2P
 * when there 2 participants.
 * @return {boolean}
 */
JitsiConference.prototype.isP2PTestModeEnabled = function () {
    return Boolean(this.options.config.testing
        && this.options.config.testing.p2pTestMode);
};
/**
 * Leaves the conference.
 * @param reason {string|undefined} The reason for leaving the conference.
 * @returns {Promise}
 */
JitsiConference.prototype.leave = function (reason) {
    return __awaiter(this, void 0, void 0, function* () {
        if (this.avgRtpStatsReporter) {
            this.avgRtpStatsReporter.dispose();
            this.avgRtpStatsReporter = null;
        }
        if (this._audioOutputProblemDetector) {
            this._audioOutputProblemDetector.dispose();
            this._audioOutputProblemDetector = null;
        }
        if (this.e2eping) {
            this.e2eping.stop();
            this.e2eping = null;
        }
        this.getLocalTracks().forEach(track => this.onLocalTrackRemoved(track));
        this.rtc.closeBridgeChannel();
        this._sendConferenceLeftAnalyticsEvent();
        if (this.statistics) {
            this.statistics.dispose();
        }
        this._delayedIceFailed && this._delayedIceFailed.cancel();
        this._maybeClearSITimeout();
        // Close both JVb and P2P JingleSessions
        if (this.jvbJingleSession) {
            this.jvbJingleSession.close();
            this.jvbJingleSession = null;
        }
        if (this.p2pJingleSession) {
            this.p2pJingleSession.close();
            this.p2pJingleSession = null;
        }
        // Leave the conference. If this.room == null we are calling second time leave().
        if (!this.room) {
            throw new Error('You have already left the conference');
        }
        const room = this.room;
        // Unregister connection state listeners
        room.removeListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_55__.XMPPEvents.CONNECTION_INTERRUPTED, this._onIceConnectionInterrupted);
        room.removeListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_55__.XMPPEvents.CONNECTION_RESTORED, this._onIceConnectionRestored);
        room.removeListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_55__.XMPPEvents.CONNECTION_ESTABLISHED, this._onIceConnectionEstablished);
        room.removeListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_55__.XMPPEvents.CONFERENCE_PROPERTIES_CHANGED, this._updateProperties);
        room.removeListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_55__.XMPPEvents.MEETING_ID_SET, this._sendConferenceJoinAnalyticsEvent);
        room.removeListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_55__.XMPPEvents.SESSION_ACCEPT, this._updateRoomPresence);
        room.removeListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_55__.XMPPEvents.SOURCE_ADD, this._updateRoomPresence);
        room.removeListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_55__.XMPPEvents.SOURCE_ADD_ERROR, this._removeLocalSourceOnReject);
        room.removeListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_55__.XMPPEvents.SOURCE_REMOVE, this._updateRoomPresence);
        this.eventManager.removeXMPPListeners();
        this._signalingLayer.setChatRoom(null);
        this.room = null;
        let leaveError;
        try {
            yield room.leave(reason);
        }
        catch (err) {
            leaveError = err;
            // Remove all participants because currently the conference
            // won't be usable anyway. This is done on success automatically
            // by the ChatRoom instance.
            this.getParticipants().forEach(participant => this.onMemberLeft(participant.getJid()));
        }
        if (this.rtc) {
            this.rtc.destroy();
        }
        if (leaveError) {
            throw leaveError;
        }
    });
};
/**
 * Returns <tt>true</tt> if end conference support is enabled in the backend.
 *
 * @returns {boolean} whether end conference is supported in the backend.
 */
JitsiConference.prototype.isEndConferenceSupported = function () {
    return Boolean(this.room && this.room.xmpp.endConferenceComponentAddress);
};
/**
 * Ends the conference.
 */
JitsiConference.prototype.end = function () {
    if (!this.isEndConferenceSupported()) {
        logger.warn('Cannot end conference: is not supported.');
        return;
    }
    if (!this.room) {
        throw new Error('You have already left the conference');
    }
    this.room.end();
};
/**
 * Returns the currently active media session if any.
 *
 * @returns {JingleSessionPC|undefined}
 */
JitsiConference.prototype.getActiveMediaSession = function () {
    return this.isP2PActive() ? this.p2pJingleSession : this.jvbJingleSession;
};
/**
 * Returns an array containing all media sessions existing in this conference.
 *
 * @returns {Array<JingleSessionPC>}
 */
JitsiConference.prototype.getMediaSessions = function () {
    const sessions = [];
    this.jvbJingleSession && sessions.push(this.jvbJingleSession);
    this.p2pJingleSession && sessions.push(this.p2pJingleSession);
    return sessions;
};
/**
 * Registers event listeners on the RTC instance.
 * @param {RTC} rtc - the RTC module instance used by this conference.
 * @private
 * @returns {void}
 */
JitsiConference.prototype._registerRtcListeners = function (rtc) {
    rtc.addListener(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_50__["default"].DATA_CHANNEL_OPEN, () => {
        for (const localTrack of this.rtc.localTracks) {
            localTrack.isVideoTrack() && this._sendBridgeVideoTypeMessage(localTrack);
        }
    });
};
/**
 * Sends the 'VideoTypeMessage' to the bridge on the bridge channel so that the bridge can make bitrate allocation
 * decisions based on the video type of the local source.
 *
 * @param {JitsiLocalTrack} localtrack - The track associated with the local source signaled to the bridge.
 * @returns {void}
 * @private
 */
JitsiConference.prototype._sendBridgeVideoTypeMessage = function (localtrack) {
    let videoType = !localtrack || localtrack.isMuted() ? (_service_RTC_BridgeVideoType__WEBPACK_IMPORTED_MODULE_47___default().NONE) : localtrack.getVideoType();
    if (videoType === (_service_RTC_BridgeVideoType__WEBPACK_IMPORTED_MODULE_47___default().DESKTOP) && this._desktopSharingFrameRate > _modules_RTC_ScreenObtainer__WEBPACK_IMPORTED_MODULE_15__.SS_DEFAULT_FRAME_RATE) {
        videoType = (_service_RTC_BridgeVideoType__WEBPACK_IMPORTED_MODULE_47___default().DESKTOP_HIGH_FPS);
    }
    localtrack && this.rtc.sendSourceVideoType(localtrack.getSourceName(), videoType);
};
/**
 * Returns name of this conference.
 */
JitsiConference.prototype.getName = function () {
    return this.options.name.toString();
};
/**
 * Returns the {@link JitsiConnection} used by this this conference.
 */
JitsiConference.prototype.getConnection = function () {
    return this.connection;
};
/**
 * Check if authentication is enabled for this conference.
 */
JitsiConference.prototype.isAuthEnabled = function () {
    return this.authEnabled;
};
/**
 * Check if user is logged in.
 */
JitsiConference.prototype.isLoggedIn = function () {
    return Boolean(this.authIdentity);
};
/**
 * Get authorized login.
 */
JitsiConference.prototype.getAuthLogin = function () {
    return this.authIdentity;
};
/**
 * Check if external authentication is enabled for this conference.
 */
JitsiConference.prototype.isExternalAuthEnabled = function () {
    return this.room && this.room.moderator.isExternalAuthEnabled();
};
/**
 * Get url for external authentication.
 * @param {boolean} [urlForPopup] if true then return url for login popup,
 *                                else url of login page.
 * @returns {Promise}
 */
JitsiConference.prototype.getExternalAuthUrl = function (urlForPopup) {
    return new Promise((resolve, reject) => {
        if (!this.isExternalAuthEnabled()) {
            reject();
            return;
        }
        if (urlForPopup) {
            this.room.moderator.getPopupLoginUrl(resolve, reject);
        }
        else {
            this.room.moderator.getLoginUrl(resolve, reject);
        }
    });
};
/**
 * Returns the local tracks of the given media type, or all local tracks if no
 * specific type is given.
 * @param {MediaType} [mediaType] Optional media type (audio or video).
 */
JitsiConference.prototype.getLocalTracks = function (mediaType) {
    let tracks = [];
    if (this.rtc) {
        tracks = this.rtc.getLocalTracks(mediaType);
    }
    return tracks;
};
/**
 * Obtains local audio track.
 * @return {JitsiLocalTrack|null}
 */
JitsiConference.prototype.getLocalAudioTrack = function () {
    return this.rtc ? this.rtc.getLocalAudioTrack() : null;
};
/**
 * Obtains local video track.
 * @return {JitsiLocalTrack|null}
 */
JitsiConference.prototype.getLocalVideoTrack = function () {
    return this.rtc ? this.rtc.getLocalVideoTrack() : null;
};
/**
 * Returns all the local video tracks.
 * @returns {Array<JitsiLocalTrack>}
 */
JitsiConference.prototype.getLocalVideoTracks = function () {
    return this.rtc ? this.rtc.getLocalVideoTracks() : null;
};
/**
 * Obtains the performance statistics.
 * @returns {Object|null}
 */
JitsiConference.prototype.getPerformanceStats = function () {
    return {
        longTasksStats: this.statistics.getLongTasksStats()
    };
};
/**
 * Attaches a handler for events(For example - "participant joined".) in the
 * conference. All possible event are defined in JitsiConferenceEvents.
 * @param eventId the event ID.
 * @param handler handler for the event.
 *
 * Note: consider adding eventing functionality by extending an EventEmitter
 * impl, instead of rolling ourselves
 */
JitsiConference.prototype.on = function (eventId, handler) {
    if (this.eventEmitter) {
        this.eventEmitter.on(eventId, handler);
    }
};
/**
 * Removes event listener
 * @param eventId the event ID.
 * @param [handler] optional, the specific handler to unbind
 *
 * Note: consider adding eventing functionality by extending an EventEmitter
 * impl, instead of rolling ourselves
 */
JitsiConference.prototype.off = function (eventId, handler) {
    if (this.eventEmitter) {
        this.eventEmitter.removeListener(eventId, handler);
    }
};
// Common aliases for event emitter
JitsiConference.prototype.addEventListener = JitsiConference.prototype.on;
JitsiConference.prototype.removeEventListener = JitsiConference.prototype.off;
/**
 * Receives notifications from other participants about commands / custom events
 * (sent by sendCommand or sendCommandOnce methods).
 * @param command {String} the name of the command
 * @param handler {Function} handler for the command
 */
JitsiConference.prototype.addCommandListener = function (command, handler) {
    if (this.room) {
        this.room.addPresenceListener(command, handler);
    }
};
/**
  * Removes command  listener
  * @param command {String} the name of the command
  * @param handler {Function} handler to remove for the command
  */
JitsiConference.prototype.removeCommandListener = function (command, handler) {
    if (this.room) {
        this.room.removePresenceListener(command, handler);
    }
};
/**
 * Sends text message to the other participants in the conference
 * @param message the text message.
 * @param elementName the element name to encapsulate the message.
 * @deprecated Use 'sendMessage' instead. TODO: this should be private.
 */
JitsiConference.prototype.sendTextMessage = function (message, elementName = 'body') {
    if (this.room) {
        this.room.sendMessage(message, elementName);
    }
};
/**
 * Send private text message to another participant of the conference
 * @param id the id of the participant to send a private message.
 * @param message the text message.
 * @param elementName the element name to encapsulate the message.
 * @deprecated Use 'sendMessage' instead. TODO: this should be private.
 */
JitsiConference.prototype.sendPrivateTextMessage = function (id, message, elementName = 'body') {
    if (this.room) {
        this.room.sendPrivateMessage(id, message, elementName);
    }
};
/**
 * Send presence command.
 * @param name {String} the name of the command.
 * @param values {Object} with keys and values that will be sent.
 **/
JitsiConference.prototype.sendCommand = function (name, values) {
    if (this.room) {
        this.room.addOrReplaceInPresence(name, values) && this.room.sendPresence();
    }
    else {
        logger.warn('Not sending a command, room not initialized.');
    }
};
/**
 * Send presence command one time.
 * @param name {String} the name of the command.
 * @param values {Object} with keys and values that will be sent.
 **/
JitsiConference.prototype.sendCommandOnce = function (name, values) {
    this.sendCommand(name, values);
    this.removeCommand(name);
};
/**
 * Removes presence command.
 * @param name {String} the name of the command.
 **/
JitsiConference.prototype.removeCommand = function (name) {
    if (this.room) {
        this.room.removeFromPresence(name);
    }
};
/**
 * Sets the display name for this conference.
 * @param name the display name to set
 */
JitsiConference.prototype.setDisplayName = function (name) {
    if (this.room) {
        const nickKey = 'nick';
        if (name) {
            this.room.addOrReplaceInPresence(nickKey, {
                attributes: { xmlns: 'http://jabber.org/protocol/nick' },
                value: name
            }) && this.room.sendPresence();
        }
        else if (this.room.getFromPresence(nickKey)) {
            this.room.removeFromPresence(nickKey);
            this.room.sendPresence();
        }
    }
};
/**
 * Set new subject for this conference. (available only for moderator)
 * @param {string} subject new subject
 */
JitsiConference.prototype.setSubject = function (subject) {
    if (this.room && this.isModerator()) {
        this.room.setSubject(subject);
    }
    else {
        logger.warn(`Failed to set subject, ${this.room ? '' : 'not in a room, '}${this.isModerator() ? '' : 'participant is not a moderator'}`);
    }
};
/**
 * Get a transcriber object for all current participants in this conference
 * @return {Transcriber} the transcriber object
 */
JitsiConference.prototype.getTranscriber = function () {
    if (this.transcriber === undefined) {
        this.transcriber = new _modules_transcription_transcriber__WEBPACK_IMPORTED_MODULE_39__["default"]();
        // add all existing local audio tracks to the transcriber
        const localAudioTracks = this.getLocalTracks(_service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_49__.MediaType.AUDIO);
        for (const localAudio of localAudioTracks) {
            this.transcriber.addTrack(localAudio);
        }
        // and all remote audio tracks
        const remoteAudioTracks = this.rtc.getRemoteTracks(_service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_49__.MediaType.AUDIO);
        for (const remoteTrack of remoteAudioTracks) {
            this.transcriber.addTrack(remoteTrack);
        }
    }
    return this.transcriber;
};
/**
 * Returns the transcription status.
 *
 * @returns {String} "on" or "off".
 */
JitsiConference.prototype.getTranscriptionStatus = function () {
    return this.room.transcriptionStatus;
};
/**
 * Adds JitsiLocalTrack object to the conference.
 * @param {JitsiLocalTrack} track the JitsiLocalTrack object.
 * @returns {Promise<JitsiLocalTrack>}
 * @throws {Error} if the specified track is a video track and there is already
 * another video track in the conference.
 */
JitsiConference.prototype.addTrack = function (track) {
    var _a;
    if (!track) {
        throw new Error('addTrack - a track is required');
    }
    const mediaType = track.getType();
    const localTracks = this.rtc.getLocalTracks(mediaType);
    // Ensure there's exactly 1 local track of each media type in the conference.
    if (localTracks.length > 0) {
        // Don't be excessively harsh and severe if the API client happens to attempt to add the same local track twice.
        if (track === localTracks[0]) {
            return Promise.resolve(track);
        }
        // Currently, only adding multiple video streams of different video types is supported.
        // TODO - remove this limitation once issues with jitsi-meet trying to add multiple camera streams is fixed.
        if (_modules_flags_FeatureFlags__WEBPACK_IMPORTED_MODULE_28__["default"].isMultiStreamSendSupportEnabled()
            && mediaType === _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_49__.MediaType.VIDEO
            && !localTracks.find(t => t.getVideoType() === track.getVideoType())) {
            const sourceName = (0,_service_RTC_SignalingLayer__WEBPACK_IMPORTED_MODULE_52__.getSourceNameForJitsiTrack)(this.myUserId(), mediaType, (_a = this.getLocalTracks(mediaType)) === null || _a === void 0 ? void 0 : _a.length);
            track.setSourceName(sourceName);
            const addTrackPromises = [];
            this.p2pJingleSession && addTrackPromises.push(this.p2pJingleSession.addTracks([track]));
            this.jvbJingleSession && addTrackPromises.push(this.jvbJingleSession.addTracks([track]));
            return Promise.all(addTrackPromises)
                .then(() => {
                this._setupNewTrack(track);
                this._sendBridgeVideoTypeMessage(track);
                this._updateRoomPresence(this.getActiveMediaSession());
                if (this.isMutedByFocus || this.isVideoMutedByFocus) {
                    this._fireMuteChangeEvent(track);
                }
            });
        }
        return Promise.reject(new Error(`Cannot add second ${mediaType} track to the conference`));
    }
    return this.replaceTrack(null, track)
        .then(() => {
        // Presence needs to be sent here for desktop track since we need the presence to reach the remote peer
        // before signaling so that a fake participant tile is created for screenshare. Otherwise, presence will
        // only be sent after a session-accept or source-add is ack'ed.
        if (track.getVideoType() === _service_RTC_VideoType__WEBPACK_IMPORTED_MODULE_53__.VideoType.DESKTOP && _modules_flags_FeatureFlags__WEBPACK_IMPORTED_MODULE_28__["default"].isMultiStreamSendSupportEnabled()) {
            this._updateRoomPresence(this.getActiveMediaSession());
        }
    });
};
/**
 * Fires TRACK_AUDIO_LEVEL_CHANGED change conference event (for local tracks).
 * @param {number} audioLevel the audio level
 * @param {TraceablePeerConnection} [tpc]
 */
JitsiConference.prototype._fireAudioLevelChangeEvent = function (audioLevel, tpc) {
    const activeTpc = this.getActivePeerConnection();
    // There will be no TraceablePeerConnection if audio levels do not come from
    // a peerconnection. LocalStatsCollector.js measures audio levels using Web
    // Audio Analyser API and emits local audio levels events through
    // JitsiTrack.setAudioLevel, but does not provide TPC instance which is
    // optional.
    if (!tpc || activeTpc === tpc) {
        this.eventEmitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_7__.TRACK_AUDIO_LEVEL_CHANGED, this.myUserId(), audioLevel);
    }
};
/**
 * Fires TRACK_MUTE_CHANGED change conference event.
 * @param track the JitsiTrack object related to the event.
 */
JitsiConference.prototype._fireMuteChangeEvent = function (track) {
    // check if track was muted by focus and now is unmuted by user
    if (this.isMutedByFocus && track.isAudioTrack() && !track.isMuted()) {
        this.isMutedByFocus = false;
        // unmute local user on server
        this.room.muteParticipant(this.room.myroomjid, false, _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_49__.MediaType.AUDIO);
    }
    else if (this.isVideoMutedByFocus && track.isVideoTrack() && !track.isMuted()) {
        this.isVideoMutedByFocus = false;
        // unmute local user on server
        this.room.muteParticipant(this.room.myroomjid, false, _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_49__.MediaType.VIDEO);
    }
    let actorParticipant;
    if (this.mutedByFocusActor && track.isAudioTrack()) {
        const actorId = strophe_js__WEBPACK_IMPORTED_MODULE_4__.Strophe.getResourceFromJid(this.mutedByFocusActor);
        actorParticipant = this.participants.get(actorId);
    }
    else if (this.mutedVideoByFocusActor && track.isVideoTrack()) {
        const actorId = strophe_js__WEBPACK_IMPORTED_MODULE_4__.Strophe.getResourceFromJid(this.mutedVideoByFocusActor);
        actorParticipant = this.participants.get(actorId);
    }
    // Send the video type message to the bridge if the track is not removed/added to the pc as part of
    // the mute/unmute operation.
    // In React Native we mute the camera by setting track.enabled but that doesn't
    // work for screen-share tracks, so do the remove-as-mute for those.
    const doesVideoMuteByStreamRemove = _modules_browser__WEBPACK_IMPORTED_MODULE_16__["default"].isReactNative() ? track.videoType === _service_RTC_VideoType__WEBPACK_IMPORTED_MODULE_53__.VideoType.DESKTOP : _modules_browser__WEBPACK_IMPORTED_MODULE_16__["default"].doesVideoMuteByStreamRemove();
    if (track.isVideoTrack() && !doesVideoMuteByStreamRemove) {
        this._sendBridgeVideoTypeMessage(track);
    }
    this.eventEmitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_7__.TRACK_MUTE_CHANGED, track, actorParticipant);
};
/**
 * Returns the list of local tracks that need to be added to the peerconnection on join.
 * This takes the startAudioMuted/startVideoMuted flags into consideration since we do not
 * want to add the tracks if the user joins the call audio/video muted. The tracks will be
 * added when the user unmutes for the first time.
 * @returns {Array<JitsiLocalTrack>} - list of local tracks that are unmuted.
 */
JitsiConference.prototype._getInitialLocalTracks = function () {
    // Always add the audio track on certain platforms:
    //  * Safari / WebKit: because of a known issue where audio playout doesn't happen
    //    if the user joins audio and video muted.
    //  * React Native: after iOS 15, if a user joins muted they won't be able to unmute.
    return this.getLocalTracks()
        .filter(track => {
        const trackType = track.getType();
        if (trackType === _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_49__.MediaType.AUDIO
            && (!(this.isStartAudioMuted() || this.startMutedPolicy.audio)
                || _modules_browser__WEBPACK_IMPORTED_MODULE_16__["default"].isWebKitBased()
                || _modules_browser__WEBPACK_IMPORTED_MODULE_16__["default"].isReactNative())) {
            return true;
        }
        else if (trackType === _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_49__.MediaType.VIDEO && !this.isStartVideoMuted() && !this.startMutedPolicy.video) {
            return true;
        }
        return false;
    });
};
/**
 * Clear JitsiLocalTrack properties and listeners.
 * @param track the JitsiLocalTrack object.
 */
JitsiConference.prototype.onLocalTrackRemoved = function (track) {
    track.setConference(null);
    this.rtc.removeLocalTrack(track);
    track.removeEventListener(_JitsiTrackEvents__WEBPACK_IMPORTED_MODULE_11__.TRACK_MUTE_CHANGED, track.muteHandler);
    if (track.isAudioTrack()) {
        track.removeEventListener(_JitsiTrackEvents__WEBPACK_IMPORTED_MODULE_11__.TRACK_AUDIO_LEVEL_CHANGED, track.audioLevelHandler);
    }
    // send event for stopping screen sharing
    // FIXME: we assume we have only one screen sharing track
    // if we change this we need to fix this check
    if (track.isVideoTrack() && track.videoType === _service_RTC_VideoType__WEBPACK_IMPORTED_MODULE_53__.VideoType.DESKTOP) {
        this.statistics.sendScreenSharingEvent(false);
    }
    this.eventEmitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_7__.TRACK_REMOVED, track);
};
/**
 * Removes JitsiLocalTrack from the conference and performs
 * a new offer/answer cycle.
 * @param {JitsiLocalTrack} track
 * @returns {Promise}
 */
JitsiConference.prototype.removeTrack = function (track) {
    return this.replaceTrack(track, null);
};
/**
 * Replaces oldTrack with newTrack and performs a single offer/answer
 *  cycle after both operations are done.  Either oldTrack or newTrack
 *  can be null; replacing a valid 'oldTrack' with a null 'newTrack'
 *  effectively just removes 'oldTrack'
 * @param {JitsiLocalTrack} oldTrack the current stream in use to be replaced
 * @param {JitsiLocalTrack} newTrack the new stream to use
 * @returns {Promise} resolves when the replacement is finished
 */
JitsiConference.prototype.replaceTrack = function (oldTrack, newTrack) {
    var _a;
    const oldVideoType = oldTrack === null || oldTrack === void 0 ? void 0 : oldTrack.getVideoType();
    const mediaType = (oldTrack === null || oldTrack === void 0 ? void 0 : oldTrack.getType()) || (newTrack === null || newTrack === void 0 ? void 0 : newTrack.getType());
    const newVideoType = newTrack === null || newTrack === void 0 ? void 0 : newTrack.getVideoType();
    if (_modules_flags_FeatureFlags__WEBPACK_IMPORTED_MODULE_28__["default"].isMultiStreamSendSupportEnabled() && oldTrack && newTrack && oldVideoType !== newVideoType) {
        throw new Error(`Replacing a track of videoType=${oldVideoType} with a track of videoType=${newVideoType} is`
            + ' not supported in this mode.');
    }
    if (newTrack) {
        const sourceName = oldTrack
            ? oldTrack.getSourceName()
            : (0,_service_RTC_SignalingLayer__WEBPACK_IMPORTED_MODULE_52__.getSourceNameForJitsiTrack)(this.myUserId(), mediaType, (_a = this.getLocalTracks(mediaType)) === null || _a === void 0 ? void 0 : _a.length);
        newTrack.setSourceName(sourceName);
    }
    const oldTrackBelongsToConference = this === (oldTrack === null || oldTrack === void 0 ? void 0 : oldTrack.conference);
    if (oldTrackBelongsToConference && oldTrack.disposed) {
        return Promise.reject(new _JitsiTrackError__WEBPACK_IMPORTED_MODULE_9__["default"](_JitsiTrackErrors__WEBPACK_IMPORTED_MODULE_10__.TRACK_IS_DISPOSED));
    }
    if (newTrack === null || newTrack === void 0 ? void 0 : newTrack.disposed) {
        return Promise.reject(new _JitsiTrackError__WEBPACK_IMPORTED_MODULE_9__["default"](_JitsiTrackErrors__WEBPACK_IMPORTED_MODULE_10__.TRACK_IS_DISPOSED));
    }
    if (oldTrack && !oldTrackBelongsToConference) {
        logger.warn(`JitsiConference.replaceTrack oldTrack (${oldTrack} does not belong to this conference`);
    }
    // Now replace the stream at the lower levels
    return this._doReplaceTrack(oldTrackBelongsToConference ? oldTrack : null, newTrack)
        .then(() => {
        if (oldTrackBelongsToConference && !oldTrack.isMuted() && !newTrack) {
            oldTrack._sendMuteStatus(true);
        }
        oldTrackBelongsToConference && this.onLocalTrackRemoved(oldTrack);
        newTrack && this._setupNewTrack(newTrack);
        // Send 'VideoTypeMessage' on the bridge channel when a video track is added/removed.
        if ((oldTrackBelongsToConference && (oldTrack === null || oldTrack === void 0 ? void 0 : oldTrack.isVideoTrack())) || (newTrack === null || newTrack === void 0 ? void 0 : newTrack.isVideoTrack())) {
            this._sendBridgeVideoTypeMessage(newTrack);
        }
        this._updateRoomPresence(this.getActiveMediaSession());
        if (newTrack !== null && (this.isMutedByFocus || this.isVideoMutedByFocus)) {
            this._fireMuteChangeEvent(newTrack);
        }
        return Promise.resolve();
    })
        .catch(error => {
        logger.error(`replaceTrack failed: ${error === null || error === void 0 ? void 0 : error.stack}`);
        return Promise.reject(error);
    });
};
/**
 * Replaces the tracks at the lower level by going through the Jingle session
 * and WebRTC peer connection. The method will resolve immediately if there is
 * currently no JingleSession started.
 * @param {JitsiLocalTrack|null} oldTrack the track to be removed during
 * the process or <tt>null</t> if the method should act as "add track"
 * @param {JitsiLocalTrack|null} newTrack the new track to be added or
 * <tt>null</tt> if the method should act as "remove track"
 * @return {Promise} resolved when the process is done or rejected with a string
 * which describes the error.
 * @private
 */
JitsiConference.prototype._doReplaceTrack = function (oldTrack, newTrack) {
    const replaceTrackPromises = [];
    if (this.jvbJingleSession) {
        replaceTrackPromises.push(this.jvbJingleSession.replaceTrack(oldTrack, newTrack));
    }
    else {
        logger.info('_doReplaceTrack - no JVB JingleSession');
    }
    if (this.p2pJingleSession) {
        replaceTrackPromises.push(this.p2pJingleSession.replaceTrack(oldTrack, newTrack));
    }
    else {
        logger.info('_doReplaceTrack - no P2P JingleSession');
    }
    return Promise.all(replaceTrackPromises);
};
/**
 * Handler for when a source-add for a local source is rejected by Jicofo.
 *
 * @param {JingleSessionPC} jingleSession - The media session.
 * @param {Error} error - The error message.
 * @param {MediaType} mediaType - The media type of the track associated with the source that was rejected.
 * @returns {void}
 */
JitsiConference.prototype._removeLocalSourceOnReject = function (jingleSession, error, mediaType) {
    if (!jingleSession) {
        return;
    }
    logger.warn(`Source-add rejected on ${jingleSession}, reason="${error === null || error === void 0 ? void 0 : error.reason}", message="${error === null || error === void 0 ? void 0 : error.msg}"`);
    const track = this.getLocalTracks(mediaType)[0];
    this.eventEmitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_7__.TRACK_UNMUTE_REJECTED, track);
};
/**
 * Operations related to creating a new track
 * @param {JitsiLocalTrack} newTrack the new track being created
 */
JitsiConference.prototype._setupNewTrack = function (newTrack) {
    var _a;
    const mediaType = newTrack.getType();
    if (newTrack.isAudioTrack() || (newTrack.isVideoTrack() && newTrack.videoType !== _service_RTC_VideoType__WEBPACK_IMPORTED_MODULE_53__.VideoType.DESKTOP)) {
        // Report active device to statistics
        const devices = _modules_RTC_RTC__WEBPACK_IMPORTED_MODULE_14__["default"].getCurrentlyAvailableMediaDevices();
        const device = devices
            .find(d => d.kind === `${newTrack.getTrack().kind}input` && d.label === newTrack.getTrack().label);
        if (device) {
            _modules_statistics_statistics__WEBPACK_IMPORTED_MODULE_38__["default"].sendActiveDeviceListEvent(_modules_RTC_RTC__WEBPACK_IMPORTED_MODULE_14__["default"].getEventDataForActiveDevice(device));
        }
    }
    // Create a source name for this track if it doesn't exist.
    if (!newTrack.getSourceName()) {
        const sourceName = (0,_service_RTC_SignalingLayer__WEBPACK_IMPORTED_MODULE_52__.getSourceNameForJitsiTrack)(this.myUserId(), mediaType, (_a = this.getLocalTracks(mediaType)) === null || _a === void 0 ? void 0 : _a.length);
        newTrack.setSourceName(sourceName);
    }
    this.rtc.addLocalTrack(newTrack);
    newTrack.setConference(this);
    // Suspend media on the inactive media session since it gets automatically enabled for a newly added source.
    if (this.isP2PActive()) {
        this._suspendMediaTransferForJvbConnection();
    }
    // Add event handlers.
    newTrack.muteHandler = this._fireMuteChangeEvent.bind(this, newTrack);
    newTrack.addEventListener(_JitsiTrackEvents__WEBPACK_IMPORTED_MODULE_11__.TRACK_MUTE_CHANGED, newTrack.muteHandler);
    if (newTrack.isAudioTrack()) {
        newTrack.audioLevelHandler = this._fireAudioLevelChangeEvent.bind(this);
        newTrack.addEventListener(_JitsiTrackEvents__WEBPACK_IMPORTED_MODULE_11__.TRACK_AUDIO_LEVEL_CHANGED, newTrack.audioLevelHandler);
    }
    this.eventEmitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_7__.TRACK_ADDED, newTrack);
};
/**
 * Sets the video type.
 * @param track
 * @return <tt>true</tt> if video type was changed in presence.
 * @private
 */
JitsiConference.prototype._setNewVideoType = function (track) {
    let videoTypeChanged = false;
    if (track) {
        videoTypeChanged = this._signalingLayer.setTrackVideoType(track.getSourceName(), track.videoType);
    }
    return videoTypeChanged;
};
/**
 * Sets mute status.
 * @param mediaType
 * @param localTrack
 * @param isMuted
 * @param <tt>true</tt> when presence was changed, <tt>false</tt> otherwise.
 * @private
 */
JitsiConference.prototype._setTrackMuteStatus = function (mediaType, localTrack, isMuted) {
    let presenceChanged = false;
    if (localTrack) {
        presenceChanged = this._signalingLayer.setTrackMuteStatus(localTrack.getSourceName(), isMuted);
        presenceChanged && logger.debug(`Mute state of ${localTrack} changed to muted=${isMuted}`);
    }
    return presenceChanged;
};
/**
 * Method called by the {@link JitsiLocalTrack} in order to add the underlying MediaStream to the RTCPeerConnection.
 *
 * @param {JitsiLocalTrack} track the local track that will be added to the pc.
 * @return {Promise} resolved when the process is done or rejected with a string which describes the error.
 */
JitsiConference.prototype._addLocalTrackToPc = function (track) {
    const addPromises = [];
    if (this.jvbJingleSession) {
        addPromises.push(this.jvbJingleSession.addTrackToPc(track));
    }
    else {
        logger.debug('Add local MediaStream - no JVB Jingle session started yet');
    }
    if (this.p2pJingleSession) {
        addPromises.push(this.p2pJingleSession.addTrackToPc(track));
    }
    else {
        logger.debug('Add local MediaStream - no P2P Jingle session started yet');
    }
    return Promise.allSettled(addPromises);
};
/**
 * Method called by the {@link JitsiLocalTrack} in order to remove the underlying MediaStream from the
 * RTCPeerConnection.
 *
 * @param {JitsiLocalTrack} track the local track that will be removed.
 * @return {Promise} resolved when the process is done or rejected with a string which describes the error.
 */
JitsiConference.prototype._removeLocalTrackFromPc = function (track) {
    const removePromises = [];
    if (this.jvbJingleSession) {
        removePromises.push(this.jvbJingleSession.removeTrackFromPc(track));
    }
    else {
        logger.debug('Remove local MediaStream - no JVB JingleSession started yet');
    }
    if (this.p2pJingleSession) {
        removePromises.push(this.p2pJingleSession.removeTrackFromPc(track));
    }
    else {
        logger.debug('Remove local MediaStream - no P2P JingleSession started yet');
    }
    return Promise.allSettled(removePromises);
};
/**
 * Get role of the local user.
 * @returns {string} user role: 'moderator' or 'none'
 */
JitsiConference.prototype.getRole = function () {
    return this.room.role;
};
/**
 * Returns whether or not the current conference has been joined as a hidden
 * user.
 *
 * @returns {boolean|null} True if hidden, false otherwise. Will return null if
 * no connection is active.
 */
JitsiConference.prototype.isHidden = function () {
    if (!this.connection) {
        return null;
    }
    return strophe_js__WEBPACK_IMPORTED_MODULE_4__.Strophe.getDomainFromJid(this.connection.getJid())
        === this.options.config.hiddenDomain;
};
/**
 * Check if local user is moderator.
 * @returns {boolean|null} true if local user is moderator, false otherwise. If
 * we're no longer in the conference room then <tt>null</tt> is returned.
 */
JitsiConference.prototype.isModerator = function () {
    return this.room ? this.room.isModerator() : null;
};
/**
 * Set password for the room.
 * @param {string} password new password for the room.
 * @returns {Promise}
 */
JitsiConference.prototype.lock = function (password) {
    if (!this.isModerator()) {
        return Promise.reject(new Error('You are not moderator.'));
    }
    return new Promise((resolve, reject) => {
        this.room.lockRoom(password || '', () => resolve(), err => reject(err), () => reject(_JitsiConferenceErrors__WEBPACK_IMPORTED_MODULE_5__.PASSWORD_NOT_SUPPORTED));
    });
};
/**
 * Remove password from the room.
 * @returns {Promise}
 */
JitsiConference.prototype.unlock = function () {
    return this.lock();
};
/**
 * Obtains the current value for "lastN". See {@link setLastN} for more info.
 * @returns {number}
 */
JitsiConference.prototype.getLastN = function () {
    return this.receiveVideoController.getLastN();
};
/**
 * Obtains the forwarded sources list in this conference.
 * @return {Array<string>|null}
 */
JitsiConference.prototype.getForwardedSources = function () {
    return this.rtc.getForwardedSources();
};
/**
 * Selects a new value for "lastN". The requested amount of videos are going
 * to be delivered after the value is in effect. Set to -1 for unlimited or
 * all available videos.
 * @param lastN the new number of videos the user would like to receive.
 * @throws Error or RangeError if the given value is not a number or is smaller
 * than -1.
 */
JitsiConference.prototype.setLastN = function (lastN) {
    if (!Number.isInteger(lastN) && !Number.parseInt(lastN, 10)) {
        throw new Error(`Invalid value for lastN: ${lastN}`);
    }
    const n = Number(lastN);
    if (n < -1) {
        throw new RangeError('lastN cannot be smaller than -1');
    }
    this.receiveVideoController.setLastN(n);
    // If the P2P session is not fully established yet, we wait until it gets established.
    if (this.p2pJingleSession) {
        const isVideoActive = n !== 0;
        this.p2pJingleSession
            .setP2pVideoTransferActive(isVideoActive)
            .catch(error => {
            logger.error(`Failed to adjust video transfer status (${isVideoActive})`, error);
        });
    }
};
/**
 * @return Array<JitsiParticipant> an array of all participants in this conference.
 */
JitsiConference.prototype.getParticipants = function () {
    return Array.from(this.participants.values());
};
/**
 * Returns the number of participants in the conference, including the local
 * participant.
 * @param countHidden {boolean} Whether or not to include hidden participants
 * in the count. Default: false.
 **/
JitsiConference.prototype.getParticipantCount = function (countHidden = false) {
    let participants = this.getParticipants();
    if (!countHidden) {
        participants = participants.filter(p => !p.isHidden());
    }
    // Add one for the local participant.
    return participants.length + 1;
};
/**
 * @returns {JitsiParticipant} the participant in this conference with the
 * specified id (or undefined if there isn't one).
 * @param id the id of the participant.
 */
JitsiConference.prototype.getParticipantById = function (id) {
    return this.participants.get(id);
};
/**
 * Grant owner rights to the participant.
 * @param {string} id id of the participant to grant owner rights to.
 */
JitsiConference.prototype.grantOwner = function (id) {
    const participant = this.getParticipantById(id);
    if (!participant) {
        return;
    }
    this.room.setAffiliation(participant.getConnectionJid(), 'owner');
};
/**
 * Revoke owner rights to the participant or local Participant as
 * the user might want to refuse to be a moderator.
 * @param {string} id id of the participant to revoke owner rights to.
 */
JitsiConference.prototype.revokeOwner = function (id) {
    const participant = this.getParticipantById(id);
    const isMyself = this.myUserId() === id;
    const role = this.isMembersOnly() ? 'member' : 'none';
    if (isMyself) {
        this.room.setAffiliation(this.connection.getJid(), role);
    }
    else if (participant) {
        this.room.setAffiliation(participant.getConnectionJid(), role);
    }
};
/**
 * Kick participant from this conference.
 * @param {string} id id of the participant to kick
 * @param {string} reason reason of the participant to kick
 */
JitsiConference.prototype.kickParticipant = function (id, reason) {
    const participant = this.getParticipantById(id);
    if (!participant) {
        return;
    }
    this.room.kick(participant.getJid(), reason);
};
/**
 * Maybe clears the timeout which emits {@link ACTION_JINGLE_SI_TIMEOUT}
 * analytics event.
 * @private
 */
JitsiConference.prototype._maybeClearSITimeout = function () {
    if (this._sessionInitiateTimeout
        && (this.jvbJingleSession || this.getParticipantCount() < 2)) {
        window.clearTimeout(this._sessionInitiateTimeout);
        this._sessionInitiateTimeout = null;
    }
};
/**
 * Sets a timeout which will emit {@link ACTION_JINGLE_SI_TIMEOUT} analytics
 * event.
 * @private
 */
JitsiConference.prototype._maybeSetSITimeout = function () {
    // Jicofo is supposed to invite if there are at least 2 participants
    if (!this.jvbJingleSession
        && this.getParticipantCount() >= 2
        && !this._sessionInitiateTimeout) {
        this._sessionInitiateTimeout = window.setTimeout(() => {
            this._sessionInitiateTimeout = null;
            _modules_statistics_statistics__WEBPACK_IMPORTED_MODULE_38__["default"].sendAnalytics((0,_service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_54__.createJingleEvent)(_service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_54__.ACTION_JINGLE_SI_TIMEOUT, {
                p2p: false,
                value: JINGLE_SI_TIMEOUT
            }));
        }, JINGLE_SI_TIMEOUT);
    }
};
/**
 * Mutes a participant.
 * @param {string} id The id of the participant to mute.
 */
JitsiConference.prototype.muteParticipant = function (id, mediaType) {
    const muteMediaType = mediaType ? mediaType : _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_49__.MediaType.AUDIO;
    if (muteMediaType !== _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_49__.MediaType.AUDIO && muteMediaType !== _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_49__.MediaType.VIDEO) {
        logger.error(`Unsupported media type: ${muteMediaType}`);
        return;
    }
    const participant = this.getParticipantById(id);
    if (!participant) {
        return;
    }
    this.room.muteParticipant(participant.getJid(), true, muteMediaType);
};
/* eslint-disable max-params */
/**
 * Notifies this JitsiConference that a new member has joined its chat room.
 *
 * FIXME This should NOT be exposed!
 *
 * @param jid the jid of the participant in the MUC
 * @param nick the display name of the participant
 * @param role the role of the participant in the MUC
 * @param isHidden indicates if this is a hidden participant (system
 * participant for example a recorder).
 * @param statsID the participant statsID (optional)
 * @param status the initial status if any
 * @param identity the member identity, if any
 * @param botType the member botType, if any
 * @param fullJid the member full jid, if any
 * @param features the member botType, if any
 * @param isReplaceParticipant whether this join replaces a participant with
 * the same jwt.
 */
JitsiConference.prototype.onMemberJoined = function (jid, nick, role, isHidden, statsID, status, identity, botType, fullJid, features, isReplaceParticipant) {
    var _a, _b, _c, _d;
    const id = strophe_js__WEBPACK_IMPORTED_MODULE_4__.Strophe.getResourceFromJid(jid);
    if (id === 'focus' || this.myUserId() === id) {
        return;
    }
    const participant = new _JitsiParticipant__WEBPACK_IMPORTED_MODULE_8__["default"](jid, this, nick, isHidden, statsID, status, identity);
    participant.setConnectionJid(fullJid);
    participant.setRole(role);
    participant.setBotType(botType);
    participant.setFeatures(features);
    participant.setIsReplacing(isReplaceParticipant);
    // Set remote tracks on the participant if source signaling was received before presence.
    const remoteTracks = this.isP2PActive()
        ? (_b = (_a = this.p2pJingleSession) === null || _a === void 0 ? void 0 : _a.peerconnection.getRemoteTracks(id)) !== null && _b !== void 0 ? _b : []
        : (_d = (_c = this.jvbJingleSession) === null || _c === void 0 ? void 0 : _c.peerconnection.getRemoteTracks(id)) !== null && _d !== void 0 ? _d : [];
    for (const track of remoteTracks) {
        participant._tracks.push(track);
    }
    this.participants.set(id, participant);
    this.eventEmitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_7__.USER_JOINED, id, participant);
    this._updateFeatures(participant);
    // maybeStart only if we had finished joining as then we will have information for the number of participants
    if (this.isJoined()) {
        this._maybeStartOrStopP2P();
    }
    this._maybeSetSITimeout();
};
/* eslint-enable max-params */
/**
 * Get notified when we joined the room.
 *
 * FIXME This should NOT be exposed!
 *
 * @private
 */
JitsiConference.prototype._onMucJoined = function () {
    this._maybeStartOrStopP2P();
};
/**
 * Updates features for a participant.
 * @param {JitsiParticipant} participant - The participant to query for features.
 * @returns {void}
 * @private
 */
JitsiConference.prototype._updateFeatures = function (participant) {
    participant.getFeatures()
        .then(features => {
        participant._supportsDTMF = features.has('urn:xmpp:jingle:dtmf:0');
        this.updateDTMFSupport();
        if (features.has(_modules_xmpp_xmpp__WEBPACK_IMPORTED_MODULE_46__.FEATURE_JIGASI)) {
            participant.setProperty('features_jigasi', true);
        }
        if (features.has(_modules_xmpp_xmpp__WEBPACK_IMPORTED_MODULE_46__.FEATURE_E2EE)) {
            participant.setProperty('features_e2ee', true);
        }
    })
        .catch(() => false);
};
/**
 * Get notified when member bot type had changed.
 * @param jid the member jid
 * @param botType the new botType value
 * @private
 */
JitsiConference.prototype._onMemberBotTypeChanged = function (jid, botType) {
    // find the participant and mark it as non bot, as the real one will join
    // in a moment
    const peers = this.getParticipants();
    const botParticipant = peers.find(p => p.getJid() === jid);
    if (botParticipant) {
        botParticipant.setBotType(botType);
        const id = strophe_js__WEBPACK_IMPORTED_MODULE_4__.Strophe.getResourceFromJid(jid);
        this.eventEmitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_7__.BOT_TYPE_CHANGED, id, botType);
    }
    // if botType changed to undefined, botType was removed, in case of
    // poltergeist mode this is the moment when the poltergeist had exited and
    // the real participant had already replaced it.
    // In this case we can check and try p2p
    if (!botParticipant.getBotType()) {
        this._maybeStartOrStopP2P();
    }
};
JitsiConference.prototype.onMemberLeft = function (jid, reason) {
    const id = strophe_js__WEBPACK_IMPORTED_MODULE_4__.Strophe.getResourceFromJid(jid);
    if (id === 'focus' || this.myUserId() === id) {
        return;
    }
    const mediaSessions = this.getMediaSessions();
    let tracksToBeRemoved = [];
    for (const session of mediaSessions) {
        const remoteTracks = session.peerconnection.getRemoteTracks(id);
        remoteTracks && (tracksToBeRemoved = [...tracksToBeRemoved, ...remoteTracks]);
        // Update the SSRC owners list.
        session._signalingLayer.updateSsrcOwnersOnLeave(id);
        if (!_modules_flags_FeatureFlags__WEBPACK_IMPORTED_MODULE_28__["default"].isSsrcRewritingSupported()) {
            // Remove the ssrcs from the remote description and renegotiate.
            session.removeRemoteStreamsOnLeave(id);
        }
    }
    tracksToBeRemoved.forEach(track => {
        if (_modules_flags_FeatureFlags__WEBPACK_IMPORTED_MODULE_28__["default"].isSsrcRewritingSupported()) {
            track.setSourceName(null);
            track.setOwner(null);
        }
        else {
            // Fire the event before renegotiation is done so that the thumbnails can be removed immediately.
            this.eventEmitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_7__.TRACK_REMOVED, track);
        }
    });
    const participant = this.participants.get(id);
    if (participant) {
        this.participants.delete(id);
        this.eventEmitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_7__.USER_LEFT, id, participant, reason);
    }
    if (this.room !== null) { // Skip if we have left the room already.
        this._maybeStartOrStopP2P(true /* triggered by user left event */);
        this._maybeClearSITimeout();
    }
};
/* eslint-disable max-params */
/**
 * Designates an event indicating that we were kicked from the XMPP MUC.
 * @param {boolean} isSelfPresence - whether it is for local participant
 * or another participant.
 * @param {string} actorId - the id of the participant who was initiator
 * of the kick.
 * @param {string?} kickedParticipantId - when it is not a kick for local participant,
 * this is the id of the participant which was kicked.
 * @param {string} reason - reason of the participant to kick
 * @param {boolean?} isReplaceParticipant - whether this is a server initiated kick in order
 * to replace it with a participant with same jwt.
 */
JitsiConference.prototype.onMemberKicked = function (isSelfPresence, actorId, kickedParticipantId, reason, isReplaceParticipant) {
    // This check which be true when we kick someone else. With the introduction of lobby
    // the ChatRoom KICKED event is now also emitted for ourselves (the kicker) so we want to
    // avoid emitting an event where `undefined` kicked someone.
    if (actorId === this.myUserId()) {
        return;
    }
    const actorParticipant = this.participants.get(actorId);
    if (isSelfPresence) {
        this.eventEmitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_7__.KICKED, actorParticipant, reason, isReplaceParticipant);
        this.leave().finally(() => this.xmpp.disconnect());
        return;
    }
    const kickedParticipant = this.participants.get(kickedParticipantId);
    kickedParticipant.setIsReplaced(isReplaceParticipant);
    this.eventEmitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_7__.PARTICIPANT_KICKED, actorParticipant, kickedParticipant, reason);
};
/**
 * Method called on local MUC role change.
 * @param {string} role the name of new user's role as defined by XMPP MUC.
 */
JitsiConference.prototype.onLocalRoleChanged = function (role) {
    // Emit role changed for local  JID
    this.eventEmitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_7__.USER_ROLE_CHANGED, this.myUserId(), role);
};
JitsiConference.prototype.onUserRoleChanged = function (jid, role) {
    const id = strophe_js__WEBPACK_IMPORTED_MODULE_4__.Strophe.getResourceFromJid(jid);
    const participant = this.getParticipantById(id);
    if (!participant) {
        return;
    }
    participant.setRole(role);
    this.eventEmitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_7__.USER_ROLE_CHANGED, id, role);
};
JitsiConference.prototype.onDisplayNameChanged = function (jid, displayName) {
    const id = strophe_js__WEBPACK_IMPORTED_MODULE_4__.Strophe.getResourceFromJid(jid);
    const participant = this.getParticipantById(id);
    if (!participant) {
        return;
    }
    if (participant._displayName === displayName) {
        return;
    }
    participant._displayName = displayName;
    this.eventEmitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_7__.DISPLAY_NAME_CHANGED, id, displayName);
};
/**
 * Notifies this JitsiConference that a JitsiRemoteTrack was added to the conference.
 *
 * @param {JitsiRemoteTrack} track the JitsiRemoteTrack which was added to this JitsiConference.
 */
JitsiConference.prototype.onRemoteTrackAdded = function (track) {
    if (track.isP2P && !this.isP2PActive()) {
        logger.info('Trying to add remote P2P track, when not in P2P - IGNORED');
        return;
    }
    else if (!track.isP2P && this.isP2PActive()) {
        logger.info('Trying to add remote JVB track, when in P2P - IGNORED');
        return;
    }
    const id = track.getParticipantId();
    const participant = this.getParticipantById(id);
    // Add track to JitsiParticipant.
    if (participant) {
        participant._tracks.push(track);
    }
    else {
        logger.info(`Source signaling received before presence for ${id}`);
    }
    if (this.transcriber) {
        this.transcriber.addTrack(track);
    }
    const emitter = this.eventEmitter;
    track.addEventListener(_JitsiTrackEvents__WEBPACK_IMPORTED_MODULE_11__.TRACK_MUTE_CHANGED, () => emitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_7__.TRACK_MUTE_CHANGED, track));
    track.isAudioTrack() && track.addEventListener(_JitsiTrackEvents__WEBPACK_IMPORTED_MODULE_11__.TRACK_AUDIO_LEVEL_CHANGED, (audioLevel, tpc) => {
        const activeTPC = this.getActivePeerConnection();
        if (activeTPC === tpc) {
            emitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_7__.TRACK_AUDIO_LEVEL_CHANGED, id, audioLevel);
        }
    });
    emitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_7__.TRACK_ADDED, track);
};
/**
 * Callback called by the Jingle plugin when 'session-answer' is received.
 * @param {JingleSessionPC} session the Jingle session for which an answer was
 * received.
 * @param {jQuery} answer a jQuery selector pointing to 'jingle' IQ element
 */
// eslint-disable-next-line no-unused-vars
JitsiConference.prototype.onCallAccepted = function (session, answer) {
    if (this.p2pJingleSession === session) {
        logger.info('P2P setAnswer');
        this.p2pJingleSession.setAnswer(answer);
        this.eventEmitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_7__._MEDIA_SESSION_STARTED, this.p2pJingleSession);
    }
};
/**
 * Callback called by the Jingle plugin when 'transport-info' is received.
 * @param {JingleSessionPC} session the Jingle session for which the IQ was
 * received
 * @param {jQuery} transportInfo a jQuery selector pointing to 'jingle' IQ
 * element
 */
// eslint-disable-next-line no-unused-vars
JitsiConference.prototype.onTransportInfo = function (session, transportInfo) {
    if (this.p2pJingleSession === session) {
        logger.info('P2P addIceCandidates');
        this.p2pJingleSession.addIceCandidates(transportInfo);
    }
};
/**
 * Notifies this JitsiConference that a JitsiRemoteTrack was removed from
 * the conference.
 *
 * @param {JitsiRemoteTrack} removedTrack
 */
JitsiConference.prototype.onRemoteTrackRemoved = function (removedTrack) {
    this.getParticipants().forEach(participant => {
        const tracks = participant.getTracks();
        for (let i = 0; i < tracks.length; i++) {
            if (tracks[i] === removedTrack) {
                // Since the tracks have been compared and are
                // considered equal the result of splice can be ignored.
                participant._tracks.splice(i, 1);
                this.eventEmitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_7__.TRACK_REMOVED, removedTrack);
                if (this.transcriber) {
                    this.transcriber.removeTrack(removedTrack);
                }
                break;
            }
        }
    }, this);
};
/**
 * Handles an incoming call event for the P2P jingle session.
 */
JitsiConference.prototype._onIncomingCallP2P = function (jingleSession, jingleOffer) {
    let rejectReason;
    const usesUnifiedPlan = _modules_browser__WEBPACK_IMPORTED_MODULE_16__["default"].supportsUnifiedPlan();
    const contentName = jingleOffer.find('>content').attr('name');
    const peerUsesUnifiedPlan = contentName === '0' || contentName === '1';
    // Reject P2P between endpoints that are not running in the same mode w.r.t to SDPs (plan-b and unified plan).
    if (usesUnifiedPlan !== peerUsesUnifiedPlan) {
        rejectReason = {
            reason: 'decline',
            reasonDescription: 'P2P disabled',
            errorMsg: 'P2P across two endpoints in different SDP modes is disabled'
        };
    }
    else if ((!this.isP2PEnabled() && !this.isP2PTestModeEnabled())
        || (_modules_browser__WEBPACK_IMPORTED_MODULE_16__["default"].isFirefox() && !this._firefoxP2pEnabled)) {
        rejectReason = {
            reason: 'decline',
            reasonDescription: 'P2P disabled',
            errorMsg: 'P2P mode disabled in the configuration or browser unsupported'
        };
    }
    else if (this.p2pJingleSession) {
        // Reject incoming P2P call (already in progress)
        rejectReason = {
            reason: 'busy',
            reasonDescription: 'P2P already in progress',
            errorMsg: 'Duplicated P2P "session-initiate"'
        };
    }
    else if (!this._shouldBeInP2PMode()) {
        rejectReason = {
            reason: 'decline',
            reasonDescription: 'P2P requirements not met',
            errorMsg: 'Received P2P "session-initiate" when should not be in P2P mode'
        };
        _modules_statistics_statistics__WEBPACK_IMPORTED_MODULE_38__["default"].sendAnalytics((0,_service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_54__.createJingleEvent)(_service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_54__.ACTION_P2P_DECLINED));
    }
    if (rejectReason) {
        this._rejectIncomingCall(jingleSession, rejectReason);
    }
    else {
        this._acceptP2PIncomingCall(jingleSession, jingleOffer);
    }
};
/**
 * Handles an incoming call event.
 */
JitsiConference.prototype.onIncomingCall = function (jingleSession, jingleOffer, now) {
    // Handle incoming P2P call
    if (jingleSession.isP2P) {
        this._onIncomingCallP2P(jingleSession, jingleOffer);
    }
    else {
        if (!this.isFocus(jingleSession.remoteJid)) {
            const description = 'Rejecting session-initiate from non-focus.';
            this._rejectIncomingCall(jingleSession, {
                reason: 'security-error',
                reasonDescription: description,
                errorMsg: description
            });
            return;
        }
        this._acceptJvbIncomingCall(jingleSession, jingleOffer, now);
    }
};
/**
 * Accepts an incoming call event for the JVB jingle session.
 */
JitsiConference.prototype._acceptJvbIncomingCall = function (jingleSession, jingleOffer, now) {
    // Accept incoming call
    this.jvbJingleSession = jingleSession;
    this.room.connectionTimes['session.initiate'] = now;
    this._sendConferenceJoinAnalyticsEvent();
    if (this.wasStopped) {
        _modules_statistics_statistics__WEBPACK_IMPORTED_MODULE_38__["default"].sendAnalyticsAndLog((0,_service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_54__.createJingleEvent)(_service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_54__.ACTION_JINGLE_RESTART, { p2p: false }));
    }
    const serverRegion = jquery__WEBPACK_IMPORTED_MODULE_2___default()(jingleOffer)
        .find('>bridge-session[xmlns="http://jitsi.org/protocol/focus"]')
        .attr('region');
    this.eventEmitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_7__.SERVER_REGION_CHANGED, serverRegion);
    this._maybeClearSITimeout();
    _modules_statistics_statistics__WEBPACK_IMPORTED_MODULE_38__["default"].sendAnalytics((0,_service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_54__.createJingleEvent)(_service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_54__.ACTION_JINGLE_SI_RECEIVED, {
        p2p: false,
        value: now
    }));
    try {
        jingleSession.initialize(this.room, this.rtc, this._signalingLayer, Object.assign(Object.assign({}, this.options.config), { codecSettings: {
                mediaType: _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_49__.MediaType.VIDEO,
                codecList: this.codecSelection.getCodecPreferenceList('jvb')
            }, enableInsertableStreams: this.isE2EEEnabled() || _modules_flags_FeatureFlags__WEBPACK_IMPORTED_MODULE_28__["default"].isRunInLiteModeEnabled() }));
    }
    catch (error) {
        _modules_util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_40___default().callErrorHandler(error);
        logger.error(error);
        return;
    }
    // Open a channel with the videobridge.
    this._setBridgeChannel(jingleOffer, jingleSession.peerconnection);
    const localTracks = this._getInitialLocalTracks();
    try {
        jingleSession.acceptOffer(jingleOffer, () => {
            // If for any reason invite for the JVB session arrived after
            // the P2P has been established already the media transfer needs
            // to be turned off here.
            if (this.isP2PActive() && this.jvbJingleSession) {
                this._suspendMediaTransferForJvbConnection();
            }
            this.eventEmitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_7__._MEDIA_SESSION_STARTED, jingleSession);
            if (!this.isP2PActive()) {
                this.eventEmitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_7__._MEDIA_SESSION_ACTIVE_CHANGED, jingleSession);
            }
        }, error => {
            _modules_util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_40___default().callErrorHandler(error);
            logger.error('Failed to accept incoming Jingle session', error);
        }, localTracks);
        // Enable or disable simulcast for plan-b screensharing based on the capture fps if it is set through the UI.
        this._desktopSharingFrameRate
            && jingleSession.peerconnection.setDesktopSharingFrameRate(this._desktopSharingFrameRate);
        // Start callstats as soon as peerconnection is initialized,
        // do not wait for XMPPEvents.PEERCONNECTION_READY, as it may never
        // happen in case if user doesn't have or denied permission to
        // both camera and microphone.
        logger.info('Starting CallStats for JVB connection...');
        this.statistics.startCallStats(this.jvbJingleSession.peerconnection, 'jitsi' /* Remote user ID for JVB is 'jitsi' */);
        this.statistics.startRemoteStats(this.jvbJingleSession.peerconnection);
    }
    catch (e) {
        _modules_util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_40___default().callErrorHandler(e);
        logger.error(e);
    }
};
/**
 * Sets the BridgeChannel.
 *
 * @param {jQuery} offerIq a jQuery selector pointing to the jingle element of
 * the offer IQ which may carry the WebSocket URL for the 'websocket'
 * BridgeChannel mode.
 * @param {TraceablePeerConnection} pc the peer connection which will be used
 * to listen for new WebRTC Data Channels (in the 'datachannel' mode).
 */
JitsiConference.prototype._setBridgeChannel = function (offerIq, pc) {
    var _a, _b, _c, _d, _e, _f, _g;
    const ignoreDomain = (_c = (_b = (_a = this.connection) === null || _a === void 0 ? void 0 : _a.options) === null || _b === void 0 ? void 0 : _b.bridgeChannel) === null || _c === void 0 ? void 0 : _c.ignoreDomain;
    const preferSctp = (_g = (_f = (_e = (_d = this.connection) === null || _d === void 0 ? void 0 : _d.options) === null || _e === void 0 ? void 0 : _e.bridgeChannel) === null || _f === void 0 ? void 0 : _f.preferSctp) !== null && _g !== void 0 ? _g : false;
    const sctpOffered = jquery__WEBPACK_IMPORTED_MODULE_2___default()(offerIq).find('>content[name="data"]')
        .first().length === 1;
    let wsUrl = null;
    logger.info(`SCTP: offered=${sctpOffered}, prefered=${preferSctp}`);
    if (!(sctpOffered && preferSctp)) {
        jquery__WEBPACK_IMPORTED_MODULE_2___default()(offerIq).find('>content>transport>web-socket')
            .toArray()
            .map(e => e.getAttribute('url'))
            .forEach(url => {
            if (!wsUrl && (!ignoreDomain || ignoreDomain !== new URL(url).hostname)) {
                wsUrl = url;
                logger.info(`Using colibri-ws url ${url}`);
            }
            else if (!wsUrl) {
                logger.info(`Ignoring colibri-ws url with domain ${ignoreDomain}`);
            }
        });
        if (!wsUrl) {
            const firstWsUrl = jquery__WEBPACK_IMPORTED_MODULE_2___default()(offerIq).find('>content>transport>web-socket')
                .first();
            if (firstWsUrl.length === 1) {
                wsUrl = firstWsUrl[0].getAttribute('url');
                logger.info(`Falling back to ${wsUrl}`);
            }
        }
    }
    if (wsUrl && !(sctpOffered && preferSctp)) {
        // If the offer contains a websocket and we don't prefer SCTP use it.
        this.rtc.initializeBridgeChannel(null, wsUrl);
    }
    else if (sctpOffered) {
        // Otherwise, fall back to an attempt to use SCTP.
        this.rtc.initializeBridgeChannel(pc, null);
    }
    else {
        logger.warn('Neither SCTP nor a websocket is available. Will not initialize bridge channel.');
    }
};
/**
 * Rejects incoming Jingle call.
 * @param {JingleSessionPC} jingleSession the session instance to be rejected.
 * @param {object} [options]
 * @param {string} options.reason the name of the reason element as defined
 * by Jingle
 * @param {string} options.reasonDescription the reason description which will
 * be included in Jingle 'session-terminate' message.
 * @param {string} options.errorMsg an error message to be logged on global
 * error handler
 * @private
 */
JitsiConference.prototype._rejectIncomingCall = function (jingleSession, options) {
    if (options === null || options === void 0 ? void 0 : options.errorMsg) {
        logger.warn(options.errorMsg);
    }
    // Terminate the jingle session with a reason
    jingleSession.terminate(null /* success callback => we don't care */, error => {
        logger.warn('An error occurred while trying to terminate'
            + ' invalid Jingle session', error);
    }, {
        reason: options && options.reason,
        reasonDescription: options && options.reasonDescription,
        sendSessionTerminate: true
    });
};
/**
 * Handles the call ended event.
 * XXX is this due to the remote side terminating the Jingle session?
 *
 * @param {JingleSessionPC} jingleSession the jingle session which has been
 * terminated.
 * @param {String} reasonCondition the Jingle reason condition.
 * @param {String|null} reasonText human readable reason text which may provide
 * more details about why the call has been terminated.
 */
JitsiConference.prototype.onCallEnded = function (jingleSession, reasonCondition, reasonText) {
    logger.info(`Call ended: ${reasonCondition} - ${reasonText} P2P ?${jingleSession.isP2P}`);
    if (jingleSession === this.jvbJingleSession) {
        this.wasStopped = true;
        _modules_statistics_statistics__WEBPACK_IMPORTED_MODULE_38__["default"].sendAnalytics((0,_service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_54__.createJingleEvent)(_service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_54__.ACTION_JINGLE_TERMINATE, { p2p: false }));
        // Stop the stats
        if (this.statistics) {
            this.statistics.stopRemoteStats(this.jvbJingleSession.peerconnection);
            logger.info('Stopping JVB CallStats');
            this.statistics.stopCallStats(this.jvbJingleSession.peerconnection);
        }
        // Current JVB JingleSession is no longer valid, so set it to null
        this.jvbJingleSession = null;
        // Let the RTC service do any cleanups
        this.rtc.onCallEnded();
    }
    else if (jingleSession === this.p2pJingleSession) {
        const stopOptions = {};
        // It's the responder who decides to enforce JVB mode, so that both
        // initiator and responder are aware if it was intentional.
        if (reasonCondition === 'decline' && reasonText === 'force JVB121') {
            logger.info('In forced JVB 121 mode...');
            _modules_statistics_statistics__WEBPACK_IMPORTED_MODULE_38__["default"].analytics.addPermanentProperties({ forceJvb121: true });
        }
        else if (reasonCondition === 'connectivity-error'
            && reasonText === 'ICE FAILED') {
            // It can happen that the other peer detects ICE failed and
            // terminates the session, before we get the event on our side.
            // But we are able to parse the reason and mark it here.
            _modules_statistics_statistics__WEBPACK_IMPORTED_MODULE_38__["default"].analytics.addPermanentProperties({ p2pFailed: true });
        }
        else if (reasonCondition === 'success' && reasonText === 'restart') {
            // When we are restarting media sessions we don't want to switch the tracks
            // to the JVB just yet.
            stopOptions.requestRestart = true;
        }
        this._stopP2PSession(stopOptions);
    }
    else {
        logger.error('Received onCallEnded for invalid session', jingleSession.sid, jingleSession.remoteJid, reasonCondition, reasonText);
    }
};
/**
 * Handles the suspend detected event. Leaves the room and fires suspended.
 * @param {JingleSessionPC} jingleSession
 */
JitsiConference.prototype.onSuspendDetected = function (jingleSession) {
    if (!jingleSession.isP2P) {
        this.leave();
        this.eventEmitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_7__.SUSPEND_DETECTED);
    }
};
JitsiConference.prototype.updateDTMFSupport = function () {
    let somebodySupportsDTMF = false;
    const participants = this.getParticipants();
    // check if at least 1 participant supports DTMF
    for (let i = 0; i < participants.length; i += 1) {
        if (participants[i].supportsDTMF()) {
            somebodySupportsDTMF = true;
            break;
        }
    }
    if (somebodySupportsDTMF !== this.somebodySupportsDTMF) {
        this.somebodySupportsDTMF = somebodySupportsDTMF;
        this.eventEmitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_7__.DTMF_SUPPORT_CHANGED, somebodySupportsDTMF);
    }
};
/**
 * Allows to check if there is at least one user in the conference
 * that supports DTMF.
 * @returns {boolean} true if somebody supports DTMF, false otherwise
 */
JitsiConference.prototype.isDTMFSupported = function () {
    return this.somebodySupportsDTMF;
};
/**
 * Returns the local user's ID
 * @return {string} local user's ID
 */
JitsiConference.prototype.myUserId = function () {
    return (this.room && this.room.myroomjid
        ? strophe_js__WEBPACK_IMPORTED_MODULE_4__.Strophe.getResourceFromJid(this.room.myroomjid)
        : null);
};
JitsiConference.prototype.sendTones = function (tones, duration, pause) {
    const peerConnection = this.getActivePeerConnection();
    if (peerConnection) {
        peerConnection.sendTones(tones, duration, pause);
    }
    else {
        logger.warn('cannot sendTones: no peer connection');
    }
};
/**
 * Starts recording the current conference.
 *
 * @param {Object} options - Configuration for the recording. See
 * {@link Chatroom#startRecording} for more info.
 * @returns {Promise} See {@link Chatroom#startRecording} for more info.
 */
JitsiConference.prototype.startRecording = function (options) {
    if (this.room) {
        return this.recordingManager.startRecording(options);
    }
    return Promise.reject(new Error('The conference is not created yet!'));
};
/**
 * Stop a recording session.
 *
 * @param {string} sessionID - The ID of the recording session that
 * should be stopped.
 * @returns {Promise} See {@link Chatroom#stopRecording} for more info.
 */
JitsiConference.prototype.stopRecording = function (sessionID) {
    if (this.room) {
        return this.recordingManager.stopRecording(sessionID);
    }
    return Promise.reject(new Error('The conference is not created yet!'));
};
/**
 * Returns true if the SIP calls are supported and false otherwise
 */
JitsiConference.prototype.isSIPCallingSupported = function () {
    var _a, _b, _c;
    return (_c = (_b = (_a = this.room) === null || _a === void 0 ? void 0 : _a.moderator) === null || _b === void 0 ? void 0 : _b.isSipGatewayEnabled()) !== null && _c !== void 0 ? _c : false;
};
/**
 * Dials a number.
 * @param number the number
 */
JitsiConference.prototype.dial = function (number) {
    if (this.room) {
        return this.room.dial(number);
    }
    return new Promise((resolve, reject) => {
        reject(new Error('The conference is not created yet!'));
    });
};
/**
 * Hangup an existing call
 */
JitsiConference.prototype.hangup = function () {
    if (this.room) {
        return this.room.hangup();
    }
    return new Promise((resolve, reject) => {
        reject(new Error('The conference is not created yet!'));
    });
};
/**
 * Starts the transcription service.
 */
JitsiConference.prototype.startTranscriber = function () {
    return this.dial('jitsi_meet_transcribe');
};
/**
 * Stops the transcription service.
 */
JitsiConference.prototype.stopTranscriber = JitsiConference.prototype.hangup;
/**
 * Returns the phone number for joining the conference.
 */
JitsiConference.prototype.getPhoneNumber = function () {
    if (this.room) {
        return this.room.getPhoneNumber();
    }
    return null;
};
/**
 * Returns the pin for joining the conference with phone.
 */
JitsiConference.prototype.getPhonePin = function () {
    if (this.room) {
        return this.room.getPhonePin();
    }
    return null;
};
/**
 * Returns the meeting unique ID if any.
 *
 * @returns {string|undefined}
 */
JitsiConference.prototype.getMeetingUniqueId = function () {
    if (this.room) {
        return this.room.getMeetingId();
    }
};
/**
 * Will return P2P or JVB <tt>TraceablePeerConnection</tt> depending on
 * which connection is currently active.
 *
 * @return {TraceablePeerConnection|null} null if there isn't any active
 * <tt>TraceablePeerConnection</tt> currently available.
 * @public (FIXME how to make package local ?)
 */
JitsiConference.prototype.getActivePeerConnection = function () {
    const session = this.isP2PActive() ? this.p2pJingleSession : this.jvbJingleSession;
    return session ? session.peerconnection : null;
};
/**
 * Returns the connection state for the current room. Its ice connection state
 * for its session.
 * NOTE that "completed" ICE state which can appear on the P2P connection will
 * be converted to "connected".
 * @return {string|null} ICE state name or <tt>null</tt> if there is no active
 * peer connection at this time.
 */
JitsiConference.prototype.getConnectionState = function () {
    const peerConnection = this.getActivePeerConnection();
    return peerConnection ? peerConnection.getConnectionState() : null;
};
/**
 * Make all new participants mute their audio/video on join.
 * @param policy {Object} object with 2 boolean properties for video and audio:
 * @param {boolean} audio if audio should be muted.
 * @param {boolean} video if video should be muted.
 */
JitsiConference.prototype.setStartMutedPolicy = function (policy) {
    if (!this.isModerator()) {
        logger.warn(`Failed to set start muted policy, ${this.room ? '' : 'not in a room, '}${this.isModerator() ? '' : 'participant is not a moderator'}`);
        return;
    }
    // Do not apply the startMutedPolicy locally on the moderator, the moderator should join with available local
    // sources and the policy needs to be applied only on users that join the call after.
    // this.startMutedPolicy = policy;
    this.room.addOrReplaceInPresence('startmuted', {
        attributes: {
            audio: policy.audio,
            video: policy.video,
            xmlns: 'http://jitsi.org/jitmeet/start-muted'
        }
    }) && this.room.sendPresence();
};
/**
 * Returns current start muted policy
 * @returns {Object} with 2 properties - audio and video.
 */
JitsiConference.prototype.getStartMutedPolicy = function () {
    return this.startMutedPolicy;
};
/**
 * Check if audio is muted on join.
 */
JitsiConference.prototype.isStartAudioMuted = function () {
    return this.startAudioMuted;
};
/**
 * Check if video is muted on join.
 */
JitsiConference.prototype.isStartVideoMuted = function () {
    return this.startVideoMuted;
};
/**
 * Returns measured connectionTimes.
 */
JitsiConference.prototype.getConnectionTimes = function () {
    return this.room.connectionTimes;
};
/**
 * Sets a property for the local participant.
 */
JitsiConference.prototype.setLocalParticipantProperty = function (name, value) {
    this.sendCommand(`jitsi_participant_${name}`, { value });
};
/**
 *  Removes a property for the local participant and sends the updated presence.
 */
JitsiConference.prototype.removeLocalParticipantProperty = function (name) {
    this.removeCommand(`jitsi_participant_${name}`);
    this.room.sendPresence();
};
/**
 * Gets a local participant property.
 *
 * @return value of the local participant property if the tagName exists in the
 * list of properties, otherwise returns undefined.
 */
JitsiConference.prototype.getLocalParticipantProperty = function (name) {
    const property = this.room.presMap.nodes.find(prop => prop.tagName === `jitsi_participant_${name}`);
    return property ? property.value : undefined;
};
/**
 * Sends the given feedback through CallStats if enabled.
 *
 * @param overallFeedback an integer between 1 and 5 indicating the
 * user feedback
 * @param detailedFeedback detailed feedback from the user. Not yet used
 * @returns {Promise} Resolves if feedback is submitted successfully.
 */
JitsiConference.prototype.sendFeedback = function (overallFeedback, detailedFeedback) {
    return this.statistics.sendFeedback(overallFeedback, detailedFeedback);
};
/**
 * Returns true if the callstats integration is enabled, otherwise returns
 * false.
 *
 * @returns true if the callstats integration is enabled, otherwise returns
 * false.
 */
JitsiConference.prototype.isCallstatsEnabled = function () {
    return this.statistics.isCallstatsEnabled();
};
/**
 * Finds the SSRC of a given track
 *
 * @param track
 * @returns {number|undefined} the SSRC of the specificed track, otherwise undefined.
 */
JitsiConference.prototype.getSsrcByTrack = function (track) {
    var _a;
    return track.isLocal() ? (_a = this.getActivePeerConnection()) === null || _a === void 0 ? void 0 : _a.getLocalSSRC(track) : track.getSSRC();
};
/**
 * Handles track attached to container (Calls associateStreamWithVideoTag method
 * from statistics module)
 * @param {JitsiLocalTrack|JitsiRemoteTrack} track the track
 * @param container the container
 */
JitsiConference.prototype._onTrackAttach = function (track, container) {
    const isLocal = track.isLocal();
    let ssrc = null;
    const isP2P = track.isP2P;
    const remoteUserId = isP2P ? track.getParticipantId() : 'jitsi';
    const peerConnection = isP2P
        ? this.p2pJingleSession && this.p2pJingleSession.peerconnection
        : this.jvbJingleSession && this.jvbJingleSession.peerconnection;
    if (isLocal) {
        // Local tracks have SSRC stored on per peer connection basis.
        if (peerConnection) {
            ssrc = peerConnection.getLocalSSRC(track);
        }
    }
    else {
        ssrc = track.getSSRC();
    }
    if (!container.id || !ssrc || !peerConnection) {
        return;
    }
    this.statistics.associateStreamWithVideoTag(peerConnection, ssrc, isLocal, remoteUserId, track.getUsageLabel(), container.id);
};
/**
 * Logs an "application log" message.
 * @param message {string} The message to log. Note that while this can be a
 * generic string, the convention used by lib-jitsi-meet and jitsi-meet is to
 * log valid JSON strings, with an "id" field used for distinguishing between
 * message types. E.g.: {id: "recorder_status", status: "off"}
 */
JitsiConference.prototype.sendApplicationLog = function (message) {
    _modules_statistics_statistics__WEBPACK_IMPORTED_MODULE_38__["default"].sendLog(message);
};
/**
 * Checks if the user identified by given <tt>mucJid</tt> is the conference focus.
 * @param mucJid the full MUC address of the user to be checked.
 * @returns {boolean|null} <tt>true</tt> if MUC user is the conference focus,
 * <tt>false</tt> when is not. <tt>null</tt> if we're not in the MUC anymore and
 * are unable to figure out the status or if given <tt>mucJid</tt> is invalid.
 */
JitsiConference.prototype.isFocus = function (mucJid) {
    return this.room ? this.room.isFocus(mucJid) : null;
};
/**
 * Fires CONFERENCE_FAILED event with INCOMPATIBLE_SERVER_VERSIONS parameter
 */
JitsiConference.prototype._fireIncompatibleVersionsEvent = function () {
    this.eventEmitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_7__.CONFERENCE_FAILED, _JitsiConferenceErrors__WEBPACK_IMPORTED_MODULE_5__.INCOMPATIBLE_SERVER_VERSIONS);
};
/**
 * Sends a message via the data channel.
 * @param to {string} the id of the endpoint that should receive the message.
 * If "" the message will be sent to all participants.
 * @param payload {object} the payload of the message.
 * @throws NetworkError or InvalidStateError or Error if the operation fails.
 * @deprecated Use 'sendMessage' instead. TODO: this should be private.
 */
JitsiConference.prototype.sendEndpointMessage = function (to, payload) {
    this.rtc.sendChannelMessage(to, payload);
};
/**
 * Sends local stats via the bridge channel which then forwards to other endpoints selectively.
 * @param {Object} payload The payload of the message.
 * @throws NetworkError/InvalidStateError/Error if the operation fails or if there is no data channel created.
 */
JitsiConference.prototype.sendEndpointStatsMessage = function (payload) {
    this.rtc.sendEndpointStatsMessage(payload);
};
/**
 * Sends a broadcast message via the data channel.
 * @param payload {object} the payload of the message.
 * @throws NetworkError or InvalidStateError or Error if the operation fails.
 * @deprecated Use 'sendMessage' instead. TODO: this should be private.
 */
JitsiConference.prototype.broadcastEndpointMessage = function (payload) {
    this.sendEndpointMessage('', payload);
};
/**
 * Sends a message to a given endpoint (if 'to' is a non-empty string), or
 * broadcasts it to all endpoints in the conference.
 * @param {string} to The ID of the endpoint/participant which is to receive
 * the message, or '' to broadcast the message to all endpoints in the
 * conference.
 * @param {string|object} message the message to send. If this is of type
 * 'string' it will be sent as a chat message. If it is of type 'object', it
 * will be encapsulated in a format recognized by jitsi-meet and converted to
 * JSON before being sent.
 * @param {boolean} sendThroughVideobridge Whether to send the message through
 * jitsi-videobridge (via the COLIBRI data channel or web socket), or through
 * the XMPP MUC. Currently only objects can be sent through jitsi-videobridge.
 */
JitsiConference.prototype.sendMessage = function (message, to = '', sendThroughVideobridge = false) {
    const messageType = typeof message;
    // Through videobridge we support only objects. Through XMPP we support
    // objects (encapsulated in a specific JSON format) and strings (i.e.
    // regular chat messages).
    if (messageType !== 'object'
        && (sendThroughVideobridge || messageType !== 'string')) {
        logger.error(`Can not send a message of type ${messageType}`);
        return;
    }
    if (sendThroughVideobridge) {
        this.sendEndpointMessage(to, message);
    }
    else {
        let messageToSend = message;
        // Name of packet extension of message stanza to send the required
        // message in.
        let elementName = 'body';
        if (messageType === 'object') {
            elementName = 'json-message';
            // Mark as valid JSON message if not already
            if (!messageToSend.hasOwnProperty(_modules_xmpp_xmpp__WEBPACK_IMPORTED_MODULE_46__.JITSI_MEET_MUC_TYPE)) {
                messageToSend[_modules_xmpp_xmpp__WEBPACK_IMPORTED_MODULE_46__.JITSI_MEET_MUC_TYPE] = '';
            }
            try {
                messageToSend = JSON.stringify(messageToSend);
            }
            catch (e) {
                logger.error('Can not send a message, stringify failed: ', e);
                return;
            }
        }
        if (to) {
            this.sendPrivateTextMessage(to, messageToSend, elementName);
        }
        else {
            // Broadcast
            this.sendTextMessage(messageToSend, elementName);
        }
    }
};
JitsiConference.prototype.isConnectionInterrupted = function () {
    return this.isP2PActive()
        ? this.isP2PConnectionInterrupted : this.isJvbConnectionInterrupted;
};
/**
 * Handles {@link XMPPEvents.CONNECTION_RESTARTED} event. This happens when the bridge goes down
 * and Jicofo moves conferences away to a different bridge.
 * @param {JingleSessionPC} session
 * @private
 */
JitsiConference.prototype._onConferenceRestarted = function (session) {
    if (!session.isP2P && this.options.config.enableForcedReload) {
        this.eventEmitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_7__.CONFERENCE_FAILED, _JitsiConferenceErrors__WEBPACK_IMPORTED_MODULE_5__.CONFERENCE_RESTARTED);
    }
};
/**
 * Handles {@link XMPPEvents.CONNECTION_INTERRUPTED}
 * @param {JingleSessionPC} session
 * @private
 */
JitsiConference.prototype._onIceConnectionInterrupted = function (session) {
    if (session.isP2P) {
        this.isP2PConnectionInterrupted = true;
    }
    else {
        this.isJvbConnectionInterrupted = true;
    }
    if (session.isP2P === this.isP2PActive()) {
        this.eventEmitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_7__.CONNECTION_INTERRUPTED);
    }
};
/**
 * Handles {@link XMPPEvents.CONNECTION_ICE_FAILED}
 * @param {JingleSessionPC} session
 * @private
 */
JitsiConference.prototype._onIceConnectionFailed = function (session) {
    // We do nothing for the JVB connection, because it's up to the Jicofo to
    // eventually come up with the new offer (at least for the time being).
    if (session.isP2P) {
        // Add p2pFailed property to analytics to distinguish, between "good"
        // and "bad" connection
        _modules_statistics_statistics__WEBPACK_IMPORTED_MODULE_38__["default"].analytics.addPermanentProperties({ p2pFailed: true });
        if (this.p2pJingleSession) {
            _modules_statistics_statistics__WEBPACK_IMPORTED_MODULE_38__["default"].sendAnalyticsAndLog((0,_service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_54__.createP2PEvent)(_service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_54__.ACTION_P2P_FAILED, {
                initiator: this.p2pJingleSession.isInitiator
            }));
        }
        this._stopP2PSession({
            reason: 'connectivity-error',
            reasonDescription: 'ICE FAILED'
        });
    }
    else if (session && this.jvbJingleSession === session) {
        this._delayedIceFailed = new _modules_connectivity_IceFailedHandling__WEBPACK_IMPORTED_MODULE_18__["default"](this);
        this._delayedIceFailed.start(session);
    }
};
/**
 * Handles {@link XMPPEvents.CONNECTION_RESTORED}
 * @param {JingleSessionPC} session
 * @private
 */
JitsiConference.prototype._onIceConnectionRestored = function (session) {
    if (session.isP2P) {
        this.isP2PConnectionInterrupted = false;
    }
    else {
        this.isJvbConnectionInterrupted = false;
        this._delayedIceFailed && this._delayedIceFailed.cancel();
    }
    if (session.isP2P === this.isP2PActive()) {
        this.eventEmitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_7__.CONNECTION_RESTORED);
    }
};
/**
 * Accept incoming P2P Jingle call.
 * @param {JingleSessionPC} jingleSession the session instance
 * @param {jQuery} jingleOffer a jQuery selector pointing to 'jingle' IQ element
 * @private
 */
JitsiConference.prototype._acceptP2PIncomingCall = function (jingleSession, jingleOffer) {
    this.isP2PConnectionInterrupted = false;
    // Accept the offer
    this.p2pJingleSession = jingleSession;
    this._sendConferenceJoinAnalyticsEvent();
    this.p2pJingleSession.initialize(this.room, this.rtc, this._signalingLayer, Object.assign(Object.assign({}, this.options.config), { codecSettings: {
            mediaType: _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_49__.MediaType.VIDEO,
            codecList: this.codecSelection.getCodecPreferenceList('p2p')
        }, enableInsertableStreams: this.isE2EEEnabled() || _modules_flags_FeatureFlags__WEBPACK_IMPORTED_MODULE_28__["default"].isRunInLiteModeEnabled() }));
    logger.info('Starting CallStats for P2P connection...');
    let remoteID = strophe_js__WEBPACK_IMPORTED_MODULE_4__.Strophe.getResourceFromJid(this.p2pJingleSession.remoteJid);
    const participant = this.participants.get(remoteID);
    if (participant) {
        remoteID = participant.getStatsID() || remoteID;
    }
    this.statistics.startCallStats(this.p2pJingleSession.peerconnection, remoteID);
    const localTracks = this.getLocalTracks();
    this.p2pJingleSession.acceptOffer(jingleOffer, () => {
        logger.debug('Got RESULT for P2P "session-accept"');
        this.eventEmitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_7__._MEDIA_SESSION_STARTED, jingleSession);
    }, error => {
        logger.error('Failed to accept incoming P2P Jingle session', error);
    }, localTracks);
};
/**
 * Adds remote tracks to the conference associated with the JVB session.
 * @private
 */
JitsiConference.prototype._addRemoteJVBTracks = function () {
    this._addRemoteTracks('JVB', this.jvbJingleSession.peerconnection.getRemoteTracks());
};
/**
 * Adds remote tracks to the conference associated with the P2P session.
 * @private
 */
JitsiConference.prototype._addRemoteP2PTracks = function () {
    this._addRemoteTracks('P2P', this.p2pJingleSession.peerconnection.getRemoteTracks());
};
/**
 * Generates fake "remote track added" events for given Jingle session.
 * @param {string} logName the session's nickname which will appear in log messages.
 * @param {Array<JitsiRemoteTrack>} remoteTracks the tracks that will be added
 * @private
 */
JitsiConference.prototype._addRemoteTracks = function (logName, remoteTracks) {
    for (const track of remoteTracks) {
        // There will be orphan (with no owner) tracks when ssrc-rewriting is enabled and all of them need to be addded
        // back to the conference.
        if (_modules_flags_FeatureFlags__WEBPACK_IMPORTED_MODULE_28__["default"].isSsrcRewritingSupported() || this.participants.has(track.ownerEndpointId)) {
            logger.info(`Adding remote ${logName} track: ${track}`);
            this.onRemoteTrackAdded(track);
        }
    }
};
/**
 * Called when {@link XMPPEvents.CONNECTION_ESTABLISHED} event is
 * triggered for a {@link JingleSessionPC}. Switches the conference to use
 * the P2P connection if the event comes from the P2P session.
 * @param {JingleSessionPC} jingleSession the session instance.
 * @private
 */
JitsiConference.prototype._onIceConnectionEstablished = function (jingleSession) {
    if (this.p2pJingleSession !== null) {
        // store the establishment time of the p2p session as a field of the
        // JitsiConference because the p2pJingleSession might get disposed (thus
        // the value is lost).
        this.p2pEstablishmentDuration
            = this.p2pJingleSession.establishmentDuration;
    }
    if (this.jvbJingleSession !== null) {
        this.jvbEstablishmentDuration
            = this.jvbJingleSession.establishmentDuration;
    }
    let done = false;
    const forceJVB121Ratio = this.options.config.forceJVB121Ratio;
    // We don't care about the JVB case, there's nothing to be done
    if (!jingleSession.isP2P) {
        done = true;
    }
    else if (this.p2pJingleSession !== jingleSession) {
        logger.error('CONNECTION_ESTABLISHED - wrong P2P session instance ?!');
        done = true;
    }
    else if (!jingleSession.isInitiator
        && typeof forceJVB121Ratio === 'number'
        && Math.random() < forceJVB121Ratio) {
        logger.info(`Forcing JVB 121 mode (ratio=${forceJVB121Ratio})...`);
        _modules_statistics_statistics__WEBPACK_IMPORTED_MODULE_38__["default"].analytics.addPermanentProperties({ forceJvb121: true });
        this._stopP2PSession({
            reason: 'decline',
            reasonDescription: 'force JVB121'
        });
        done = true;
    }
    if (!isNaN(this.p2pEstablishmentDuration)
        && !isNaN(this.jvbEstablishmentDuration)) {
        const establishmentDurationDiff = this.p2pEstablishmentDuration - this.jvbEstablishmentDuration;
        _modules_statistics_statistics__WEBPACK_IMPORTED_MODULE_38__["default"].sendAnalytics(_service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_54__.ICE_ESTABLISHMENT_DURATION_DIFF, { value: establishmentDurationDiff });
    }
    if (jingleSession.isP2P === this.isP2PActive()) {
        this.eventEmitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_7__.CONNECTION_ESTABLISHED);
    }
    if (done) {
        return;
    }
    // Update P2P status and emit events
    this._setP2PStatus(true);
    // Remove remote tracks
    if (this.jvbJingleSession) {
        this._removeRemoteJVBTracks();
    }
    else {
        logger.info('Not removing remote JVB tracks - no session yet');
    }
    this._addRemoteP2PTracks();
    // Stop media transfer over the JVB connection
    if (this.jvbJingleSession) {
        this._suspendMediaTransferForJvbConnection();
    }
    logger.info('Starting remote stats with p2p connection');
    this.statistics.startRemoteStats(this.p2pJingleSession.peerconnection);
    _modules_statistics_statistics__WEBPACK_IMPORTED_MODULE_38__["default"].sendAnalyticsAndLog((0,_service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_54__.createP2PEvent)(_service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_54__.ACTION_P2P_ESTABLISHED, {
        initiator: this.p2pJingleSession.isInitiator
    }));
};
/**
 * Called when the chat room reads a new list of properties from jicofo's
 * presence. The properties may have changed, but they don't have to.
 *
 * @param {Object} properties - The properties keyed by the property name
 * ('key').
 * @private
 */
JitsiConference.prototype._updateProperties = function (properties = {}) {
    const changed = !lodash_isequal__WEBPACK_IMPORTED_MODULE_3___default()(properties, this.properties);
    this.properties = properties;
    if (changed) {
        this.eventEmitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_7__.PROPERTIES_CHANGED, this.properties);
        const audioLimitReached = this.properties['audio-limit-reached'] === 'true';
        const videoLimitReached = this.properties['video-limit-reached'] === 'true';
        if (this._audioSenderLimitReached !== audioLimitReached) {
            this._audioSenderLimitReached = audioLimitReached;
            this.eventEmitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_7__.AUDIO_UNMUTE_PERMISSIONS_CHANGED, audioLimitReached);
            logger.info(`Audio unmute permissions set by Jicofo to ${audioLimitReached}`);
        }
        if (this._videoSenderLimitReached !== videoLimitReached) {
            this._videoSenderLimitReached = videoLimitReached;
            this.eventEmitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_7__.VIDEO_UNMUTE_PERMISSIONS_CHANGED, videoLimitReached);
            logger.info(`Video unmute permissions set by Jicofo to ${videoLimitReached}`);
        }
        // Some of the properties need to be added to analytics events.
        const analyticsKeys = [
            // The number of jitsi-videobridge instances currently used for the
            // conference.
            'bridge-count'
        ];
        analyticsKeys.forEach(key => {
            if (properties[key] !== undefined) {
                _modules_statistics_statistics__WEBPACK_IMPORTED_MODULE_38__["default"].analytics.addPermanentProperties({
                    [key.replace('-', '_')]: properties[key]
                });
            }
        });
    }
};
/**
 * Gets a conference property with a given key.
 *
 * @param {string} key - The key.
 * @returns {*} The value
 */
JitsiConference.prototype.getProperty = function (key) {
    return this.properties[key];
};
/**
 * Clears the deferred start P2P task if it has been scheduled.
 * @private
 */
JitsiConference.prototype._maybeClearDeferredStartP2P = function () {
    if (this.deferredStartP2PTask) {
        logger.info('Cleared deferred start P2P task');
        clearTimeout(this.deferredStartP2PTask);
        this.deferredStartP2PTask = null;
    }
};
/**
 * Removes from the conference remote tracks associated with the JVB
 * connection.
 * @private
 */
JitsiConference.prototype._removeRemoteJVBTracks = function () {
    this._removeRemoteTracks('JVB', this.jvbJingleSession.peerconnection.getRemoteTracks());
};
/**
 * Removes from the conference remote tracks associated with the P2P
 * connection.
 * @private
 */
JitsiConference.prototype._removeRemoteP2PTracks = function () {
    this._removeRemoteTracks('P2P', this.p2pJingleSession.peerconnection.getRemoteTracks());
};
/**
 * Generates fake "remote track removed" events for given Jingle session.
 * @param {string} sessionNickname the session's nickname which will appear in
 * log messages.
 * @param {Array<JitsiRemoteTrack>} remoteTracks the tracks that will be removed
 * @private
 */
JitsiConference.prototype._removeRemoteTracks = function (sessionNickname, remoteTracks) {
    for (const track of remoteTracks) {
        logger.info(`Removing remote ${sessionNickname} track: ${track}`);
        this.onRemoteTrackRemoved(track);
    }
};
/**
 * Resumes media transfer over the JVB connection.
 * @private
 */
JitsiConference.prototype._resumeMediaTransferForJvbConnection = function () {
    logger.info('Resuming media transfer over the JVB connection...');
    this.jvbJingleSession.setMediaTransferActive(true)
        .then(() => {
        logger.info('Resumed media transfer over the JVB connection!');
    })
        .catch(error => {
        logger.error('Failed to resume media transfer over the JVB connection:', error);
    });
};
/**
 * Sets new P2P status and updates some events/states hijacked from
 * the <tt>JitsiConference</tt>.
 * @param {boolean} newStatus the new P2P status value, <tt>true</tt> means that
 * P2P is now in use, <tt>false</tt> means that the JVB connection is now in use
 * @private
 */
JitsiConference.prototype._setP2PStatus = function (newStatus) {
    if (this.p2p === newStatus) {
        logger.debug(`Called _setP2PStatus with the same status: ${newStatus}`);
        return;
    }
    this.p2p = newStatus;
    if (newStatus) {
        logger.info('Peer to peer connection established!');
        // When we end up in a valid P2P session need to reset the properties
        // in case they have persisted, after session with another peer.
        _modules_statistics_statistics__WEBPACK_IMPORTED_MODULE_38__["default"].analytics.addPermanentProperties({
            p2pFailed: false,
            forceJvb121: false
        });
        // Sync up video transfer active in case p2pJingleSession not existed
        // when the lastN value was being adjusted.
        const isVideoActive = this.getLastN() !== 0;
        this.p2pJingleSession.setP2pVideoTransferActive(isVideoActive)
            .catch(error => {
            logger.error(`Failed to sync up P2P video transfer status (${isVideoActive}), ${error}`);
        });
    }
    else {
        logger.info('Peer to peer connection closed!');
    }
    // Put the JVB connection on hold/resume
    if (this.jvbJingleSession) {
        this.statistics.sendConnectionResumeOrHoldEvent(this.jvbJingleSession.peerconnection, !newStatus);
    }
    // Clear dtmfManager, so that it can be recreated with new connection
    this.dtmfManager = null;
    // Update P2P status
    this.eventEmitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_7__.P2P_STATUS, this, this.p2p);
    this.eventEmitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_7__._MEDIA_SESSION_ACTIVE_CHANGED, this.getActiveMediaSession());
    // Refresh connection interrupted/restored
    this.eventEmitter.emit(this.isConnectionInterrupted()
        ? _JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_7__.CONNECTION_INTERRUPTED
        : _JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_7__.CONNECTION_RESTORED);
};
/**
 * Starts new P2P session.
 * @param {string} remoteJid the JID of the remote participant
 * @private
 */
JitsiConference.prototype._startP2PSession = function (remoteJid) {
    this._maybeClearDeferredStartP2P();
    if (this.p2pJingleSession) {
        logger.error('P2P session already started!');
        return;
    }
    this.isP2PConnectionInterrupted = false;
    this.p2pJingleSession
        = this.xmpp.connection.jingle.newP2PJingleSession(this.room.myroomjid, remoteJid);
    logger.info('Created new P2P JingleSession', this.room.myroomjid, remoteJid);
    this._sendConferenceJoinAnalyticsEvent();
    this.p2pJingleSession.initialize(this.room, this.rtc, this._signalingLayer, Object.assign(Object.assign({}, this.options.config), { codecSettings: {
            mediaType: _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_49__.MediaType.VIDEO,
            codecList: this.codecSelection.getCodecPreferenceList('p2p')
        }, enableInsertableStreams: this.isE2EEEnabled() || _modules_flags_FeatureFlags__WEBPACK_IMPORTED_MODULE_28__["default"].isRunInLiteModeEnabled() }));
    logger.info('Starting CallStats for P2P connection...');
    let remoteID = strophe_js__WEBPACK_IMPORTED_MODULE_4__.Strophe.getResourceFromJid(this.p2pJingleSession.remoteJid);
    const participant = this.participants.get(remoteID);
    if (participant) {
        remoteID = participant.getStatsID() || remoteID;
    }
    this.statistics.startCallStats(this.p2pJingleSession.peerconnection, remoteID);
    const localTracks = this.getLocalTracks();
    this.p2pJingleSession.invite(localTracks);
};
/**
 * Suspends media transfer over the JVB connection.
 * @private
 */
JitsiConference.prototype._suspendMediaTransferForJvbConnection = function () {
    logger.info('Suspending media transfer over the JVB connection...');
    this.jvbJingleSession.setMediaTransferActive(false)
        .then(() => {
        logger.info('Suspended media transfer over the JVB connection !');
    })
        .catch(error => {
        logger.error('Failed to suspend media transfer over the JVB connection:', error);
    });
};
/**
 * Method when called will decide whether it's the time to start or stop
 * the P2P session.
 * @param {boolean} userLeftEvent if <tt>true</tt> it means that the call
 * originates from the user left event.
 * @private
 */
JitsiConference.prototype._maybeStartOrStopP2P = function (userLeftEvent) {
    if (!this.isP2PEnabled()
        || this.isP2PTestModeEnabled()
        || (_modules_browser__WEBPACK_IMPORTED_MODULE_16__["default"].isFirefox() && !this._firefoxP2pEnabled)
        || this.isE2EEEnabled()) {
        logger.info('Auto P2P disabled');
        return;
    }
    const peers = this.getParticipants();
    const peerCount = peers.length;
    // FIXME 1 peer and it must *support* P2P switching
    const shouldBeInP2P = this._shouldBeInP2PMode();
    // Clear deferred "start P2P" task
    if (!shouldBeInP2P && this.deferredStartP2PTask) {
        this._maybeClearDeferredStartP2P();
    }
    // Start peer to peer session
    if (!this.p2pJingleSession && shouldBeInP2P) {
        const peer = peerCount && peers[0];
        const myId = this.myUserId();
        const peersId = peer.getId();
        if (myId > peersId) {
            logger.debug('I\'m the bigger peersId - '
                + 'the other peer should start P2P', myId, peersId);
            return;
        }
        else if (myId === peersId) {
            logger.error('The same IDs ? ', myId, peersId);
            return;
        }
        const jid = peer.getJid();
        if (userLeftEvent) {
            if (this.deferredStartP2PTask) {
                logger.error('Deferred start P2P task\'s been set already!');
                return;
            }
            logger.info(`Will start P2P with: ${jid} after ${this.backToP2PDelay} seconds...`);
            this.deferredStartP2PTask = setTimeout(this._startP2PSession.bind(this, jid), this.backToP2PDelay * 1000);
        }
        else {
            logger.info(`Will start P2P with: ${jid}`);
            this._startP2PSession(jid);
        }
    }
    else if (this.p2pJingleSession && !shouldBeInP2P) {
        logger.info(`Will stop P2P with: ${this.p2pJingleSession.remoteJid}`);
        // Log that there will be a switch back to the JVB connection
        if (this.p2pJingleSession.isInitiator && peerCount > 1) {
            _modules_statistics_statistics__WEBPACK_IMPORTED_MODULE_38__["default"].sendAnalyticsAndLog((0,_service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_54__.createP2PEvent)(_service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_54__.ACTION_P2P_SWITCH_TO_JVB));
        }
        this._stopP2PSession();
    }
};
/**
 * Tells whether or not this conference should be currently in the P2P mode.
 *
 * @private
 * @returns {boolean}
 */
JitsiConference.prototype._shouldBeInP2PMode = function () {
    const peers = this.getParticipants();
    const peerCount = peers.length;
    const hasBotPeer = peers.find(p => p.getBotType() === 'poltergeist' || p.hasFeature(_modules_xmpp_xmpp__WEBPACK_IMPORTED_MODULE_46__.FEATURE_JIGASI)) !== undefined;
    const shouldBeInP2P = peerCount === 1 && !hasBotPeer;
    logger.debug(`P2P? peerCount: ${peerCount}, hasBotPeer: ${hasBotPeer} => ${shouldBeInP2P}`);
    return shouldBeInP2P;
};
/**
 * Stops the current P2P session.
 * @param {Object} options - Options for stopping P2P.
 * @param {string} options.reason - One of the Jingle "reason" element
 * names as defined by https://xmpp.org/extensions/xep-0166.html#def-reason
 * @param {string} options.reasonDescription - Text
 * description that will be included in the session terminate message
 * @param {boolean} requestRestart - Whether this is due to a session restart, in which case
 * media will not be resumed on the JVB.
 * @private
 */
JitsiConference.prototype._stopP2PSession = function (options = {}) {
    const { reason = 'success', reasonDescription = 'Turning off P2P session', requestRestart = false } = options;
    if (!this.p2pJingleSession) {
        logger.error('No P2P session to be stopped!');
        return;
    }
    const wasP2PEstablished = this.isP2PActive();
    // Swap remote tracks, but only if the P2P has been fully established
    if (wasP2PEstablished) {
        if (this.jvbJingleSession && !requestRestart) {
            this._resumeMediaTransferForJvbConnection();
        }
        // Remove remote P2P tracks
        this._removeRemoteP2PTracks();
    }
    // Stop P2P stats
    logger.info('Stopping remote stats for P2P connection');
    this.statistics.stopRemoteStats(this.p2pJingleSession.peerconnection);
    logger.info('Stopping CallStats for P2P connection');
    this.statistics.stopCallStats(this.p2pJingleSession.peerconnection);
    this.p2pJingleSession.terminate(() => {
        logger.info('P2P session terminate RESULT');
    }, error => {
        // Because both initiator and responder are simultaneously
        // terminating their JingleSessions in case of the 'to JVB switch'
        // when 3rd participant joins, both will dispose their sessions and
        // reply with 'item-not-found' (see strophe.jingle.js). We don't
        // want to log this as an error since it's expected behaviour.
        //
        // We want them both to terminate, because in case of initiator's
        // crash the responder would stay in P2P mode until ICE fails which
        // could take up to 20 seconds.
        //
        // NOTE: whilst this is an error callback,  'success' as a reason is
        // considered as graceful session terminate
        // where both initiator and responder terminate their sessions
        // simultaneously.
        if (reason !== 'success') {
            logger.error('An error occurred while trying to terminate P2P Jingle session', error);
        }
    }, {
        reason,
        reasonDescription,
        sendSessionTerminate: this.room
            && this.getParticipantById(strophe_js__WEBPACK_IMPORTED_MODULE_4__.Strophe.getResourceFromJid(this.p2pJingleSession.remoteJid))
    });
    this.p2pJingleSession = null;
    // Update P2P status and other affected events/states
    this._setP2PStatus(false);
    if (wasP2PEstablished) {
        // Add back remote JVB tracks
        if (this.jvbJingleSession && !requestRestart) {
            this._addRemoteJVBTracks();
        }
        else {
            logger.info('Not adding remote JVB tracks - no session yet');
        }
    }
};
/**
 * Updates room presence if needed and send the packet in case of a modification.
 * @param {JingleSessionPC} jingleSession the session firing the event, contains the peer connection which
 * tracks we will check.
 * @param {Object|null} ctx a context object we can distinguish multiple calls of the same pass of updating tracks.
 */
JitsiConference.prototype._updateRoomPresence = function (jingleSession, ctx) {
    if (!jingleSession) {
        return;
    }
    // skips sending presence twice for the same pass of updating ssrcs
    if (ctx) {
        if (ctx.skip) {
            return;
        }
        ctx.skip = true;
    }
    let presenceChanged = false;
    let muteStatusChanged, videoTypeChanged;
    const localTracks = jingleSession.peerconnection.getLocalTracks();
    // Set presence for all the available local tracks.
    for (const track of localTracks) {
        const muted = track.isMuted();
        muteStatusChanged = this._setTrackMuteStatus(track.getType(), track, muted);
        muteStatusChanged && logger.debug(`Updating mute state of ${track} in presence to muted=${muted}`);
        if (track.getType() === _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_49__.MediaType.VIDEO) {
            videoTypeChanged = this._setNewVideoType(track);
            videoTypeChanged && logger.debug(`Updating videoType in presence to ${track.getVideoType()}`);
        }
        presenceChanged = presenceChanged || muteStatusChanged || videoTypeChanged;
    }
    presenceChanged && this.room.sendPresence();
};
/**
 * Checks whether or not the conference is currently in the peer to peer mode.
 * Being in peer to peer mode means that the direct connection has been
 * established and the P2P connection is being used for media transmission.
 * @return {boolean} <tt>true</tt> if in P2P mode or <tt>false</tt> otherwise.
 */
JitsiConference.prototype.isP2PActive = function () {
    return this.p2p;
};
/**
 * Returns the current ICE state of the P2P connection.
 * NOTE: method is used by the jitsi-meet-torture tests.
 * @return {string|null} an ICE state or <tt>null</tt> if there's currently
 * no P2P connection.
 */
JitsiConference.prototype.getP2PConnectionState = function () {
    if (this.isP2PActive()) {
        return this.p2pJingleSession.peerconnection.getConnectionState();
    }
    return null;
};
/**
 * Configures the peerconnection so that a given framre rate can be achieved for desktop share.
 *
 * @param {number} maxFps The capture framerate to be used for desktop tracks.
 * @returns {boolean} true if the operation is successful, false otherwise.
 */
JitsiConference.prototype.setDesktopSharingFrameRate = function (maxFps) {
    if (typeof maxFps !== 'number' || isNaN(maxFps)) {
        logger.error(`Invalid value ${maxFps} specified for desktop capture frame rate`);
        return false;
    }
    this._desktopSharingFrameRate = maxFps;
    // Enable or disable simulcast for plan-b screensharing based on the capture fps.
    this.jvbJingleSession && this.jvbJingleSession.peerconnection.setDesktopSharingFrameRate(maxFps);
    // Set the capture rate for desktop sharing.
    this.rtc.setDesktopSharingFrameRate(maxFps);
    return true;
};
/**
 * Manually starts new P2P session (should be used only in the tests).
 */
JitsiConference.prototype.startP2PSession = function () {
    const peers = this.getParticipants();
    // Start peer to peer session
    if (peers.length === 1) {
        const peerJid = peers[0].getJid();
        this._startP2PSession(peerJid);
    }
    else {
        throw new Error('There must be exactly 1 participant to start the P2P session !');
    }
};
/**
 * Manually stops the current P2P session (should be used only in the tests).
 */
JitsiConference.prototype.stopP2PSession = function (options) {
    this._stopP2PSession(options);
};
/**
 * Get a summary of how long current participants have been the dominant speaker
 * @returns {object}
 */
JitsiConference.prototype.getSpeakerStats = function () {
    return this.speakerStatsCollector.getStats();
};
/**
 * Sends a face landmarks object to the xmpp server.
 * @param {Object} payload
 */
JitsiConference.prototype.sendFaceLandmarks = function (payload) {
    if (payload.faceExpression) {
        this.xmpp.sendFaceLandmarksEvent(this.room.roomjid, payload);
    }
};
/**
 * Sets the constraints for the video that is requested from the bridge.
 *
 * @param {Object} videoConstraints The constraints which are specified in the following format. The message updates
 * the fields that are present and leaves the rest unchanged on the bridge. Therefore, any field that is not applicable
 * anymore should be cleared by passing an empty object or list (whatever is applicable).
 * {
 *      'lastN': 20,
 *      'selectedSources': ['A', 'B', 'C'],
 *      'onStageSources': ['A'],
 *      'defaultConstraints': { 'maxHeight': 180 },
 *      'constraints': {
 *          'A': { 'maxHeight': 720 }
 *      }
 * }
 * Where A, B and C are source-names of the remote tracks that are being requested from the bridge.
 */
JitsiConference.prototype.setReceiverConstraints = function (videoConstraints) {
    this.receiveVideoController.setReceiverConstraints(videoConstraints);
};
/**
 * Sets the assumed bandwidth bps for the video that is requested from the bridge.
 *
 * @param {Number} assumedBandwidthBps - The bandwidth value expressed in bits per second.
 */
JitsiConference.prototype.setAssumedBandwidthBps = function (assumedBandwidthBps) {
    this.receiveVideoController.setAssumedBandwidthBps(assumedBandwidthBps);
};
/**
 * Sets the maximum video size the local participant should receive from remote
 * participants.
 *
 * @param {number} maxFrameHeight - the maximum frame height, in pixels,
 * this receiver is willing to receive.
 * @returns {void}
 */
JitsiConference.prototype.setReceiverVideoConstraint = function (maxFrameHeight) {
    this.receiveVideoController.setPreferredReceiveMaxFrameHeight(maxFrameHeight);
};
/**
 * Sets the maximum video size the local participant should send to remote
 * participants.
 * @param {number} maxFrameHeight - The user preferred max frame height.
 * @returns {Promise} promise that will be resolved when the operation is
 * successful and rejected otherwise.
 */
JitsiConference.prototype.setSenderVideoConstraint = function (maxFrameHeight) {
    return this.sendVideoController.setPreferredSendMaxFrameHeight(maxFrameHeight);
};
/**
 * Creates a video SIP GW session and returns it if service is enabled. Before
 * creating a session one need to check whether video SIP GW service is
 * available in the system {@link JitsiConference.isVideoSIPGWAvailable}. Even
 * if there are available nodes to serve this request, after creating the
 * session those nodes can be taken and the request about using the
 * created session can fail.
 *
 * @param {string} sipAddress - The sip address to be used.
 * @param {string} displayName - The display name to be used for this session.
 * @returns {JitsiVideoSIPGWSession|Error} Returns null if conference is not
 * initialised and there is no room.
 */
JitsiConference.prototype.createVideoSIPGWSession = function (sipAddress, displayName) {
    if (!this.room) {
        return new Error(_modules_videosipgw_VideoSIPGWConstants__WEBPACK_IMPORTED_MODULE_44__.ERROR_NO_CONNECTION);
    }
    return this.videoSIPGWHandler
        .createVideoSIPGWSession(sipAddress, displayName);
};
/**
 * Sends a conference.join analytics event.
 *
 * @returns {void}
 */
JitsiConference.prototype._sendConferenceJoinAnalyticsEvent = function () {
    const meetingId = this.getMeetingUniqueId();
    if (this._conferenceJoinAnalyticsEventSent || !meetingId || this.getActivePeerConnection() === null) {
        return;
    }
    _modules_statistics_statistics__WEBPACK_IMPORTED_MODULE_38__["default"].sendAnalytics((0,_service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_54__.createConferenceEvent)('joined', {
        meetingId,
        participantId: `${meetingId}.${this._statsCurrentId}`
    }));
    this._conferenceJoinAnalyticsEventSent = Date.now();
};
/**
 * Sends conference.left analytics event.
 * @private
 */
JitsiConference.prototype._sendConferenceLeftAnalyticsEvent = function () {
    const meetingId = this.getMeetingUniqueId();
    if (!meetingId || !this._conferenceJoinAnalyticsEventSent) {
        return;
    }
    _modules_statistics_statistics__WEBPACK_IMPORTED_MODULE_38__["default"].sendAnalytics((0,_service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_54__.createConferenceEvent)('left', {
        meetingId,
        participantId: `${meetingId}.${this._statsCurrentId}`,
        stats: {
            duration: Math.floor((Date.now() - this._conferenceJoinAnalyticsEventSent) / 1000),
            perf: this.getPerformanceStats()
        }
    }));
};
/**
 * Restarts all active media sessions.
 *
 * @returns {void}
 */
JitsiConference.prototype._restartMediaSessions = function () {
    if (this.p2pJingleSession) {
        this._stopP2PSession({
            reasonDescription: 'restart',
            requestRestart: true
        });
    }
    if (this.jvbJingleSession) {
        this.jvbJingleSession.terminate(null /* success callback => we don't care */, error => {
            logger.warn('An error occurred while trying to terminate the JVB session', error);
        }, {
            reason: 'success',
            reasonDescription: 'restart required',
            requestRestart: true,
            sendSessionTerminate: true
        });
    }
    this._maybeStartOrStopP2P(false);
};
/**
 * Returns whether End-To-End encryption is enabled.
 *
 * @returns {boolean}
 */
JitsiConference.prototype.isE2EEEnabled = function () {
    return Boolean(this._e2eEncryption && this._e2eEncryption.isEnabled());
};
/**
 * Returns whether End-To-End encryption is supported. Note that not all participants
 * in the conference may support it.
 *
 * @returns {boolean}
 */
JitsiConference.prototype.isE2EESupported = function () {
    return _modules_e2ee_E2EEncryption__WEBPACK_IMPORTED_MODULE_25__.E2EEncryption.isSupported(this.options.config);
};
/**
 * Enables / disables End-to-End encryption.
 *
 * @param {boolean} enabled whether to enable E2EE or not.
 * @returns {void}
 */
JitsiConference.prototype.toggleE2EE = function (enabled) {
    if (!this.isE2EESupported()) {
        logger.warn('Cannot enable / disable E2EE: platform is not supported.');
        return;
    }
    this._e2eEncryption.setEnabled(enabled);
};
/**
 * Sets the key and index for End-to-End encryption.
 *
 * @param {CryptoKey} [keyInfo.encryptionKey] - encryption key.
 * @param {Number} [keyInfo.index] - the index of the encryption key.
 * @returns {void}
 */
JitsiConference.prototype.setMediaEncryptionKey = function (keyInfo) {
    this._e2eEncryption.setEncryptionKey(keyInfo);
};
/**
 * Starts the participant verification process.
 *
 * @param {string} participantId The participant which will be marked as verified.
 * @returns {void}
 */
JitsiConference.prototype.startVerification = function (participantId) {
    const participant = this.getParticipantById(participantId);
    if (!participant) {
        return;
    }
    this._e2eEncryption.startVerification(participant);
};
/**
 * Marks the given participant as verified. After this is done, MAC verification will
 * be performed and an event will be emitted with the result.
 *
 * @param {string} participantId The participant which will be marked as verified.
 * @param {boolean} isVerified - whether the verification was succesfull.
 * @returns {void}
 */
JitsiConference.prototype.markParticipantVerified = function (participantId, isVerified) {
    const participant = this.getParticipantById(participantId);
    if (!participant) {
        return;
    }
    this._e2eEncryption.markParticipantVerified(participant, isVerified);
};
/**
 * Returns <tt>true</tt> if lobby support is enabled in the backend.
 *
 * @returns {boolean} whether lobby is supported in the backend.
 */
JitsiConference.prototype.isLobbySupported = function () {
    return Boolean(this.room && this.room.getLobby().isSupported());
};
/**
 * Returns <tt>true</tt> if the room has members only enabled.
 *
 * @returns {boolean} whether conference room is members only.
 */
JitsiConference.prototype.isMembersOnly = function () {
    return Boolean(this.room && this.room.membersOnlyEnabled);
};
/**
 * Enables lobby by moderators
 *
 * @returns {Promise} resolves when lobby room is joined or rejects with the error.
 */
JitsiConference.prototype.enableLobby = function () {
    if (this.room && this.isModerator()) {
        return this.room.getLobby().enable();
    }
    return Promise.reject(new Error('The conference not started or user is not moderator'));
};
/**
 * Disabled lobby by moderators
 *
 * @returns {void}
 */
JitsiConference.prototype.disableLobby = function () {
    if (this.room && this.isModerator()) {
        this.room.getLobby().disable();
    }
    else {
        logger.warn(`Failed to disable lobby, ${this.room ? '' : 'not in a room, '}${this.isModerator() ? '' : 'participant is not a moderator'}`);
    }
};
/**
 * Joins the lobby room with display name and optional email or with a shared password to skip waiting.
 *
 * @param {string} displayName Display name should be set to show it to moderators.
 * @param {string} email Optional email is used to present avatar to the moderator.
 * @returns {Promise<never>}
 */
JitsiConference.prototype.joinLobby = function (displayName, email) {
    if (this.room) {
        return this.room.getLobby().join(displayName, email);
    }
    return Promise.reject(new Error('The conference not started'));
};
/**
 * Gets the local id for a participant in a lobby room.
 * Returns undefined when current participant is not in the lobby room.
 * This is used for lobby room private chat messages.
 *
 * @returns {string}
 */
JitsiConference.prototype.myLobbyUserId = function () {
    if (this.room) {
        return this.room.getLobby().getLocalId();
    }
};
/**
 * Sends a message to a lobby room.
 * When id is specified it sends a private message.
 * Otherwise it sends the message to all moderators.
 * @param {message} Object The message to send
 * @param {string} id The participant id.
 *
 * @returns {void}
 */
JitsiConference.prototype.sendLobbyMessage = function (message, id) {
    if (this.room) {
        if (id) {
            return this.room.getLobby().sendPrivateMessage(id, message);
        }
        return this.room.getLobby().sendMessage(message);
    }
};
/**
 * Adds a message listener to the lobby room
 * @param {Function} listener The listener function,
 * called when a new message is received in the lobby room.
 *
 * @returns {Function} Handler returned to be able to remove it later.
 */
JitsiConference.prototype.addLobbyMessageListener = function (listener) {
    if (this.room) {
        return this.room.getLobby().addMessageListener(listener);
    }
};
/**
 * Removes a message handler from the lobby room
 * @param {Function} handler The handler function  to remove.
 *
 * @returns {void}
 */
JitsiConference.prototype.removeLobbyMessageHandler = function (handler) {
    if (this.room) {
        return this.room.getLobby().removeMessageHandler(handler);
    }
};
/**
 * Denies an occupant in the lobby room access to the conference.
 * @param {string} id The participant id.
 */
JitsiConference.prototype.lobbyDenyAccess = function (id) {
    if (this.room) {
        this.room.getLobby().denyAccess(id);
    }
};
/**
 * Approves the request to join the conference to a participant waiting in the lobby.
 *
 * @param {string} id The participant id.
 */
JitsiConference.prototype.lobbyApproveAccess = function (id) {
    if (this.room) {
        this.room.getLobby().approveAccess(id);
    }
};
/**
 * Returns <tt>true</tt> if AV Moderation support is enabled in the backend.
 *
 * @returns {boolean} whether AV Moderation is supported in the backend.
 */
JitsiConference.prototype.isAVModerationSupported = function () {
    return Boolean(this.room && this.room.getAVModeration().isSupported());
};
/**
 * Enables AV Moderation.
 * @param {MediaType} mediaType "audio" or "video"
 */
JitsiConference.prototype.enableAVModeration = function (mediaType) {
    if (this.room && this.isModerator()
        && (mediaType === _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_49__.MediaType.AUDIO || mediaType === _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_49__.MediaType.VIDEO)) {
        this.room.getAVModeration().enable(true, mediaType);
    }
    else {
        logger.warn(`Failed to enable AV moderation, ${this.room ? '' : 'not in a room, '}${this.isModerator() ? '' : 'participant is not a moderator, '}${this.room && this.isModerator() ? 'wrong media type passed' : ''}`);
    }
};
/**
 * Disables AV Moderation.
 * @param {MediaType} mediaType "audio" or "video"
 */
JitsiConference.prototype.disableAVModeration = function (mediaType) {
    if (this.room && this.isModerator()
        && (mediaType === _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_49__.MediaType.AUDIO || mediaType === _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_49__.MediaType.VIDEO)) {
        this.room.getAVModeration().enable(false, mediaType);
    }
    else {
        logger.warn(`Failed to disable AV moderation, ${this.room ? '' : 'not in a room, '}${this.isModerator() ? '' : 'participant is not a moderator, '}${this.room && this.isModerator() ? 'wrong media type passed' : ''}`);
    }
};
/**
 * Approve participant access to certain media, allows unmuting audio or video.
 *
 * @param {MediaType} mediaType "audio" or "video"
 * @param id the id of the participant.
 */
JitsiConference.prototype.avModerationApprove = function (mediaType, id) {
    if (this.room && this.isModerator()
        && (mediaType === _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_49__.MediaType.AUDIO || mediaType === _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_49__.MediaType.VIDEO)) {
        const participant = this.getParticipantById(id);
        if (!participant) {
            return;
        }
        this.room.getAVModeration().approve(mediaType, participant.getJid());
    }
    else {
        logger.warn(`AV moderation approve skipped , ${this.room ? '' : 'not in a room, '}${this.isModerator() ? '' : 'participant is not a moderator, '}${this.room && this.isModerator() ? 'wrong media type passed' : ''}`);
    }
};
/**
 * Reject participant access to certain media, blocks unmuting audio or video.
 *
 * @param {MediaType} mediaType "audio" or "video"
 * @param id the id of the participant.
 */
JitsiConference.prototype.avModerationReject = function (mediaType, id) {
    if (this.room && this.isModerator()
        && (mediaType === _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_49__.MediaType.AUDIO || mediaType === _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_49__.MediaType.VIDEO)) {
        const participant = this.getParticipantById(id);
        if (!participant) {
            return;
        }
        this.room.getAVModeration().reject(mediaType, participant.getJid());
    }
    else {
        logger.warn(`AV moderation reject skipped , ${this.room ? '' : 'not in a room, '}${this.isModerator() ? '' : 'participant is not a moderator, '}${this.room && this.isModerator() ? 'wrong media type passed' : ''}`);
    }
};
/**
 * Returns the breakout rooms manager object.
 *
 * @returns {Object} the breakout rooms manager.
 */
JitsiConference.prototype.getBreakoutRooms = function () {
    var _a;
    return (_a = this.room) === null || _a === void 0 ? void 0 : _a.getBreakoutRooms();
};
/**
 * Returns the metadata handler object.
 *
 * @returns {Object} the room metadata handler.
 */
JitsiConference.prototype.getMetadataHandler = function () {
    var _a;
    return (_a = this.room) === null || _a === void 0 ? void 0 : _a.getMetadataHandler();
};
//# sourceMappingURL=JitsiConference.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/JitsiConferenceErrors.js":
/*!******************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/JitsiConferenceErrors.js ***!
  \******************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   AUTHENTICATION_REQUIRED: () => (/* binding */ AUTHENTICATION_REQUIRED),
/* harmony export */   CHAT_ERROR: () => (/* binding */ CHAT_ERROR),
/* harmony export */   CONFERENCE_ACCESS_DENIED: () => (/* binding */ CONFERENCE_ACCESS_DENIED),
/* harmony export */   CONFERENCE_DESTROYED: () => (/* binding */ CONFERENCE_DESTROYED),
/* harmony export */   CONFERENCE_MAX_USERS: () => (/* binding */ CONFERENCE_MAX_USERS),
/* harmony export */   CONFERENCE_RESTARTED: () => (/* binding */ CONFERENCE_RESTARTED),
/* harmony export */   CONNECTION_ERROR: () => (/* binding */ CONNECTION_ERROR),
/* harmony export */   DISPLAY_NAME_REQUIRED: () => (/* binding */ DISPLAY_NAME_REQUIRED),
/* harmony export */   FOCUS_DISCONNECTED: () => (/* binding */ FOCUS_DISCONNECTED),
/* harmony export */   FOCUS_LEFT: () => (/* binding */ FOCUS_LEFT),
/* harmony export */   GRACEFUL_SHUTDOWN: () => (/* binding */ GRACEFUL_SHUTDOWN),
/* harmony export */   ICE_FAILED: () => (/* binding */ ICE_FAILED),
/* harmony export */   INCOMPATIBLE_SERVER_VERSIONS: () => (/* binding */ INCOMPATIBLE_SERVER_VERSIONS),
/* harmony export */   JitsiConferenceErrors: () => (/* binding */ JitsiConferenceErrors),
/* harmony export */   MEMBERS_ONLY_ERROR: () => (/* binding */ MEMBERS_ONLY_ERROR),
/* harmony export */   NOT_ALLOWED_ERROR: () => (/* binding */ NOT_ALLOWED_ERROR),
/* harmony export */   OFFER_ANSWER_FAILED: () => (/* binding */ OFFER_ANSWER_FAILED),
/* harmony export */   PASSWORD_NOT_SUPPORTED: () => (/* binding */ PASSWORD_NOT_SUPPORTED),
/* harmony export */   PASSWORD_REQUIRED: () => (/* binding */ PASSWORD_REQUIRED),
/* harmony export */   REDIRECTED: () => (/* binding */ REDIRECTED),
/* harmony export */   RESERVATION_ERROR: () => (/* binding */ RESERVATION_ERROR),
/* harmony export */   SETTINGS_ERROR: () => (/* binding */ SETTINGS_ERROR),
/* harmony export */   VIDEOBRIDGE_NOT_AVAILABLE: () => (/* binding */ VIDEOBRIDGE_NOT_AVAILABLE)
/* harmony export */ });
/**
 * The errors for the conference.
 */
var JitsiConferenceErrors;
(function (JitsiConferenceErrors) {
    /**
     * Indicates that client must be authenticated to create the conference.
     */
    JitsiConferenceErrors["AUTHENTICATION_REQUIRED"] = "conference.authenticationRequired";
    /**
     * Indicates that chat error occurred.
     */
    JitsiConferenceErrors["CHAT_ERROR"] = "conference.chatError";
    /**
     * Indicates that a settings error occurred.
     */
    JitsiConferenceErrors["SETTINGS_ERROR"] = "conference.settingsError";
    /**
     * Indicates that conference has been destroyed.
     */
    JitsiConferenceErrors["CONFERENCE_DESTROYED"] = "conference.destroyed";
    /**
     * Indicates that max users limit has been reached.
     */
    JitsiConferenceErrors["CONFERENCE_MAX_USERS"] = "conference.max_users";
    /**
     * Indicates that a connection error occurred when trying to join a conference.
     */
    JitsiConferenceErrors["CONNECTION_ERROR"] = "conference.connectionError";
    /**
     * Indicates that the client has been forced to restart by jicofo when the
     * conference was migrated from one bridge to another.
     */
    JitsiConferenceErrors["CONFERENCE_RESTARTED"] = "conference.restarted";
    /**
     * Indicates that a connection error is due to not allowed,
     * occurred when trying to join a conference.
     */
    JitsiConferenceErrors["NOT_ALLOWED_ERROR"] = "conference.connectionError.notAllowed";
    /**
     * Indicates that a connection error is due to not allowed,
     * occurred when trying to join a conference, only approved members are allowed to join.
     */
    JitsiConferenceErrors["MEMBERS_ONLY_ERROR"] = "conference.connectionError.membersOnly";
    /**
     * Indicates that a connection error is due to denied access to the room,
     * occurred after joining a lobby room and access is denied by the room moderators.
     */
    JitsiConferenceErrors["CONFERENCE_ACCESS_DENIED"] = "conference.connectionError.accessDenied";
    /**
     * Indicates that the display name is required when joining the room.
     * There are cases like lobby room where display name is required.
     * @param {boolean|null} lobby whether the error is because lobby is enabled.
     */
    JitsiConferenceErrors["DISPLAY_NAME_REQUIRED"] = "conference.display_name_required";
    /**
     * Indicates that focus error happened.
     */
    JitsiConferenceErrors["FOCUS_DISCONNECTED"] = "conference.focusDisconnected";
    /**
     * Indicates that focus left the conference.
     */
    JitsiConferenceErrors["FOCUS_LEFT"] = "conference.focusLeft";
    /**
     * Indicates that graceful shutdown happened.
     */
    JitsiConferenceErrors["GRACEFUL_SHUTDOWN"] = "conference.gracefulShutdown";
    /**
     * Indicates that the media connection has failed.
     */
    JitsiConferenceErrors["ICE_FAILED"] = "conference.iceFailed";
    /**
     * Indicates that the versions of the server side components are incompatible
     * with the client side.
     */
    JitsiConferenceErrors["INCOMPATIBLE_SERVER_VERSIONS"] = "conference.incompatible_server_versions";
    /**
     * Indicates that offer/answer had failed.
     */
    JitsiConferenceErrors["OFFER_ANSWER_FAILED"] = "conference.offerAnswerFailed";
    /**
     * Indicates that password cannot be set for this conference.
     */
    JitsiConferenceErrors["PASSWORD_NOT_SUPPORTED"] = "conference.passwordNotSupported";
    /**
     * Indicates that a password is required in order to join the conference.
     */
    JitsiConferenceErrors["PASSWORD_REQUIRED"] = "conference.passwordRequired";
    /**
     * The conference is redirected to a visitor node.
     */
    JitsiConferenceErrors["REDIRECTED"] = "conference.redirected";
    /**
     * Indicates that reservation system returned error.
     */
    JitsiConferenceErrors["RESERVATION_ERROR"] = "conference.reservationError";
    /**
     * Indicates that there is no available videobridge.
     */
    JitsiConferenceErrors["VIDEOBRIDGE_NOT_AVAILABLE"] = "conference.videobridgeNotAvailable";
})(JitsiConferenceErrors || (JitsiConferenceErrors = {}));
;
// exported for backward compatibility
const AUTHENTICATION_REQUIRED = JitsiConferenceErrors.AUTHENTICATION_REQUIRED;
const CHAT_ERROR = JitsiConferenceErrors.CHAT_ERROR;
const SETTINGS_ERROR = JitsiConferenceErrors.SETTINGS_ERROR;
const CONFERENCE_DESTROYED = JitsiConferenceErrors.CONFERENCE_DESTROYED;
const CONFERENCE_MAX_USERS = JitsiConferenceErrors.CONFERENCE_MAX_USERS;
const CONNECTION_ERROR = JitsiConferenceErrors.CONNECTION_ERROR;
const CONFERENCE_RESTARTED = JitsiConferenceErrors.CONFERENCE_RESTARTED;
const NOT_ALLOWED_ERROR = JitsiConferenceErrors.NOT_ALLOWED_ERROR;
const MEMBERS_ONLY_ERROR = JitsiConferenceErrors.MEMBERS_ONLY_ERROR;
const CONFERENCE_ACCESS_DENIED = JitsiConferenceErrors.CONFERENCE_ACCESS_DENIED;
const DISPLAY_NAME_REQUIRED = JitsiConferenceErrors.DISPLAY_NAME_REQUIRED;
const FOCUS_DISCONNECTED = JitsiConferenceErrors.FOCUS_DISCONNECTED;
const FOCUS_LEFT = JitsiConferenceErrors.FOCUS_LEFT;
const GRACEFUL_SHUTDOWN = JitsiConferenceErrors.GRACEFUL_SHUTDOWN;
const ICE_FAILED = JitsiConferenceErrors.ICE_FAILED;
const INCOMPATIBLE_SERVER_VERSIONS = JitsiConferenceErrors.INCOMPATIBLE_SERVER_VERSIONS;
const OFFER_ANSWER_FAILED = JitsiConferenceErrors.OFFER_ANSWER_FAILED;
const PASSWORD_NOT_SUPPORTED = JitsiConferenceErrors.PASSWORD_NOT_SUPPORTED;
const PASSWORD_REQUIRED = JitsiConferenceErrors.PASSWORD_REQUIRED;
const REDIRECTED = JitsiConferenceErrors.REDIRECTED;
const RESERVATION_ERROR = JitsiConferenceErrors.RESERVATION_ERROR;
const VIDEOBRIDGE_NOT_AVAILABLE = JitsiConferenceErrors.VIDEOBRIDGE_NOT_AVAILABLE;
//# sourceMappingURL=JitsiConferenceErrors.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/JitsiConferenceEventManager.js":
/*!************************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/JitsiConferenceEventManager.js ***!
  \************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
var __filename = "/index.js";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (/* binding */ JitsiConferenceEventManager)
/* harmony export */ });
/* harmony import */ var _jitsi_logger__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @jitsi/logger */ "./node_modules/@jitsi/logger/lib/index.js");
/* harmony import */ var _jitsi_logger__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(_jitsi_logger__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var strophe_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! strophe.js */ "./node_modules/strophe.js/dist/strophe.umd.js");
/* harmony import */ var strophe_js__WEBPACK_IMPORTED_MODULE_1___default = /*#__PURE__*/__webpack_require__.n(strophe_js__WEBPACK_IMPORTED_MODULE_1__);
/* harmony import */ var _JitsiConferenceErrors__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./JitsiConferenceErrors */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/JitsiConferenceErrors.js");
/* harmony import */ var _JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./JitsiConferenceEvents */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/JitsiConferenceEvents.js");
/* harmony import */ var _JitsiTrackEvents__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./JitsiTrackEvents */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/JitsiTrackEvents.js");
/* harmony import */ var _modules_statistics_constants__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./modules/statistics/constants */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/statistics/constants.js");
/* harmony import */ var _modules_statistics_statistics__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./modules/statistics/statistics */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/statistics/statistics.js");
/* harmony import */ var _modules_util_EventEmitterForwarder__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./modules/util/EventEmitterForwarder */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/util/EventEmitterForwarder.js");
/* harmony import */ var _modules_util_EventEmitterForwarder__WEBPACK_IMPORTED_MODULE_7___default = /*#__PURE__*/__webpack_require__.n(_modules_util_EventEmitterForwarder__WEBPACK_IMPORTED_MODULE_7__);
/* harmony import */ var _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ./service/RTC/MediaType */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/RTC/MediaType.js");
/* harmony import */ var _service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ./service/RTC/RTCEvents */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/RTC/RTCEvents.js");
/* harmony import */ var _service_RTC_VideoType__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ./service/RTC/VideoType */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/RTC/VideoType.js");
/* harmony import */ var _service_authentication_AuthenticationEvents__WEBPACK_IMPORTED_MODULE_11__ = __webpack_require__(/*! ./service/authentication/AuthenticationEvents */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/authentication/AuthenticationEvents.js");
/* harmony import */ var _service_authentication_AuthenticationEvents__WEBPACK_IMPORTED_MODULE_11___default = /*#__PURE__*/__webpack_require__.n(_service_authentication_AuthenticationEvents__WEBPACK_IMPORTED_MODULE_11__);
/* harmony import */ var _service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_12__ = __webpack_require__(/*! ./service/statistics/AnalyticsEvents */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/statistics/AnalyticsEvents.js");
/* harmony import */ var _service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_13__ = __webpack_require__(/*! ./service/xmpp/XMPPEvents */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/xmpp/XMPPEvents.js");














const logger = (0,_jitsi_logger__WEBPACK_IMPORTED_MODULE_0__.getLogger)(__filename);
/**
 * Setups all event listeners related to conference
 * @param conference {JitsiConference} the conference
 */
function JitsiConferenceEventManager(conference) {
    this.conference = conference;
    this.xmppListeners = {};
    // Listeners related to the conference only
    conference.on(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_3__.TRACK_MUTE_CHANGED, track => {
        if (!track.isLocal() || !conference.statistics) {
            return;
        }
        const session = track.isP2P
            ? conference.p2pJingleSession : conference.jvbJingleSession;
        // TPC will be null, before the conference starts, but the event
        // still should be queued
        const tpc = (session && session.peerconnection) || null;
        conference.statistics.sendMuteEvent(tpc, track.isMuted(), track.getType());
    });
}
/**
 * Setups event listeners related to conference.chatRoom
 */
JitsiConferenceEventManager.prototype.setupChatRoomListeners = function () {
    const conference = this.conference;
    const chatRoom = conference.room;
    this.chatRoomForwarder = new (_modules_util_EventEmitterForwarder__WEBPACK_IMPORTED_MODULE_7___default())(chatRoom, this.conference.eventEmitter);
    chatRoom.addListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_13__.XMPPEvents.ICE_RESTARTING, jingleSession => {
        if (!jingleSession.isP2P) {
            // If using DataChannel as bridge channel, it must be closed
            // before ICE restart, otherwise Chrome will not trigger "opened"
            // event for the channel established with the new bridge.
            // TODO: This may be bypassed when using a WebSocket as bridge
            // channel.
            conference.rtc.closeBridgeChannel();
        }
        // else: there are no DataChannels in P2P session (at least for now)
    });
    chatRoom.addListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_13__.XMPPEvents.PARTICIPANT_FEATURES_CHANGED, (from, features) => {
        const participant = conference.getParticipantById(strophe_js__WEBPACK_IMPORTED_MODULE_1__.Strophe.getResourceFromJid(from));
        if (participant) {
            participant.setFeatures(features);
            conference.eventEmitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_3__.PARTCIPANT_FEATURES_CHANGED, participant);
        }
    });
    chatRoom.addListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_13__.XMPPEvents.ICE_RESTART_SUCCESS, (jingleSession, offerIq) => {
        // The JVB data chanel needs to be reopened in case the conference
        // has been moved to a new bridge.
        !jingleSession.isP2P
            && conference._setBridgeChannel(offerIq, jingleSession.peerconnection);
    });
    chatRoom.addListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_13__.XMPPEvents.AUDIO_MUTED_BY_FOCUS, actor => {
        // TODO: Add a way to differentiate between commands which caused
        // us to mute and those that did not change our state (i.e. we were
        // already muted).
        _modules_statistics_statistics__WEBPACK_IMPORTED_MODULE_6__["default"].sendAnalytics((0,_service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_12__.createRemotelyMutedEvent)(_service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_8__.MediaType.AUDIO));
        conference.mutedByFocusActor = actor;
        // set isMutedByFocus when setAudioMute Promise ends
        conference.rtc.setAudioMute(true).then(() => {
            conference.isMutedByFocus = true;
            conference.mutedByFocusActor = null;
        })
            .catch(error => {
            conference.mutedByFocusActor = null;
            logger.warn('Error while audio muting due to focus request', error);
        });
    });
    chatRoom.addListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_13__.XMPPEvents.VIDEO_MUTED_BY_FOCUS, actor => {
        // TODO: Add a way to differentiate between commands which caused
        // us to mute and those that did not change our state (i.e. we were
        // already muted).
        _modules_statistics_statistics__WEBPACK_IMPORTED_MODULE_6__["default"].sendAnalytics((0,_service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_12__.createRemotelyMutedEvent)(_service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_8__.MediaType.VIDEO));
        conference.mutedVideoByFocusActor = actor;
        // set isVideoMutedByFocus when setVideoMute Promise ends
        conference.rtc.setVideoMute(true).then(() => {
            conference.isVideoMutedByFocus = true;
            conference.mutedVideoByFocusActor = null;
        })
            .catch(error => {
            conference.mutedVideoByFocusActor = null;
            logger.warn('Error while video muting due to focus request', error);
        });
    });
    this.chatRoomForwarder.forward(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_13__.XMPPEvents.SUBJECT_CHANGED, _JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_3__.SUBJECT_CHANGED);
    this.chatRoomForwarder.forward(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_13__.XMPPEvents.MUC_JOINED, _JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_3__.CONFERENCE_JOINED);
    this.chatRoomForwarder.forward(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_13__.XMPPEvents.MUC_JOIN_IN_PROGRESS, _JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_3__.CONFERENCE_JOIN_IN_PROGRESS);
    this.chatRoomForwarder.forward(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_13__.XMPPEvents.MEETING_ID_SET, _JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_3__.CONFERENCE_UNIQUE_ID_SET);
    // send some analytics events
    chatRoom.addListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_13__.XMPPEvents.MUC_JOINED, () => {
        this.conference._onMucJoined();
        this.conference.isJvbConnectionInterrupted = false;
        // TODO: Move all of the 'connectionTimes' logic to its own module.
        Object.keys(chatRoom.connectionTimes).forEach(key => {
            const event = (0,_service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_12__.createConnectionStageReachedEvent)(`conference_${key}`, { value: chatRoom.connectionTimes[key] });
            _modules_statistics_statistics__WEBPACK_IMPORTED_MODULE_6__["default"].sendAnalytics(event);
        });
        // TODO: Move all of the 'connectionTimes' logic to its own module.
        Object.keys(chatRoom.xmpp.connectionTimes).forEach(key => {
            const event = (0,_service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_12__.createConnectionStageReachedEvent)(`xmpp_${key}`, { value: chatRoom.xmpp.connectionTimes[key] });
            _modules_statistics_statistics__WEBPACK_IMPORTED_MODULE_6__["default"].sendAnalytics(event);
        });
    });
    chatRoom.addListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_13__.XMPPEvents.RENEGOTIATION_FAILED, (e, session) => {
        if (!session.isP2P) {
            conference.eventEmitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_3__.CONFERENCE_FAILED, _JitsiConferenceErrors__WEBPACK_IMPORTED_MODULE_2__.OFFER_ANSWER_FAILED, e);
        }
    });
    chatRoom.addListener(_JitsiTrackEvents__WEBPACK_IMPORTED_MODULE_4__.TRACK_REMOVED, track => {
        conference.eventEmitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_3__.TRACK_REMOVED, track);
    });
    this.chatRoomForwarder.forward(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_13__.XMPPEvents.ROOM_JOIN_ERROR, _JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_3__.CONFERENCE_FAILED, _JitsiConferenceErrors__WEBPACK_IMPORTED_MODULE_2__.CONNECTION_ERROR);
    this.chatRoomForwarder.forward(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_13__.XMPPEvents.DISPLAY_NAME_REQUIRED, _JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_3__.CONFERENCE_FAILED, _JitsiConferenceErrors__WEBPACK_IMPORTED_MODULE_2__.DISPLAY_NAME_REQUIRED);
    this.chatRoomForwarder.forward(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_13__.XMPPEvents.ROOM_CONNECT_ERROR, _JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_3__.CONFERENCE_FAILED, _JitsiConferenceErrors__WEBPACK_IMPORTED_MODULE_2__.CONNECTION_ERROR);
    this.chatRoomForwarder.forward(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_13__.XMPPEvents.ROOM_CONNECT_NOT_ALLOWED_ERROR, _JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_3__.CONFERENCE_FAILED, _JitsiConferenceErrors__WEBPACK_IMPORTED_MODULE_2__.NOT_ALLOWED_ERROR);
    this.chatRoomForwarder.forward(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_13__.XMPPEvents.ROOM_CONNECT_MEMBERS_ONLY_ERROR, _JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_3__.CONFERENCE_FAILED, _JitsiConferenceErrors__WEBPACK_IMPORTED_MODULE_2__.MEMBERS_ONLY_ERROR);
    this.chatRoomForwarder.forward(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_13__.XMPPEvents.ROOM_MAX_USERS_ERROR, _JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_3__.CONFERENCE_FAILED, _JitsiConferenceErrors__WEBPACK_IMPORTED_MODULE_2__.CONFERENCE_MAX_USERS);
    this.chatRoomForwarder.forward(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_13__.XMPPEvents.PASSWORD_REQUIRED, _JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_3__.CONFERENCE_FAILED, _JitsiConferenceErrors__WEBPACK_IMPORTED_MODULE_2__.PASSWORD_REQUIRED);
    this.chatRoomForwarder.forward(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_13__.XMPPEvents.AUTHENTICATION_REQUIRED, _JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_3__.CONFERENCE_FAILED, _JitsiConferenceErrors__WEBPACK_IMPORTED_MODULE_2__.AUTHENTICATION_REQUIRED);
    this.chatRoomForwarder.forward(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_13__.XMPPEvents.REDIRECTED, _JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_3__.CONFERENCE_FAILED, _JitsiConferenceErrors__WEBPACK_IMPORTED_MODULE_2__.REDIRECTED);
    this.chatRoomForwarder.forward(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_13__.XMPPEvents.BRIDGE_DOWN, _JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_3__.CONFERENCE_FAILED, _JitsiConferenceErrors__WEBPACK_IMPORTED_MODULE_2__.VIDEOBRIDGE_NOT_AVAILABLE);
    chatRoom.addListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_13__.XMPPEvents.BRIDGE_DOWN, () => _modules_statistics_statistics__WEBPACK_IMPORTED_MODULE_6__["default"].sendAnalytics((0,_service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_12__.createBridgeDownEvent)()));
    chatRoom.addListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_13__.XMPPEvents.CONNECTION_RESTARTED, jingleSession => {
        conference._onConferenceRestarted(jingleSession);
    });
    this.chatRoomForwarder.forward(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_13__.XMPPEvents.RESERVATION_ERROR, _JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_3__.CONFERENCE_FAILED, _JitsiConferenceErrors__WEBPACK_IMPORTED_MODULE_2__.RESERVATION_ERROR);
    this.chatRoomForwarder.forward(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_13__.XMPPEvents.GRACEFUL_SHUTDOWN, _JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_3__.CONFERENCE_FAILED, _JitsiConferenceErrors__WEBPACK_IMPORTED_MODULE_2__.GRACEFUL_SHUTDOWN);
    chatRoom.addListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_13__.XMPPEvents.CONNECTION_ICE_FAILED, jingleSession => {
        conference._onIceConnectionFailed(jingleSession);
    });
    this.chatRoomForwarder.forward(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_13__.XMPPEvents.MUC_DESTROYED, _JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_3__.CONFERENCE_FAILED, _JitsiConferenceErrors__WEBPACK_IMPORTED_MODULE_2__.CONFERENCE_DESTROYED);
    this.chatRoomForwarder.forward(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_13__.XMPPEvents.CHAT_ERROR_RECEIVED, _JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_3__.CONFERENCE_ERROR, _JitsiConferenceErrors__WEBPACK_IMPORTED_MODULE_2__.CHAT_ERROR);
    this.chatRoomForwarder.forward(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_13__.XMPPEvents.SETTINGS_ERROR_RECEIVED, _JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_3__.CONFERENCE_ERROR, _JitsiConferenceErrors__WEBPACK_IMPORTED_MODULE_2__.SETTINGS_ERROR);
    this.chatRoomForwarder.forward(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_13__.XMPPEvents.FOCUS_DISCONNECTED, _JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_3__.CONFERENCE_FAILED, _JitsiConferenceErrors__WEBPACK_IMPORTED_MODULE_2__.FOCUS_DISCONNECTED);
    chatRoom.addListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_13__.XMPPEvents.FOCUS_LEFT, () => {
        _modules_statistics_statistics__WEBPACK_IMPORTED_MODULE_6__["default"].sendAnalytics((0,_service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_12__.createFocusLeftEvent)());
        conference.eventEmitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_3__.CONFERENCE_FAILED, _JitsiConferenceErrors__WEBPACK_IMPORTED_MODULE_2__.FOCUS_LEFT);
    });
    chatRoom.addListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_13__.XMPPEvents.SESSION_ACCEPT_TIMEOUT, jingleSession => {
        _modules_statistics_statistics__WEBPACK_IMPORTED_MODULE_6__["default"].sendAnalyticsAndLog((0,_service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_12__.createJingleEvent)(_service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_12__.ACTION_JINGLE_SA_TIMEOUT, { p2p: jingleSession.isP2P }));
    });
    chatRoom.addListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_13__.XMPPEvents.RECORDER_STATE_CHANGED, (session, jid) => {
        if (jid) {
            const resource = strophe_js__WEBPACK_IMPORTED_MODULE_1__.Strophe.getResourceFromJid(jid);
            const participant = conference.getParticipantById(resource) || resource;
            if (session.getStatus() === 'off') {
                session.setTerminator(participant);
            }
            else if (session.getStatus() === 'on') {
                session.setInitiator(participant);
            }
        }
        conference.eventEmitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_3__.RECORDER_STATE_CHANGED, session);
    });
    this.chatRoomForwarder.forward(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_13__.XMPPEvents.TRANSCRIPTION_STATUS_CHANGED, _JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_3__.TRANSCRIPTION_STATUS_CHANGED);
    this.chatRoomForwarder.forward(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_13__.XMPPEvents.VIDEO_SIP_GW_AVAILABILITY_CHANGED, _JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_3__.VIDEO_SIP_GW_AVAILABILITY_CHANGED);
    this.chatRoomForwarder.forward(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_13__.XMPPEvents.VIDEO_SIP_GW_SESSION_STATE_CHANGED, _JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_3__.VIDEO_SIP_GW_SESSION_STATE_CHANGED);
    this.chatRoomForwarder.forward(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_13__.XMPPEvents.PHONE_NUMBER_CHANGED, _JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_3__.PHONE_NUMBER_CHANGED);
    chatRoom.setParticipantPropertyListener((node, from) => {
        const participant = conference.getParticipantById(from);
        if (!participant) {
            return;
        }
        participant.setProperty(node.tagName.substring('jitsi_participant_'.length), node.value);
    });
    chatRoom.addListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_13__.XMPPEvents.KICKED, conference.onMemberKicked.bind(conference));
    chatRoom.addListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_13__.XMPPEvents.SUSPEND_DETECTED, conference.onSuspendDetected.bind(conference));
    this.chatRoomForwarder.forward(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_13__.XMPPEvents.MUC_LOCK_CHANGED, _JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_3__.LOCK_STATE_CHANGED);
    this.chatRoomForwarder.forward(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_13__.XMPPEvents.MUC_MEMBERS_ONLY_CHANGED, _JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_3__.MEMBERS_ONLY_CHANGED);
    chatRoom.addListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_13__.XMPPEvents.MUC_MEMBER_JOINED, conference.onMemberJoined.bind(conference));
    this.chatRoomForwarder.forward(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_13__.XMPPEvents.MUC_LOBBY_MEMBER_JOINED, _JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_3__.LOBBY_USER_JOINED);
    this.chatRoomForwarder.forward(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_13__.XMPPEvents.MUC_LOBBY_MEMBER_UPDATED, _JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_3__.LOBBY_USER_UPDATED);
    this.chatRoomForwarder.forward(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_13__.XMPPEvents.MUC_LOBBY_MEMBER_LEFT, _JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_3__.LOBBY_USER_LEFT);
    chatRoom.addListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_13__.XMPPEvents.MUC_MEMBER_BOT_TYPE_CHANGED, conference._onMemberBotTypeChanged.bind(conference));
    chatRoom.addListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_13__.XMPPEvents.MUC_MEMBER_LEFT, conference.onMemberLeft.bind(conference));
    this.chatRoomForwarder.forward(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_13__.XMPPEvents.MUC_LEFT, _JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_3__.CONFERENCE_LEFT);
    this.chatRoomForwarder.forward(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_13__.XMPPEvents.MUC_DENIED_ACCESS, _JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_3__.CONFERENCE_FAILED, _JitsiConferenceErrors__WEBPACK_IMPORTED_MODULE_2__.CONFERENCE_ACCESS_DENIED);
    chatRoom.addListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_13__.XMPPEvents.DISPLAY_NAME_CHANGED, conference.onDisplayNameChanged.bind(conference));
    chatRoom.addListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_13__.XMPPEvents.LOCAL_ROLE_CHANGED, role => {
        conference.onLocalRoleChanged(role);
        // log all events for the recorder operated by the moderator
        if (conference.statistics && conference.isModerator()) {
            conference.on(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_3__.RECORDER_STATE_CHANGED, recorderSession => {
                const logObject = {
                    error: recorderSession.getError(),
                    id: 'recorder_status',
                    status: recorderSession.getStatus()
                };
                _modules_statistics_statistics__WEBPACK_IMPORTED_MODULE_6__["default"].sendLog(JSON.stringify(logObject));
            });
        }
    });
    chatRoom.addListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_13__.XMPPEvents.MUC_ROLE_CHANGED, conference.onUserRoleChanged.bind(conference));
    chatRoom.addListener((_service_authentication_AuthenticationEvents__WEBPACK_IMPORTED_MODULE_11___default().IDENTITY_UPDATED), (authEnabled, authIdentity) => {
        conference.authEnabled = authEnabled;
        conference.authIdentity = authIdentity;
        conference.eventEmitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_3__.AUTH_STATUS_CHANGED, authEnabled, authIdentity);
    });
    chatRoom.addListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_13__.XMPPEvents.MESSAGE_RECEIVED, 
    // eslint-disable-next-line max-params
    (jid, txt, myJid, ts, nick, isGuest) => {
        const id = strophe_js__WEBPACK_IMPORTED_MODULE_1__.Strophe.getResourceFromJid(jid);
        conference.eventEmitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_3__.MESSAGE_RECEIVED, id, txt, ts, nick, isGuest);
    });
    chatRoom.addListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_13__.XMPPEvents.PRIVATE_MESSAGE_RECEIVED, 
    // eslint-disable-next-line max-params
    (jid, txt, myJid, ts) => {
        const id = strophe_js__WEBPACK_IMPORTED_MODULE_1__.Strophe.getResourceFromJid(jid);
        conference.eventEmitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_3__.PRIVATE_MESSAGE_RECEIVED, id, txt, ts);
    });
    chatRoom.addListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_13__.XMPPEvents.PRESENCE_STATUS, (jid, status) => {
        const id = strophe_js__WEBPACK_IMPORTED_MODULE_1__.Strophe.getResourceFromJid(jid);
        const participant = conference.getParticipantById(id);
        if (!participant || participant._status === status) {
            return;
        }
        participant._status = status;
        conference.eventEmitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_3__.USER_STATUS_CHANGED, id, status);
    });
    chatRoom.addListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_13__.XMPPEvents.JSON_MESSAGE_RECEIVED, (from, payload) => {
        const id = strophe_js__WEBPACK_IMPORTED_MODULE_1__.Strophe.getResourceFromJid(from);
        const participant = conference.getParticipantById(id);
        if (participant) {
            conference.eventEmitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_3__.ENDPOINT_MESSAGE_RECEIVED, participant, payload);
        }
        else {
            conference.eventEmitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_3__.NON_PARTICIPANT_MESSAGE_RECEIVED, id, payload);
        }
    });
    chatRoom.addPresenceListener('startmuted', (data, from) => {
        // Ignore the strartmuted policy if the presence is received from self. The moderator should join with
        // available local sources and the policy needs to be applied only on users that join the call after.
        if (conference.myUserId() === from) {
            return;
        }
        const participant = conference.getParticipantById(from);
        if (!participant || !participant.isModerator()) {
            return;
        }
        const startAudioMuted = data.attributes.audio === 'true';
        const startVideoMuted = data.attributes.video === 'true';
        let updated = false;
        if (startAudioMuted !== conference.startMutedPolicy.audio) {
            conference.startMutedPolicy.audio = startAudioMuted;
            updated = true;
        }
        if (startVideoMuted !== conference.startMutedPolicy.video) {
            conference.startMutedPolicy.video = startVideoMuted;
            updated = true;
        }
        if (updated) {
            conference.eventEmitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_3__.START_MUTED_POLICY_CHANGED, conference.startMutedPolicy);
        }
    });
    if (conference.statistics) {
        // FIXME ICE related events should end up in RTCEvents eventually
        chatRoom.addListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_13__.XMPPEvents.CONNECTION_ICE_FAILED, session => {
            conference.statistics.sendIceConnectionFailedEvent(session.peerconnection);
        });
        // FIXME XMPPEvents.ADD_ICE_CANDIDATE_FAILED is never emitted
        chatRoom.addListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_13__.XMPPEvents.ADD_ICE_CANDIDATE_FAILED, (e, pc) => {
            conference.statistics.sendAddIceCandidateFailed(e, pc);
        });
    }
    // Breakout rooms.
    this.chatRoomForwarder.forward(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_13__.XMPPEvents.BREAKOUT_ROOMS_MOVE_TO_ROOM, _JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_3__.BREAKOUT_ROOMS_MOVE_TO_ROOM);
    this.chatRoomForwarder.forward(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_13__.XMPPEvents.BREAKOUT_ROOMS_UPDATED, _JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_3__.BREAKOUT_ROOMS_UPDATED);
    // Room metadata.
    this.chatRoomForwarder.forward(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_13__.XMPPEvents.ROOM_METADATA_UPDATED, _JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_3__.METADATA_UPDATED);
};
/**
 * Setups event listeners related to conference.rtc
 */
JitsiConferenceEventManager.prototype.setupRTCListeners = function () {
    const conference = this.conference;
    const rtc = conference.rtc;
    rtc.addListener(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_9__["default"].REMOTE_TRACK_ADDED, conference.onRemoteTrackAdded.bind(conference));
    rtc.addListener(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_9__["default"].REMOTE_TRACK_REMOVED, conference.onRemoteTrackRemoved.bind(conference));
    rtc.addListener(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_9__["default"].DOMINANT_SPEAKER_CHANGED, (dominant, previous, silence) => {
        if ((conference.lastDominantSpeaker !== dominant || conference.dominantSpeakerIsSilent !== silence)
            && conference.room) {
            conference.lastDominantSpeaker = dominant;
            conference.dominantSpeakerIsSilent = silence;
            conference.eventEmitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_3__.DOMINANT_SPEAKER_CHANGED, dominant, previous, silence);
            if (conference.statistics && conference.myUserId() === dominant) {
                // We are the new dominant speaker.
                conference.statistics.sendDominantSpeakerEvent(conference.room.roomjid, silence);
            }
            if (conference.lastDominantSpeaker !== dominant) {
                if (previous && previous.length) {
                    const speakerList = previous.slice(0);
                    // Add the dominant speaker to the top of the list (exclude self).
                    if (conference.myUserId !== dominant) {
                        speakerList.splice(0, 0, dominant);
                    }
                    // Trim the list to the top 5 speakers only.
                    if (speakerList.length > _modules_statistics_constants__WEBPACK_IMPORTED_MODULE_5__.SPEAKERS_AUDIO_LEVELS) {
                        speakerList.splice(_modules_statistics_constants__WEBPACK_IMPORTED_MODULE_5__.SPEAKERS_AUDIO_LEVELS, speakerList.length - _modules_statistics_constants__WEBPACK_IMPORTED_MODULE_5__.SPEAKERS_AUDIO_LEVELS);
                    }
                    conference.statistics && conference.statistics.setSpeakerList(speakerList);
                }
            }
        }
    });
    rtc.addListener(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_9__["default"].DATA_CHANNEL_OPEN, () => {
        const now = window.performance.now();
        const key = 'data.channel.opened';
        // TODO: Move all of the 'connectionTimes' logic to its own module.
        logger.log(`(TIME) ${key}:\t`, now);
        conference.room.connectionTimes[key] = now;
        _modules_statistics_statistics__WEBPACK_IMPORTED_MODULE_6__["default"].sendAnalytics((0,_service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_12__.createConnectionStageReachedEvent)(key, { value: now }));
        conference.eventEmitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_3__.DATA_CHANNEL_OPENED);
    });
    rtc.addListener(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_9__["default"].DATA_CHANNEL_CLOSED, ev => {
        conference.eventEmitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_3__.DATA_CHANNEL_CLOSED, ev);
    });
    rtc.addListener(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_9__["default"].VIDEO_SSRCS_REMAPPED, msg => {
        for (const session of this.conference.getMediaSessions()) {
            session.processSourceMap(msg, _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_8__.MediaType.VIDEO);
        }
    });
    rtc.addListener(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_9__["default"].AUDIO_SSRCS_REMAPPED, msg => {
        for (const session of this.conference.getMediaSessions()) {
            session.processSourceMap(msg, _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_8__.MediaType.AUDIO);
        }
    });
    rtc.addListener(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_9__["default"].ENDPOINT_MESSAGE_RECEIVED, (from, payload) => {
        const participant = conference.getParticipantById(from);
        if (participant) {
            conference.eventEmitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_3__.ENDPOINT_MESSAGE_RECEIVED, participant, payload);
        }
        else {
            logger.warn('Ignored ENDPOINT_MESSAGE_RECEIVED for not existing '
                + `participant: ${from}`, payload);
        }
    });
    rtc.addListener(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_9__["default"].ENDPOINT_STATS_RECEIVED, (from, payload) => {
        const participant = conference.getParticipantById(from);
        if (participant) {
            conference.eventEmitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_3__.ENDPOINT_STATS_RECEIVED, participant, payload);
        }
        else {
            logger.warn(`Ignoring ENDPOINT_STATS_RECEIVED for a non-existant participant: ${from}`);
        }
    });
    rtc.addListener(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_9__["default"].LOCAL_UFRAG_CHANGED, (tpc, ufrag) => {
        if (!tpc.isP2P) {
            _modules_statistics_statistics__WEBPACK_IMPORTED_MODULE_6__["default"].sendLog(JSON.stringify({
                id: 'local_ufrag',
                value: ufrag
            }));
        }
    });
    rtc.addListener(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_9__["default"].REMOTE_UFRAG_CHANGED, (tpc, ufrag) => {
        if (!tpc.isP2P) {
            _modules_statistics_statistics__WEBPACK_IMPORTED_MODULE_6__["default"].sendLog(JSON.stringify({
                id: 'remote_ufrag',
                value: ufrag
            }));
        }
    });
    rtc.addListener(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_9__["default"].CREATE_ANSWER_FAILED, (e, tpc) => {
        conference.statistics.sendCreateAnswerFailed(e, tpc);
        if (!tpc.isP2P) {
            conference.eventEmitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_3__.CONFERENCE_FAILED, _JitsiConferenceErrors__WEBPACK_IMPORTED_MODULE_2__.OFFER_ANSWER_FAILED, e);
        }
    });
    rtc.addListener(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_9__["default"].CREATE_OFFER_FAILED, (e, tpc) => {
        conference.statistics.sendCreateOfferFailed(e, tpc);
        if (!tpc.isP2P) {
            conference.eventEmitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_3__.CONFERENCE_FAILED, _JitsiConferenceErrors__WEBPACK_IMPORTED_MODULE_2__.OFFER_ANSWER_FAILED, e);
        }
    });
    rtc.addListener(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_9__["default"].SET_LOCAL_DESCRIPTION_FAILED, (e, tpc) => {
        conference.statistics.sendSetLocalDescFailed(e, tpc);
        if (!tpc.isP2P) {
            conference.eventEmitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_3__.CONFERENCE_FAILED, _JitsiConferenceErrors__WEBPACK_IMPORTED_MODULE_2__.OFFER_ANSWER_FAILED, e);
        }
    });
    rtc.addListener(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_9__["default"].SET_REMOTE_DESCRIPTION_FAILED, (e, tpc) => {
        conference.statistics.sendSetRemoteDescFailed(e, tpc);
        if (!tpc.isP2P) {
            conference.eventEmitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_3__.CONFERENCE_FAILED, _JitsiConferenceErrors__WEBPACK_IMPORTED_MODULE_2__.OFFER_ANSWER_FAILED, e);
        }
    });
    rtc.addListener(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_9__["default"].LOCAL_TRACK_SSRC_UPDATED, (track, ssrc) => {
        // when starting screen sharing, the track is created and when
        // we do set local description and we process the ssrc we
        // will be notified for it and we will report it with the event
        // for screen sharing
        if (track.isVideoTrack() && track.videoType === _service_RTC_VideoType__WEBPACK_IMPORTED_MODULE_10__.VideoType.DESKTOP) {
            conference.statistics.sendScreenSharingEvent(true, ssrc);
        }
    });
};
/**
 * Removes event listeners related to conference.xmpp
 */
JitsiConferenceEventManager.prototype.removeXMPPListeners = function () {
    const conference = this.conference;
    Object.keys(this.xmppListeners).forEach(eventName => {
        conference.xmpp.removeListener(eventName, this.xmppListeners[eventName]);
    });
    this.xmppListeners = {};
};
/**
 * Setups event listeners related to conference.xmpp
 */
JitsiConferenceEventManager.prototype.setupXMPPListeners = function () {
    const conference = this.conference;
    this._addConferenceXMPPListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_13__.XMPPEvents.CALL_INCOMING, conference.onIncomingCall.bind(conference));
    this._addConferenceXMPPListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_13__.XMPPEvents.CALL_ACCEPTED, conference.onCallAccepted.bind(conference));
    this._addConferenceXMPPListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_13__.XMPPEvents.TRANSPORT_INFO, conference.onTransportInfo.bind(conference));
    this._addConferenceXMPPListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_13__.XMPPEvents.CALL_ENDED, conference.onCallEnded.bind(conference));
    this._addConferenceXMPPListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_13__.XMPPEvents.START_MUTED_FROM_FOCUS, (audioMuted, videoMuted) => {
        if (conference.options.config.ignoreStartMuted) {
            return;
        }
        conference.startAudioMuted = audioMuted;
        conference.startVideoMuted = videoMuted;
        if (audioMuted) {
            conference.isMutedByFocus = true;
        }
        if (videoMuted) {
            conference.isVideoMutedByFocus = true;
        }
        // mute existing local tracks because this is initial mute from
        // Jicofo
        conference.getLocalTracks().forEach(track => {
            switch (track.getType()) {
                case _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_8__.MediaType.AUDIO:
                    conference.startAudioMuted && track.mute();
                    break;
                case _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_8__.MediaType.VIDEO:
                    conference.startVideoMuted && track.mute();
                    break;
            }
        });
        conference.eventEmitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_3__.STARTED_MUTED);
    });
    this._addConferenceXMPPListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_13__.XMPPEvents.CONFERENCE_TIMESTAMP_RECEIVED, createdTimestamp => {
        conference.eventEmitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_3__.CONFERENCE_CREATED_TIMESTAMP, createdTimestamp);
    });
    this._addConferenceXMPPListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_13__.XMPPEvents.AV_MODERATION_CHANGED, (value, mediaType, actorJid) => {
        const actorParticipant = conference.getParticipants().find(p => p.getJid() === actorJid);
        conference.eventEmitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_3__.AV_MODERATION_CHANGED, {
            enabled: value,
            mediaType,
            actor: actorParticipant
        });
    });
    this._addConferenceXMPPListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_13__.XMPPEvents.AV_MODERATION_PARTICIPANT_APPROVED, (mediaType, jid) => {
        const participant = conference.getParticipantById(strophe_js__WEBPACK_IMPORTED_MODULE_1__.Strophe.getResourceFromJid(jid));
        if (participant) {
            conference.eventEmitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_3__.AV_MODERATION_PARTICIPANT_APPROVED, {
                participant,
                mediaType
            });
        }
    });
    this._addConferenceXMPPListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_13__.XMPPEvents.AV_MODERATION_PARTICIPANT_REJECTED, (mediaType, jid) => {
        const participant = conference.getParticipantById(strophe_js__WEBPACK_IMPORTED_MODULE_1__.Strophe.getResourceFromJid(jid));
        if (participant) {
            conference.eventEmitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_3__.AV_MODERATION_PARTICIPANT_REJECTED, {
                participant,
                mediaType
            });
        }
    });
    this._addConferenceXMPPListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_13__.XMPPEvents.AV_MODERATION_APPROVED, value => conference.eventEmitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_3__.AV_MODERATION_APPROVED, { mediaType: value }));
    this._addConferenceXMPPListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_13__.XMPPEvents.AV_MODERATION_REJECTED, value => {
        conference.eventEmitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_3__.AV_MODERATION_REJECTED, { mediaType: value });
    });
};
/**
 * Add XMPP listener and save its reference for remove on leave conference.
 */
JitsiConferenceEventManager.prototype._addConferenceXMPPListener = function (eventName, listener) {
    this.xmppListeners[eventName] = listener;
    this.conference.xmpp.addListener(eventName, listener);
};
/**
 * Setups event listeners related to conference.statistics
 */
JitsiConferenceEventManager.prototype.setupStatisticsListeners = function () {
    const conference = this.conference;
    if (!conference.statistics) {
        return;
    }
    /* eslint-disable max-params */
    conference.statistics.addAudioLevelListener((tpc, ssrc, level, isLocal) => {
        conference.rtc.setAudioLevel(tpc, ssrc, level, isLocal);
    });
    /* eslint-enable max-params */
    // Forward the "before stats disposed" event
    conference.statistics.addBeforeDisposedListener(() => {
        conference.eventEmitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_3__.BEFORE_STATISTICS_DISPOSED);
    });
    // if we are in startSilent mode we will not be sending/receiving so nothing to detect
    if (!conference.options.config.startSilent) {
        conference.statistics.addByteSentStatsListener((tpc, stats) => {
            conference.getLocalTracks(_service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_8__.MediaType.AUDIO).forEach(track => {
                const ssrc = tpc.getLocalSSRC(track);
                if (!ssrc || !stats.hasOwnProperty(ssrc)) {
                    return;
                }
                track.onByteSentStatsReceived(tpc, stats[ssrc]);
            });
        });
    }
};
//# sourceMappingURL=JitsiConferenceEventManager.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/JitsiConferenceEvents.js":
/*!******************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/JitsiConferenceEvents.js ***!
  \******************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   AUDIO_INPUT_STATE_CHANGE: () => (/* binding */ AUDIO_INPUT_STATE_CHANGE),
/* harmony export */   AUDIO_UNMUTE_PERMISSIONS_CHANGED: () => (/* binding */ AUDIO_UNMUTE_PERMISSIONS_CHANGED),
/* harmony export */   AUTH_STATUS_CHANGED: () => (/* binding */ AUTH_STATUS_CHANGED),
/* harmony export */   AV_MODERATION_APPROVED: () => (/* binding */ AV_MODERATION_APPROVED),
/* harmony export */   AV_MODERATION_CHANGED: () => (/* binding */ AV_MODERATION_CHANGED),
/* harmony export */   AV_MODERATION_PARTICIPANT_APPROVED: () => (/* binding */ AV_MODERATION_PARTICIPANT_APPROVED),
/* harmony export */   AV_MODERATION_PARTICIPANT_REJECTED: () => (/* binding */ AV_MODERATION_PARTICIPANT_REJECTED),
/* harmony export */   AV_MODERATION_REJECTED: () => (/* binding */ AV_MODERATION_REJECTED),
/* harmony export */   BEFORE_STATISTICS_DISPOSED: () => (/* binding */ BEFORE_STATISTICS_DISPOSED),
/* harmony export */   BOT_TYPE_CHANGED: () => (/* binding */ BOT_TYPE_CHANGED),
/* harmony export */   BREAKOUT_ROOMS_MOVE_TO_ROOM: () => (/* binding */ BREAKOUT_ROOMS_MOVE_TO_ROOM),
/* harmony export */   BREAKOUT_ROOMS_UPDATED: () => (/* binding */ BREAKOUT_ROOMS_UPDATED),
/* harmony export */   CONFERENCE_CREATED_TIMESTAMP: () => (/* binding */ CONFERENCE_CREATED_TIMESTAMP),
/* harmony export */   CONFERENCE_ERROR: () => (/* binding */ CONFERENCE_ERROR),
/* harmony export */   CONFERENCE_FAILED: () => (/* binding */ CONFERENCE_FAILED),
/* harmony export */   CONFERENCE_JOINED: () => (/* binding */ CONFERENCE_JOINED),
/* harmony export */   CONFERENCE_JOIN_IN_PROGRESS: () => (/* binding */ CONFERENCE_JOIN_IN_PROGRESS),
/* harmony export */   CONFERENCE_LEFT: () => (/* binding */ CONFERENCE_LEFT),
/* harmony export */   CONFERENCE_UNIQUE_ID_SET: () => (/* binding */ CONFERENCE_UNIQUE_ID_SET),
/* harmony export */   CONNECTION_ESTABLISHED: () => (/* binding */ CONNECTION_ESTABLISHED),
/* harmony export */   CONNECTION_INTERRUPTED: () => (/* binding */ CONNECTION_INTERRUPTED),
/* harmony export */   CONNECTION_RESTORED: () => (/* binding */ CONNECTION_RESTORED),
/* harmony export */   DATA_CHANNEL_CLOSED: () => (/* binding */ DATA_CHANNEL_CLOSED),
/* harmony export */   DATA_CHANNEL_OPENED: () => (/* binding */ DATA_CHANNEL_OPENED),
/* harmony export */   DISPLAY_NAME_CHANGED: () => (/* binding */ DISPLAY_NAME_CHANGED),
/* harmony export */   DOMINANT_SPEAKER_CHANGED: () => (/* binding */ DOMINANT_SPEAKER_CHANGED),
/* harmony export */   DTMF_SUPPORT_CHANGED: () => (/* binding */ DTMF_SUPPORT_CHANGED),
/* harmony export */   E2EE_VERIFICATION_AVAILABLE: () => (/* binding */ E2EE_VERIFICATION_AVAILABLE),
/* harmony export */   E2EE_VERIFICATION_COMPLETED: () => (/* binding */ E2EE_VERIFICATION_COMPLETED),
/* harmony export */   E2EE_VERIFICATION_READY: () => (/* binding */ E2EE_VERIFICATION_READY),
/* harmony export */   ENDPOINT_MESSAGE_RECEIVED: () => (/* binding */ ENDPOINT_MESSAGE_RECEIVED),
/* harmony export */   ENDPOINT_STATS_RECEIVED: () => (/* binding */ ENDPOINT_STATS_RECEIVED),
/* harmony export */   FORWARDED_SOURCES_CHANGED: () => (/* binding */ FORWARDED_SOURCES_CHANGED),
/* harmony export */   JVB121_STATUS: () => (/* binding */ JVB121_STATUS),
/* harmony export */   JitsiConferenceEvents: () => (/* binding */ JitsiConferenceEvents),
/* harmony export */   KICKED: () => (/* binding */ KICKED),
/* harmony export */   LAST_N_ENDPOINTS_CHANGED: () => (/* binding */ LAST_N_ENDPOINTS_CHANGED),
/* harmony export */   LOBBY_USER_JOINED: () => (/* binding */ LOBBY_USER_JOINED),
/* harmony export */   LOBBY_USER_LEFT: () => (/* binding */ LOBBY_USER_LEFT),
/* harmony export */   LOBBY_USER_UPDATED: () => (/* binding */ LOBBY_USER_UPDATED),
/* harmony export */   LOCK_STATE_CHANGED: () => (/* binding */ LOCK_STATE_CHANGED),
/* harmony export */   MEMBERS_ONLY_CHANGED: () => (/* binding */ MEMBERS_ONLY_CHANGED),
/* harmony export */   MESSAGE_RECEIVED: () => (/* binding */ MESSAGE_RECEIVED),
/* harmony export */   METADATA_UPDATED: () => (/* binding */ METADATA_UPDATED),
/* harmony export */   NOISY_MIC: () => (/* binding */ NOISY_MIC),
/* harmony export */   NON_PARTICIPANT_MESSAGE_RECEIVED: () => (/* binding */ NON_PARTICIPANT_MESSAGE_RECEIVED),
/* harmony export */   NO_AUDIO_INPUT: () => (/* binding */ NO_AUDIO_INPUT),
/* harmony export */   P2P_STATUS: () => (/* binding */ P2P_STATUS),
/* harmony export */   PARTCIPANT_FEATURES_CHANGED: () => (/* binding */ PARTCIPANT_FEATURES_CHANGED),
/* harmony export */   PARTICIPANT_KICKED: () => (/* binding */ PARTICIPANT_KICKED),
/* harmony export */   PARTICIPANT_PROPERTY_CHANGED: () => (/* binding */ PARTICIPANT_PROPERTY_CHANGED),
/* harmony export */   PARTICIPANT_SOURCE_UPDATED: () => (/* binding */ PARTICIPANT_SOURCE_UPDATED),
/* harmony export */   PHONE_NUMBER_CHANGED: () => (/* binding */ PHONE_NUMBER_CHANGED),
/* harmony export */   PRIVATE_MESSAGE_RECEIVED: () => (/* binding */ PRIVATE_MESSAGE_RECEIVED),
/* harmony export */   PROPERTIES_CHANGED: () => (/* binding */ PROPERTIES_CHANGED),
/* harmony export */   RECORDER_STATE_CHANGED: () => (/* binding */ RECORDER_STATE_CHANGED),
/* harmony export */   SERVER_REGION_CHANGED: () => (/* binding */ SERVER_REGION_CHANGED),
/* harmony export */   STARTED_MUTED: () => (/* binding */ STARTED_MUTED),
/* harmony export */   START_MUTED_POLICY_CHANGED: () => (/* binding */ START_MUTED_POLICY_CHANGED),
/* harmony export */   SUBJECT_CHANGED: () => (/* binding */ SUBJECT_CHANGED),
/* harmony export */   SUSPEND_DETECTED: () => (/* binding */ SUSPEND_DETECTED),
/* harmony export */   TALK_WHILE_MUTED: () => (/* binding */ TALK_WHILE_MUTED),
/* harmony export */   TRACK_ADDED: () => (/* binding */ TRACK_ADDED),
/* harmony export */   TRACK_AUDIO_LEVEL_CHANGED: () => (/* binding */ TRACK_AUDIO_LEVEL_CHANGED),
/* harmony export */   TRACK_MUTE_CHANGED: () => (/* binding */ TRACK_MUTE_CHANGED),
/* harmony export */   TRACK_REMOVED: () => (/* binding */ TRACK_REMOVED),
/* harmony export */   TRACK_UNMUTE_REJECTED: () => (/* binding */ TRACK_UNMUTE_REJECTED),
/* harmony export */   TRANSCRIPTION_STATUS_CHANGED: () => (/* binding */ TRANSCRIPTION_STATUS_CHANGED),
/* harmony export */   USER_JOINED: () => (/* binding */ USER_JOINED),
/* harmony export */   USER_LEFT: () => (/* binding */ USER_LEFT),
/* harmony export */   USER_ROLE_CHANGED: () => (/* binding */ USER_ROLE_CHANGED),
/* harmony export */   USER_STATUS_CHANGED: () => (/* binding */ USER_STATUS_CHANGED),
/* harmony export */   VIDEO_SIP_GW_AVAILABILITY_CHANGED: () => (/* binding */ VIDEO_SIP_GW_AVAILABILITY_CHANGED),
/* harmony export */   VIDEO_SIP_GW_SESSION_STATE_CHANGED: () => (/* binding */ VIDEO_SIP_GW_SESSION_STATE_CHANGED),
/* harmony export */   VIDEO_UNMUTE_PERMISSIONS_CHANGED: () => (/* binding */ VIDEO_UNMUTE_PERMISSIONS_CHANGED),
/* harmony export */   _MEDIA_SESSION_ACTIVE_CHANGED: () => (/* binding */ _MEDIA_SESSION_ACTIVE_CHANGED),
/* harmony export */   _MEDIA_SESSION_STARTED: () => (/* binding */ _MEDIA_SESSION_STARTED)
/* harmony export */ });
/**
 * The events for the conference.
 */
var JitsiConferenceEvents;
(function (JitsiConferenceEvents) {
    /**
     * Event indicates that the current conference audio input switched between audio
     * input states,i.e. with or without audio input.
     */
    JitsiConferenceEvents["AUDIO_INPUT_STATE_CHANGE"] = "conference.audio_input_state_changed";
    /**
     * Event indicates that the permission for unmuting audio has changed based on the number of audio senders in the call
     * and the audio sender limit configured in Jicofo.
     */
    JitsiConferenceEvents["AUDIO_UNMUTE_PERMISSIONS_CHANGED"] = "conference.audio_unmute_permissions_changed";
    /**
     * Indicates that authentication status changed.
     */
    JitsiConferenceEvents["AUTH_STATUS_CHANGED"] = "conference.auth_status_changed";
    /**
     * Fired just before the statistics module is disposed and it's the last chance
     * to submit some logs to the statistics service (ex. CallStats if enabled),
     * before it's disconnected.
     */
    JitsiConferenceEvents["BEFORE_STATISTICS_DISPOSED"] = "conference.beforeStatisticsDisposed";
    /**
     * Indicates that an error occurred.
     */
    JitsiConferenceEvents["CONFERENCE_ERROR"] = "conference.error";
    /**
     * Indicates that conference failed.
     */
    JitsiConferenceEvents["CONFERENCE_FAILED"] = "conference.failed";
    /**
     * Indicates that conference is in progress of joining.
     */
    JitsiConferenceEvents["CONFERENCE_JOIN_IN_PROGRESS"] = "conference.join_in_progress";
    /**
     * Indicates that conference has been joined. The event does NOT provide any
     * parameters to its listeners.
     */
    JitsiConferenceEvents["CONFERENCE_JOINED"] = "conference.joined";
    /**
     * Indicates that conference has been left.
     */
    JitsiConferenceEvents["CONFERENCE_LEFT"] = "conference.left";
    /**
     * Indicates that the conference unique identifier has been set.
     */
    JitsiConferenceEvents["CONFERENCE_UNIQUE_ID_SET"] = "conference.unique_id_set";
    /**
     * Indicates that the connection to the conference has been established
     * XXX This is currently fired when the *ICE* connection enters 'connected'
     * state for the first time.
     */
    JitsiConferenceEvents["CONNECTION_ESTABLISHED"] = "conference.connectionEstablished";
    /**
     * Indicates that the connection to the conference has been interrupted for some
     * reason.
     * XXX This is currently fired when the *ICE* connection is interrupted.
     */
    JitsiConferenceEvents["CONNECTION_INTERRUPTED"] = "conference.connectionInterrupted";
    /**
     * Indicates that the connection to the conference has been restored.
     * XXX This is currently fired when the *ICE* connection is restored.
     */
    JitsiConferenceEvents["CONNECTION_RESTORED"] = "conference.connectionRestored";
    /**
     * A connection to the video bridge's data channel has been established.
     */
    JitsiConferenceEvents["DATA_CHANNEL_OPENED"] = "conference.dataChannelOpened";
    /**
     * A connection to the video bridge's data channel has been closed.
     * This event is only emitted in
     */
    JitsiConferenceEvents["DATA_CHANNEL_CLOSED"] = "conference.dataChannelClosed";
    /**
     * A user has changed it display name
     */
    JitsiConferenceEvents["DISPLAY_NAME_CHANGED"] = "conference.displayNameChanged";
    /**
     * The dominant speaker was changed.
     */
    JitsiConferenceEvents["DOMINANT_SPEAKER_CHANGED"] = "conference.dominantSpeaker";
    /**
     * UTC conference timestamp when first participant joined.
     */
    JitsiConferenceEvents["CONFERENCE_CREATED_TIMESTAMP"] = "conference.createdTimestamp";
    /**
     * Indicates that DTMF support changed.
     */
    JitsiConferenceEvents["DTMF_SUPPORT_CHANGED"] = "conference.dtmfSupportChanged";
    /**
     * Indicates that a message from another participant is received on data
     * channel.
     */
    JitsiConferenceEvents["ENDPOINT_MESSAGE_RECEIVED"] = "conference.endpoint_message_received";
    /**
     * Indicates that a message for the remote endpoint statistics has been received on the bridge channel.
     */
    JitsiConferenceEvents["ENDPOINT_STATS_RECEIVED"] = "conference.endpoint_stats_received";
    /**
     * NOTE This is lib-jitsi-meet internal event and can be removed at any time !
     *
     * Event emitted when conference transits, between one to one and multiparty JVB
     * conference. If the conference switches to P2P it's neither one to one nor
     * a multiparty JVB conference, but P2P (the status argument of this event will
     * be <tt>false</tt>).
     *
     * The first argument is a boolean which carries the previous value and
     * the seconds argument is a boolean with the new status. The event is emitted
     * only if the previous and the new values are different.
     *
     * @type {string}
     */
    JitsiConferenceEvents["JVB121_STATUS"] = "conference.jvb121Status";
    /**
     * You are kicked from the conference.
     * @param {JitsiParticipant} the participant that initiated the kick.
     */
    JitsiConferenceEvents["KICKED"] = "conference.kicked";
    /**
     * Participant was kicked from the conference.
     * @param {JitsiParticipant} the participant that initiated the kick.
     * @param {JitsiParticipant} the participant that was kicked.
     */
    JitsiConferenceEvents["PARTICIPANT_KICKED"] = "conference.participant_kicked";
    /**
     * The Last N set is changed.
     *
     * @param {Array<string>|null} leavingEndpointIds the ids of all the endpoints
     * which are leaving Last N
     * @param {Array<string>|null} enteringEndpointIds the ids of all the endpoints
     * which are entering Last N
     */
    JitsiConferenceEvents["LAST_N_ENDPOINTS_CHANGED"] = "conference.lastNEndpointsChanged";
    /**
     * The forwarded sources set is changed.
     *
     * @param {Array<string>} leavingForwardedSources the sourceNames of all the tracks which are leaving forwarded
     * sources
     * @param {Array<string>} enteringForwardedSources the sourceNames of all the tracks which are entering forwarded
     * sources
     */
    JitsiConferenceEvents["FORWARDED_SOURCES_CHANGED"] = "conference.forwardedSourcesChanged";
    /**
     * Indicates that the room has been locked or unlocked.
     */
    JitsiConferenceEvents["LOCK_STATE_CHANGED"] = "conference.lock_state_changed";
    /**
     * Indicates that the region of the media server (jitsi-videobridge) that we
     * are connected to changed (or was initially set).
     * @type {string} the region.
     */
    JitsiConferenceEvents["SERVER_REGION_CHANGED"] = "conference.server_region_changed";
    /**
     * An event(library-private) fired when a new media session is added to the conference.
     * @type {string}
     * @private
     */
    JitsiConferenceEvents["_MEDIA_SESSION_STARTED"] = "conference.media_session.started";
    /**
     * An event(library-private) fired when the conference switches the currently active media session.
     * @type {string}
     * @private
     */
    JitsiConferenceEvents["_MEDIA_SESSION_ACTIVE_CHANGED"] = "conference.media_session.active_changed";
    /**
     * Indicates that the conference had changed to members only enabled/disabled.
     * The first argument of this event is a <tt>boolean</tt> which when set to
     * <tt>true</tt> means that the conference is running in members only mode.
     * You may need to use Lobby if supported to ask for permissions to enter the conference.
     */
    JitsiConferenceEvents["MEMBERS_ONLY_CHANGED"] = "conference.membersOnlyChanged";
    /**
     * New text message was received.
     */
    JitsiConferenceEvents["MESSAGE_RECEIVED"] = "conference.messageReceived";
    /**
     * Event indicates that the current selected input device has no signal
     */
    JitsiConferenceEvents["NO_AUDIO_INPUT"] = "conference.no_audio_input";
    /**
     * Event indicates that the current microphone used by the conference is noisy.
     */
    JitsiConferenceEvents["NOISY_MIC"] = "conference.noisy_mic";
    /**
     * Indicates that a message from the local user or from the Prosody backend
     * was received on the data channel.
     */
    JitsiConferenceEvents["NON_PARTICIPANT_MESSAGE_RECEIVED"] = "conference.non_participant_message_received";
    /**
     * New private text message was received.
     */
    JitsiConferenceEvents["PRIVATE_MESSAGE_RECEIVED"] = "conference.privateMessageReceived";
    /**
     * Indicates that the features of the participant has been changed.
     * TODO: there is a spelling mistake in this event name and associated constants
     */
    JitsiConferenceEvents["PARTCIPANT_FEATURES_CHANGED"] = "conference.partcipant_features_changed";
    /**
     * Indicates that a the value of a specific property of a specific participant
     * has changed.
     */
    JitsiConferenceEvents["PARTICIPANT_PROPERTY_CHANGED"] = "conference.participant_property_changed";
    /**
     * Indicates the state of sources attached to a given remote participant has changed.
     */
    JitsiConferenceEvents["PARTICIPANT_SOURCE_UPDATED"] = "conference.participant_source_updated";
    /**
     * Indicates that the conference has switched between JVB and P2P connections.
     * The first argument of this event is a <tt>boolean</tt> which when set to
     * <tt>true</tt> means that the conference is running on the P2P connection.
     */
    JitsiConferenceEvents["P2P_STATUS"] = "conference.p2pStatus";
    /**
     * Indicates that phone number changed.
     */
    JitsiConferenceEvents["PHONE_NUMBER_CHANGED"] = "conference.phoneNumberChanged";
    /**
     * The conference properties changed.
     * @type {string}
     */
    JitsiConferenceEvents["PROPERTIES_CHANGED"] = "conference.propertiesChanged";
    /**
     * Indicates that recording state changed.
     */
    JitsiConferenceEvents["RECORDER_STATE_CHANGED"] = "conference.recorderStateChanged";
    /**
     * Indicates that video SIP GW state changed.
     * @param {VideoSIPGWConstants} status.
     */
    JitsiConferenceEvents["VIDEO_SIP_GW_AVAILABILITY_CHANGED"] = "conference.videoSIPGWAvailabilityChanged";
    /**
     * Indicates that video SIP GW Session state changed.
     * @param {options} event - {
     *     {string} address,
     *     {VideoSIPGWConstants} oldState,
     *     {VideoSIPGWConstants} newState,
     *     {string} displayName}
     * }.
     */
    JitsiConferenceEvents["VIDEO_SIP_GW_SESSION_STATE_CHANGED"] = "conference.videoSIPGWSessionStateChanged";
    /**
     * Indicates that start muted settings changed.
     */
    JitsiConferenceEvents["START_MUTED_POLICY_CHANGED"] = "conference.start_muted_policy_changed";
    /**
     * Indicates that the local user has started muted.
     */
    JitsiConferenceEvents["STARTED_MUTED"] = "conference.started_muted";
    /**
     * Indicates that subject of the conference has changed.
     */
    JitsiConferenceEvents["SUBJECT_CHANGED"] = "conference.subjectChanged";
    /**
     * Indicates that DTMF support changed.
     */
    JitsiConferenceEvents["SUSPEND_DETECTED"] = "conference.suspendDetected";
    /**
     * Event indicates that local user is talking while he muted himself
     */
    JitsiConferenceEvents["TALK_WHILE_MUTED"] = "conference.talk_while_muted";
    /**
     * A new media track was added to the conference. The event provides the
     * following parameters to its listeners:
     *
     * @param {JitsiTrack} track the added JitsiTrack
     */
    JitsiConferenceEvents["TRACK_ADDED"] = "conference.trackAdded";
    /**
     * Audio levels of a media track ( attached to the conference) was changed.
     */
    JitsiConferenceEvents["TRACK_AUDIO_LEVEL_CHANGED"] = "conference.audioLevelsChanged";
    /**
     * A media track ( attached to the conference) mute status was changed.
     * @param {JitsiParticipant|null} the participant that initiated the mute
     * if it is a remote mute.
     */
    JitsiConferenceEvents["TRACK_MUTE_CHANGED"] = "conference.trackMuteChanged";
    /**
     * The media track was removed from the conference. The event provides the
     * following parameters to its listeners:
     *
     * @param {JitsiTrack} track the removed JitsiTrack
     */
    JitsiConferenceEvents["TRACK_REMOVED"] = "conference.trackRemoved";
    /**
     * The source-add for unmuting of a media track was rejected by Jicofo.
     *
     */
    JitsiConferenceEvents["TRACK_UNMUTE_REJECTED"] = "conference.trackUnmuteRejected";
    /**
     * Notifies for transcription status changes. The event provides the
     * following parameters to its listeners:
     *
     * @param {String} status - The new status.
     */
    JitsiConferenceEvents["TRANSCRIPTION_STATUS_CHANGED"] = "conference.transcriptionStatusChanged";
    /**
     * A new user joined the conference.
     */
    JitsiConferenceEvents["USER_JOINED"] = "conference.userJoined";
    /**
     * A user has left the conference.
     */
    JitsiConferenceEvents["USER_LEFT"] = "conference.userLeft";
    /**
     * User role changed.
     */
    JitsiConferenceEvents["USER_ROLE_CHANGED"] = "conference.roleChanged";
    /**
     * User status changed.
     */
    JitsiConferenceEvents["USER_STATUS_CHANGED"] = "conference.statusChanged";
    /**
     * Event indicates that the permission for unmuting video has changed based on the number of video senders in the call
     * and the video sender limit configured in Jicofo.
     */
    JitsiConferenceEvents["VIDEO_UNMUTE_PERMISSIONS_CHANGED"] = "conference.video_unmute_permissions_changed";
    /**
     * Event indicates that the bot participant type changed.
     */
    JitsiConferenceEvents["BOT_TYPE_CHANGED"] = "conference.bot_type_changed";
    /**
     * A new user joined the lobby room.
     */
    JitsiConferenceEvents["LOBBY_USER_JOINED"] = "conference.lobby.userJoined";
    /**
     * A user from the lobby room has been update.
     */
    JitsiConferenceEvents["LOBBY_USER_UPDATED"] = "conference.lobby.userUpdated";
    /**
     * A user left the lobby room.
     */
    JitsiConferenceEvents["LOBBY_USER_LEFT"] = "conference.lobby.userLeft";
    /**
     * The local participant was approved to be able to unmute.
     * @param {options} event - {
     *     {MediaType} mediaType
     * }.
     */
    JitsiConferenceEvents["AV_MODERATION_APPROVED"] = "conference.av_moderation.approved";
    /**
     * The local participant was blocked to be able to unmute.
     * @param {options} event - {
     *     {MediaType} mediaType
     * }.
     */
    JitsiConferenceEvents["AV_MODERATION_REJECTED"] = "conference.av_moderation.rejected";
    /**
     * AV Moderation was enabled/disabled. The actor is the participant that is currently in the meeting,
     * or undefined if that participant has left the meeting.
     *
     * @param {options} event - {
     *     {boolean} enabled,
     *     {MediaType} mediaType,
     *     {JitsiParticipant} actor
     * }.
     */
    JitsiConferenceEvents["AV_MODERATION_CHANGED"] = "conference.av_moderation.changed";
    /**
     * AV Moderation, report for user being approved to unmute.
     * @param {options} event - {
     *     {JitsiParticipant} participant,
     *     {MediaType} mediaType
     * }.
     */
    JitsiConferenceEvents["AV_MODERATION_PARTICIPANT_APPROVED"] = "conference.av_moderation.participant.approved";
    /**
     * AV Moderation, report for user being blocked to unmute.
     * @param {options} event - {
     *     {JitsiParticipant} participant,
     *     {MediaType} mediaType
     * }.
     */
    JitsiConferenceEvents["AV_MODERATION_PARTICIPANT_REJECTED"] = "conference.av_moderation.participant.rejected";
    /**
     * Event fired when a participant is requested to join a given (breakout) room.
     */
    JitsiConferenceEvents["BREAKOUT_ROOMS_MOVE_TO_ROOM"] = "conference.breakout-rooms.move-to-room";
    /**
     * Event fired when the breakout rooms data was updated.
     */
    JitsiConferenceEvents["BREAKOUT_ROOMS_UPDATED"] = "conference.breakout-rooms.updated";
    /**
     * Event fired when the conference metadata is updated.
     */
    JitsiConferenceEvents["METADATA_UPDATED"] = "conference.metadata.updated";
    JitsiConferenceEvents["E2EE_VERIFICATION_AVAILABLE"] = "conference.e2ee.verification.available";
    JitsiConferenceEvents["E2EE_VERIFICATION_READY"] = "conference.e2ee.verification.ready";
    JitsiConferenceEvents["E2EE_VERIFICATION_COMPLETED"] = "conference.e2ee.verification.completed";
})(JitsiConferenceEvents || (JitsiConferenceEvents = {}));
;
// exported for backward compatibility
const AUDIO_INPUT_STATE_CHANGE = JitsiConferenceEvents.AUDIO_INPUT_STATE_CHANGE;
const AUDIO_UNMUTE_PERMISSIONS_CHANGED = JitsiConferenceEvents.AUDIO_UNMUTE_PERMISSIONS_CHANGED;
const AUTH_STATUS_CHANGED = JitsiConferenceEvents.AUTH_STATUS_CHANGED;
const BEFORE_STATISTICS_DISPOSED = JitsiConferenceEvents.BEFORE_STATISTICS_DISPOSED;
const CONFERENCE_ERROR = JitsiConferenceEvents.CONFERENCE_ERROR;
const CONFERENCE_FAILED = JitsiConferenceEvents.CONFERENCE_FAILED;
const CONFERENCE_JOIN_IN_PROGRESS = JitsiConferenceEvents.CONFERENCE_JOIN_IN_PROGRESS;
const CONFERENCE_JOINED = JitsiConferenceEvents.CONFERENCE_JOINED;
const CONFERENCE_LEFT = JitsiConferenceEvents.CONFERENCE_LEFT;
const CONFERENCE_UNIQUE_ID_SET = JitsiConferenceEvents.CONFERENCE_UNIQUE_ID_SET;
const CONNECTION_ESTABLISHED = JitsiConferenceEvents.CONNECTION_ESTABLISHED;
const CONNECTION_INTERRUPTED = JitsiConferenceEvents.CONNECTION_INTERRUPTED;
const CONNECTION_RESTORED = JitsiConferenceEvents.CONNECTION_RESTORED;
const DATA_CHANNEL_OPENED = JitsiConferenceEvents.DATA_CHANNEL_OPENED;
const DATA_CHANNEL_CLOSED = JitsiConferenceEvents.DATA_CHANNEL_CLOSED;
const DISPLAY_NAME_CHANGED = JitsiConferenceEvents.DISPLAY_NAME_CHANGED;
const DOMINANT_SPEAKER_CHANGED = JitsiConferenceEvents.DOMINANT_SPEAKER_CHANGED;
const CONFERENCE_CREATED_TIMESTAMP = JitsiConferenceEvents.CONFERENCE_CREATED_TIMESTAMP;
const DTMF_SUPPORT_CHANGED = JitsiConferenceEvents.DTMF_SUPPORT_CHANGED;
const ENDPOINT_MESSAGE_RECEIVED = JitsiConferenceEvents.ENDPOINT_MESSAGE_RECEIVED;
const ENDPOINT_STATS_RECEIVED = JitsiConferenceEvents.ENDPOINT_STATS_RECEIVED;
const E2EE_VERIFICATION_AVAILABLE = JitsiConferenceEvents.E2EE_VERIFICATION_AVAILABLE;
const E2EE_VERIFICATION_READY = JitsiConferenceEvents.E2EE_VERIFICATION_READY;
const E2EE_VERIFICATION_COMPLETED = JitsiConferenceEvents.E2EE_VERIFICATION_COMPLETED;
const JVB121_STATUS = JitsiConferenceEvents.JVB121_STATUS;
const KICKED = JitsiConferenceEvents.KICKED;
const PARTICIPANT_KICKED = JitsiConferenceEvents.PARTICIPANT_KICKED;
const PARTICIPANT_SOURCE_UPDATED = JitsiConferenceEvents.PARTICIPANT_SOURCE_UPDATED;
const LAST_N_ENDPOINTS_CHANGED = JitsiConferenceEvents.LAST_N_ENDPOINTS_CHANGED;
const FORWARDED_SOURCES_CHANGED = JitsiConferenceEvents.FORWARDED_SOURCES_CHANGED;
const LOCK_STATE_CHANGED = JitsiConferenceEvents.LOCK_STATE_CHANGED;
const SERVER_REGION_CHANGED = JitsiConferenceEvents.SERVER_REGION_CHANGED;
const _MEDIA_SESSION_STARTED = JitsiConferenceEvents._MEDIA_SESSION_STARTED;
const _MEDIA_SESSION_ACTIVE_CHANGED = JitsiConferenceEvents._MEDIA_SESSION_ACTIVE_CHANGED;
const MEMBERS_ONLY_CHANGED = JitsiConferenceEvents.MEMBERS_ONLY_CHANGED;
const MESSAGE_RECEIVED = JitsiConferenceEvents.MESSAGE_RECEIVED;
const NO_AUDIO_INPUT = JitsiConferenceEvents.NO_AUDIO_INPUT;
const NOISY_MIC = JitsiConferenceEvents.NOISY_MIC;
const NON_PARTICIPANT_MESSAGE_RECEIVED = JitsiConferenceEvents.NON_PARTICIPANT_MESSAGE_RECEIVED;
const PRIVATE_MESSAGE_RECEIVED = JitsiConferenceEvents.PRIVATE_MESSAGE_RECEIVED;
const PARTCIPANT_FEATURES_CHANGED = JitsiConferenceEvents.PARTCIPANT_FEATURES_CHANGED;
const PARTICIPANT_PROPERTY_CHANGED = JitsiConferenceEvents.PARTICIPANT_PROPERTY_CHANGED;
const P2P_STATUS = JitsiConferenceEvents.P2P_STATUS;
const PHONE_NUMBER_CHANGED = JitsiConferenceEvents.PHONE_NUMBER_CHANGED;
const PROPERTIES_CHANGED = JitsiConferenceEvents.PROPERTIES_CHANGED;
const RECORDER_STATE_CHANGED = JitsiConferenceEvents.RECORDER_STATE_CHANGED;
const VIDEO_SIP_GW_AVAILABILITY_CHANGED = JitsiConferenceEvents.VIDEO_SIP_GW_AVAILABILITY_CHANGED;
const VIDEO_SIP_GW_SESSION_STATE_CHANGED = JitsiConferenceEvents.VIDEO_SIP_GW_SESSION_STATE_CHANGED;
const START_MUTED_POLICY_CHANGED = JitsiConferenceEvents.START_MUTED_POLICY_CHANGED;
const STARTED_MUTED = JitsiConferenceEvents.STARTED_MUTED;
const SUBJECT_CHANGED = JitsiConferenceEvents.SUBJECT_CHANGED;
const SUSPEND_DETECTED = JitsiConferenceEvents.SUSPEND_DETECTED;
const TALK_WHILE_MUTED = JitsiConferenceEvents.TALK_WHILE_MUTED;
const TRACK_ADDED = JitsiConferenceEvents.TRACK_ADDED;
const TRACK_AUDIO_LEVEL_CHANGED = JitsiConferenceEvents.TRACK_AUDIO_LEVEL_CHANGED;
const TRACK_MUTE_CHANGED = JitsiConferenceEvents.TRACK_MUTE_CHANGED;
const TRACK_REMOVED = JitsiConferenceEvents.TRACK_REMOVED;
const TRACK_UNMUTE_REJECTED = JitsiConferenceEvents.TRACK_UNMUTE_REJECTED;
const TRANSCRIPTION_STATUS_CHANGED = JitsiConferenceEvents.TRANSCRIPTION_STATUS_CHANGED;
const USER_JOINED = JitsiConferenceEvents.USER_JOINED;
const USER_LEFT = JitsiConferenceEvents.USER_LEFT;
const USER_ROLE_CHANGED = JitsiConferenceEvents.USER_ROLE_CHANGED;
const USER_STATUS_CHANGED = JitsiConferenceEvents.USER_STATUS_CHANGED;
const VIDEO_UNMUTE_PERMISSIONS_CHANGED = JitsiConferenceEvents.VIDEO_UNMUTE_PERMISSIONS_CHANGED;
const BOT_TYPE_CHANGED = JitsiConferenceEvents.BOT_TYPE_CHANGED;
const LOBBY_USER_JOINED = JitsiConferenceEvents.LOBBY_USER_JOINED;
const LOBBY_USER_UPDATED = JitsiConferenceEvents.LOBBY_USER_UPDATED;
const LOBBY_USER_LEFT = JitsiConferenceEvents.LOBBY_USER_LEFT;
const AV_MODERATION_APPROVED = JitsiConferenceEvents.AV_MODERATION_APPROVED;
const AV_MODERATION_REJECTED = JitsiConferenceEvents.AV_MODERATION_REJECTED;
const AV_MODERATION_CHANGED = JitsiConferenceEvents.AV_MODERATION_CHANGED;
const AV_MODERATION_PARTICIPANT_APPROVED = JitsiConferenceEvents.AV_MODERATION_PARTICIPANT_APPROVED;
const AV_MODERATION_PARTICIPANT_REJECTED = JitsiConferenceEvents.AV_MODERATION_PARTICIPANT_REJECTED;
const BREAKOUT_ROOMS_MOVE_TO_ROOM = JitsiConferenceEvents.BREAKOUT_ROOMS_MOVE_TO_ROOM;
const BREAKOUT_ROOMS_UPDATED = JitsiConferenceEvents.BREAKOUT_ROOMS_UPDATED;
const METADATA_UPDATED = JitsiConferenceEvents.METADATA_UPDATED;
//# sourceMappingURL=JitsiConferenceEvents.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/JitsiConnection.js":
/*!************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/JitsiConnection.js ***!
  \************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (/* binding */ JitsiConnection)
/* harmony export */ });
/* harmony import */ var _JitsiConference__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./JitsiConference */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/JitsiConference.js");
/* harmony import */ var _JitsiConnectionEvents__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./JitsiConnectionEvents */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/JitsiConnectionEvents.js");
/* harmony import */ var _modules_statistics_statistics__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./modules/statistics/statistics */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/statistics/statistics.js");
/* harmony import */ var _modules_xmpp_xmpp__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./modules/xmpp/xmpp */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/xmpp/xmpp.js");
/* harmony import */ var _service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./service/statistics/AnalyticsEvents */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/statistics/AnalyticsEvents.js");





/**
 * Creates a new connection object for the Jitsi Meet server side video
 * conferencing service. Provides access to the JitsiConference interface.
 * @param appID identification for the provider of Jitsi Meet video conferencing
 * services.
 * @param token the JWT token used to authenticate with the server(optional)
 * @param options Object with properties / settings related to connection with
 * the server.
 * @constructor
 */
function JitsiConnection(appID, token, options) {
    this.appID = appID;
    this.token = token;
    this.options = options;
    this.xmpp = new _modules_xmpp_xmpp__WEBPACK_IMPORTED_MODULE_3__["default"](options, token);
    /* eslint-disable max-params */
    this.addEventListener(_JitsiConnectionEvents__WEBPACK_IMPORTED_MODULE_1__.CONNECTION_FAILED, (errType, msg, credentials, details) => {
        _modules_statistics_statistics__WEBPACK_IMPORTED_MODULE_2__["default"].sendAnalyticsAndLog((0,_service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_4__.createConnectionFailedEvent)(errType, msg, details));
    });
    /* eslint-enable max-params */
    this.addEventListener(_JitsiConnectionEvents__WEBPACK_IMPORTED_MODULE_1__.CONNECTION_DISCONNECTED, msg => {
        // we can see disconnects from normal tab closing of the browser
        // and then there are no msgs, but we want to log only disconnects
        // when there is real error
        // XXX Do we need the difference in handling between the log and
        // analytics event here?
        if (msg) {
            _modules_statistics_statistics__WEBPACK_IMPORTED_MODULE_2__["default"].sendAnalytics(_service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_4__.CONNECTION_DISCONNECTED, { message: msg });
        }
        _modules_statistics_statistics__WEBPACK_IMPORTED_MODULE_2__["default"].sendLog(JSON.stringify({
            id: _service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_4__.CONNECTION_DISCONNECTED,
            msg
        }));
    });
}
/**
 * Connect the client with the server.
 * @param options {object} connecting options
 * (for example authentications parameters).
 */
JitsiConnection.prototype.connect = function (options = {}) {
    this.xmpp.connect(options.id, options.password);
};
/**
 * Attach to existing connection. Can be used for optimizations. For example:
 * if the connection is created on the server we can attach to it and start
 * using it.
 *
 * @param options {object} connecting options - rid, sid and jid.
 */
JitsiConnection.prototype.attach = function (options) {
    this.xmpp.attach(options);
};
/**
 * Disconnect the client from the server.
 * @returns {Promise} - Resolves when the disconnect process is finished or rejects with an error.
 */
JitsiConnection.prototype.disconnect = function (...args) {
    // XXX Forward any arguments passed to JitsiConnection.disconnect to
    // XMPP.disconnect. For example, the caller of JitsiConnection.disconnect
    // may optionally pass the event which triggered the disconnect in order to
    // provide the implementation with finer-grained context.
    return this.xmpp.disconnect(...args);
};
/**
 * Returns the jid of the participant associated with the XMPP connection.
 *
 * @returns {string} The jid of the participant.
 */
JitsiConnection.prototype.getJid = function () {
    return this.xmpp.getJid();
};
/**
 * This method allows renewal of the tokens if they are expiring.
 * @param token the new token.
 */
JitsiConnection.prototype.setToken = function (token) {
    this.token = token;
};
/**
 * Creates and joins new conference.
 * @param name the name of the conference; if null - a generated name will be
 * provided from the api
 * @param options Object with properties / settings related to the conference
 * that will be created.
 * @returns {JitsiConference} returns the new conference object.
 */
JitsiConnection.prototype.initJitsiConference = function (name, options) {
    return new _JitsiConference__WEBPACK_IMPORTED_MODULE_0__["default"]({
        name,
        config: options,
        connection: this
    });
};
/**
 * Subscribes the passed listener to the event.
 * @param event {JitsiConnectionEvents} the connection event.
 * @param listener {Function} the function that will receive the event
 */
JitsiConnection.prototype.addEventListener = function (event, listener) {
    this.xmpp.addListener(event, listener);
};
/**
 * Unsubscribes the passed handler.
 * @param event {JitsiConnectionEvents} the connection event.
 * @param listener {Function} the function that will receive the event
 */
JitsiConnection.prototype.removeEventListener = function (event, listener) {
    this.xmpp.removeListener(event, listener);
};
/**
 * Returns measured connectionTimes.
 */
JitsiConnection.prototype.getConnectionTimes = function () {
    return this.xmpp.connectionTimes;
};
/**
 * Adds new feature to the list of supported features for the local
 * participant.
 * @param {String} feature the name of the feature.
 * @param {boolean} submit if true - the new list of features will be
 * immediately submitted to the others.
 */
JitsiConnection.prototype.addFeature = function (feature, submit = false) {
    this.xmpp.caps.addFeature(feature, submit, true);
};
/**
 * Removes a feature from the list of supported features for the local
 * participant
 * @param {String} feature the name of the feature.
 * @param {boolean} submit if true - the new list of features will be
 * immediately submitted to the others.
 */
JitsiConnection.prototype.removeFeature = function (feature, submit = false) {
    this.xmpp.caps.removeFeature(feature, submit, true);
};
/**
 * Get object with internal logs.
 */
JitsiConnection.prototype.getLogs = function () {
    const data = this.xmpp.getJingleLog();
    const metadata = {};
    metadata.time = new Date();
    metadata.url = window.location.href;
    metadata.ua = navigator.userAgent;
    const log = this.xmpp.getXmppLog();
    if (log) {
        metadata.xmpp = log;
    }
    data.metadata = metadata;
    return data;
};
//# sourceMappingURL=JitsiConnection.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/JitsiConnectionErrors.js":
/*!******************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/JitsiConnectionErrors.js ***!
  \******************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   CONNECTION_DROPPED_ERROR: () => (/* binding */ CONNECTION_DROPPED_ERROR),
/* harmony export */   JitsiConnectionErrors: () => (/* binding */ JitsiConnectionErrors),
/* harmony export */   OTHER_ERROR: () => (/* binding */ OTHER_ERROR),
/* harmony export */   PASSWORD_REQUIRED: () => (/* binding */ PASSWORD_REQUIRED),
/* harmony export */   SERVER_ERROR: () => (/* binding */ SERVER_ERROR)
/* harmony export */ });
/**
 * The errors for the connection.
 */
var JitsiConnectionErrors;
(function (JitsiConnectionErrors) {
    /**
     * Indicates that the connection was dropped with an error which was most likely
     * caused by some networking issues. The dropped term in this context means that
     * the connection was closed unexpectedly (not on user's request).
     *
     * One example is 'item-not-found' error thrown by Prosody when the BOSH session
     * times out after 60 seconds of inactivity. On the other hand 'item-not-found'
     * could also happen when BOSH request is sent to the server with the session-id
     * that is not know to the server. But this should not happen in lib-jitsi-meet
     * case as long as the service is configured correctly (there is no bug).
     */
    JitsiConnectionErrors["CONNECTION_DROPPED_ERROR"] = "connection.droppedError";
    /**
     * Not specified errors.
     */
    JitsiConnectionErrors["OTHER_ERROR"] = "connection.otherError";
    /**
     * Indicates that a password is required in order to join the conference.
     */
    JitsiConnectionErrors["PASSWORD_REQUIRED"] = "connection.passwordRequired";
    /**
     * Indicates that the connection was dropped, because of too many 5xx HTTP
     * errors on BOSH requests.
     */
    JitsiConnectionErrors["SERVER_ERROR"] = "connection.serverError";
})(JitsiConnectionErrors || (JitsiConnectionErrors = {}));
;
// exported for backward compatibility
const CONNECTION_DROPPED_ERROR = JitsiConnectionErrors.CONNECTION_DROPPED_ERROR;
const OTHER_ERROR = JitsiConnectionErrors.OTHER_ERROR;
const PASSWORD_REQUIRED = JitsiConnectionErrors.PASSWORD_REQUIRED;
const SERVER_ERROR = JitsiConnectionErrors.SERVER_ERROR;
//# sourceMappingURL=JitsiConnectionErrors.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/JitsiConnectionEvents.js":
/*!******************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/JitsiConnectionEvents.js ***!
  \******************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   CONNECTION_DISCONNECTED: () => (/* binding */ CONNECTION_DISCONNECTED),
/* harmony export */   CONNECTION_ESTABLISHED: () => (/* binding */ CONNECTION_ESTABLISHED),
/* harmony export */   CONNECTION_FAILED: () => (/* binding */ CONNECTION_FAILED),
/* harmony export */   DISPLAY_NAME_REQUIRED: () => (/* binding */ DISPLAY_NAME_REQUIRED),
/* harmony export */   JitsiConnectionEvents: () => (/* binding */ JitsiConnectionEvents),
/* harmony export */   WRONG_STATE: () => (/* binding */ WRONG_STATE)
/* harmony export */ });
/**
 * The events for the connection.
 */
var JitsiConnectionEvents;
(function (JitsiConnectionEvents) {
    /**
     * Indicates that the connection has been disconnected. The event provides
     * the following parameters to its listeners:
     *
     * @param msg {string} a message associated with the disconnect such as the
     * last (known) error message
     */
    JitsiConnectionEvents["CONNECTION_DISCONNECTED"] = "connection.connectionDisconnected";
    /**
     * Indicates that the connection has been established. The event provides
     * the following parameters to its listeners:
     *
     * @param id {string} the ID of the local endpoint/participant/peer (within
     * the context of the established connection)
     */
    JitsiConnectionEvents["CONNECTION_ESTABLISHED"] = "connection.connectionEstablished";
    /**
     * Indicates that the connection has been failed for some reason. The event
     * provides the following parameters to its listeners:
     *
     * @param errType {JitsiConnectionErrors} the type of error associated with
     * the failure
     * @param errReason {string} the error (message) associated with the failure
     * @param credentials {object} the credentials used to connect (if any)
     * @param errReasonDetails {object} an optional object with details about
     * the error, like shard moving, suspending. Used for analytics purposes.
     */
    JitsiConnectionEvents["CONNECTION_FAILED"] = "connection.connectionFailed";
    /**
     * Indicates that the performed action cannot be executed because the
     * connection is not in the correct state(connected, disconnected, etc.)
     */
    JitsiConnectionEvents["WRONG_STATE"] = "connection.wrongState";
    /**
     * Indicates that the display name is required over this connection and need to be supplied when
     * joining the room.
     * There are cases like lobby room where display name is required.
     */
    JitsiConnectionEvents["DISPLAY_NAME_REQUIRED"] = "connection.display_name_required";
})(JitsiConnectionEvents || (JitsiConnectionEvents = {}));
;
// exported for backward compatibility
const CONNECTION_DISCONNECTED = JitsiConnectionEvents.CONNECTION_DISCONNECTED;
const CONNECTION_ESTABLISHED = JitsiConnectionEvents.CONNECTION_ESTABLISHED;
const CONNECTION_FAILED = JitsiConnectionEvents.CONNECTION_FAILED;
const WRONG_STATE = JitsiConnectionEvents.WRONG_STATE;
const DISPLAY_NAME_REQUIRED = JitsiConnectionEvents.DISPLAY_NAME_REQUIRED;
//# sourceMappingURL=JitsiConnectionEvents.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/JitsiMediaDevices.js":
/*!**************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/JitsiMediaDevices.js ***!
  \**************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (__WEBPACK_DEFAULT_EXPORT__)
/* harmony export */ });
/* harmony import */ var events__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! events */ "./node_modules/events/events.js");
/* harmony import */ var events__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(events__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var _JitsiMediaDevicesEvents__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./JitsiMediaDevicesEvents */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/JitsiMediaDevicesEvents.js");
/* harmony import */ var _modules_RTC_RTC__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./modules/RTC/RTC */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/RTC/RTC.js");
/* harmony import */ var _modules_browser__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./modules/browser */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/browser/index.js");
/* harmony import */ var _modules_statistics_statistics__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./modules/statistics/statistics */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/statistics/statistics.js");
/* harmony import */ var _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./service/RTC/MediaType */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/RTC/MediaType.js");
/* harmony import */ var _service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./service/RTC/RTCEvents */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/RTC/RTCEvents.js");







const AUDIO_PERMISSION_NAME = 'microphone';
const PERMISSION_GRANTED_STATUS = 'granted';
const VIDEO_PERMISSION_NAME = 'camera';
/**
 * Media devices utilities for Jitsi.
 */
class JitsiMediaDevices {
    /**
     * Initializes a {@code JitsiMediaDevices} object. There will be a single
     * instance of this class.
     */
    constructor() {
        this._eventEmitter = new (events__WEBPACK_IMPORTED_MODULE_0___default())();
        this._permissions = {};
        _modules_RTC_RTC__WEBPACK_IMPORTED_MODULE_2__["default"].addListener(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_6__["default"].DEVICE_LIST_CHANGED, devices => this._eventEmitter.emit(_JitsiMediaDevicesEvents__WEBPACK_IMPORTED_MODULE_1__.DEVICE_LIST_CHANGED, devices));
        _modules_RTC_RTC__WEBPACK_IMPORTED_MODULE_2__["default"].addListener(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_6__["default"].DEVICE_LIST_AVAILABLE, devices => this._logOutputDevice(this.getAudioOutputDevice(), devices));
        // We would still want to update the permissions cache in case the permissions API is not supported.
        _modules_RTC_RTC__WEBPACK_IMPORTED_MODULE_2__["default"].addListener(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_6__["default"].PERMISSIONS_CHANGED, permissions => this._handlePermissionsChange(permissions));
        // Test if the W3C Permissions API is implemented and the 'camera' and 'microphone' permissions are
        // implemented. If supported add onchange listeners.
        this._permissionsApiSupported = new Promise(resolve => {
            if (!navigator.permissions) {
                resolve(false);
                return;
            }
            const self = this;
            const promises = [];
            promises.push(navigator.permissions.query({ name: VIDEO_PERMISSION_NAME })
                .then(status => {
                this._handlePermissionsChange({
                    [_service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_5__.MediaType.VIDEO]: this._parsePermissionState(status)
                });
                status.onchange = function () {
                    try {
                        self._handlePermissionsChange({
                            [_service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_5__.MediaType.VIDEO]: self._parsePermissionState(this)
                        });
                    }
                    catch (error) {
                        // Nothing to do.
                    }
                };
                return true;
            })
                .catch(() => false));
            promises.push(navigator.permissions.query({ name: AUDIO_PERMISSION_NAME })
                .then(status => {
                this._handlePermissionsChange({
                    [_service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_5__.MediaType.AUDIO]: this._parsePermissionState(status)
                });
                status.onchange = function () {
                    try {
                        self._handlePermissionsChange({
                            [_service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_5__.MediaType.AUDIO]: self._parsePermissionState(this)
                        });
                    }
                    catch (error) {
                        // Nothing to do.
                    }
                };
                return true;
            })
                .catch(() => false));
            Promise.all(promises).then(results => resolve(results.every(supported => supported)));
        });
    }
    /**
     * Parses a PermissionState object and returns true for granted and false otherwise.
     *
     * @param {PermissionState} permissionStatus - The PermissionState object retrieved from the Permissions API.
     * @returns {boolean} - True for granted and false for denied.
     * @throws {TypeError}
     */
    _parsePermissionState(permissionStatus = {}) {
        // The status attribute is deprecated, and state
        // should be used instead, but check both for now
        // for backwards compatibility.
        const status = permissionStatus.state || permissionStatus.status;
        if (typeof status !== 'string') {
            throw new TypeError();
        }
        return status === PERMISSION_GRANTED_STATUS;
    }
    /**
     * Updates the local granted/denied permissions cache. A permissions might be
     * granted, denied, or undefined. This is represented by having its media
     * type key set to {@code true} or {@code false} respectively.
     *
     * @param {Object} permissions - Object with the permissions.
     */
    _handlePermissionsChange(permissions) {
        const hasPermissionsChanged = [_service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_5__.MediaType.AUDIO, _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_5__.MediaType.VIDEO]
            .some(type => type in permissions && permissions[type] !== this._permissions[type]);
        if (hasPermissionsChanged) {
            this._permissions = Object.assign(Object.assign({}, this._permissions), permissions);
            this._eventEmitter.emit(_JitsiMediaDevicesEvents__WEBPACK_IMPORTED_MODULE_1__.PERMISSIONS_CHANGED, this._permissions);
            if (this._permissions[_service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_5__.MediaType.AUDIO] || this._permissions[_service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_5__.MediaType.VIDEO]) {
                // Triggering device list update when the permissiions are granted in order to update
                // the labels the devices.
                // eslint-disable-next-line no-empty-function
                this.enumerateDevices(() => { });
            }
        }
    }
    /**
     * Gathers data and sends it to statistics.
     * @param deviceID the device id to log
     * @param devices list of devices
     */
    _logOutputDevice(deviceID, devices) {
        const device = devices.find(d => d.kind === 'audiooutput' && d.deviceId === deviceID);
        if (device) {
            _modules_statistics_statistics__WEBPACK_IMPORTED_MODULE_4__["default"].sendActiveDeviceListEvent(_modules_RTC_RTC__WEBPACK_IMPORTED_MODULE_2__["default"].getEventDataForActiveDevice(device));
        }
    }
    /**
     * Executes callback with list of media devices connected.
     * @param {function} callback
     */
    enumerateDevices(callback) {
        _modules_RTC_RTC__WEBPACK_IMPORTED_MODULE_2__["default"].enumerateDevices(callback);
    }
    /**
     * Checks if its possible to enumerate available cameras/micropones.
     * @returns {Promise<boolean>} a Promise which will be resolved only once
     * the WebRTC stack is ready, either with true if the device listing is
     * available available or with false otherwise.
     */
    isDeviceListAvailable() {
        return _modules_RTC_RTC__WEBPACK_IMPORTED_MODULE_2__["default"].isDeviceListAvailable();
    }
    /**
     * Returns true if changing the input (camera / microphone) or output
     * (audio) device is supported and false if not.
     * @param {string} [deviceType] - type of device to change. Default is
     *      undefined or 'input', 'output' - for audio output device change.
     * @returns {boolean} true if available, false otherwise.
     */
    isDeviceChangeAvailable(deviceType) {
        return _modules_RTC_RTC__WEBPACK_IMPORTED_MODULE_2__["default"].isDeviceChangeAvailable(deviceType);
    }
    /**
     * Checks if the permission for the given device was granted.
     *
     * @param {'audio'|'video'} [type] - type of devices to check,
     *      undefined stands for both 'audio' and 'video' together
     * @returns {Promise<boolean>}
     */
    isDevicePermissionGranted(type) {
        return new Promise(resolve => {
            // Shortcut: first check if we already know the permission was
            // granted.
            if (type in this._permissions) {
                resolve(this._permissions[type]);
                return;
            }
            // Check using the Permissions API.
            this._permissionsApiSupported.then(supported => {
                if (!supported) {
                    resolve(false);
                    return;
                }
                const promises = [];
                switch (type) {
                    case _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_5__.MediaType.VIDEO:
                        promises.push(navigator.permissions.query({
                            name: VIDEO_PERMISSION_NAME
                        }));
                        break;
                    case _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_5__.MediaType.AUDIO:
                        promises.push(navigator.permissions.query({
                            name: AUDIO_PERMISSION_NAME
                        }));
                        break;
                    default:
                        promises.push(navigator.permissions.query({
                            name: VIDEO_PERMISSION_NAME
                        }));
                        promises.push(navigator.permissions.query({
                            name: AUDIO_PERMISSION_NAME
                        }));
                }
                Promise.all(promises).then(results => resolve(results.every(permissionStatus => {
                    try {
                        return this._parsePermissionState(permissionStatus);
                    }
                    catch (_a) {
                        return false;
                    }
                })), () => resolve(false));
            });
        });
    }
    /**
     * Returns true if it is possible to be simultaneously capturing audio from more than one device.
     *
     * @returns {boolean}
     */
    isMultipleAudioInputSupported() {
        return !((_modules_browser__WEBPACK_IMPORTED_MODULE_3__["default"].isFirefox() && _modules_browser__WEBPACK_IMPORTED_MODULE_3__["default"].isVersionLessThan('101'))
            || _modules_browser__WEBPACK_IMPORTED_MODULE_3__["default"].isIosBrowser());
    }
    /**
     * Returns currently used audio output device id, 'default' stands
     * for default device
     * @returns {string}
     */
    getAudioOutputDevice() {
        return _modules_RTC_RTC__WEBPACK_IMPORTED_MODULE_2__["default"].getAudioOutputDevice();
    }
    /**
     * Sets current audio output device.
     * @param {string} deviceId - id of 'audiooutput' device from
     *      navigator.mediaDevices.enumerateDevices(), 'default' is for
     *      default device
     * @returns {Promise} - resolves when audio output is changed, is rejected
     *      otherwise
     */
    setAudioOutputDevice(deviceId) {
        const availableDevices = _modules_RTC_RTC__WEBPACK_IMPORTED_MODULE_2__["default"].getCurrentlyAvailableMediaDevices();
        if (availableDevices.length > 0) {
            // if we have devices info report device to stats
            // normally this will not happen on startup as this method is called
            // too early. This will happen only on user selection of new device
            this._logOutputDevice(deviceId, _modules_RTC_RTC__WEBPACK_IMPORTED_MODULE_2__["default"].getCurrentlyAvailableMediaDevices());
        }
        return _modules_RTC_RTC__WEBPACK_IMPORTED_MODULE_2__["default"].setAudioOutputDevice(deviceId);
    }
    /**
     * Adds an event handler.
     * @param {string} event - event name
     * @param {function} handler - event handler
     */
    addEventListener(event, handler) {
        this._eventEmitter.addListener(event, handler);
    }
    /**
     * Removes event handler.
     * @param {string} event - event name
     * @param {function} handler - event handler
     */
    removeEventListener(event, handler) {
        this._eventEmitter.removeListener(event, handler);
    }
    /**
     * Emits an event.
     * @param {string} event - event name
     */
    emitEvent(event, ...args) {
        this._eventEmitter.emit(event, ...args);
    }
}
/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (new JitsiMediaDevices());
//# sourceMappingURL=JitsiMediaDevices.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/JitsiMediaDevicesEvents.js":
/*!********************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/JitsiMediaDevicesEvents.js ***!
  \********************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   DEVICE_LIST_CHANGED: () => (/* binding */ DEVICE_LIST_CHANGED),
/* harmony export */   JitsiMediaDevicesEvents: () => (/* binding */ JitsiMediaDevicesEvents),
/* harmony export */   PERMISSIONS_CHANGED: () => (/* binding */ PERMISSIONS_CHANGED),
/* harmony export */   PERMISSION_PROMPT_IS_SHOWN: () => (/* binding */ PERMISSION_PROMPT_IS_SHOWN),
/* harmony export */   SLOW_GET_USER_MEDIA: () => (/* binding */ SLOW_GET_USER_MEDIA)
/* harmony export */ });
/**
 * The events for the media devices.
 */
var JitsiMediaDevicesEvents;
(function (JitsiMediaDevicesEvents) {
    /**
     * Indicates that the list of available media devices has been changed. The
     * event provides the following parameters to its listeners:
     *
     * @param {MediaDeviceInfo[]} devices - array of MediaDeviceInfo or
     *  MediaDeviceInfo-like objects that are currently connected.
     *  @see https://developer.mozilla.org/en-US/docs/Web/API/MediaDeviceInfo
     */
    JitsiMediaDevicesEvents["DEVICE_LIST_CHANGED"] = "mediaDevices.devicechange";
    /**
     * Event emitted when the user granted/blocked a permission for the camera / mic.
     * Used to keep track of the granted permissions on browsers which don't
     * support the Permissions API.
     */
    JitsiMediaDevicesEvents["PERMISSIONS_CHANGED"] = "rtc.permissions_changed";
    /**
     * Indicates that the environment is currently showing permission prompt to
     * access camera and/or microphone. The event provides the following
     * parameters to its listeners:
     *
     * @param {'chrome'|'opera'|'firefox'|'safari'|'nwjs'
     *  |'react-native'|'android'} environmentType - type of browser or
     *  other execution environment.
     */
    JitsiMediaDevicesEvents["PERMISSION_PROMPT_IS_SHOWN"] = "mediaDevices.permissionPromptIsShown";
    JitsiMediaDevicesEvents["SLOW_GET_USER_MEDIA"] = "mediaDevices.slowGetUserMedia";
})(JitsiMediaDevicesEvents || (JitsiMediaDevicesEvents = {}));
;
// exported for backward compatibility
const DEVICE_LIST_CHANGED = JitsiMediaDevicesEvents.DEVICE_LIST_CHANGED;
const PERMISSIONS_CHANGED = JitsiMediaDevicesEvents.PERMISSIONS_CHANGED;
const PERMISSION_PROMPT_IS_SHOWN = JitsiMediaDevicesEvents.PERMISSION_PROMPT_IS_SHOWN;
const SLOW_GET_USER_MEDIA = JitsiMediaDevicesEvents.SLOW_GET_USER_MEDIA;
//# sourceMappingURL=JitsiMediaDevicesEvents.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/JitsiMeetJS.js":
/*!********************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/JitsiMeetJS.js ***!
  \********************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
var __filename = "/index.js";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (__WEBPACK_DEFAULT_EXPORT__)
/* harmony export */ });
/* harmony import */ var _jitsi_logger__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @jitsi/logger */ "./node_modules/@jitsi/logger/lib/index.js");
/* harmony import */ var _jitsi_logger__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(_jitsi_logger__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var _JitsiConferenceErrors__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./JitsiConferenceErrors */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/JitsiConferenceErrors.js");
/* harmony import */ var _JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./JitsiConferenceEvents */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/JitsiConferenceEvents.js");
/* harmony import */ var _JitsiConnection__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./JitsiConnection */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/JitsiConnection.js");
/* harmony import */ var _JitsiConnectionErrors__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./JitsiConnectionErrors */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/JitsiConnectionErrors.js");
/* harmony import */ var _JitsiConnectionEvents__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./JitsiConnectionEvents */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/JitsiConnectionEvents.js");
/* harmony import */ var _JitsiMediaDevices__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./JitsiMediaDevices */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/JitsiMediaDevices.js");
/* harmony import */ var _JitsiMediaDevicesEvents__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./JitsiMediaDevicesEvents */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/JitsiMediaDevicesEvents.js");
/* harmony import */ var _JitsiTrackError__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ./JitsiTrackError */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/JitsiTrackError.js");
/* harmony import */ var _JitsiTrackErrors__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ./JitsiTrackErrors */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/JitsiTrackErrors.js");
/* harmony import */ var _JitsiTrackEvents__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ./JitsiTrackEvents */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/JitsiTrackEvents.js");
/* harmony import */ var _JitsiTranscriptionStatus__WEBPACK_IMPORTED_MODULE_11__ = __webpack_require__(/*! ./JitsiTranscriptionStatus */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/JitsiTranscriptionStatus.js");
/* harmony import */ var _modules_RTC_RTC__WEBPACK_IMPORTED_MODULE_12__ = __webpack_require__(/*! ./modules/RTC/RTC */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/RTC/RTC.js");
/* harmony import */ var _modules_RTC_JitsiTrack__WEBPACK_IMPORTED_MODULE_13__ = __webpack_require__(/*! ./modules/RTC/JitsiTrack */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/RTC/JitsiTrack.js");
/* harmony import */ var _modules_RTC_JitsiLocalTrack__WEBPACK_IMPORTED_MODULE_14__ = __webpack_require__(/*! ./modules/RTC/JitsiLocalTrack */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/RTC/JitsiLocalTrack.js");
/* harmony import */ var _modules_RTC_JitsiRemoteTrack__WEBPACK_IMPORTED_MODULE_15__ = __webpack_require__(/*! ./modules/RTC/JitsiRemoteTrack */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/RTC/JitsiRemoteTrack.js");
/* harmony import */ var _modules_browser__WEBPACK_IMPORTED_MODULE_16__ = __webpack_require__(/*! ./modules/browser */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/browser/index.js");
/* harmony import */ var _modules_connectivity_NetworkInfo__WEBPACK_IMPORTED_MODULE_17__ = __webpack_require__(/*! ./modules/connectivity/NetworkInfo */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/connectivity/NetworkInfo.js");
/* harmony import */ var _modules_connectivity_TrackStreamingStatus__WEBPACK_IMPORTED_MODULE_18__ = __webpack_require__(/*! ./modules/connectivity/TrackStreamingStatus */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/connectivity/TrackStreamingStatus.js");
/* harmony import */ var _modules_detection_ActiveDeviceDetector__WEBPACK_IMPORTED_MODULE_19__ = __webpack_require__(/*! ./modules/detection/ActiveDeviceDetector */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/detection/ActiveDeviceDetector.js");
/* harmony import */ var _modules_detection_DetectionEvents__WEBPACK_IMPORTED_MODULE_20__ = __webpack_require__(/*! ./modules/detection/DetectionEvents */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/detection/DetectionEvents.js");
/* harmony import */ var _modules_detection_TrackVADEmitter__WEBPACK_IMPORTED_MODULE_21__ = __webpack_require__(/*! ./modules/detection/TrackVADEmitter */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/detection/TrackVADEmitter.js");
/* harmony import */ var _modules_flags_FeatureFlags__WEBPACK_IMPORTED_MODULE_22__ = __webpack_require__(/*! ./modules/flags/FeatureFlags */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/flags/FeatureFlags.js");
/* harmony import */ var _modules_proxyconnection_ProxyConnectionService__WEBPACK_IMPORTED_MODULE_23__ = __webpack_require__(/*! ./modules/proxyconnection/ProxyConnectionService */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/proxyconnection/ProxyConnectionService.js");
/* harmony import */ var _modules_recording_recordingConstants__WEBPACK_IMPORTED_MODULE_24__ = __webpack_require__(/*! ./modules/recording/recordingConstants */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/recording/recordingConstants.js");
/* harmony import */ var _modules_settings_Settings__WEBPACK_IMPORTED_MODULE_25__ = __webpack_require__(/*! ./modules/settings/Settings */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/settings/Settings.js");
/* harmony import */ var _modules_statistics_LocalStatsCollector__WEBPACK_IMPORTED_MODULE_26__ = __webpack_require__(/*! ./modules/statistics/LocalStatsCollector */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/statistics/LocalStatsCollector.js");
/* harmony import */ var _modules_statistics_PrecallTest__WEBPACK_IMPORTED_MODULE_27__ = __webpack_require__(/*! ./modules/statistics/PrecallTest */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/statistics/PrecallTest.js");
/* harmony import */ var _modules_statistics_statistics__WEBPACK_IMPORTED_MODULE_28__ = __webpack_require__(/*! ./modules/statistics/statistics */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/statistics/statistics.js");
/* harmony import */ var _modules_util_AuthUtil__WEBPACK_IMPORTED_MODULE_29__ = __webpack_require__(/*! ./modules/util/AuthUtil */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/util/AuthUtil.js");
/* harmony import */ var _modules_util_AuthUtil__WEBPACK_IMPORTED_MODULE_29___default = /*#__PURE__*/__webpack_require__.n(_modules_util_AuthUtil__WEBPACK_IMPORTED_MODULE_29__);
/* harmony import */ var _modules_util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_30__ = __webpack_require__(/*! ./modules/util/GlobalOnErrorHandler */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/util/GlobalOnErrorHandler.js");
/* harmony import */ var _modules_util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_30___default = /*#__PURE__*/__webpack_require__.n(_modules_util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_30__);
/* harmony import */ var _modules_util_ScriptUtil__WEBPACK_IMPORTED_MODULE_31__ = __webpack_require__(/*! ./modules/util/ScriptUtil */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/util/ScriptUtil.js");
/* harmony import */ var _modules_util_ScriptUtil__WEBPACK_IMPORTED_MODULE_31___default = /*#__PURE__*/__webpack_require__.n(_modules_util_ScriptUtil__WEBPACK_IMPORTED_MODULE_31__);
/* harmony import */ var _modules_videosipgw_VideoSIPGWConstants__WEBPACK_IMPORTED_MODULE_32__ = __webpack_require__(/*! ./modules/videosipgw/VideoSIPGWConstants */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/videosipgw/VideoSIPGWConstants.js");
/* harmony import */ var _modules_webaudio_AudioMixer__WEBPACK_IMPORTED_MODULE_33__ = __webpack_require__(/*! ./modules/webaudio/AudioMixer */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/webaudio/AudioMixer.js");
/* harmony import */ var _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_34__ = __webpack_require__(/*! ./service/RTC/MediaType */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/RTC/MediaType.js");
/* harmony import */ var _service_connectivity_ConnectionQualityEvents__WEBPACK_IMPORTED_MODULE_35__ = __webpack_require__(/*! ./service/connectivity/ConnectionQualityEvents */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/connectivity/ConnectionQualityEvents.js");
/* harmony import */ var _service_e2eping_E2ePingEvents__WEBPACK_IMPORTED_MODULE_36__ = __webpack_require__(/*! ./service/e2eping/E2ePingEvents */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/e2eping/E2ePingEvents.js");
/* harmony import */ var _service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_37__ = __webpack_require__(/*! ./service/statistics/AnalyticsEvents */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/statistics/AnalyticsEvents.js");
var __rest = (undefined && undefined.__rest) || function (s, e) {
    var t = {};
    for (var p in s) if (Object.prototype.hasOwnProperty.call(s, p) && e.indexOf(p) < 0)
        t[p] = s[p];
    if (s != null && typeof Object.getOwnPropertySymbols === "function")
        for (var i = 0, p = Object.getOwnPropertySymbols(s); i < p.length; i++) {
            if (e.indexOf(p[i]) < 0 && Object.prototype.propertyIsEnumerable.call(s, p[i]))
                t[p[i]] = s[p[i]];
        }
    return t;
};






































const logger = _jitsi_logger__WEBPACK_IMPORTED_MODULE_0___default().getLogger(__filename);
/**
 * The amount of time to wait until firing
 * {@link JitsiMediaDevicesEvents.PERMISSION_PROMPT_IS_SHOWN} event.
 */
const USER_MEDIA_SLOW_PROMISE_TIMEOUT = 1000;
/**
 * Extracts from an 'options' objects with a specific format (TODO what IS the
 * format?) the attributes which are to be logged in analytics events.
 *
 * @param options gum options (???)
 * @returns {*} the attributes to attach to analytics events.
 */
function getAnalyticsAttributesFromOptions(options) {
    const attributes = {};
    attributes['audio_requested'] = options.devices.includes('audio');
    attributes['video_requested'] = options.devices.includes('video');
    attributes['screen_sharing_requested'] = options.devices.includes('desktop');
    if (attributes.video_requested) {
        attributes.resolution = options.resolution;
    }
    return attributes;
}
/**
 * The public API of the Jitsi Meet library (a.k.a. {@code JitsiMeetJS}).
 */
/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = ({
    version: '{#COMMIT_HASH#}',
    JitsiConnection: _JitsiConnection__WEBPACK_IMPORTED_MODULE_3__["default"],
    /**
     * {@code ProxyConnectionService} is used to connect a remote peer to a
     * local Jitsi participant without going through a Jitsi conference. It is
     * currently used for room integration development, specifically wireless
     * screensharing. Its API is experimental and will likely change; usage of
     * it is advised against.
     */
    ProxyConnectionService: _modules_proxyconnection_ProxyConnectionService__WEBPACK_IMPORTED_MODULE_23__["default"],
    constants: {
        recording: _modules_recording_recordingConstants__WEBPACK_IMPORTED_MODULE_24__["default"],
        sipVideoGW: _modules_videosipgw_VideoSIPGWConstants__WEBPACK_IMPORTED_MODULE_32__,
        transcriptionStatus: _JitsiTranscriptionStatus__WEBPACK_IMPORTED_MODULE_11__,
        trackStreamingStatus: _modules_connectivity_TrackStreamingStatus__WEBPACK_IMPORTED_MODULE_18__.TrackStreamingStatus
    },
    events: {
        conference: _JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_2__,
        connection: _JitsiConnectionEvents__WEBPACK_IMPORTED_MODULE_5__,
        detection: _modules_detection_DetectionEvents__WEBPACK_IMPORTED_MODULE_20__,
        track: _JitsiTrackEvents__WEBPACK_IMPORTED_MODULE_10__,
        mediaDevices: _JitsiMediaDevicesEvents__WEBPACK_IMPORTED_MODULE_7__,
        connectionQuality: _service_connectivity_ConnectionQualityEvents__WEBPACK_IMPORTED_MODULE_35__,
        e2eping: _service_e2eping_E2ePingEvents__WEBPACK_IMPORTED_MODULE_36__
    },
    errors: {
        conference: _JitsiConferenceErrors__WEBPACK_IMPORTED_MODULE_1__,
        connection: _JitsiConnectionErrors__WEBPACK_IMPORTED_MODULE_4__,
        track: _JitsiTrackErrors__WEBPACK_IMPORTED_MODULE_9__
    },
    errorTypes: {
        JitsiTrackError: _JitsiTrackError__WEBPACK_IMPORTED_MODULE_8__["default"]
    },
    logLevels: (_jitsi_logger__WEBPACK_IMPORTED_MODULE_0___default().levels),
    mediaDevices: _JitsiMediaDevices__WEBPACK_IMPORTED_MODULE_6__["default"],
    analytics: _modules_statistics_statistics__WEBPACK_IMPORTED_MODULE_28__["default"].analytics,
    init(options = {}) {
        // @ts-ignore
        logger.info(`This appears to be ${_modules_browser__WEBPACK_IMPORTED_MODULE_16__["default"].getName()}, ver: ${_modules_browser__WEBPACK_IMPORTED_MODULE_16__["default"].getVersion()}`);
        _modules_settings_Settings__WEBPACK_IMPORTED_MODULE_25__["default"].init(options.externalStorage);
        _modules_statistics_statistics__WEBPACK_IMPORTED_MODULE_28__["default"].init(options);
        const flags = options.flags || {};
        // Configure the feature flags.
        _modules_flags_FeatureFlags__WEBPACK_IMPORTED_MODULE_22__["default"].init(flags);
        // Initialize global window.connectionTimes
        // FIXME do not use 'window'
        if (!window.connectionTimes) {
            window.connectionTimes = {};
        }
        if (options.enableAnalyticsLogging !== true) {
            logger.warn('Analytics disabled, disposing.');
            this.analytics.dispose();
        }
        if (options.enableWindowOnErrorHandler) {
            _modules_util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_30___default().addHandler(this.getGlobalOnErrorHandler.bind(this));
        }
        if (this.version) {
            const logObject = {
                id: 'component_version',
                component: 'lib-jitsi-meet',
                version: this.version
            };
            _modules_statistics_statistics__WEBPACK_IMPORTED_MODULE_28__["default"].sendLog(JSON.stringify(logObject));
        }
        return _modules_RTC_RTC__WEBPACK_IMPORTED_MODULE_12__["default"].init(options);
    },
    /**
     * Returns whether the desktop sharing is enabled or not.
     *
     * @returns {boolean}
     */
    isDesktopSharingEnabled() {
        return _modules_RTC_RTC__WEBPACK_IMPORTED_MODULE_12__["default"].isDesktopSharingEnabled();
    },
    /**
     * Returns whether the current execution environment supports WebRTC (for
     * use within this library).
     *
     * @returns {boolean} {@code true} if WebRTC is supported in the current
     * execution environment (for use within this library); {@code false},
     * otherwise.
     */
    isWebRtcSupported() {
        return _modules_RTC_RTC__WEBPACK_IMPORTED_MODULE_12__["default"].isWebRtcSupported();
    },
    setLogLevel(level) {
        _jitsi_logger__WEBPACK_IMPORTED_MODULE_0___default().setLogLevel(level);
    },
    /**
     * Sets the log level to the <tt>Logger</tt> instance with given id.
     *
     * @param {Logger.levels} level the logging level to be set
     * @param {string} id the logger id to which new logging level will be set.
     * Usually it's the name of the JavaScript source file including the path
     * ex. "modules/xmpp/ChatRoom.js"
     */
    setLogLevelById(level, id) {
        _jitsi_logger__WEBPACK_IMPORTED_MODULE_0___default().setLogLevelById(level, id);
    },
    /**
     * Registers new global logger transport to the library logging framework.
     *
     * @param globalTransport
     * @see Logger.addGlobalTransport
     */
    addGlobalLogTransport(globalTransport) {
        _jitsi_logger__WEBPACK_IMPORTED_MODULE_0___default().addGlobalTransport(globalTransport);
    },
    /**
     * Removes global logging transport from the library logging framework.
     *
     * @param globalTransport
     * @see Logger.removeGlobalTransport
     */
    removeGlobalLogTransport(globalTransport) {
        _jitsi_logger__WEBPACK_IMPORTED_MODULE_0___default().removeGlobalTransport(globalTransport);
    },
    /**
    * Sets global options which will be used by all loggers. Changing these
    * works even after other loggers are created.
    *
    * @param options
    * @see Logger.setGlobalOptions
    */
    setGlobalLogOptions(options) {
        _jitsi_logger__WEBPACK_IMPORTED_MODULE_0___default().setGlobalOptions(options);
    },
    /**
     * Creates the media tracks and returns them trough the callback.
     *
     * @param options Object with properties / settings specifying the tracks
     * which should be created. should be created or some additional
     * configurations about resolution for example.
     * @param {Array} options.effects optional effects array for the track
     * @param {boolean} options.firePermissionPromptIsShownEvent - if event
     * JitsiMediaDevicesEvents.PERMISSION_PROMPT_IS_SHOWN should be fired
     * @param {boolean} options.fireSlowPromiseEvent - if event
     * JitsiMediaDevicesEvents.USER_MEDIA_SLOW_PROMISE_TIMEOUT should be fired
     * @param {Array} options.devices the devices that will be requested
     * @param {string} options.resolution resolution constraints
     * @param {string} options.cameraDeviceId
     * @param {string} options.micDeviceId
     * @param {intiger} interval - the interval (in ms) for
     * checking whether the desktop sharing extension is installed or not
     * @param {Function} checkAgain - returns boolean. While checkAgain()==true
     * createLocalTracks will wait and check on every "interval" ms for the
     * extension. If the desktop extension is not install and checkAgain()==true
     * createLocalTracks will finish with rejected Promise.
     * @param {Function} listener - The listener will be called to notify the
     * user of lib-jitsi-meet that createLocalTracks is starting external
     * extension installation process.
     * NOTE: If the inline installation process is not possible and external
     * installation is enabled the listener property will be called to notify
     * the start of external installation process. After that createLocalTracks
     * will start to check for the extension on every interval ms until the
     * plugin is installed or until checkAgain return false. If the extension
     * is found createLocalTracks will try to get the desktop sharing track and
     * will finish the execution. If checkAgain returns false, createLocalTracks
     * will finish the execution with rejected Promise.
     *
     * @deprecated old firePermissionPromptIsShownEvent
     * @returns {Promise.<{Array.<JitsiTrack>}, JitsiConferenceError>} A promise
     * that returns an array of created JitsiTracks if resolved, or a
     * JitsiConferenceError if rejected.
     */
    createLocalTracks(options = {}, oldfirePermissionPromptIsShownEvent) {
        let promiseFulfilled = false;
        const { firePermissionPromptIsShownEvent, fireSlowPromiseEvent } = options, restOptions = __rest(options, ["firePermissionPromptIsShownEvent", "fireSlowPromiseEvent"]);
        const firePermissionPrompt = firePermissionPromptIsShownEvent || oldfirePermissionPromptIsShownEvent;
        if (firePermissionPrompt && !_modules_RTC_RTC__WEBPACK_IMPORTED_MODULE_12__["default"].arePermissionsGrantedForAvailableDevices()) {
            // @ts-ignore
            _JitsiMediaDevices__WEBPACK_IMPORTED_MODULE_6__["default"].emitEvent(_JitsiMediaDevicesEvents__WEBPACK_IMPORTED_MODULE_7__.PERMISSION_PROMPT_IS_SHOWN, _modules_browser__WEBPACK_IMPORTED_MODULE_16__["default"].getName());
        }
        else if (fireSlowPromiseEvent) {
            window.setTimeout(() => {
                if (!promiseFulfilled) {
                    _JitsiMediaDevices__WEBPACK_IMPORTED_MODULE_6__["default"].emitEvent(_JitsiMediaDevicesEvents__WEBPACK_IMPORTED_MODULE_7__.SLOW_GET_USER_MEDIA);
                }
            }, USER_MEDIA_SLOW_PROMISE_TIMEOUT);
        }
        if (!window.connectionTimes) {
            window.connectionTimes = {};
        }
        window.connectionTimes['obtainPermissions.start']
            = window.performance.now();
        return _modules_RTC_RTC__WEBPACK_IMPORTED_MODULE_12__["default"].obtainAudioAndVideoPermissions(restOptions)
            .then(tracks => {
            promiseFulfilled = true;
            window.connectionTimes['obtainPermissions.end']
                = window.performance.now();
            _modules_statistics_statistics__WEBPACK_IMPORTED_MODULE_28__["default"].sendAnalytics((0,_service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_37__.createGetUserMediaEvent)('success', getAnalyticsAttributesFromOptions(restOptions)));
            if (this.isCollectingLocalStats()) {
                for (let i = 0; i < tracks.length; i++) {
                    const track = tracks[i];
                    if (track.getType() === _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_34__.MediaType.AUDIO) {
                        _modules_statistics_statistics__WEBPACK_IMPORTED_MODULE_28__["default"].startLocalStats(track, track.setAudioLevel.bind(track));
                    }
                }
            }
            // set real device ids
            const currentlyAvailableMediaDevices = _modules_RTC_RTC__WEBPACK_IMPORTED_MODULE_12__["default"].getCurrentlyAvailableMediaDevices();
            if (currentlyAvailableMediaDevices) {
                for (let i = 0; i < tracks.length; i++) {
                    const track = tracks[i];
                    track._setRealDeviceIdFromDeviceList(currentlyAvailableMediaDevices);
                }
            }
            return tracks;
        })
            .catch(error => {
            promiseFulfilled = true;
            if (error.name === _JitsiTrackErrors__WEBPACK_IMPORTED_MODULE_9__.SCREENSHARING_USER_CANCELED) {
                // User cancelled action is not really an error, so only
                // log it as an event to avoid having conference classified
                // as partially failed
                const logObject = {
                    id: 'screensharing_user_canceled',
                    message: error.message
                };
                _modules_statistics_statistics__WEBPACK_IMPORTED_MODULE_28__["default"].sendLog(JSON.stringify(logObject));
                _modules_statistics_statistics__WEBPACK_IMPORTED_MODULE_28__["default"].sendAnalytics((0,_service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_37__.createGetUserMediaEvent)('warning', {
                    reason: 'extension install user canceled'
                }));
            }
            else if (error.name === _JitsiTrackErrors__WEBPACK_IMPORTED_MODULE_9__.NOT_FOUND) {
                // logs not found devices with just application log to cs
                const logObject = {
                    id: 'usermedia_missing_device',
                    status: error.gum.devices
                };
                _modules_statistics_statistics__WEBPACK_IMPORTED_MODULE_28__["default"].sendLog(JSON.stringify(logObject));
                const attributes = getAnalyticsAttributesFromOptions(options);
                attributes.reason = 'device not found';
                attributes.devices = error.gum.devices.join('.');
                _modules_statistics_statistics__WEBPACK_IMPORTED_MODULE_28__["default"].sendAnalytics((0,_service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_37__.createGetUserMediaEvent)('error', attributes));
            }
            else {
                // Report gUM failed to the stats
                _modules_statistics_statistics__WEBPACK_IMPORTED_MODULE_28__["default"].sendGetUserMediaFailed(error);
                const attributes = getAnalyticsAttributesFromOptions(options);
                attributes.reason = error.name;
                _modules_statistics_statistics__WEBPACK_IMPORTED_MODULE_28__["default"].sendAnalytics((0,_service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_37__.createGetUserMediaEvent)('error', attributes));
            }
            window.connectionTimes['obtainPermissions.end']
                = window.performance.now();
            return Promise.reject(error);
        });
    },
    /**
     * Create a TrackVADEmitter service that connects an audio track to an VAD (voice activity detection) processor in
     * order to obtain VAD scores for individual PCM audio samples.
     * @param {string} localAudioDeviceId - The target local audio device.
     * @param {number} sampleRate - Sample rate at which the emitter will operate. Possible values  256, 512, 1024,
     * 4096, 8192, 16384. Passing other values will default to closes neighbor.
     * I.e. Providing a value of 4096 means that the emitter will process 4096 PCM samples at a time, higher values mean
     * longer calls, lowers values mean more calls but shorter.
     * @param {Object} vadProcessor - VAD Processors that does the actual compute on a PCM sample.The processor needs
     * to implement the following functions:
     * - <tt>getSampleLength()</tt> - Returns the sample size accepted by calculateAudioFrameVAD.
     * - <tt>getRequiredPCMFrequency()</tt> - Returns the PCM frequency at which the processor operates.
     * i.e. (16KHz, 44.1 KHz etc.)
     * - <tt>calculateAudioFrameVAD(pcmSample)</tt> - Process a 32 float pcm sample of getSampleLength size.
     * @returns {Promise<TrackVADEmitter>}
     */
    createTrackVADEmitter(localAudioDeviceId, sampleRate, vadProcessor) {
        return _modules_detection_TrackVADEmitter__WEBPACK_IMPORTED_MODULE_21__["default"].create(localAudioDeviceId, sampleRate, vadProcessor);
    },
    /**
     * Create AudioMixer, which is essentially a wrapper over web audio ChannelMergerNode. It essentially allows the
     * user to mix multiple MediaStreams into a single one.
     *
     * @returns {AudioMixer}
     */
    createAudioMixer() {
        return new _modules_webaudio_AudioMixer__WEBPACK_IMPORTED_MODULE_33__["default"]();
    },
    /**
     * Go through all audio devices on the system and return one that is active, i.e. has audio signal.
     *
     * @returns Promise<Object> - Object containing information about the found device.
     */
    getActiveAudioDevice() {
        return (0,_modules_detection_ActiveDeviceDetector__WEBPACK_IMPORTED_MODULE_19__["default"])();
    },
    /**
     * Checks if its possible to enumerate available cameras/microphones.
     *
     * @returns {Promise<boolean>} a Promise which will be resolved only once
     * the WebRTC stack is ready, either with true if the device listing is
     * available available or with false otherwise.
     * @deprecated use JitsiMeetJS.mediaDevices.isDeviceListAvailable instead
     */
    isDeviceListAvailable() {
        logger.warn('This method is deprecated, use '
            + 'JitsiMeetJS.mediaDevices.isDeviceListAvailable instead');
        return this.mediaDevices.isDeviceListAvailable();
    },
    /**
     * Returns true if changing the input (camera / microphone) or output
     * (audio) device is supported and false if not.
     *
     * @param {string} [deviceType] - type of device to change. Default is
     * {@code undefined} or 'input', 'output' - for audio output device change.
     * @returns {boolean} {@code true} if available; {@code false}, otherwise.
     * @deprecated use JitsiMeetJS.mediaDevices.isDeviceChangeAvailable instead
     */
    isDeviceChangeAvailable(deviceType) {
        logger.warn('This method is deprecated, use '
            + 'JitsiMeetJS.mediaDevices.isDeviceChangeAvailable instead');
        return this.mediaDevices.isDeviceChangeAvailable(deviceType);
    },
    /**
     * Checks if the current environment supports having multiple audio
     * input devices in use simultaneously.
     *
     * @returns {boolean} True if multiple audio input devices can be used.
     */
    isMultipleAudioInputSupported() {
        return this.mediaDevices.isMultipleAudioInputSupported();
    },
    /**
     * Checks if local tracks can collect stats and collection is enabled.
     *
     * @param {boolean} True if stats are being collected for local tracks.
     */
    isCollectingLocalStats() {
        return _modules_statistics_statistics__WEBPACK_IMPORTED_MODULE_28__["default"].audioLevelsEnabled && _modules_statistics_LocalStatsCollector__WEBPACK_IMPORTED_MODULE_26__["default"].isLocalStatsSupported();
    },
    /**
     * Executes callback with list of media devices connected.
     *
     * @param {function} callback
     * @deprecated use JitsiMeetJS.mediaDevices.enumerateDevices instead
     */
    enumerateDevices(callback) {
        logger.warn('This method is deprecated, use '
            + 'JitsiMeetJS.mediaDevices.enumerateDevices instead');
        this.mediaDevices.enumerateDevices(callback);
    },
    /* eslint-disable max-params */
    /**
     * @returns function that can be used to be attached to window.onerror and
     * if options.enableWindowOnErrorHandler is enabled returns
     * the function used by the lib.
     * (function(message, source, lineno, colno, error)).
     */
    getGlobalOnErrorHandler(message, source, lineno, colno, error) {
        logger.error(`UnhandledError: ${message}`, `Script: ${source}`, `Line: ${lineno}`, `Column: ${colno}`, 'StackTrace: ', error);
        _modules_statistics_statistics__WEBPACK_IMPORTED_MODULE_28__["default"].reportGlobalError(error);
    },
    /**
     * Informs lib-jitsi-meet about the current network status.
     *
     * @param {object} state - The network info state.
     * @param {boolean} state.isOnline - {@code true} if the internet connectivity is online or {@code false}
     * otherwise.
     */
    setNetworkInfo({ isOnline }) {
        _modules_connectivity_NetworkInfo__WEBPACK_IMPORTED_MODULE_17__["default"].updateNetworkInfo({ isOnline });
    },
    precallTest: _modules_statistics_PrecallTest__WEBPACK_IMPORTED_MODULE_27__["default"],
    /* eslint-enable max-params */
    /**
     * Represents a hub/namespace for utility functionality which may be of
     * interest to lib-jitsi-meet clients.
     */
    util: {
        AuthUtil: (_modules_util_AuthUtil__WEBPACK_IMPORTED_MODULE_29___default()),
        ScriptUtil: (_modules_util_ScriptUtil__WEBPACK_IMPORTED_MODULE_31___default()),
        browser: _modules_browser__WEBPACK_IMPORTED_MODULE_16__["default"],
        RTC: _modules_RTC_RTC__WEBPACK_IMPORTED_MODULE_12__["default"],
        JitsiTrack: _modules_RTC_JitsiTrack__WEBPACK_IMPORTED_MODULE_13__["default"],
        JitsiLocalTrack: _modules_RTC_JitsiLocalTrack__WEBPACK_IMPORTED_MODULE_14__["default"],
        JitsiRemoteTrack: _modules_RTC_JitsiRemoteTrack__WEBPACK_IMPORTED_MODULE_15__["default"]
    }
});
//# sourceMappingURL=JitsiMeetJS.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/JitsiParticipant.js":
/*!*************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/JitsiParticipant.js ***!
  \*************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (/* binding */ JitsiParticipant)
/* harmony export */ });
/* harmony import */ var strophe_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! strophe.js */ "./node_modules/strophe.js/dist/strophe.umd.js");
/* harmony import */ var strophe_js__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(strophe_js__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var _JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./JitsiConferenceEvents */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/JitsiConferenceEvents.js");
/* harmony import */ var _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./service/RTC/MediaType */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/RTC/MediaType.js");



/**
 * Represents a participant in (i.e. a member of) a conference.
 */
class JitsiParticipant {
    /* eslint-disable max-params */
    /**
     * Initializes a new JitsiParticipant instance.
     *
     * @constructor
     * @param jid the conference XMPP jid
     * @param conference
     * @param displayName
     * @param {Boolean} hidden - True if the new JitsiParticipant instance is to
     * represent a hidden participant; otherwise, false.
     * @param {string} statsID - optional participant statsID
     * @param {string} status - the initial status if any.
     * @param {object} identity - the xmpp identity
     * @param {boolean?} isReplacing - whether this is a participant replacing another into the meeting.
     * @param {boolean?} isReplaced - whether this is a participant to be kicked and replaced into the meeting.
     */
    constructor(jid, conference, displayName, hidden, statsID, status, identity, isReplacing, isReplaced) {
        this._jid = jid;
        this._id = strophe_js__WEBPACK_IMPORTED_MODULE_0__.Strophe.getResourceFromJid(jid);
        this._conference = conference;
        this._displayName = displayName;
        this._supportsDTMF = false;
        this._tracks = [];
        this._role = 'none';
        this._status = status;
        this._hidden = hidden;
        this._statsID = statsID;
        this._properties = {};
        this._identity = identity;
        this._isReplacing = isReplacing;
        this._isReplaced = isReplaced;
        this._features = new Set();
        /**
         * Remote sources associated with the participant in the following format.
         * Map<mediaType, Map<sourceName, sourceInfo>>
         *
         * mediaType - 'audio' or 'video'.
         * sourceName - name of the remote source.
         * sourceInfo: {
         *   muted: boolean;
         *   videoType: string;
         * }
         */
        this._sources = new Map();
    }
    /**
     * Determines whether all JitsiTracks which are of a specific MediaType and which belong to this
     * JitsiParticipant are muted.
     *
     * @param {MediaType} mediaType - The MediaType of the JitsiTracks to be checked.
     * @private
     * @returns {Boolean} True if all JitsiTracks which are of the specified mediaType and which belong to this
     * JitsiParticipant are muted; otherwise, false.
     */
    _isMediaTypeMuted(mediaType) {
        return this.getTracks().reduce((muted, track) => muted && (track.getType() !== mediaType || track.isMuted()), true);
    }
    /**
     * Sets source info.
     * @param {MediaType} mediaType The media type, 'audio' or 'video'.
     * @param {boolean} muted The new muted state.
     * @param {string} sourceName The name of the source.
     * @param {string} videoType The video type of the source.
     * @returns {void}
     */
    _setSources(mediaType, muted, sourceName, videoType) {
        let sourceByMediaType = this._sources.get(mediaType);
        const sourceInfo = {
            muted,
            videoType
        };
        if (sourceByMediaType === null || sourceByMediaType === void 0 ? void 0 : sourceByMediaType.size) {
            sourceByMediaType.set(sourceName, sourceInfo);
            return;
        }
        sourceByMediaType = new Map();
        sourceByMediaType.set(sourceName, sourceInfo);
        this._sources.set(mediaType, sourceByMediaType);
    }
    /**
     * Returns the bot type for the participant.
     *
     * @returns {string|undefined} - The bot type of the participant.
     */
    getBotType() {
        return this._botType;
    }
    /**
     * @returns {JitsiConference} The conference that this participant belongs
     * to.
     */
    getConference() {
        return this._conference;
    }
    /**
     * Returns the connection jid for the participant.
     *
     * @returns {string|undefined} - The connection jid of the participant.
     */
    getConnectionJid() {
        return this._connectionJid;
    }
    /**
     * @returns {String} The human-readable display name of this participant.
     */
    getDisplayName() {
        return this._displayName;
    }
    /**
     * Returns a set with the features for the participant.
     * @returns {Promise<Set<String>, Error>}
     */
    getFeatures() {
        return Promise.resolve(this._features);
    }
    /**
     * @returns {String} The ID of this participant.
     */
    getId() {
        return this._id;
    }
    /**
     * @returns {String} The JID of this participant.
     */
    getJid() {
        return this._jid;
    }
    /**
     * Gets the value of a property of this participant.
     */
    getProperty(name) {
        return this._properties[name];
    }
    /**
     * @returns {String} The role of this participant.
     */
    getRole() {
        return this._role;
    }
    /**
     * Returns the sources associated with this participant.
     * @returns Map<string, Map<string, Object>>
     */
    getSources() {
        return this._sources;
    }
    /**
     * @returns {String} The stats ID of this participant.
     */
    getStatsID() {
        return this._statsID;
    }
    /**
     * @returns {String} The status of the participant.
     */
    getStatus() {
        return this._status;
    }
    /**
     * @returns {Array.<JitsiTrack>} The list of media tracks for this
     * participant.
     */
    getTracks() {
        return this._tracks.slice();
    }
    /**
     * @param {MediaType} mediaType
     * @returns {Array.<JitsiTrack>} an array of media tracks for this
     * participant, for given media type.
     */
    getTracksByMediaType(mediaType) {
        return this.getTracks().filter(track => track.getType() === mediaType);
    }
    /**
     * Checks current set features.
     * @param {String} feature - the feature to check.
     * @return {boolean} <tt>true</tt> if this <tt>participant</tt> contains the
     * <tt>feature</tt>.
     */
    hasFeature(feature) {
        return this._features.has(feature);
    }
    /**
     * @returns {Boolean} Whether this participant has muted their audio.
     */
    isAudioMuted() {
        return this._isMediaTypeMuted(_service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_2__.MediaType.AUDIO);
    }
    /**
     * @returns {Boolean} Whether this participant is a hidden participant. Some
     * special system participants may want to join hidden (like for example the
     * recorder).
     */
    isHidden() {
        return this._hidden;
    }
    /**
     * @returns {Boolean} Whether this participant is a hidden participant. Some
     * special system participants may want to join hidden (like for example the
     * recorder).
     */
    isHiddenFromRecorder() {
        var _a, _b;
        return ((_b = (_a = this._identity) === null || _a === void 0 ? void 0 : _a.user) === null || _b === void 0 ? void 0 : _b['hidden-from-recorder']) === 'true';
    }
    /**
     * @returns {Boolean} Whether this participant is a moderator or not.
     */
    isModerator() {
        return this._role === 'moderator';
    }
    /**
     * @returns {Boolean} Wheter this participants will be replaced by another
     * participant in the meeting.
     */
    isReplaced() {
        return this._isReplaced;
    }
    /**
     * @returns {Boolean} Whether this participant replaces another participant
     * from the meeting.
     */
    isReplacing() {
        return this._isReplacing;
    }
    /**
     * @returns {Boolean} Whether this participant has muted their video.
     */
    isVideoMuted() {
        return this._isMediaTypeMuted(_service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_2__.MediaType.VIDEO);
    }
    /**
     * Sets the bot type for the participant.
     * @param {String} newBotType - The new bot type to set.
     */
    setBotType(newBotType) {
        this._botType = newBotType;
    }
    /**
     * Sets the connection jid for the participant.
     * @param {String} newJid - The connection jid to set.
     */
    setConnectionJid(newJid) {
        this._connectionJid = newJid;
    }
    /**
     * Set new features.
     * @param {Set<String>|undefined} newFeatures - Sets new features.
     */
    setFeatures(newFeatures) {
        this._features = newFeatures || new Set();
    }
    /**
     * Sets whether participant is being replaced by another based on jwt.
     * @param {boolean} newIsReplaced - whether is being replaced.
     */
    setIsReplaced(newIsReplaced) {
        this._isReplaced = newIsReplaced;
    }
    /**
     * Sets whether participant is replacing another based on jwt.
     * @param {String} newIsReplacing - whether is replacing.
     */
    setIsReplacing(newIsReplacing) {
        this._isReplacing = newIsReplacing;
    }
    /**
     * Sets the value of a property of this participant, and fires an event if
     * the value has changed.
     * @name the name of the property.
     * @value the value to set.
     */
    setProperty(name, value) {
        const oldValue = this._properties[name];
        if (value !== oldValue) {
            this._properties[name] = value;
            this._conference.eventEmitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_1__.PARTICIPANT_PROPERTY_CHANGED, this, name, oldValue, value);
        }
    }
    /**
     * Sets a new participant role.
     * @param {String} newRole - the new role.
     */
    setRole(newRole) {
        this._role = newRole;
    }
    /**
     *
     */
    supportsDTMF() {
        return this._supportsDTMF;
    }
}
//# sourceMappingURL=JitsiParticipant.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/JitsiTrackError.js":
/*!************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/JitsiTrackError.js ***!
  \************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (__WEBPACK_DEFAULT_EXPORT__)
/* harmony export */ });
/* harmony import */ var _JitsiTrackErrors__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./JitsiTrackErrors */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/JitsiTrackErrors.js");

const TRACK_ERROR_TO_MESSAGE_MAP = {};
TRACK_ERROR_TO_MESSAGE_MAP[_JitsiTrackErrors__WEBPACK_IMPORTED_MODULE_0__.UNSUPPORTED_RESOLUTION]
    = 'Video resolution is not supported: ';
TRACK_ERROR_TO_MESSAGE_MAP[_JitsiTrackErrors__WEBPACK_IMPORTED_MODULE_0__.SCREENSHARING_USER_CANCELED]
    = 'User canceled screen sharing prompt';
TRACK_ERROR_TO_MESSAGE_MAP[_JitsiTrackErrors__WEBPACK_IMPORTED_MODULE_0__.SCREENSHARING_GENERIC_ERROR]
    = 'Unknown error from screensharing';
TRACK_ERROR_TO_MESSAGE_MAP[_JitsiTrackErrors__WEBPACK_IMPORTED_MODULE_0__.ELECTRON_DESKTOP_PICKER_ERROR]
    = 'Unkown error from desktop picker';
TRACK_ERROR_TO_MESSAGE_MAP[_JitsiTrackErrors__WEBPACK_IMPORTED_MODULE_0__.ELECTRON_DESKTOP_PICKER_NOT_FOUND]
    = 'Failed to detect desktop picker';
TRACK_ERROR_TO_MESSAGE_MAP[_JitsiTrackErrors__WEBPACK_IMPORTED_MODULE_0__.GENERAL]
    = 'Generic getUserMedia error';
TRACK_ERROR_TO_MESSAGE_MAP[_JitsiTrackErrors__WEBPACK_IMPORTED_MODULE_0__.PERMISSION_DENIED]
    = 'User denied permission to use device(s): ';
TRACK_ERROR_TO_MESSAGE_MAP[_JitsiTrackErrors__WEBPACK_IMPORTED_MODULE_0__.NOT_FOUND]
    = 'Requested device(s) was/were not found: ';
TRACK_ERROR_TO_MESSAGE_MAP[_JitsiTrackErrors__WEBPACK_IMPORTED_MODULE_0__.CONSTRAINT_FAILED]
    = 'Constraint could not be satisfied: ';
TRACK_ERROR_TO_MESSAGE_MAP[_JitsiTrackErrors__WEBPACK_IMPORTED_MODULE_0__.TIMEOUT]
    = 'Could not start media source. Timeout occured!';
TRACK_ERROR_TO_MESSAGE_MAP[_JitsiTrackErrors__WEBPACK_IMPORTED_MODULE_0__.TRACK_IS_DISPOSED]
    = 'Track has been already disposed';
TRACK_ERROR_TO_MESSAGE_MAP[_JitsiTrackErrors__WEBPACK_IMPORTED_MODULE_0__.TRACK_NO_STREAM_FOUND]
    = 'Track does not have an associated Media Stream';
// FIXME: Using prototype inheritance because otherwise instanceof is not
// working properly (see https://github.com/babel/babel/issues/3083)
/**
 *
 * Represents an error that occurred to a JitsiTrack. Can represent various
 * types of errors. For error descriptions (@see JitsiTrackErrors).
 *
 * @extends Error
 *
 *
 * @constructor
 * @param {Object|string} error - error object or error name
 * @param {Object|string} (options) - getUserMedia constraints object or
 * error message
 * @param {('audio'|'video'|'desktop'|'screen'|'audiooutput')[]} (devices) -
 * list of getUserMedia requested devices
 */
function JitsiTrackError(error, options, devices) {
    if (typeof error === 'object' && typeof error.name !== 'undefined') {
        /**
         * Additional information about original getUserMedia error
         * and constraints.
         * @type {{
         *     error: Object,
         *     constraints: Object,
         *     devices: Array.<'audio'|'video'|'desktop'|'screen'>
         * }}
         */
        this.gum = {
            error,
            constraints: options,
            devices: devices && Array.isArray(devices)
                ? devices.slice(0)
                : undefined
        };
        switch (error.name) {
            case 'NotAllowedError':
            case 'PermissionDeniedError':
            case 'SecurityError':
                this.name = _JitsiTrackErrors__WEBPACK_IMPORTED_MODULE_0__.PERMISSION_DENIED;
                this.message
                    = TRACK_ERROR_TO_MESSAGE_MAP[this.name]
                        + (this.gum.devices || []).join(', ');
                break;
            case 'DevicesNotFoundError':
            case 'NotFoundError':
                this.name = _JitsiTrackErrors__WEBPACK_IMPORTED_MODULE_0__.NOT_FOUND;
                this.message
                    = TRACK_ERROR_TO_MESSAGE_MAP[this.name]
                        + (this.gum.devices || []).join(', ');
                break;
            case 'ConstraintNotSatisfiedError':
            case 'OverconstrainedError': {
                const constraintName = error.constraintName || error.constraint;
                // we treat deviceId as unsupported resolution, as we want to
                // retry and finally if everything fails to remove deviceId from
                // mandatory constraints
                if (options
                    && options.video
                    && (!devices || devices.indexOf('video') > -1)
                    && (constraintName === 'minWidth'
                        || constraintName === 'maxWidth'
                        || constraintName === 'minHeight'
                        || constraintName === 'maxHeight'
                        || constraintName === 'width'
                        || constraintName === 'height'
                        || constraintName === 'deviceId')) {
                    this.name = _JitsiTrackErrors__WEBPACK_IMPORTED_MODULE_0__.UNSUPPORTED_RESOLUTION;
                    this.message
                        = TRACK_ERROR_TO_MESSAGE_MAP[this.name]
                            + getResolutionFromFailedConstraint(constraintName, options);
                }
                else {
                    this.name = _JitsiTrackErrors__WEBPACK_IMPORTED_MODULE_0__.CONSTRAINT_FAILED;
                    this.message
                        = TRACK_ERROR_TO_MESSAGE_MAP[this.name]
                            + error.constraintName;
                }
                break;
            }
            default:
                this.name = _JitsiTrackErrors__WEBPACK_IMPORTED_MODULE_0__.GENERAL;
                this.message
                    = error.message || TRACK_ERROR_TO_MESSAGE_MAP[this.name];
                break;
        }
    }
    else if (typeof error === 'string') {
        if (TRACK_ERROR_TO_MESSAGE_MAP[error]) {
            this.name = error;
            this.message = options || TRACK_ERROR_TO_MESSAGE_MAP[error];
        }
        else {
            // this is some generic error that do not fit any of our
            // pre-defined errors, so don't give it any specific name, just
            // store message
            this.message = error;
        }
    }
    else {
        throw new Error('Invalid arguments');
    }
    this.stack = error.stack || new Error().stack;
}
JitsiTrackError.prototype = Object.create(Error.prototype);
JitsiTrackError.prototype.constructor = JitsiTrackError;
/**
 * Gets failed resolution constraint from corresponding object.
 * @param {string} failedConstraintName
 * @param {Object} constraints
 * @returns {string|number}
 */
function getResolutionFromFailedConstraint(failedConstraintName, constraints) {
    if (constraints && constraints.video && constraints.video.mandatory) {
        switch (failedConstraintName) {
            case 'width':
                return constraints.video.mandatory.minWidth;
            case 'height':
                return constraints.video.mandatory.minHeight;
            default:
                return constraints.video.mandatory[failedConstraintName] || '';
        }
    }
    return '';
}
/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (JitsiTrackError);
//# sourceMappingURL=JitsiTrackError.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/JitsiTrackErrors.js":
/*!*************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/JitsiTrackErrors.js ***!
  \*************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   CONSTRAINT_FAILED: () => (/* binding */ CONSTRAINT_FAILED),
/* harmony export */   ELECTRON_DESKTOP_PICKER_ERROR: () => (/* binding */ ELECTRON_DESKTOP_PICKER_ERROR),
/* harmony export */   ELECTRON_DESKTOP_PICKER_NOT_FOUND: () => (/* binding */ ELECTRON_DESKTOP_PICKER_NOT_FOUND),
/* harmony export */   GENERAL: () => (/* binding */ GENERAL),
/* harmony export */   JitsiTrackErrors: () => (/* binding */ JitsiTrackErrors),
/* harmony export */   NOT_FOUND: () => (/* binding */ NOT_FOUND),
/* harmony export */   PERMISSION_DENIED: () => (/* binding */ PERMISSION_DENIED),
/* harmony export */   SCREENSHARING_GENERIC_ERROR: () => (/* binding */ SCREENSHARING_GENERIC_ERROR),
/* harmony export */   SCREENSHARING_USER_CANCELED: () => (/* binding */ SCREENSHARING_USER_CANCELED),
/* harmony export */   TIMEOUT: () => (/* binding */ TIMEOUT),
/* harmony export */   TRACK_IS_DISPOSED: () => (/* binding */ TRACK_IS_DISPOSED),
/* harmony export */   TRACK_NO_STREAM_FOUND: () => (/* binding */ TRACK_NO_STREAM_FOUND),
/* harmony export */   UNSUPPORTED_RESOLUTION: () => (/* binding */ UNSUPPORTED_RESOLUTION)
/* harmony export */ });
/**
 * The errors for the JitsiTrack objects.
 */
var JitsiTrackErrors;
(function (JitsiTrackErrors) {
    /**
     * An error which indicates that some of requested constraints in
     * getUserMedia call were not satisfied.
     */
    JitsiTrackErrors["CONSTRAINT_FAILED"] = "gum.constraint_failed";
    /**
     * A generic error which indicates an error occurred while selecting
     * a DesktopCapturerSource from the electron app.
     */
    JitsiTrackErrors["ELECTRON_DESKTOP_PICKER_ERROR"] = "gum.electron_desktop_picker_error";
    /**
     * An error which indicates a custom desktop picker could not be detected
     * for the electron app.
     */
    JitsiTrackErrors["ELECTRON_DESKTOP_PICKER_NOT_FOUND"] = "gum.electron_desktop_picker_not_found";
    /**
     * Generic getUserMedia error.
     */
    JitsiTrackErrors["GENERAL"] = "gum.general";
    /**
     * An error which indicates that requested device was not found.
     */
    JitsiTrackErrors["NOT_FOUND"] = "gum.not_found";
    /**
     * An error which indicates that user denied permission to share requested
     * device.
     */
    JitsiTrackErrors["PERMISSION_DENIED"] = "gum.permission_denied";
    /**
     * Generic error for screensharing failure.
     */
    JitsiTrackErrors["SCREENSHARING_GENERIC_ERROR"] = "gum.screensharing_generic_error";
    /**
     * An error which indicates that user canceled screen sharing window
     * selection dialog.
     */
    JitsiTrackErrors["SCREENSHARING_USER_CANCELED"] = "gum.screensharing_user_canceled";
    /**
     * Indicates that the timeout passed to the obtainAudioAndVideoPermissions has expired without GUM resolving.
     */
    JitsiTrackErrors["TIMEOUT"] = "gum.timeout";
    /**
     * An error which indicates that track has been already disposed and cannot
     * be longer used.
     */
    JitsiTrackErrors["TRACK_IS_DISPOSED"] = "track.track_is_disposed";
    /**
     * An error which indicates that track has no MediaStream associated.
     */
    JitsiTrackErrors["TRACK_NO_STREAM_FOUND"] = "track.no_stream_found";
    /**
     * An error which indicates that requested video resolution is not supported
     * by a webcam.
     */
    JitsiTrackErrors["UNSUPPORTED_RESOLUTION"] = "gum.unsupported_resolution";
})(JitsiTrackErrors || (JitsiTrackErrors = {}));
// exported for backward compatibility
const CONSTRAINT_FAILED = JitsiTrackErrors.CONSTRAINT_FAILED;
const ELECTRON_DESKTOP_PICKER_ERROR = JitsiTrackErrors.ELECTRON_DESKTOP_PICKER_ERROR;
const ELECTRON_DESKTOP_PICKER_NOT_FOUND = JitsiTrackErrors.ELECTRON_DESKTOP_PICKER_NOT_FOUND;
const GENERAL = JitsiTrackErrors.GENERAL;
const NOT_FOUND = JitsiTrackErrors.NOT_FOUND;
const PERMISSION_DENIED = JitsiTrackErrors.PERMISSION_DENIED;
const SCREENSHARING_GENERIC_ERROR = JitsiTrackErrors.SCREENSHARING_GENERIC_ERROR;
const SCREENSHARING_USER_CANCELED = JitsiTrackErrors.SCREENSHARING_USER_CANCELED;
const TIMEOUT = JitsiTrackErrors.TIMEOUT;
const TRACK_IS_DISPOSED = JitsiTrackErrors.TRACK_IS_DISPOSED;
const TRACK_NO_STREAM_FOUND = JitsiTrackErrors.TRACK_NO_STREAM_FOUND;
const UNSUPPORTED_RESOLUTION = JitsiTrackErrors.UNSUPPORTED_RESOLUTION;
//# sourceMappingURL=JitsiTrackErrors.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/JitsiTrackEvents.js":
/*!*************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/JitsiTrackEvents.js ***!
  \*************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   JitsiTrackEvents: () => (/* binding */ JitsiTrackEvents),
/* harmony export */   LOCAL_TRACK_STOPPED: () => (/* binding */ LOCAL_TRACK_STOPPED),
/* harmony export */   NO_AUDIO_INPUT: () => (/* binding */ NO_AUDIO_INPUT),
/* harmony export */   NO_DATA_FROM_SOURCE: () => (/* binding */ NO_DATA_FROM_SOURCE),
/* harmony export */   TRACK_AUDIO_LEVEL_CHANGED: () => (/* binding */ TRACK_AUDIO_LEVEL_CHANGED),
/* harmony export */   TRACK_AUDIO_OUTPUT_CHANGED: () => (/* binding */ TRACK_AUDIO_OUTPUT_CHANGED),
/* harmony export */   TRACK_MUTE_CHANGED: () => (/* binding */ TRACK_MUTE_CHANGED),
/* harmony export */   TRACK_OWNER_CHANGED: () => (/* binding */ TRACK_OWNER_CHANGED),
/* harmony export */   TRACK_REMOVED: () => (/* binding */ TRACK_REMOVED),
/* harmony export */   TRACK_STREAMING_STATUS_CHANGED: () => (/* binding */ TRACK_STREAMING_STATUS_CHANGED),
/* harmony export */   TRACK_VIDEOTYPE_CHANGED: () => (/* binding */ TRACK_VIDEOTYPE_CHANGED)
/* harmony export */ });
var JitsiTrackEvents;
(function (JitsiTrackEvents) {
    /**
     * The media track was removed to the conference.
     */
    JitsiTrackEvents["LOCAL_TRACK_STOPPED"] = "track.stopped";
    /**
     * Audio levels of a this track was changed.
     * The first argument is a number with audio level value in range [0, 1].
     * The second argument is a <tt>TraceablePeerConnection</tt> which is the peer
     * connection which measured the audio level (one audio track can be added
     * to multiple peer connection at the same time). This argument is optional for
     * local tracks for which we can measure audio level without the peer
     * connection (the value will be <tt>undefined</tt>).
     *
     * NOTE The second argument should be treated as library internal and can be
     * removed at any time.
     */
    JitsiTrackEvents["TRACK_AUDIO_LEVEL_CHANGED"] = "track.audioLevelsChanged";
    /**
     * The audio output of the track was changed.
     */
    JitsiTrackEvents["TRACK_AUDIO_OUTPUT_CHANGED"] = "track.audioOutputChanged";
    /**
     * A media track mute status was changed.
     */
    JitsiTrackEvents["TRACK_MUTE_CHANGED"] = "track.trackMuteChanged";
    /**
     * The video type("camera" or "desktop") of the track was changed.
     */
    JitsiTrackEvents["TRACK_VIDEOTYPE_CHANGED"] = "track.videoTypeChanged";
    /**
     * Indicates that the track is not receiving any data even though we expect it
     * to receive data (i.e. the stream is not stopped).
     */
    JitsiTrackEvents["NO_DATA_FROM_SOURCE"] = "track.no_data_from_source";
    /**
     * Indicates that the local audio track is not receiving any audio input from
     * the microphone that is currently selected.
     */
    JitsiTrackEvents["NO_AUDIO_INPUT"] = "track.no_audio_input";
    /**
     * Event fired whenever video track's streaming changes.
     * First argument is the sourceName of the track and the second is a string indicating if the connection is currently
     * - active - the connection is active.
     * - inactive - the connection is inactive, was intentionally interrupted by the bridge because of low BWE or because
     *   of the endpoint falling out of last N.
     * - interrupted - a network problem occurred.
     * - restoring - the connection was inactive and is restoring now.
     *
     * The current status value can be obtained by calling JitsiRemoteTrack.getTrackStreamingStatus().
     */
    JitsiTrackEvents["TRACK_STREAMING_STATUS_CHANGED"] = "track.streaming_status_changed";
    /**
     * An SSRC has been remapped. The track is now associated with a new participant.
     */
    JitsiTrackEvents["TRACK_OWNER_CHANGED"] = "track.owner_changed";
    /**
     * A track is being removed. Fired when a session terminates for tracks
     * that persist in ssrc-rewriting mode.
     */
    JitsiTrackEvents["TRACK_REMOVED"] = "track.removed";
})(JitsiTrackEvents || (JitsiTrackEvents = {}));
;
// exported for backward compatibility
const LOCAL_TRACK_STOPPED = JitsiTrackEvents.LOCAL_TRACK_STOPPED;
const TRACK_AUDIO_LEVEL_CHANGED = JitsiTrackEvents.TRACK_AUDIO_LEVEL_CHANGED;
const TRACK_AUDIO_OUTPUT_CHANGED = JitsiTrackEvents.TRACK_AUDIO_OUTPUT_CHANGED;
const TRACK_MUTE_CHANGED = JitsiTrackEvents.TRACK_MUTE_CHANGED;
const TRACK_VIDEOTYPE_CHANGED = JitsiTrackEvents.TRACK_VIDEOTYPE_CHANGED;
const NO_DATA_FROM_SOURCE = JitsiTrackEvents.NO_DATA_FROM_SOURCE;
const NO_AUDIO_INPUT = JitsiTrackEvents.NO_AUDIO_INPUT;
const TRACK_STREAMING_STATUS_CHANGED = JitsiTrackEvents.TRACK_STREAMING_STATUS_CHANGED;
const TRACK_OWNER_CHANGED = JitsiTrackEvents.TRACK_OWNER_CHANGED;
const TRACK_REMOVED = JitsiTrackEvents.TRACK_REMOVED;
//# sourceMappingURL=JitsiTrackEvents.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/JitsiTranscriptionStatus.js":
/*!*********************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/JitsiTranscriptionStatus.js ***!
  \*********************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   JitsiTranscriptionStatus: () => (/* binding */ JitsiTranscriptionStatus),
/* harmony export */   OFF: () => (/* binding */ OFF),
/* harmony export */   ON: () => (/* binding */ ON)
/* harmony export */ });
var JitsiTranscriptionStatus;
(function (JitsiTranscriptionStatus) {
    /**
     * The transcription is on.
     */
    JitsiTranscriptionStatus["ON"] = "on";
    /**
     * The transcription is off.
     */
    JitsiTranscriptionStatus["OFF"] = "off";
})(JitsiTranscriptionStatus || (JitsiTranscriptionStatus = {}));
// exported for backward compatibility
const ON = JitsiTranscriptionStatus.ON;
const OFF = JitsiTranscriptionStatus.OFF;
//# sourceMappingURL=JitsiTranscriptionStatus.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/authenticateAndUpgradeRole.js":
/*!***********************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/authenticateAndUpgradeRole.js ***!
  \***********************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (/* binding */ authenticateAndUpgradeRole)
/* harmony export */ });
/* harmony import */ var _JitsiConnectionEvents__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./JitsiConnectionEvents */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/JitsiConnectionEvents.js");
/* harmony import */ var _modules_xmpp_xmpp__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./modules/xmpp/xmpp */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/xmpp/xmpp.js");


/**
 * @typedef {Object} UpgradeRoleError
 *
 * @property {JitsiConnectionErrors} [connectionError] - One of
 * {@link JitsiConnectionErrors} which occurred when trying to connect to the
 * XMPP server.
 * @property {String} [authenticationError] - One of XMPP error conditions
 * returned by Jicofo on authentication attempt. See
 * {@link https://xmpp.org/rfcs/rfc3920.html#streams-error}.
 * @property {String} [message] - More details about the error.
 * @property {Object} [credentials] - The credentials that failed the
 * authentication.
 * @property {String} [credentials.jid] - The XMPP ID part of the credentials
 * that failed the authentication.
 * @property {string} [credentials.password] - The password part of the
 * credentials that failed the authentication.
 *
 * NOTE If neither one of the errors is present, then the operation has been
 * canceled.
 */
/* eslint-disable no-invalid-this */
/**
 * Connects to the XMPP server using the specified credentials and contacts
 * Jicofo in order to obtain a session ID (which is then stored in the local
 * storage). The user's role of the parent conference will be upgraded to
 * moderator (by Jicofo). It's also used to join the conference when starting
 * from anonymous domain and only authenticated users are allowed to create new
 * rooms.
 *
 * @param {Object} options
 * @param {string} options.id - XMPP user's ID to log in. For example,
 * user@xmpp-server.com.
 * @param {string} options.password - XMPP user's password to log in with.
 * @param {Function} [options.onLoginSuccessful] - Callback called when logging
 * into the XMPP server was successful. The next step will be to obtain a new
 * session ID from Jicofo and join the MUC using it which will effectively
 * upgrade the user's role to moderator.
 * @returns {Object} A <tt>thenable</tt> which (1) settles when the process of
 * authenticating and upgrading the role of the specified XMPP user finishes and
 * (2) has a <tt>cancel</tt> method that allows the caller to interrupt the
 * process. If the process finishes successfully, the session ID has been stored
 * in the settings and the <tt>thenable</tt> is resolved. If the process
 * finishes with failure, the <tt>thenable</tt> is rejected with reason of type
 * {@link UpgradeRoleError} which will have either <tt>connectionError</tt> or
 * <tt>authenticationError</tt> property set depending on which of the steps has
 * failed. If <tt>cancel</tt> is called before the process finishes, then the
 * thenable will be rejected with an empty object (i.e. no error property will
 * be set on the rejection reason).
 */
function authenticateAndUpgradeRole({ 
// 1. Log the specified XMPP user in.
id, password, onCreateResource, 
// 2. Let the API client/consumer know as soon as the XMPP user has been
//    successfully logged in.
onLoginSuccessful }) {
    let canceled = false;
    let rejectPromise;
    let xmpp = new _modules_xmpp_xmpp__WEBPACK_IMPORTED_MODULE_1__["default"](this.connection.options);
    const process = new Promise((resolve, reject) => {
        // The process is represented by a Thenable with a cancel method. The
        // Thenable is implemented using Promise and the cancel using the
        // Promise's reject function.
        rejectPromise = reject;
        xmpp.addListener(_JitsiConnectionEvents__WEBPACK_IMPORTED_MODULE_0__.CONNECTION_DISCONNECTED, () => {
            xmpp = undefined;
        });
        xmpp.addListener(_JitsiConnectionEvents__WEBPACK_IMPORTED_MODULE_0__.CONNECTION_ESTABLISHED, () => {
            if (canceled) {
                return;
            }
            // Let the caller know that the XMPP login was successful.
            onLoginSuccessful && onLoginSuccessful();
            // Now authenticate with Jicofo and get a new session ID.
            const room = xmpp.createRoom(this.options.name, this.options.config, onCreateResource);
            room.moderator.authenticate()
                .then(() => {
                xmpp && xmpp.disconnect();
                if (canceled) {
                    return;
                }
                // At this point we should have the new session ID
                // stored in the settings. Send a new conference IQ.
                this.room.moderator.sendConferenceRequest().finally(resolve);
            })
                .catch(({ error, message }) => {
                xmpp.disconnect();
                reject({
                    authenticationError: error,
                    message
                });
            });
        });
        xmpp.addListener(_JitsiConnectionEvents__WEBPACK_IMPORTED_MODULE_0__.CONNECTION_FAILED, (connectionError, message, credentials) => {
            reject({
                connectionError,
                credentials,
                message
            });
            xmpp = undefined;
        });
        canceled || xmpp.connect(id, password);
    });
    /**
     * Cancels the process, if it's in progress, of authenticating and upgrading
     * the role of the local participant/user.
     *
     * @public
     * @returns {void}
     */
    process.cancel = () => {
        canceled = true;
        rejectPromise({});
        xmpp && xmpp.disconnect();
    };
    return process;
}
/* eslint-enable no-invalid-this */
//# sourceMappingURL=authenticateAndUpgradeRole.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/RTC/BridgeChannel.js":
/*!**********************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/RTC/BridgeChannel.js ***!
  \**********************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
var __filename = "/index.js";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (/* binding */ BridgeChannel)
/* harmony export */ });
/* harmony import */ var _jitsi_logger__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @jitsi/logger */ "./node_modules/@jitsi/logger/lib/index.js");
/* harmony import */ var _jitsi_logger__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(_jitsi_logger__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var _service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../service/RTC/RTCEvents */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/RTC/RTCEvents.js");
/* harmony import */ var _service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../service/statistics/AnalyticsEvents */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/statistics/AnalyticsEvents.js");
/* harmony import */ var _statistics_statistics__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../statistics/statistics */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/statistics/statistics.js");
/* harmony import */ var _util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../util/GlobalOnErrorHandler */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/util/GlobalOnErrorHandler.js");
/* harmony import */ var _util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_4___default = /*#__PURE__*/__webpack_require__.n(_util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_4__);





const logger = (0,_jitsi_logger__WEBPACK_IMPORTED_MODULE_0__.getLogger)(__filename);
/**
 * Handles a WebRTC RTCPeerConnection or a WebSocket instance to communicate
 * with the videobridge.
 */
class BridgeChannel {
    /**
     * Binds "ondatachannel" event listener on the given RTCPeerConnection
     * instance, or creates a WebSocket connection with the videobridge.
     * At least one of both, peerconnection or wsUrl parameters, must be
     * given.
     * @param {RTCPeerConnection} [peerconnection] WebRTC peer connection
     * instance.
     * @param {string} [wsUrl] WebSocket URL.
     * @param {EventEmitter} emitter the EventEmitter instance to use for event emission.
     * @param {JitsiConference} conference the conference instance.
     */
    constructor(peerconnection, wsUrl, emitter, conference) {
        if (!peerconnection && !wsUrl) {
            throw new TypeError('At least peerconnection or wsUrl must be given');
        }
        else if (peerconnection && wsUrl) {
            throw new TypeError('Just one of peerconnection or wsUrl must be given');
        }
        if (peerconnection) {
            logger.debug('constructor() with peerconnection');
        }
        else {
            logger.debug(`constructor() with wsUrl:"${wsUrl}"`);
        }
        // The underlying WebRTC RTCDataChannel or WebSocket instance.
        // @type {RTCDataChannel|WebSocket}
        this._channel = null;
        // The conference that uses this bridge channel.
        this._conference = conference;
        // Whether the channel is connected or not. It will start as undefined
        // for the first connection attempt. Then transition to either true or false.
        this._connected = undefined;
        // @type {EventEmitter}
        this._eventEmitter = emitter;
        // Whether a RTCDataChannel or WebSocket is internally used.
        // @type {string} "datachannel" / "websocket"
        this._mode = null;
        // Indicates whether the connection retries are enabled or not.
        this._areRetriesEnabled = false;
        // Indicates whether the connection was closed from the client or not.
        this._closedFromClient = false;
        // If a RTCPeerConnection is given, listen for new RTCDataChannel
        // event.
        if (peerconnection) {
            const datachannel = peerconnection.createDataChannel('JVB data channel', {
                protocol: 'http://jitsi.org/protocols/colibri'
            });
            // Handle the RTCDataChannel.
            this._handleChannel(datachannel);
            this._mode = 'datachannel';
            // Otherwise create a WebSocket connection.
        }
        else if (wsUrl) {
            this._areRetriesEnabled = true;
            this._wsUrl = wsUrl;
            this._initWebSocket();
        }
    }
    /**
     * Initializes the web socket channel.
     *
     * @returns {void}
     */
    _initWebSocket() {
        // Create a WebSocket instance.
        const ws = new WebSocket(this._wsUrl);
        // Handle the WebSocket.
        this._handleChannel(ws);
        this._mode = 'websocket';
    }
    /**
     * Starts the websocket connection retries.
     *
     * @returns {void}
     */
    _startConnectionRetries() {
        let timeoutS = 1;
        const reload = () => {
            const isConnecting = this._channel && (this._channel.readyState === 'connecting'
                || this._channel.readyState === WebSocket.CONNECTING);
            // Should not spawn new websockets while one is already trying to connect.
            if (isConnecting) {
                // Timeout is still required as there is flag `_areRetriesEnabled` that
                // blocks new retrying cycles until any channel opens in current cycle.
                this._retryTimeout = setTimeout(reload, timeoutS * 1000);
                return;
            }
            if (this.isOpen()) {
                return;
            }
            this._initWebSocket(this._wsUrl);
            timeoutS = Math.min(timeoutS * 2, 60);
            this._retryTimeout = setTimeout(reload, timeoutS * 1000);
        };
        this._retryTimeout = setTimeout(reload, timeoutS * 1000);
    }
    /**
     * Stops the websocket connection retries.
     *
     * @returns {void}
     */
    _stopConnectionRetries() {
        if (this._retryTimeout) {
            clearTimeout(this._retryTimeout);
            this._retryTimeout = undefined;
        }
    }
    /**
     * Retries to establish the websocket connection after the connection was closed by the server.
     *
     * @param {CloseEvent} closeEvent - The close event that triggered the retries.
     * @returns {void}
     */
    _retryWebSocketConnection(closeEvent) {
        if (!this._areRetriesEnabled) {
            return;
        }
        const { code, reason } = closeEvent;
        _statistics_statistics__WEBPACK_IMPORTED_MODULE_3__["default"].sendAnalytics((0,_service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_2__.createBridgeChannelClosedEvent)(code, reason));
        this._areRetriesEnabled = false;
        this._eventEmitter.once(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_1__["default"].DATA_CHANNEL_OPEN, () => {
            this._stopConnectionRetries();
            this._areRetriesEnabled = true;
        });
        this._startConnectionRetries();
    }
    /**
     * The channel mode.
     * @return {string} "datachannel" or "websocket" (or null if not yet set).
     */
    get mode() {
        return this._mode;
    }
    /**
     * Closes the currently opened channel.
     */
    close() {
        this._closedFromClient = true;
        this._stopConnectionRetries();
        this._areRetriesEnabled = false;
        if (this._channel) {
            try {
                this._channel.close();
            }
            catch (error) { } // eslint-disable-line no-empty
            this._channel = null;
        }
    }
    /**
     * Whether there is an underlying RTCDataChannel or WebSocket and it's
     * open.
     * @return {boolean}
     */
    isOpen() {
        return this._channel && (this._channel.readyState === 'open'
            || this._channel.readyState === WebSocket.OPEN);
    }
    /**
     * Sends local stats via the bridge channel.
     * @param {Object} payload The payload of the message.
     * @throws NetworkError/InvalidStateError/Error if the operation fails or if there is no data channel created.
     */
    sendEndpointStatsMessage(payload) {
        this._send(Object.assign({ colibriClass: 'EndpointStats' }, payload));
    }
    /**
     * Sends message via the channel.
     * @param {string} to The id of the endpoint that should receive the
     * message. If "" the message will be sent to all participants.
     * @param  {object} payload The payload of the message.
     * @throws NetworkError or InvalidStateError from RTCDataChannel#send (@see
     * {@link https://developer.mozilla.org/docs/Web/API/RTCDataChannel/send})
     * or from WebSocket#send or Error with "No opened channel" message.
     */
    sendMessage(to, payload) {
        this._send({
            colibriClass: 'EndpointMessage',
            msgPayload: payload,
            to
        });
    }
    /**
     * Sends a "lastN value changed" message via the channel.
     * @param {number} value The new value for lastN. -1 means unlimited.
     */
    sendSetLastNMessage(value) {
        logger.log(`Sending lastN=${value}.`);
        this._send({
            colibriClass: 'LastNChangedEvent',
            lastN: value
        });
    }
    /**
     * Sends a 'ReceiverVideoConstraints' message via the bridge channel.
     *
     * @param {ReceiverVideoConstraints} constraints video constraints.
     */
    sendReceiverVideoConstraintsMessage(constraints) {
        logger.log(`Sending ReceiverVideoConstraints with ${JSON.stringify(constraints)}`);
        this._send(Object.assign({ colibriClass: 'ReceiverVideoConstraints' }, constraints));
    }
    /**
     * Sends a 'SourceVideoTypeMessage' message via the bridge channel.
     *
     * @param {BridgeVideoType} videoType - the video type.
     * @param {SourceName} sourceName - the source name of the video track.
     * @returns {void}
     */
    sendSourceVideoTypeMessage(sourceName, videoType) {
        logger.info(`Sending SourceVideoTypeMessage with video type ${sourceName}: ${videoType}`);
        this._send({
            colibriClass: 'SourceVideoTypeMessage',
            sourceName,
            videoType
        });
    }
    /**
     * Set events on the given RTCDataChannel or WebSocket instance.
     */
    _handleChannel(channel) {
        const emitter = this._eventEmitter;
        channel.onopen = () => {
            logger.info(`${this._mode} channel opened`);
            this._connected = true;
            emitter.emit(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_1__["default"].DATA_CHANNEL_OPEN);
        };
        channel.onerror = event => {
            // WS error events contain no information about the failure (this is available in the onclose event) and
            // the event references the WS object itself, which causes hangs on mobile.
            if (this._mode !== 'websocket') {
                logger.error(`Channel error: ${event.message}`);
            }
        };
        channel.onmessage = ({ data }) => {
            // JSON object.
            let obj;
            try {
                obj = JSON.parse(data);
            }
            catch (error) {
                _util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_4___default().callErrorHandler(error);
                logger.error('Failed to parse channel message as JSON: ', data, error);
                return;
            }
            const colibriClass = obj.colibriClass;
            switch (colibriClass) {
                case 'DominantSpeakerEndpointChangeEvent': {
                    const { dominantSpeakerEndpoint, previousSpeakers = [], silence } = obj;
                    logger.debug(`Dominant speaker: ${dominantSpeakerEndpoint}, previous speakers: ${previousSpeakers}`);
                    emitter.emit(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_1__["default"].DOMINANT_SPEAKER_CHANGED, dominantSpeakerEndpoint, previousSpeakers, silence);
                    break;
                }
                case 'EndpointConnectivityStatusChangeEvent': {
                    const endpoint = obj.endpoint;
                    const isActive = obj.active === 'true';
                    logger.info(`Endpoint connection status changed: ${endpoint} active=${isActive}`);
                    emitter.emit(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_1__["default"].ENDPOINT_CONN_STATUS_CHANGED, endpoint, isActive);
                    break;
                }
                case 'EndpointMessage': {
                    emitter.emit(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_1__["default"].ENDPOINT_MESSAGE_RECEIVED, obj.from, obj.msgPayload);
                    break;
                }
                case 'EndpointStats': {
                    emitter.emit(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_1__["default"].ENDPOINT_STATS_RECEIVED, obj.from, obj);
                    break;
                }
                case 'ForwardedSources': {
                    const forwardedSources = obj.forwardedSources;
                    logger.info(`New forwarded sources: ${forwardedSources}`);
                    emitter.emit(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_1__["default"].FORWARDED_SOURCES_CHANGED, forwardedSources);
                    break;
                }
                case 'SenderSourceConstraints': {
                    if (typeof obj.sourceName === 'string' && typeof obj.maxHeight === 'number') {
                        logger.info(`SenderSourceConstraints: ${obj.sourceName} - ${obj.maxHeight}`);
                        emitter.emit(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_1__["default"].SENDER_VIDEO_CONSTRAINTS_CHANGED, obj);
                    }
                    else {
                        logger.error(`Invalid SenderSourceConstraints: ${obj.sourceName} - ${obj.maxHeight}`);
                    }
                    break;
                }
                case 'ServerHello': {
                    logger.info(`Received ServerHello, version=${obj.version}.`);
                    break;
                }
                case 'VideoSourcesMap': {
                    logger.info(`Received VideoSourcesMap: ${JSON.stringify(obj.mappedSources)}`);
                    emitter.emit(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_1__["default"].VIDEO_SSRCS_REMAPPED, obj);
                    break;
                }
                case 'AudioSourcesMap': {
                    logger.info(`Received AudioSourcesMap: ${JSON.stringify(obj.mappedSources)}`);
                    emitter.emit(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_1__["default"].AUDIO_SSRCS_REMAPPED, obj);
                    break;
                }
                default: {
                    logger.debug('Channel JSON-formatted message: ', obj);
                    // The received message appears to be appropriately formatted
                    // (i.e. is a JSON object which assigns a value to the
                    // mandatory property colibriClass) so don't just swallow it,
                    // expose it to public consumption.
                    emitter.emit(`rtc.datachannel.${colibriClass}`, obj);
                }
            }
        };
        channel.onclose = event => {
            logger.debug(`Channel closed by ${this._closedFromClient ? 'client' : 'server'}`);
            if (channel !== this._channel) {
                logger.debug('Skip close handler, channel instance is not equal to stored one');
                return;
            }
            // When the JVB closes the connection gracefully due to the participant being alone in the meeting it uses
            // code 1001. However, the same code is also used by Cloudflare when it terminates the ws. Therefore, check
            // for the number of remote participants in the call and abort retries only when the endpoint is the only
            // endpoint in the call.
            const isGracefulClose = this._closedFromClient
                || (event.code === 1001 && this._conference.getParticipantCount() === 1);
            if (!isGracefulClose) {
                const { code, reason } = event;
                logger.error(`Channel closed: ${code} ${reason}`);
                if (this._mode === 'websocket') {
                    this._retryWebSocketConnection(event);
                    // We only want to send this event the first time the failure happens.
                    if (this._connected !== false) {
                        emitter.emit(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_1__["default"].DATA_CHANNEL_CLOSED, {
                            code,
                            reason
                        });
                    }
                }
            }
            this._connected = false;
            // Remove the channel.
            this._channel = null;
        };
        // Store the channel.
        this._channel = channel;
    }
    /**
     * Sends passed object via the channel.
     * @param {object} jsonObject The object that will be sent.
     * @throws NetworkError or InvalidStateError from RTCDataChannel#send (@see
     * {@link https://developer.mozilla.org/docs/Web/API/RTCDataChannel/send})
     * or from WebSocket#send or Error with "No opened channel" message.
     */
    _send(jsonObject) {
        const channel = this._channel;
        if (!this.isOpen()) {
            logger.error('Bridge Channel send: no opened channel.');
            throw new Error('No opened channel');
        }
        channel.send(JSON.stringify(jsonObject));
    }
}
//# sourceMappingURL=BridgeChannel.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/RTC/CodecSelection.js":
/*!***********************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/RTC/CodecSelection.js ***!
  \***********************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
var __filename = "/index.js";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   CodecSelection: () => (/* binding */ CodecSelection)
/* harmony export */ });
/* harmony import */ var _jitsi_logger__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @jitsi/logger */ "./node_modules/@jitsi/logger/lib/index.js");
/* harmony import */ var _jitsi_logger__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(_jitsi_logger__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var _JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../JitsiConferenceEvents */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/JitsiConferenceEvents.js");
/* harmony import */ var _service_RTC_CodecMimeType__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../service/RTC/CodecMimeType */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/RTC/CodecMimeType.js");
/* harmony import */ var _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../service/RTC/MediaType */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/RTC/MediaType.js");
/* harmony import */ var _browser__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../browser */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/browser/index.js");





const logger = (0,_jitsi_logger__WEBPACK_IMPORTED_MODULE_0__.getLogger)(__filename);
// Default video codec preferences on mobile and desktop endpoints.
const DESKTOP_VIDEO_CODEC_ORDER = [_service_RTC_CodecMimeType__WEBPACK_IMPORTED_MODULE_2__["default"].VP9, _service_RTC_CodecMimeType__WEBPACK_IMPORTED_MODULE_2__["default"].VP8, _service_RTC_CodecMimeType__WEBPACK_IMPORTED_MODULE_2__["default"].H264];
const MOBILE_P2P_VIDEO_CODEC_ORDER = [_service_RTC_CodecMimeType__WEBPACK_IMPORTED_MODULE_2__["default"].H264, _service_RTC_CodecMimeType__WEBPACK_IMPORTED_MODULE_2__["default"].VP8, _service_RTC_CodecMimeType__WEBPACK_IMPORTED_MODULE_2__["default"].VP9];
const MOBILE_VIDEO_CODEC_ORDER = [_service_RTC_CodecMimeType__WEBPACK_IMPORTED_MODULE_2__["default"].VP8, _service_RTC_CodecMimeType__WEBPACK_IMPORTED_MODULE_2__["default"].VP9, _service_RTC_CodecMimeType__WEBPACK_IMPORTED_MODULE_2__["default"].H264];
/**
 * This class handles the codec selection mechanism for the conference based on the config.js settings.
 * The preferred codec is selected based on the settings and the list of codecs supported by the browser.
 * The preferred codec is published in presence which is then used by the other endpoints in the
 * conference to pick a supported codec at join time and when the call transitions between p2p and jvb
 * connections.
 */
class CodecSelection {
    /**
     * Creates a new instance for a given conference.
     *
     * @param {JitsiConference} conference the conference instance
     * @param {*} options
     * @param {string} options.jvb settings (codec list, preferred and disabled) for the jvb connection.
     * @param {string} options.p2p settings (codec list, preferred and disabled) for the p2p connection.
     */
    constructor(conference, options) {
        this.conference = conference;
        this.options = options;
        this.codecPreferenceOrder = {};
        for (const connectionType of Object.keys(options)) {
            // eslint-disable-next-line prefer-const
            let { disabledCodec, preferredCodec, preferenceOrder } = options[connectionType];
            const supportedCodecs = new Set(this._getSupportedVideoCodecs(connectionType));
            // Default preference codec order when no codec preferences are set in config.js
            let selectedOrder = Array.from(supportedCodecs);
            if (preferenceOrder) {
                preferenceOrder = preferenceOrder.map(codec => codec.toLowerCase());
                // Select all codecs that are supported by the browser.
                selectedOrder = preferenceOrder.filter(codec => supportedCodecs.has(codec));
                // Generate the codec list based on the supported codecs and the preferred/disabled (deprecated) settings
            }
            else if (preferredCodec || disabledCodec) {
                disabledCodec = disabledCodec === null || disabledCodec === void 0 ? void 0 : disabledCodec.toLowerCase();
                preferredCodec = preferredCodec === null || preferredCodec === void 0 ? void 0 : preferredCodec.toLowerCase();
                // VP8 cannot be disabled since it the default codec.
                if (disabledCodec && disabledCodec !== _service_RTC_CodecMimeType__WEBPACK_IMPORTED_MODULE_2__["default"].VP8) {
                    selectedOrder = selectedOrder.filter(codec => codec !== disabledCodec);
                }
                const index = selectedOrder.findIndex(codec => codec === preferredCodec);
                // Move the preferred codec to the top of the list.
                if (preferredCodec && index !== -1) {
                    selectedOrder.splice(index, 1);
                    selectedOrder.unshift(preferredCodec);
                }
            }
            // Push VP9 to the end of the list so that the client continues to decode VP9 even if its not
            // preferable to encode VP9 (because of browser bugs on the encoding side or added complexity on mobile
            // devices).
            if (!_browser__WEBPACK_IMPORTED_MODULE_4__["default"].supportsVP9() || this.conference.isE2EEEnabled()) {
                const index = selectedOrder.findIndex(codec => codec === _service_RTC_CodecMimeType__WEBPACK_IMPORTED_MODULE_2__["default"].VP9);
                if (index !== -1) {
                    selectedOrder.splice(index, 1);
                    // Remove VP9 from the list when E2EE is enabled since it is not supported.
                    // TODO - remove this check when support for VP9-E2EE is introduced.
                    if (!this.conference.isE2EEEnabled()) {
                        selectedOrder.push(_service_RTC_CodecMimeType__WEBPACK_IMPORTED_MODULE_2__["default"].VP9);
                    }
                }
            }
            logger.info(`Codec preference order for ${connectionType} connection is ${selectedOrder}`);
            this.codecPreferenceOrder[connectionType] = selectedOrder;
        }
        this.conference.on(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_1__._MEDIA_SESSION_STARTED, session => this._selectPreferredCodec(session));
        this.conference.on(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_1__.USER_JOINED, () => this._selectPreferredCodec());
        this.conference.on(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_1__.USER_LEFT, () => this._selectPreferredCodec());
    }
    /**
     * Returns a list of video codecs that are supported by the browser.
     *
     * @param {string} connectionType - media connection type, p2p or jvb.
     * @returns {Array}
     */
    _getSupportedVideoCodecs(connectionType) {
        const videoCodecMimeTypes = _browser__WEBPACK_IMPORTED_MODULE_4__["default"].isMobileDevice() && connectionType === 'p2p'
            ? MOBILE_P2P_VIDEO_CODEC_ORDER
            : _browser__WEBPACK_IMPORTED_MODULE_4__["default"].isMobileDevice() ? MOBILE_VIDEO_CODEC_ORDER : DESKTOP_VIDEO_CODEC_ORDER;
        return videoCodecMimeTypes.filter(codec => {
            var _a, _b, _c, _d;
            return ((_d = (_c = (_b = (_a = window.RTCRtpReceiver) === null || _a === void 0 ? void 0 : _a.getCapabilities) === null || _b === void 0 ? void 0 : _b.call(_a, _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_3__.MediaType.VIDEO)) === null || _c === void 0 ? void 0 : _c.codecs) !== null && _d !== void 0 ? _d : [])
                .some(supportedCodec => supportedCodec.mimeType.toLowerCase() === `${_service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_3__.MediaType.VIDEO}/${codec}`);
        });
    }
    /**
     * Filters VP9 from the list of the preferred video codecs for JVB if E2EE is enabled.
     *
     * @returns {Array}
     */
    _maybeFilterJvbCodecs() {
        // TODO - remove this check when support for VP9-E2EE is introduced.
        if (this.conference.isE2EEEnabled()) {
            return this.codecPreferenceOrder.jvb.filter(codec => codec !== _service_RTC_CodecMimeType__WEBPACK_IMPORTED_MODULE_2__["default"].VP9);
        }
        return this.codecPreferenceOrder.jvb;
    }
    /**
     * Sets the codec on the media session based on the codec preference order configured in config.js and the supported
     * codecs published by the remote participants in their presence.
     *
     * @param {JingleSessionPC} mediaSession session for which the codec selection has to be made.
     */
    _selectPreferredCodec(mediaSession) {
        const session = mediaSession ? mediaSession : this.conference.jvbJingleSession;
        if (!session) {
            return;
        }
        const currentCodecOrder = session.peerconnection.getConfiguredVideoCodecs();
        const localPreferredCodecOrder = session === this.conference.jvbJingleSession
            ? this._maybeFilterJvbCodecs()
            : this.codecPreferenceOrder.p2p;
        const remoteParticipants = this.conference.getParticipants().map(participant => participant.getId());
        const remoteCodecsPerParticipant = remoteParticipants === null || remoteParticipants === void 0 ? void 0 : remoteParticipants.map(remote => {
            var _a;
            const peerMediaInfo = session._signalingLayer.getPeerMediaInfo(remote, _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_3__.MediaType.VIDEO);
            return peerMediaInfo
                ? (_a = peerMediaInfo.codecList) !== null && _a !== void 0 ? _a : [peerMediaInfo.codecType]
                : [];
        });
        const selectedCodecOrder = localPreferredCodecOrder.reduce((acc, localCodec) => {
            let codecNotSupportedByRemote = false;
            // Ignore remote codecs for p2p since only the JVB codec preferences are published in presence.
            // For p2p, we rely on the codec order present in the remote offer/answer.
            if (!session.isP2P) {
                // Remove any codecs that are not supported by any of the remote endpoints. The order of the supported
                // codecs locally however will remain the same since we want to support asymmetric codecs.
                for (const remoteCodecs of remoteCodecsPerParticipant) {
                    codecNotSupportedByRemote = codecNotSupportedByRemote
                        || !remoteCodecs.find(participantCodec => participantCodec === localCodec);
                }
            }
            if (!codecNotSupportedByRemote) {
                acc.push(localCodec);
            }
            return acc;
        }, []);
        if (!selectedCodecOrder.length) {
            logger.warn('Invalid codec list generated because of a user joining/leaving the call');
            return;
        }
        // Reconfigure the codecs on the media session.
        if (!selectedCodecOrder.every((val, index) => val === currentCodecOrder[index])) {
            session.setVideoCodecs(selectedCodecOrder);
        }
    }
    /**
     * Returns the current codec preference order for the given connection type.
     *
     * @param {String} connectionType The media connection type, 'p2p' or 'jvb'.
     * @returns {Array<string>}
     */
    getCodecPreferenceList(connectionType) {
        return this.codecPreferenceOrder[connectionType];
    }
}
//# sourceMappingURL=CodecSelection.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/RTC/JitsiLocalTrack.js":
/*!************************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/RTC/JitsiLocalTrack.js ***!
  \************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
var __filename = "/index.js";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (/* binding */ JitsiLocalTrack)
/* harmony export */ });
/* harmony import */ var _jitsi_logger__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @jitsi/logger */ "./node_modules/@jitsi/logger/lib/index.js");
/* harmony import */ var _jitsi_logger__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(_jitsi_logger__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var _JitsiTrackError__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../JitsiTrackError */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/JitsiTrackError.js");
/* harmony import */ var _JitsiTrackErrors__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../JitsiTrackErrors */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/JitsiTrackErrors.js");
/* harmony import */ var _JitsiTrackEvents__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../JitsiTrackEvents */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/JitsiTrackEvents.js");
/* harmony import */ var _service_RTC_CameraFacingMode__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../../service/RTC/CameraFacingMode */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/RTC/CameraFacingMode.js");
/* harmony import */ var _service_RTC_CameraFacingMode__WEBPACK_IMPORTED_MODULE_4___default = /*#__PURE__*/__webpack_require__.n(_service_RTC_CameraFacingMode__WEBPACK_IMPORTED_MODULE_4__);
/* harmony import */ var _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../../service/RTC/MediaType */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/RTC/MediaType.js");
/* harmony import */ var _service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../../service/RTC/RTCEvents */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/RTC/RTCEvents.js");
/* harmony import */ var _service_RTC_VideoType__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../../service/RTC/VideoType */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/RTC/VideoType.js");
/* harmony import */ var _service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ../../service/statistics/AnalyticsEvents */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/statistics/AnalyticsEvents.js");
/* harmony import */ var _browser__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ../browser */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/browser/index.js");
/* harmony import */ var _flags_FeatureFlags__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ../flags/FeatureFlags */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/flags/FeatureFlags.js");
/* harmony import */ var _statistics_statistics__WEBPACK_IMPORTED_MODULE_11__ = __webpack_require__(/*! ../statistics/statistics */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/statistics/statistics.js");
/* harmony import */ var _JitsiTrack__WEBPACK_IMPORTED_MODULE_12__ = __webpack_require__(/*! ./JitsiTrack */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/RTC/JitsiTrack.js");
/* harmony import */ var _RTCUtils__WEBPACK_IMPORTED_MODULE_13__ = __webpack_require__(/*! ./RTCUtils */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/RTC/RTCUtils.js");
var __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {
    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};














const logger = (0,_jitsi_logger__WEBPACK_IMPORTED_MODULE_0__.getLogger)(__filename);
/**
 * Represents a single media track(either audio or video).
 * One <tt>JitsiLocalTrack</tt> corresponds to one WebRTC MediaStreamTrack.
 */
class JitsiLocalTrack extends _JitsiTrack__WEBPACK_IMPORTED_MODULE_12__["default"] {
    /**
     * Constructs a new JitsiLocalTrack instance.
     *
     * @constructor
     * @param {Object} trackInfo
     * @param {number} trackInfo.rtcId - The ID assigned by the RTC module.
     * @param {Object} trackInfo.stream - The WebRTC MediaStream, parent of the track.
     * @param {Object} trackInfo.track - The underlying WebRTC MediaStreamTrack for new JitsiLocalTrack.
     * @param {string} trackInfo.mediaType - The MediaType of the JitsiLocalTrack.
     * @param {string} trackInfo.videoType - The VideoType of the JitsiLocalTrack.
     * @param {Array<Object>} trackInfo.effects - The effects to be applied to the JitsiLocalTrack.
     * @param {number} trackInfo.resolution - The the video resolution if it's a video track
     * @param {string} trackInfo.deviceId - The ID of the local device for this track.
     * @param {string} trackInfo.facingMode - Thehe camera facing mode used in getUserMedia call (for mobile only).
     * @param {sourceId} trackInfo.sourceId - The id of the desktop sharing source. NOTE: defined for desktop sharing
     * tracks only.
     */
    constructor({ deviceId, facingMode, mediaType, resolution, rtcId, sourceId, sourceType, stream, track, videoType, effects = [] }) {
        super(
        /* conference */ null, stream, track, 
        /* streamInactiveHandler */ () => this.emit(_JitsiTrackEvents__WEBPACK_IMPORTED_MODULE_3__.LOCAL_TRACK_STOPPED, this), mediaType, videoType);
        this._setEffectInProgress = false;
        const effect = effects.find(e => e.isEnabled(this));
        if (effect) {
            this._startStreamEffect(effect);
        }
        const displaySurface = videoType === _service_RTC_VideoType__WEBPACK_IMPORTED_MODULE_7__.VideoType.DESKTOP
            ? track.getSettings().displaySurface
            : null;
        /**
         * Track metadata.
         */
        this.metadata = Object.assign({ timestamp: Date.now() }, displaySurface ? { displaySurface } : {});
        /**
         * The ID assigned by the RTC module on instance creation.
         *
         * @type {number}
         */
        this.rtcId = rtcId;
        this.sourceId = sourceId;
        this.sourceType = sourceType !== null && sourceType !== void 0 ? sourceType : displaySurface;
        // Get the resolution from the track itself because it cannot be
        // certain which resolution webrtc has fallen back to using.
        this.resolution = track.getSettings().height;
        this.maxEnabledResolution = resolution;
        // Cache the constraints of the track in case of any this track
        // model needs to call getUserMedia again, such as when unmuting.
        this._constraints = track.getConstraints();
        // Safari returns an empty constraints object, construct the constraints using getSettings.
        if (!Object.keys(this._constraints).length && videoType === _service_RTC_VideoType__WEBPACK_IMPORTED_MODULE_7__.VideoType.CAMERA) {
            this._constraints = {
                height: track.getSettings().height,
                width: track.getSettings().width
            };
        }
        this.deviceId = deviceId;
        /**
         * The <tt>Promise</tt> which represents the progress of a previously
         * queued/scheduled {@link _setMuted} (from the point of view of
         * {@link _queueSetMuted}).
         *
         * @private
         * @type {Promise}
         */
        this._prevSetMuted = Promise.resolve();
        /**
         * The facing mode of the camera from which this JitsiLocalTrack
         * instance was obtained.
         *
         * @private
         * @type {CameraFacingMode|undefined}
         */
        this._facingMode = facingMode;
        // Currently there is no way to know the MediaStreamTrack ended due to
        // to device disconnect in Firefox through e.g. "readyState" property.
        // Instead we will compare current track's label with device labels from
        // enumerateDevices() list.
        this._trackEnded = false;
        /**
         * Indicates whether data has been sent or not.
         */
        this._hasSentData = false;
        /**
         * Used only for detection of audio problems. We want to check only once
         * whether the track is sending data ot not. This flag is set to false
         * after the check.
         */
        this._testDataSent = true;
        // Currently there is no way to determine with what device track was
        // created (until getConstraints() support), however we can associate
        // tracks with real devices obtained from enumerateDevices() call as
        // soon as it's called.
        // NOTE: this.deviceId corresponds to the device id specified in GUM constraints and this._realDeviceId seems to
        // correspond to the id of a matching device from the available device list.
        this._realDeviceId = this.deviceId === '' ? undefined : this.deviceId;
        // The source name that will be signaled for this track.
        this._sourceName = null;
        this._trackMutedTS = 0;
        this._onDeviceListWillChange = devices => {
            const oldRealDeviceId = this._realDeviceId;
            this._setRealDeviceIdFromDeviceList(devices);
            if (
            // Mark track as ended for those browsers that do not support
            // "readyState" property. We do not touch tracks created with
            // default device ID "".
            (typeof this.getTrack().readyState === 'undefined'
                && typeof this._realDeviceId !== 'undefined'
                && !devices.find(d => d.deviceId === this._realDeviceId))
                // If there was an associated realDeviceID and after the device change the realDeviceId is undefined
                // then the associated device has been disconnected and the _trackEnded flag needs to be set. In
                // addition on some Chrome versions the readyState property is set after the device change event is
                // triggered which causes issues in jitsi-meet with the selection of a new device because we don't
                // detect that the old one was removed.
                || (typeof oldRealDeviceId !== 'undefined' && typeof this._realDeviceId === 'undefined')) {
                this._trackEnded = true;
            }
        };
        // Subscribe each created local audio track to
        // RTCEvents.AUDIO_OUTPUT_DEVICE_CHANGED event. This is different from
        // handling this event for remote tracks (which are handled in RTC.js),
        // because there might be local tracks not attached to a conference.
        if (this.isAudioTrack() && _RTCUtils__WEBPACK_IMPORTED_MODULE_13__["default"].isDeviceChangeAvailable('output')) {
            this._onAudioOutputDeviceChanged = this.setAudioOutput.bind(this);
            _RTCUtils__WEBPACK_IMPORTED_MODULE_13__["default"].addListener(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_6__["default"].AUDIO_OUTPUT_DEVICE_CHANGED, this._onAudioOutputDeviceChanged);
        }
        _RTCUtils__WEBPACK_IMPORTED_MODULE_13__["default"].addListener(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_6__["default"].DEVICE_LIST_WILL_CHANGE, this._onDeviceListWillChange);
        this._initNoDataFromSourceHandlers();
    }
    /**
     * Adds stream to conference and marks it as "unmute" operation.
     *
     * @private
     * @returns {Promise}
     */
    _addStreamToConferenceAsUnmute() {
        if (!this.conference) {
            return Promise.resolve();
        }
        // FIXME it would be good to not included conference as part of this process. Only TraceablePeerConnections to
        // which the track is attached should care about this action. The TPCs to which the track is not attached can
        // sync up when track is re-attached. A problem with that is that the "modify sources" queue is part of the
        // JingleSessionPC and it would be excluded from the process. One solution would be to extract class between
        // TPC and JingleSessionPC which would contain the queue and would notify the signaling layer when local SSRCs
        // are changed. This would help to separate XMPP from the RTC module.
        return new Promise((resolve, reject) => {
            this.conference._addLocalTrackToPc(this)
                .then(resolve, error => reject(new Error(error)));
        });
    }
    /**
     * Fires NO_DATA_FROM_SOURCE event and logs it to analytics and callstats.
     *
     * @private
     * @returns {void}
     */
    _fireNoDataFromSourceEvent() {
        const value = !this.isReceivingData();
        this.emit(_JitsiTrackEvents__WEBPACK_IMPORTED_MODULE_3__.NO_DATA_FROM_SOURCE, value);
        // FIXME: Should we report all of those events
        _statistics_statistics__WEBPACK_IMPORTED_MODULE_11__["default"].sendAnalytics((0,_service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_8__.createNoDataFromSourceEvent)(this.getType(), value));
        _statistics_statistics__WEBPACK_IMPORTED_MODULE_11__["default"].sendLog(JSON.stringify({
            name: _JitsiTrackEvents__WEBPACK_IMPORTED_MODULE_3__.NO_DATA_FROM_SOURCE,
            log: value
        }));
    }
    /**
     * Sets handlers to the MediaStreamTrack object that will detect camera issues.
     *
     * @private
     * @returns {void}
     */
    _initNoDataFromSourceHandlers() {
        if (!this._isNoDataFromSourceEventsEnabled()) {
            return;
        }
        this._setHandler('track_mute', () => {
            this._trackMutedTS = window.performance.now();
            this._fireNoDataFromSourceEvent();
        });
        this._setHandler('track_unmute', () => {
            this._fireNoDataFromSourceEvent();
            _statistics_statistics__WEBPACK_IMPORTED_MODULE_11__["default"].sendAnalyticsAndLog(_service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_8__.TRACK_UNMUTED, {
                'media_type': this.getType(),
                'track_type': 'local',
                value: window.performance.now() - this._trackMutedTS
            });
        });
        if (this.isVideoTrack() && this.videoType === _service_RTC_VideoType__WEBPACK_IMPORTED_MODULE_7__.VideoType.CAMERA) {
            this._setHandler('track_ended', () => {
                if (!this.isReceivingData()) {
                    this._fireNoDataFromSourceEvent();
                }
            });
        }
    }
    /**
     * Returns true if no data from source events are enabled for this JitsiLocalTrack and false otherwise.
     *
     * @private
     * @returns {boolean} - True if no data from source events are enabled for this JitsiLocalTrack and false otherwise.
     */
    _isNoDataFromSourceEventsEnabled() {
        // Disable the events for screen sharing.
        return !this.isVideoTrack() || this.videoType !== _service_RTC_VideoType__WEBPACK_IMPORTED_MODULE_7__.VideoType.DESKTOP;
    }
    /**
     * Initializes a new Promise to execute {@link #_setMuted}. May be called multiple times in a row and the
     * invocations of {@link #_setMuted} and, consequently, {@link #mute} and/or {@link #unmute} will be resolved in a
     * serialized fashion.
     *
     * @param {boolean} muted - The value to invoke <tt>_setMuted</tt> with.
     * @private
     * @returns {Promise}
     */
    _queueSetMuted(muted) {
        const setMuted = this._setMuted.bind(this, muted);
        this._prevSetMuted = this._prevSetMuted.then(setMuted, setMuted);
        return this._prevSetMuted;
    }
    /**
     * Removes stream from conference and marks it as "mute" operation.
     *
     * @param {Function} successCallback - Callback that will be called when the operation is successful.
     * @param {Function} errorCallback - Callback that will be called when the operation fails.
     * @private
     * @returns {Promise}
     */
    _removeStreamFromConferenceAsMute(successCallback, errorCallback) {
        if (!this.conference) {
            successCallback();
            return;
        }
        this.conference._removeLocalTrackFromPc(this).then(successCallback, error => errorCallback(new Error(error)));
    }
    /**
     * Sends mute status for a track to conference if any.
     *
     * @param {boolean} mute - If track is muted.
     * @private
     * @returns {void}
     */
    _sendMuteStatus(mute) {
        if (this.conference) {
            this.conference._setTrackMuteStatus(this.getType(), this, mute) && this.conference.room.sendPresence();
        }
    }
    /**
     * Mutes / unmutes this track.
     *
     * @param {boolean} muted - If <tt>true</tt>, this track will be muted; otherwise, this track will be unmuted.
     * @private
     * @returns {Promise}
     */
    _setMuted(muted) {
        if (this.isMuted() === muted
            && !(this.videoType === _service_RTC_VideoType__WEBPACK_IMPORTED_MODULE_7__.VideoType.DESKTOP && _flags_FeatureFlags__WEBPACK_IMPORTED_MODULE_10__["default"].isMultiStreamSendSupportEnabled())) {
            return Promise.resolve();
        }
        if (this.disposed) {
            return Promise.reject(new _JitsiTrackError__WEBPACK_IMPORTED_MODULE_1__["default"](_JitsiTrackErrors__WEBPACK_IMPORTED_MODULE_2__.TRACK_IS_DISPOSED));
        }
        let promise = Promise.resolve();
        // A function that will print info about muted status transition
        const logMuteInfo = () => logger.info(`Mute ${this}: ${muted}`);
        // In React Native we mute the camera by setting track.enabled but that doesn't
        // work for screen-share tracks, so do the remove-as-mute for those.
        const doesVideoMuteByStreamRemove = _browser__WEBPACK_IMPORTED_MODULE_9__["default"].isReactNative() ? this.videoType === _service_RTC_VideoType__WEBPACK_IMPORTED_MODULE_7__.VideoType.DESKTOP : _browser__WEBPACK_IMPORTED_MODULE_9__["default"].doesVideoMuteByStreamRemove();
        // In the multi-stream mode, desktop tracks are muted from jitsi-meet instead of being removed from the
        // conference. This is needed because we don't want the client to signal a source-remove to the remote peer for
        // the desktop track when screenshare is stopped. Later when screenshare is started again, the same sender will
        // be re-used without the need for signaling a new ssrc through source-add.
        if (this.isAudioTrack()
            || (this.videoType === _service_RTC_VideoType__WEBPACK_IMPORTED_MODULE_7__.VideoType.DESKTOP && !_flags_FeatureFlags__WEBPACK_IMPORTED_MODULE_10__["default"].isMultiStreamSendSupportEnabled())
            || !doesVideoMuteByStreamRemove) {
            logMuteInfo();
            // If we have a stream effect that implements its own mute functionality, prioritize it before
            // normal mute e.g. the stream effect that implements system audio sharing has a custom
            // mute state in which if the user mutes, system audio still has to go through.
            if (this._streamEffect && this._streamEffect.setMuted) {
                this._streamEffect.setMuted(muted);
            }
            else if (this.track) {
                this.track.enabled = !muted;
            }
        }
        else if (muted) {
            promise = new Promise((resolve, reject) => {
                logMuteInfo();
                this._removeStreamFromConferenceAsMute(() => {
                    if (this._streamEffect) {
                        this._stopStreamEffect();
                    }
                    // FIXME: Maybe here we should set the SRC for the
                    // containers to something
                    // We don't want any events to be fired on this stream
                    this._unregisterHandlers();
                    this.stopStream();
                    this._setStream(null);
                    resolve();
                }, reject);
            });
        }
        else {
            logMuteInfo();
            // This path is only for camera.
            const streamOptions = {
                cameraDeviceId: this.getDeviceId(),
                devices: [_service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_5__.MediaType.VIDEO],
                effects: this._streamEffect ? [this._streamEffect] : [],
                facingMode: this.getCameraFacingMode()
            };
            promise
                = _RTCUtils__WEBPACK_IMPORTED_MODULE_13__["default"].obtainAudioAndVideoPermissions(Object.assign({}, streamOptions, { constraints: { video: this._constraints } }));
            promise = promise.then(streamsInfo => {
                const streamInfo = streamsInfo.find(info => info.track.kind === this.getType());
                if (streamInfo) {
                    this._setStream(streamInfo.stream);
                    this.track = streamInfo.track;
                    // This is not good when video type changes after
                    // unmute, but let's not crash here
                    if (this.videoType !== streamInfo.videoType) {
                        logger.warn(`${this}: video type has changed after unmute!`, this.videoType, streamInfo.videoType);
                        this.videoType = streamInfo.videoType;
                    }
                }
                else {
                    throw new _JitsiTrackError__WEBPACK_IMPORTED_MODULE_1__["default"](_JitsiTrackErrors__WEBPACK_IMPORTED_MODULE_2__.TRACK_NO_STREAM_FOUND);
                }
                if (this._streamEffect) {
                    this._startStreamEffect(this._streamEffect);
                }
                this.containers.map(cont => _RTCUtils__WEBPACK_IMPORTED_MODULE_13__["default"].attachMediaStream(cont, this.stream));
                return this._addStreamToConferenceAsUnmute();
            });
        }
        return promise
            .then(() => {
            this._sendMuteStatus(muted);
            // Send the videoType message to the bridge.
            this.isVideoTrack() && this.conference && this.conference._sendBridgeVideoTypeMessage(this);
            this.emit(_JitsiTrackEvents__WEBPACK_IMPORTED_MODULE_3__.TRACK_MUTE_CHANGED, this);
        });
    }
    /**
     * Sets real device ID by comparing track information with device information. This is temporary solution until
     * getConstraints() method will be implemented in browsers.
     *
     * @param {MediaDeviceInfo[]} devices - The list of devices obtained from enumerateDevices() call.
     * @private
     * @returns {void}
     */
    _setRealDeviceIdFromDeviceList(devices) {
        const track = this.getTrack();
        const kind = `${track.kind}input`;
        // We need to match by deviceId as well, in case of multiple devices with the same label.
        let device = devices.find(d => d.kind === kind && d.label === track.label && d.deviceId === this.deviceId);
        if (!device && this._realDeviceId === 'default') { // the default device has been changed.
            // If the default device was 'A' and the default device is changed to 'B' the label for the track will
            // remain 'Default - A' but the label for the device in the device list will be updated to 'A'. That's
            // why in order to match it we need to remove the 'Default - ' part.
            const label = (track.label || '').replace('Default - ', '');
            device = devices.find(d => d.kind === kind && d.label === label);
        }
        if (device) {
            this._realDeviceId = device.deviceId;
        }
        else {
            this._realDeviceId = undefined;
        }
    }
    /**
     * Sets the stream property of JitsiLocalTrack object and sets all stored handlers to it.
     *
     * @param {MediaStream} stream - The new MediaStream.
     * @private
     * @returns {void}
     */
    _setStream(stream) {
        super._setStream(stream);
        if (stream) {
            // Store the MSID for video mute/unmute purposes.
            this.storedMSID = this.getMSID();
            logger.debug(`Setting new MSID: ${this.storedMSID} on ${this}`);
        }
        else {
            logger.debug(`Setting 'null' stream on ${this}`);
        }
    }
    /**
     * Starts the effect process and returns the modified stream.
     *
     * @param {Object} effect - Represents effect instance
     * @private
     * @returns {void}
     */
    _startStreamEffect(effect) {
        this._streamEffect = effect;
        this._originalStream = this.stream;
        this._setStream(this._streamEffect.startEffect(this._originalStream));
        this.track = this.stream.getTracks()[0];
    }
    /**
     * Stops the effect process and returns the original stream.
     *
     * @private
     * @returns {void}
     */
    _stopStreamEffect() {
        if (this._streamEffect) {
            this._streamEffect.stopEffect();
            this._setStream(this._originalStream);
            this._originalStream = null;
            this.track = this.stream ? this.stream.getTracks()[0] : null;
        }
    }
    /**
     * Switches the camera facing mode if the WebRTC implementation supports the custom MediaStreamTrack._switchCamera
     * method. Currently, the method in question is implemented in react-native-webrtc only. When such a WebRTC
     * implementation is executing, the method is the preferred way to switch between the front/user-facing and the
     * back/environment-facing cameras because it will likely be (as is the case of react-native-webrtc) noticeably
     * faster that creating a new MediaStreamTrack via a new getUserMedia call with the switched facingMode constraint
     * value. Moreover, the approach with a new getUserMedia call may not even work: WebRTC on Android and iOS is
     * either very slow to open the camera a second time or plainly freezes attempting to do that.
     *
     * @returns {void}
     */
    _switchCamera() {
        if (this.isVideoTrack()
            && this.videoType === _service_RTC_VideoType__WEBPACK_IMPORTED_MODULE_7__.VideoType.CAMERA
            && typeof this.track._switchCamera === 'function') {
            this.track._switchCamera();
            this._facingMode
                = this._facingMode === (_service_RTC_CameraFacingMode__WEBPACK_IMPORTED_MODULE_4___default().ENVIRONMENT)
                    ? (_service_RTC_CameraFacingMode__WEBPACK_IMPORTED_MODULE_4___default().USER)
                    : (_service_RTC_CameraFacingMode__WEBPACK_IMPORTED_MODULE_4___default().ENVIRONMENT);
        }
    }
    /**
     * Stops the currently used effect (if there is one) and starts the passed effect (if there is one).
     *
     * @param {Object|undefined} effect - The new effect to be set.
     * @private
     * @returns {void}
     */
    _switchStreamEffect(effect) {
        if (this._streamEffect) {
            this._stopStreamEffect();
            this._streamEffect = undefined;
        }
        if (effect) {
            this._startStreamEffect(effect);
        }
    }
    /**
     * @inheritdoc
     *
     * Stops sending the media track. And removes it from the HTML. NOTE: Works for local tracks only.
     *
     * @extends JitsiTrack#dispose
     * @returns {Promise}
     */
    dispose() {
        const _super = Object.create(null, {
            dispose: { get: () => super.dispose }
        });
        return __awaiter(this, void 0, void 0, function* () {
            // Remove the effect instead of stopping it so that the original stream is restored
            // on both the local track and on the peerconnection.
            if (this._streamEffect) {
                yield this.setEffect();
            }
            if (this.conference) {
                yield this.conference.removeTrack(this);
            }
            if (this.stream) {
                this.stopStream();
                this.detach();
            }
            _RTCUtils__WEBPACK_IMPORTED_MODULE_13__["default"].removeListener(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_6__["default"].DEVICE_LIST_WILL_CHANGE, this._onDeviceListWillChange);
            if (this._onAudioOutputDeviceChanged) {
                _RTCUtils__WEBPACK_IMPORTED_MODULE_13__["default"].removeListener(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_6__["default"].AUDIO_OUTPUT_DEVICE_CHANGED, this._onAudioOutputDeviceChanged);
            }
            return _super.dispose.call(this);
        });
    }
    /**
     * Returns facing mode for video track from camera. For other cases (e.g. audio track or 'desktop' video track)
     * returns undefined.
     *
     * @returns {CameraFacingMode|undefined}
     */
    getCameraFacingMode() {
        var _a, _b;
        if (this.isVideoTrack() && this.videoType === _service_RTC_VideoType__WEBPACK_IMPORTED_MODULE_7__.VideoType.CAMERA) {
            // MediaStreamTrack#getSettings() is not implemented in many
            // browsers, so we need feature checking here. Progress on the
            // respective browser's implementation can be tracked at
            // https://bugs.chromium.org/p/webrtc/issues/detail?id=2481 for
            // Chromium and https://bugzilla.mozilla.org/show_bug.cgi?id=1213517
            // for Firefox. Even if a browser implements getSettings() already,
            // it might still not return anything for 'facingMode'.
            const trackSettings = (_b = (_a = this.track).getSettings) === null || _b === void 0 ? void 0 : _b.call(_a);
            if (trackSettings && 'facingMode' in trackSettings) {
                return trackSettings.facingMode;
            }
            if (typeof this._facingMode !== 'undefined') {
                return this._facingMode;
            }
            // In most cases we are showing a webcam. So if we've gotten here,
            // it should be relatively safe to assume that we are probably
            // showing the user-facing camera.
            return (_service_RTC_CameraFacingMode__WEBPACK_IMPORTED_MODULE_4___default().USER);
        }
        return undefined;
    }
    /**
     * Returns device id associated with track.
     *
     * @returns {string}
     */
    getDeviceId() {
        return this._realDeviceId || this.deviceId;
    }
    /**
     * Get the duration of the track.
     *
     * @returns {Number} the duration of the track in seconds
     */
    getDuration() {
        return (Date.now() / 1000) - (this.metadata.timestamp / 1000);
    }
    /**
     * Returns the participant id which owns the track.
     *
     * @returns {string} the id of the participants. It corresponds to the
     * Colibri endpoint id/MUC nickname in case of Jitsi-meet.
     */
    getParticipantId() {
        return this.conference && this.conference.myUserId();
    }
    /**
     * Returns the source name associated with the jitsi track.
     *
     * @returns {string | null} source name
     */
    getSourceName() {
        return this._sourceName;
    }
    /**
     * Returns if associated MediaStreamTrack is in the 'ended' state
     *
     * @returns {boolean}
     */
    isEnded() {
        if (this.isVideoTrack() && this.isMuted()) {
            // If a video track is muted the readyState will be ended, that's why we need to rely only on the
            // _trackEnded flag.
            return this._trackEnded;
        }
        return this.getTrack().readyState === 'ended' || this._trackEnded;
    }
    /**
     * Returns <tt>true</tt>.
     *
     * @returns {boolean} <tt>true</tt>
     */
    isLocal() {
        return true;
    }
    /**
     * Returns <tt>true</tt> - if the stream is muted and <tt>false</tt> otherwise.
     *
     * @returns {boolean} <tt>true</tt> - if the stream is muted and <tt>false</tt> otherwise.
     */
    isMuted() {
        // this.stream will be null when we mute local video on Chrome
        if (!this.stream) {
            return true;
        }
        if (this.isVideoTrack() && !this.isActive()) {
            return true;
        }
        // If currently used stream effect has its own muted state, use that.
        if (this._streamEffect && this._streamEffect.isMuted) {
            return this._streamEffect.isMuted();
        }
        return !this.track || !this.track.enabled;
    }
    /**
     * Checks whether the attached MediaStream is receiving data from source or not. If the stream property is null
     * (because of mute or another reason) this method will return false.
     * NOTE: This method doesn't indicate problem with the streams directly. For example in case of video mute the
     * method will return false or if the user has disposed the track.
     *
     * @returns {boolean} true if the stream is receiving data and false this otherwise.
     */
    isReceivingData() {
        if (this.isVideoTrack()
            && (this.isMuted() || this._stopStreamInProgress || this.videoType === _service_RTC_VideoType__WEBPACK_IMPORTED_MODULE_7__.VideoType.DESKTOP)) {
            return true;
        }
        if (!this.stream) {
            return false;
        }
        // In older version of the spec there is no muted property and readyState can have value muted. In the latest
        // versions readyState can have values "live" and "ended" and there is muted boolean property. If the stream is
        // muted that means that we aren't receiving any data from the source. We want to notify the users for error if
        // the stream is muted or ended on it's creation.
        // For video blur enabled use the original video stream
        const stream = this._effectEnabled ? this._originalStream : this.stream;
        return stream.getTracks().some(track => (!('readyState' in track) || track.readyState === 'live')
            && (!('muted' in track) || track.muted !== true));
    }
    /**
     * Asynchronously mutes this track.
     *
     * @returns {Promise}
     */
    mute() {
        return this._queueSetMuted(true);
    }
    /**
     * Handles bytes sent statistics. NOTE: used only for audio tracks to detect audio issues.
     *
     * @param {TraceablePeerConnection} tpc - The peerconnection that is reporting the bytes sent stat.
     * @param {number} bytesSent - The new value.
     * @returns {void}
     */
    onByteSentStatsReceived(tpc, bytesSent) {
        if (bytesSent > 0) {
            this._hasSentData = true;
        }
        const iceConnectionState = tpc.getConnectionState();
        if (this._testDataSent && iceConnectionState === 'connected') {
            setTimeout(() => {
                if (!this._hasSentData) {
                    logger.warn(`${this} 'bytes sent' <= 0: \
                        ${bytesSent}`);
                    _statistics_statistics__WEBPACK_IMPORTED_MODULE_11__["default"].analytics.sendEvent(_service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_8__.NO_BYTES_SENT, { 'media_type': this.getType() });
                }
            }, 3000);
            this._testDataSent = false;
        }
    }
    /**
     * Sets the JitsiConference object associated with the track. This is temp solution.
     *
     * @param conference - JitsiConference object.
     * @returns {void}
     */
    setConference(conference) {
        this.conference = conference;
        // We want to keep up with postponed events which should have been fired
        // on "attach" call, but for local track we not always have the
        // conference before attaching. However this may result in duplicated
        // events if they have been triggered on "attach" already.
        for (let i = 0; i < this.containers.length; i++) {
            this._maybeFireTrackAttached(this.containers[i]);
        }
    }
    /**
     * Sets the effect and switches between the modified stream and original one.
     *
     * @param {Object} effect - Represents the effect instance to be used.
     * @returns {Promise}
     */
    setEffect(effect) {
        if (typeof this._streamEffect === 'undefined' && typeof effect === 'undefined') {
            return Promise.resolve();
        }
        if (typeof effect !== 'undefined' && !effect.isEnabled(this)) {
            return Promise.reject(new Error('Incompatible effect instance!'));
        }
        if (this._setEffectInProgress === true) {
            return Promise.reject(new Error('setEffect already in progress!'));
        }
        // In case we have an audio track that is being enhanced with an effect, we still want it to be applied,
        // even if the track is muted. Where as for video the actual track doesn't exists if it's muted.
        if (this.isMuted() && !this.isAudioTrack()) {
            this._streamEffect = effect;
            return Promise.resolve();
        }
        const conference = this.conference;
        if (!conference) {
            this._switchStreamEffect(effect);
            if (this.isVideoTrack()) {
                this.containers.forEach(cont => _RTCUtils__WEBPACK_IMPORTED_MODULE_13__["default"].attachMediaStream(cont, this.stream));
            }
            return Promise.resolve();
        }
        this._setEffectInProgress = true;
        return conference._removeLocalTrackFromPc(this)
            .then(() => {
            this._switchStreamEffect(effect);
            if (this.isVideoTrack()) {
                this.containers.forEach(cont => _RTCUtils__WEBPACK_IMPORTED_MODULE_13__["default"].attachMediaStream(cont, this.stream));
            }
            return conference._addLocalTrackToPc(this);
        })
            .then(() => {
            this._setEffectInProgress = false;
        })
            .catch(error => {
            // Any error will be not recovarable and will trigger CONFERENCE_FAILED event. But let's try to cleanup
            // everyhting related to the effect functionality.
            this._setEffectInProgress = false;
            this._switchStreamEffect();
            logger.error('Failed to switch to the new stream!', error);
            throw error;
        });
    }
    /**
     * Sets the source name to be used for signaling the jitsi track.
     *
     * @param {string} name The source name.
     */
    setSourceName(name) {
        this._sourceName = name;
    }
    /**
     * Stops the associated MediaStream.
     *
     * @returns {void}
     */
    stopStream() {
        /**
         * Indicates that we are executing {@link #stopStream} i.e.
         * {@link RTCUtils#stopMediaStream} for the <tt>MediaStream</tt>
         * associated with this <tt>JitsiTrack</tt> instance.
         *
         * @private
         * @type {boolean}
         */
        this._stopStreamInProgress = true;
        try {
            _RTCUtils__WEBPACK_IMPORTED_MODULE_13__["default"].stopMediaStream(this.stream);
        }
        finally {
            this._stopStreamInProgress = false;
        }
    }
    /**
     * Creates a text representation of this local track instance.
     *
     * @return {string}
     */
    toString() {
        return `LocalTrack[${this.rtcId},${this.getType()}]`;
    }
    /**
     * Asynchronously unmutes this track.
     *
     * @returns {Promise}
     */
    unmute() {
        return this._queueSetMuted(false);
    }
}
//# sourceMappingURL=JitsiLocalTrack.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/RTC/JitsiRemoteTrack.js":
/*!*************************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/RTC/JitsiRemoteTrack.js ***!
  \*************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
var __filename = "/index.js";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (/* binding */ JitsiRemoteTrack)
/* harmony export */ });
/* harmony import */ var _JitsiTrackEvents__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../JitsiTrackEvents */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/JitsiTrackEvents.js");
/* harmony import */ var _service_RTC_VideoType__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../service/RTC/VideoType */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/RTC/VideoType.js");
/* harmony import */ var _service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../service/statistics/AnalyticsEvents */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/statistics/AnalyticsEvents.js");
/* harmony import */ var _connectivity_TrackStreamingStatus__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../connectivity/TrackStreamingStatus */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/connectivity/TrackStreamingStatus.js");
/* harmony import */ var _statistics_statistics__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../statistics/statistics */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/statistics/statistics.js");
/* harmony import */ var _JitsiTrack__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./JitsiTrack */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/RTC/JitsiTrack.js");






const logger = (__webpack_require__(/*! @jitsi/logger */ "./node_modules/@jitsi/logger/lib/index.js").getLogger)(__filename);
const RTCEvents = __webpack_require__(/*! ../../service/RTC/RTCEvents */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/RTC/RTCEvents.js");
let ttfmTrackerAudioAttached = false;
let ttfmTrackerVideoAttached = false;
/**
 * List of container events that we are going to process. _onContainerEventHandler will be added as listener to the
 * container for every event in the list.
 */
const containerEvents = ['abort', 'canplaythrough', 'ended', 'error'];
/* eslint-disable max-params */
/**
 * Represents a single media track (either audio or video).
 */
class JitsiRemoteTrack extends _JitsiTrack__WEBPACK_IMPORTED_MODULE_5__["default"] {
    /**
     * Creates new JitsiRemoteTrack instance.
     * @param {RTC} rtc the RTC service instance.
     * @param {JitsiConference} conference the conference to which this track
     *        belongs to
     * @param {string} ownerEndpointId the endpoint ID of the track owner
     * @param {MediaStream} stream WebRTC MediaStream, parent of the track
     * @param {MediaStreamTrack} track underlying WebRTC MediaStreamTrack for
     *        the new JitsiRemoteTrack
     * @param {MediaType} mediaType the type of the media
     * @param {VideoType} videoType the type of the video if applicable
     * @param {number} ssrc the SSRC number of the Media Stream
     * @param {boolean} muted the initial muted state
     * @param {boolean} isP2P indicates whether or not this track belongs to a
     * P2P session
     * @param {String} sourceName the source name signaled for the track
     * @throws {TypeError} if <tt>ssrc</tt> is not a number.
     * @constructor
     */
    constructor(rtc, conference, ownerEndpointId, stream, track, mediaType, videoType, ssrc, muted, isP2P, sourceName) {
        super(conference, stream, track, () => {
            // Nothing to do if the track is inactive.
        }, mediaType, videoType);
        this.rtc = rtc;
        // Prevent from mixing up type of SSRC which should be a number
        if (typeof ssrc !== 'number') {
            throw new TypeError(`SSRC ${ssrc} is not a number`);
        }
        this.ssrc = ssrc;
        this.ownerEndpointId = ownerEndpointId;
        this.muted = muted;
        this.isP2P = isP2P;
        this._sourceName = sourceName;
        this._trackStreamingStatus = null;
        this._trackStreamingStatusImpl = null;
        /**
         * This holds the timestamp indicating when remote video track entered forwarded sources set. Track entering
         * forwardedSources will have streaming status restoring and when we start receiving video will become active,
         * but if video is not received for certain time {@link DEFAULT_RESTORING_TIMEOUT} that track streaming status
         * will become interrupted.
         */
        this._enteredForwardedSourcesTimestamp = null;
        this.addEventListener = this.on = this._addEventListener.bind(this);
        this.removeEventListener = this.off = this._removeEventListener.bind(this);
        logger.debug(`New remote track created: ${this}`);
        // we want to mark whether the track has been ever muted
        // to detect ttfm events for startmuted conferences, as it can
        // significantly increase ttfm values
        this.hasBeenMuted = muted;
        // Bind 'onmute' and 'onunmute' event handlers
        if (this.rtc && this.track) {
            this._bindTrackHandlers();
        }
        this._containerHandlers = {};
        containerEvents.forEach(event => {
            this._containerHandlers[event] = this._containerEventHandler.bind(this, event);
        });
    }
    /* eslint-enable max-params */
    /**
     * Attaches the track handlers.
     *
     * @returns {void}
     */
    _bindTrackHandlers() {
        this.track.addEventListener('mute', () => this._onTrackMute());
        this.track.addEventListener('unmute', () => this._onTrackUnmute());
        this.track.addEventListener('ended', () => {
            logger.debug(`"onended" event(${Date.now()}): ${this}`);
        });
    }
    /**
     * Overrides addEventListener method to init TrackStreamingStatus instance when there are listeners for the
     * {@link JitsiTrackEvents.TRACK_STREAMING_STATUS_CHANGED} event.
     *
     * @param {string} event - event name
     * @param {function} handler - event handler
     */
    _addEventListener(event, handler) {
        super.addListener(event, handler);
        if (event === _JitsiTrackEvents__WEBPACK_IMPORTED_MODULE_0__.TRACK_STREAMING_STATUS_CHANGED
            && this.listenerCount(_JitsiTrackEvents__WEBPACK_IMPORTED_MODULE_0__.TRACK_STREAMING_STATUS_CHANGED)
            && !this._trackStreamingStatusImpl) {
            this._initTrackStreamingStatus();
            logger.debug(`Initializing track streaming status: ${this._sourceName}`);
        }
    }
    /**
     * Overrides removeEventListener method to dispose TrackStreamingStatus instance.
     *
     * @param {string} event - event name
     * @param {function} handler - event handler
     */
    _removeEventListener(event, handler) {
        super.removeListener(event, handler);
        if (event === _JitsiTrackEvents__WEBPACK_IMPORTED_MODULE_0__.TRACK_STREAMING_STATUS_CHANGED
            && !this.listenerCount(_JitsiTrackEvents__WEBPACK_IMPORTED_MODULE_0__.TRACK_STREAMING_STATUS_CHANGED)) {
            this._disposeTrackStreamingStatus();
            logger.debug(`Disposing track streaming status: ${this._sourceName}`);
        }
    }
    /**
     * Callback invoked when the track is muted. Emits an event notifying
     * listeners of the mute event.
     *
     * @private
     * @returns {void}
     */
    _onTrackMute() {
        logger.debug(`"onmute" event(${Date.now()}): ${this}`);
        // Ignore mute events that get fired on desktop tracks because of 0Hz screensharing introduced in Chromium.
        // The sender stops sending frames if the content of the captured window doesn't change resulting in the
        // receiver showing avatar instead of the shared content.
        if (this.videoType === _service_RTC_VideoType__WEBPACK_IMPORTED_MODULE_1__.VideoType.DESKTOP) {
            logger.debug('Ignoring mute event on desktop tracks.');
            return;
        }
        this.rtc.eventEmitter.emit(RTCEvents.REMOTE_TRACK_MUTE, this);
    }
    /**
     * Callback invoked when the track is unmuted. Emits an event notifying
     * listeners of the mute event.
     *
     * @private
     * @returns {void}
     */
    _onTrackUnmute() {
        logger.debug(`"onunmute" event(${Date.now()}): ${this}`);
        this.rtc.eventEmitter.emit(RTCEvents.REMOTE_TRACK_UNMUTE, this);
    }
    /**
     * Removes attached event listeners and dispose TrackStreamingStatus .
     *
     * @returns {Promise}
     */
    dispose() {
        this._disposeTrackStreamingStatus();
        return super.dispose();
    }
    /**
     * Sets current muted status and fires an events for the change.
     * @param value the muted status.
     */
    setMute(value) {
        if (this.muted === value) {
            return;
        }
        if (value) {
            this.hasBeenMuted = true;
        }
        // we can have a fake video stream
        if (this.stream) {
            this.stream.muted = value;
        }
        this.muted = value;
        this.emit(_JitsiTrackEvents__WEBPACK_IMPORTED_MODULE_0__.TRACK_MUTE_CHANGED, this);
    }
    /**
     * Returns the current muted status of the track.
     * @returns {boolean|*|JitsiRemoteTrack.muted} <tt>true</tt> if the track is
     * muted and <tt>false</tt> otherwise.
     */
    isMuted() {
        return this.muted;
    }
    /**
     * Returns the participant id which owns the track.
     *
     * @returns {string} the id of the participants. It corresponds to the
     * Colibri endpoint id/MUC nickname in case of Jitsi-meet.
     */
    getParticipantId() {
        return this.ownerEndpointId;
    }
    /**
     * Return false;
     */
    isLocal() {
        return false;
    }
    /**
     * Returns the synchronization source identifier (SSRC) of this remote
     * track.
     *
     * @returns {number} the SSRC of this remote track.
     */
    getSSRC() {
        return this.ssrc;
    }
    /**
     * Returns the tracks source name
     *
     * @returns {string} the track's source name
     */
    getSourceName() {
        return this._sourceName;
    }
    /**
     * Update the properties when the track is remapped to another source.
     *
     * @param {string} owner The endpoint ID of the new owner.
     */
    setOwner(owner) {
        this.ownerEndpointId = owner;
        this.emit(_JitsiTrackEvents__WEBPACK_IMPORTED_MODULE_0__.TRACK_OWNER_CHANGED, owner);
    }
    /**
     * Sets the name of the source associated with the remtoe track.
     *
     * @param {string} name - The source name to be associated with the track.
     */
    setSourceName(name) {
        this._sourceName = name;
    }
    /**
     * Changes the video type of the track.
     *
     * @param {string} type - The new video type("camera", "desktop").
     */
    _setVideoType(type) {
        if (this.videoType === type) {
            return;
        }
        this.videoType = type;
        this.emit(_JitsiTrackEvents__WEBPACK_IMPORTED_MODULE_0__.TRACK_VIDEOTYPE_CHANGED, type);
    }
    /**
     * Handles track play events.
     */
    _playCallback() {
        if (!this.conference.room) {
            return;
        }
        const type = this.isVideoTrack() ? 'video' : 'audio';
        const now = window.performance.now();
        logger.info(`(TIME) Render ${type}:\t`, now);
        this.conference.getConnectionTimes()[`${type}.render`] = now;
        // The conference can be started without calling GUM
        // FIXME if there would be a module for connection times this kind
        // of logic (gumDuration or ttfm) should end up there
        const gumStart = window.connectionTimes['obtainPermissions.start'];
        const gumEnd = window.connectionTimes['obtainPermissions.end'];
        const gumDuration = !isNaN(gumEnd) && !isNaN(gumStart) ? gumEnd - gumStart : 0;
        // Subtract the muc.joined-to-session-initiate duration because jicofo
        // waits until there are 2 participants to start Jingle sessions.
        const ttfm = now
            - (this.conference.getConnectionTimes()['session.initiate']
                - this.conference.getConnectionTimes()['muc.joined'])
            - gumDuration;
        this.conference.getConnectionTimes()[`${type}.ttfm`] = ttfm;
        logger.info(`(TIME) TTFM ${type}:\t`, ttfm);
        _statistics_statistics__WEBPACK_IMPORTED_MODULE_4__["default"].sendAnalytics((0,_service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_2__.createTtfmEvent)({
            'media_type': type,
            muted: this.hasBeenMuted,
            value: ttfm
        }));
    }
    /**
     * Attach time to first media tracker only if there is conference and only
     * for the first element.
     * @param container the HTML container which can be 'video' or 'audio'
     * element.
     * @private
     */
    _attachTTFMTracker(container) {
        if ((ttfmTrackerAudioAttached && this.isAudioTrack())
            || (ttfmTrackerVideoAttached && this.isVideoTrack())) {
            return;
        }
        if (this.isAudioTrack()) {
            ttfmTrackerAudioAttached = true;
        }
        if (this.isVideoTrack()) {
            ttfmTrackerVideoAttached = true;
        }
        container.addEventListener('canplay', this._playCallback.bind(this));
    }
    /**
     * Called when the track has been attached to a new container.
     *
     * @param {HTMLElement} container the HTML container which can be 'video' or 'audio' element.
     * @private
     */
    _onTrackAttach(container) {
        containerEvents.forEach(event => {
            container.addEventListener(event, this._containerHandlers[event]);
        });
    }
    /**
     * Called when the track has been detached from a container.
     *
     * @param {HTMLElement} container the HTML container which can be 'video' or 'audio' element.
     * @private
     */
    _onTrackDetach(container) {
        containerEvents.forEach(event => {
            container.removeEventListener(event, this._containerHandlers[event]);
        });
    }
    /**
     * An event handler for events triggered by the attached container.
     *
     * @param {string} type - The type of the event.
     */
    _containerEventHandler(type) {
        logger.debug(`${type} handler was called for a container with attached ${this}`);
    }
    /**
     * Returns a string with a description of the current status of the track.
     *
     * @returns {string}
     */
    _getStatus() {
        const { enabled, muted, readyState } = this.track;
        return `readyState: ${readyState}, muted: ${muted}, enabled: ${enabled}`;
    }
    /**
     * Initializes trackStreamingStatusImpl.
     */
    _initTrackStreamingStatus() {
        const config = this.conference.options.config;
        this._trackStreamingStatus = _connectivity_TrackStreamingStatus__WEBPACK_IMPORTED_MODULE_3__.TrackStreamingStatus.ACTIVE;
        this._trackStreamingStatusImpl = new _connectivity_TrackStreamingStatus__WEBPACK_IMPORTED_MODULE_3__["default"](this.rtc, this.conference, this, {
            // These options are not public API, leaving it here only as an entry point through config for
            // tuning up purposes. Default values should be adjusted as soon as optimal values are discovered.
            p2pRtcMuteTimeout: config._p2pConnStatusRtcMuteTimeout,
            rtcMuteTimeout: config._peerConnStatusRtcMuteTimeout,
            outOfForwardedSourcesTimeout: config._peerConnStatusOutOfLastNTimeout
        });
        this._trackStreamingStatusImpl.init();
        // In some edge cases, both browser 'unmute' and bridge's forwarded sources events are received before a
        // LargeVideoUpdate is scheduled for auto-pinning a new screenshare track. If there are no layout changes and
        // no further track events are received for the SS track, a black tile will be displayed for screenshare on
        // stage. Fire a TRACK_STREAMING_STATUS_CHANGED event if the media is already being received for the remote
        // track to prevent this from happening.
        !this._trackStreamingStatusImpl.isVideoTrackFrozen()
            && this.rtc.eventEmitter.emit(_JitsiTrackEvents__WEBPACK_IMPORTED_MODULE_0__.TRACK_STREAMING_STATUS_CHANGED, this, this._trackStreamingStatus);
    }
    /**
     * Disposes trackStreamingStatusImpl and clears trackStreamingStatus.
     */
    _disposeTrackStreamingStatus() {
        if (this._trackStreamingStatusImpl) {
            this._trackStreamingStatusImpl.dispose();
            this._trackStreamingStatusImpl = null;
            this._trackStreamingStatus = null;
        }
    }
    /**
     * Updates track's streaming status.
     *
     * @param {string} state the current track streaming state. {@link TrackStreamingStatus}.
     */
    _setTrackStreamingStatus(status) {
        this._trackStreamingStatus = status;
    }
    /**
     * Returns track's streaming status.
     *
     * @returns {string} the streaming status <tt>TrackStreamingStatus</tt> of the track. Returns null
     * if trackStreamingStatusImpl hasn't been initialized.
     *
     * {@link TrackStreamingStatus}.
     */
    getTrackStreamingStatus() {
        return this._trackStreamingStatus;
    }
    /**
     * Clears the timestamp of when the track entered forwarded sources.
     */
    _clearEnteredForwardedSourcesTimestamp() {
        this._enteredForwardedSourcesTimestamp = null;
    }
    /**
     * Updates the timestamp of when the track entered forwarded sources.
     *
     * @param {number} timestamp the time in millis
     */
    _setEnteredForwardedSourcesTimestamp(timestamp) {
        this._enteredForwardedSourcesTimestamp = timestamp;
    }
    /**
     * Returns the timestamp of when the track entered forwarded sources.
     *
     * @returns {number} the time in millis
     */
    _getEnteredForwardedSourcesTimestamp() {
        return this._enteredForwardedSourcesTimestamp;
    }
    /**
     * Creates a text representation of this remote track instance.
     * @return {string}
     */
    toString() {
        return `RemoteTrack[userID: ${this.getParticipantId()}, type: ${this.getType()}, ssrc: ${this.getSSRC()}, p2p: ${this.isP2P}, sourceName: ${this._sourceName}, status: {${this._getStatus()}}]`;
    }
}
//# sourceMappingURL=JitsiRemoteTrack.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/RTC/JitsiTrack.js":
/*!*******************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/RTC/JitsiTrack.js ***!
  \*******************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
var __filename = "/index.js";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (/* binding */ JitsiTrack)
/* harmony export */ });
/* harmony import */ var _jitsi_logger__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @jitsi/logger */ "./node_modules/@jitsi/logger/lib/index.js");
/* harmony import */ var _jitsi_logger__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(_jitsi_logger__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var events__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! events */ "./node_modules/events/events.js");
/* harmony import */ var events__WEBPACK_IMPORTED_MODULE_1___default = /*#__PURE__*/__webpack_require__.n(events__WEBPACK_IMPORTED_MODULE_1__);
/* harmony import */ var _JitsiTrackEvents__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../JitsiTrackEvents */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/JitsiTrackEvents.js");
/* harmony import */ var _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../service/RTC/MediaType */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/RTC/MediaType.js");
/* harmony import */ var _browser__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../browser */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/browser/index.js");
/* harmony import */ var _RTCUtils__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./RTCUtils */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/RTC/RTCUtils.js");






const logger = (0,_jitsi_logger__WEBPACK_IMPORTED_MODULE_0__.getLogger)(__filename);
/**
 * Maps our handler types to MediaStreamTrack properties.
 */
const trackHandler2Prop = {
    'track_mute': 'onmute',
    'track_unmute': 'onunmute',
    'track_ended': 'onended'
};
/**
 * Represents a single media track (either audio or video).
 */
class JitsiTrack extends (events__WEBPACK_IMPORTED_MODULE_1___default()) {
    /* eslint-disable max-params */
    /**
     * Represents a single media track (either audio or video).
     * @constructor
     * @param conference the rtc instance
     * @param stream the WebRTC MediaStream instance
     * @param track the WebRTC MediaStreamTrack instance, must be part of
     * the given <tt>stream</tt>.
     * @param streamInactiveHandler the function that will handle
     *        onended/oninactive events of the stream.
     * @param trackMediaType the media type of the JitsiTrack
     * @param videoType the VideoType for this track if any
     */
    constructor(conference, stream, track, streamInactiveHandler, trackMediaType, videoType) {
        super();
        // aliases for addListener/removeListener
        this.addEventListener = this.addListener;
        this.removeEventListener = this.off = this.removeListener;
        /**
         * Array with the HTML elements that are displaying the streams.
         * @type {Array}
         */
        this.containers = [];
        this.conference = conference;
        this.audioLevel = -1;
        this.type = trackMediaType;
        this.track = track;
        this.videoType = videoType;
        this.handlers = new Map();
        /**
         * Indicates whether this JitsiTrack has been disposed. If true, this
         * JitsiTrack is to be considered unusable and operations involving it
         * are to fail (e.g. {@link JitsiConference#addTrack(JitsiTrack)},
         * {@link JitsiConference#removeTrack(JitsiTrack)}).
         * @type {boolean}
         */
        this.disposed = false;
        /**
         * The inactive handler which will be triggered when the underlying
         * <tt>MediaStream</tt> ends.
         *
         * @private
         * @type {Function}
         */
        this._streamInactiveHandler = streamInactiveHandler;
        this._setStream(stream);
    }
    /**
     * Adds onended/oninactive handler to a MediaStream or a MediaStreamTrack.
     * Firefox doesn't fire a inactive event on the MediaStream, instead it fires
     * a onended event on the MediaStreamTrack.
     * @param {Function} handler the handler
     */
    _addMediaStreamInactiveHandler(handler) {
        if (_browser__WEBPACK_IMPORTED_MODULE_4__["default"].isFirefox()) {
            this.track.onended = handler;
        }
        else {
            this.stream.oninactive = handler;
        }
    }
    /**
     * Attach time to first media tracker only if there is conference and only
     * for the first element.
     *
     * @param {HTMLElement} container the HTML container which can be 'video' or
     * 'audio' element.
     * @private
     */
    _attachTTFMTracker(container) {
        // Should be defined by the classes that are extending JitsiTrack
    }
    /**
     * Eventually will trigger RTCEvents.TRACK_ATTACHED event.
     * @param container the video/audio container to which this stream is
     *        attached and for which event will be fired.
     * @private
     */
    _maybeFireTrackAttached(container) {
        if (this.conference && container) {
            this.conference._onTrackAttach(this, container);
        }
    }
    /**
     * Called when the track has been attached to a new container.
     *
     * @param {HTMLElement} container the HTML container which can be 'video' or
     * 'audio' element.
     * @private
     */
    _onTrackAttach(container) {
        // Should be defined by the classes that are extending JitsiTrack
    }
    /**
     * Called when the track has been detached from a container.
     *
     * @param {HTMLElement} container the HTML container which can be 'video' or
     * 'audio' element.
     * @private
     */
    _onTrackDetach(container) {
        // Should be defined by the classes that are extending JitsiTrack
    }
    /**
     * Sets handler to the WebRTC MediaStream or MediaStreamTrack object
     * depending on the passed type.
     * @param {string} type the type of the handler that is going to be set
     * @param {Function} handler the handler.
     */
    _setHandler(type, handler) {
        if (!trackHandler2Prop.hasOwnProperty(type)) {
            logger.error(`Invalid handler type ${type}`);
            return;
        }
        if (handler) {
            this.handlers.set(type, handler);
        }
        else {
            this.handlers.delete(type);
        }
        if (this.stream) {
            for (const track of this.stream.getTracks()) {
                track[trackHandler2Prop[type]] = handler;
            }
        }
    }
    /**
     * Sets the stream property of JitsiTrack object and sets all stored
     * handlers to it.
     *
     * @param {MediaStream} stream the new stream.
     * @protected
     */
    _setStream(stream) {
        if (this.stream === stream) {
            return;
        }
        this.stream = stream;
        // TODO Practically, that's like the opposite of _unregisterHandlers
        // i.e. may be abstracted into a function/method called
        // _registerHandlers for clarity and easing the maintenance of the two
        // pieces of source code.
        if (this.stream) {
            for (const type of this.handlers.keys()) {
                this._setHandler(type, this.handlers.get(type));
            }
            if (this._streamInactiveHandler) {
                this._addMediaStreamInactiveHandler(this._streamInactiveHandler);
            }
        }
    }
    /**
     * Unregisters all event handlers bound to the underlying media stream/track
     * @private
     */
    _unregisterHandlers() {
        if (!this.stream) {
            logger.warn(`${this}: unable to unregister handlers - no stream object`);
            return;
        }
        for (const type of this.handlers.keys()) {
            // FIXME Why only video tracks?
            for (const videoTrack of this.stream.getVideoTracks()) {
                videoTrack[trackHandler2Prop[type]] = undefined;
            }
        }
        if (this._streamInactiveHandler) {
            this._addMediaStreamInactiveHandler(undefined);
        }
    }
    /**
     * Attaches the MediaStream of this track to an HTML container.
     * Adds the container to the list of containers that are displaying the
     * track.
     *
     * @param container the HTML container which can be 'video' or 'audio'
     * element.
     *
     * @returns {void}
     */
    attach(container) {
        if (this.stream) {
            this._onTrackAttach(container);
            _RTCUtils__WEBPACK_IMPORTED_MODULE_5__["default"].attachMediaStream(container, this.stream);
        }
        this.containers.push(container);
        this._maybeFireTrackAttached(container);
        this._attachTTFMTracker(container);
    }
    /**
     * Removes this JitsiTrack from the passed HTML container.
     *
     * @param container the HTML container to detach from this JitsiTrack. If
     * <tt>null</tt> or <tt>undefined</tt>, all containers are removed. A
     * container can be a 'video', 'audio' or 'object' HTML element instance to
     * which this JitsiTrack is currently attached.
     */
    detach(container) {
        for (let cs = this.containers, i = cs.length - 1; i >= 0; --i) {
            const c = cs[i];
            if (!container) {
                this._onTrackDetach(c);
                _RTCUtils__WEBPACK_IMPORTED_MODULE_5__["default"].attachMediaStream(c, null);
            }
            if (!container || c === container) {
                cs.splice(i, 1);
            }
        }
        if (container) {
            this._onTrackDetach(container);
            _RTCUtils__WEBPACK_IMPORTED_MODULE_5__["default"].attachMediaStream(container, null);
        }
    }
    /**
     * Removes attached event listeners.
     *
     * @returns {Promise}
     */
    dispose() {
        this.removeAllListeners();
        this.disposed = true;
        return Promise.resolve();
    }
    /**
     * Returns id of the track.
     * @returns {string|null} id of the track or null if this is fake track.
     */
    getId() {
        return this.getStreamId();
    }
    /**
     * Returns the msid of the stream attached to the JitsiTrack object or null
     * if no stream is attached.
     */
    getMSID() {
        const streamId = this.getStreamId();
        const trackId = this.getTrackId();
        return streamId && trackId ? `${streamId} ${trackId}` : null;
    }
    /**
     * Returns the WebRTC MediaStream instance.
     */
    getOriginalStream() {
        return this.stream;
    }
    /**
     * Returns the source name of the track.
     * @returns {String|undefined}
     */
    getSourceName() {
        // Should be defined by the classes that are extending JitsiTrack
    }
    /**
     * Returns the ID of the underlying WebRTC Media Stream(if any)
     * @returns {String|null}
     */
    getStreamId() {
        return this.stream ? this.stream.id : null;
    }
    /**
     * Return the underlying WebRTC MediaStreamTrack
     * @returns {MediaStreamTrack}
     */
    getTrack() {
        return this.track;
    }
    /**
     * Return the underlying WebRTC MediaStreamTrack label
     * @returns {string}
     */
    getTrackLabel() {
        return this.track.label;
    }
    /**
     * Returns the ID of the underlying WebRTC MediaStreamTrack(if any)
     * @returns {String|null}
     */
    getTrackId() {
        return this.track ? this.track.id : null;
    }
    /**
     * Returns the type (audio or video) of this track.
     */
    getType() {
        return this.type;
    }
    /**
     * Return meaningful usage label for this track depending on it's media and
     * eventual video type.
     * @returns {string}
     */
    getUsageLabel() {
        if (this.isAudioTrack()) {
            return 'mic';
        }
        return this.videoType ? this.videoType : 'default';
    }
    /**
     * Returns the video type (camera or desktop) of this track.
     */
    getVideoType() {
        return this.videoType;
    }
    /**
     * Checks whether the MediaStream is active/not ended.
     * When there is no check for active we don't have information and so
     * will return that stream is active (in case of FF).
     * @returns {boolean} whether MediaStream is active.
     */
    isActive() {
        if (typeof this.stream.active !== 'undefined') {
            return this.stream.active;
        }
        return true;
    }
    /**
     * Check if this is an audio track.
     */
    isAudioTrack() {
        return this.getType() === _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_3__.MediaType.AUDIO;
    }
    /**
     * Checks whether this is a local track.
     * @abstract
     * @return {boolean} 'true' if it's a local track or 'false' otherwise.
     */
    isLocal() {
        throw new Error('Not implemented by subclass');
    }
    /**
     * Check whether this is a local audio track.
     *
     * @return {boolean} -  true if track represents a local audio track, false otherwise.
     */
    isLocalAudioTrack() {
        return this.isAudioTrack() && this.isLocal();
    }
    /**
     * Check if this is a video track.
     */
    isVideoTrack() {
        return this.getType() === _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_3__.MediaType.VIDEO;
    }
    /**
     * Checks whether the underlying WebRTC <tt>MediaStreamTrack</tt> is muted
     * according to it's 'muted' field status.
     * @return {boolean} <tt>true</tt> if the underlying
     * <tt>MediaStreamTrack</tt> is muted or <tt>false</tt> otherwise.
     */
    isWebRTCTrackMuted() {
        return this.track && this.track.muted;
    }
    /**
     * Sets the audio level for the stream
     * @param {number} audioLevel value between 0 and 1
     * @param {TraceablePeerConnection} [tpc] the peerconnection instance which
     * is source for the audio level. It can be <tt>undefined</tt> for
     * a local track if the audio level was measured outside of the
     * peerconnection (see /modules/statistics/LocalStatsCollector.js).
     */
    setAudioLevel(audioLevel, tpc) {
        let newAudioLevel = audioLevel;
        // When using getSynchornizationSources on the audio receiver to gather audio levels for
        // remote tracks, browser reports last known audio levels even when the remote user is
        // audio muted, we need to reset the value to zero here so that the audio levels are cleared.
        // Remote tracks have the tpc info present while local tracks do not.
        if (_browser__WEBPACK_IMPORTED_MODULE_4__["default"].supportsReceiverStats() && typeof tpc !== 'undefined' && this.isMuted()) {
            newAudioLevel = 0;
        }
        if (this.audioLevel !== newAudioLevel) {
            this.audioLevel = newAudioLevel;
            this.emit(_JitsiTrackEvents__WEBPACK_IMPORTED_MODULE_2__.TRACK_AUDIO_LEVEL_CHANGED, newAudioLevel, tpc);
            // LocalStatsCollector reports a value of 0.008 for muted mics
            // and a value of 0 when there is no audio input.
        }
        else if (this.audioLevel === 0
            && newAudioLevel === 0
            && this.isLocal()
            && !this.isWebRTCTrackMuted()) {
            this.emit(_JitsiTrackEvents__WEBPACK_IMPORTED_MODULE_2__.NO_AUDIO_INPUT, newAudioLevel);
        }
    }
    /**
     * Sets new audio output device for track's DOM elements. Video tracks are
     * ignored.
     * @param {string} audioOutputDeviceId - id of 'audiooutput' device from
     *      navigator.mediaDevices.enumerateDevices(), '' for default device
     * @emits JitsiTrackEvents.TRACK_AUDIO_OUTPUT_CHANGED
     * @returns {Promise}
     */
    setAudioOutput(audioOutputDeviceId) {
        if (!_RTCUtils__WEBPACK_IMPORTED_MODULE_5__["default"].isDeviceChangeAvailable('output')) {
            return Promise.reject(new Error('Audio output device change is not supported'));
        }
        // All audio communication is done through audio tracks, so ignore
        // changing audio output for video tracks at all.
        if (this.isVideoTrack()) {
            return Promise.resolve();
        }
        return (Promise.all(this.containers.map(element => element.setSinkId(audioOutputDeviceId)
            .catch(error => {
            logger.warn('Failed to change audio output device on'
                + ' element. Default or previously set'
                + ' audio output device will be used.', element, error);
            throw error;
        })))
            .then(() => {
            this.emit(_JitsiTrackEvents__WEBPACK_IMPORTED_MODULE_2__.TRACK_AUDIO_OUTPUT_CHANGED, audioOutputDeviceId);
        }));
    }
    /**
     * Assigns the source name to a track.
     * @param {String} name - The name to be assigned to the track.
     * @returns {void}
     */
    setSourceName(name) {
        // Should be defined by the classes that are extending JitsiTrack
    }
}
//# sourceMappingURL=JitsiTrack.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/RTC/RTC.js":
/*!************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/RTC/RTC.js ***!
  \************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
var __filename = "/index.js";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (/* binding */ RTC)
/* harmony export */ });
/* harmony import */ var _jitsi_logger__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @jitsi/logger */ "./node_modules/@jitsi/logger/lib/index.js");
/* harmony import */ var _jitsi_logger__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(_jitsi_logger__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var _JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../JitsiConferenceEvents */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/JitsiConferenceEvents.js");
/* harmony import */ var _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../service/RTC/MediaType */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/RTC/MediaType.js");
/* harmony import */ var _service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../service/RTC/RTCEvents */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/RTC/RTCEvents.js");
/* harmony import */ var _browser__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../browser */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/browser/index.js");
/* harmony import */ var _util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../util/GlobalOnErrorHandler */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/util/GlobalOnErrorHandler.js");
/* harmony import */ var _util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_5___default = /*#__PURE__*/__webpack_require__.n(_util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_5__);
/* harmony import */ var _util_Listenable__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../util/Listenable */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/util/Listenable.js");
/* harmony import */ var _util_MathUtil__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../util/MathUtil */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/util/MathUtil.js");
/* harmony import */ var _BridgeChannel__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ./BridgeChannel */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/RTC/BridgeChannel.js");
/* harmony import */ var _JitsiLocalTrack__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ./JitsiLocalTrack */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/RTC/JitsiLocalTrack.js");
/* harmony import */ var _RTCUtils__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ./RTCUtils */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/RTC/RTCUtils.js");
/* harmony import */ var _TraceablePeerConnection__WEBPACK_IMPORTED_MODULE_11__ = __webpack_require__(/*! ./TraceablePeerConnection */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/RTC/TraceablePeerConnection.js");












const logger = (0,_jitsi_logger__WEBPACK_IMPORTED_MODULE_0__.getLogger)(__filename);
/**
 * The counter used to generated id numbers assigned to peer connections
 * @type {number}
 */
let peerConnectionIdCounter = 0;
/**
 * The counter used to generate id number for the local
 * <code>MediaStreamTrack</code>s.
 * @type {number}
 */
let rtcTrackIdCounter = 0;
/**
 * Creates {@code JitsiLocalTrack} instances from the passed in meta information
 * about MedieaTracks.
 *
 * @param {Object[]} mediaStreamMetaData - An array of meta information with
 * MediaTrack instances. Each can look like:
 * {{
 *     stream: MediaStream instance that holds a track with audio or video,
 *     track: MediaTrack within the MediaStream,
 *     videoType: "camera" or "desktop" or falsy,
 *     sourceId: ID of the desktopsharing source,
 *     sourceType: The desktopsharing source type,
 *     effects: Array of effect types
 * }}
 */
function _createLocalTracks(mediaStreamMetaData = []) {
    return mediaStreamMetaData.map(metaData => {
        const { sourceId, sourceType, stream, track, videoType, effects } = metaData;
        const { deviceId, facingMode } = track.getSettings();
        // FIXME Move rtcTrackIdCounter to a static method in JitsiLocalTrack
        // so RTC does not need to handle ID management. This move would be
        // safer to do once the old createLocalTracks is removed.
        rtcTrackIdCounter = (0,_util_MathUtil__WEBPACK_IMPORTED_MODULE_7__.safeCounterIncrement)(rtcTrackIdCounter);
        return new _JitsiLocalTrack__WEBPACK_IMPORTED_MODULE_9__["default"]({
            deviceId,
            facingMode,
            mediaType: track.kind,
            rtcId: rtcTrackIdCounter,
            sourceId,
            sourceType,
            stream,
            track,
            videoType: videoType || null,
            effects
        });
    });
}
/**
 *
 */
class RTC extends _util_Listenable__WEBPACK_IMPORTED_MODULE_6__["default"] {
    /**
     *
     * @param conference
     * @param options
     */
    constructor(conference, options = {}) {
        super();
        this.conference = conference;
        /**
         * A map of active <tt>TraceablePeerConnection</tt>.
         * @type {Map.<number, TraceablePeerConnection>}
         */
        this.peerConnections = new Map();
        this.localTracks = [];
        this.options = options;
        // BridgeChannel instance.
        // @private
        // @type {BridgeChannel}
        this._channel = null;
        /**
         * The value specified to the last invocation of setLastN before the
         * channel completed opening. If non-null, the value will be sent
         * through a channel (once) as soon as it opens and will then be
         * discarded.
         * @private
         * @type {number}
         */
        this._lastN = undefined;
        /**
         * Defines the forwarded sources list. It can be null or an array once initialised with a channel forwarded
         * sources event.
         *
         * @type {Array<string>|null}
         * @private
         */
        this._forwardedSources = null;
        // The forwarded sources change listener.
        this._forwardedSourcesChangeListener = this._onForwardedSourcesChanged.bind(this);
        this._onDeviceListChanged = this._onDeviceListChanged.bind(this);
        this._updateAudioOutputForAudioTracks = this._updateAudioOutputForAudioTracks.bind(this);
        // Switch audio output device on all remote audio tracks. Local audio
        // tracks handle this event by themselves.
        if (_RTCUtils__WEBPACK_IMPORTED_MODULE_10__["default"].isDeviceChangeAvailable('output')) {
            _RTCUtils__WEBPACK_IMPORTED_MODULE_10__["default"].addListener(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_3__["default"].AUDIO_OUTPUT_DEVICE_CHANGED, this._updateAudioOutputForAudioTracks);
            _RTCUtils__WEBPACK_IMPORTED_MODULE_10__["default"].addListener(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_3__["default"].DEVICE_LIST_CHANGED, this._onDeviceListChanged);
        }
    }
    /**
     * Removes any listeners and stored state from this {@code RTC} instance.
     *
     * @returns {void}
     */
    destroy() {
        _RTCUtils__WEBPACK_IMPORTED_MODULE_10__["default"].removeListener(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_3__["default"].AUDIO_OUTPUT_DEVICE_CHANGED, this._updateAudioOutputForAudioTracks);
        _RTCUtils__WEBPACK_IMPORTED_MODULE_10__["default"].removeListener(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_3__["default"].DEVICE_LIST_CHANGED, this._onDeviceListChanged);
        if (this._channelOpenListener) {
            this.removeListener(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_3__["default"].DATA_CHANNEL_OPEN, this._channelOpenListener);
        }
    }
    /**
     * Exposes the private helper for converting a WebRTC MediaStream to a
     * JitsiLocalTrack.
     *
     * @param {Array<Object>} tracksInfo
     * @returns {Array<JitsiLocalTrack>}
     */
    static createLocalTracks(tracksInfo) {
        return _createLocalTracks(tracksInfo);
    }
    /**
     * Creates the local MediaStreams.
     * @param {object} [options] Optional parameters.
     * @param {Array=} options.devices The devices that will be requested.
     * @param {string=} options.resolution Resolution constraints.
     * @param {string=} options.cameraDeviceId
     * @param {string=} options.micDeviceId
     * @returns {*} Promise object that will receive the new JitsiTracks
     */
    static obtainAudioAndVideoPermissions(options) {
        return _RTCUtils__WEBPACK_IMPORTED_MODULE_10__["default"].obtainAudioAndVideoPermissions(options)
            .then(tracksInfo => _createLocalTracks(tracksInfo));
    }
    /**
     * Initializes the bridge channel of this instance.
     * At least one of both, peerconnection or wsUrl parameters, must be
     * given.
     * @param {RTCPeerConnection} [peerconnection] WebRTC peer connection
     * instance.
     * @param {string} [wsUrl] WebSocket URL.
     */
    initializeBridgeChannel(peerconnection, wsUrl) {
        this._channel = new _BridgeChannel__WEBPACK_IMPORTED_MODULE_8__["default"](peerconnection, wsUrl, this.eventEmitter, this.conference);
        this._channelOpenListener = () => {
            const logError = (error, msgType, value) => {
                _util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_5___default().callErrorHandler(error);
                logger.error(`Cannot send ${msgType}(${JSON.stringify(value)}) endpoint message`, error);
            };
            // When the channel becomes available, tell the bridge about video selections so that it can do adaptive
            // simulcast, we want the notification to trigger even if userJid is undefined, or null.
            if (this._receiverVideoConstraints) {
                try {
                    this._channel.sendReceiverVideoConstraintsMessage(this._receiverVideoConstraints);
                }
                catch (error) {
                    logError(error, 'ReceiverVideoConstraints', this._receiverVideoConstraints);
                }
            }
            if (typeof this._lastN !== 'undefined' && this._lastN !== -1) {
                try {
                    this._channel.sendSetLastNMessage(this._lastN);
                }
                catch (error) {
                    logError(error, 'LastNChangedEvent', this._lastN);
                }
            }
        };
        this.addListener(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_3__["default"].DATA_CHANNEL_OPEN, this._channelOpenListener);
        // Add forwarded sources change listener.
        this.addListener(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_3__["default"].FORWARDED_SOURCES_CHANGED, this._forwardedSourcesChangeListener);
    }
    /**
     * Callback invoked when the list of known audio and video devices has
     * been updated. Attempts to update the known available audio output
     * devices.
     *
     * @private
     * @returns {void}
     */
    _onDeviceListChanged() {
        this._updateAudioOutputForAudioTracks(_RTCUtils__WEBPACK_IMPORTED_MODULE_10__["default"].getAudioOutputDevice());
    }
    /**
     * Receives events when forwarded sources had changed.
     *
     * @param {array} forwardedSources The new forwarded sources.
     * @private
     */
    _onForwardedSourcesChanged(forwardedSources = []) {
        const oldForwardedSources = this._forwardedSources || [];
        let leavingForwardedSources = [];
        let enteringForwardedSources = [];
        const timestamp = Date.now();
        this._forwardedSources = forwardedSources;
        leavingForwardedSources = oldForwardedSources.filter(sourceName => !this.isInForwardedSources(sourceName));
        enteringForwardedSources = forwardedSources.filter(sourceName => oldForwardedSources.indexOf(sourceName) === -1);
        logger.debug(`Fowarded sources changed leaving=${leavingForwardedSources}, entering=`
            + `${enteringForwardedSources} at ${timestamp}`);
        this.conference.eventEmitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_1__.FORWARDED_SOURCES_CHANGED, leavingForwardedSources, enteringForwardedSources, timestamp);
    }
    /**
     * Should be called when current media session ends and after the
     * PeerConnection has been closed using PeerConnection.close() method.
     */
    onCallEnded() {
        if (this._channel) {
            // The BridgeChannel is not explicitly closed as the PeerConnection
            // is closed on call ended which triggers datachannel onclose
            // events. If using a WebSocket, the channel must be closed since
            // it is not managed by the PeerConnection.
            // The reference is cleared to disable any logic related to the
            // channel.
            if (this._channel && this._channel.mode === 'websocket') {
                this._channel.close();
            }
            this._channel = null;
        }
    }
    /**
     * Sets the capture frame rate to be used for desktop tracks.
     *
     * @param {number} maxFps framerate to be used for desktop track capture.
     */
    setDesktopSharingFrameRate(maxFps) {
        _RTCUtils__WEBPACK_IMPORTED_MODULE_10__["default"].setDesktopSharingFrameRate(maxFps);
    }
    /**
     * Sets the receiver video constraints that determine how bitrate is allocated to each of the video streams
     * requested from the bridge. The constraints are cached and sent through the bridge channel once the channel
     * is established.
     * @param {*} constraints
     */
    setReceiverVideoConstraints(constraints) {
        this._receiverVideoConstraints = constraints;
        if (this._channel && this._channel.isOpen()) {
            this._channel.sendReceiverVideoConstraintsMessage(constraints);
        }
    }
    /**
     * Sends the track's  video type to the JVB.
     * @param {SourceName} sourceName - the track's source name.
     * @param {BridgeVideoType} videoType - the track's video type.
     */
    sendSourceVideoType(sourceName, videoType) {
        if (this._channel && this._channel.isOpen()) {
            this._channel.sendSourceVideoTypeMessage(sourceName, videoType);
        }
    }
    /**
     *
     * @param eventType
     * @param listener
     */
    static addListener(eventType, listener) {
        _RTCUtils__WEBPACK_IMPORTED_MODULE_10__["default"].addListener(eventType, listener);
    }
    /**
     *
     * @param eventType
     * @param listener
     */
    static removeListener(eventType, listener) {
        _RTCUtils__WEBPACK_IMPORTED_MODULE_10__["default"].removeListener(eventType, listener);
    }
    /**
     *
     * @param options
     */
    static init(options = {}) {
        this.options = options;
        return _RTCUtils__WEBPACK_IMPORTED_MODULE_10__["default"].init(this.options);
    }
    /* eslint-disable max-params */
    /**
     * Creates new <tt>TraceablePeerConnection</tt>
     * @param {SignalingLayer} signaling The signaling layer that will provide information about the media or
     * participants which is not carried over SDP.
     * @param {object} pcConfig The {@code RTCConfiguration} to use for the WebRTC peer connection.
     * @param {boolean} isP2P Indicates whether or not the new TPC will be used in a peer to peer type of session.
     * @param {object} options The config options.
     * @param {boolean} options.enableInsertableStreams - Set to true when the insertable streams constraints is to be
     * enabled on the PeerConnection.
     * @param {boolean} options.disableSimulcast If set to 'true' will disable the simulcast.
     * @param {boolean} options.disableRtx If set to 'true' will disable the RTX.
     * @param {boolean} options.startSilent If set to 'true' no audio will be sent or received.
     * @return {TraceablePeerConnection}
     */
    createPeerConnection(signaling, pcConfig, isP2P, options) {
        const pcConstraints = JSON.parse(JSON.stringify(_RTCUtils__WEBPACK_IMPORTED_MODULE_10__["default"].pcConstraints));
        if (options.enableInsertableStreams) {
            logger.debug('E2EE - setting insertable streams constraints');
            pcConfig.encodedInsertableStreams = true;
        }
        // TODO: remove this.
        const supportsSdpSemantics = _browser__WEBPACK_IMPORTED_MODULE_4__["default"].isChromiumBased() && !options.usesUnifiedPlan;
        if (supportsSdpSemantics) {
            logger.debug('WebRTC application is running in plan-b mode');
            pcConfig.sdpSemantics = 'plan-b';
        }
        if (options.forceTurnRelay) {
            pcConfig.iceTransportPolicy = 'relay';
        }
        // Set the RTCBundlePolicy to max-bundle so that only one set of ice candidates is generated.
        // The default policy generates separate ice candidates for audio and video connections.
        // This change is necessary for Unified plan to work properly on Chrome and Safari.
        pcConfig.bundlePolicy = 'max-bundle';
        peerConnectionIdCounter = (0,_util_MathUtil__WEBPACK_IMPORTED_MODULE_7__.safeCounterIncrement)(peerConnectionIdCounter);
        const newConnection = new _TraceablePeerConnection__WEBPACK_IMPORTED_MODULE_11__["default"](this, peerConnectionIdCounter, signaling, pcConfig, pcConstraints, isP2P, options);
        this.peerConnections.set(newConnection.id, newConnection);
        return newConnection;
    }
    /* eslint-enable max-params */
    /**
     * Removed given peer connection from this RTC module instance.
     * @param {TraceablePeerConnection} traceablePeerConnection
     * @return {boolean} <tt>true</tt> if the given peer connection was removed
     * successfully or <tt>false</tt> if there was no peer connection mapped in
     * this RTC instance.
     */
    _removePeerConnection(traceablePeerConnection) {
        const id = traceablePeerConnection.id;
        if (this.peerConnections.has(id)) {
            // NOTE Remote tracks are not removed here.
            this.peerConnections.delete(id);
            return true;
        }
        return false;
    }
    /**
     *
     * @param track
     */
    addLocalTrack(track) {
        if (!track) {
            throw new Error('track must not be null nor undefined');
        }
        this.localTracks.push(track);
        track.conference = this.conference;
    }
    /**
     * Get forwarded sources list.
     * @returns {Array<string>|null}
     */
    getForwardedSources() {
        return this._forwardedSources;
    }
    /**
     * Get local video track.
     * @returns {JitsiLocalTrack|undefined}
     */
    getLocalVideoTrack() {
        const localVideo = this.getLocalTracks(_service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_2__.MediaType.VIDEO);
        return localVideo.length ? localVideo[0] : undefined;
    }
    /**
     * Returns all the local video tracks.
     * @returns {Array<JitsiLocalTrack>}
     */
    getLocalVideoTracks() {
        return this.getLocalTracks(_service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_2__.MediaType.VIDEO);
    }
    /**
     * Get local audio track.
     * @returns {JitsiLocalTrack|undefined}
     */
    getLocalAudioTrack() {
        const localAudio = this.getLocalTracks(_service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_2__.MediaType.AUDIO);
        return localAudio.length ? localAudio[0] : undefined;
    }
    /**
     * Returns the endpoint id for the local user.
     * @returns {string}
     */
    getLocalEndpointId() {
        return this.conference.myUserId();
    }
    /**
     * Returns the local tracks of the given media type, or all local tracks if
     * no specific type is given.
     * @param {MediaType} [mediaType] Optional media type filter.
     * (audio or video).
     */
    getLocalTracks(mediaType) {
        let tracks = this.localTracks.slice();
        if (mediaType !== undefined) {
            tracks = tracks.filter(track => track.getType() === mediaType);
        }
        return tracks;
    }
    /**
     * Obtains all remote tracks currently known to this RTC module instance.
     * @param {MediaType} [mediaType] The remote tracks will be filtered
     *      by their media type if this argument is specified.
     * @return {Array<JitsiRemoteTrack>}
     */
    getRemoteTracks(mediaType) {
        let remoteTracks = [];
        for (const tpc of this.peerConnections.values()) {
            const pcRemoteTracks = tpc.getRemoteTracks(undefined, mediaType);
            if (pcRemoteTracks) {
                remoteTracks = remoteTracks.concat(pcRemoteTracks);
            }
        }
        return remoteTracks;
    }
    /**
     * Set mute for all local audio streams attached to the conference.
     * @param value The mute value.
     * @returns {Promise}
     */
    setAudioMute(value) {
        const mutePromises = [];
        this.getLocalTracks(_service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_2__.MediaType.AUDIO).forEach(audioTrack => {
            // this is a Promise
            mutePromises.push(value ? audioTrack.mute() : audioTrack.unmute());
        });
        // We return a Promise from all Promises so we can wait for their
        // execution.
        return Promise.all(mutePromises);
    }
    /**
    * Set mute for all local video streams attached to the conference.
    * @param value The mute value.
    * @returns {Promise}
    */
    setVideoMute(value) {
        const mutePromises = [];
        this.getLocalTracks(_service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_2__.MediaType.VIDEO)
            .forEach(videoTrack => {
            // this is a Promise
            mutePromises.push(value ? videoTrack.mute() : videoTrack.unmute());
        });
        // We return a Promise from all Promises so we can wait for their
        // execution.
        return Promise.all(mutePromises);
    }
    /**
     *
     * @param track
     */
    removeLocalTrack(track) {
        const pos = this.localTracks.indexOf(track);
        if (pos === -1) {
            return;
        }
        this.localTracks.splice(pos, 1);
    }
    /**
     *
     * @param elSelector
     * @param stream
     */
    static attachMediaStream(elSelector, stream) {
        return _RTCUtils__WEBPACK_IMPORTED_MODULE_10__["default"].attachMediaStream(elSelector, stream);
    }
    /**
     * Returns true if retrieving the list of input devices is supported
     * and false if not.
     */
    static isDeviceListAvailable() {
        return _RTCUtils__WEBPACK_IMPORTED_MODULE_10__["default"].isDeviceListAvailable();
    }
    /**
     * Returns true if changing the input (camera / microphone) or output
     * (audio) device is supported and false if not.
     * @param {string} [deviceType] Type of device to change. Default is
     *      undefined or 'input', 'output' - for audio output device change.
     * @returns {boolean} true if available, false otherwise.
     */
    static isDeviceChangeAvailable(deviceType) {
        return _RTCUtils__WEBPACK_IMPORTED_MODULE_10__["default"].isDeviceChangeAvailable(deviceType);
    }
    /**
     * Returns whether the current execution environment supports WebRTC (for
     * use within this library).
     *
     * @returns {boolean} {@code true} if WebRTC is supported in the current
     * execution environment (for use within this library); {@code false},
     * otherwise.
     */
    static isWebRtcSupported() {
        return _browser__WEBPACK_IMPORTED_MODULE_4__["default"].isSupported();
    }
    /**
     * Returns currently used audio output device id, '' stands for default
     * device
     * @returns {string}
     */
    static getAudioOutputDevice() {
        return _RTCUtils__WEBPACK_IMPORTED_MODULE_10__["default"].getAudioOutputDevice();
    }
    /**
     * Returns list of available media devices if its obtained, otherwise an
     * empty array is returned/
     * @returns {array} list of available media devices.
     */
    static getCurrentlyAvailableMediaDevices() {
        return _RTCUtils__WEBPACK_IMPORTED_MODULE_10__["default"].getCurrentlyAvailableMediaDevices();
    }
    /**
     * Returns whether available devices have permissions granted
     * @returns {Boolean}
     */
    static arePermissionsGrantedForAvailableDevices() {
        return _RTCUtils__WEBPACK_IMPORTED_MODULE_10__["default"].arePermissionsGrantedForAvailableDevices();
    }
    /**
     * Returns event data for device to be reported to stats.
     * @returns {MediaDeviceInfo} device.
     */
    static getEventDataForActiveDevice(device) {
        return _RTCUtils__WEBPACK_IMPORTED_MODULE_10__["default"].getEventDataForActiveDevice(device);
    }
    /**
     * Sets current audio output device.
     * @param {string} deviceId Id of 'audiooutput' device from
     *      navigator.mediaDevices.enumerateDevices().
     * @returns {Promise} resolves when audio output is changed, is rejected
     *      otherwise
     */
    static setAudioOutputDevice(deviceId) {
        return _RTCUtils__WEBPACK_IMPORTED_MODULE_10__["default"].setAudioOutputDevice(deviceId);
    }
    /**
     * Returns <tt>true<tt/> if given WebRTC MediaStream is considered a valid
     * "user" stream which means that it's not a "receive only" stream nor a
     * "mixed" JVB stream.
     *
     * Clients that implement Unified Plan, such as Firefox use recvonly
     * "streams/channels/tracks" for receiving remote stream/tracks, as opposed
     * to Plan B where there are only 3 channels: audio, video and data.
     *
     * @param {MediaStream} stream The WebRTC MediaStream instance.
     * @returns {boolean}
     */
    static isUserStream(stream) {
        return RTC.isUserStreamById(stream.id);
    }
    /**
     * Returns <tt>true<tt/> if a WebRTC MediaStream identified by given stream
     * ID is considered a valid "user" stream which means that it's not a
     * "receive only" stream nor a "mixed" JVB stream.
     *
     * Clients that implement Unified Plan, such as Firefox use recvonly
     * "streams/channels/tracks" for receiving remote stream/tracks, as opposed
     * to Plan B where there are only 3 channels: audio, video and data.
     *
     * @param {string} streamId The id of WebRTC MediaStream.
     * @returns {boolean}
     */
    static isUserStreamById(streamId) {
        return streamId && streamId !== 'mixedmslabel'
            && streamId !== 'default';
    }
    /**
     * Allows to receive list of available cameras/microphones.
     * @param {function} callback Would receive array of devices as an
     *      argument.
     */
    static enumerateDevices(callback) {
        _RTCUtils__WEBPACK_IMPORTED_MODULE_10__["default"].enumerateDevices(callback);
    }
    /**
     * A method to handle stopping of the stream.
     * One point to handle the differences in various implementations.
     * @param {MediaStream} mediaStream MediaStream object to stop.
     */
    static stopMediaStream(mediaStream) {
        _RTCUtils__WEBPACK_IMPORTED_MODULE_10__["default"].stopMediaStream(mediaStream);
    }
    /**
     * Returns whether the desktop sharing is enabled or not.
     * @returns {boolean}
     */
    static isDesktopSharingEnabled() {
        return _RTCUtils__WEBPACK_IMPORTED_MODULE_10__["default"].isDesktopSharingEnabled();
    }
    /**
     * Closes the currently opened bridge channel.
     */
    closeBridgeChannel() {
        if (this._channel) {
            this._channel.close();
            this._channel = null;
        }
    }
    /* eslint-disable max-params */
    /**
     *
     * @param {TraceablePeerConnection} tpc
     * @param {number} ssrc
     * @param {number} audioLevel
     * @param {boolean} isLocal
     */
    setAudioLevel(tpc, ssrc, audioLevel, isLocal) {
        const track = tpc.getTrackBySSRC(ssrc);
        if (!track) {
            return;
        }
        else if (!track.isAudioTrack()) {
            logger.warn(`Received audio level for non-audio track: ${ssrc}`);
            return;
        }
        else if (track.isLocal() !== isLocal) {
            logger.error(`${track} was expected to ${isLocal ? 'be' : 'not be'} local`);
        }
        track.setAudioLevel(audioLevel, tpc);
    }
    /**
     * Sends message via the bridge channel.
     * @param {string} to The id of the endpoint that should receive the
     *      message. If "" the message will be sent to all participants.
     * @param {object} payload The payload of the message.
     * @throws NetworkError or InvalidStateError or Error if the operation
     * fails or there is no data channel created.
     */
    sendChannelMessage(to, payload) {
        if (this._channel) {
            this._channel.sendMessage(to, payload);
        }
        else {
            throw new Error('Channel support is disabled!');
        }
    }
    /**
     * Sends the local stats via the bridge channel.
     * @param {Object} payload The payload of the message.
     * @throws NetworkError/InvalidStateError/Error if the operation fails or if there is no data channel created.
     */
    sendEndpointStatsMessage(payload) {
        if (this._channel && this._channel.isOpen()) {
            this._channel.sendEndpointStatsMessage(payload);
        }
    }
    /**
     * Selects a new value for "lastN". The requested amount of videos are going
     * to be delivered after the value is in effect. Set to -1 for unlimited or
     * all available videos.
     * @param {number} value the new value for lastN.
     */
    setLastN(value) {
        if (this._lastN !== value) {
            this._lastN = value;
            if (this._channel && this._channel.isOpen()) {
                this._channel.sendSetLastNMessage(value);
            }
            this.eventEmitter.emit(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_3__["default"].LASTN_VALUE_CHANGED, value);
        }
    }
    /**
     * Indicates if the source name is currently included in the forwarded sources.
     *
     * @param {string} sourceName The source name that we check for forwarded sources.
     * @returns {boolean} true if the source name is in the forwarded sources or if we don't have bridge channel
     * support, otherwise we return false.
     */
    isInForwardedSources(sourceName) {
        return !this._forwardedSources // forwardedSources not initialised yet.
            || this._forwardedSources.indexOf(sourceName) > -1;
    }
    /**
     * Updates the target audio output device for all remote audio tracks.
     *
     * @param {string} deviceId - The device id of the audio ouput device to
     * use for all remote tracks.
     * @private
     * @returns {void}
     */
    _updateAudioOutputForAudioTracks(deviceId) {
        const remoteAudioTracks = this.getRemoteTracks(_service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_2__.MediaType.AUDIO);
        for (const track of remoteAudioTracks) {
            track.setAudioOutput(deviceId);
        }
    }
}
//# sourceMappingURL=RTC.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/RTC/RTCUtils.js":
/*!*****************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/RTC/RTCUtils.js ***!
  \*****************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
var __filename = "/index.js";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (__WEBPACK_DEFAULT_EXPORT__)
/* harmony export */ });
/* harmony import */ var _jitsi_logger__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @jitsi/logger */ "./node_modules/@jitsi/logger/lib/index.js");
/* harmony import */ var _jitsi_logger__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(_jitsi_logger__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var events__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! events */ "./node_modules/events/events.js");
/* harmony import */ var events__WEBPACK_IMPORTED_MODULE_1___default = /*#__PURE__*/__webpack_require__.n(events__WEBPACK_IMPORTED_MODULE_1__);
/* harmony import */ var lodash_clonedeep__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! lodash.clonedeep */ "./node_modules/lodash.clonedeep/index.js");
/* harmony import */ var lodash_clonedeep__WEBPACK_IMPORTED_MODULE_2___default = /*#__PURE__*/__webpack_require__.n(lodash_clonedeep__WEBPACK_IMPORTED_MODULE_2__);
/* harmony import */ var webrtc_adapter__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! webrtc-adapter */ "./node_modules/webrtc-adapter/src/js/adapter_core.js");
/* harmony import */ var _JitsiTrackError__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../../JitsiTrackError */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/JitsiTrackError.js");
/* harmony import */ var _JitsiTrackErrors__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../../JitsiTrackErrors */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/JitsiTrackErrors.js");
/* harmony import */ var _service_RTC_CameraFacingMode__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../../service/RTC/CameraFacingMode */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/RTC/CameraFacingMode.js");
/* harmony import */ var _service_RTC_CameraFacingMode__WEBPACK_IMPORTED_MODULE_6___default = /*#__PURE__*/__webpack_require__.n(_service_RTC_CameraFacingMode__WEBPACK_IMPORTED_MODULE_6__);
/* harmony import */ var _service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../../service/RTC/RTCEvents */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/RTC/RTCEvents.js");
/* harmony import */ var _service_RTC_Resolutions__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ../../service/RTC/Resolutions */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/RTC/Resolutions.js");
/* harmony import */ var _service_RTC_Resolutions__WEBPACK_IMPORTED_MODULE_8___default = /*#__PURE__*/__webpack_require__.n(_service_RTC_Resolutions__WEBPACK_IMPORTED_MODULE_8__);
/* harmony import */ var _service_RTC_VideoType__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ../../service/RTC/VideoType */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/RTC/VideoType.js");
/* harmony import */ var _service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ../../service/statistics/AnalyticsEvents */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/statistics/AnalyticsEvents.js");
/* harmony import */ var _browser__WEBPACK_IMPORTED_MODULE_11__ = __webpack_require__(/*! ../browser */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/browser/index.js");
/* harmony import */ var _statistics_statistics__WEBPACK_IMPORTED_MODULE_12__ = __webpack_require__(/*! ../statistics/statistics */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/statistics/statistics.js");
/* harmony import */ var _util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_13__ = __webpack_require__(/*! ../util/GlobalOnErrorHandler */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/util/GlobalOnErrorHandler.js");
/* harmony import */ var _util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_13___default = /*#__PURE__*/__webpack_require__.n(_util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_13__);
/* harmony import */ var _util_Listenable__WEBPACK_IMPORTED_MODULE_14__ = __webpack_require__(/*! ../util/Listenable */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/util/Listenable.js");
/* harmony import */ var _ScreenObtainer__WEBPACK_IMPORTED_MODULE_15__ = __webpack_require__(/*! ./ScreenObtainer */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/RTC/ScreenObtainer.js");
var __rest = (undefined && undefined.__rest) || function (s, e) {
    var t = {};
    for (var p in s) if (Object.prototype.hasOwnProperty.call(s, p) && e.indexOf(p) < 0)
        t[p] = s[p];
    if (s != null && typeof Object.getOwnPropertySymbols === "function")
        for (var i = 0, p = Object.getOwnPropertySymbols(s); i < p.length; i++) {
            if (e.indexOf(p[i]) < 0 && Object.prototype.propertyIsEnumerable.call(s, p[i]))
                t[p[i]] = s[p[i]];
        }
    return t;
};
















const logger = (0,_jitsi_logger__WEBPACK_IMPORTED_MODULE_0__.getLogger)(__filename);
const eventEmitter = new (events__WEBPACK_IMPORTED_MODULE_1___default())();
const AVAILABLE_DEVICES_POLL_INTERVAL_TIME = 3000; // ms
/**
 * Default MediaStreamConstraints to use for calls to getUserMedia.
 *
 * @private
 */
const DEFAULT_CONSTRAINTS = {
    video: {
        height: {
            ideal: 720,
            max: 720,
            min: 180
        },
        width: {
            ideal: 1280,
            max: 1280,
            min: 320
        }
    }
};
// Currently audio output device change is supported only in Chrome and
// default output always has 'default' device ID
let audioOutputDeviceId = 'default'; // default device
// whether user has explicitly set a device to use
let audioOutputChanged = false;
// Disables all audio processing
let disableAP = false;
// Disables Acoustic Echo Cancellation
let disableAEC = false;
// Disables Noise Suppression
let disableNS = false;
// Disables Automatic Gain Control
let disableAGC = false;
// Enables stereo.
let stereo = null;
const featureDetectionAudioEl = document.createElement('audio');
const isAudioOutputDeviceChangeAvailable = typeof featureDetectionAudioEl.setSinkId !== 'undefined';
let availableDevices = [];
let availableDevicesPollTimer;
/**
 * An empty function.
 */
function emptyFuncton() {
    // no-op
}
/**
 * Creates a constraints object to be passed into a call to getUserMedia.
 *
 * @param {Array} um - An array of user media types to get. The accepted types are "video", "audio", and "desktop."
 * @param {Object} options - Various values to be added to the constraints.
 * @param {string} options.cameraDeviceId - The device id for the video capture device to get video from.
 * @param {Object} options.constraints - Default constraints object to use as a base for the returned constraints.
 * @param {Object} options.desktopStream - The desktop source id from which to capture a desktop sharing video.
 * @param {string} options.facingMode - Which direction the camera is pointing to (applicable on mobile)
 * @param {string} options.micDeviceId - The device id for the audio capture device to get audio from.
 * @private
 * @returns {Object}
 */
function getConstraints(um = [], options = {}) {
    // Create a deep copy of the constraints to avoid any modification of
    // the passed in constraints object.
    const constraints = lodash_clonedeep__WEBPACK_IMPORTED_MODULE_2___default()(options.constraints || DEFAULT_CONSTRAINTS);
    if (um.indexOf('video') >= 0) {
        // The "resolution" option is a shortcut and takes precendence.
        if ((_service_RTC_Resolutions__WEBPACK_IMPORTED_MODULE_8___default())[options.resolution]) {
            const r = (_service_RTC_Resolutions__WEBPACK_IMPORTED_MODULE_8___default())[options.resolution];
            constraints.video.height = { ideal: r.height };
            constraints.video.width = { ideal: r.width };
        }
        if (!constraints.video) {
            constraints.video = {};
        }
        // Override the constraints on Safari because of the following webkit bug.
        // https://bugs.webkit.org/show_bug.cgi?id=210932
        // Camera doesn't start on older macOS versions if min/max constraints are specified.
        // TODO: remove this hack when the bug fix is available on Mojave, Sierra and High Sierra.
        if (_browser__WEBPACK_IMPORTED_MODULE_11__["default"].isWebKitBased()) {
            if (constraints.video.height && constraints.video.height.ideal) {
                constraints.video.height = { ideal: constraints.video.height.ideal };
            }
            else {
                logger.warn('Ideal camera height missing, camera may not start properly');
            }
            if (constraints.video.width && constraints.video.width.ideal) {
                constraints.video.width = { ideal: constraints.video.width.ideal };
            }
            else {
                logger.warn('Ideal camera width missing, camera may not start properly');
            }
        }
        if (options.cameraDeviceId) {
            constraints.video.deviceId = options.cameraDeviceId;
        }
        else {
            const facingMode = options.facingMode || (_service_RTC_CameraFacingMode__WEBPACK_IMPORTED_MODULE_6___default().USER);
            constraints.video.facingMode = facingMode;
        }
    }
    else {
        constraints.video = false;
    }
    if (um.indexOf('audio') >= 0) {
        if (!constraints.audio || typeof constraints.audio === 'boolean') {
            constraints.audio = {};
        }
        constraints.audio = {
            autoGainControl: !disableAGC && !disableAP,
            deviceId: options.micDeviceId,
            echoCancellation: !disableAEC && !disableAP,
            noiseSuppression: !disableNS && !disableAP
        };
        if (stereo) {
            Object.assign(constraints.audio, { channelCount: 2 });
        }
    }
    else {
        constraints.audio = false;
    }
    return constraints;
}
/**
 * Updates the granted permissions based on the options we requested and the
 * streams we received.
 * @param um the options we requested to getUserMedia.
 * @param stream the stream we received from calling getUserMedia.
 */
function updateGrantedPermissions(um, stream) {
    const audioTracksReceived = Boolean(stream) && stream.getAudioTracks().length > 0;
    const videoTracksReceived = Boolean(stream) && stream.getVideoTracks().length > 0;
    const grantedPermissions = {};
    if (um.indexOf('video') !== -1) {
        grantedPermissions.video = videoTracksReceived;
    }
    if (um.indexOf('audio') !== -1) {
        grantedPermissions.audio = audioTracksReceived;
    }
    eventEmitter.emit(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_7__["default"].PERMISSIONS_CHANGED, grantedPermissions);
}
/**
 * Checks if new list of available media devices differs from previous one.
 * @param {MediaDeviceInfo[]} newDevices - list of new devices.
 * @returns {boolean} - true if list is different, false otherwise.
 */
function compareAvailableMediaDevices(newDevices) {
    if (newDevices.length !== availableDevices.length) {
        return true;
    }
    /* eslint-disable newline-per-chained-call */
    return (newDevices.map(mediaDeviceInfoToJSON).sort().join('')
        !== availableDevices
            .map(mediaDeviceInfoToJSON).sort().join(''));
    /* eslint-enable newline-per-chained-call */
    /**
     *
     * @param info
     */
    function mediaDeviceInfoToJSON(info) {
        return JSON.stringify({
            kind: info.kind,
            deviceId: info.deviceId,
            groupId: info.groupId,
            label: info.label,
            facing: info.facing
        });
    }
}
/**
 * Sends analytics event with the passed device list.
 *
 * @param {Array<MediaDeviceInfo>} deviceList - List with info about the
 * available devices.
 * @returns {void}
 */
function sendDeviceListToAnalytics(deviceList) {
    const audioInputDeviceCount = deviceList.filter(d => d.kind === 'audioinput').length;
    const audioOutputDeviceCount = deviceList.filter(d => d.kind === 'audiooutput').length;
    const videoInputDeviceCount = deviceList.filter(d => d.kind === 'videoinput').length;
    const videoOutputDeviceCount = deviceList.filter(d => d.kind === 'videooutput').length;
    deviceList.forEach(device => {
        const attributes = {
            'audio_input_device_count': audioInputDeviceCount,
            'audio_output_device_count': audioOutputDeviceCount,
            'video_input_device_count': videoInputDeviceCount,
            'video_output_device_count': videoOutputDeviceCount,
            'device_id': device.deviceId,
            'device_group_id': device.groupId,
            'device_kind': device.kind,
            'device_label': device.label
        };
        _statistics_statistics__WEBPACK_IMPORTED_MODULE_12__["default"].sendAnalytics(_service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_10__.AVAILABLE_DEVICE, attributes);
    });
}
/**
 * Update known devices.
 *
 * @param {Array<Object>} pds - The new devices.
 * @returns {void}
 *
 * NOTE: Use this function as a shared callback to handle both the devicechange event  and the polling implementations.
 * This prevents duplication and works around a chrome bug (verified to occur on 68) where devicechange fires twice in
 * a row, which can cause async post devicechange processing to collide.
 */
function updateKnownDevices(pds) {
    if (compareAvailableMediaDevices(pds)) {
        onMediaDevicesListChanged(pds);
    }
}
/**
 * Event handler for the 'devicechange' event.
 *
 * @param {MediaDeviceInfo[]} devices - list of media devices.
 * @emits RTCEvents.DEVICE_LIST_CHANGED
 */
function onMediaDevicesListChanged(devicesReceived) {
    availableDevices = devicesReceived.slice(0);
    logger.info('list of media devices has changed:', availableDevices);
    sendDeviceListToAnalytics(availableDevices);
    // Used by tracks to update the real device id before the consumer of lib-jitsi-meet receives the new device list.
    eventEmitter.emit(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_7__["default"].DEVICE_LIST_WILL_CHANGE, availableDevices);
    eventEmitter.emit(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_7__["default"].DEVICE_LIST_CHANGED, availableDevices);
}
/**
 *
 */
class RTCUtils extends _util_Listenable__WEBPACK_IMPORTED_MODULE_14__["default"] {
    /**
     *
     */
    constructor() {
        super(eventEmitter);
    }
    /**
     * Depending on the browser, sets difference instance methods for
     * interacting with user media and adds methods to native WebRTC-related
     * objects. Also creates an instance variable for peer connection
     * constraints.
     *
     * @param {Object} options
     * @returns {void}
     */
    init(options = {}) {
        var _a;
        if (typeof options.disableAEC === 'boolean') {
            disableAEC = options.disableAEC;
            logger.info(`Disable AEC: ${disableAEC}`);
        }
        if (typeof options.disableNS === 'boolean') {
            disableNS = options.disableNS;
            logger.info(`Disable NS: ${disableNS}`);
        }
        if (typeof options.disableAP === 'boolean') {
            disableAP = options.disableAP;
            logger.info(`Disable AP: ${disableAP}`);
        }
        if (typeof options.disableAGC === 'boolean') {
            disableAGC = options.disableAGC;
            logger.info(`Disable AGC: ${disableAGC}`);
        }
        if (typeof ((_a = options.audioQuality) === null || _a === void 0 ? void 0 : _a.stereo) === 'boolean') {
            stereo = options.audioQuality.stereo;
            logger.info(`Stereo: ${stereo}`);
        }
        window.clearInterval(availableDevicesPollTimer);
        availableDevicesPollTimer = undefined;
        if (!_browser__WEBPACK_IMPORTED_MODULE_11__["default"].isReactNative()) {
            this.attachMediaStream
                = wrapAttachMediaStream((element, stream) => {
                    if (element) {
                        element.srcObject = stream;
                    }
                });
        }
        this.pcConstraints = {};
        _ScreenObtainer__WEBPACK_IMPORTED_MODULE_15__["default"].init(options);
        if (this.isDeviceListAvailable()) {
            this.enumerateDevices(ds => {
                availableDevices = ds.slice(0);
                logger.debug('Available devices: ', availableDevices);
                sendDeviceListToAnalytics(availableDevices);
                eventEmitter.emit(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_7__["default"].DEVICE_LIST_AVAILABLE, availableDevices);
                if (_browser__WEBPACK_IMPORTED_MODULE_11__["default"].supportsDeviceChangeEvent()) {
                    navigator.mediaDevices.addEventListener('devicechange', () => this.enumerateDevices(emptyFuncton));
                }
                else {
                    // Periodically poll enumerateDevices() method to check if
                    // list of media devices has changed.
                    availableDevicesPollTimer = window.setInterval(() => this.enumerateDevices(emptyFuncton), AVAILABLE_DEVICES_POLL_INTERVAL_TIME);
                }
            });
        }
    }
    /**
     *
     * @param {Function} callback
     */
    enumerateDevices(callback) {
        navigator.mediaDevices.enumerateDevices()
            .then(devices => {
            updateKnownDevices(devices);
            callback(devices);
        })
            .catch(error => {
            logger.warn(`Failed to  enumerate devices. ${error}`);
            updateKnownDevices([]);
            callback([]);
        });
    }
    /**
     * Acquires a media stream via getUserMedia that
     * matches the given constraints
     *
     * @param {array} umDevices which devices to acquire (e.g. audio, video)
     * @param {Object} constraints - Stream specifications to use.
     * @param {number} timeout - The timeout in ms for GUM.
     * @returns {Promise}
     */
    _getUserMedia(umDevices, constraints = {}, timeout = 0) {
        return new Promise((resolve, reject) => {
            let gumTimeout, timeoutExpired = false;
            if (typeof timeout === 'number' && !isNaN(timeout) && timeout > 0) {
                gumTimeout = setTimeout(() => {
                    timeoutExpired = true;
                    gumTimeout = undefined;
                    reject(new _JitsiTrackError__WEBPACK_IMPORTED_MODULE_4__["default"](_JitsiTrackErrors__WEBPACK_IMPORTED_MODULE_5__.TIMEOUT));
                }, timeout);
            }
            navigator.mediaDevices.getUserMedia(constraints)
                .then(stream => {
                logger.log('onUserMediaSuccess');
                updateGrantedPermissions(umDevices, stream);
                if (!timeoutExpired) {
                    if (typeof gumTimeout !== 'undefined') {
                        clearTimeout(gumTimeout);
                    }
                    resolve(stream);
                }
            })
                .catch(error => {
                logger.warn(`Failed to get access to local media. ${error} ${JSON.stringify(constraints)}`);
                const jitsiError = new _JitsiTrackError__WEBPACK_IMPORTED_MODULE_4__["default"](error, constraints, umDevices);
                if (!timeoutExpired) {
                    if (typeof gumTimeout !== 'undefined') {
                        clearTimeout(gumTimeout);
                    }
                    reject(jitsiError);
                }
                if (jitsiError.name === _JitsiTrackErrors__WEBPACK_IMPORTED_MODULE_5__.PERMISSION_DENIED) {
                    updateGrantedPermissions(umDevices, undefined);
                }
                // else {
                // Probably the error is not caused by the lack of permissions and we don't need to update them.
                // }
            });
        });
    }
    /**
     * Acquire a display stream via the screenObtainer. This requires extra
     * logic compared to use screenObtainer versus normal device capture logic
     * in RTCUtils#_getUserMedia.
     *
     * @param {Object} options - Optional parameters.
     * @returns {Promise} A promise which will be resolved with an object which
     * contains the acquired display stream. If desktop sharing is not supported
     * then a rejected promise will be returned.
     */
    _getDesktopMedia(options) {
        if (!_ScreenObtainer__WEBPACK_IMPORTED_MODULE_15__["default"].isSupported()) {
            return Promise.reject(new Error('Desktop sharing is not supported!'));
        }
        return new Promise((resolve, reject) => {
            _ScreenObtainer__WEBPACK_IMPORTED_MODULE_15__["default"].obtainStream(stream => {
                resolve(stream);
            }, error => {
                reject(error);
            }, options);
        });
    }
    /**
     * Private utility for determining if the passed in MediaStream contains
     * tracks of the type(s) specified in the requested devices.
     *
     * @param {string[]} requestedDevices - The track types that are expected to
     * be includes in the stream.
     * @param {MediaStream} stream - The MediaStream to check if it has the
     * expected track types.
     * @returns {string[]} An array of string with the missing track types. The
     * array will be empty if all requestedDevices are found in the stream.
     */
    _getMissingTracks(requestedDevices = [], stream) {
        const missingDevices = [];
        const audioDeviceRequested = requestedDevices.includes('audio');
        const audioTracksReceived = stream && stream.getAudioTracks().length > 0;
        if (audioDeviceRequested && !audioTracksReceived) {
            missingDevices.push('audio');
        }
        const videoDeviceRequested = requestedDevices.includes('video');
        const videoTracksReceived = stream && stream.getVideoTracks().length > 0;
        if (videoDeviceRequested && !videoTracksReceived) {
            missingDevices.push('video');
        }
        return missingDevices;
    }
    /**
     * Gets streams from specified device types. This function intentionally
     * ignores errors for upstream to catch and handle instead.
     *
     * @param {Object} options - A hash describing what devices to get and
     * relevant constraints.
     * @param {string[]} options.devices - The types of media to capture. Valid
     * values are "desktop", "audio", and "video".
     * @param {Object} options.desktopSharingFrameRate
     * @param {Object} options.desktopSharingFrameRate.min - Minimum fps
     * @param {Object} options.desktopSharingFrameRate.max - Maximum fps
     * @param {String} options.desktopSharingSourceDevice - The device id or
     * label for a video input source that should be used for screensharing.
     * @param {Array<string>} options.desktopSharingSources - The types of sources ("screen", "window", etc)
     * from which the user can select what to share.
     * @returns {Promise} The promise, when successful, will return an array of
     * meta data for the requested device type, which includes the stream and
     * track. If an error occurs, it will be deferred to the caller for
     * handling.
     */
    obtainAudioAndVideoPermissions(options) {
        const { timeout } = options, otherOptions = __rest(options, ["timeout"]);
        const mediaStreamsMetaData = [];
        // Declare private functions to be used in the promise chain below.
        // These functions are declared in the scope of this function because
        // they are not being used anywhere else, so only this function needs to
        // know about them.
        /**
         * Executes a request for desktop media if specified in options.
         *
         * @returns {Promise}
         */
        const maybeRequestDesktopDevice = function () {
            const umDevices = otherOptions.devices || [];
            const isDesktopDeviceRequested = umDevices.indexOf('desktop') !== -1;
            if (!isDesktopDeviceRequested) {
                return Promise.resolve();
            }
            const { desktopSharingSourceDevice, desktopSharingSources } = otherOptions;
            // Attempt to use a video input device as a screenshare source if
            // the option is defined.
            if (desktopSharingSourceDevice) {
                const matchingDevice = availableDevices && availableDevices.find(device => device.kind === 'videoinput'
                    && (device.deviceId === desktopSharingSourceDevice
                        || device.label === desktopSharingSourceDevice));
                if (!matchingDevice) {
                    return Promise.reject(new _JitsiTrackError__WEBPACK_IMPORTED_MODULE_4__["default"]({ name: 'ConstraintNotSatisfiedError' }, {}, [desktopSharingSourceDevice]));
                }
                const requestedDevices = ['video'];
                const constraints = {
                    video: {
                        deviceId: matchingDevice.deviceId
                        // frameRate is omited here on purpose since this is a device that we'll pretend is a screen.
                    }
                };
                return this._getUserMedia(requestedDevices, constraints, timeout)
                    .then(stream => {
                    return {
                        sourceType: 'device',
                        stream
                    };
                });
            }
            return this._getDesktopMedia({ desktopSharingSources });
        }.bind(this);
        /**
         * Creates a meta data object about the passed in desktopStream and
         * pushes the meta data to the internal array mediaStreamsMetaData to be
         * returned later.
         *
         * @param {MediaStreamTrack} desktopStream - A track for a desktop
         * capture.
         * @returns {void}
         */
        const maybeCreateAndAddDesktopTrack = function (desktopStream) {
            if (!desktopStream) {
                return;
            }
            const { stream, sourceId, sourceType } = desktopStream;
            const desktopAudioTracks = stream.getAudioTracks();
            if (desktopAudioTracks.length) {
                const desktopAudioStream = new MediaStream(desktopAudioTracks);
                mediaStreamsMetaData.push({
                    stream: desktopAudioStream,
                    sourceId,
                    sourceType,
                    track: desktopAudioStream.getAudioTracks()[0]
                });
            }
            const desktopVideoTracks = stream.getVideoTracks();
            if (desktopVideoTracks.length) {
                const desktopVideoStream = new MediaStream(desktopVideoTracks);
                mediaStreamsMetaData.push({
                    stream: desktopVideoStream,
                    sourceId,
                    sourceType,
                    track: desktopVideoStream.getVideoTracks()[0],
                    videoType: _service_RTC_VideoType__WEBPACK_IMPORTED_MODULE_9__.VideoType.DESKTOP
                });
            }
        };
        /**
         * Executes a request for audio and/or video, as specified in options.
         * By default both audio and video will be captured if options.devices
         * is not defined.
         *
         * @returns {Promise}
         */
        const maybeRequestCaptureDevices = function () {
            const umDevices = otherOptions.devices || ['audio', 'video'];
            const requestedCaptureDevices = umDevices.filter(device => device === 'audio' || device === 'video');
            if (!requestedCaptureDevices.length) {
                return Promise.resolve();
            }
            const constraints = getConstraints(requestedCaptureDevices, otherOptions);
            logger.info('Got media constraints: ', JSON.stringify(constraints));
            return this._getUserMedia(requestedCaptureDevices, constraints, timeout);
        }.bind(this);
        /**
         * Splits the passed in media stream into separate audio and video
         * streams and creates meta data objects for each and pushes them to the
         * internal array mediaStreamsMetaData to be returned later.
         *
         * @param {MediaStreamTrack} avStream - A track for with audio and/or
         * video track.
         * @returns {void}
         */
        const maybeCreateAndAddAVTracks = function (avStream) {
            if (!avStream) {
                return;
            }
            const audioTracks = avStream.getAudioTracks();
            if (audioTracks.length) {
                const audioStream = new MediaStream(audioTracks);
                mediaStreamsMetaData.push({
                    stream: audioStream,
                    track: audioStream.getAudioTracks()[0],
                    effects: otherOptions.effects
                });
            }
            const videoTracks = avStream.getVideoTracks();
            if (videoTracks.length) {
                const videoStream = new MediaStream(videoTracks);
                mediaStreamsMetaData.push({
                    stream: videoStream,
                    track: videoStream.getVideoTracks()[0],
                    videoType: _service_RTC_VideoType__WEBPACK_IMPORTED_MODULE_9__.VideoType.CAMERA,
                    effects: otherOptions.effects
                });
            }
        };
        return maybeRequestDesktopDevice()
            .then(maybeCreateAndAddDesktopTrack)
            .then(maybeRequestCaptureDevices)
            .then(maybeCreateAndAddAVTracks)
            .then(() => mediaStreamsMetaData)
            .catch(error => {
            mediaStreamsMetaData.forEach(({ stream }) => {
                this.stopMediaStream(stream);
            });
            return Promise.reject(error);
        });
    }
    /**
     * Checks whether it is possible to enumerate available cameras/microphones.
     *
     * @returns {boolean} {@code true} if the device listing is available;
     * {@code false}, otherwise.
     */
    isDeviceListAvailable() {
        return Boolean(navigator.mediaDevices
            && navigator.mediaDevices.enumerateDevices);
    }
    /**
     * Returns true if changing the input (camera / microphone) or output
     * (audio) device is supported and false if not.
     * @params {string} [deviceType] - type of device to change. Default is
     *      undefined or 'input', 'output' - for audio output device change.
     * @returns {boolean} true if available, false otherwise.
     */
    isDeviceChangeAvailable(deviceType) {
        if (deviceType === 'output' || deviceType === 'audiooutput') {
            return isAudioOutputDeviceChangeAvailable;
        }
        return true;
    }
    /**
     * A method to handle stopping of the stream.
     * One point to handle the differences in various implementations.
     * @param mediaStream MediaStream object to stop.
     */
    stopMediaStream(mediaStream) {
        if (!mediaStream) {
            return;
        }
        mediaStream.getTracks().forEach(track => {
            if (track.stop) {
                track.stop();
            }
        });
        // leave stop for implementation still using it
        if (mediaStream.stop) {
            mediaStream.stop();
        }
        // The MediaStream implementation of the react-native-webrtc project has
        // an explicit release method that is to be invoked in order to release
        // used resources such as memory.
        if (mediaStream.release) {
            mediaStream.release();
        }
    }
    /**
     * Returns whether the desktop sharing is enabled or not.
     * @returns {boolean}
     */
    isDesktopSharingEnabled() {
        return _ScreenObtainer__WEBPACK_IMPORTED_MODULE_15__["default"].isSupported();
    }
    /**
     * Sets current audio output device.
     * @param {string} deviceId - id of 'audiooutput' device from
     *      navigator.mediaDevices.enumerateDevices(), 'default' for default
     *      device
     * @returns {Promise} - resolves when audio output is changed, is rejected
     *      otherwise
     */
    setAudioOutputDevice(deviceId) {
        if (!this.isDeviceChangeAvailable('output')) {
            return Promise.reject(new Error('Audio output device change is not supported'));
        }
        return featureDetectionAudioEl.setSinkId(deviceId)
            .then(() => {
            audioOutputDeviceId = deviceId;
            audioOutputChanged = true;
            logger.log(`Audio output device set to ${deviceId}`);
            eventEmitter.emit(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_7__["default"].AUDIO_OUTPUT_DEVICE_CHANGED, deviceId);
        });
    }
    /**
     * Sets the capture frame rate for desktop tracks.
     *
     * @param {number} maxFps - max fps to be used as the capture frame rate.
     * @returns {void}
     */
    setDesktopSharingFrameRate(maxFps) {
        _ScreenObtainer__WEBPACK_IMPORTED_MODULE_15__["default"].setDesktopSharingFrameRate(maxFps);
    }
    /**
     * Returns currently used audio output device id, '' stands for default
     * device
     * @returns {string}
     */
    getAudioOutputDevice() {
        return audioOutputDeviceId;
    }
    /**
     * Returns list of available media devices if its obtained, otherwise an
     * empty array is returned/
     * @returns {Array} list of available media devices.
     */
    getCurrentlyAvailableMediaDevices() {
        return availableDevices;
    }
    /**
     * Returns whether available devices have permissions granted
     * @returns {Boolean}
     */
    arePermissionsGrantedForAvailableDevices() {
        return availableDevices.some(device => Boolean(device.label));
    }
    /**
     * Returns event data for device to be reported to stats.
     * @returns {MediaDeviceInfo} device.
     */
    getEventDataForActiveDevice(device) {
        const deviceList = [];
        const deviceData = {
            'deviceId': device.deviceId,
            'kind': device.kind,
            'label': device.label,
            'groupId': device.groupId
        };
        deviceList.push(deviceData);
        return { deviceList };
    }
}
const rtcUtils = new RTCUtils();
/**
 * Wraps original attachMediaStream function to set current audio output device
 * if this is supported.
 * @param {Function} origAttachMediaStream
 * @returns {Function}
 */
function wrapAttachMediaStream(origAttachMediaStream) {
    return function (element, stream) {
        // eslint-disable-next-line prefer-rest-params
        const res = origAttachMediaStream.apply(rtcUtils, arguments);
        if (stream
            && rtcUtils.isDeviceChangeAvailable('output')
            && stream.getAudioTracks
            && stream.getAudioTracks().length
            // we skip setting audio output if there was no explicit change
            && audioOutputChanged) {
            element.setSinkId(rtcUtils.getAudioOutputDevice())
                .catch(function (ex) {
                const err = new _JitsiTrackError__WEBPACK_IMPORTED_MODULE_4__["default"](ex, null, ['audiooutput']);
                _util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_13___default().callUnhandledRejectionHandler({
                    promise: this,
                    reason: err
                });
                logger.warn('Failed to set audio output device for the element.'
                    + ' Default audio output device will be used'
                    + ' instead', element, err);
            });
        }
        return res;
    };
}
/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (rtcUtils);
//# sourceMappingURL=RTCUtils.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/RTC/ScreenObtainer.js":
/*!***********************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/RTC/ScreenObtainer.js ***!
  \***********************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
var __filename = "/index.js";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   SS_DEFAULT_FRAME_RATE: () => (/* binding */ SS_DEFAULT_FRAME_RATE),
/* harmony export */   "default": () => (__WEBPACK_DEFAULT_EXPORT__)
/* harmony export */ });
/* harmony import */ var _JitsiTrackError__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../JitsiTrackError */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/JitsiTrackError.js");
/* harmony import */ var _JitsiTrackErrors__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../JitsiTrackErrors */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/JitsiTrackErrors.js");
/* harmony import */ var _browser__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../browser */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/browser/index.js");



const logger = (__webpack_require__(/*! @jitsi/logger */ "./node_modules/@jitsi/logger/lib/index.js").getLogger)(__filename);
/**
 * The default frame rate for Screen Sharing.
 */
const SS_DEFAULT_FRAME_RATE = 5;
/**
 * Handles obtaining a stream from a screen capture on different browsers.
 */
const ScreenObtainer = {
    /**
     * If not <tt>null</tt> it means that the initialization process is still in
     * progress. It is used to make desktop stream request wait and continue
     * after it's done.
     * {@type Promise|null}
     */
    obtainStream: null,
    /**
     * Initializes the function used to obtain a screen capture
     * (this.obtainStream).
     *
     * @param {object} options
     */
    init(options = {}) {
        this.options = options;
        this.obtainStream = this._createObtainStreamMethod();
        if (!this.obtainStream) {
            logger.info('Desktop sharing disabled');
        }
    },
    /**
     * Returns a method which will be used to obtain the screen sharing stream
     * (based on the browser type).
     *
     * @returns {Function}
     * @private
     */
    _createObtainStreamMethod() {
        if (_browser__WEBPACK_IMPORTED_MODULE_2__["default"].isNWJS()) {
            return (onSuccess, onFailure) => {
                window.JitsiMeetNW.obtainDesktopStream(onSuccess, (error, constraints) => {
                    let jitsiError;
                    // FIXME:
                    // This is very very dirty fix for recognising that the
                    // user have clicked the cancel button from the Desktop
                    // sharing pick window. The proper solution would be to
                    // detect this in the NWJS application by checking the
                    // streamId === "". Even better solution would be to
                    // stop calling GUM from the NWJS app and just pass the
                    // streamId to lib-jitsi-meet. This way the desktop
                    // sharing implementation for NWJS and chrome extension
                    // will be the same and lib-jitsi-meet will be able to
                    // control the constraints, check the streamId, etc.
                    //
                    // I cannot find documentation about "InvalidStateError"
                    // but this is what we are receiving from GUM when the
                    // streamId for the desktop sharing is "".
                    if (error && error.name === 'InvalidStateError') {
                        jitsiError = new _JitsiTrackError__WEBPACK_IMPORTED_MODULE_0__["default"](_JitsiTrackErrors__WEBPACK_IMPORTED_MODULE_1__.SCREENSHARING_USER_CANCELED);
                    }
                    else {
                        jitsiError = new _JitsiTrackError__WEBPACK_IMPORTED_MODULE_0__["default"](error, constraints, ['desktop']);
                    }
                    (typeof onFailure === 'function')
                        && onFailure(jitsiError);
                });
            };
        }
        else if (_browser__WEBPACK_IMPORTED_MODULE_2__["default"].isElectron()) {
            return this.obtainScreenOnElectron;
        }
        else if (_browser__WEBPACK_IMPORTED_MODULE_2__["default"].isReactNative() && _browser__WEBPACK_IMPORTED_MODULE_2__["default"].supportsGetDisplayMedia()) {
            return this.obtainScreenFromGetDisplayMediaRN;
        }
        else if (_browser__WEBPACK_IMPORTED_MODULE_2__["default"].supportsGetDisplayMedia()) {
            return this.obtainScreenFromGetDisplayMedia;
        }
        logger.log('Screen sharing not supported on ', _browser__WEBPACK_IMPORTED_MODULE_2__["default"].getName());
        return null;
    },
    /**
     * Gets the appropriate constraints for audio sharing.
     *
     * @returns {Object|boolean}
     */
    _getAudioConstraints() {
        const { audioQuality } = this.options;
        const audio = (audioQuality === null || audioQuality === void 0 ? void 0 : audioQuality.stereo) ? {
            autoGainControl: false,
            channelCount: 2,
            echoCancellation: false,
            noiseSuppression: false
        } : true;
        return audio;
    },
    /**
     * Checks whether obtaining a screen capture is supported in the current
     * environment.
     * @returns {boolean}
     */
    isSupported() {
        return this.obtainStream !== null;
    },
    /**
     * Obtains a screen capture stream on Electron.
     *
     * @param onSuccess - Success callback.
     * @param onFailure - Failure callback.
     * @param {Object} options - Optional parameters.
     */
    obtainScreenOnElectron(onSuccess, onFailure, options = {}) {
        if (window.JitsiMeetScreenObtainer && window.JitsiMeetScreenObtainer.openDesktopPicker) {
            const { desktopSharingFrameRate, desktopSharingResolution, desktopSharingSources } = this.options;
            window.JitsiMeetScreenObtainer.openDesktopPicker({
                desktopSharingSources: options.desktopSharingSources || desktopSharingSources || ['screen', 'window']
            }, (streamId, streamType, screenShareAudio = false) => {
                var _a, _b, _c, _d, _e, _f, _g, _h;
                if (streamId) {
                    let audioConstraints = false;
                    if (screenShareAudio) {
                        audioConstraints = {};
                        const optionalConstraints = this._getAudioConstraints();
                        if (typeof optionalConstraints !== 'boolean') {
                            audioConstraints = {
                                optional: optionalConstraints
                            };
                        }
                        // Audio screen sharing for electron only works for screen type devices.
                        // i.e. when the user shares the whole desktop.
                        // Note. The documentation specifies that chromeMediaSourceId should not be present
                        // which, in the case a users has multiple monitors, leads to them being shared all
                        // at once. However we tested with chromeMediaSourceId present and it seems to be
                        // working properly.
                        if (streamType === 'screen') {
                            audioConstraints.mandatory = {
                                chromeMediaSource: 'desktop'
                            };
                        }
                    }
                    const constraints = {
                        audio: audioConstraints,
                        video: {
                            mandatory: {
                                chromeMediaSource: 'desktop',
                                chromeMediaSourceId: streamId,
                                minFrameRate: (_a = desktopSharingFrameRate === null || desktopSharingFrameRate === void 0 ? void 0 : desktopSharingFrameRate.min) !== null && _a !== void 0 ? _a : SS_DEFAULT_FRAME_RATE,
                                maxFrameRate: (_b = desktopSharingFrameRate === null || desktopSharingFrameRate === void 0 ? void 0 : desktopSharingFrameRate.max) !== null && _b !== void 0 ? _b : SS_DEFAULT_FRAME_RATE,
                                minWidth: (_c = desktopSharingResolution === null || desktopSharingResolution === void 0 ? void 0 : desktopSharingResolution.width) === null || _c === void 0 ? void 0 : _c.min,
                                minHeight: (_d = desktopSharingResolution === null || desktopSharingResolution === void 0 ? void 0 : desktopSharingResolution.height) === null || _d === void 0 ? void 0 : _d.min,
                                maxWidth: (_f = (_e = desktopSharingResolution === null || desktopSharingResolution === void 0 ? void 0 : desktopSharingResolution.width) === null || _e === void 0 ? void 0 : _e.max) !== null && _f !== void 0 ? _f : window.screen.width,
                                maxHeight: (_h = (_g = desktopSharingResolution === null || desktopSharingResolution === void 0 ? void 0 : desktopSharingResolution.height) === null || _g === void 0 ? void 0 : _g.max) !== null && _h !== void 0 ? _h : window.screen.height
                            }
                        }
                    };
                    // We have to use the old API on Electron to get a desktop stream.
                    navigator.mediaDevices.getUserMedia(constraints)
                        .then(stream => {
                        this.setContentHint(stream);
                        onSuccess({
                            stream,
                            sourceId: streamId,
                            sourceType: streamType
                        });
                    })
                        .catch(err => onFailure(err));
                }
                else {
                    // As noted in Chrome Desktop Capture API:
                    // If user didn't select any source (i.e. canceled the prompt)
                    // then the callback is called with an empty streamId.
                    onFailure(new _JitsiTrackError__WEBPACK_IMPORTED_MODULE_0__["default"](_JitsiTrackErrors__WEBPACK_IMPORTED_MODULE_1__.SCREENSHARING_USER_CANCELED));
                }
            }, err => onFailure(new _JitsiTrackError__WEBPACK_IMPORTED_MODULE_0__["default"](_JitsiTrackErrors__WEBPACK_IMPORTED_MODULE_1__.ELECTRON_DESKTOP_PICKER_ERROR, err)));
        }
        else {
            onFailure(new _JitsiTrackError__WEBPACK_IMPORTED_MODULE_0__["default"](_JitsiTrackErrors__WEBPACK_IMPORTED_MODULE_1__.ELECTRON_DESKTOP_PICKER_NOT_FOUND));
        }
    },
    /**
     * Obtains a screen capture stream using getDisplayMedia.
     *
     * @param callback - The success callback.
     * @param errorCallback - The error callback.
     */
    obtainScreenFromGetDisplayMedia(callback, errorCallback) {
        let getDisplayMedia;
        if (navigator.getDisplayMedia) {
            getDisplayMedia = navigator.getDisplayMedia.bind(navigator);
        }
        else {
            // eslint-disable-next-line max-len
            getDisplayMedia = navigator.mediaDevices.getDisplayMedia.bind(navigator.mediaDevices);
        }
        const audio = this._getAudioConstraints();
        let video = {};
        const { desktopSharingFrameRate } = this.options;
        if (typeof desktopSharingFrameRate === 'object') {
            video.frameRate = desktopSharingFrameRate;
        }
        // At the time of this writing 'min' constraint for fps is not supported by getDisplayMedia on any of the
        // browsers. getDisplayMedia will fail with an error "invalid constraints" in this case.
        video.frameRate && delete video.frameRate.min;
        if (_browser__WEBPACK_IMPORTED_MODULE_2__["default"].isChromiumBased()) {
            // Allow users to seamlessly switch which tab they are sharing without having to select the tab again.
            _browser__WEBPACK_IMPORTED_MODULE_2__["default"].isVersionGreaterThan(106) && (video.surfaceSwitching = 'include');
            // Set bogus resolution constraints to work around
            // https://bugs.chromium.org/p/chromium/issues/detail?id=1056311 for low fps screenshare. Capturing SS at
            // very high resolutions restricts the framerate. Therefore, skip this hack when capture fps > 5 fps.
            if (!((desktopSharingFrameRate === null || desktopSharingFrameRate === void 0 ? void 0 : desktopSharingFrameRate.max) > SS_DEFAULT_FRAME_RATE)) {
                video.height = 99999;
                video.width = 99999;
            }
        }
        if (Object.keys(video).length === 0) {
            video = true;
        }
        const constraints = {
            video,
            audio,
            cursor: 'always'
        };
        logger.info('Using getDisplayMedia for screen sharing', constraints);
        getDisplayMedia(constraints)
            .then(stream => {
            this.setContentHint(stream);
            callback({
                stream,
                sourceId: stream.id
            });
        })
            .catch(error => {
            const errorDetails = {
                errorName: error && error.name,
                errorMsg: error && error.message,
                errorStack: error && error.stack
            };
            logger.error('getDisplayMedia error', constraints, errorDetails);
            if (errorDetails.errorMsg && errorDetails.errorMsg.indexOf('denied by system') !== -1) {
                // On Chrome this is the only thing different between error returned when user cancels
                // and when no permission was given on the OS level.
                errorCallback(new _JitsiTrackError__WEBPACK_IMPORTED_MODULE_0__["default"](_JitsiTrackErrors__WEBPACK_IMPORTED_MODULE_1__.PERMISSION_DENIED));
                return;
            }
            errorCallback(new _JitsiTrackError__WEBPACK_IMPORTED_MODULE_0__["default"](_JitsiTrackErrors__WEBPACK_IMPORTED_MODULE_1__.SCREENSHARING_USER_CANCELED));
        });
    },
    /**
     * Obtains a screen capture stream using getDisplayMedia.
     *
     * @param callback - The success callback.
     * @param errorCallback - The error callback.
     */
    obtainScreenFromGetDisplayMediaRN(callback, errorCallback) {
        logger.info('Using getDisplayMedia for screen sharing');
        navigator.mediaDevices.getDisplayMedia({ video: true })
            .then(stream => {
            this.setContentHint(stream);
            callback({
                stream,
                sourceId: stream.id
            });
        })
            .catch(() => {
            errorCallback(new _JitsiTrackError__WEBPACK_IMPORTED_MODULE_0__["default"](_JitsiTrackErrors__WEBPACK_IMPORTED_MODULE_1__.SCREENSHARING_USER_CANCELED));
        });
    },
    /** Sets the contentHint on the transmitted MediaStreamTrack to indicate charaterstics in the video stream, which
     * informs RTCPeerConnection on how to encode the track (to prefer motion or individual frame detail).
     *
     * @param {MediaStream} stream - The captured desktop stream.
     * @returns {void}
     */
    setContentHint(stream) {
        const { desktopSharingFrameRate } = this.options;
        const desktopTrack = stream.getVideoTracks()[0];
        // Set contentHint on the desktop track based on the fps requested.
        if ('contentHint' in desktopTrack) {
            desktopTrack.contentHint = (desktopSharingFrameRate === null || desktopSharingFrameRate === void 0 ? void 0 : desktopSharingFrameRate.max) > SS_DEFAULT_FRAME_RATE ? 'motion' : 'detail';
        }
        else {
            logger.warn('MediaStreamTrack contentHint attribute not supported');
        }
    },
    /**
     * Sets the max frame rate to be used for a desktop track capture.
     *
     * @param {number} maxFps capture frame rate to be used for desktop tracks.
     * @returns {void}
     */
    setDesktopSharingFrameRate(maxFps) {
        logger.info(`Setting the desktop capture rate to ${maxFps}`);
        this.options.desktopSharingFrameRate = {
            min: SS_DEFAULT_FRAME_RATE,
            max: maxFps
        };
    }
};
/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (ScreenObtainer);
//# sourceMappingURL=ScreenObtainer.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/RTC/TPCUtils.js":
/*!*****************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/RTC/TPCUtils.js ***!
  \*****************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
var __filename = "/index.js";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   HD_BITRATE: () => (/* binding */ HD_BITRATE),
/* harmony export */   HD_SCALE_FACTOR: () => (/* binding */ HD_SCALE_FACTOR),
/* harmony export */   LD_SCALE_FACTOR: () => (/* binding */ LD_SCALE_FACTOR),
/* harmony export */   SD_SCALE_FACTOR: () => (/* binding */ SD_SCALE_FACTOR),
/* harmony export */   SIM_LAYER_RIDS: () => (/* binding */ SIM_LAYER_RIDS),
/* harmony export */   TPCUtils: () => (/* binding */ TPCUtils)
/* harmony export */ });
/* harmony import */ var _jitsi_logger__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @jitsi/logger */ "./node_modules/@jitsi/logger/lib/index.js");
/* harmony import */ var _jitsi_logger__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(_jitsi_logger__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var sdp_transform__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! sdp-transform */ "./node_modules/sdp-transform/lib/index.js");
/* harmony import */ var _service_RTC_MediaDirection__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../service/RTC/MediaDirection */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/RTC/MediaDirection.js");
/* harmony import */ var _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../service/RTC/MediaType */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/RTC/MediaType.js");
/* harmony import */ var _service_RTC_SignalingLayer__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../../service/RTC/SignalingLayer */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/RTC/SignalingLayer.js");
/* harmony import */ var _service_RTC_VideoType__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../../service/RTC/VideoType */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/RTC/VideoType.js");
/* harmony import */ var _browser__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../browser */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/browser/index.js");
/* harmony import */ var _flags_FeatureFlags__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../flags/FeatureFlags */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/flags/FeatureFlags.js");








const logger = (0,_jitsi_logger__WEBPACK_IMPORTED_MODULE_0__.getLogger)(__filename);
const DESKTOP_SHARE_RATE = 500000;
const LD_BITRATE = 200000;
const SD_BITRATE = 700000;
const SIM_LAYER_1_RID = '1';
const SIM_LAYER_2_RID = '2';
const SIM_LAYER_3_RID = '3';
const HD_BITRATE = 2500000;
const HD_SCALE_FACTOR = 1;
const LD_SCALE_FACTOR = 4;
const SD_SCALE_FACTOR = 2;
const SIM_LAYER_RIDS = [SIM_LAYER_1_RID, SIM_LAYER_2_RID, SIM_LAYER_3_RID];
/**
 * Handles track related operations on TraceablePeerConnection when browser is
 * running in unified plan mode.
 */
class TPCUtils {
    /**
     * Creates a new instance for a given TraceablePeerConnection
     *
     * @param peerconnection - the tpc instance for which we have utility functions.
     */
    constructor(peerconnection) {
        var _a, _b, _c;
        this.pc = peerconnection;
        const bitrateSettings = (_b = (_a = this.pc.options) === null || _a === void 0 ? void 0 : _a.videoQuality) === null || _b === void 0 ? void 0 : _b.maxBitratesVideo;
        const standardBitrates = {
            low: LD_BITRATE,
            standard: SD_BITRATE,
            high: HD_BITRATE,
            ssHigh: HD_BITRATE
        };
        // Check if the max. bitrates for video are specified through config.js videoQuality settings.
        // Right now only VP8 bitrates are configured on the simulcast encodings, VP9 bitrates have to be
        // configured on the SDP using b:AS line.
        this.videoBitrates = bitrateSettings !== null && bitrateSettings !== void 0 ? bitrateSettings : standardBitrates;
        this.encodingBitrates = (_c = this.videoBitrates.VP8) !== null && _c !== void 0 ? _c : this.videoBitrates;
    }
    /**
     * Obtains stream encodings that need to be configured on the given track based
     * on the track media type and the simulcast setting.
     * @param {JitsiLocalTrack} localTrack
     */
    _getStreamEncodings(localTrack) {
        if (this.pc.isSimulcastOn() && localTrack.isVideoTrack()) {
            return this._getVideoStreamEncodings(localTrack.getVideoType());
        }
        return localTrack.isVideoTrack()
            ? [{
                    active: this.pc.videoTransferActive,
                    maxBitrate: this.videoBitrates.high
                }]
            : [{ active: this.pc.audioTransferActive }];
    }
    /**
     * The startup configuration for the stream encodings that are applicable to
     * the video stream when a new sender is created on the peerconnection. The initial
     * config takes into account the differences in browser's simulcast implementation.
     *
     * Encoding parameters:
     * active - determine the on/off state of a particular encoding.
     * maxBitrate - max. bitrate value to be applied to that particular encoding
     *  based on the encoding's resolution and config.js videoQuality settings if applicable.
     * rid - Rtp Stream ID that is configured for a particular simulcast stream.
     * scaleResolutionDownBy - the factor by which the encoding is scaled down from the
     *  original resolution of the captured video.
     *
     *  @param {VideoType} videoType
     */
    _getVideoStreamEncodings(videoType) {
        const maxVideoBitrate = videoType === _service_RTC_VideoType__WEBPACK_IMPORTED_MODULE_5__.VideoType.DESKTOP && this.encodingBitrates.ssHigh
            ? this.encodingBitrates.ssHigh : this.encodingBitrates.high;
        return [
            {
                active: this.pc.videoTransferActive,
                maxBitrate: _browser__WEBPACK_IMPORTED_MODULE_6__["default"].isFirefox() ? maxVideoBitrate : this.encodingBitrates.low,
                rid: SIM_LAYER_1_RID,
                scaleResolutionDownBy: _browser__WEBPACK_IMPORTED_MODULE_6__["default"].isFirefox() ? HD_SCALE_FACTOR : LD_SCALE_FACTOR
            },
            {
                active: this.pc.videoTransferActive,
                maxBitrate: this.encodingBitrates.standard,
                rid: SIM_LAYER_2_RID,
                scaleResolutionDownBy: SD_SCALE_FACTOR
            },
            {
                active: this.pc.videoTransferActive,
                maxBitrate: _browser__WEBPACK_IMPORTED_MODULE_6__["default"].isFirefox() ? this.encodingBitrates.low : maxVideoBitrate,
                rid: SIM_LAYER_3_RID,
                scaleResolutionDownBy: _browser__WEBPACK_IMPORTED_MODULE_6__["default"].isFirefox() ? LD_SCALE_FACTOR : HD_SCALE_FACTOR
            }
        ];
    }
    /**
     * Ensures that the ssrcs associated with a FID ssrc-group appear in the correct order, i.e.,
     * the primary ssrc first and the secondary rtx ssrc later. This is important for unified
     * plan since we have only one FID group per media description.
     * @param {Object} description the webRTC session description instance for the remote
     * description.
     * @private
     */
    ensureCorrectOrderOfSsrcs(description) {
        const parsedSdp = sdp_transform__WEBPACK_IMPORTED_MODULE_1__.parse(description.sdp);
        parsedSdp.media.forEach(mLine => {
            if (mLine.type === _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_3__.MediaType.AUDIO) {
                return;
            }
            if (!mLine.ssrcGroups || !mLine.ssrcGroups.length) {
                return;
            }
            let reorderedSsrcs = [];
            const ssrcs = new Set();
            mLine.ssrcGroups.map(group => group.ssrcs
                .split(' ')
                .filter(Boolean)
                .forEach(ssrc => ssrcs.add(ssrc)));
            ssrcs.forEach(ssrc => {
                const sources = mLine.ssrcs.filter(source => source.id.toString() === ssrc);
                reorderedSsrcs = reorderedSsrcs.concat(sources);
            });
            mLine.ssrcs = reorderedSsrcs;
        });
        return new RTCSessionDescription({
            type: description.type,
            sdp: sdp_transform__WEBPACK_IMPORTED_MODULE_1__.write(parsedSdp)
        });
    }
    /**
     * Returns the transceiver associated with a given RTCRtpSender/RTCRtpReceiver.
     *
     * @param {string} mediaType - type of track associated with the transceiver 'audio' or 'video'.
     * @param {JitsiLocalTrack} localTrack - local track to be used for lookup.
     * @returns {RTCRtpTransceiver}
     */
    findTransceiver(mediaType, localTrack = null) {
        const transceiver = (localTrack === null || localTrack === void 0 ? void 0 : localTrack.track) && localTrack.getOriginalStream()
            ? this.pc.peerconnection.getTransceivers().find(t => { var _a, _b; return ((_b = (_a = t.sender) === null || _a === void 0 ? void 0 : _a.track) === null || _b === void 0 ? void 0 : _b.id) === localTrack.getTrackId(); })
            : this.pc.peerconnection.getTransceivers().find(t => { var _a, _b; return ((_b = (_a = t.receiver) === null || _a === void 0 ? void 0 : _a.track) === null || _b === void 0 ? void 0 : _b.kind) === mediaType; });
        return transceiver;
    }
    /**
     * Takes in a *unified plan* offer and inserts the appropriate
     * parameters for adding simulcast receive support.
     * @param {Object} desc - A session description object
     * @param {String} desc.type - the type (offer/answer)
     * @param {String} desc.sdp - the sdp content
     *
     * @return {Object} A session description (same format as above) object
     * with its sdp field modified to advertise simulcast receive support
     */
    insertUnifiedPlanSimulcastReceive(desc) {
        // a=simulcast line is not needed on browsers where we SDP munging is used for enabling on simulcast.
        // Remove this check when the client switches to RID/MID based simulcast on all browsers.
        if (_browser__WEBPACK_IMPORTED_MODULE_6__["default"].usesSdpMungingForSimulcast()) {
            return desc;
        }
        const sdp = sdp_transform__WEBPACK_IMPORTED_MODULE_1__.parse(desc.sdp);
        const idx = sdp.media.findIndex(mline => mline.type === _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_3__.MediaType.VIDEO);
        if (sdp.media[idx].rids && (sdp.media[idx].simulcast_03 || sdp.media[idx].simulcast)) {
            // Make sure we don't have the simulcast recv line on video descriptions other than
            // the first video description.
            sdp.media.forEach((mline, i) => {
                if (mline.type === _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_3__.MediaType.VIDEO && i !== idx) {
                    sdp.media[i].rids = undefined;
                    sdp.media[i].simulcast = undefined;
                    // eslint-disable-next-line camelcase
                    sdp.media[i].simulcast_03 = undefined;
                }
            });
            return new RTCSessionDescription({
                type: desc.type,
                sdp: sdp_transform__WEBPACK_IMPORTED_MODULE_1__.write(sdp)
            });
        }
        // In order of highest to lowest spatial quality
        sdp.media[idx].rids = [
            {
                id: SIM_LAYER_1_RID,
                direction: 'recv'
            },
            {
                id: SIM_LAYER_2_RID,
                direction: 'recv'
            },
            {
                id: SIM_LAYER_3_RID,
                direction: 'recv'
            }
        ];
        // Firefox 72 has stopped parsing the legacy rid= parameters in simulcast attributes.
        // eslint-disable-next-line max-len
        // https://www.fxsitecompat.dev/en-CA/docs/2019/pt-and-rid-in-webrtc-simulcast-attributes-are-no-longer-supported/
        const simulcastLine = _browser__WEBPACK_IMPORTED_MODULE_6__["default"].isFirefox() && _browser__WEBPACK_IMPORTED_MODULE_6__["default"].isVersionGreaterThan(71)
            ? `recv ${SIM_LAYER_RIDS.join(';')}`
            : `recv rid=${SIM_LAYER_RIDS.join(';')}`;
        // eslint-disable-next-line camelcase
        sdp.media[idx].simulcast_03 = {
            value: simulcastLine
        };
        return new RTCSessionDescription({
            type: desc.type,
            sdp: sdp_transform__WEBPACK_IMPORTED_MODULE_1__.write(sdp)
        });
    }
    /**
    * Adds {@link JitsiLocalTrack} to the WebRTC peerconnection for the first time.
    * @param {JitsiLocalTrack} track - track to be added to the peerconnection.
    * @param {boolean} isInitiator - boolean that indicates if the endpoint is offerer in a p2p connection.
    * @returns {void}
    */
    addTrack(localTrack, isInitiator) {
        const track = localTrack.getTrack();
        if (isInitiator) {
            const streams = [];
            if (localTrack.getOriginalStream()) {
                streams.push(localTrack.getOriginalStream());
            }
            // Use pc.addTransceiver() for the initiator case when local tracks are getting added
            // to the peerconnection before a session-initiate is sent over to the peer.
            const transceiverInit = {
                direction: _service_RTC_MediaDirection__WEBPACK_IMPORTED_MODULE_2__.MediaDirection.SENDRECV,
                streams,
                sendEncodings: []
            };
            if (!_browser__WEBPACK_IMPORTED_MODULE_6__["default"].isFirefox()) {
                transceiverInit.sendEncodings = this._getStreamEncodings(localTrack);
            }
            this.pc.peerconnection.addTransceiver(track, transceiverInit);
        }
        else {
            // Use pc.addTrack() for responder case so that we can re-use the m-lines that were created
            // when setRemoteDescription was called. pc.addTrack() automatically  attaches to any existing
            // unused "recv-only" transceiver.
            this.pc.peerconnection.addTrack(track);
        }
    }
    /**
     * Returns the calculated active state of the simulcast encodings based on the frame height requested for the send
     * stream. All the encodings that have a resolution lower than the frame height requested will be enabled.
     *
     * @param {JitsiLocalTrack} localVideoTrack The local video track.
     * @param {number} newHeight The resolution requested for the video track.
     * @returns {Array<boolean>}
     */
    calculateEncodingsActiveState(localVideoTrack, newHeight) {
        const localTrack = localVideoTrack.getTrack();
        const { height } = localTrack.getSettings();
        const videoStreamEncodings = this._getVideoStreamEncodings(localVideoTrack.getVideoType());
        const encodingsState = videoStreamEncodings
            .map(encoding => height / encoding.scaleResolutionDownBy)
            .map((frameHeight, idx) => {
            var _a;
            let active = localVideoTrack.getVideoType() === _service_RTC_VideoType__WEBPACK_IMPORTED_MODULE_5__.VideoType.CAMERA
                // Keep the LD stream enabled even when the LD stream's resolution is higher than of the requested
                // resolution. This can happen when camera is captured at resolutions higher than 720p but the
                // requested resolution is 180. Since getParameters doesn't give us information about the resolutions
                // of the simulcast encodings, we have to rely on our initial config for the simulcast streams.
                ? newHeight > 0 && ((_a = videoStreamEncodings[idx]) === null || _a === void 0 ? void 0 : _a.scaleResolutionDownBy) === LD_SCALE_FACTOR
                    ? true
                    : frameHeight <= newHeight
                // Keep all the encodings for desktop track active.
                : true;
            // Disable the lower spatial layers for screensharing in Unified plan when low fps screensharing is in
            // progress. Sending all three streams often results in the browser suspending the high resolution in low
            // b/w and cpu cases, especially on the low end machines. Suspending the low resolution streams ensures
            // that the highest resolution stream is available always. Safari is an exception here since it does not
            // send the desktop stream at all if only the high resolution stream is enabled.
            if (localVideoTrack.getVideoType() === _service_RTC_VideoType__WEBPACK_IMPORTED_MODULE_5__.VideoType.DESKTOP
                && this.pc._capScreenshareBitrate
                && this.pc.usesUnifiedPlan()
                && !_browser__WEBPACK_IMPORTED_MODULE_6__["default"].isWebKitBased()
                && videoStreamEncodings[idx].scaleResolutionDownBy !== HD_SCALE_FACTOR) {
                active = false;
            }
            return active;
        });
        return encodingsState;
    }
    /**
     * Returns the calculates max bitrates that need to be configured on the simulcast encodings based on the video
     * type and other considerations associated with screenshare.
     *
     * @param {JitsiLocalTrack} localVideoTrack The local video track.
     * @returns {Array<number>}
     */
    calculateEncodingsBitrates(localVideoTrack) {
        var _a, _b;
        const videoType = localVideoTrack.getVideoType();
        const desktopShareBitrate = ((_b = (_a = this.pc.options) === null || _a === void 0 ? void 0 : _a.videoQuality) === null || _b === void 0 ? void 0 : _b.desktopBitrate) || DESKTOP_SHARE_RATE;
        const lowFpsScreenshare = localVideoTrack.getVideoType() === _service_RTC_VideoType__WEBPACK_IMPORTED_MODULE_5__.VideoType.DESKTOP
            && this.pc._capScreenshareBitrate
            && !_browser__WEBPACK_IMPORTED_MODULE_6__["default"].isWebKitBased();
        const encodingsBitrates = this._getVideoStreamEncodings(localVideoTrack.getVideoType())
            .map(encoding => {
            const bitrate = lowFpsScreenshare
                ? desktopShareBitrate
                // For high fps screenshare, 'maxBitrate' setting must be cleared on Chrome in plan-b, because
                // if simulcast is enabled for screen and maxBitrates are set then Chrome will not send the
                // desktop stream.
                : videoType === _service_RTC_VideoType__WEBPACK_IMPORTED_MODULE_5__.VideoType.DESKTOP && _browser__WEBPACK_IMPORTED_MODULE_6__["default"].isChromiumBased() && !this.pc.usesUnifiedPlan()
                    ? undefined
                    : encoding.maxBitrate;
            return bitrate;
        });
        return encodingsBitrates;
    }
    /**
     * Returns the max resolution that the client is configured to encode for a given local video track. The actual
     * send resolution might be downscaled based on cpu and bandwidth constraints.
     *
     * @param {JitsiLocalTrack} localVideoTrack - The local video track.
     * @returns {number|null} The max encoded resolution for the given video track.
     */
    getConfiguredEncodeResolution(localVideoTrack) {
        var _a;
        const localTrack = localVideoTrack.getTrack();
        const { height } = localTrack.getSettings();
        const videoSender = this.pc.findSenderForTrack(localVideoTrack.getTrack());
        let maxHeight = 0;
        if (!videoSender) {
            return null;
        }
        const parameters = videoSender.getParameters();
        if (!((_a = parameters === null || parameters === void 0 ? void 0 : parameters.encodings) === null || _a === void 0 ? void 0 : _a.length)) {
            return null;
        }
        const hasIncorrectConfig = this.pc._capScreenshareBitrate
            ? parameters.encodings.every(encoding => encoding.active)
            : parameters.encodings.some(encoding => !encoding.active);
        // Check if every encoding is active for screenshare track when low fps screenshare is configured or some
        // of the encodings are disabled when high fps screenshare is configured. In both these cases, the track
        // encodings need to be reconfigured. This is needed when p2p->jvb switch happens and new sender constraints
        // are not received by the client.
        if (localVideoTrack.getVideoType() === _service_RTC_VideoType__WEBPACK_IMPORTED_MODULE_5__.VideoType.DESKTOP && hasIncorrectConfig) {
            return null;
        }
        for (const encoding in parameters.encodings) {
            if (parameters.encodings[encoding].active) {
                const scaleResolutionDownBy = this.pc.isSimulcastOn()
                    ? this._getVideoStreamEncodings(localVideoTrack.getVideoType())[encoding].scaleResolutionDownBy
                    : parameters.encodings[encoding].scaleResolutionDownBy;
                maxHeight = Math.max(maxHeight, height / scaleResolutionDownBy);
            }
        }
        return maxHeight;
    }
    /**
     * Replaces the existing track on a RTCRtpSender with the given track.
     *
     * @param {JitsiLocalTrack} oldTrack - existing track on the sender that needs to be removed.
     * @param {JitsiLocalTrack} newTrack - new track that needs to be added to the sender.
     * @returns {Promise<RTCRtpTransceiver>} - resolved with the associated transceiver when done, rejected otherwise.
     */
    replaceTrack(oldTrack, newTrack) {
        var _a, _b, _c;
        const mediaType = (_a = newTrack === null || newTrack === void 0 ? void 0 : newTrack.getType()) !== null && _a !== void 0 ? _a : oldTrack === null || oldTrack === void 0 ? void 0 : oldTrack.getType();
        const localTracks = this.pc.getLocalTracks(mediaType);
        const track = (_b = newTrack === null || newTrack === void 0 ? void 0 : newTrack.getTrack()) !== null && _b !== void 0 ? _b : null;
        const isNewLocalSource = _flags_FeatureFlags__WEBPACK_IMPORTED_MODULE_7__["default"].isMultiStreamSendSupportEnabled()
            && (localTracks === null || localTracks === void 0 ? void 0 : localTracks.length)
            && !oldTrack
            && newTrack
            && !localTracks.find(t => t === newTrack);
        let transceiver;
        // If old track exists, replace the track on the corresponding sender.
        if (oldTrack && !oldTrack.isMuted()) {
            transceiver = this.pc.peerconnection.getTransceivers().find(t => t.sender.track === oldTrack.getTrack());
            // Find the first recvonly transceiver when more than one track of the same media type is being added to the pc.
            // As part of the track addition, a new m-line was added to the remote description with direction set to
            // recvonly.
        }
        else if (isNewLocalSource) {
            transceiver = this.pc.peerconnection.getTransceivers().find(t => t.receiver.track.kind === mediaType
                && t.direction === _service_RTC_MediaDirection__WEBPACK_IMPORTED_MODULE_2__.MediaDirection.RECVONLY
                // Re-use any existing recvonly transceiver (if available) for p2p case.
                && ((this.pc.isP2P && t.currentDirection === _service_RTC_MediaDirection__WEBPACK_IMPORTED_MODULE_2__.MediaDirection.RECVONLY)
                    || (t.currentDirection === _service_RTC_MediaDirection__WEBPACK_IMPORTED_MODULE_2__.MediaDirection.INACTIVE && !t.stopped)));
            // For mute/unmute operations, find the transceiver based on the track index in the source name if present,
            // otherwise it is assumed to be the first local track that was added to the peerconnection.
        }
        else {
            transceiver = this.pc.peerconnection.getTransceivers().find(t => t.receiver.track.kind === mediaType);
            const sourceName = (_c = newTrack === null || newTrack === void 0 ? void 0 : newTrack.getSourceName()) !== null && _c !== void 0 ? _c : oldTrack === null || oldTrack === void 0 ? void 0 : oldTrack.getSourceName();
            if (sourceName) {
                const trackIndex = (0,_service_RTC_SignalingLayer__WEBPACK_IMPORTED_MODULE_4__.getSourceIndexFromSourceName)(sourceName);
                if (this.pc.isP2P) {
                    transceiver = this.pc.peerconnection.getTransceivers()
                        .filter(t => t.receiver.track.kind === mediaType)[trackIndex];
                }
                else if (oldTrack) {
                    const transceiverMid = this.pc._localTrackTransceiverMids.get(oldTrack.rtcId);
                    transceiver = this.pc.peerconnection.getTransceivers().find(t => t.mid === transceiverMid);
                }
                else if (trackIndex) {
                    transceiver = this.pc.peerconnection.getTransceivers()
                        .filter(t => t.receiver.track.kind === mediaType
                        && t.direction !== _service_RTC_MediaDirection__WEBPACK_IMPORTED_MODULE_2__.MediaDirection.RECVONLY)[trackIndex];
                }
            }
        }
        if (!transceiver) {
            return Promise.reject(new Error(`Replace track failed - no transceiver for old: ${oldTrack}, new: ${newTrack}`));
        }
        logger.debug(`${this.pc} Replacing ${oldTrack} with ${newTrack}`);
        return transceiver.sender.replaceTrack(track)
            .then(() => Promise.resolve(transceiver));
    }
    /**
     * Set the simulcast stream encoding properties on the RTCRtpSender.
     * @param {JitsiLocalTrack} track - the current track in use for which
     * the encodings are to be set.
     * @returns {Promise<void>} - resolved when done.
     */
    setEncodings(track) {
        var _a, _b;
        const mediaType = track.getType();
        const transceiver = this.findTransceiver(mediaType, track);
        const parameters = (_a = transceiver === null || transceiver === void 0 ? void 0 : transceiver.sender) === null || _a === void 0 ? void 0 : _a.getParameters();
        // Resolve if the encodings are not available yet. This happens immediately after the track is added to the
        // peerconnection on chrome in unified-plan. It is ok to ignore and not report the error here since the
        // action that triggers 'addTrack' (like unmute) will also configure the encodings and set bitrates after that.
        if (!((_b = parameters === null || parameters === void 0 ? void 0 : parameters.encodings) === null || _b === void 0 ? void 0 : _b.length)) {
            return Promise.resolve();
        }
        parameters.encodings = this._getStreamEncodings(track);
        const promise = transceiver.sender.setParameters(parameters);
        if (mediaType === _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_3__.MediaType.VIDEO) {
            return this.pc._updateVideoSenderParameters(promise);
        }
        return promise;
    }
    /**
     * Resumes or suspends media on the peerconnection by setting the active state on RTCRtpEncodingParameters
     * associated with all the senders that have a track attached to it.
     *
     * @param {boolean} enable - whether media needs to be enabled or suspended.
     * @returns {Promise} - A promise that is resolved when the change is succesful on all the senders, rejected
     * otherwise.
     */
    setMediaTransferActive(enable) {
        var _a;
        logger.info(`${this.pc} ${enable ? 'Resuming' : 'Suspending'} media transfer.`);
        const senders = this.pc.peerconnection.getSenders().filter(s => Boolean(s.track));
        const promises = [];
        for (const sender of senders) {
            const parameters = sender.getParameters();
            if ((_a = parameters === null || parameters === void 0 ? void 0 : parameters.encodings) === null || _a === void 0 ? void 0 : _a.length) {
                for (const encoding of parameters.encodings) {
                    encoding.active = enable;
                }
            }
            const setActivePromise = sender.setParameters(parameters);
            if (sender.track.kind === _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_3__.MediaType.VIDEO) {
                promises.push(this.pc._updateVideoSenderParameters(setActivePromise));
            }
            else {
                promises.push(setActivePromise);
            }
        }
        return Promise.allSettled(promises)
            .then(settledResult => {
            const errors = settledResult
                .filter(result => result.status === 'rejected')
                .map(result => result.reason);
            if (errors.length) {
                return Promise.reject(new Error('Failed to change encodings on the RTCRtpSenders'
                    + `${errors.join(' ')}`));
            }
            return Promise.resolve();
        });
    }
    /**
     * Enables/disables video media transmission on the peer connection. When disabled the SDP video media direction in
     * the local SDP will be adjusted to 'inactive' which means that no data will be sent nor accepted, but the
     * connection should be kept alive. This is used for setting lastn=0 on p2p connection.
     *
     * @param {boolean} active - true to enable media transmission or false to disable.
     * @returns {void}
     */
    setVideoTransferActive(active) {
        const transceivers = this.pc.peerconnection.getTransceivers()
            .filter(t => t.receiver && t.receiver.track && t.receiver.track.kind === _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_3__.MediaType.VIDEO);
        logger.info(`${this.pc} ${active ? 'Enabling' : 'Suspending'} video media transfer.`);
        transceivers.forEach(transceiver => {
            const localTrackMids = Array.from(this.pc._localTrackTransceiverMids);
            const direction = active
                ? localTrackMids.find(mids => mids[1] === transceiver.mid)
                    ? _service_RTC_MediaDirection__WEBPACK_IMPORTED_MODULE_2__.MediaDirection.SENDRECV : _service_RTC_MediaDirection__WEBPACK_IMPORTED_MODULE_2__.MediaDirection.RECVONLY
                : _service_RTC_MediaDirection__WEBPACK_IMPORTED_MODULE_2__.MediaDirection.INACTIVE;
            logger.debug(`Setting direction to ${direction} on mid=${transceiver.mid}`);
            transceiver.direction = direction;
        });
    }
    /**
     * Ensures that the resolution of the stream encodings are consistent with the values
     * that were configured on the RTCRtpSender when the source was added to the peerconnection.
     * This should prevent us from overriding the default values if the browser returns
     * erroneous values when RTCRtpSender.getParameters is used for getting the encodings info.
     * @param {JitsiLocalTrack} localVideoTrack The local video track.
     * @param {Object} parameters - the RTCRtpEncodingParameters obtained from the browser.
     * @returns {void}
     */
    updateEncodingsResolution(localVideoTrack, parameters) {
        if (!(_browser__WEBPACK_IMPORTED_MODULE_6__["default"].isWebKitBased() && parameters.encodings && Array.isArray(parameters.encodings))) {
            return;
        }
        const allEqualEncodings = encodings => encodings.every(encoding => typeof encoding.scaleResolutionDownBy !== 'undefined'
            && encoding.scaleResolutionDownBy === encodings[0].scaleResolutionDownBy);
        // Implement the workaround only when all the encodings report the same resolution.
        if (allEqualEncodings(parameters.encodings)) {
            const videoStreamEncodings = this._getVideoStreamEncodings(localVideoTrack.getVideoType());
            parameters.encodings.forEach((encoding, idx) => {
                encoding.scaleResolutionDownBy = videoStreamEncodings[idx].scaleResolutionDownBy;
            });
        }
    }
}
//# sourceMappingURL=TPCUtils.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/RTC/TraceablePeerConnection.js":
/*!********************************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/RTC/TraceablePeerConnection.js ***!
  \********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
var __filename = "/index.js";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (/* binding */ TraceablePeerConnection)
/* harmony export */ });
/* harmony import */ var _jitsi_logger__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @jitsi/logger */ "./node_modules/@jitsi/logger/lib/index.js");
/* harmony import */ var _jitsi_logger__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(_jitsi_logger__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var _jitsi_sdp_interop__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! @jitsi/sdp-interop */ "./node_modules/@jitsi/sdp-interop/lib/index.js");
/* harmony import */ var sdp_transform__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! sdp-transform */ "./node_modules/sdp-transform/lib/index.js");
/* harmony import */ var _service_RTC_CodecMimeType__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../service/RTC/CodecMimeType */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/RTC/CodecMimeType.js");
/* harmony import */ var _service_RTC_MediaDirection__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../../service/RTC/MediaDirection */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/RTC/MediaDirection.js");
/* harmony import */ var _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../../service/RTC/MediaType */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/RTC/MediaType.js");
/* harmony import */ var _service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../../service/RTC/RTCEvents */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/RTC/RTCEvents.js");
/* harmony import */ var _service_RTC_SignalingEvents__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../../service/RTC/SignalingEvents */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/RTC/SignalingEvents.js");
/* harmony import */ var _service_RTC_SignalingLayer__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ../../service/RTC/SignalingLayer */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/RTC/SignalingLayer.js");
/* harmony import */ var _service_RTC_VideoType__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ../../service/RTC/VideoType */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/RTC/VideoType.js");
/* harmony import */ var _RTC_ScreenObtainer__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ../RTC/ScreenObtainer */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/RTC/ScreenObtainer.js");
/* harmony import */ var _browser__WEBPACK_IMPORTED_MODULE_11__ = __webpack_require__(/*! ../browser */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/browser/index.js");
/* harmony import */ var _flags_FeatureFlags__WEBPACK_IMPORTED_MODULE_12__ = __webpack_require__(/*! ../flags/FeatureFlags */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/flags/FeatureFlags.js");
/* harmony import */ var _sdp_LocalSdpMunger__WEBPACK_IMPORTED_MODULE_13__ = __webpack_require__(/*! ../sdp/LocalSdpMunger */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/sdp/LocalSdpMunger.js");
/* harmony import */ var _sdp_RtxModifier__WEBPACK_IMPORTED_MODULE_14__ = __webpack_require__(/*! ../sdp/RtxModifier */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/sdp/RtxModifier.js");
/* harmony import */ var _sdp_SDP__WEBPACK_IMPORTED_MODULE_15__ = __webpack_require__(/*! ../sdp/SDP */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/sdp/SDP.js");
/* harmony import */ var _sdp_SDPUtil__WEBPACK_IMPORTED_MODULE_16__ = __webpack_require__(/*! ../sdp/SDPUtil */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/sdp/SDPUtil.js");
/* harmony import */ var _sdp_SdpConsistency__WEBPACK_IMPORTED_MODULE_17__ = __webpack_require__(/*! ../sdp/SdpConsistency */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/sdp/SdpConsistency.js");
/* harmony import */ var _sdp_SdpSimulcast__WEBPACK_IMPORTED_MODULE_18__ = __webpack_require__(/*! ../sdp/SdpSimulcast */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/sdp/SdpSimulcast.js");
/* harmony import */ var _sdp_SdpTransformUtil__WEBPACK_IMPORTED_MODULE_19__ = __webpack_require__(/*! ../sdp/SdpTransformUtil */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/sdp/SdpTransformUtil.js");
/* harmony import */ var _util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_20__ = __webpack_require__(/*! ../util/GlobalOnErrorHandler */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/util/GlobalOnErrorHandler.js");
/* harmony import */ var _util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_20___default = /*#__PURE__*/__webpack_require__.n(_util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_20__);
/* harmony import */ var _JitsiRemoteTrack__WEBPACK_IMPORTED_MODULE_21__ = __webpack_require__(/*! ./JitsiRemoteTrack */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/RTC/JitsiRemoteTrack.js");
/* harmony import */ var _RTC__WEBPACK_IMPORTED_MODULE_22__ = __webpack_require__(/*! ./RTC */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/RTC/RTC.js");
/* harmony import */ var _TPCUtils__WEBPACK_IMPORTED_MODULE_23__ = __webpack_require__(/*! ./TPCUtils */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/RTC/TPCUtils.js");
























// FIXME SDP tools should end up in some kind of util module
const logger = (0,_jitsi_logger__WEBPACK_IMPORTED_MODULE_0__.getLogger)(__filename);
const DEGRADATION_PREFERENCE_CAMERA = 'maintain-framerate';
const DEGRADATION_PREFERENCE_DESKTOP = 'maintain-resolution';
/* eslint-disable max-params */
/**
 * Creates new instance of 'TraceablePeerConnection'.
 *
 * @param {RTC} rtc the instance of <tt>RTC</tt> service
 * @param {number} id the peer connection id assigned by the parent RTC module.
 * @param {SignalingLayer} signalingLayer the signaling layer instance
 * @param {object} pcConfig The {@code RTCConfiguration} to use for the WebRTC peer connection.
 * @param {object} constraints WebRTC 'PeerConnection' constraints
 * @param {boolean} isP2P indicates whether or not the new instance will be used in a peer to peer connection.
 * @param {object} options <tt>TracablePeerConnection</tt> config options.
 * @param {boolean} options.disableSimulcast if set to 'true' will disable the simulcast.
 * @param {boolean} options.disableRtx if set to 'true' will disable the RTX.
 * @param {string} options.disabledCodec the mime type of the code that should not be negotiated on the peerconnection.
 * @param {string} options.preferredCodec the mime type of the codec that needs to be made the preferred codec for the
 * peerconnection.
 * @param {boolean} options.startSilent If set to 'true' no audio will be sent or received.
 * @param {boolean} options.usesUnifiedPlan Indicates if the  browser is running in unified plan mode.
 *
 * FIXME: initially the purpose of TraceablePeerConnection was to be able to
 * debug the peer connection. Since many other responsibilities have been added
 * it would make sense to extract a separate class from it and come up with
 * a more suitable name.
 *
 * @constructor
 */
function TraceablePeerConnection(rtc, id, signalingLayer, pcConfig, constraints, isP2P, options) {
    /**
     * Indicates whether or not this peer connection instance is actively
     * sending/receiving audio media. When set to <tt>false</tt> the SDP audio
     * media direction will be adjusted to 'inactive' in order to suspend
     * the transmission.
     * @type {boolean}
     * @private
     */
    this.audioTransferActive = !(options.startSilent === true);
    /**
     * The DTMF sender instance used to send DTMF tones.
     *
     * @type {RTCDTMFSender|undefined}
     * @private
     */
    this._dtmfSender = undefined;
    /**
     * @typedef {Object} TouchToneRequest
     * @property {string} tones - The DTMF tones string as defined by
     * {@code RTCDTMFSender.insertDTMF}, 'tones' argument.
     * @property {number} duration - The amount of time in milliseconds that
     * each DTMF should last.
     * @property {string} interToneGap - The length of time in miliseconds to
     * wait between tones.
     */
    /**
     * TouchToneRequests which are waiting to be played. This queue is filled
     * if there are touch tones currently being played.
     *
     * @type {Array<TouchToneRequest>}
     * @private
     */
    this._dtmfTonesQueue = [];
    /**
     * Indicates whether or not this peer connection instance is actively
     * sending/receiving video media. When set to <tt>false</tt> the SDP video
     * media direction will be adjusted to 'inactive' in order to suspend
     * the transmission.
     * @type {boolean}
     * @private
     */
    this.videoTransferActive = true;
    /**
     * The parent instance of RTC service which created this
     * <tt>TracablePeerConnection</tt>.
     * @type {RTC}
     */
    this.rtc = rtc;
    /**
     * The peer connection identifier assigned by the RTC module.
     * @type {number}
     */
    this.id = id;
    /**
     * Indicates whether or not this instance is used in a peer to peer
     * connection.
     * @type {boolean}
     */
    this.isP2P = isP2P;
    /**
     * The map holds remote tracks associated with this peer connection. It maps user's JID to media type and a set of
     * remote tracks.
     * @type {Map<string, Map<MediaType, Set<JitsiRemoteTrack>>>}
     */
    this.remoteTracks = new Map();
    /**
     * A map which stores local tracks mapped by {@link JitsiLocalTrack.rtcId}
     * @type {Map<number, JitsiLocalTrack>}
     */
    this.localTracks = new Map();
    /**
     * Keeps tracks of the WebRTC <tt>MediaStream</tt>s that have been added to
     * the underlying WebRTC PeerConnection.
     * @type {Array}
     * @private
     */
    this._addedStreams = [];
    /**
     * @typedef {Object} TPCGroupInfo
     * @property {string} semantics the SSRC groups semantics
     * @property {Array<number>} ssrcs group's SSRCs in order where the first
     * one is group's primary SSRC, the second one is secondary (RTX) and so
     * on...
     */
    /**
     * @typedef {Object} TPCSSRCInfo
     * @property {Array<number>} ssrcs an array which holds all track's SSRCs
     * @property {Array<TPCGroupInfo>} groups an array stores all track's SSRC
     * groups
     */
    /**
     * Holds the info about local track's SSRCs mapped per their
     * {@link JitsiLocalTrack.rtcId}
     * @type {Map<number, TPCSSRCInfo>}
     */
    this.localSSRCs = new Map();
    /**
     * The set of remote SSRCs seen so far.
     * Distinguishes new SSRCs from those that have been remapped.
     * @type {Set<number>}
     */
    this.remoteSSRCs = new Set();
    /**
     * Mapping of source-names and their associated SSRCs that have been signaled by the JVB.
     * @type {Map<string, number>}
     */
    this.remoteSources = new Map();
    /**
     * The local ICE username fragment for this session.
     */
    this.localUfrag = null;
    /**
     * The remote ICE username fragment for this session.
     */
    this.remoteUfrag = null;
    /**
     * The DTLS transport object for the PeerConnection.
     * Note: this assume only one shared transport exists because we bundled
     *       all streams on the same underlying transport.
     */
    this._dtlsTransport = null;
    /**
     * The signaling layer which operates this peer connection.
     * @type {SignalingLayer}
     */
    this.signalingLayer = signalingLayer;
    // SignalingLayer listeners
    this._peerVideoTypeChanged = this._peerVideoTypeChanged.bind(this);
    this.signalingLayer.on(_service_RTC_SignalingEvents__WEBPACK_IMPORTED_MODULE_7__.PEER_VIDEO_TYPE_CHANGED, this._peerVideoTypeChanged);
    this._peerMutedChanged = this._peerMutedChanged.bind(this);
    this.signalingLayer.on(_service_RTC_SignalingEvents__WEBPACK_IMPORTED_MODULE_7__.PEER_MUTED_CHANGED, this._peerMutedChanged);
    this.options = options;
    // Setup SignalingLayer listeners for source-name based events.
    this.signalingLayer.on(_service_RTC_SignalingEvents__WEBPACK_IMPORTED_MODULE_7__.SOURCE_MUTED_CHANGED, (sourceName, isMuted) => this._sourceMutedChanged(sourceName, isMuted));
    this.signalingLayer.on(_service_RTC_SignalingEvents__WEBPACK_IMPORTED_MODULE_7__.SOURCE_VIDEO_TYPE_CHANGED, (sourceName, videoType) => this._sourceVideoTypeChanged(sourceName, videoType));
    // Make sure constraints is properly formatted in order to provide information about whether or not this
    // connection is P2P to rtcstats.
    const safeConstraints = constraints || {};
    safeConstraints.optional = safeConstraints.optional || [];
    // The `optional` parameter needs to be of type array, otherwise chrome will throw an error.
    // Firefox and Safari just ignore it.
    if (Array.isArray(safeConstraints.optional)) {
        safeConstraints.optional.push({ rtcStatsSFUP2P: this.isP2P });
    }
    else {
        logger.warn('Optional param is not an array, rtcstats p2p data is omitted.');
    }
    this.peerconnection = new RTCPeerConnection(pcConfig, safeConstraints);
    this.tpcUtils = new _TPCUtils__WEBPACK_IMPORTED_MODULE_23__.TPCUtils(this);
    this.updateLog = [];
    this.stats = {};
    this.statsinterval = null;
    /**
     * Flag used to indicate if low fps screenshare is desired.
     */
    this._capScreenshareBitrate = this.options.capScreenshareBitrate;
    /**
    * Flag used to indicate if the browser is running in unified  plan mode.
    */
    this._usesUnifiedPlan = options.usesUnifiedPlan;
    /**
     * Codec preferences set for the peerconnection through config.js.
     */
    this.codecSettings = this.options.codecSettings;
    /**
     * Flag used to indicate if RTCRtpTransceiver#setCodecPreferences is to be used instead of SDP
     * munging for codec selection.
     */
    this._usesTransceiverCodecPreferences = _browser__WEBPACK_IMPORTED_MODULE_11__["default"].supportsCodecPreferences() && this._usesUnifiedPlan;
    this._usesTransceiverCodecPreferences
        && logger.info('Using RTCRtpTransceiver#setCodecPreferences for codec selection');
    // We currently need these flags only for FF and that's why we are updating them only for unified plan.
    if (this._usesUnifiedPlan) {
        /**
         * Indicates whether an audio track has ever been added to the peer connection.
         */
        this._hasHadAudioTrack = false;
        /**
         * Indicates whether a video track has ever been added to the peer connection.
         */
        this._hasHadVideoTrack = false;
    }
    /**
     * @type {number} The max number of stats to keep in this.stats. Limit to
     * 300 values, i.e. 5 minutes; set to 0 to disable
     */
    this.maxstats = options.maxstats;
    this.interop = new _jitsi_sdp_interop__WEBPACK_IMPORTED_MODULE_1__.Interop();
    if (this._usesUnifiedPlan) {
        this.simulcast = new _sdp_SdpSimulcast__WEBPACK_IMPORTED_MODULE_18__["default"]({ numOfLayers: _TPCUtils__WEBPACK_IMPORTED_MODULE_23__.SIM_LAYER_RIDS.length });
    }
    else {
        const Simulcast = __webpack_require__(/*! @jitsi/sdp-simulcast */ "./node_modules/@jitsi/sdp-simulcast/lib/index.js");
        this.simulcast = new Simulcast({
            numOfLayers: _TPCUtils__WEBPACK_IMPORTED_MODULE_23__.SIM_LAYER_RIDS.length,
            explodeRemoteSimulcast: false,
            usesUnifiedPlan: false
        });
    }
    this.sdpConsistency = new _sdp_SdpConsistency__WEBPACK_IMPORTED_MODULE_17__["default"](this.toString());
    /**
     * Munges local SDP provided to the Jingle Session in order to prevent from
     * sending SSRC updates on attach/detach and mute/unmute (for video).
     * @type {LocalSdpMunger}
     */
    this.localSdpMunger = new _sdp_LocalSdpMunger__WEBPACK_IMPORTED_MODULE_13__["default"](this, this.rtc.getLocalEndpointId());
    /**
     * TracablePeerConnection uses RTC's eventEmitter
     * @type {EventEmitter}
     */
    this.eventEmitter = rtc.eventEmitter;
    this.rtxModifier = new _sdp_RtxModifier__WEBPACK_IMPORTED_MODULE_14__["default"]();
    /**
     * The height constraint applied on the video sender. The default value is 2160 (4K) when layer suspension is
     * explicitly disabled.
     */
    this._senderVideoMaxHeight = 2160;
    /**
     * The height constraints to be applied on the sender per local video source (source name as the key).
     * @type {Map<string, number>}
     */
    this._senderMaxHeights = new Map();
    /**
     * Holds the RTCRtpTransceiver mids that the local tracks are attached to, mapped per their
     * {@link JitsiLocalTrack.rtcId}.
     * @type {Map<string, string>}
     */
    this._localTrackTransceiverMids = new Map();
    // override as desired
    this.trace = (what, info) => {
        logger.debug(what, info);
        this.updateLog.push({
            time: new Date(),
            type: what,
            value: info || ''
        });
    };
    this.onicecandidate = null;
    this.peerconnection.onicecandidate = event => {
        this.trace('onicecandidate', JSON.stringify(event.candidate, null, ' '));
        if (this.onicecandidate !== null) {
            this.onicecandidate(event);
        }
    };
    // Use track events when browser is running in unified plan mode and stream events in plan-b mode.
    if (this._usesUnifiedPlan) {
        this.onTrack = evt => {
            const stream = evt.streams[0];
            this._remoteTrackAdded(stream, evt.track, evt.transceiver);
            stream.addEventListener('removetrack', e => {
                this._remoteTrackRemoved(stream, e.track);
            });
        };
        this.peerconnection.addEventListener('track', this.onTrack);
    }
    else {
        this.peerconnection.onaddstream = event => this._remoteStreamAdded(event.stream);
        this.peerconnection.onremovestream = event => this._remoteStreamRemoved(event.stream);
    }
    this.onsignalingstatechange = null;
    this.peerconnection.onsignalingstatechange = event => {
        this.trace('onsignalingstatechange', this.signalingState);
        if (this.onsignalingstatechange !== null) {
            this.onsignalingstatechange(event);
        }
    };
    this.oniceconnectionstatechange = null;
    this.peerconnection.oniceconnectionstatechange = event => {
        this.trace('oniceconnectionstatechange', this.iceConnectionState);
        if (this.oniceconnectionstatechange !== null) {
            this.oniceconnectionstatechange(event);
        }
    };
    this.onnegotiationneeded = null;
    this.peerconnection.onnegotiationneeded = event => {
        this.trace('onnegotiationneeded');
        if (this.onnegotiationneeded !== null) {
            this.onnegotiationneeded(event);
        }
    };
    this.onconnectionstatechange = null;
    this.peerconnection.onconnectionstatechange = event => {
        this.trace('onconnectionstatechange', this.connectionState);
        if (this.onconnectionstatechange !== null) {
            this.onconnectionstatechange(event);
        }
    };
    this.ondatachannel = null;
    this.peerconnection.ondatachannel = event => {
        this.trace('ondatachannel');
        if (this.ondatachannel !== null) {
            this.ondatachannel(event);
        }
    };
    if (this.maxstats) {
        this.statsinterval = window.setInterval(() => {
            this.getStats().then(stats => {
                if (typeof (stats === null || stats === void 0 ? void 0 : stats.result) === 'function') {
                    const results = stats.result();
                    for (let i = 0; i < results.length; ++i) {
                        const res = results[i];
                        res.names().forEach(name => {
                            this._processStat(res, name, res.stat(name));
                        });
                    }
                }
                else {
                    stats.forEach(r => this._processStat(r, '', r));
                }
            });
        }, 1000);
    }
    this._lastVideoSenderUpdatePromise = Promise.resolve();
    logger.info(`Create new ${this}`);
}
/* eslint-enable max-params */
/**
 * Process stat and adds it to the array of stats we store.
 * @param report the current stats report.
 * @param name the name of the report, if available
 * @param statValue the value to add.
 * @private
 */
TraceablePeerConnection.prototype._processStat
    = function (report, name, statValue) {
        const id = `${report.id}-${name}`;
        let s = this.stats[id];
        const now = new Date();
        if (!s) {
            this.stats[id] = s = {
                startTime: now,
                endTime: now,
                values: [],
                times: []
            };
        }
        s.values.push(statValue);
        s.times.push(now.getTime());
        if (s.values.length > this.maxstats) {
            s.values.shift();
            s.times.shift();
        }
        s.endTime = now;
    };
/**
 * Returns a string representation of a SessionDescription object.
 */
const dumpSDP = function (description) {
    if (typeof description === 'undefined' || description === null) {
        return '';
    }
    return `type: ${description.type}\r\n${description.sdp}`;
};
/**
 * Forwards the {@link peerconnection.iceConnectionState} state except that it
 * will convert "completed" into "connected" where both mean that the ICE has
 * succeeded and is up and running. We never see "completed" state for
 * the JVB connection, but it started appearing for the P2P one. This method
 * allows to adapt old logic to this new situation.
 * @return {string}
 */
TraceablePeerConnection.prototype.getConnectionState = function () {
    const state = this.peerconnection.iceConnectionState;
    if (state === 'completed') {
        return 'connected';
    }
    return state;
};
/**
 * Obtains the media direction for given {@link MediaType}. The method takes
 * into account whether or not there are any local tracks for media and
 * the {@link audioTransferActive} and {@link videoTransferActive} flags.
 * @param {MediaType} mediaType
 * @param {boolean} isAddOperation whether the direction is to be calculated after a source-add action.
 * @return {string} one of the SDP direction constants ('sendrecv, 'recvonly'
 * etc.) which should be used when setting local description on the peer
 * connection.
 * @private
 */
TraceablePeerConnection.prototype.getDesiredMediaDirection = function (mediaType, isAddOperation = false) {
    const hasLocalSource = this.hasAnyTracksOfType(mediaType);
    if (this._usesUnifiedPlan) {
        return isAddOperation
            ? hasLocalSource ? _service_RTC_MediaDirection__WEBPACK_IMPORTED_MODULE_4__.MediaDirection.SENDRECV : _service_RTC_MediaDirection__WEBPACK_IMPORTED_MODULE_4__.MediaDirection.SENDONLY
            : hasLocalSource ? _service_RTC_MediaDirection__WEBPACK_IMPORTED_MODULE_4__.MediaDirection.RECVONLY : _service_RTC_MediaDirection__WEBPACK_IMPORTED_MODULE_4__.MediaDirection.INACTIVE;
    }
    const mediaTransferActive = mediaType === _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_5__.MediaType.AUDIO ? this.audioTransferActive : this.videoTransferActive;
    if (mediaTransferActive) {
        return hasLocalSource ? _service_RTC_MediaDirection__WEBPACK_IMPORTED_MODULE_4__.MediaDirection.SENDRECV : _service_RTC_MediaDirection__WEBPACK_IMPORTED_MODULE_4__.MediaDirection.RECVONLY;
    }
    return _service_RTC_MediaDirection__WEBPACK_IMPORTED_MODULE_4__.MediaDirection.INACTIVE;
};
/**
 * Returns the MID of the m-line associated with the local desktop track (if it exists).
 *
 * @returns {Number|null}
 */
TraceablePeerConnection.prototype._getDesktopTrackMid = function () {
    const desktopTrack = this.getLocalVideoTracks().find(track => track.getVideoType() === _service_RTC_VideoType__WEBPACK_IMPORTED_MODULE_9__.VideoType.DESKTOP);
    if (desktopTrack) {
        return Number(this._localTrackTransceiverMids.get(desktopTrack.rtcId));
    }
    return null;
};
/**
 * Returns the list of RTCRtpReceivers created for the source of the given media type associated with
 * the set of remote endpoints specified.
 * @param {Array<string>} endpoints list of the endpoints
 * @param {string} mediaType 'audio' or 'video'
 * @returns {Array<RTCRtpReceiver>} list of receivers created by the peerconnection.
 */
TraceablePeerConnection.prototype._getReceiversByEndpointIds = function (endpoints, mediaType) {
    let remoteTracks = [];
    let receivers = [];
    for (const endpoint of endpoints) {
        remoteTracks = remoteTracks.concat(this.getRemoteTracks(endpoint, mediaType));
    }
    // Get the ids of the MediaStreamTracks associated with each of these remote tracks.
    const remoteTrackIds = remoteTracks.map(remote => { var _a; return (_a = remote.track) === null || _a === void 0 ? void 0 : _a.id; });
    receivers = this.peerconnection.getReceivers()
        .filter(receiver => receiver.track
        && receiver.track.kind === mediaType
        && remoteTrackIds.find(trackId => trackId === receiver.track.id));
    return receivers;
};
/**
 * Tells whether or not this TPC instance is using Simulcast.
 * @return {boolean} <tt>true</tt> if simulcast is enabled and active or
 * <tt>false</tt> if it's turned off.
 */
TraceablePeerConnection.prototype.isSimulcastOn = function () {
    return !this.options.disableSimulcast;
};
/**
 * Handles {@link SignalingEvents.PEER_VIDEO_TYPE_CHANGED}
 * @param {string} endpointId the video owner's ID (MUC nickname)
 * @param {VideoType} videoType the new value
 * @private
 */
TraceablePeerConnection.prototype._peerVideoTypeChanged = function (endpointId, videoType) {
    // Check if endpointId has a value to avoid action on random track
    if (!endpointId) {
        logger.error(`${this} No endpointID on peerVideoTypeChanged`);
        return;
    }
    const videoTrack = this.getRemoteTracks(endpointId, _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_5__.MediaType.VIDEO);
    if (videoTrack.length) {
        // NOTE 1 track per media type is assumed
        videoTrack[0]._setVideoType(videoType);
    }
};
/**
 * Handles remote track mute / unmute events.
 * @param {string} endpointId the track owner's identifier (MUC nickname)
 * @param {MediaType} mediaType "audio" or "video"
 * @param {boolean} isMuted the new mute state
 * @private
 */
TraceablePeerConnection.prototype._peerMutedChanged = function (endpointId, mediaType, isMuted) {
    // Check if endpointId is a value to avoid doing action on all remote tracks
    if (!endpointId) {
        logger.error(`${this} On peerMuteChanged - no endpoint ID`);
        return;
    }
    const track = this.getRemoteTracks(endpointId, mediaType);
    if (track.length) {
        // NOTE 1 track per media type is assumed
        track[0].setMute(isMuted);
    }
};
/**
 * Handles remote source mute and unmute changed events.
 *
 * @param {string} sourceName - The name of the remote source.
 * @param {boolean} isMuted - The new mute state.
 */
TraceablePeerConnection.prototype._sourceMutedChanged = function (sourceName, isMuted) {
    const track = this.getRemoteTracks().find(t => t.getSourceName() === sourceName);
    if (!track) {
        if (_flags_FeatureFlags__WEBPACK_IMPORTED_MODULE_12__["default"].isSsrcRewritingSupported()) {
            logger.debug(`Remote track not found for source=${sourceName}, mute update failed!`);
        }
        return;
    }
    track.setMute(isMuted);
};
/**
 * Handles remote source videoType changed events.
 *
 * @param {string} sourceName - The name of the remote source.
 * @param {boolean} isMuted - The new value.
 */
TraceablePeerConnection.prototype._sourceVideoTypeChanged = function (sourceName, videoType) {
    const track = this.getRemoteTracks().find(t => t.getSourceName() === sourceName);
    if (!track) {
        return;
    }
    track._setVideoType(videoType);
};
/**
 * Obtains audio levels of the remote audio tracks by getting the source information on the RTCRtpReceivers.
 * The information relevant to the ssrc is updated each time a RTP packet constaining the ssrc is received.
 * @param {Array<string>} speakerList list of endpoint ids for which audio levels are to be gathered.
 * @returns {Object} containing ssrc and audio level information as a key-value pair.
 */
TraceablePeerConnection.prototype.getAudioLevels = function (speakerList = []) {
    const audioLevels = {};
    const audioReceivers = speakerList.length
        ? this._getReceiversByEndpointIds(speakerList, _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_5__.MediaType.AUDIO)
        : this.peerconnection.getReceivers()
            .filter(receiver => receiver.track && receiver.track.kind === _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_5__.MediaType.AUDIO && receiver.track.enabled);
    audioReceivers.forEach(remote => {
        const ssrc = remote.getSynchronizationSources();
        if (ssrc && ssrc.length) {
            // As per spec, this audiolevel is a value between 0..1 (linear), where 1.0
            // represents 0 dBov, 0 represents silence, and 0.5 represents approximately
            // 6 dBSPL change in the sound pressure level from 0 dBov.
            // https://www.w3.org/TR/webrtc/#dom-rtcrtpcontributingsource-audiolevel
            audioLevels[ssrc[0].source] = ssrc[0].audioLevel;
        }
    });
    return audioLevels;
};
/**
 * Checks if the browser is currently doing true simulcast where in three different media streams are being sent to the
 * bridge. Currently this happens only when VP8 is the selected codec.
 * @returns {boolean}
 */
TraceablePeerConnection.prototype.doesTrueSimulcast = function () {
    return this.isSimulcastOn() && this.getConfiguredVideoCodec() === _service_RTC_CodecMimeType__WEBPACK_IMPORTED_MODULE_3__["default"].VP8;
};
/**
 * Returns the SSRCs associated with a given local video track.
 *
 * @param {JitsiLocalTrack} localTrack
 * @returns
 */
TraceablePeerConnection.prototype.getLocalVideoSSRCs = function (localTrack) {
    var _a, _b, _c;
    const ssrcs = [];
    if (!localTrack || !localTrack.isVideoTrack()) {
        return ssrcs;
    }
    const ssrcGroup = this.isSimulcastOn() ? 'SIM' : 'FID';
    return ((_c = (_b = (_a = this.localSSRCs.get(localTrack.rtcId)) === null || _a === void 0 ? void 0 : _a.groups) === null || _b === void 0 ? void 0 : _b.find(group => group.semantics === ssrcGroup)) === null || _c === void 0 ? void 0 : _c.ssrcs) || ssrcs;
};
/**
 * Obtains local tracks for given {@link MediaType}. If the <tt>mediaType</tt>
 * argument is omitted the list of all local tracks will be returned.
 * @param {MediaType} [mediaType]
 * @return {Array<JitsiLocalTrack>}
 */
TraceablePeerConnection.prototype.getLocalTracks = function (mediaType) {
    let tracks = Array.from(this.localTracks.values());
    if (mediaType !== undefined) {
        tracks = tracks.filter(track => track.getType() === mediaType);
    }
    return tracks;
};
/**
 * Retrieves the local video tracks.
 *
 * @returns {Array<JitsiLocalTrack>} - local video tracks.
 */
TraceablePeerConnection.prototype.getLocalVideoTracks = function () {
    return this.getLocalTracks(_service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_5__.MediaType.VIDEO);
};
/**
 * Checks whether or not this {@link TraceablePeerConnection} instance contains any local tracks for given
 * <tt>mediaType</tt>.
 *
 * @param {MediaType} mediaType - The media type.
 * @return {boolean}
 */
TraceablePeerConnection.prototype.hasAnyTracksOfType = function (mediaType) {
    if (!mediaType) {
        throw new Error('"mediaType" is required');
    }
    return this.getLocalTracks(mediaType).length > 0;
};
/**
 * Obtains all remote tracks currently known to this PeerConnection instance.
 *
 * @param {string} [endpointId] - The track owner's identifier (MUC nickname)
 * @param {MediaType} [mediaType] - The remote tracks will be filtered by their media type if this argument is
 * specified.
 * @return {Array<JitsiRemoteTrack>}
 */
TraceablePeerConnection.prototype.getRemoteTracks = function (endpointId, mediaType) {
    let remoteTracks = [];
    const endpoints = endpointId ? [endpointId] : this.remoteTracks.keys();
    for (const endpoint of endpoints) {
        const endpointTracksByMediaType = this.remoteTracks.get(endpoint);
        if (endpointTracksByMediaType) {
            for (const trackMediaType of endpointTracksByMediaType.keys()) {
                // per media type filtering
                if (!mediaType || mediaType === trackMediaType) {
                    remoteTracks = remoteTracks.concat(Array.from(endpointTracksByMediaType.get(trackMediaType)));
                }
            }
        }
    }
    return remoteTracks;
};
/**
 * Parses the remote description and returns the sdp lines of the sources associated with a remote participant.
 *
 * @param {string} id Endpoint id of the remote participant.
 * @returns {Array<string>} The sdp lines that have the ssrc information.
 */
TraceablePeerConnection.prototype.getRemoteSourceInfoByParticipant = function (id) {
    const removeSsrcInfo = [];
    const remoteTracks = this.getRemoteTracks(id);
    if (!(remoteTracks === null || remoteTracks === void 0 ? void 0 : remoteTracks.length)) {
        return removeSsrcInfo;
    }
    const primarySsrcs = remoteTracks.map(track => track.getSSRC());
    const sdp = new _sdp_SDP__WEBPACK_IMPORTED_MODULE_15__["default"](this.remoteDescription.sdp);
    primarySsrcs.forEach((ssrc, idx) => {
        for (const media of sdp.media) {
            let lines = '';
            let ssrcLines = _sdp_SDPUtil__WEBPACK_IMPORTED_MODULE_16__["default"].findLines(media, `a=ssrc:${ssrc}`);
            if (ssrcLines.length) {
                if (!removeSsrcInfo[idx]) {
                    removeSsrcInfo[idx] = '';
                }
                // Check if there are any FID groups present for the primary ssrc.
                const fidLines = _sdp_SDPUtil__WEBPACK_IMPORTED_MODULE_16__["default"].findLines(media, `a=ssrc-group:FID ${ssrc}`);
                if (fidLines.length) {
                    const secondarySsrc = fidLines[0].split(' ')[2];
                    lines += `${fidLines[0]}\r\n`;
                    ssrcLines = ssrcLines.concat(_sdp_SDPUtil__WEBPACK_IMPORTED_MODULE_16__["default"].findLines(media, `a=ssrc:${secondarySsrc}`));
                }
                removeSsrcInfo[idx] += `${ssrcLines.join('\r\n')}\r\n`;
                removeSsrcInfo[idx] += lines;
            }
        }
    });
    return removeSsrcInfo;
};
/**
 * Returns the target bitrates configured for the local video source.
 *
 * @returns {Object}
 */
TraceablePeerConnection.prototype.getTargetVideoBitrates = function () {
    const currentCodec = this.getConfiguredVideoCodec();
    return this.tpcUtils.videoBitrates[currentCodec.toUpperCase()] || this.tpcUtils.videoBitrates;
};
/**
 * Tries to find {@link JitsiTrack} for given SSRC number. It will search both
 * local and remote tracks bound to this instance.
 * @param {number} ssrc
 * @return {JitsiTrack|null}
 */
TraceablePeerConnection.prototype.getTrackBySSRC = function (ssrc) {
    if (typeof ssrc !== 'number') {
        throw new Error(`SSRC ${ssrc} is not a number`);
    }
    for (const localTrack of this.localTracks.values()) {
        if (this.getLocalSSRC(localTrack) === ssrc) {
            return localTrack;
        }
    }
    for (const remoteTrack of this.getRemoteTracks()) {
        if (remoteTrack.getSSRC() === ssrc) {
            return remoteTrack;
        }
    }
    return null;
};
/**
 * Tries to find SSRC number for given {@link JitsiTrack} id. It will search
 * both local and remote tracks bound to this instance.
 * @param {string} id
 * @return {number|null}
 */
TraceablePeerConnection.prototype.getSsrcByTrackId = function (id) {
    const findTrackById = track => track.getTrack().id === id;
    const localTrack = this.getLocalTracks().find(findTrackById);
    if (localTrack) {
        return this.getLocalSSRC(localTrack);
    }
    const remoteTrack = this.getRemoteTracks().find(findTrackById);
    if (remoteTrack) {
        return remoteTrack.getSSRC();
    }
    return null;
};
/**
 * Called when new remote MediaStream is added to the PeerConnection.
 * @param {MediaStream} stream the WebRTC MediaStream for remote participant
 */
TraceablePeerConnection.prototype._remoteStreamAdded = function (stream) {
    const streamId = stream.id;
    // Do not create remote tracks for 'mixed' JVB SSRCs (used by JVB for RTCP termination).
    if (!_RTC__WEBPACK_IMPORTED_MODULE_22__["default"].isUserStreamById(streamId)) {
        return;
    }
    // Bind 'addtrack'/'removetrack' event handlers
    if (_browser__WEBPACK_IMPORTED_MODULE_11__["default"].isChromiumBased()) {
        stream.onaddtrack = event => {
            this._remoteTrackAdded(stream, event.track);
        };
        stream.onremovetrack = event => {
            this._remoteTrackRemoved(stream, event.track);
        };
    }
    // Call remoteTrackAdded for each track in the stream
    const streamAudioTracks = stream.getAudioTracks();
    for (const audioTrack of streamAudioTracks) {
        this._remoteTrackAdded(stream, audioTrack);
    }
    const streamVideoTracks = stream.getVideoTracks();
    for (const videoTrack of streamVideoTracks) {
        this._remoteTrackAdded(stream, videoTrack);
    }
};
/**
 * Called on "track added" and "stream added" PeerConnection events (because we
 * handle streams on per track basis). Finds the owner and the SSRC for
 * the track and passes that to ChatRoom for further processing.
 * @param {MediaStream} stream the WebRTC MediaStream instance which is
 * the parent of the track
 * @param {MediaStreamTrack} track the WebRTC MediaStreamTrack added for remote
 * participant.
 * @param {RTCRtpTransceiver} transceiver the WebRTC transceiver that is created
 * for the remote participant in unified plan.
 */
TraceablePeerConnection.prototype._remoteTrackAdded = function (stream, track, transceiver = null) {
    const streamId = stream.id;
    const mediaType = track.kind;
    // Do not create remote tracks for 'mixed' JVB SSRCs (used by JVB for RTCP termination).
    if (!this.isP2P && !_RTC__WEBPACK_IMPORTED_MODULE_22__["default"].isUserStreamById(streamId)) {
        return;
    }
    logger.info(`${this} Received track event for remote stream[id=${streamId},type=${mediaType}]`);
    // look up an associated JID for a stream id
    if (!mediaType) {
        _util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_20__.callErrorHandler(new Error(`MediaType undefined for remote track, stream id: ${streamId}, track creation failed!`));
        return;
    }
    const remoteSDP = this._usesUnifiedPlan
        ? new _sdp_SDP__WEBPACK_IMPORTED_MODULE_15__["default"](this.peerconnection.remoteDescription.sdp)
        : new _sdp_SDP__WEBPACK_IMPORTED_MODULE_15__["default"](this.remoteDescription.sdp);
    let mediaLine;
    // In unified plan mode, find the matching mline using 'mid' or the 'msid' attr of the stream.
    if (this._usesUnifiedPlan) {
        if (transceiver === null || transceiver === void 0 ? void 0 : transceiver.mid) {
            const mid = transceiver.mid;
            mediaLine = remoteSDP.media.find(mls => _sdp_SDPUtil__WEBPACK_IMPORTED_MODULE_16__["default"].findLine(mls, `a=mid:${mid}`));
        }
        else {
            mediaLine = remoteSDP.media.find(mls => {
                const msid = _sdp_SDPUtil__WEBPACK_IMPORTED_MODULE_16__["default"].findLine(mls, 'a=msid:');
                return typeof msid === 'string' && streamId === msid.substring(7).split(' ')[0];
            });
        }
    }
    else {
        mediaLine = remoteSDP.media.find(mls => mls.startsWith(`m=${mediaType}`));
    }
    if (!mediaLine) {
        _util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_20__.callErrorHandler(new Error(`Matching media line not found in remote SDP for remote stream[id=${streamId},type=${mediaType}],`
            + 'track creation failed!'));
        return;
    }
    let ssrcLines = _sdp_SDPUtil__WEBPACK_IMPORTED_MODULE_16__["default"].findLines(mediaLine, 'a=ssrc:');
    ssrcLines = ssrcLines.filter(line => line.indexOf(`msid:${streamId}`) !== -1);
    if (!ssrcLines.length) {
        _util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_20__.callErrorHandler(new Error(`No SSRC lines found in remote SDP for remote stream[msid=${streamId},type=${mediaType}]`
            + 'track creation failed!'));
        return;
    }
    // FIXME the length of ssrcLines[0] not verified, but it will fail
    // with global error handler anyway
    const ssrcStr = ssrcLines[0].substring(7).split(' ')[0];
    const trackSsrc = Number(ssrcStr);
    const ownerEndpointId = this.signalingLayer.getSSRCOwner(trackSsrc);
    if (isNaN(trackSsrc) || trackSsrc < 0) {
        _util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_20__.callErrorHandler(new Error(`Invalid SSRC for remote stream[ssrc=${trackSsrc},id=${streamId},type=${mediaType}]`
            + 'track creation failed!'));
        return;
    }
    if (!ownerEndpointId) {
        _util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_20__.callErrorHandler(new Error(`No SSRC owner known for remote stream[ssrc=${trackSsrc},id=${streamId},type=${mediaType}]`
            + 'track creation failed!'));
        return;
    }
    const sourceName = this.signalingLayer.getTrackSourceName(trackSsrc);
    const peerMediaInfo = this.signalingLayer.getPeerMediaInfo(ownerEndpointId, mediaType, sourceName);
    // Assume default presence state for remote source. Presence can be received after source signaling. This shouldn't
    // prevent the endpoint from creating a remote track for the source.
    let muted = true;
    let videoType = mediaType === _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_5__.MediaType.VIDEO ? _service_RTC_VideoType__WEBPACK_IMPORTED_MODULE_9__.VideoType.CAMERA : undefined; // 'camera' by default
    if (peerMediaInfo) {
        muted = peerMediaInfo.muted;
        videoType = peerMediaInfo.videoType; // can be undefined
    }
    else {
        logger.info(`${this}: no source-info available for ${ownerEndpointId}:${sourceName}, assuming default state`);
    }
    this._createRemoteTrack(ownerEndpointId, stream, track, mediaType, videoType, trackSsrc, muted, sourceName);
};
// FIXME cleanup params
/* eslint-disable max-params */
/**
 * Initializes a new JitsiRemoteTrack instance with the data provided by
 * the signaling layer and SDP.
 *
 * @param {string} ownerEndpointId the owner's endpoint ID (MUC nickname)
 * @param {MediaStream} stream the WebRTC stream instance
 * @param {MediaStreamTrack} track the WebRTC track instance
 * @param {MediaType} mediaType the track's type of the media
 * @param {VideoType} [videoType] the track's type of the video (if applicable)
 * @param {number} ssrc the track's main SSRC number
 * @param {boolean} muted the initial muted status
 * @param {String} sourceName the track's source name
 */
TraceablePeerConnection.prototype._createRemoteTrack = function (ownerEndpointId, stream, track, mediaType, videoType, ssrc, muted, sourceName) {
    logger.info(`${this} creating remote track[endpoint=${ownerEndpointId},ssrc=${ssrc},`
        + `type=${mediaType},sourceName=${sourceName}]`);
    let remoteTracksMap = this.remoteTracks.get(ownerEndpointId);
    if (!remoteTracksMap) {
        remoteTracksMap = new Map();
        remoteTracksMap.set(_service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_5__.MediaType.AUDIO, new Set());
        remoteTracksMap.set(_service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_5__.MediaType.VIDEO, new Set());
        this.remoteTracks.set(ownerEndpointId, remoteTracksMap);
    }
    const userTracksByMediaType = remoteTracksMap.get(mediaType);
    if ((userTracksByMediaType === null || userTracksByMediaType === void 0 ? void 0 : userTracksByMediaType.size)
        && Array.from(userTracksByMediaType).find(jitsiTrack => jitsiTrack.getTrack() === track)) {
        // Ignore duplicated event which can originate either from 'onStreamAdded' or 'onTrackAdded'.
        logger.info(`${this} ignored duplicated track event for track[endpoint=${ownerEndpointId},type=${mediaType}]`);
        return;
    }
    const remoteTrack = new _JitsiRemoteTrack__WEBPACK_IMPORTED_MODULE_21__["default"](this.rtc, this.rtc.conference, ownerEndpointId, stream, track, mediaType, videoType, ssrc, muted, this.isP2P, sourceName);
    userTracksByMediaType.add(remoteTrack);
    this.eventEmitter.emit(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_6__["default"].REMOTE_TRACK_ADDED, remoteTrack, this);
};
/**
 * Handles remote stream removal.
 * @param stream the WebRTC MediaStream object which is being removed from the
 * PeerConnection
 */
TraceablePeerConnection.prototype._remoteStreamRemoved = function (stream) {
    if (!_RTC__WEBPACK_IMPORTED_MODULE_22__["default"].isUserStream(stream)) {
        logger.info(`Ignored remote 'stream removed' event for stream[id=${stream.id}]`);
        return;
    }
    // Call remoteTrackRemoved for each track in the stream
    const streamVideoTracks = stream.getVideoTracks();
    for (const videoTrack of streamVideoTracks) {
        this._remoteTrackRemoved(stream, videoTrack);
    }
    const streamAudioTracks = stream.getAudioTracks();
    for (const audioTrack of streamAudioTracks) {
        this._remoteTrackRemoved(stream, audioTrack);
    }
};
/**
 * Handles remote media track removal.
 *
 * @param {MediaStream} stream - WebRTC MediaStream instance which is the parent of the track.
 * @param {MediaStreamTrack} track - WebRTC MediaStreamTrack which has been removed from the PeerConnection.
 * @returns {void}
 */
TraceablePeerConnection.prototype._remoteTrackRemoved = function (stream, track) {
    const streamId = stream.id;
    const trackId = track === null || track === void 0 ? void 0 : track.id;
    // Ignore stream removed events for JVB "mixed" sources (used for RTCP termination).
    if (!_RTC__WEBPACK_IMPORTED_MODULE_22__["default"].isUserStreamById(streamId)) {
        return;
    }
    if (!streamId) {
        _util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_20__.callErrorHandler(new Error(`${this} remote track removal failed - no stream ID`));
        return;
    }
    if (!trackId) {
        _util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_20__.callErrorHandler(new Error(`${this} remote track removal failed - no track ID`));
        return;
    }
    const toBeRemoved = this.getRemoteTracks().find(remoteTrack => remoteTrack.getStreamId() === streamId && remoteTrack.getTrackId() === trackId);
    if (!toBeRemoved) {
        _util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_20__.callErrorHandler(new Error(`${this} remote track removal failed - track not found`));
        return;
    }
    this._removeRemoteTrack(toBeRemoved);
};
/**
 * Removes all JitsiRemoteTracks associated with given MUC nickname (resource part of the JID).
 *
 * @param {string} owner - The resource part of the MUC JID.
 * @returns {JitsiRemoteTrack[]} - The array of removed tracks.
 */
TraceablePeerConnection.prototype.removeRemoteTracks = function (owner) {
    let removedTracks = [];
    const remoteTracksByMedia = this.remoteTracks.get(owner);
    if (remoteTracksByMedia) {
        removedTracks = removedTracks.concat(Array.from(remoteTracksByMedia.get(_service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_5__.MediaType.AUDIO)));
        removedTracks = removedTracks.concat(Array.from(remoteTracksByMedia.get(_service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_5__.MediaType.VIDEO)));
        this.remoteTracks.delete(owner);
    }
    logger.debug(`${this} removed remote tracks[endpoint=${owner},count=${removedTracks.length}`);
    return removedTracks;
};
/**
 * Removes and disposes given <tt>JitsiRemoteTrack</tt> instance. Emits {@link RTCEvents.REMOTE_TRACK_REMOVED}.
 *
 * @param {JitsiRemoteTrack} toBeRemoved - The remote track to be removed.
 * @returns {void}
 */
TraceablePeerConnection.prototype._removeRemoteTrack = function (toBeRemoved) {
    var _a;
    logger.info(`${this} Removing remote track stream[id=${toBeRemoved.getStreamId()},`
        + `trackId=${toBeRemoved.getTrackId()}]`);
    toBeRemoved.dispose();
    const participantId = toBeRemoved.getParticipantId();
    if (!participantId && _flags_FeatureFlags__WEBPACK_IMPORTED_MODULE_12__["default"].isSsrcRewritingSupported()) {
        return;
    }
    const userTracksByMediaType = this.remoteTracks.get(participantId);
    if (!userTracksByMediaType) {
        logger.error(`${this} removeRemoteTrack: no remote tracks map for endpoint=${participantId}`);
    }
    else if (!((_a = userTracksByMediaType.get(toBeRemoved.getType())) === null || _a === void 0 ? void 0 : _a.delete(toBeRemoved))) {
        logger.error(`${this} Failed to remove ${toBeRemoved} - type mapping messed up ?`);
    }
    this.eventEmitter.emit(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_6__["default"].REMOTE_TRACK_REMOVED, toBeRemoved);
};
/**
 * Returns a map with keys msid/mediaType and <tt>TrackSSRCInfo</tt> values.
 * @param {RTCSessionDescription} desc the local description.
 * @return {Map<string,TrackSSRCInfo>}
 */
TraceablePeerConnection.prototype._extractSSRCMap = function (desc) {
    /**
     * Track SSRC infos mapped by stream ID (msid) or mediaType (unified-plan)
     * @type {Map<string,TrackSSRCInfo>}
     */
    const ssrcMap = new Map();
    /**
     * Groups mapped by primary SSRC number
     * @type {Map<number,Array<SSRCGroupInfo>>}
     */
    const groupsMap = new Map();
    if (typeof desc !== 'object' || desc === null
        || typeof desc.sdp !== 'string') {
        logger.warn('An empty description was passed as an argument');
        return ssrcMap;
    }
    const session = sdp_transform__WEBPACK_IMPORTED_MODULE_2__.parse(desc.sdp);
    if (!Array.isArray(session.media)) {
        return ssrcMap;
    }
    let media = session.media;
    if (this._usesUnifiedPlan) {
        media = media.filter(mline => mline.direction === _service_RTC_MediaDirection__WEBPACK_IMPORTED_MODULE_4__.MediaDirection.SENDONLY
            || mline.direction === _service_RTC_MediaDirection__WEBPACK_IMPORTED_MODULE_4__.MediaDirection.SENDRECV);
    }
    else {
        media = [];
        [_service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_5__.MediaType.AUDIO, _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_5__.MediaType.VIDEO].forEach(mediaType => {
            const mLine = session.media.find(m => m.type === mediaType);
            mLine && media.push(mLine);
        });
    }
    let index = 0;
    for (const mLine of media) {
        if (!Array.isArray(mLine.ssrcs)) {
            continue; // eslint-disable-line no-continue
        }
        if (Array.isArray(mLine.ssrcGroups)) {
            for (const group of mLine.ssrcGroups) {
                if (typeof group.semantics !== 'undefined' && typeof group.ssrcs !== 'undefined') {
                    // Parse SSRCs and store as numbers
                    const groupSSRCs = group.ssrcs.split(' ').map(ssrcStr => parseInt(ssrcStr, 10));
                    const primarySSRC = groupSSRCs[0];
                    // Note that group.semantics is already present
                    group.ssrcs = groupSSRCs;
                    // eslint-disable-next-line max-depth
                    if (!groupsMap.has(primarySSRC)) {
                        groupsMap.set(primarySSRC, []);
                    }
                    groupsMap.get(primarySSRC).push(group);
                }
            }
            const simGroup = mLine.ssrcGroups.find(group => group.semantics === 'SIM');
            // Add a SIM group if its missing in the description (happens on Firefox).
            if (!simGroup) {
                const groupSsrcs = mLine.ssrcGroups.map(group => group.ssrcs[0]);
                groupsMap.get(groupSsrcs[0]).push({
                    semantics: 'SIM',
                    ssrcs: groupSsrcs
                });
            }
        }
        let ssrcs = mLine.ssrcs;
        // Filter the ssrcs with 'msid' attribute for plan-b clients and 'cname' for unified-plan clients.
        ssrcs = this._usesUnifiedPlan
            ? ssrcs.filter(s => s.attribute === 'cname')
            : ssrcs.filter(s => s.attribute === 'msid');
        for (const ssrc of ssrcs) {
            // Use the mediaType as key for the source map for unified plan clients since msids are not part of
            // the standard and the unified plan SDPs do not have a proper msid attribute for the sources.
            // Also the ssrcs for sources do not change for Unified plan clients since RTCRtpSender#replaceTrack is
            // used for switching the tracks so it is safe to use the mediaType as the key for the TrackSSRCInfo map.
            const key = this._usesUnifiedPlan ? `${mLine.type}-${index}` : ssrc.value;
            const ssrcNumber = ssrc.id;
            let ssrcInfo = ssrcMap.get(key);
            if (!ssrcInfo) {
                ssrcInfo = {
                    ssrcs: [],
                    groups: [],
                    msid: key
                };
                ssrcMap.set(key, ssrcInfo);
            }
            ssrcInfo.ssrcs.push(ssrcNumber);
            if (groupsMap.has(ssrcNumber)) {
                const ssrcGroups = groupsMap.get(ssrcNumber);
                for (const group of ssrcGroups) {
                    ssrcInfo.groups.push(group);
                }
            }
        }
        // Currently multi-stream is supported for video only.
        mLine.type === _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_5__.MediaType.VIDEO && index++;
    }
    return ssrcMap;
};
/**
 * Takes a SessionDescription object and returns a "normalized" version.
 * Currently it takes care of ordering the a=ssrc lines and denoting receive
 * only SSRCs.
 */
const normalizePlanB = function (desc) {
    if (typeof desc !== 'object' || desc === null
        || typeof desc.sdp !== 'string') {
        logger.warn('An empty description was passed as an argument');
        return desc;
    }
    // eslint-disable-next-line no-shadow
    const transform = __webpack_require__(/*! sdp-transform */ "./node_modules/sdp-transform/lib/index.js");
    const session = transform.parse(desc.sdp);
    if (typeof session !== 'undefined'
        && typeof session.media !== 'undefined'
        && Array.isArray(session.media)) {
        session.media.forEach(mLine => {
            // Chrome appears to be picky about the order in which a=ssrc lines
            // are listed in an m-line when rtx is enabled (and thus there are
            // a=ssrc-group lines with FID semantics). Specifically if we have
            // "a=ssrc-group:FID S1 S2" and the "a=ssrc:S2" lines appear before
            // the "a=ssrc:S1" lines, SRD fails.
            // So, put SSRC which appear as the first SSRC in an FID ssrc-group
            // first.
            const firstSsrcs = [];
            const newSsrcLines = [];
            if (typeof mLine.ssrcGroups !== 'undefined'
                && Array.isArray(mLine.ssrcGroups)) {
                mLine.ssrcGroups.forEach(group => {
                    if (typeof group.semantics !== 'undefined'
                        && group.semantics === 'FID') {
                        if (typeof group.ssrcs !== 'undefined') {
                            firstSsrcs.push(Number(group.ssrcs.split(' ')[0]));
                        }
                    }
                });
            }
            if (Array.isArray(mLine.ssrcs)) {
                let i;
                for (i = 0; i < mLine.ssrcs.length; i++) {
                    if (typeof mLine.ssrcs[i] === 'object'
                        && typeof mLine.ssrcs[i].id !== 'undefined'
                        && firstSsrcs.indexOf(mLine.ssrcs[i].id) >= 0) {
                        newSsrcLines.push(mLine.ssrcs[i]);
                        delete mLine.ssrcs[i];
                    }
                }
                for (i = 0; i < mLine.ssrcs.length; i++) {
                    if (typeof mLine.ssrcs[i] !== 'undefined') {
                        newSsrcLines.push(mLine.ssrcs[i]);
                    }
                }
                mLine.ssrcs = replaceDefaultUnifiedPlanMsid(newSsrcLines);
            }
        });
    }
    const resStr = transform.write(session);
    return new RTCSessionDescription({
        type: desc.type,
        sdp: resStr
    });
};
/**
 * Unified plan differentiates a remote track not associated with a stream using
 * the msid "-", which can incorrectly trigger an onaddstream event in plan-b.
 * For jitsi, these tracks are actually receive-only ssrcs. To prevent
 * onaddstream from firing, remove the ssrcs with msid "-" except the cname
 * line. Normally the ssrcs are not used by the client, as the bridge controls
 * media flow, but keep one reference to the ssrc for the p2p case.
 *
 * @param {Array<Object>} ssrcLines - The ssrc lines from a remote description.
 * @private
 * @returns {Array<Object>} ssrcLines with removed lines referencing msid "-".
 */
function replaceDefaultUnifiedPlanMsid(ssrcLines = []) {
    if (!_browser__WEBPACK_IMPORTED_MODULE_11__["default"].isChrome() || !_browser__WEBPACK_IMPORTED_MODULE_11__["default"].isVersionGreaterThan(70)) {
        return ssrcLines;
    }
    let filteredLines = [...ssrcLines];
    const problematicSsrcIds = ssrcLines.filter(ssrcLine => ssrcLine.attribute === 'mslabel' && ssrcLine.value === '-')
        .map(ssrcLine => ssrcLine.id);
    problematicSsrcIds.forEach(ssrcId => {
        // Find the cname which is to be modified and left in.
        const cnameLine = filteredLines.find(line => line.id === ssrcId && line.attribute === 'cname');
        cnameLine.value = `${_service_RTC_MediaDirection__WEBPACK_IMPORTED_MODULE_4__.MediaDirection.RECVONLY}-${ssrcId}`;
        // Remove all of lines for the ssrc.
        filteredLines
            = filteredLines.filter(line => line.id !== ssrcId);
        // But re-add the cname line so there is a reference kept to the ssrc
        // in the SDP.
        filteredLines.push(cnameLine);
    });
    return filteredLines;
}
/**
 * Makes sure that both audio and video directions are configured as 'sendrecv'.
 * @param {Object} localDescription the SDP object as defined by WebRTC.
 * @param {object} options <tt>TracablePeerConnection</tt> config options.
 */
const enforceSendRecv = function (localDescription, options) {
    var _a, _b;
    if (!localDescription) {
        throw new Error('No local description passed in.');
    }
    const transformer = new _sdp_SdpTransformUtil__WEBPACK_IMPORTED_MODULE_19__.SdpTransformWrap(localDescription.sdp);
    const audioMedia = (_a = transformer.selectMedia(_service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_5__.MediaType.AUDIO)) === null || _a === void 0 ? void 0 : _a[0];
    let changed = false;
    if (audioMedia && audioMedia.direction !== _service_RTC_MediaDirection__WEBPACK_IMPORTED_MODULE_4__.MediaDirection.SENDRECV) {
        if (options.startSilent) {
            audioMedia.direction = _service_RTC_MediaDirection__WEBPACK_IMPORTED_MODULE_4__.MediaDirection.INACTIVE;
        }
        else {
            audioMedia.direction = _service_RTC_MediaDirection__WEBPACK_IMPORTED_MODULE_4__.MediaDirection.SENDRECV;
        }
        changed = true;
    }
    const videoMedia = (_b = transformer.selectMedia(_service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_5__.MediaType.VIDEO)) === null || _b === void 0 ? void 0 : _b[0];
    if (videoMedia && videoMedia.direction !== _service_RTC_MediaDirection__WEBPACK_IMPORTED_MODULE_4__.MediaDirection.SENDRECV) {
        videoMedia.direction = _service_RTC_MediaDirection__WEBPACK_IMPORTED_MODULE_4__.MediaDirection.SENDRECV;
        changed = true;
    }
    if (changed) {
        return new RTCSessionDescription({
            type: localDescription.type,
            sdp: transformer.toRawSDP()
        });
    }
    return localDescription;
};
/**
 *
 * @param {JitsiLocalTrack} localTrack
 */
TraceablePeerConnection.prototype.getLocalSSRC = function (localTrack) {
    const ssrcInfo = this._getSSRC(localTrack.rtcId);
    return ssrcInfo && ssrcInfo.ssrcs[0];
};
/**
 * When doing unified plan simulcast, we'll have a set of ssrcs but no ssrc-groups on Firefox. Unfortunately, Jicofo
 * will complain if it sees ssrcs with matching msids but no ssrc-group, so a ssrc-group line is injected to make
 * Jicofo happy.
 *
 * @param desc A session description object (with 'type' and 'sdp' fields)
 * @return A session description object with its sdp field modified to contain an inject ssrc-group for simulcast.
 */
TraceablePeerConnection.prototype._injectSsrcGroupForUnifiedSimulcast = function (desc) {
    const sdp = sdp_transform__WEBPACK_IMPORTED_MODULE_2__.parse(desc.sdp);
    const video = sdp.media.find(mline => mline.type === 'video');
    // Check if the browser supports RTX, add only the primary ssrcs to the SIM group if that is the case.
    video.ssrcGroups = video.ssrcGroups || [];
    const fidGroups = video.ssrcGroups.filter(group => group.semantics === 'FID');
    if (video.simulcast || video.simulcast_03) {
        const ssrcs = [];
        if (fidGroups && fidGroups.length) {
            fidGroups.forEach(group => {
                ssrcs.push(group.ssrcs.split(' ')[0]);
            });
        }
        else {
            video.ssrcs.forEach(ssrc => {
                if (ssrc.attribute === 'msid') {
                    ssrcs.push(ssrc.id);
                }
            });
        }
        if (video.ssrcGroups.find(group => group.semantics === 'SIM')) {
            // Group already exists, no need to do anything
            return desc;
        }
        // Add a SIM group for every 3 FID groups.
        for (let i = 0; i < ssrcs.length; i += 3) {
            const simSsrcs = ssrcs.slice(i, i + 3);
            video.ssrcGroups.push({
                semantics: 'SIM',
                ssrcs: simSsrcs.join(' ')
            });
        }
    }
    return new RTCSessionDescription({
        type: desc.type,
        sdp: sdp_transform__WEBPACK_IMPORTED_MODULE_2__.write(sdp)
    });
};
/* eslint-disable-next-line vars-on-top */
const getters = {
    signalingState() {
        return this.peerconnection.signalingState;
    },
    iceConnectionState() {
        return this.peerconnection.iceConnectionState;
    },
    connectionState() {
        return this.peerconnection.connectionState;
    },
    localDescription() {
        let desc = this.peerconnection.localDescription;
        if (!desc) {
            logger.debug(`${this} getLocalDescription no localDescription found`);
            return {};
        }
        this.trace('getLocalDescription::preTransform', dumpSDP(desc));
        // If the browser is running in unified plan mode and this is a jvb connection,
        // transform the SDP to Plan B first.
        if (this._usesUnifiedPlan && !this.isP2P) {
            desc = this.interop.toPlanB(desc);
            this.trace('getLocalDescription::postTransform (Plan B)', dumpSDP(desc));
            desc = this._injectSsrcGroupForUnifiedSimulcast(desc);
            this.trace('getLocalDescription::postTransform (inject ssrc group)', dumpSDP(desc));
        }
        else if (!this._usesUnifiedPlan) {
            if (_browser__WEBPACK_IMPORTED_MODULE_11__["default"].doesVideoMuteByStreamRemove()) {
                desc = this.localSdpMunger.maybeAddMutedLocalVideoTracksToSDP(desc);
                logger.debug('getLocalDescription::postTransform (munge local SDP)', desc);
            }
            // What comes out of this getter will be signalled over Jingle to
            // the other peer, so we need to make sure the media direction is
            // 'sendrecv' because we won't change the direction later and don't want
            // the other peer to think we can't send or receive.
            //
            // Note that the description we set in chrome does have the accurate
            // direction (e.g. 'recvonly'), since that is technically what is
            // happening (check setLocalDescription impl).
            desc = enforceSendRecv(desc, this.options);
        }
        // See the method's doc for more info about this transformation.
        desc = this.localSdpMunger.transformStreamIdentifiers(desc);
        return desc;
    },
    remoteDescription() {
        let desc = this.peerconnection.remoteDescription;
        if (!desc) {
            logger.debug(`${this} getRemoteDescription no remoteDescription found`);
            return {};
        }
        this.trace('getRemoteDescription::preTransform', dumpSDP(desc));
        if (this._usesUnifiedPlan) {
            if (this.isP2P) {
                // Adjust the media direction for p2p based on whether a local source has been added.
                desc = this._adjustRemoteMediaDirection(desc);
            }
            else {
                // If this is a jvb connection, transform the SDP to Plan B first.
                desc = this.interop.toPlanB(desc);
                this.trace('getRemoteDescription::postTransform (Plan B)', dumpSDP(desc));
            }
        }
        return desc;
    }
};
Object.keys(getters).forEach(prop => {
    Object.defineProperty(TraceablePeerConnection.prototype, prop, {
        get: getters[prop]
    });
});
TraceablePeerConnection.prototype._getSSRC = function (rtcId) {
    return this.localSSRCs.get(rtcId);
};
/**
 * Checks if low fps screensharing is in progress.
 *
 * @private
 * @returns {boolean} Returns true if 5 fps screensharing is in progress, false otherwise.
 */
TraceablePeerConnection.prototype.isSharingLowFpsScreen = function () {
    return this._isSharingScreen() && this._capScreenshareBitrate;
};
/**
 * Checks if screensharing is in progress.
 *
 * @returns {boolean}  Returns true if a desktop track has been added to the peerconnection, false otherwise.
 */
TraceablePeerConnection.prototype._isSharingScreen = function () {
    const tracks = this.getLocalVideoTracks();
    return Boolean(tracks.find(track => track.videoType === _service_RTC_VideoType__WEBPACK_IMPORTED_MODULE_9__.VideoType.DESKTOP));
};
/**
 * Munges the order of the codecs in the SDP passed based on the preference
 * set through config.js settings. All instances of the specified codec are
 * moved up to the top of the list when it is preferred. The specified codec
 * is deleted from the list if the configuration specifies that the codec be
 * disabled.
 * @param {RTCSessionDescription} description that needs to be munged.
 * @returns {RTCSessionDescription} the munged description.
 */
TraceablePeerConnection.prototype._mungeCodecOrder = function (description) {
    if (!this.codecSettings) {
        return description;
    }
    const parsedSdp = sdp_transform__WEBPACK_IMPORTED_MODULE_2__.parse(description.sdp);
    const mLines = parsedSdp.media.filter(m => m.type === this.codecSettings.mediaType);
    if (!mLines.length) {
        return description;
    }
    for (const mLine of mLines) {
        const currentCodecs = this.getConfiguredVideoCodecs();
        for (const codec of currentCodecs) {
            // Strip the high profile H264 codecs on mobile clients for p2p connection. High profile codecs give better
            // quality at the expense of higher load which we do not want on mobile clients. Jicofo offers only the
            // baseline code for the jvb connection and therefore this is not needed for jvb connection.
            if (codec === _service_RTC_CodecMimeType__WEBPACK_IMPORTED_MODULE_3__["default"].H264 && _browser__WEBPACK_IMPORTED_MODULE_11__["default"].isMobileDevice() && this.isP2P) {
                _sdp_SDPUtil__WEBPACK_IMPORTED_MODULE_16__["default"].stripCodec(mLine, codec, true /* high profile */);
            }
        }
        // Reorder the codecs based on the preferred settings.
        for (const codec of this.codecSettings.codecList.slice().reverse()) {
            _sdp_SDPUtil__WEBPACK_IMPORTED_MODULE_16__["default"].preferCodec(mLine, codec);
        }
    }
    return new RTCSessionDescription({
        type: description.type,
        sdp: sdp_transform__WEBPACK_IMPORTED_MODULE_2__.write(parsedSdp)
    });
};
/**
 * Add {@link JitsiLocalTrack} to this TPC.
 * @param {JitsiLocalTrack} track
 * @param {boolean} isInitiator indicates if the endpoint is the offerer.
 * @returns {Promise<void>} - resolved when done.
 */
TraceablePeerConnection.prototype.addTrack = function (track, isInitiator = false) {
    const rtcId = track.rtcId;
    logger.info(`${this} adding ${track}`);
    if (this.localTracks.has(rtcId)) {
        return Promise.reject(new Error(`${track} is already in ${this}`));
    }
    this.localTracks.set(rtcId, track);
    const webrtcStream = track.getOriginalStream();
    if (this._usesUnifiedPlan) {
        logger.debug(`${this} TPC.addTrack using unified plan`);
        try {
            this.tpcUtils.addTrack(track, isInitiator);
            if (track) {
                if (track.isAudioTrack()) {
                    this._hasHadAudioTrack = true;
                }
                else {
                    this._hasHadVideoTrack = true;
                }
            }
        }
        catch (error) {
            logger.error(`${this} Adding track=${track} failed: ${error === null || error === void 0 ? void 0 : error.message}`);
            return Promise.reject(error);
        }
    }
    else {
        // Use addStream API for the plan-b case.
        if (webrtcStream) {
            this._addStream(webrtcStream);
            // It's not ok for a track to not have a WebRTC stream if:
        }
        else if (!_browser__WEBPACK_IMPORTED_MODULE_11__["default"].doesVideoMuteByStreamRemove()
            || track.isAudioTrack()
            || (track.isVideoTrack() && !track.isMuted())) {
            return Promise.reject(new Error(`${this} no WebRTC stream for track=${track}`));
        }
        // Muted video tracks do not have WebRTC stream
        if (_browser__WEBPACK_IMPORTED_MODULE_11__["default"].doesVideoMuteByStreamRemove() && track.isVideoTrack() && track.isMuted()) {
            const ssrcInfo = this.generateNewStreamSSRCInfo(track);
            this.sdpConsistency.setPrimarySsrc(ssrcInfo.ssrcs[0]);
            const simGroup = ssrcInfo.groups.find(groupInfo => groupInfo.semantics === 'SIM');
            if (simGroup) {
                this.simulcast.setSsrcCache(simGroup.ssrcs);
            }
            const fidGroups = ssrcInfo.groups.filter(groupInfo => groupInfo.semantics === 'FID');
            if (fidGroups) {
                const rtxSsrcMapping = new Map();
                fidGroups.forEach(fidGroup => {
                    const primarySsrc = fidGroup.ssrcs[0];
                    const rtxSsrc = fidGroup.ssrcs[1];
                    rtxSsrcMapping.set(primarySsrc, rtxSsrc);
                });
                this.rtxModifier.setSsrcCache(rtxSsrcMapping);
            }
        }
    }
    let promiseChain = Promise.resolve();
    // On Firefox, the encodings have to be configured on the sender only after the transceiver is created.
    if (_browser__WEBPACK_IMPORTED_MODULE_11__["default"].isFirefox()) {
        promiseChain = promiseChain.then(() => webrtcStream && this.tpcUtils.setEncodings(track));
    }
    return promiseChain;
};
/**
 * Adds local track to the RTCPeerConnection.
 *
 * @param {JitsiLocalTrack} track the track to be added to the pc.
 * @return {Promise<boolean>} Promise that resolves to true if the underlying PeerConnection's state has changed and
 * renegotiation is required, false if no renegotiation is needed or Promise is rejected when something goes wrong.
 */
TraceablePeerConnection.prototype.addTrackToPc = function (track) {
    logger.info(`${this} Adding track=${track} to PC`);
    if (!this._assertTrackBelongs('addTrackToPc', track)) {
        // Abort
        return Promise.reject('Track not found on the peerconnection');
    }
    const webRtcStream = track.getOriginalStream();
    if (!webRtcStream) {
        logger.error(`${this} Unable to add track=${track} to PC - no WebRTC stream`);
        return Promise.reject('Stream not found');
    }
    if (this._usesUnifiedPlan) {
        return this.tpcUtils.replaceTrack(null, track).then(() => {
            if (track) {
                if (track.isAudioTrack()) {
                    this._hasHadAudioTrack = true;
                }
                else {
                    this._hasHadVideoTrack = true;
                }
            }
            return false;
        });
    }
    this._addStream(webRtcStream);
    return Promise.resolve(true);
};
/**
 * Adds WebRTC media stream to the underlying PeerConnection
 * @param {MediaStream} mediaStream
 * @private
 */
TraceablePeerConnection.prototype._addStream = function (mediaStream) {
    this.peerconnection.addStream(mediaStream);
    this._addedStreams.push(mediaStream);
};
/**
 * Removes WebRTC media stream from the underlying PeerConection
 * @param {MediaStream} mediaStream
 */
TraceablePeerConnection.prototype._removeStream = function (mediaStream) {
    this.peerconnection.removeStream(mediaStream);
    this._addedStreams
        = this._addedStreams.filter(stream => stream !== mediaStream);
};
/**
 * This method when called will check if given <tt>localTrack</tt> belongs to
 * this TPC (that it has been previously added using {@link addTrack}). If the
 * track does not belong an error message will be logged.
 * @param {string} methodName the method name that will be logged in an error
 * message
 * @param {JitsiLocalTrack} localTrack
 * @return {boolean} <tt>true</tt> if given local track belongs to this TPC or
 * <tt>false</tt> otherwise.
 * @private
 */
TraceablePeerConnection.prototype._assertTrackBelongs = function (methodName, localTrack) {
    const doesBelong = this.localTracks.has(localTrack === null || localTrack === void 0 ? void 0 : localTrack.rtcId);
    if (!doesBelong) {
        logger.error(`${this} ${methodName}: track=${localTrack} does not belong to pc`);
    }
    return doesBelong;
};
/**
 * Returns the codec that is configured on the client as the preferred video codec.
 * This takes into account the current order of codecs in the local description sdp.
 *
 * @returns {CodecMimeType} The codec that is set as the preferred codec to receive
 * video in the local SDP.
 */
TraceablePeerConnection.prototype.getConfiguredVideoCodec = function () {
    var _a;
    const sdp = (_a = this.peerconnection.localDescription) === null || _a === void 0 ? void 0 : _a.sdp;
    const defaultCodec = _service_RTC_CodecMimeType__WEBPACK_IMPORTED_MODULE_3__["default"].VP8;
    if (!sdp) {
        return defaultCodec;
    }
    const parsedSdp = sdp_transform__WEBPACK_IMPORTED_MODULE_2__.parse(sdp);
    const mLine = parsedSdp.media.find(m => m.type === _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_5__.MediaType.VIDEO);
    const codec = mLine.rtp[0].codec;
    if (codec) {
        return Object.values(_service_RTC_CodecMimeType__WEBPACK_IMPORTED_MODULE_3__["default"]).find(value => value === codec.toLowerCase());
    }
    return defaultCodec;
};
/**
 * Returns the codecs in the current order of preference as configured on the peerconnection.
 *
 * @returns {Array}
 */
TraceablePeerConnection.prototype.getConfiguredVideoCodecs = function () {
    var _a;
    const sdp = (_a = this.peerconnection.localDescription) === null || _a === void 0 ? void 0 : _a.sdp;
    if (!sdp) {
        return [];
    }
    const parsedSdp = sdp_transform__WEBPACK_IMPORTED_MODULE_2__.parse(sdp);
    const mLine = parsedSdp.media.find(m => m.type === _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_5__.MediaType.VIDEO);
    const codecs = new Set(mLine.rtp
        .filter(pt => pt.codec.toLowerCase() !== 'rtx')
        .map(pt => pt.codec.toLowerCase()));
    return Array.from(codecs);
};
/**
 * Checks if the client has negotiated not to receive video encoded using the given codec, i.e., the codec has been
 * removed from the local description.
 */
TraceablePeerConnection.prototype.isVideoCodecDisabled = function (codec) {
    var _a;
    const sdp = (_a = this.peerconnection.localDescription) === null || _a === void 0 ? void 0 : _a.sdp;
    if (!sdp) {
        return false;
    }
    const parsedSdp = sdp_transform__WEBPACK_IMPORTED_MODULE_2__.parse(sdp);
    const mLine = parsedSdp.media.find(m => m.type === _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_5__.MediaType.VIDEO);
    return !mLine.rtp.find(r => r.codec === codec);
};
/**
 * Enables or disables simulcast for screenshare based on the frame rate requested for desktop track capture.
 *
 * @param {number} maxFps framerate to be used for desktop track capture.
 */
TraceablePeerConnection.prototype.setDesktopSharingFrameRate = function (maxFps) {
    const lowFps = maxFps <= _RTC_ScreenObtainer__WEBPACK_IMPORTED_MODULE_10__.SS_DEFAULT_FRAME_RATE;
    this._capScreenshareBitrate = this.isSimulcastOn() && lowFps;
};
/**
 * Sets the codec preference on the peerconnection. The codec preference goes into effect when
 * the next renegotiation happens.
 *
 * @param {CodecMimeType} preferredCodec the preferred codec.
 * @param {CodecMimeType} disabledCodec the codec that needs to be disabled.
 * @returns {void}
 */
TraceablePeerConnection.prototype.setVideoCodecs = function (codecList) {
    if (!this.codecSettings || !(codecList === null || codecList === void 0 ? void 0 : codecList.length)) {
        return;
    }
    this.codecSettings.codecList = codecList;
};
/**
 * Tells if the given WebRTC <tt>MediaStream</tt> has been added to
 * the underlying WebRTC PeerConnection.
 * @param {MediaStream} mediaStream
 * @returns {boolean}
 */
TraceablePeerConnection.prototype.isMediaStreamInPc = function (mediaStream) {
    return this._addedStreams.indexOf(mediaStream) > -1;
};
/**
 * Remove local track from this TPC.
 * @param {JitsiLocalTrack} localTrack the track to be removed from this TPC.
 *
 * FIXME It should probably remove a boolean just like {@link removeTrackFromPc}
 *       The same applies to addTrack.
 */
TraceablePeerConnection.prototype.removeTrack = function (localTrack) {
    const webRtcStream = localTrack.getOriginalStream();
    this.trace('removeStream', localTrack.rtcId, webRtcStream ? webRtcStream.id : undefined);
    if (!this._assertTrackBelongs('removeStream', localTrack)) {
        // Abort - nothing to be done here
        return;
    }
    this.localTracks.delete(localTrack.rtcId);
    this.localSSRCs.delete(localTrack.rtcId);
    if (webRtcStream) {
        this.peerconnection.removeStream(webRtcStream);
    }
};
/**
 * Returns the sender corresponding to the given media type.
 * @param {MEDIA_TYPE} mediaType - The media type 'audio' or 'video' to be used for the search.
 * @returns {RTPSender|undefined} - The found sender or undefined if no sender
 * was found.
 */
TraceablePeerConnection.prototype.findSenderByKind = function (mediaType) {
    if (this.peerconnection.getSenders) {
        return this.peerconnection.getSenders().find(s => s.track && s.track.kind === mediaType);
    }
};
/**
 * Returns the receiver corresponding to the given MediaStreamTrack.
 *
 * @param {MediaSreamTrack} track - The media stream track used for the search.
 * @returns {RTCRtpReceiver|undefined} - The found receiver or undefined if no receiver
 * was found.
 */
TraceablePeerConnection.prototype.findReceiverForTrack = function (track) {
    return this.peerconnection.getReceivers().find(r => r.track === track);
};
/**
 * Returns the sender corresponding to the given MediaStreamTrack.
 *
 * @param {MediaSreamTrack} track - The media stream track used for the search.
 * @returns {RTCRtpSender|undefined} - The found sender or undefined if no sender
 * was found.
 */
TraceablePeerConnection.prototype.findSenderForTrack = function (track) {
    if (this.peerconnection.getSenders) {
        return this.peerconnection.getSenders().find(s => s.track === track);
    }
};
/**
 * Processes the local description SDP and caches the mids of the mlines associated with the given tracks.
 *
 * @param {Array<JitsiLocalTrack>} localTracks - local tracks that are added to the peerconnection.
 * @returns {void}
 */
TraceablePeerConnection.prototype.processLocalSdpForTransceiverInfo = function (localTracks) {
    var _a;
    const localSdp = (_a = this.peerconnection.localDescription) === null || _a === void 0 ? void 0 : _a.sdp;
    if (!localSdp) {
        return;
    }
    [_service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_5__.MediaType.AUDIO, _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_5__.MediaType.VIDEO].forEach(mediaType => {
        const tracks = localTracks.filter(t => t.getType() === mediaType);
        const parsedSdp = sdp_transform__WEBPACK_IMPORTED_MODULE_2__.parse(localSdp);
        const mLines = parsedSdp.media.filter(mline => mline.type === mediaType);
        tracks.forEach((track, idx) => {
            if (!this._localTrackTransceiverMids.has(track.rtcId)) {
                this._localTrackTransceiverMids.set(track.rtcId, mLines[idx].mid.toString());
            }
        });
    });
};
/**
 * Replaces <tt>oldTrack</tt> with <tt>newTrack</tt> from the peer connection.
 * Either <tt>oldTrack</tt> or <tt>newTrack</tt> can be null; replacing a valid
 * <tt>oldTrack</tt> with a null <tt>newTrack</tt> effectively just removes
 * <tt>oldTrack</tt>
 *
 * @param {JitsiLocalTrack|null} oldTrack - The current track in use to be replaced on the pc.
 * @param {JitsiLocalTrack|null} newTrack - The new track to be used.
 *
 * @returns {Promise<boolean>} - If the promise resolves with true, renegotiation will be needed.
 * Otherwise no renegotiation is needed.
 */
TraceablePeerConnection.prototype.replaceTrack = function (oldTrack, newTrack) {
    if (!(oldTrack || newTrack)) {
        logger.info(`${this} replaceTrack called with no new track and no old track`);
        return Promise.resolve();
    }
    if (this._usesUnifiedPlan) {
        logger.debug(`${this} TPC.replaceTrack using unified plan`);
        return this.tpcUtils.replaceTrack(oldTrack, newTrack)
            .then(transceiver => {
            var _a;
            if (oldTrack) {
                this.localTracks.delete(oldTrack.rtcId);
                this._localTrackTransceiverMids.delete(oldTrack.rtcId);
            }
            if (newTrack) {
                if (newTrack.isAudioTrack()) {
                    this._hasHadAudioTrack = true;
                }
                else {
                    this._hasHadVideoTrack = true;
                }
                this._localTrackTransceiverMids.set(newTrack.rtcId, (_a = transceiver === null || transceiver === void 0 ? void 0 : transceiver.mid) === null || _a === void 0 ? void 0 : _a.toString());
                this.localTracks.set(newTrack.rtcId, newTrack);
            }
            // Update the local SSRC cache for the case when one track gets replaced with another and no
            // renegotiation is triggered as a result of this.
            if (oldTrack && newTrack) {
                const oldTrackSSRC = this.localSSRCs.get(oldTrack.rtcId);
                if (oldTrackSSRC) {
                    this.localSSRCs.delete(oldTrack.rtcId);
                    this.localSSRCs.set(newTrack.rtcId, oldTrackSSRC);
                }
            }
            if (transceiver) {
                // In the scenario where we remove the oldTrack (oldTrack is not null and newTrack is null) on FF
                // if we change the direction to RECVONLY, create answer will generate SDP with only 1 receive
                // only ssrc instead of keeping all 6 ssrcs that we currently have. Stopping the screen sharing
                // and then starting it again will trigger 2 rounds of source-remove and source-add replacing
                // the 6 ssrcs for the screen sharing with 1 receive only ssrc and then removing the receive
                // only ssrc and adding the same 6 ssrcs. On the remote participant's side the same ssrcs will
                // be reused on a new m-line and if the remote participant is FF due to
                // https://bugzilla.mozilla.org/show_bug.cgi?id=1768729 the video stream won't be rendered.
                // That's why we need keep the direction to SENDRECV for FF.
                //
                // NOTE: If we return back to the approach of not removing the track for FF and instead using the
                // enabled property for mute or stopping screensharing we may need to change the direction to
                // RECVONLY if FF still sends the media even though the enabled flag is set to false.
                transceiver.direction
                    = newTrack || _browser__WEBPACK_IMPORTED_MODULE_11__["default"].isFirefox() ? _service_RTC_MediaDirection__WEBPACK_IMPORTED_MODULE_4__.MediaDirection.SENDRECV : _service_RTC_MediaDirection__WEBPACK_IMPORTED_MODULE_4__.MediaDirection.RECVONLY;
            }
            // Avoid configuring the encodings on Chromium/Safari until simulcast is configured
            // for the newly added track using SDP munging which happens during the renegotiation.
            const configureEncodingsPromise = _browser__WEBPACK_IMPORTED_MODULE_11__["default"].usesSdpMungingForSimulcast() || !newTrack
                ? Promise.resolve()
                : this.tpcUtils.setEncodings(newTrack);
            return configureEncodingsPromise.then(() => this.isP2P);
        });
    }
    logger.debug(`${this} TPC.replaceTrack using plan B`);
    let promiseChain = Promise.resolve();
    if (oldTrack) {
        this.removeTrack(oldTrack);
    }
    if (newTrack) {
        promiseChain = this.addTrack(newTrack);
    }
    return promiseChain.then(() => true);
};
/**
 * Removes local track from the RTCPeerConnection.
 *
 * @param {JitsiLocalTrack} localTrack the local track to be removed.
 * @return {Promise<boolean>} Promise that resolves to true if the underlying PeerConnection's state has changed and
 * renegotiation is required, false if no renegotiation is needed or Promise is rejected when something goes wrong.
 */
TraceablePeerConnection.prototype.removeTrackFromPc = function (localTrack) {
    const webRtcStream = localTrack.getOriginalStream();
    this.trace('removeTrack', localTrack.rtcId, webRtcStream ? webRtcStream.id : null);
    if (!this._assertTrackBelongs('removeTrack', localTrack)) {
        // Abort - nothing to be done here
        return Promise.reject('Track not found in the peerconnection');
    }
    if (this._usesUnifiedPlan) {
        return this.tpcUtils.replaceTrack(localTrack, null).then(() => false);
    }
    if (webRtcStream) {
        logger.info(`${this} Removing track=${localTrack} from PC`);
        this._removeStream(webRtcStream);
        return Promise.resolve(true);
    }
    logger.error(`${this} removeTrack - no WebRTC stream for track=${localTrack}`);
    return Promise.reject('Stream not found');
};
TraceablePeerConnection.prototype.createDataChannel = function (label, opts) {
    this.trace('createDataChannel', label, opts);
    return this.peerconnection.createDataChannel(label, opts);
};
/**
 * Ensures that the simulcast ssrc-group appears after any other ssrc-groups
 * in the SDP so that simulcast is properly activated.
 *
 * @param {Object} localSdp the WebRTC session description instance for
 * the local description.
 * @private
 */
TraceablePeerConnection.prototype._ensureSimulcastGroupIsLast = function (localSdp) {
    let sdpStr = localSdp.sdp;
    const videoStartIndex = sdpStr.indexOf('m=video');
    const simStartIndex = sdpStr.indexOf('a=ssrc-group:SIM', videoStartIndex);
    let otherStartIndex = sdpStr.lastIndexOf('a=ssrc-group');
    if (simStartIndex === -1
        || otherStartIndex === -1
        || otherStartIndex === simStartIndex) {
        return localSdp;
    }
    const simEndIndex = sdpStr.indexOf('\r\n', simStartIndex);
    const simStr = sdpStr.substring(simStartIndex, simEndIndex + 2);
    sdpStr = sdpStr.replace(simStr, '');
    otherStartIndex = sdpStr.lastIndexOf('a=ssrc-group');
    const otherEndIndex = sdpStr.indexOf('\r\n', otherStartIndex);
    const sdpHead = sdpStr.slice(0, otherEndIndex);
    const simStrTrimmed = simStr.trim();
    const sdpTail = sdpStr.slice(otherEndIndex);
    sdpStr = `${sdpHead}\r\n${simStrTrimmed}${sdpTail}`;
    return new RTCSessionDescription({
        type: localSdp.type,
        sdp: sdpStr
    });
};
/**
 * Will adjust audio and video media direction in the given SDP object to
 * reflect the current status of the {@link audioTransferActive} and
 * {@link videoTransferActive} flags.
 * @param {RTCSessionDescription} localDescription the WebRTC session description instance for
 * the local description.
 * @private
 */
TraceablePeerConnection.prototype._adjustLocalMediaDirection = function (localDescription) {
    var _a, _b;
    const transformer = new _sdp_SdpTransformUtil__WEBPACK_IMPORTED_MODULE_19__.SdpTransformWrap(localDescription.sdp);
    let modifiedDirection = false;
    const audioMedia = (_a = transformer.selectMedia(_service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_5__.MediaType.AUDIO)) === null || _a === void 0 ? void 0 : _a[0];
    if (audioMedia) {
        const desiredAudioDirection = this.getDesiredMediaDirection(_service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_5__.MediaType.AUDIO);
        if (audioMedia.direction !== desiredAudioDirection) {
            audioMedia.direction = desiredAudioDirection;
            logger.info(`${this} Adjusted local audio direction to ${desiredAudioDirection}`);
            modifiedDirection = true;
        }
    }
    else {
        logger.warn(`${this} No "audio" media found in the local description`);
    }
    const videoMedia = (_b = transformer.selectMedia(_service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_5__.MediaType.VIDEO)) === null || _b === void 0 ? void 0 : _b[0];
    if (videoMedia) {
        const desiredVideoDirection = this.getDesiredMediaDirection(_service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_5__.MediaType.VIDEO);
        if (videoMedia.direction !== desiredVideoDirection) {
            videoMedia.direction = desiredVideoDirection;
            logger.info(`${this} Adjusted local video direction to ${desiredVideoDirection}`);
            modifiedDirection = true;
        }
    }
    else {
        logger.warn(`${this} No "video" media found in the local description`);
    }
    if (modifiedDirection) {
        return new RTCSessionDescription({
            type: localDescription.type,
            sdp: transformer.toRawSDP()
        });
    }
    return localDescription;
};
/**
 * Adjusts the media direction on the remote description based on availability of local and remote sources in a p2p
 * media connection.
 *
 * @param {RTCSessionDescription} remoteDescription the WebRTC session description instance for the remote description.
 * @returns the transformed remoteDescription.
 * @private
 */
TraceablePeerConnection.prototype._adjustRemoteMediaDirection = function (remoteDescription) {
    const transformer = new _sdp_SdpTransformUtil__WEBPACK_IMPORTED_MODULE_19__.SdpTransformWrap(remoteDescription.sdp);
    [_service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_5__.MediaType.AUDIO, _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_5__.MediaType.VIDEO].forEach(mediaType => {
        const media = transformer.selectMedia(mediaType);
        const localSources = this.getLocalTracks(mediaType).length;
        const remoteSources = this.getRemoteTracks(null, mediaType).length;
        media.forEach((mLine, idx) => {
            if (localSources && localSources === remoteSources) {
                mLine.direction = _service_RTC_MediaDirection__WEBPACK_IMPORTED_MODULE_4__.MediaDirection.SENDRECV;
            }
            else if (!localSources && !remoteSources) {
                mLine.direction = _service_RTC_MediaDirection__WEBPACK_IMPORTED_MODULE_4__.MediaDirection.INACTIVE;
            }
            else if (!localSources) {
                mLine.direction = _service_RTC_MediaDirection__WEBPACK_IMPORTED_MODULE_4__.MediaDirection.SENDONLY;
            }
            else if (!remoteSources) {
                mLine.direction = _service_RTC_MediaDirection__WEBPACK_IMPORTED_MODULE_4__.MediaDirection.RECVONLY;
                // When there are 2 local sources and 1 remote source, the first m-line should be set to 'sendrecv' while
                // the second one needs to be set to 'recvonly'.
            }
            else if (localSources > remoteSources) {
                mLine.direction = idx ? _service_RTC_MediaDirection__WEBPACK_IMPORTED_MODULE_4__.MediaDirection.RECVONLY : _service_RTC_MediaDirection__WEBPACK_IMPORTED_MODULE_4__.MediaDirection.SENDRECV;
                // When there are 2 remote sources and 1 local source, the first m-line should be set to 'sendrecv' while
                // the second one needs to be set to 'sendonly'.
            }
            else {
                mLine.direction = idx ? _service_RTC_MediaDirection__WEBPACK_IMPORTED_MODULE_4__.MediaDirection.SENDONLY : _service_RTC_MediaDirection__WEBPACK_IMPORTED_MODULE_4__.MediaDirection.SENDRECV;
            }
        });
    });
    return new RTCSessionDescription({
        type: remoteDescription.type,
        sdp: transformer.toRawSDP()
    });
};
/**
 * Munges the stereo flag as well as the opusMaxAverageBitrate in the SDP, based
 * on values set through config.js, if present.
 *
 * @param {RTCSessionDescription} description that needs to be munged.
 * @returns {RTCSessionDescription} the munged description.
 */
TraceablePeerConnection.prototype._mungeOpus = function (description) {
    const { audioQuality } = this.options;
    if (!(audioQuality === null || audioQuality === void 0 ? void 0 : audioQuality.enableOpusDtx) && !(audioQuality === null || audioQuality === void 0 ? void 0 : audioQuality.stereo) && !(audioQuality === null || audioQuality === void 0 ? void 0 : audioQuality.opusMaxAverageBitrate)) {
        return description;
    }
    const parsedSdp = sdp_transform__WEBPACK_IMPORTED_MODULE_2__.parse(description.sdp);
    const mLines = parsedSdp.media;
    for (const mLine of mLines) {
        if (mLine.type === 'audio') {
            const { payload } = mLine.rtp.find(protocol => protocol.codec === _service_RTC_CodecMimeType__WEBPACK_IMPORTED_MODULE_3__["default"].OPUS);
            if (!payload) {
                // eslint-disable-next-line no-continue
                continue;
            }
            let fmtpOpus = mLine.fmtp.find(protocol => protocol.payload === payload);
            if (!fmtpOpus) {
                fmtpOpus = {
                    payload,
                    config: ''
                };
            }
            const fmtpConfig = sdp_transform__WEBPACK_IMPORTED_MODULE_2__.parseParams(fmtpOpus.config);
            let sdpChanged = false;
            if (audioQuality === null || audioQuality === void 0 ? void 0 : audioQuality.stereo) {
                fmtpConfig.stereo = 1;
                sdpChanged = true;
            }
            if (audioQuality === null || audioQuality === void 0 ? void 0 : audioQuality.opusMaxAverageBitrate) {
                fmtpConfig.maxaveragebitrate = audioQuality.opusMaxAverageBitrate;
                sdpChanged = true;
            }
            // On Firefox, the OpusDtx enablement has no effect
            if (!_browser__WEBPACK_IMPORTED_MODULE_11__["default"].isFirefox() && (audioQuality === null || audioQuality === void 0 ? void 0 : audioQuality.enableOpusDtx)) {
                fmtpConfig.usedtx = 1;
                sdpChanged = true;
            }
            if (!sdpChanged) {
                // eslint-disable-next-line no-continue
                continue;
            }
            let mungedConfig = '';
            for (const key of Object.keys(fmtpConfig)) {
                mungedConfig += `${key}=${fmtpConfig[key]}; `;
            }
            fmtpOpus.config = mungedConfig.trim();
        }
    }
    return new RTCSessionDescription({
        type: description.type,
        sdp: sdp_transform__WEBPACK_IMPORTED_MODULE_2__.write(parsedSdp)
    });
};
/**
 * Munges the SDP to set all directions to inactive and drop all ssrc and ssrc-groups.
 *
 * @param {RTCSessionDescription} description that needs to be munged.
 * @returns {RTCSessionDescription} the munged description.
 */
TraceablePeerConnection.prototype._mungeInactive = function (description) {
    const parsedSdp = sdp_transform__WEBPACK_IMPORTED_MODULE_2__.parse(description.sdp);
    const mLines = parsedSdp.media;
    for (const mLine of mLines) {
        mLine.direction = _service_RTC_MediaDirection__WEBPACK_IMPORTED_MODULE_4__.MediaDirection.INACTIVE;
        mLine.ssrcs = undefined;
        mLine.ssrcGroups = undefined;
    }
    return new RTCSessionDescription({
        type: description.type,
        sdp: sdp_transform__WEBPACK_IMPORTED_MODULE_2__.write(parsedSdp)
    });
};
/**
 * Sets up the _dtlsTransport object and initializes callbacks for it.
 */
TraceablePeerConnection.prototype._initializeDtlsTransport = function () {
    // We are assuming here that we only have one bundled transport here
    if (!this.peerconnection.getSenders || this._dtlsTransport) {
        return;
    }
    const senders = this.peerconnection.getSenders();
    if (senders.length !== 0 && senders[0].transport) {
        this._dtlsTransport = senders[0].transport;
        this._dtlsTransport.onerror = error => {
            logger.error(`${this} DtlsTransport error: ${error}`);
        };
        this._dtlsTransport.onstatechange = () => {
            this.trace('dtlsTransport.onstatechange', this._dtlsTransport.state);
        };
    }
};
/**
 * Sets the max bitrates on the video m-lines when VP9 is the selected codec.
 *
 * @param {RTCSessionDescription} description - The local description that needs to be munged.
 * @param {boolean} isLocalSdp - Whether the max bitrate (via b=AS line in SDP) is set on local SDP.
 * @returns RTCSessionDescription
 */
TraceablePeerConnection.prototype._setVp9MaxBitrates = function (description, isLocalSdp = false) {
    if (!this.codecSettings) {
        return description;
    }
    const parsedSdp = sdp_transform__WEBPACK_IMPORTED_MODULE_2__.parse(description.sdp);
    // Find all the m-lines associated with the local sources.
    const direction = isLocalSdp ? _service_RTC_MediaDirection__WEBPACK_IMPORTED_MODULE_4__.MediaDirection.RECVONLY : _service_RTC_MediaDirection__WEBPACK_IMPORTED_MODULE_4__.MediaDirection.SENDONLY;
    const mLines = parsedSdp.media.filter(m => m.type === _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_5__.MediaType.VIDEO && m.direction !== direction);
    for (const mLine of mLines) {
        if (this.codecSettings.codecList[0] === _service_RTC_CodecMimeType__WEBPACK_IMPORTED_MODULE_3__["default"].VP9) {
            const bitrates = this.tpcUtils.videoBitrates.VP9 || this.tpcUtils.videoBitrates;
            const hdBitrate = bitrates.high ? bitrates.high : _TPCUtils__WEBPACK_IMPORTED_MODULE_23__.HD_BITRATE;
            const ssHdBitrate = bitrates.ssHigh ? bitrates.ssHigh : _TPCUtils__WEBPACK_IMPORTED_MODULE_23__.HD_BITRATE;
            const mid = mLine.mid;
            const isSharingScreen = _flags_FeatureFlags__WEBPACK_IMPORTED_MODULE_12__["default"].isMultiStreamSendSupportEnabled()
                ? mid === this._getDesktopTrackMid()
                : this._isSharingScreen();
            const limit = Math.floor((isSharingScreen ? ssHdBitrate : hdBitrate) / 1000);
            // Use only the HD bitrate for now as there is no API available yet for configuring
            // the bitrates on the individual SVC layers.
            mLine.bandwidth = [{
                    type: 'AS',
                    limit
                }];
        }
        else {
            // Clear the bandwidth limit in SDP when VP9 is no longer the preferred codec.
            // This is needed on react native clients as react-native-webrtc returns the
            // SDP that the application passed instead of returning the SDP off the native side.
            // This line automatically gets cleared on web on every renegotiation.
            mLine.bandwidth = undefined;
        }
    }
    return new RTCSessionDescription({
        type: description.type,
        sdp: sdp_transform__WEBPACK_IMPORTED_MODULE_2__.write(parsedSdp)
    });
};
/**
 * Configures the stream encodings depending on the video type and the bitrates configured.
 *
 * @param {JitsiLocalTrack} - The local track for which the sender encodings have to configured.
 * @returns {Promise} promise that will be resolved when the operation is successful and rejected otherwise.
 */
TraceablePeerConnection.prototype.configureSenderVideoEncodings = function (localVideoTrack = null) {
    // If media is suspended on the peerconnection, make sure that media stays disabled. The default 'active' state for
    // the encodings after the source is added to the peerconnection is 'true', so it needs to be explicitly disabled
    // after the source is added.
    if (!(this.videoTransferActive && this.audioTransferActive)) {
        return this.tpcUtils.setMediaTransferActive(false);
    }
    if (localVideoTrack) {
        return this.setSenderVideoConstraints(this._senderMaxHeights.get(localVideoTrack.getSourceName()), localVideoTrack);
    }
    const promises = [];
    for (const track of this.getLocalVideoTracks()) {
        promises.push(this.setSenderVideoConstraints(this._senderMaxHeights.get(track.getSourceName()), track));
    }
    return Promise.allSettled(promises);
};
TraceablePeerConnection.prototype.setLocalDescription = function (description) {
    let localDescription = description;
    this.trace('setLocalDescription::preTransform', dumpSDP(localDescription));
    // Munge stereo flag and opusMaxAverageBitrate based on config.js
    localDescription = this._mungeOpus(localDescription);
    if (!this._usesUnifiedPlan) {
        localDescription = this._adjustLocalMediaDirection(localDescription);
        localDescription = this._ensureSimulcastGroupIsLast(localDescription);
    }
    // Munge the order of the codecs based on the preferences set through config.js.
    localDescription = this._mungeCodecOrder(localDescription);
    localDescription = this._setVp9MaxBitrates(localDescription, true);
    this.trace('setLocalDescription::postTransform', dumpSDP(localDescription));
    return new Promise((resolve, reject) => {
        this.peerconnection.setLocalDescription(localDescription)
            .then(() => {
            this.trace('setLocalDescriptionOnSuccess');
            const localUfrag = _sdp_SDPUtil__WEBPACK_IMPORTED_MODULE_16__["default"].getUfrag(localDescription.sdp);
            if (localUfrag !== this.localUfrag) {
                this.localUfrag = localUfrag;
                this.eventEmitter.emit(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_6__["default"].LOCAL_UFRAG_CHANGED, this, localUfrag);
            }
            this._initializeDtlsTransport();
            resolve();
        }, err => {
            this.trace('setLocalDescriptionOnFailure', err);
            this.eventEmitter.emit(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_6__["default"].SET_LOCAL_DESCRIPTION_FAILED, err, this);
            reject(err);
        });
    });
};
TraceablePeerConnection.prototype.setRemoteDescription = function (description) {
    let remoteDescription = description;
    this.trace('setRemoteDescription::preTransform', dumpSDP(description));
    // Munge stereo flag and opusMaxAverageBitrate based on config.js
    remoteDescription = this._mungeOpus(remoteDescription);
    if (this._usesUnifiedPlan) {
        // Translate the SDP to Unified plan format first for the jvb case, p2p case will only have 2 m-lines.
        if (!this.isP2P) {
            const currentDescription = this.peerconnection.remoteDescription;
            remoteDescription = this.interop.toUnifiedPlan(remoteDescription, currentDescription);
            this.trace('setRemoteDescription::postTransform (Unified)', dumpSDP(remoteDescription));
        }
        if (this.isSimulcastOn()) {
            remoteDescription = this.tpcUtils.insertUnifiedPlanSimulcastReceive(remoteDescription);
            this.trace('setRemoteDescription::postTransform (sim receive)', dumpSDP(remoteDescription));
        }
        remoteDescription = this.tpcUtils.ensureCorrectOrderOfSsrcs(remoteDescription);
        this.trace('setRemoteDescription::postTransform (correct ssrc order)', dumpSDP(remoteDescription));
    }
    else {
        if (this.isSimulcastOn()) {
            // Implode the simulcast ssrcs so that the remote sdp has only the first ssrc in the SIM group.
            remoteDescription = this.simulcast.mungeRemoteDescription(remoteDescription, true /* add x-google-conference flag */);
            this.trace('setRemoteDescription::postTransform (simulcast)', dumpSDP(remoteDescription));
        }
        remoteDescription = normalizePlanB(remoteDescription);
    }
    // Munge the order of the codecs based on the preferences set through config.js.
    remoteDescription = this._mungeCodecOrder(remoteDescription);
    remoteDescription = this._setVp9MaxBitrates(remoteDescription);
    this.trace('setRemoteDescription::postTransform (munge codec order)', dumpSDP(remoteDescription));
    return new Promise((resolve, reject) => {
        this.peerconnection.setRemoteDescription(remoteDescription)
            .then(() => {
            this.trace('setRemoteDescriptionOnSuccess');
            const remoteUfrag = _sdp_SDPUtil__WEBPACK_IMPORTED_MODULE_16__["default"].getUfrag(remoteDescription.sdp);
            if (remoteUfrag !== this.remoteUfrag) {
                this.remoteUfrag = remoteUfrag;
                this.eventEmitter.emit(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_6__["default"].REMOTE_UFRAG_CHANGED, this, remoteUfrag);
            }
            this._initializeDtlsTransport();
            resolve();
        }, err => {
            this.trace('setRemoteDescriptionOnFailure', err);
            this.eventEmitter.emit(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_6__["default"].SET_REMOTE_DESCRIPTION_FAILED, err, this);
            reject(err);
        });
    });
};
/**
 * Changes the resolution of the video stream that is sent to the peer based on the resolution requested by the peer
 * and user preference, sets the degradation preference on the sender based on the video type, configures the maximum
 * bitrates on the send stream.
 *
 * @param {number} frameHeight - The max frame height to be imposed on the outgoing video stream.
 * @param {JitsiLocalTrack} - The local track for which the sender constraints have to be applied.
 * @returns {Promise} promise that will be resolved when the operation is successful and rejected otherwise.
 */
TraceablePeerConnection.prototype.setSenderVideoConstraints = function (frameHeight, localVideoTrack) {
    var _a, _b;
    if (frameHeight < 0) {
        throw new Error(`Invalid frameHeight: ${frameHeight}`);
    }
    if (!localVideoTrack) {
        throw new Error('Local video track is missing');
    }
    const sourceName = localVideoTrack.getSourceName();
    // Ignore sender constraints if the media on the peerconnection is suspended (jvb conn when p2p is currently active)
    // or if the video track is muted.
    if (!this.videoTransferActive || localVideoTrack.isMuted()) {
        this._senderMaxHeights.set(sourceName, frameHeight);
        return Promise.resolve();
    }
    const configuredResolution = this.tpcUtils.getConfiguredEncodeResolution(localVideoTrack);
    // Ignore sender constraints if the client is already sending video of the requested resolution. Note that for
    // screensharing sources, the max resolution will be the height of the window being captured irrespective of the
    // height being requested by the peer.
    if ((localVideoTrack.getVideoType() === _service_RTC_VideoType__WEBPACK_IMPORTED_MODULE_9__.VideoType.CAMERA && configuredResolution === frameHeight)
        || (localVideoTrack.getVideoType() === _service_RTC_VideoType__WEBPACK_IMPORTED_MODULE_9__.VideoType.DESKTOP
            && frameHeight > 0
            && configuredResolution === ((_b = (_a = localVideoTrack.getTrack()) === null || _a === void 0 ? void 0 : _a.getSettings()) === null || _b === void 0 ? void 0 : _b.height))) {
        return Promise.resolve();
    }
    this._senderMaxHeights.set(sourceName, frameHeight);
    return this._updateVideoSenderParameters(this._updateVideoSenderEncodings(frameHeight, localVideoTrack));
};
/**
 * Returns a wrapped-up promise so that the setParameters() call on the RTCRtpSender for video sources are chained.
 * This is needed on Chrome as it resets the transaction id after executing setParameters() and can affect the next on
 * the fly updates if they are not chained.
 * https://chromium.googlesource.com/external/webrtc/+/master/pc/rtp_sender.cc#340
 * @param {Promise} promise - The promise that needs to be chained.
 * @returns {Promise}
 */
TraceablePeerConnection.prototype._updateVideoSenderParameters = function (promise) {
    const nextPromise = this._lastVideoSenderUpdatePromise
        .finally(() => promise);
    this._lastVideoSenderUpdatePromise = nextPromise;
    return nextPromise;
};
/**
 * Configures the video stream with resolution / degradation / maximum bitrates
 *
 * @param {number} frameHeight - The max frame height to be imposed on the outgoing video stream.
 * @param {JitsiLocalTrack} - The local track for which the sender constraints have to be applied.
 * @returns {Promise} promise that will be resolved when the operation is successful and rejected otherwise.
 */
TraceablePeerConnection.prototype._updateVideoSenderEncodings = function (frameHeight, localVideoTrack) {
    var _a, _b, _c, _d, _e, _f, _g, _h;
    const videoSender = this.findSenderForTrack(localVideoTrack.getTrack());
    if (!videoSender) {
        return Promise.resolve();
    }
    const parameters = videoSender.getParameters();
    if (!((_a = parameters === null || parameters === void 0 ? void 0 : parameters.encodings) === null || _a === void 0 ? void 0 : _a.length)) {
        return Promise.resolve();
    }
    const isSharingLowFpsScreen = localVideoTrack.getVideoType() === _service_RTC_VideoType__WEBPACK_IMPORTED_MODULE_9__.VideoType.DESKTOP && this._capScreenshareBitrate;
    // Set the degradation preference.
    const preference = isSharingLowFpsScreen
        ? DEGRADATION_PREFERENCE_DESKTOP // Prefer resolution for low fps share.
        : DEGRADATION_PREFERENCE_CAMERA; // Prefer frame-rate for high fps share and camera.
    parameters.degradationPreference = preference;
    logger.info(`${this} Setting degradation preference [preference=${preference},track=${localVideoTrack}`);
    // Calculate the encodings active state based on the resolution requested by the bridge.
    this.encodingsEnabledState = this.tpcUtils.calculateEncodingsActiveState(localVideoTrack, frameHeight);
    const maxBitrates = this.tpcUtils.calculateEncodingsBitrates(localVideoTrack);
    const videoType = localVideoTrack.getVideoType();
    if (this.isSimulcastOn()) {
        for (const encoding in parameters.encodings) {
            if (parameters.encodings.hasOwnProperty(encoding)) {
                parameters.encodings[encoding].active = this.encodingsEnabledState[encoding];
                // Firefox doesn't follow the spec and lets application specify the degradation preference on the
                // encodings.
                _browser__WEBPACK_IMPORTED_MODULE_11__["default"].isFirefox() && (parameters.encodings[encoding].degradationPreference = preference);
                if (this.getConfiguredVideoCodec() === _service_RTC_CodecMimeType__WEBPACK_IMPORTED_MODULE_3__["default"].VP8
                    && (((_c = (_b = this.options) === null || _b === void 0 ? void 0 : _b.videoQuality) === null || _c === void 0 ? void 0 : _c.maxBitratesVideo)
                        || isSharingLowFpsScreen
                        || this._usesUnifiedPlan)) {
                    parameters.encodings[encoding].maxBitrate = maxBitrates[encoding];
                }
            }
        }
        this.tpcUtils.updateEncodingsResolution(localVideoTrack, parameters);
        // For p2p and cases and where simulcast is explicitly disabled.
    }
    else if (frameHeight > 0) {
        let scaleFactor = _TPCUtils__WEBPACK_IMPORTED_MODULE_23__.HD_SCALE_FACTOR;
        // Do not scale down encodings for desktop tracks for non-simulcast case.
        if (videoType === _service_RTC_VideoType__WEBPACK_IMPORTED_MODULE_9__.VideoType.CAMERA && localVideoTrack.resolution > frameHeight) {
            scaleFactor = Math.floor(localVideoTrack.resolution / frameHeight);
        }
        parameters.encodings[0].active = true;
        parameters.encodings[0].scaleResolutionDownBy = scaleFactor;
        // Firefox doesn't follow the spec and lets application specify the degradation preference on the encodings.
        _browser__WEBPACK_IMPORTED_MODULE_11__["default"].isFirefox() && (parameters.encodings[0].degradationPreference = preference);
        // Configure the bitrate.
        if (this.getConfiguredVideoCodec() === _service_RTC_CodecMimeType__WEBPACK_IMPORTED_MODULE_3__["default"].VP8 && ((_e = (_d = this.options) === null || _d === void 0 ? void 0 : _d.videoQuality) === null || _e === void 0 ? void 0 : _e.maxBitratesVideo)) {
            let bitrate = (_f = this.getTargetVideoBitrates()) === null || _f === void 0 ? void 0 : _f.high;
            if (videoType === _service_RTC_VideoType__WEBPACK_IMPORTED_MODULE_9__.VideoType.CAMERA) {
                bitrate = (_h = (_g = this.tpcUtils._getVideoStreamEncodings(localVideoTrack.getVideoType())
                    .find(layer => layer.scaleResolutionDownBy === scaleFactor)) === null || _g === void 0 ? void 0 : _g.maxBitrate) !== null && _h !== void 0 ? _h : bitrate;
            }
            parameters.encodings[0].maxBitrate = bitrate;
        }
        else {
            parameters.encodings[0].maxBitrate = undefined;
        }
    }
    else {
        parameters.encodings[0].active = false;
    }
    logger.info(`${this} setting max height=${frameHeight},encodings=${JSON.stringify(parameters.encodings)}`);
    return videoSender.setParameters(parameters).then(() => {
        localVideoTrack.maxEnabledResolution = frameHeight;
        this.eventEmitter.emit(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_6__["default"].LOCAL_TRACK_MAX_ENABLED_RESOLUTION_CHANGED, localVideoTrack);
    });
};
/**
 * Enables/disables video media transmission on this peer connection. When
 * disabled the SDP video media direction in the local SDP will be adjusted to
 * 'inactive' which means that no data will be sent nor accepted, but
 * the connection should be kept alive.
 * @param {boolean} active <tt>true</tt> to enable video media transmission or
 * <tt>false</tt> to disable. If the value is not a boolean the call will have
 * no effect.
 * @return {boolean} <tt>true</tt> if the value has changed and sRD/sLD cycle
 * needs to be executed in order for the changes to take effect or
 * <tt>false</tt> if the given value was the same as the previous one.
 * @public
 */
TraceablePeerConnection.prototype.setVideoTransferActive = function (active) {
    logger.debug(`${this} video transfer active: ${active}`);
    const changed = this.videoTransferActive !== active;
    this.videoTransferActive = active;
    if (this._usesUnifiedPlan) {
        this.tpcUtils.setVideoTransferActive(active);
        // false means no renegotiation up the chain which is not needed in the Unified mode
        return false;
    }
    return changed;
};
/**
 * Sends DTMF tones if possible.
 *
 * @param {string} tones - The DTMF tones string as defined by {@code RTCDTMFSender.insertDTMF}, 'tones' argument.
 * @param {number} duration - The amount of time in milliseconds that each DTMF should last. It's 200ms by default.
 * @param {number} interToneGap - The length of time in miliseconds to wait between tones. It's 200ms by default.
 *
 * @returns {void}
 */
TraceablePeerConnection.prototype.sendTones = function (tones, duration = 200, interToneGap = 200) {
    if (!this._dtmfSender) {
        if (this.peerconnection.getSenders) {
            const rtpSender = this.peerconnection.getSenders().find(s => s.dtmf);
            this._dtmfSender = rtpSender && rtpSender.dtmf;
            this._dtmfSender && logger.info(`${this} initialized DTMFSender using getSenders`);
        }
        if (!this._dtmfSender) {
            const localAudioTrack = Array.from(this.localTracks.values()).find(t => t.isAudioTrack());
            if (this.peerconnection.createDTMFSender && localAudioTrack) {
                this._dtmfSender = this.peerconnection.createDTMFSender(localAudioTrack.getTrack());
            }
            this._dtmfSender && logger.info(`${this} initialized DTMFSender using deprecated createDTMFSender`);
        }
        if (this._dtmfSender) {
            this._dtmfSender.ontonechange = this._onToneChange.bind(this);
        }
    }
    if (this._dtmfSender) {
        if (this._dtmfSender.toneBuffer) {
            this._dtmfTonesQueue.push({
                tones,
                duration,
                interToneGap
            });
            return;
        }
        this._dtmfSender.insertDTMF(tones, duration, interToneGap);
    }
    else {
        logger.warn(`${this} sendTones - failed to select DTMFSender`);
    }
};
/**
 * Callback ivoked by {@code this._dtmfSender} when it has finished playing
 * a single tone.
 *
 * @param {Object} event - The tonechange event which indicates what characters
 * are left to be played for the current tone.
 * @private
 * @returns {void}
 */
TraceablePeerConnection.prototype._onToneChange = function (event) {
    // An empty event.tone indicates the current tones have finished playing.
    // Automatically start playing any queued tones on finish.
    if (this._dtmfSender && event.tone === '' && this._dtmfTonesQueue.length) {
        const { tones, duration, interToneGap } = this._dtmfTonesQueue.shift();
        this._dtmfSender.insertDTMF(tones, duration, interToneGap);
    }
};
/**
 * Makes the underlying TraceablePeerConnection generate new SSRC for
 * the recvonly video stream.
 */
TraceablePeerConnection.prototype.generateRecvonlySsrc = function () {
    const newSSRC = _sdp_SDPUtil__WEBPACK_IMPORTED_MODULE_16__["default"].generateSsrc();
    logger.info(`${this} generated new recvonly SSRC=${newSSRC}`);
    this.sdpConsistency.setPrimarySsrc(newSSRC);
};
/**
 * Makes the underlying TraceablePeerConnection forget the current primary video
 * SSRC.
 */
TraceablePeerConnection.prototype.clearRecvonlySsrc = function () {
    logger.info(`${this} Clearing primary video SSRC!`);
    this.sdpConsistency.clearVideoSsrcCache();
};
/**
 * Closes underlying WebRTC PeerConnection instance and removes all remote
 * tracks by emitting {@link RTCEvents.REMOTE_TRACK_REMOVED} for each one of
 * them.
 */
TraceablePeerConnection.prototype.close = function () {
    this.trace('stop');
    // Off SignalingEvents
    this.signalingLayer.off(_service_RTC_SignalingEvents__WEBPACK_IMPORTED_MODULE_7__.PEER_MUTED_CHANGED, this._peerMutedChanged);
    this.signalingLayer.off(_service_RTC_SignalingEvents__WEBPACK_IMPORTED_MODULE_7__.PEER_VIDEO_TYPE_CHANGED, this._peerVideoTypeChanged);
    this._usesUnifiedPlan && this.peerconnection.removeEventListener('track', this.onTrack);
    for (const peerTracks of this.remoteTracks.values()) {
        for (const remoteTracks of peerTracks.values()) {
            for (const remoteTrack of remoteTracks) {
                this._removeRemoteTrack(remoteTrack);
            }
        }
    }
    this.remoteTracks.clear();
    this._addedStreams = [];
    this._dtmfSender = null;
    this._dtmfTonesQueue = [];
    if (!this.rtc._removePeerConnection(this)) {
        logger.error(`${this} RTC._removePeerConnection returned false`);
    }
    if (this.statsinterval !== null) {
        window.clearInterval(this.statsinterval);
        this.statsinterval = null;
    }
    logger.info(`${this} Closing peerconnection`);
    this.peerconnection.close();
};
TraceablePeerConnection.prototype.createAnswer = function (constraints) {
    return this._createOfferOrAnswer(false /* answer */, constraints);
};
TraceablePeerConnection.prototype.createOffer = function (constraints) {
    return this._createOfferOrAnswer(true /* offer */, constraints);
};
TraceablePeerConnection.prototype._createOfferOrAnswer = function (isOffer, constraints) {
    var _a;
    const logName = isOffer ? 'Offer' : 'Answer';
    this.trace(`create${logName}`, JSON.stringify(constraints, null, ' '));
    const handleSuccess = (resultSdp, resolveFn, rejectFn) => {
        try {
            this.trace(`create${logName}OnSuccess::preTransform`, dumpSDP(resultSdp));
            if (!this._usesUnifiedPlan) {
                // If there are no local video tracks, then a "recvonly"
                // SSRC needs to be generated
                if (!this.hasAnyTracksOfType(_service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_5__.MediaType.VIDEO)
                    && !this.sdpConsistency.hasPrimarySsrcCached()) {
                    this.generateRecvonlySsrc();
                }
                // eslint-disable-next-line no-param-reassign
                resultSdp = new RTCSessionDescription({
                    type: resultSdp.type,
                    sdp: this.sdpConsistency.makeVideoPrimarySsrcsConsistent(resultSdp.sdp)
                });
                this.trace(`create${logName}OnSuccess::postTransform `
                    + '(make primary audio/video ssrcs consistent)', dumpSDP(resultSdp));
            }
            const localVideoTrack = this.getLocalVideoTracks()[0];
            // Configure simulcast for camera tracks and for desktop tracks that need simulcast.
            if (this.isSimulcastOn() && _browser__WEBPACK_IMPORTED_MODULE_11__["default"].usesSdpMungingForSimulcast()
                && ((localVideoTrack === null || localVideoTrack === void 0 ? void 0 : localVideoTrack.getVideoType()) === _service_RTC_VideoType__WEBPACK_IMPORTED_MODULE_9__.VideoType.CAMERA
                    || this._usesUnifiedPlan)) {
                // eslint-disable-next-line no-param-reassign
                resultSdp = this.simulcast.mungeLocalDescription(resultSdp);
                this.trace(`create${logName} OnSuccess::postTransform (simulcast)`, dumpSDP(resultSdp));
            }
            if (!this.options.disableRtx && _browser__WEBPACK_IMPORTED_MODULE_11__["default"].usesSdpMungingForSimulcast()) {
                // eslint-disable-next-line no-param-reassign
                resultSdp = new RTCSessionDescription({
                    type: resultSdp.type,
                    sdp: this.rtxModifier.modifyRtxSsrcs(resultSdp.sdp)
                });
                this.trace(`create${logName}`
                    + 'OnSuccess::postTransform (rtx modifier)', dumpSDP(resultSdp));
            }
            const ssrcMap = this._extractSSRCMap(resultSdp);
            this._processLocalSSRCsMap(ssrcMap);
            resolveFn(resultSdp);
        }
        catch (e) {
            this.trace(`create${logName}OnError`, e);
            this.trace(`create${logName}OnError`, dumpSDP(resultSdp));
            logger.error(`${this} create${logName}OnError`, e, dumpSDP(resultSdp));
            rejectFn(e);
        }
    };
    const handleFailure = (err, rejectFn) => {
        this.trace(`create${logName}OnFailure`, err);
        const eventType = isOffer
            ? _service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_6__["default"].CREATE_OFFER_FAILED
            : _service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_6__["default"].CREATE_ANSWER_FAILED;
        this.eventEmitter.emit(eventType, err, this);
        rejectFn(err);
    };
    // Set the codec preference before creating an offer or answer so that the generated SDP will have
    // the correct preference order.
    if (this._usesTransceiverCodecPreferences && this.codecSettings) {
        const { codecList, mediaType } = this.codecSettings;
        const transceivers = this.peerconnection.getTransceivers()
            .filter(t => { var _a, _b; return t.receiver && ((_b = (_a = t.receiver) === null || _a === void 0 ? void 0 : _a.track) === null || _b === void 0 ? void 0 : _b.kind) === mediaType; });
        let capabilities = (_a = RTCRtpReceiver.getCapabilities(mediaType)) === null || _a === void 0 ? void 0 : _a.codecs;
        if (transceivers.length && capabilities) {
            // Remove codecs that are not in the preferred list.
            capabilities = capabilities
                .filter(caps => codecList.find(codec => `${mediaType}/${codec}` === caps.mimeType.toLowerCase()));
            // Rearrange the codec list as per the preference order.
            for (const codec of codecList.slice().reverse()) {
                // Move the desired codecs (all variations of it as well) to the beginning of the list
                /* eslint-disable-next-line arrow-body-style */
                capabilities.sort(caps => {
                    return caps.mimeType.toLowerCase() === `${mediaType}/${codec}` ? -1 : 1;
                });
            }
            // Disable ulpfec on Google Chrome and derivatives because
            // https://bugs.chromium.org/p/chromium/issues/detail?id=1276427
            if (_browser__WEBPACK_IMPORTED_MODULE_11__["default"].isChromiumBased() && mediaType === _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_5__.MediaType.VIDEO) {
                capabilities = capabilities
                    .filter(caps => caps.mimeType.toLowerCase() !== `${_service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_5__.MediaType.VIDEO}/${_service_RTC_CodecMimeType__WEBPACK_IMPORTED_MODULE_3__["default"].ULPFEC}`);
            }
            // Apply codec preference to all the transceivers associated with the given media type.
            for (const transceiver of transceivers) {
                transceiver.setCodecPreferences(capabilities);
            }
        }
    }
    return new Promise((resolve, reject) => {
        let oaPromise;
        if (isOffer) {
            oaPromise = this.peerconnection.createOffer(constraints);
        }
        else {
            oaPromise = this.peerconnection.createAnswer(constraints);
        }
        oaPromise
            .then(sdp => handleSuccess(sdp, resolve, reject), error => handleFailure(error, reject));
    });
};
/**
 * Extract primary SSRC from given {@link TrackSSRCInfo} object.
 * @param {TrackSSRCInfo} ssrcObj
 * @return {number|null} the primary SSRC or <tt>null</tt>
 */
TraceablePeerConnection.prototype._extractPrimarySSRC = function (ssrcObj) {
    if (ssrcObj && ssrcObj.groups && ssrcObj.groups.length) {
        return ssrcObj.groups[0].ssrcs[0];
    }
    else if (ssrcObj && ssrcObj.ssrcs && ssrcObj.ssrcs.length) {
        return ssrcObj.ssrcs[0];
    }
    return null;
};
/**
 * Goes over the SSRC map extracted from the latest local description and tries
 * to match them with the local tracks (by MSID). Will update the values
 * currently stored in the {@link TraceablePeerConnection.localSSRCs} map.
 * @param {Map<string,TrackSSRCInfo>} ssrcMap
 * @private
 */
TraceablePeerConnection.prototype._processLocalSSRCsMap = function (ssrcMap) {
    for (const track of this.localTracks.values()) {
        const sourceName = track.getSourceName();
        const sourceIndex = (0,_service_RTC_SignalingLayer__WEBPACK_IMPORTED_MODULE_8__.getSourceIndexFromSourceName)(sourceName);
        const sourceIdentifier = this._usesUnifiedPlan
            ? `${track.getType()}-${sourceIndex}`
            : track.storedMSID;
        if (ssrcMap.has(sourceIdentifier)) {
            const newSSRC = ssrcMap.get(sourceIdentifier);
            if (!newSSRC) {
                logger.error(`${this} No SSRC found for stream=${sourceIdentifier}`);
                return;
            }
            const oldSSRC = this.localSSRCs.get(track.rtcId);
            const newSSRCNum = this._extractPrimarySSRC(newSSRC);
            const oldSSRCNum = this._extractPrimarySSRC(oldSSRC);
            // eslint-disable-next-line no-negated-condition
            if (newSSRCNum !== oldSSRCNum) {
                oldSSRCNum && logger.error(`${this} Overwriting SSRC for track=${track}] with ssrc=${newSSRC}`);
                this.localSSRCs.set(track.rtcId, newSSRC);
                this.eventEmitter.emit(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_6__["default"].LOCAL_TRACK_SSRC_UPDATED, track, newSSRCNum);
            }
        }
        else if (!track.isVideoTrack() && !track.isMuted()) {
            // It is normal to find no SSRCs for a muted video track in
            // the local SDP as the recv-only SSRC is no longer munged in.
            // So log the warning only if it's not a muted video track.
            logger.warn(`${this} No SSRCs found in the local SDP for track=${track}, stream=${sourceIdentifier}`);
        }
    }
};
/**
 * Track the SSRCs seen so far.
 * @param {number} ssrc - SSRC.
 * @return {boolean} - Whether this is a new SSRC.
 */
TraceablePeerConnection.prototype.addRemoteSsrc = function (ssrc) {
    const existing = this.remoteSSRCs.has(ssrc);
    if (!existing) {
        this.remoteSSRCs.add(ssrc);
    }
    return !existing;
};
TraceablePeerConnection.prototype.addIceCandidate = function (candidate) {
    this.trace('addIceCandidate', JSON.stringify({
        candidate: candidate.candidate,
        sdpMid: candidate.sdpMid,
        sdpMLineIndex: candidate.sdpMLineIndex,
        usernameFragment: candidate.usernameFragment
    }, null, ' '));
    return this.peerconnection.addIceCandidate(candidate);
};
/**
 * Returns the number of simulcast streams that are currently enabled on the peerconnection.
 *
 * @returns {number} The number of simulcast streams currently enabled or 1 when simulcast is disabled.
 */
TraceablePeerConnection.prototype.getActiveSimulcastStreams = function () {
    var _a;
    let activeStreams = 1;
    if (this.isSimulcastOn() && this.encodingsEnabledState) {
        activeStreams = (_a = this.encodingsEnabledState.filter(stream => Boolean(stream))) === null || _a === void 0 ? void 0 : _a.length;
    }
    else if (this.isSimulcastOn()) {
        activeStreams = _TPCUtils__WEBPACK_IMPORTED_MODULE_23__.SIM_LAYER_RIDS.length;
    }
    return activeStreams;
};
/**
 * Obtains call-related stats from the peer connection.
 *
 * @returns {Promise<Object>} Promise which resolves with data providing statistics about
 * the peerconnection.
 */
TraceablePeerConnection.prototype.getStats = function () {
    return this.peerconnection.getStats();
};
/**
 * Generates and stores new SSRC info object for given local track.
 * The method should be called only for a video track being added to this TPC
 * in the muted state (given that the current browser uses this strategy).
 * @param {JitsiLocalTrack} track
 * @return {TPCSSRCInfo}
 */
TraceablePeerConnection.prototype.generateNewStreamSSRCInfo = function (track) {
    const rtcId = track.rtcId;
    let ssrcInfo = this._getSSRC(rtcId);
    if (ssrcInfo) {
        logger.error(`${this} Overwriting local SSRCs for track id=${rtcId}`);
    }
    // Configure simulcast for camera tracks and desktop tracks that need simulcast.
    if (this.isSimulcastOn()
        && (track.getVideoType() === _service_RTC_VideoType__WEBPACK_IMPORTED_MODULE_9__.VideoType.CAMERA || !this.isSharingLowFpsScreen())) {
        ssrcInfo = {
            ssrcs: [],
            groups: []
        };
        for (let i = 0; i < _TPCUtils__WEBPACK_IMPORTED_MODULE_23__.SIM_LAYER_RIDS.length; i++) {
            ssrcInfo.ssrcs.push(_sdp_SDPUtil__WEBPACK_IMPORTED_MODULE_16__["default"].generateSsrc());
        }
        ssrcInfo.groups.push({
            ssrcs: ssrcInfo.ssrcs.slice(),
            semantics: 'SIM'
        });
    }
    else {
        ssrcInfo = {
            ssrcs: [_sdp_SDPUtil__WEBPACK_IMPORTED_MODULE_16__["default"].generateSsrc()],
            groups: []
        };
    }
    if (!this.options.disableRtx) {
        // Specifically use a for loop here because we'll
        //  be adding to the list we're iterating over, so we
        //  only want to iterate through the items originally
        //  on the list
        const currNumSsrcs = ssrcInfo.ssrcs.length;
        for (let i = 0; i < currNumSsrcs; ++i) {
            const primarySsrc = ssrcInfo.ssrcs[i];
            const rtxSsrc = _sdp_SDPUtil__WEBPACK_IMPORTED_MODULE_16__["default"].generateSsrc();
            ssrcInfo.ssrcs.push(rtxSsrc);
            ssrcInfo.groups.push({
                ssrcs: [primarySsrc, rtxSsrc],
                semantics: 'FID'
            });
        }
    }
    ssrcInfo.msid = track.storedMSID;
    this.localSSRCs.set(rtcId, ssrcInfo);
    return ssrcInfo;
};
/**
 * Returns if the peer connection uses Unified plan implementation.
 *
 * @returns {boolean} True if the pc uses Unified plan, false otherwise.
 */
TraceablePeerConnection.prototype.usesUnifiedPlan = function () {
    return this._usesUnifiedPlan;
};
/**
 * Creates a text representation of this <tt>TraceablePeerConnection</tt>
 * instance.
 * @return {string}
 */
TraceablePeerConnection.prototype.toString = function () {
    return `TPC[id=${this.id},type=${this.isP2P ? 'P2P' : 'JVB'}]`;
};
//# sourceMappingURL=TraceablePeerConnection.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/browser/BrowserCapabilities.js":
/*!********************************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/browser/BrowserCapabilities.js ***!
  \********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (/* binding */ BrowserCapabilities)
/* harmony export */ });
/* harmony import */ var _jitsi_js_utils__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @jitsi/js-utils */ "./node_modules/@jitsi/js-utils/index.js");

/* Minimum required Chrome / Chromium version. This applies also to derivatives. */
const MIN_REQUIRED_CHROME_VERSION = 72;
const MIN_REQUIRED_SAFARI_VERSION = 14;
const MIN_REQUIRED_IOS_VERSION = 14;
// TODO: Move this code to js-utils.
// NOTE: Now we are extending BrowserDetection in order to preserve
// RTCBrowserType interface but maybe it worth exporting BrowserCapabilities
// and BrowserDetection as separate objects in future.
/**
 * Implements browser capabilities for lib-jitsi-meet.
 */
class BrowserCapabilities extends _jitsi_js_utils__WEBPACK_IMPORTED_MODULE_0__.BrowserDetection {
    /**
     * Tells whether or not the <tt>MediaStream/tt> is removed from the <tt>PeerConnection</tt> and disposed on video
     * mute (in order to turn off the camera device). This is needed on Firefox because of the following bug
     * https://bugzilla.mozilla.org/show_bug.cgi?id=1735951
     *
     * @return {boolean} <tt>true</tt> if the current browser supports this strategy or <tt>false</tt> otherwise.
     */
    doesVideoMuteByStreamRemove() {
        return this.isChromiumBased() || this.isWebKitBased() || this.isFirefox();
    }
    /**
     * Checks if the client is running on an Android browser.
     *
     * @returns {boolean}
     */
    isAndroidBrowser() {
        const { userAgent } = navigator;
        return !this.isReactNative() && userAgent.match(/Android/i);
    }
    /**
     * Checks if the current browser is Chromium based, i.e., it's either Chrome / Chromium or uses it as its engine,
     * but doesn't identify as Chrome.
     *
     * This includes the following browsers:
     * - Chrome and Chromium.
     * - Other browsers which use the Chrome engine, but are detected as Chrome, such as Brave and Vivaldi.
     * - Browsers which are NOT Chrome but use it as their engine, and have custom detection code: Opera, Electron
     *   and NW.JS.
     * This excludes
     * - Chrome on iOS since it uses WKWebView.
     */
    isChromiumBased() {
        return (this.isChrome()
            || this.isElectron()
            || this.isNWJS()
            || this.isOpera())
            && !this.isWebKitBased();
    }
    /**
     * Checks if the current platform is iOS.
     *
     * @returns {boolean}
     */
    isIosBrowser() {
        const { userAgent, maxTouchPoints, platform } = navigator;
        return Boolean(userAgent.match(/iP(ad|hone|od)/i))
            || (maxTouchPoints && maxTouchPoints > 2 && /MacIntel/.test(platform));
    }
    /**
     * Checks if the client is running on a mobile device.
     */
    isMobileDevice() {
        return this.isAndroidBrowser() || this.isIosBrowser() || this.isReactNative();
    }
    /**
     * Checks if the current browser is WebKit based. It's either
     * Safari or uses WebKit as its engine.
     *
     * This includes Chrome and Firefox on iOS
     *
     * @returns {boolean}
     */
    isWebKitBased() {
        // https://trac.webkit.org/changeset/236144/webkit/trunk/LayoutTests/webrtc/video-addLegacyTransceiver.html
        return this._bowser.isEngine('webkit')
            && typeof navigator.mediaDevices !== 'undefined'
            && typeof navigator.mediaDevices.getUserMedia !== 'undefined'
            && typeof window.RTCRtpTransceiver !== 'undefined'
            // eslint-disable-next-line no-undef
            && Object.keys(RTCRtpTransceiver.prototype).indexOf('currentDirection') > -1;
    }
    /**
     * Checks whether current running context is a Trusted Web Application.
     *
     * @returns {boolean} Whether the current context is a TWA.
     */
    isTwa() {
        return 'matchMedia' in window && window.matchMedia('(display-mode:standalone)').matches;
    }
    /**
     * Checks if the current browser is supported.
     *
     * @returns {boolean} true if the browser is supported, false otherwise.
     */
    isSupported() {
        if (this.isSafari() && this._getSafariVersion() < MIN_REQUIRED_SAFARI_VERSION) {
            return false;
        }
        return (this.isChromiumBased() && this._getChromiumBasedVersion() >= MIN_REQUIRED_CHROME_VERSION)
            || this.isFirefox()
            || this.isReactNative()
            || this.isWebKitBased();
    }
    /**
     * Returns whether the browser is supported for Android
     * @returns {boolean} true if the browser is supported for Android devices
     */
    isSupportedAndroidBrowser() {
        return this.isChromiumBased() || this.isFirefox();
    }
    /**
     * Returns whether the browser is supported for iOS
     * @returns {boolean} true if the browser is supported for iOS devices
     */
    isSupportedIOSBrowser() {
        return this._getIOSVersion() >= MIN_REQUIRED_IOS_VERSION;
    }
    /**
     * Returns whether or not the current environment needs a user interaction
     * with the page before any unmute can occur.
     *
     * @returns {boolean}
     */
    isUserInteractionRequiredForUnmute() {
        return this.isFirefox() && this.isVersionLessThan('68');
    }
    /**
     * Checks if the current browser triggers 'onmute'/'onunmute' events when
     * user's connection is interrupted and the video stops playback.
     * @returns {*|boolean} 'true' if the event is supported or 'false'
     * otherwise.
     */
    supportsVideoMuteOnConnInterrupted() {
        return this.isChromiumBased() || this.isReactNative();
    }
    /**
     * Checks if the current browser reports upload and download bandwidth
     * statistics.
     * @return {boolean}
     */
    supportsBandwidthStatistics() {
        // FIXME bandwidth stats are currently not implemented for FF on our
        // side, but not sure if not possible ?
        return !this.isFirefox() && !this.isWebKitBased();
    }
    /**
     * Checks if the current browser supports setting codec preferences on the transceiver.
     * @returns {boolean}
     */
    supportsCodecPreferences() {
        return Boolean(window.RTCRtpTransceiver
            && 'setCodecPreferences' in window.RTCRtpTransceiver.prototype
            && window.RTCRtpReceiver
            && typeof window.RTCRtpReceiver.getCapabilities !== 'undefined')
            // this is not working on Safari because of the following bug
            // https://bugs.webkit.org/show_bug.cgi?id=215567
            && !this.isWebKitBased();
    }
    /**
     * Checks if the current browser support the device change event.
     * @return {boolean}
     */
    supportsDeviceChangeEvent() {
        return navigator.mediaDevices
            && typeof navigator.mediaDevices.ondevicechange !== 'undefined'
            && typeof navigator.mediaDevices.addEventListener !== 'undefined';
    }
    /**
     * Checks if the current browser supports the Long Tasks API that lets us observe
     * performance measurement events and be notified of tasks that take longer than
     * 50ms to execute on the main thread.
     */
    supportsPerformanceObserver() {
        return typeof window.PerformanceObserver !== 'undefined'
            && PerformanceObserver.supportedEntryTypes.indexOf('longtask') > -1;
    }
    /**
     * Checks if the current browser supports audio level stats on the receivers.
     */
    supportsReceiverStats() {
        return typeof window.RTCRtpReceiver !== 'undefined'
            && Object.keys(RTCRtpReceiver.prototype).indexOf('getSynchronizationSources') > -1;
    }
    /**
     * Checks if the current browser reports round trip time statistics for
     * the ICE candidate pair.
     * @return {boolean}
     */
    supportsRTTStatistics() {
        // Firefox does not seem to report RTT for ICE candidate pair:
        // eslint-disable-next-line max-len
        // https://www.w3.org/TR/webrtc-stats/#dom-rtcicecandidatepairstats-currentroundtriptime
        // It does report mozRTT for RTP streams, but at the time of this
        // writing it's value does not make sense most of the time
        // (is reported as 1):
        // https://bugzilla.mozilla.org/show_bug.cgi?id=1241066
        // For Chrome and others we rely on 'googRtt'.
        return !this.isFirefox();
    }
    /**
     * Returns true if the browser supports track based statistics for the local video track. Otherwise,
     * track resolution and framerate will be calculated based on the 'outbound-rtp' statistics.
     * @returns {boolean}
     */
    supportsTrackBasedStats() {
        return this.isChromiumBased() && this.isVersionLessThan(112);
    }
    /**
     * Returns true if VP9 is supported by the client on the browser. VP9 is currently disabled on Firefox and Safari
     * because of issues with rendering. Please check https://bugzilla.mozilla.org/show_bug.cgi?id=1492500,
     * https://bugs.webkit.org/show_bug.cgi?id=231071 and https://bugs.webkit.org/show_bug.cgi?id=231074 for details.
     */
    supportsVP9() {
        return this.isChromiumBased() || this.isReactNative();
    }
    /**
     * Checks if the browser uses SDP munging for turning on simulcast.
     *
     * @returns {boolean}
     */
    usesSdpMungingForSimulcast() {
        return this.isChromiumBased() || this.isReactNative() || this.isWebKitBased();
    }
    /**
     * Checks if the browser uses RIDs/MIDs for siganling the simulcast streams
     * to the bridge instead of the ssrcs.
     */
    usesRidsForSimulcast() {
        return false;
    }
    /**
     * Checks if the browser supports getDisplayMedia.
     * @returns {boolean} {@code true} if the browser supports getDisplayMedia.
     */
    supportsGetDisplayMedia() {
        return typeof navigator.getDisplayMedia !== 'undefined'
            || (typeof navigator.mediaDevices !== 'undefined'
                && typeof navigator.mediaDevices.getDisplayMedia
                    !== 'undefined');
    }
    /**
     * Checks if the browser supports WebRTC Encoded Transform, an alternative
     * to insertable streams.
     *
     * NOTE: At the time of this writing the only browser supporting this is
     * Safari / WebKit, behind a flag.
     *
     * @returns {boolean} {@code true} if the browser supports it.
     */
    supportsEncodedTransform() {
        return Boolean(window.RTCRtpScriptTransform);
    }
    /**
     * Checks if the browser supports insertable streams, needed for E2EE.
     * @returns {boolean} {@code true} if the browser supports insertable streams.
     */
    supportsInsertableStreams() {
        if (!(typeof window.RTCRtpSender !== 'undefined'
            && window.RTCRtpSender.prototype.createEncodedStreams)) {
            return false;
        }
        // Feature-detect transferable streams which we need to operate in a worker.
        // See https://groups.google.com/a/chromium.org/g/blink-dev/c/1LStSgBt6AM/m/hj0odB8pCAAJ
        const stream = new ReadableStream();
        try {
            window.postMessage(stream, '*', [stream]);
            return true;
        }
        catch (_a) {
            return false;
        }
    }
    /**
     * Whether the browser supports the RED format for audio.
     */
    supportsAudioRed() {
        return Boolean(window.RTCRtpSender
            && window.RTCRtpSender.getCapabilities
            && window.RTCRtpSender.getCapabilities('audio').codecs.some(codec => codec.mimeType === 'audio/red')
            && window.RTCRtpReceiver
            && window.RTCRtpReceiver.getCapabilities
            && window.RTCRtpReceiver.getCapabilities('audio').codecs.some(codec => codec.mimeType === 'audio/red'));
    }
    /**
     * Checks if the browser supports unified plan.
     *
     * @returns {boolean}
     */
    supportsUnifiedPlan() {
        // We do not want to enable unified plan on Electron clients that have Chromium version < 96 because of
        // performance and screensharing issues.
        return !(this.isElectron() && (this._getChromiumBasedVersion() < 96));
    }
    /**
     * Checks if the browser supports voice activity detection via the @type {VADAudioAnalyser} service.
     *
     * @returns {boolean}
     */
    supportsVADDetection() {
        return this.isChromiumBased();
    }
    /**
     * Check if the browser supports the RTP RTX feature (and it is usable).
     *
     * @returns {boolean}
     */
    supportsRTX() {
        // Disable RTX on Firefox up to 96 because we prefer simulcast over RTX
        // see https://bugzilla.mozilla.org/show_bug.cgi?id=1738504
        return !(this.isFirefox() && this.isVersionLessThan('96'));
    }
    /**
     * Returns the version of a Chromium based browser.
     *
     * @returns {Number}
     */
    _getChromiumBasedVersion() {
        if (this.isChromiumBased()) {
            // NW.JS doesn't expose the Chrome version in the UA string.
            if (this.isNWJS()) {
                // eslint-disable-next-line no-undef
                return Number.parseInt(process.versions.chromium, 10);
            }
            // Here we process all browsers which use the Chrome engine but
            // don't necessarily identify as Chrome. We cannot use the version
            // comparing functions because the Electron, Opera and NW.JS
            // versions are inconsequential here, as we need to know the actual
            // Chrome engine version.
            const ua = navigator.userAgent;
            if (ua.match(/Chrome/)) {
                const version = Number.parseInt(ua.match(/Chrome\/([\d.]+)/)[1], 10);
                return version;
            }
        }
        return -1;
    }
    /**
     * Returns the version of a Safari browser.
     *
     * @returns {Number}
     */
    _getSafariVersion() {
        if (this.isSafari()) {
            return Number.parseInt(this.getVersion(), 10);
        }
        return -1;
    }
    /**
     * Returns the version of an ios browser.
     *
     * @returns {Number}
     */
    _getIOSVersion() {
        if (this.isWebKitBased()) {
            return Number.parseInt(this.getVersion(), 10);
        }
        return -1;
    }
}
//# sourceMappingURL=BrowserCapabilities.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/browser/index.js":
/*!******************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/browser/index.js ***!
  \******************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (__WEBPACK_DEFAULT_EXPORT__)
/* harmony export */ });
/* harmony import */ var _BrowserCapabilities__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./BrowserCapabilities */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/browser/BrowserCapabilities.js");

/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (new _BrowserCapabilities__WEBPACK_IMPORTED_MODULE_0__["default"]());
//# sourceMappingURL=index.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/connectivity/ConnectionQuality.js":
/*!***********************************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/connectivity/ConnectionQuality.js ***!
  \***********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
var __filename = "/index.js";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (/* binding */ ConnectionQuality)
/* harmony export */ });
/* harmony import */ var _jitsi_logger__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @jitsi/logger */ "./node_modules/@jitsi/logger/lib/index.js");
/* harmony import */ var _jitsi_logger__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(_jitsi_logger__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var _JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../JitsiConferenceEvents */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/JitsiConferenceEvents.js");
/* harmony import */ var _service_RTC_CodecMimeType__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../service/RTC/CodecMimeType */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/RTC/CodecMimeType.js");
/* harmony import */ var _service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../service/RTC/RTCEvents */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/RTC/RTCEvents.js");
/* harmony import */ var _service_connectivity_ConnectionQualityEvents__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../../service/connectivity/ConnectionQualityEvents */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/connectivity/ConnectionQualityEvents.js");





const Resolutions = __webpack_require__(/*! ../../service/RTC/Resolutions */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/RTC/Resolutions.js");
const { VideoType } = __webpack_require__(/*! ../../service/RTC/VideoType */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/RTC/VideoType.js");
const { XMPPEvents } = __webpack_require__(/*! ../../service/xmpp/XMPPEvents */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/xmpp/XMPPEvents.js");
const logger = (0,_jitsi_logger__WEBPACK_IMPORTED_MODULE_0__.getLogger)(__filename);
/**
 * The value to use for the "type" field for messages sent by ConnectionQuality
 * over the data channel.
 */
const STATS_MESSAGE_TYPE = 'stats';
const kSimulcastFormats = [
    { width: 1920,
        height: 1080,
        layers: 3,
        target: 'high' },
    { width: 1280,
        height: 720,
        layers: 3,
        target: 'high' },
    { width: 960,
        height: 540,
        layers: 3,
        target: 'standard' },
    { width: 640,
        height: 360,
        layers: 2,
        target: 'standard' },
    { width: 480,
        height: 270,
        layers: 2,
        target: 'low' },
    { width: 320,
        height: 180,
        layers: 1,
        target: 'low' }
];
/**
 * The maximum bitrate to use as a measurement against the participant's current
 * bitrate. This cap helps in the cases where the participant's bitrate is high
 * but not enough to fulfill high targets, such as with 1080p.
 */
const MAX_TARGET_BITRATE = 2500;
/**
 * The initial bitrate for video in kbps.
 */
let startBitrate = 800;
/**
 * Gets the expected bitrate (in kbps) in perfect network conditions.
 * @param simulcast {boolean} whether simulcast is enabled or not.
 * @param resolution {Resolution} the resolution.
 * @param millisSinceStart {number} the number of milliseconds since sending video started.
 * @param videoQualitySettings {Object} the bitrate and codec settings for the local video source.
 */
function getTarget(simulcast, resolution, millisSinceStart, videoQualitySettings) {
    let target = 0;
    let height = Math.min(resolution.height, resolution.width);
    // Find the first format with height no bigger than ours.
    let simulcastFormat = kSimulcastFormats.find(f => f.height <= height);
    if (simulcastFormat && simulcast && videoQualitySettings.codec === _service_RTC_CodecMimeType__WEBPACK_IMPORTED_MODULE_2__["default"].VP8) {
        // Sum the target fields from all simulcast layers for the given
        // resolution (e.g. 720p + 360p + 180p) for VP8 simulcast.
        for (height = simulcastFormat.height; height >= 180; height /= 2) {
            const targetHeight = height;
            simulcastFormat = kSimulcastFormats.find(f => f.height === targetHeight);
            if (simulcastFormat) {
                target += videoQualitySettings[simulcastFormat.target];
            }
            else {
                break;
            }
        }
    }
    else if (simulcastFormat) {
        // For VP9 SVC, H.264 (simulcast automatically disabled) and p2p, target bitrate will be
        // same as that of the individual stream bitrate.
        target = videoQualitySettings[simulcastFormat.target];
    }
    // Allow for an additional 1 second for ramp up -- delay any initial drop
    // of connection quality by 1 second. Convert target from bps to kbps.
    return Math.min(target / 1000, rampUp(Math.max(0, millisSinceStart - 1000)));
}
/**
 * Gets the bitrate to which GCC would have ramped up in perfect network
 * conditions after millisSinceStart milliseconds.
 * @param millisSinceStart {number} the number of milliseconds since sending
 * video was enabled.
 */
function rampUp(millisSinceStart) {
    if (millisSinceStart > 60000) {
        return Number.MAX_SAFE_INTEGER;
    }
    // According to GCC the send side bandwidth estimation grows with at most
    // 8% per second.
    // https://tools.ietf.org/html/draft-ietf-rmcat-gcc-02#section-5.5
    return startBitrate * Math.pow(1.08, millisSinceStart / 1000);
}
/**
 * A class which monitors the local statistics coming from the RTC modules, and
 * calculates a "connection quality" value, in percent, for the media
 * connection. A value of 100% indicates a very good network connection, and a
 * value of 0% indicates a poor connection.
 */
class ConnectionQuality {
    /**
     *
     * @param conference
     * @param eventEmitter
     * @param options
     */
    constructor(conference, eventEmitter, options) {
        var _a;
        this.eventEmitter = eventEmitter;
        /**
         * The owning JitsiConference.
         */
        this._conference = conference;
        /**
         * Holds statistics about the local connection quality.
         */
        this._localStats = {
            connectionQuality: 100,
            jvbRTT: undefined
        };
        /**
         * The time this._localStats.connectionQuality was last updated.
         */
        this._lastConnectionQualityUpdate = -1;
        /**
         * Conference options.
         */
        this._options = options;
        /**
         * Maps a participant ID to an object holding connection quality
         * statistics received from this participant.
         */
        this._remoteStats = {};
        /**
         * The time that the ICE state last changed to CONNECTED. We use this
         * to calculate how much time we as a sender have had to ramp-up.
         */
        this._timeIceConnected = -1;
        /**
         * The time that local video was unmuted. We use this to calculate how
         * much time we as a sender have had to ramp-up.
         */
        this._timeVideoUnmuted = -1;
        // We assume a global startBitrate value for the sake of simplicity.
        if (((_a = this._options.config) === null || _a === void 0 ? void 0 : _a.startBitrate) > 0) {
            startBitrate = this._options.config.startBitrate;
        }
        // TODO: consider ignoring these events and letting the user of
        // lib-jitsi-meet handle these separately.
        conference.on(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_1__.CONNECTION_INTERRUPTED, () => {
            this._updateLocalConnectionQuality(0);
            this.eventEmitter.emit(_service_connectivity_ConnectionQualityEvents__WEBPACK_IMPORTED_MODULE_4__.LOCAL_STATS_UPDATED, this._localStats);
            this._broadcastLocalStats();
        });
        conference.room.addListener(XMPPEvents.ICE_CONNECTION_STATE_CHANGED, (jingleSession, newState) => {
            if (!jingleSession.isP2P && newState === 'connected') {
                this._timeIceConnected = window.performance.now();
            }
        });
        // Listen to DataChannel message from other participants in the
        // conference, and update the _remoteStats field accordingly.
        // TODO - Delete this when all the mobile endpoints switch to using the new Colibri
        // message format for sending the endpoint stats.
        conference.on(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_1__.ENDPOINT_MESSAGE_RECEIVED, (participant, payload) => {
            if (payload.type === STATS_MESSAGE_TYPE) {
                this._updateRemoteStats(participant.getId(), payload.values);
            }
        });
        conference.on(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_1__.ENDPOINT_STATS_RECEIVED, (participant, payload) => {
            this._updateRemoteStats(participant.getId(), payload);
        });
        if (!this._options.config.disableLocalStats) {
            // Listen to local statistics events originating from the RTC module and update the _localStats field.
            conference.statistics.addConnectionStatsListener(this._updateLocalStats.bind(this));
        }
        // Save the last time we were unmuted.
        conference.on(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_1__.TRACK_MUTE_CHANGED, track => {
            if (track.isVideoTrack()) {
                if (track.isMuted()) {
                    this._timeVideoUnmuted = -1;
                }
                else {
                    this._maybeUpdateUnmuteTime();
                }
            }
        });
        conference.on(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_1__.TRACK_ADDED, track => {
            if (track.isVideoTrack() && !track.isMuted()) {
                this._maybeUpdateUnmuteTime();
            }
        });
        conference.rtc.on(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_3__.LOCAL_TRACK_MAX_ENABLED_RESOLUTION_CHANGED, track => {
            this._localStats.maxEnabledResolution = track.maxEnabledResolution;
        });
        conference.on(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_1__.SERVER_REGION_CHANGED, serverRegion => {
            this._localStats.serverRegion = serverRegion;
        });
        conference.on(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_1__.PROPERTIES_CHANGED, properties => {
            this._localStats.bridgeCount
                = Number((properties || {})['bridge-count']);
        });
    }
    /**
     * Sets _timeVideoUnmuted if it was previously unset. If it was already set,
     * doesn't change it.
     */
    _maybeUpdateUnmuteTime() {
        if (this._timeVideoUnmuted < 0) {
            this._timeVideoUnmuted = window.performance.now();
        }
    }
    /**
     * Calculates a new "connection quality" value.
     * @param videoType {VideoType} the type of the video source (camera or a screen capture).
     * @param isMuted {boolean} whether the local video is muted.
     * @param resolutionName {Resolution} the input resolution used by the camera.
     * @returns {*} the newly calculated connection quality.
     */
    _calculateConnectionQuality(videoType, isMuted, resolutionName) {
        var _a, _b;
        // resolutionName is an index into Resolutions (where "720" is
        // "1280x720" and "960" is "960x720" ...).
        const resolution = Resolutions[resolutionName];
        let quality = 100;
        let packetLoss;
        // TODO: take into account packet loss for received streams
        if (this._localStats.packetLoss) {
            packetLoss = this._localStats.packetLoss.upload;
            // Ugly Hack Alert (UHA):
            // The packet loss for the upload direction is calculated based on
            // incoming RTCP Receiver Reports. Since we don't have RTCP
            // termination for audio, these reports come from the actual
            // receivers in the conference and therefore the reported packet
            // loss includes loss from the bridge to the receiver.
            // When we are sending video this effect is small, because the
            // number of video packets is much larger than the number of audio
            // packets (and our calculation is based on the total number of
            // received and lost packets).
            // When video is muted, however, the effect might be significant,
            // but we don't know what it is. We do know that it is positive, so
            // as a temporary solution, until RTCP termination is implemented
            // for the audio streams, we relax the packet loss checks here.
            if (isMuted) {
                packetLoss *= 0.5;
            }
        }
        if (isMuted || !resolution || videoType === VideoType.DESKTOP
            || this._timeIceConnected < 0
            || this._timeVideoUnmuted < 0) {
            // Calculate a value based on packet loss only.
            if (packetLoss === undefined) {
                logger.error('Cannot calculate connection quality, unknown '
                    + 'packet loss.');
                quality = 100;
            }
            else if (packetLoss <= 2) {
                quality = 100; // Full 5 bars.
            }
            else if (packetLoss <= 4) {
                quality = 70; // 4 bars
            }
            else if (packetLoss <= 6) {
                quality = 50; // 3 bars
            }
            else if (packetLoss <= 8) {
                quality = 30; // 2 bars
            }
            else if (packetLoss <= 12) {
                quality = 10; // 1 bars
            }
            else {
                quality = 0; // Still 1 bar, but slower climb-up.
            }
        }
        else {
            // Calculate a value based on the send video bitrate on the active TPC.
            const activeTPC = this._conference.getActivePeerConnection();
            if (activeTPC) {
                const isSimulcastOn = activeTPC.isSimulcastOn();
                const videoQualitySettings = activeTPC.getTargetVideoBitrates();
                // Add the codec info as well.
                videoQualitySettings.codec = activeTPC.getConfiguredVideoCodec();
                // Time since sending of video was enabled.
                const millisSinceStart = window.performance.now()
                    - Math.max(this._timeVideoUnmuted, this._timeIceConnected);
                const statsInterval = (_b = (_a = this._options.config) === null || _a === void 0 ? void 0 : _a.pcStatsInterval) !== null && _b !== void 0 ? _b : 10000;
                // Expected sending bitrate in perfect conditions.
                let target = getTarget(isSimulcastOn, resolution, millisSinceStart, videoQualitySettings);
                target = Math.min(target, MAX_TARGET_BITRATE);
                // Calculate the quality only after the stats are available (after video was enabled).
                if (millisSinceStart > statsInterval) {
                    quality = 100 * this._localStats.bitrate.upload / target;
                }
            }
            // Whatever the bitrate, drop early if there is significant loss
            if (packetLoss && packetLoss >= 10) {
                quality = Math.min(quality, 30);
            }
        }
        // Make sure that the quality doesn't climb quickly
        if (this._lastConnectionQualityUpdate > 0) {
            const maxIncreasePerSecond = 2;
            const prevConnectionQuality = this._localStats.connectionQuality;
            const diffSeconds = (window.performance.now() - this._lastConnectionQualityUpdate) / 1000;
            quality = Math.min(quality, prevConnectionQuality + (diffSeconds * maxIncreasePerSecond));
        }
        return Math.min(100, quality);
    }
    /**
     * Updates the localConnectionQuality value
     * @param values {number} the new value. Should be in [0, 100].
     */
    _updateLocalConnectionQuality(value) {
        this._localStats.connectionQuality = value;
        this._lastConnectionQualityUpdate = window.performance.now();
    }
    /**
     * Broadcasts the local statistics to all other participants in the
     * conference.
     */
    _broadcastLocalStats() {
        // Send only the data that remote participants care about.
        const data = {
            bitrate: this._localStats.bitrate,
            packetLoss: this._localStats.packetLoss,
            connectionQuality: this._localStats.connectionQuality,
            jvbRTT: this._localStats.jvbRTT,
            serverRegion: this._localStats.serverRegion,
            maxEnabledResolution: this._localStats.maxEnabledResolution,
            avgAudioLevels: this._localStats.localAvgAudioLevels
        };
        try {
            this._conference.sendEndpointStatsMessage(data);
        }
        catch (err) {
            // Ignore the error as we might hit it in the beginning of the call before the channel is ready.
            // The statistics will be sent again after few seconds and error is logged elseware as well.
        }
    }
    /**
     * Updates the local statistics
     * @param {TraceablePeerConnection} tpc the peerconnection which emitted
     * the stats
     * @param data new statistics
     */
    _updateLocalStats(tpc, data) {
        // Update jvbRTT
        if (!tpc.isP2P) {
            const jvbRTT = data.transport
                && data.transport.length && data.transport[0].rtt;
            this._localStats.jvbRTT = jvbRTT ? jvbRTT : undefined;
        }
        // Do not continue with processing of other stats if they do not
        // originate from the active peerconnection
        if (tpc !== this._conference.getActivePeerConnection()) {
            return;
        }
        let key;
        const updateLocalConnectionQuality = !this._conference.isConnectionInterrupted();
        const localVideoTrack = this._conference.getLocalVideoTrack();
        const videoType = localVideoTrack ? localVideoTrack.videoType : undefined;
        const isMuted = localVideoTrack ? localVideoTrack.isMuted() : true;
        const resolution = localVideoTrack
            ? Math.min(localVideoTrack.resolution, localVideoTrack.maxEnabledResolution) : null;
        if (!isMuted) {
            this._maybeUpdateUnmuteTime();
        }
        // Copy the fields already in 'data'.
        for (key in data) {
            if (data.hasOwnProperty(key)) {
                this._localStats[key] = data[key];
            }
        }
        // And re-calculate the connectionQuality field.
        if (updateLocalConnectionQuality) {
            this._updateLocalConnectionQuality(this._calculateConnectionQuality(videoType, isMuted, resolution));
        }
        this.eventEmitter.emit(_service_connectivity_ConnectionQualityEvents__WEBPACK_IMPORTED_MODULE_4__.LOCAL_STATS_UPDATED, this._localStats);
        this._broadcastLocalStats();
    }
    /**
     * Updates remote statistics
     * @param id the id of the remote participant
     * @param data the statistics received
     */
    _updateRemoteStats(id, data) {
        // Use only the fields we need
        this._remoteStats[id] = {
            bitrate: data.bitrate,
            packetLoss: data.packetLoss,
            connectionQuality: data.connectionQuality,
            jvbRTT: data.jvbRTT,
            serverRegion: data.serverRegion,
            maxEnabledResolution: data.maxEnabledResolution,
            avgAudioLevels: data.avgAudioLevels
        };
        this.eventEmitter.emit(_service_connectivity_ConnectionQualityEvents__WEBPACK_IMPORTED_MODULE_4__.REMOTE_STATS_UPDATED, id, this._remoteStats[id]);
    }
    /**
     * Returns the local statistics.
     * Exported only for use in jitsi-meet-torture.
     */
    getStats() {
        return this._localStats;
    }
}
//# sourceMappingURL=ConnectionQuality.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/connectivity/IceFailedHandling.js":
/*!***********************************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/connectivity/IceFailedHandling.js ***!
  \***********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
var __filename = "/index.js";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (/* binding */ IceFailedHandling)
/* harmony export */ });
/* harmony import */ var _jitsi_logger__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @jitsi/logger */ "./node_modules/@jitsi/logger/lib/index.js");
/* harmony import */ var _jitsi_logger__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(_jitsi_logger__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var _JitsiConferenceErrors__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../JitsiConferenceErrors */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/JitsiConferenceErrors.js");
/* harmony import */ var _JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../JitsiConferenceEvents */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/JitsiConferenceEvents.js");



const logger = (0,_jitsi_logger__WEBPACK_IMPORTED_MODULE_0__.getLogger)(__filename);
/**
 * This class deals with shenanigans around JVB media session's ICE failed status handling.
 *
 * If ICE restarts are NOT explicitly enabled by the {@code enableIceRestart} config option, then the conference will
 * delay emitting the {@JitsiConferenceErrors.ICE_FAILED} event by 15 seconds. If the network info module reports
 * the internet offline status then the time will start counting after the internet comes back online.
 *
 * If ICE restart are enabled, then a delayed ICE failed notification to Jicofo will be sent, only if the ICE connection
 * does not recover soon after or before the XMPP connection is restored (if it was ever broken). If ICE fails while
 * the XMPP connection is not broken then the notifications will be sent after 2 seconds delay.
 */
class IceFailedHandling {
    /**
     * Creates new {@code DelayedIceFailed} task.
     * @param {JitsiConference} conference
     */
    constructor(conference) {
        this._conference = conference;
    }
    /**
     * After making sure there's no way for the ICE connection to recover this method either sends ICE failed
     * notification to Jicofo or emits the ice failed conference event.
     * @private
     * @returns {void}
     */
    _actOnIceFailed() {
        if (!this._conference.room) {
            return;
        }
        const { enableForcedReload, enableIceRestart } = this._conference.options.config;
        const explicitlyDisabled = typeof enableIceRestart !== 'undefined' && !enableIceRestart;
        const supportsRestartByTerminate = this._conference.room.supportsRestartByTerminate();
        const useTerminateForRestart = supportsRestartByTerminate && !enableIceRestart;
        logger.info('ICE failed,'
            + ` enableForcedReload: ${enableForcedReload},`
            + ` enableIceRestart: ${enableIceRestart},`
            + ` supports restart by terminate: ${supportsRestartByTerminate}`);
        if (explicitlyDisabled || (!enableIceRestart && !supportsRestartByTerminate) || enableForcedReload) {
            logger.info('ICE failed, but ICE restarts are disabled');
            const reason = enableForcedReload
                ? _JitsiConferenceErrors__WEBPACK_IMPORTED_MODULE_1__.CONFERENCE_RESTARTED
                : _JitsiConferenceErrors__WEBPACK_IMPORTED_MODULE_1__.ICE_FAILED;
            this._conference.eventEmitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_2__.CONFERENCE_FAILED, reason);
            return;
        }
        const jvbConnection = this._conference.jvbJingleSession;
        const jvbConnIceState = jvbConnection && jvbConnection.getIceConnectionState();
        if (!jvbConnection) {
            logger.warn('Not sending ICE failed - no JVB connection');
        }
        else if (jvbConnIceState === 'connected') {
            logger.info('ICE connection restored - not sending ICE failed');
        }
        else {
            logger.info('Sending ICE failed - the connection did not recover, '
                + `ICE state: ${jvbConnIceState}, `
                + `use 'session-terminate': ${useTerminateForRestart}`);
            if (useTerminateForRestart) {
                this._conference.jvbJingleSession.terminate(() => {
                    logger.info('session-terminate for ice restart - done');
                }, error => {
                    logger.error(`session-terminate for ice restart - error: ${error.message}`);
                }, {
                    reason: 'connectivity-error',
                    reasonDescription: 'ICE FAILED',
                    requestRestart: true,
                    sendSessionTerminate: true
                });
            }
            else {
                this._conference.jvbJingleSession.sendIceFailedNotification();
            }
        }
    }
    /**
     * Starts the task.
     */
    start() {
        //  Using xmpp.ping allows to handle both XMPP being disconnected and internet offline cases. The ping function
        // uses sendIQ2 method which is resilient to XMPP connection disconnected state and will patiently wait until it
        // gets reconnected.
        //  This also handles the case about waiting for the internet to come back online, because ping
        // will only succeed when the internet is online and then there's a chance for the ICE to recover from FAILED to
        // CONNECTED which is the extra 2 second timeout after ping.
        //  The 65 second timeout is given on purpose as there's no chance for XMPP to recover after 65 seconds of no
        // communication with the server. Such resume attempt will result in unrecoverable conference failed event due
        // to 'item-not-found' error returned by the server.
        this._conference.xmpp.ping(65000).then(() => {
            if (!this._canceled) {
                this._iceFailedTimeout = window.setTimeout(() => {
                    this._iceFailedTimeout = undefined;
                    this._actOnIceFailed();
                }, 2000);
            }
        }, error => {
            logger.error('PING error/timeout - not sending ICE failed', error);
        });
    }
    /**
     * Cancels the task.
     */
    cancel() {
        this._canceled = true;
        window.clearTimeout(this._iceFailedTimeout);
    }
}
//# sourceMappingURL=IceFailedHandling.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/connectivity/NetworkInfo.js":
/*!*****************************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/connectivity/NetworkInfo.js ***!
  \*****************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
var __filename = "/index.js";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   NETWORK_INFO_EVENT: () => (/* binding */ NETWORK_INFO_EVENT),
/* harmony export */   NetworkInfo: () => (/* binding */ NetworkInfo),
/* harmony export */   "default": () => (__WEBPACK_DEFAULT_EXPORT__)
/* harmony export */ });
/* harmony import */ var _jitsi_logger__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @jitsi/logger */ "./node_modules/@jitsi/logger/lib/index.js");
/* harmony import */ var _jitsi_logger__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(_jitsi_logger__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var _util_Listenable__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../util/Listenable */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/util/Listenable.js");


const NETWORK_INFO_EVENT = 'NETWORK_INFO_CHANGED';
const logger = (0,_jitsi_logger__WEBPACK_IMPORTED_MODULE_0__.getLogger)(__filename);
/**
 * Module provides information about the current status of the internet
 * connection. Lib-jitsi-meet doesn't have any logic for detecting internet
 * online/offline, but rather it relies on the information supplied by the app
 * that uses it. By default the online state is assumed and the lib acts as if
 * it was connected. See {@link JitsiMeetJS.setNetworkInfo}.
 */
class NetworkInfo extends _util_Listenable__WEBPACK_IMPORTED_MODULE_1__["default"] {
    /**
     * Creates new {@link NetworkInfo} instance.
     */
    constructor() {
        super();
        this._current = {
            isOnline: true
        };
    }
    /**
     * Updates the network info state.
     *
     * @param {object} state - The network info state.
     * @param {boolean} state.isOnline - {@code true} if the internet connectivity is online or {@code false}
     * otherwise.
     */
    updateNetworkInfo({ isOnline }) {
        logger.debug('updateNetworkInfo', { isOnline });
        this._current = {
            isOnline: isOnline === true
        };
        this.eventEmitter.emit(NETWORK_INFO_EVENT, this._current);
    }
    /**
     * Returns the online/offline internet status. By default the value is {@code true} and changes only if
     * the lib's user wires the state through {@link JitsiMeetJS.setNetworkInfo} like the jitsi-meet does. Because of
     * that any logic should still assume that the internet may be offline and should handle the failure gracefully.
     * It's only a good hint in the other way around: to pause internet operations until it comes back online.
     * @returns {boolean}
     */
    isOnline() {
        return this._current.isOnline === true;
    }
}
const networkInfo = new NetworkInfo();
/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (networkInfo);
//# sourceMappingURL=NetworkInfo.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/connectivity/TrackStreamingStatus.js":
/*!**************************************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/connectivity/TrackStreamingStatus.js ***!
  \**************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
var __filename = "/index.js";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   TrackStreamingStatus: () => (/* binding */ TrackStreamingStatus),
/* harmony export */   TrackStreamingStatusImpl: () => (/* binding */ TrackStreamingStatusImpl),
/* harmony export */   "default": () => (__WEBPACK_DEFAULT_EXPORT__)
/* harmony export */ });
/* harmony import */ var _jitsi_logger__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @jitsi/logger */ "./node_modules/@jitsi/logger/lib/index.js");
/* harmony import */ var _jitsi_logger__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(_jitsi_logger__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var _JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../JitsiConferenceEvents */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/JitsiConferenceEvents.js");
/* harmony import */ var _JitsiTrackEvents__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../JitsiTrackEvents */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/JitsiTrackEvents.js");
/* harmony import */ var _service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../service/RTC/RTCEvents */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/RTC/RTCEvents.js");
/* harmony import */ var _service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../../service/statistics/AnalyticsEvents */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/statistics/AnalyticsEvents.js");
/* harmony import */ var _browser__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../browser */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/browser/index.js");
/* harmony import */ var _statistics_statistics__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../statistics/statistics */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/statistics/statistics.js");







/** Track streaming statuses. */
var TrackStreamingStatus;
(function (TrackStreamingStatus) {
    /**
     * Status indicating that streaming is currently active.
     */
    TrackStreamingStatus["ACTIVE"] = "active";
    /**
     * Status indicating that streaming is currently inactive.
     * Inactive means the streaming was stopped on purpose from the bridge, like exiting forwarded sources or
     * adaptivity decided to drop video because of not enough bandwidth.
     */
    TrackStreamingStatus["INACTIVE"] = "inactive";
    /**
     * Status indicating that streaming is currently interrupted.
     */
    TrackStreamingStatus["INTERRUPTED"] = "interrupted";
    /**
     * Status indicating that streaming is currently restoring.
     */
    TrackStreamingStatus["RESTORING"] = "restoring";
})(TrackStreamingStatus || (TrackStreamingStatus = {}));
const logger = (0,_jitsi_logger__WEBPACK_IMPORTED_MODULE_0__.getLogger)(__filename);
/**
 * Default value of 500 milliseconds for {@link TrackStreamingStatusImpl.outOfForwardedSourcesTimeout}.
 */
const DEFAULT_NOT_IN_FORWARDED_SOURCES_TIMEOUT = 500;
/**
 * Default value of 2500 milliseconds for {@link TrackStreamingStatusImpl.p2pRtcMuteTimeout}.
 */
const DEFAULT_P2P_RTC_MUTE_TIMEOUT = 2500;
/**
 * Default value of 10000 milliseconds for {@link TrackStreamingStatusImpl.rtcMuteTimeout}.
 */
const DEFAULT_RTC_MUTE_TIMEOUT = 10000;
/**
 * The time to wait a track to be restored. Track which was out of forwarded sources should be inactive and when
 * entering forwarded sources it becomes restoring and when data is received from bridge it will become active, but if
 * no data is received for some time we set status of that track streaming to interrupted.
 */
const DEFAULT_RESTORING_TIMEOUT = 10000;
/**
 * Class is responsible for emitting JitsiTrackEvents.TRACK_STREAMING_STATUS_CHANGED events.
 */
class TrackStreamingStatusImpl {
    /**
     * Creates new instance of <tt>TrackStreamingStatus</tt>.
     *
     * @constructor
     * @param rtc - the RTC service instance
     * @param conference - parent conference instance
     * @param {Object} options
     * @param {number} [options.p2pRtcMuteTimeout=2500] custom value for
     * {@link TrackStreamingStatusImpl.p2pRtcMuteTimeout}.
     * @param {number} [options.rtcMuteTimeout=2000] custom value for
     * {@link TrackStreamingStatusImpl.rtcMuteTimeout}.
     * @param {number} [options.outOfForwardedSourcesTimeout=500] custom value for
     * {@link TrackStreamingStatusImpl.outOfForwardedSourcesTimeout}.
     */
    constructor(rtc, conference, track, options) {
        this.rtc = rtc;
        this.conference = conference;
        this.track = track;
        this.restoringTimer = null;
        this.rtcMutedTimestamp = null;
        this.streamingStatusMap = {};
        this.trackTimer = null;
        this.outOfForwardedSourcesTimeout = typeof options.outOfForwardedSourcesTimeout === 'number'
            ? options.outOfForwardedSourcesTimeout : DEFAULT_NOT_IN_FORWARDED_SOURCES_TIMEOUT;
        this.p2pRtcMuteTimeout = typeof options.p2pRtcMuteTimeout === 'number'
            ? options.p2pRtcMuteTimeout : DEFAULT_P2P_RTC_MUTE_TIMEOUT;
        this.rtcMuteTimeout = typeof options.rtcMuteTimeout === 'number'
            ? options.rtcMuteTimeout : DEFAULT_RTC_MUTE_TIMEOUT;
        logger.info(`RtcMuteTimeout set to: ${this.rtcMuteTimeout}`);
    }
    /* eslint-disable max-params*/
    /**
     * Calculates the new {@link TrackStreamingStatus} based on the values given for some specific remote track. It is
     * assumed that the conference is currently in the JVB mode (in contrary to the P2P mode)
     * @param isInForwardedSources - indicates whether the track is in the forwarded sources set. When set to
     * false it means that JVB is not sending any video for the track.
     * @param isRestoringTimedout - if true it means that the track has been outside of forwarded sources too
     * long to be considered {@link TrackStreamingStatus.RESTORING}.
     * @param isVideoMuted - true if the track is video muted and we should not expect to receive any video.
     * @param isVideoTrackFrozen - if the current browser support video frozen detection then it will be set to
     * true when the video track is frozen. If the current browser does not support frozen detection the it's always
     * false.
     * @return {TrackStreamingStatus} the new streaming status for the track for whom the values above were provided.
     * @private
     */
    static _getNewStateForJvbMode(isInForwardedSources, isRestoringTimedout, isVideoMuted, isVideoTrackFrozen) {
        // We are currently not checking the endpoint connection status received from the JVB.
        if (isVideoMuted) {
            // If the connection is active according to JVB and the track is video muted there is no way for the
            // connection to be inactive, because the detection logic below only makes sense for video.
            return TrackStreamingStatus.ACTIVE;
        }
        // Logic when isVideoTrackFrozen is supported
        if (_browser__WEBPACK_IMPORTED_MODULE_5__["default"].supportsVideoMuteOnConnInterrupted()) {
            if (!isVideoTrackFrozen) {
                // If the video is playing we're good
                return TrackStreamingStatus.ACTIVE;
            }
            else if (isInForwardedSources) {
                return isRestoringTimedout ? TrackStreamingStatus.INTERRUPTED : TrackStreamingStatus.RESTORING;
            }
            return TrackStreamingStatus.INACTIVE;
        }
        // Because this browser is incapable of detecting frozen video we must rely on the forwarded sources value
        return isInForwardedSources ? TrackStreamingStatus.ACTIVE : TrackStreamingStatus.INACTIVE;
    }
    /* eslint-enable max-params*/
    /**
     * In P2P mode we don't care about any values coming from the JVB and the streaming status can be only active or
     * interrupted.
     * @param isVideoMuted - true if video muted
     * @param isVideoTrackFrozen - true if the video track for the remote track is currently frozen. If the
     * current browser does not support video frozen detection then it's always false.
     * @return {TrackStreamingStatus}
     * @private
     */
    static _getNewStateForP2PMode(isVideoMuted, isVideoTrackFrozen) {
        if (!_browser__WEBPACK_IMPORTED_MODULE_5__["default"].supportsVideoMuteOnConnInterrupted()) {
            // There's no way to detect problems in P2P when there's no video track frozen detection...
            return TrackStreamingStatus.ACTIVE;
        }
        return isVideoMuted || !isVideoTrackFrozen
            ? TrackStreamingStatus.ACTIVE : TrackStreamingStatus.INTERRUPTED;
    }
    /**
     * Gets the video frozen timeout for given source name.
     * @return how long are we going to wait since RTC video muted even, before a video track is considered
     * frozen.
     * @private
     */
    _getVideoFrozenTimeout() {
        const sourceName = this.track.getSourceName();
        return this.rtc.isInForwardedSources(sourceName)
            ? this.rtcMuteTimeout
            : this.conference.isP2PActive() ? this.p2pRtcMuteTimeout : this.outOfForwardedSourcesTimeout;
    }
    /**
     * Initializes <tt>TrackStreamingStatus</tt> and bind required event listeners.
     */
    init() {
        // Handles P2P status changes
        this._onP2PStatus = this.figureOutStreamingStatus.bind(this);
        this.conference.on(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_1__.JitsiConferenceEvents.P2P_STATUS, this._onP2PStatus);
        // Used to send analytics events for the participant that left the call.
        this._onUserLeft = this.onUserLeft.bind(this);
        this.conference.on(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_1__.JitsiConferenceEvents.USER_LEFT, this._onUserLeft);
        // On some browsers MediaStreamTrack trigger "onmute"/"onunmute" events for video type tracks when they stop
        // receiving data which is often a sign that remote user is having connectivity issues.
        if (_browser__WEBPACK_IMPORTED_MODULE_5__["default"].supportsVideoMuteOnConnInterrupted()) {
            this._onTrackRtcMuted = this.onTrackRtcMuted.bind(this);
            this.rtc.addListener(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_3__["default"].REMOTE_TRACK_MUTE, this._onTrackRtcMuted);
            this._onTrackRtcUnmuted = this.onTrackRtcUnmuted.bind(this);
            this.rtc.addListener(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_3__["default"].REMOTE_TRACK_UNMUTE, this._onTrackRtcUnmuted);
            // Listened which will be bound to JitsiRemoteTrack to listen for signalling mute/unmute events.
            this._onSignallingMuteChanged = this.onSignallingMuteChanged.bind(this);
            this.track.on(_JitsiTrackEvents__WEBPACK_IMPORTED_MODULE_2__.TRACK_MUTE_CHANGED, this._onSignallingMuteChanged);
            // Used to send an analytics event when the video type changes.
            this._onTrackVideoTypeChanged = this.onTrackVideoTypeChanged.bind(this);
            this.track.on(_JitsiTrackEvents__WEBPACK_IMPORTED_MODULE_2__.TRACK_VIDEOTYPE_CHANGED, this._onTrackVideoTypeChanged);
        }
        this._onForwardedSourcesChanged = this.onForwardedSourcesChanged.bind(this);
        this.conference.on(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_1__.JitsiConferenceEvents.FORWARDED_SOURCES_CHANGED, this._onForwardedSourcesChanged);
        this._onLastNValueChanged = this.figureOutStreamingStatus.bind(this);
        this.rtc.on(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_3__["default"].LASTN_VALUE_CHANGED, this._onLastNValueChanged);
    }
    /**
     * Removes all event listeners and disposes of all resources held by this instance.
     */
    dispose() {
        if (_browser__WEBPACK_IMPORTED_MODULE_5__["default"].supportsVideoMuteOnConnInterrupted()) {
            this.rtc.removeListener(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_3__["default"].REMOTE_TRACK_MUTE, this._onTrackRtcMuted);
            this.rtc.removeListener(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_3__["default"].REMOTE_TRACK_UNMUTE, this._onTrackRtcUnmuted);
            this.track.off(_JitsiTrackEvents__WEBPACK_IMPORTED_MODULE_2__.TRACK_MUTE_CHANGED, this._onSignallingMuteChanged);
            this.track.off(_JitsiTrackEvents__WEBPACK_IMPORTED_MODULE_2__.TRACK_VIDEOTYPE_CHANGED, this._onTrackVideoTypeChanged);
        }
        this.conference.off(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_1__.JitsiConferenceEvents.FORWARDED_SOURCES_CHANGED, this._onForwardedSourcesChanged);
        this.conference.off(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_1__.JitsiConferenceEvents.P2P_STATUS, this._onP2PStatus);
        this.conference.off(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_1__.JitsiConferenceEvents.USER_LEFT, this._onUserLeft);
        this.rtc.removeListener(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_3__["default"].LASTN_VALUE_CHANGED, this._onLastNValueChanged);
        this.clearTimeout();
        this.clearRtcMutedTimestamp();
        this.maybeSendTrackStreamingStatusEvent(Date.now());
        this.figureOutStreamingStatus();
    }
    /**
     * Changes streaming status.
     * @param newStatus
     */
    _changeStreamingStatus(newStatus) {
        if (this.track.getTrackStreamingStatus() !== newStatus) {
            const sourceName = this.track.getSourceName();
            this.track._setTrackStreamingStatus(newStatus);
            logger.debug(`Emit track streaming status(${Date.now()}) ${sourceName}: ${newStatus}`);
            // Log the event on CallStats
            _statistics_statistics__WEBPACK_IMPORTED_MODULE_6__["default"].sendLog(JSON.stringify({
                id: 'track.streaming.status',
                track: sourceName,
                status: newStatus
            }));
            // It's common for the event listeners to access the JitsiRemoteTrack. Thus pass it as a parameter here.
            this.track.emit(_JitsiTrackEvents__WEBPACK_IMPORTED_MODULE_2__.TRACK_STREAMING_STATUS_CHANGED, this.track, newStatus);
        }
    }
    /**
     * Reset the postponed "streaming interrupted" event which was previously scheduled as a timeout on RTC 'onmute'
     * event.
     */
    clearTimeout() {
        if (this.trackTimer) {
            window.clearTimeout(this.trackTimer);
            this.trackTimer = null;
        }
    }
    /**
     * Clears the timestamp of the RTC muted event for remote video track.
     */
    clearRtcMutedTimestamp() {
        this.rtcMutedTimestamp = null;
    }
    /**
     * Checks if track is considered frozen.
     * @return <tt>true</tt> if the video has frozen or <tt>false</tt> when it's either not considered frozen
     * (yet) or if freeze detection is not supported by the current browser.
     *
     * FIXME merge this logic with NO_DATA_FROM_SOURCE event implemented in JitsiLocalTrack by extending the event to
     *       the remote track and allowing to set different timeout for local and remote tracks.
     */
    isVideoTrackFrozen() {
        if (!_browser__WEBPACK_IMPORTED_MODULE_5__["default"].supportsVideoMuteOnConnInterrupted()) {
            return false;
        }
        const isVideoRTCMuted = this.track.isWebRTCTrackMuted();
        const rtcMutedTimestamp = this.rtcMutedTimestamp;
        const timeout = this._getVideoFrozenTimeout();
        return isVideoRTCMuted && typeof rtcMutedTimestamp === 'number' && (Date.now() - rtcMutedTimestamp) >= timeout;
    }
    /**
     * Figures out (and updates) the current streaming status for the track identified by the source name.
     */
    figureOutStreamingStatus() {
        const sourceName = this.track.getSourceName();
        const inP2PMode = this.conference.isP2PActive();
        const isRestoringTimedOut = this._isRestoringTimedout();
        const audioOnlyMode = this.conference.getLastN() === 0;
        // NOTE Overriding videoMuted to true for audioOnlyMode should disable any detection based on video playback or
        // forwarded sources.
        const isVideoMuted = this.track.isMuted() || audioOnlyMode;
        const isVideoTrackFrozen = this.isVideoTrackFrozen();
        const isInForwardedSources = this.rtc.isInForwardedSources(sourceName);
        const newState = inP2PMode
            ? TrackStreamingStatusImpl._getNewStateForP2PMode(isVideoMuted, isVideoTrackFrozen)
            : TrackStreamingStatusImpl._getNewStateForJvbMode(isInForwardedSources, isRestoringTimedOut, isVideoMuted, isVideoTrackFrozen);
        // if the new state is not restoring clear timers and timestamps that we use to track the restoring state
        if (newState !== TrackStreamingStatus.RESTORING) {
            this._clearRestoringTimer();
        }
        logger.debug(`Figure out conn status for ${sourceName}, is video muted: ${isVideoMuted} video track frozen: ${isVideoTrackFrozen} p2p mode: ${inP2PMode} is in forwarded sources: ${isInForwardedSources} currentStatus => newStatus: ${this.track.getTrackStreamingStatus()} => ${newState}`);
        const oldStreamingStatus = this.streamingStatusMap || {};
        // Send an analytics event (guard on either the p2p flag or the streaming status has changed since the last
        // time this code block run).
        if (!('p2p' in oldStreamingStatus)
            || !('streamingStatus' in oldStreamingStatus)
            || oldStreamingStatus.p2p !== inP2PMode
            || oldStreamingStatus.streamingStatus !== newState) {
            const nowMs = Date.now();
            this.maybeSendTrackStreamingStatusEvent(nowMs);
            this.streamingStatusMap = Object.assign(Object.assign({}, oldStreamingStatus), { streamingStatus: newState, p2p: inP2PMode, startedMs: nowMs });
            // sometimes (always?) we're late to hook the TRACK_VIDEOTYPE_CHANGED event and the video type is not in
            // oldStreamingStatus.
            if (!('videoType' in this.streamingStatusMap)) {
                this.streamingStatusMap.videoType = this.track.getVideoType();
            }
        }
        this._changeStreamingStatus(newState);
    }
    /**
     * Computes the duration of the current streaming status for the track (i.e. 15 seconds in the INTERRUPTED state)
     * and sends a track streaming status event.
     * @param nowMs - The current time (in millis).
     */
    maybeSendTrackStreamingStatusEvent(nowMs) {
        const trackStreamingStatus = this.streamingStatusMap;
        if (trackStreamingStatus
            && 'startedMs' in trackStreamingStatus
            && 'videoType' in trackStreamingStatus
            && 'streamingStatus' in trackStreamingStatus
            && 'p2p' in trackStreamingStatus) {
            trackStreamingStatus.value = nowMs - trackStreamingStatus.startedMs;
            _statistics_statistics__WEBPACK_IMPORTED_MODULE_6__["default"].sendAnalytics((0,_service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_4__.createTrackStreamingStatusEvent)(trackStreamingStatus));
        }
    }
    /**
     * On change in forwarded sources set check all leaving and entering track to change their corresponding statuses.
     *
     * @param leavingForwardedSources - The array of sourceName leaving forwarded sources.
     * @param enteringForwardedSources - The array of sourceName entering forwarded sources.
     * @param timestamp - The time in millis
     * @private
     */
    onForwardedSourcesChanged(leavingForwardedSources = [], enteringForwardedSources = [], timestamp) {
        const sourceName = this.track.getSourceName();
        // If the browser doesn't fire the mute/onmute events when the remote peer stops/starts sending media,
        // calculate the streaming status for all the tracks since it won't get triggered automatically on the track
        // that has started/stopped receiving media.
        if (!_browser__WEBPACK_IMPORTED_MODULE_5__["default"].supportsVideoMuteOnConnInterrupted()) {
            this.figureOutStreamingStatus();
        }
        if (leavingForwardedSources.includes(sourceName)) {
            this.track._clearEnteredForwardedSourcesTimestamp();
            this._clearRestoringTimer();
            _browser__WEBPACK_IMPORTED_MODULE_5__["default"].supportsVideoMuteOnConnInterrupted() && this.figureOutStreamingStatus();
        }
        if (enteringForwardedSources.includes(sourceName)) {
            // store the timestamp this track is entering forwarded sources
            this.track._setEnteredForwardedSourcesTimestamp(timestamp);
            _browser__WEBPACK_IMPORTED_MODULE_5__["default"].supportsVideoMuteOnConnInterrupted() && this.figureOutStreamingStatus();
        }
    }
    /**
     * Clears the restoring timer for video track and the timestamp for entering forwarded sources.
     */
    _clearRestoringTimer() {
        const rTimer = this.restoringTimer;
        if (rTimer) {
            clearTimeout(rTimer);
            this.restoringTimer = null;
        }
    }
    /**
     * Checks whether a track had stayed enough in restoring state, compares current time and the time the track
     * entered in forwarded sources. If it hasn't timedout and there is no timer added, add new timer in order to give
     * it more time to become active or mark it as interrupted on next check.
     *
     * @returns <tt>true</tt> if the track was in restoring state more than the timeout
     * ({@link DEFAULT_RESTORING_TIMEOUT}.) in order to set its status to interrupted.
     * @private
     */
    _isRestoringTimedout() {
        const enteredForwardedSourcesTimestamp = this.track._getEnteredForwardedSourcesTimestamp();
        if (enteredForwardedSourcesTimestamp
            && (Date.now() - enteredForwardedSourcesTimestamp) >= DEFAULT_RESTORING_TIMEOUT) {
            return true;
        }
        // still haven't reached timeout, if there is no timer scheduled, schedule one so we can track the restoring
        // state and change it after reaching the timeout
        const rTimer = this.restoringTimer;
        if (!rTimer) {
            this.restoringTimer = setTimeout(() => this.figureOutStreamingStatus(), DEFAULT_RESTORING_TIMEOUT);
        }
        return false;
    }
    /** Checks whether a track is the current track. */
    _isCurrentTrack(track) {
        return track.getSourceName() === this.track.getSourceName();
    }
    /**
     * Sends a last/final track streaming status event for the track of the user that left the conference.
     * @param id - The id of the participant that left the conference.
     */
    onUserLeft(id) {
        if (this.track.getParticipantId() === id) {
            this.maybeSendTrackStreamingStatusEvent(Date.now());
            this.streamingStatusMap = {};
        }
    }
    /**
     * Handles RTC 'onmute' event for the video track.
     *
     * @param track - The video track for which 'onmute' event will be processed.
     */
    onTrackRtcMuted(track) {
        if (!this._isCurrentTrack(track)) {
            return;
        }
        const sourceName = track.getSourceName();
        logger.debug(`Detector track RTC muted: ${sourceName}`, Date.now());
        this.rtcMutedTimestamp = Date.now();
        if (!track.isMuted()) {
            // If the user is not muted according to the signalling we'll give it some time, before the streaming
            // interrupted event is triggered.
            this.clearTimeout();
            // The timeout is reduced when track is not in the forwarded sources
            const timeout = this._getVideoFrozenTimeout();
            this.trackTimer = window.setTimeout(() => {
                logger.debug(`Set track RTC muted for: ${sourceName} after the timeout of ${timeout} ms`);
                this.clearTimeout();
                this.figureOutStreamingStatus();
            }, timeout);
        }
    }
    /**
     * Handles RTC 'onunmute' event for the video track.
     *
     * @param track - The video track for which 'onunmute' event will be processed.
     */
    onTrackRtcUnmuted(track) {
        if (!this._isCurrentTrack(track)) {
            return;
        }
        const sourceName = this.track.getSourceName();
        logger.debug(`Detector track RTC unmuted: ${sourceName}`, Date.now());
        this.clearTimeout();
        this.clearRtcMutedTimestamp();
        this.figureOutStreamingStatus();
    }
    /**
     * Here the signalling "mute"/"unmute" events are processed.
     *
     * @param track - The remote video track for which the signalling mute/unmute event will be
     * processed.
     */
    onSignallingMuteChanged(track) {
        if (!this._isCurrentTrack(track)) {
            return;
        }
        const sourceName = this.track.getSourceName();
        logger.debug(`Detector on track signalling mute changed: ${sourceName}`, track.isMuted());
        this.figureOutStreamingStatus();
    }
    /**
     * Sends a track streaming status event as a result of the video type changing.
     * @deprecated this will go away with full multiple streams support
     * @param type - The video type.
     */
    onTrackVideoTypeChanged(type) {
        const nowMs = Date.now();
        this.maybeSendTrackStreamingStatusEvent(nowMs);
        this.streamingStatusMap = Object.assign(Object.assign({}, this.streamingStatusMap || {}), { videoType: type, startedMs: nowMs });
    }
}
/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (TrackStreamingStatusImpl);
//# sourceMappingURL=TrackStreamingStatus.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/detection/ActiveDeviceDetector.js":
/*!***********************************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/detection/ActiveDeviceDetector.js ***!
  \***********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
var __filename = "/index.js";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (/* binding */ getActiveAudioDevice)
/* harmony export */ });
/* harmony import */ var _jitsi_logger__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @jitsi/logger */ "./node_modules/@jitsi/logger/lib/index.js");
/* harmony import */ var _jitsi_logger__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(_jitsi_logger__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var _JitsiTrackEvents__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../JitsiTrackEvents */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/JitsiTrackEvents.js");
/* harmony import */ var _RTC_RTC__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../RTC/RTC */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/RTC/RTC.js");
/* harmony import */ var _statistics_statistics__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../statistics/statistics */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/statistics/statistics.js");




const logger = (0,_jitsi_logger__WEBPACK_IMPORTED_MODULE_0__.getLogger)(__filename);
// If after 3000 ms the detector did not find any active devices consider that there aren't any usable ones available
// i.e. audioLevel > 0.008
const DETECTION_TIMEOUT = 3000;
/**
 * Go through all audio devices on the system and return one that is active, i.e. has audio signal.
 *
 * @returns Promise<Object> - Object containing information about the found device.
 */
function getActiveAudioDevice() {
    return new Promise(resolve => {
        _RTC_RTC__WEBPACK_IMPORTED_MODULE_2__["default"].enumerateDevices(devices => {
            const audioDevices = devices.filter(device => device.kind === 'audioinput');
            const devicePromiseArray = [];
            for (const micDevice of audioDevices) {
                const devicePromise = _RTC_RTC__WEBPACK_IMPORTED_MODULE_2__["default"].obtainAudioAndVideoPermissions({ devices: ['audio'],
                    micDeviceId: micDevice.deviceId }).then(tracks => {
                    // We expect a single device to be available when obtained from obtainAudioAndVideoPermissions
                    // that's  why only take p.value[0].
                    const track = tracks[0];
                    _statistics_statistics__WEBPACK_IMPORTED_MODULE_3__["default"].startLocalStats(track, track.setAudioLevel.bind(track));
                    return track;
                });
                devicePromiseArray.push(devicePromise);
            }
            Promise.allSettled(devicePromiseArray).then(outcomeArray => {
                const successfulPromises = outcomeArray.filter(p => p.status === 'fulfilled');
                const rejectedPromises = outcomeArray.filter(p => p.status === 'rejected');
                const availableDevices = successfulPromises.map(p => p.value);
                const rejectReasons = rejectedPromises.map(p => p.value);
                for (const reason of rejectReasons) {
                    logger.error('Failed to acquire audio device with error: ', reason);
                }
                // Setup event handlers for monitored devices.
                for (const device of availableDevices) {
                    device.on(_JitsiTrackEvents__WEBPACK_IMPORTED_MODULE_1__.TRACK_AUDIO_LEVEL_CHANGED, audioLevel => {
                        // This is a very naive approach but works, a more accurate one would be to use rnnoise in
                        // order to limit  the number of false positives. The 0.008 constant is due to how
                        // LocalStatsCollector from lib-jitsi-meet publishes audio-levels, in this case 0.008 denotes //
                        // no input.
                        if (audioLevel > 0.008) {
                            stopActiveDevices(availableDevices);
                            resolve({ deviceId: device.deviceId,
                                deviceLabel: device.track.label });
                        }
                    });
                }
                // Cancel the detection in case no devices was found with audioLevel > 0 in the set timeout.
                setTimeout(() => {
                    stopActiveDevices(availableDevices);
                    resolve({
                        deviceId: '',
                        deviceLabel: ''
                    });
                }, DETECTION_TIMEOUT);
            });
        });
    });
}
/**
 * Stop the streams of the provided JitsiLocalTracks.
 *
 * @param {Array<JitsiLocalTrack>} deviceList - Array of JitsiLocalTracks to stop.
 * @returns {void}
 */
function stopActiveDevices(deviceList) {
    for (const device of deviceList) {
        device.stopStream();
    }
}
//# sourceMappingURL=ActiveDeviceDetector.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/detection/DetectionEvents.js":
/*!******************************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/detection/DetectionEvents.js ***!
  \******************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   AUDIO_INPUT_STATE_CHANGE: () => (/* binding */ AUDIO_INPUT_STATE_CHANGE),
/* harmony export */   DETECTOR_STATE_CHANGE: () => (/* binding */ DETECTOR_STATE_CHANGE),
/* harmony export */   DetectionEvents: () => (/* binding */ DetectionEvents),
/* harmony export */   NO_AUDIO_INPUT: () => (/* binding */ NO_AUDIO_INPUT),
/* harmony export */   VAD_NOISY_DEVICE: () => (/* binding */ VAD_NOISY_DEVICE),
/* harmony export */   VAD_REPORT_PUBLISHED: () => (/* binding */ VAD_REPORT_PUBLISHED),
/* harmony export */   VAD_SCORE_PUBLISHED: () => (/* binding */ VAD_SCORE_PUBLISHED),
/* harmony export */   VAD_TALK_WHILE_MUTED: () => (/* binding */ VAD_TALK_WHILE_MUTED)
/* harmony export */ });
var DetectionEvents;
(function (DetectionEvents) {
    /**
     * Event triggered by a audio detector indicating that its active state has changed from active to inactive or vice
     * versa.
     * @event
     * @type {boolean} - true when service has changed to active false otherwise.
     */
    DetectionEvents["DETECTOR_STATE_CHANGE"] = "detector_state_change";
    /** Event triggered by {@link NoAudioSignalDetector} when the local audio device associated with a JitsiConference
     * starts receiving audio levels with the value of 0 meaning no audio is being captured on that device, or when
     * it starts receiving audio levels !== 0 after being in a state of no audio.
     * @event
     * @type {boolean} - true when the current conference audio track has audio input false otherwise.
     */
    DetectionEvents["AUDIO_INPUT_STATE_CHANGE"] = "audio_input_state_changed";
    /** Event triggered by NoAudioSignalDetector when the local audio device associated with a JitsiConference goes silent
     * for a period of time, meaning that the device is either broken or hardware/software muted.
     * @event
     * @type {void}
     */
    DetectionEvents["NO_AUDIO_INPUT"] = "no_audio_input_detected";
    /**
     *  Event generated by {@link VADNoiseDetection} when the tracked device is considered noisy.
     *  @event
     *  @type {Object}
     */
    DetectionEvents["VAD_NOISY_DEVICE"] = "detection.vad_noise_device";
    /**
     * Event generated by VADReportingService when if finishes creating a VAD report for the monitored devices.
     * The generated objects are of type Array<Object>, one score for each monitored device.
     * @event VAD_REPORT_PUBLISHED
     * @type Array<Object> with the following structure:
     * @property {Date} timestamp - Timestamp at which the compute took place.
     * @property {number} avgVAD - Average VAD score over monitored period of time.
     * @property {string} deviceId - Associate local audio device ID.
     */
    DetectionEvents["VAD_REPORT_PUBLISHED"] = "vad-report-published";
    /**
     * Event generated by {@link TrackVADEmitter} when PCM sample VAD score is available.
     *
     * @event
     * @type {Object}
     * @property {Date}   timestamp - Exact time at which processed PCM sample was generated.
     * @property {number} score - VAD score on a scale from 0 to 1 (i.e. 0.7)
     * @property {Float32Array} pcmData - Raw PCM data with which the VAD score was calculated.
     * @property {string} deviceId - Device id of the associated track.
     */
    DetectionEvents["VAD_SCORE_PUBLISHED"] = "detection.vad_score_published";
    /**
     *  Event generated by {@link VADTalkMutedDetection} when a user is talking while the mic is muted.
     *
     *  @event
     *  @type {Object}
     */
    DetectionEvents["VAD_TALK_WHILE_MUTED"] = "detection.vad_talk_while_muted";
})(DetectionEvents || (DetectionEvents = {}));
;
// exported for backward compatibility
const DETECTOR_STATE_CHANGE = DetectionEvents.DETECTOR_STATE_CHANGE;
const AUDIO_INPUT_STATE_CHANGE = DetectionEvents.AUDIO_INPUT_STATE_CHANGE;
const NO_AUDIO_INPUT = DetectionEvents.NO_AUDIO_INPUT;
const VAD_NOISY_DEVICE = DetectionEvents.VAD_NOISY_DEVICE;
const VAD_REPORT_PUBLISHED = DetectionEvents.VAD_REPORT_PUBLISHED;
const VAD_SCORE_PUBLISHED = DetectionEvents.VAD_SCORE_PUBLISHED;
const VAD_TALK_WHILE_MUTED = DetectionEvents.VAD_TALK_WHILE_MUTED;
//# sourceMappingURL=DetectionEvents.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/detection/NoAudioSignalDetection.js":
/*!*************************************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/detection/NoAudioSignalDetection.js ***!
  \*************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (/* binding */ NoAudioSignalDetection)
/* harmony export */ });
/* harmony import */ var events__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! events */ "./node_modules/events/events.js");
/* harmony import */ var events__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(events__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var _JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../JitsiConferenceEvents */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/JitsiConferenceEvents.js");
/* harmony import */ var _JitsiTrackEvents__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../JitsiTrackEvents */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/JitsiTrackEvents.js");
/* harmony import */ var _DetectionEvents__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./DetectionEvents */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/detection/DetectionEvents.js");




// We wait a certain time interval for constant silence input from the current device to account for
// potential abnormalities and for a better use experience i.e. don't generate event the instant
// an audio track is added to the tcr.
// Potential improvement - add this as a configurable parameter.
const SILENCE_PERIOD_MS = 4000;
/**
 * Detect if there is no audio input on the current TraceAblePeerConnection selected track. The no audio
 * state must be constant for a configured amount of time in order for the event to be triggered.
 * @fires DetectionEvents.AUDIO_INPUT_STATE_CHANGE
 * @fires DetectionEvents.NO_AUDIO_INPUT
 */
class NoAudioSignalDetection extends (events__WEBPACK_IMPORTED_MODULE_0___default()) {
    /**
     * Creates new NoAudioSignalDetection.
     *
     * @param conference the JitsiConference instance that created us.
     * @constructor
     */
    constructor(conference) {
        super();
        this._conference = conference;
        this._timeoutTrigger = null;
        this._hasAudioInput = null;
        conference.on(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_1__.TRACK_ADDED, this._trackAdded.bind(this));
    }
    /**
     * Clear the timeout state.
     */
    _clearTriggerTimeout() {
        clearTimeout(this._timeoutTrigger);
        this._timeoutTrigger = null;
    }
    /**
     * Generated event triggered by a change in the current conference audio input state.
     *
     * @param {*} audioLevel - The audio level of the ssrc.
     * @fires DetectionEvents.AUDIO_INPUT_STATE_CHANGE
     */
    _handleAudioInputStateChange(audioLevel) {
        // Current audio input state of the active local track in the conference, true for audio input false for no
        // audio input.
        const status = audioLevel !== 0;
        // If this is the first audio event picked up or the current status is different from the previous trigger
        // the event.
        if (this._hasAudioInput === null || this._hasAudioInput !== status) {
            this._hasAudioInput = status;
            this.emit(_DetectionEvents__WEBPACK_IMPORTED_MODULE_3__.AUDIO_INPUT_STATE_CHANGE, this._hasAudioInput);
        }
    }
    /**
     * Generate event triggered by a prolonged period of no audio input.
     *
     * @param {number} audioLevel - The audio level of the ssrc.
     * @fires DetectionEvents.NO_AUDIO_INPUT
     */
    _handleNoAudioInputDetection(audioLevel) {
        if (this._eventFired) {
            return;
        }
        if (audioLevel === 0 && !this._timeoutTrigger) {
            this._timeoutTrigger = setTimeout(() => {
                this._eventFired = true;
                this.emit(_DetectionEvents__WEBPACK_IMPORTED_MODULE_3__.NO_AUDIO_INPUT);
            }, SILENCE_PERIOD_MS);
        }
        else if (audioLevel !== 0 && this._timeoutTrigger) {
            this._clearTriggerTimeout();
        }
    }
    /**
     * Receives audio level events for all send and receive streams on the current TraceablePeerConnection.
     *
     * @param {TraceablePeerConnection} tpc - TraceablePeerConnection of the owning conference.
     * @param {number} ssrc - The synchronization source identifier (SSRC) of the endpoint/participant/stream
     * being reported.
     * @param {number} audioLevel - The audio level of the ssrc.
     * @param {boolean} isLocal - true for local/send streams or false for remote/receive streams.
     */
    _audioLevel(tpc, ssrc, audioLevel, isLocal) {
        // We are interested in the local audio streams
        if (!isLocal || !this._audioTrack) {
            return;
        }
        // Get currently active local tracks from the TraceablePeerConnection
        const localSSRCs = tpc.localSSRCs.get(this._audioTrack.rtcId);
        // Only target the current active track in the tpc. For some reason audio levels for previous
        // devices are also picked up from the PeerConnection so we filter them out.
        if (!localSSRCs || !localSSRCs.ssrcs.includes(ssrc)) {
            return;
        }
        // First handle audio input state change. In case the state changed to no input the no audio input event
        // can try to fire again.
        this._handleAudioInputStateChange(audioLevel);
        this._handleNoAudioInputDetection(audioLevel);
    }
    /**
     * Notifies NoAudioSignalDetection that a JitsiTrack was added to the associated JitsiConference.
     * Only take into account local audio tracks.
     *
     * @param {JitsiTrack} track - The added JitsiTrack.
     */
    _trackAdded(track) {
        if (track.isLocalAudioTrack()) {
            // Reset state for the new track.
            this._audioTrack = track;
            this._eventFired = false;
            this._clearTriggerTimeout();
            // Listen for the audio levels on the newly added audio track
            track.on(_JitsiTrackEvents__WEBPACK_IMPORTED_MODULE_2__.NO_AUDIO_INPUT, audioLevel => {
                this._handleNoAudioInputDetection(audioLevel);
            });
            track.on(_JitsiTrackEvents__WEBPACK_IMPORTED_MODULE_2__.TRACK_AUDIO_LEVEL_CHANGED, audioLevel => {
                this._handleNoAudioInputDetection(audioLevel);
                this._handleAudioInputStateChange(audioLevel);
            });
        }
    }
}
//# sourceMappingURL=NoAudioSignalDetection.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/detection/P2PDominantSpeakerDetection.js":
/*!******************************************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/detection/P2PDominantSpeakerDetection.js ***!
  \******************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (/* binding */ P2PDominantSpeakerDetection)
/* harmony export */ });
/* harmony import */ var _JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../JitsiConferenceEvents */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/JitsiConferenceEvents.js");
/* harmony import */ var _service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../service/RTC/RTCEvents */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/RTC/RTCEvents.js");


/**
 * The value which we use to say, every sound over this threshold
 * is talking on the mic.
 * @type {number}
 */
const SPEECH_DETECT_THRESHOLD = 0.6;
/**
 * The <tt>P2PDominantSpeakerDetection</tt> is activated only when p2p is
 * currently used.
 * Listens for changes in the audio level changes of the local p2p audio track
 * or remote p2p one and fires dominant speaker events to be able to use
 * features depending on those events (speaker stats), to make them work without
 * the video bridge.
 */
class P2PDominantSpeakerDetection {
    /**
     * Creates P2PDominantSpeakerDetection
     * @param conference the JitsiConference instance that created us.
     * @constructor
     */
    constructor(conference) {
        this.conference = conference;
        conference.addEventListener(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_0__.TRACK_AUDIO_LEVEL_CHANGED, this._audioLevel.bind(this));
        this.myUserID = this.conference.myUserId();
    }
    /**
     * Receives audio level events for all streams in the conference.
     *
     * @param {String} id - The participant id
     * @param {number} audioLevel - The audio level.
     */
    _audioLevel(id, audioLevel) {
        // we do not process if p2p is not active
        // or audio level is under certain threshold
        // or if the audio level is for local audio track which is muted
        if (!this.conference.isP2PActive()
            || audioLevel <= SPEECH_DETECT_THRESHOLD
            || (id === this.myUserID
                && this.conference.getLocalAudioTrack().isMuted())) {
            return;
        }
        this.conference.rtc.eventEmitter.emit(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_1__["default"].DOMINANT_SPEAKER_CHANGED, id);
    }
}
//# sourceMappingURL=P2PDominantSpeakerDetection.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/detection/TrackVADEmitter.js":
/*!******************************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/detection/TrackVADEmitter.js ***!
  \******************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (/* binding */ TrackVADEmitter)
/* harmony export */ });
/* harmony import */ var events__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! events */ "./node_modules/events/events.js");
/* harmony import */ var events__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(events__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var _RTC_RTC__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../RTC/RTC */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/RTC/RTC.js");
/* harmony import */ var _webaudio_WebAudioUtils__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../webaudio/WebAudioUtils */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/webaudio/WebAudioUtils.js");
/* harmony import */ var _DetectionEvents__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./DetectionEvents */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/detection/DetectionEvents.js");




/**
 * Connects an audio JitsiLocalTrack to a vadProcessor using WebAudio ScriptProcessorNode.
 * Once an object is created audio from the local track flows through the ScriptProcessorNode as raw PCM.
 * The PCM is processed by the injected vad module and a voice activity detection score is obtained, the
 * score is published to consumers via an EventEmitter.
 * After work is done with this service the destroy method needs to be called for a proper cleanup.
 *
 * @fires VAD_SCORE_PUBLISHED
 */
class TrackVADEmitter extends (events__WEBPACK_IMPORTED_MODULE_0___default()) {
    /**
     * Constructor.
     *
     * @param {number} procNodeSampleRate - Sample rate of the ScriptProcessorNode. Possible values  256, 512, 1024,
     *  2048, 4096, 8192, 16384. Passing other values will default to closes neighbor.
     * @param {Object} vadProcessor - VAD processor that allows us to calculate VAD score for PCM samples.
     * @param {JitsiLocalTrack} jitsiLocalTrack - JitsiLocalTrack corresponding to micDeviceId.
     */
    constructor(procNodeSampleRate, vadProcessor, jitsiLocalTrack) {
        super();
        /**
         * Sample rate of the ScriptProcessorNode.
         */
        this._procNodeSampleRate = procNodeSampleRate;
        /**
         * VAD Processor that allows us to calculate VAD score for PCM samples
         */
        this._vadProcessor = vadProcessor;
        /**
         * The JitsiLocalTrack instance.
         */
        this._localTrack = jitsiLocalTrack;
        /**
         * Buffer to hold residue PCM resulting after a ScriptProcessorNode callback
         */
        this._bufferResidue = new Float32Array([]);
        /**
         * The AudioContext instance with the preferred sample frequency.
         */
        this._audioContext = (0,_webaudio_WebAudioUtils__WEBPACK_IMPORTED_MODULE_2__.createAudioContext)({ sampleRate: vadProcessor.getRequiredPCMFrequency() });
        /**
         * PCM Sample size expected by the VAD Processor instance. We cache it here as this value is used extensively,
         * saves a couple of function calls.
         */
        this._vadSampleSize = vadProcessor.getSampleLength();
        /**
         * Event listener function that will be called by the ScriptProcessNode with raw PCM data, depending on the set
         * sample rate.
         */
        this._onAudioProcess = this._onAudioProcess.bind(this);
        this._initializeAudioContext();
    }
    /**
     * Factory method that sets up all the necessary components for the creation of the TrackVADEmitter.
     *
     * @param {string} micDeviceId - Target microphone device id.
     * @param {number} procNodeSampleRate - Sample rate of the proc node.
     * @param {Object} vadProcessor -Module that calculates the voice activity score for a certain audio PCM sample.
     * The processor needs to implement the following functions:
     * - <tt>getSampleLength()</tt> - Returns the sample size accepted by getSampleLength.
     * - <tt>getRequiredPCMFrequency()</tt> - Returns the PCM frequency at which the processor operates.
     * - <tt>calculateAudioFrameVAD(pcmSample)</tt> - Process a 32 float pcm sample of getSampleLength size.
     * @returns {Promise<TrackVADEmitter>} - Promise resolving in a new instance of TrackVADEmitter.
     */
    static create(micDeviceId, procNodeSampleRate, vadProcessor) {
        return _RTC_RTC__WEBPACK_IMPORTED_MODULE_1__["default"].obtainAudioAndVideoPermissions({
            devices: ['audio'],
            micDeviceId
        }).then(localTrack => {
            // We only expect one audio track when specifying a device id.
            if (!localTrack[0]) {
                throw new Error(`Failed to create jitsi local track for device id: ${micDeviceId}`);
            }
            return new TrackVADEmitter(procNodeSampleRate, vadProcessor, localTrack[0]);
            // We have no exception handling at this point as there is nothing to clean up, the vadProcessor
            // life cycle is handled by whoever created this instance.
        });
    }
    /**
     * Sets up the audio graph in the AudioContext.
     *
     * @returns {void}
     */
    _initializeAudioContext() {
        this._audioSource = this._audioContext.createMediaStreamSource(this._localTrack.stream);
        // TODO AudioProcessingNode is deprecated in the web audio specifications and the recommended replacement
        // is audio worklet, however at the point of implementation AudioProcessingNode was still de de facto way
        // of achieving this functionality and supported in all major browsers as opposed to audio worklet which
        // was only available in Chrome. This todo is just a reminder that we should replace AudioProcessingNode
        // with audio worklet when it's mature enough and has more browser support.
        // We don't need stereo for determining the VAD score so we create a single channel processing node.
        this._audioProcessingNode = this._audioContext.createScriptProcessor(this._procNodeSampleRate, 1, 1);
    }
    /**
     * ScriptProcessorNode callback, the input parameters contains the PCM audio that is then sent to rnnoise.
     * Rnnoise only accepts PCM samples of 480 bytes whereas the webaudio processor node can't sample at a multiple
     * of 480 thus after each _onAudioProcess callback there will remain and PCM buffer residue equal
     * to _procNodeSampleRate / 480 which will be added to the next sample buffer and so on.\
     *
     *
     * @param {AudioProcessingEvent} audioEvent - Audio event.
     * @returns {void}
     * @fires VAD_SCORE_PUBLISHED
     */
    _onAudioProcess(audioEvent) {
        // Prepend the residue PCM buffer from the previous process callback.
        const inData = audioEvent.inputBuffer.getChannelData(0);
        const completeInData = [...this._bufferResidue, ...inData];
        const sampleTimestamp = Date.now();
        let i = 0;
        for (; i + this._vadSampleSize < completeInData.length; i += this._vadSampleSize) {
            const pcmSample = completeInData.slice(i, i + this._vadSampleSize);
            // The VAD processor might change the values inside the array so we make a copy.
            const vadScore = this._vadProcessor.calculateAudioFrameVAD(pcmSample.slice());
            this.emit(_DetectionEvents__WEBPACK_IMPORTED_MODULE_3__.VAD_SCORE_PUBLISHED, {
                timestamp: sampleTimestamp,
                score: vadScore,
                pcmData: pcmSample,
                deviceId: this._localTrack.getDeviceId()
            });
        }
        this._bufferResidue = completeInData.slice(i, completeInData.length);
    }
    /**
     * Connects the nodes in the AudioContext to start the flow of audio data.
     *
     * @returns {void}
     */
    _connectAudioGraph() {
        this._audioProcessingNode.onaudioprocess = this._onAudioProcess;
        this._audioSource.connect(this._audioProcessingNode);
        this._audioProcessingNode.connect(this._audioContext.destination);
    }
    /**
     * Disconnects the nodes in the AudioContext.
     *
     * @returns {void}
     */
    _disconnectAudioGraph() {
        // Even thought we disconnect the processing node it seems that some callbacks remain queued,
        // resulting in calls with and uninitialized context.
        // eslint-disable-next-line no-empty-function
        this._audioProcessingNode.onaudioprocess = () => { };
        this._audioProcessingNode.disconnect();
        this._audioSource.disconnect();
    }
    /**
     * Cleanup potentially acquired resources.
     *
     * @returns {void}
     */
    _cleanupResources() {
        this._disconnectAudioGraph();
        this._localTrack.stopStream();
    }
    /**
     * Get the associated track device ID.
     *
     * @returns {string}
     */
    getDeviceId() {
        return this._localTrack.getDeviceId();
    }
    /**
     * Get the associated track label.
     *
     * @returns {string}
     */
    getTrackLabel() {
        return this._localTrack.getDeviceLabel();
    }
    /**
     * Start the emitter by connecting the audio graph.
     *
     * @returns {void}
     */
    start() {
        this._connectAudioGraph();
    }
    /**
     * Stops the emitter by disconnecting the audio graph.
     *
     * @returns {void}
     */
    stop() {
        this._disconnectAudioGraph();
        this._bufferResidue = [];
    }
    /**
     * Destroy TrackVADEmitter instance (release resources and stop callbacks).
     *
     * @returns {void}
     */
    destroy() {
        if (this._destroyed) {
            return;
        }
        this._cleanupResources();
        this._destroyed = true;
    }
}
//# sourceMappingURL=TrackVADEmitter.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/detection/VADAudioAnalyser.js":
/*!*******************************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/detection/VADAudioAnalyser.js ***!
  \*******************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
var __filename = "/index.js";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (/* binding */ VADAudioAnalyser)
/* harmony export */ });
/* harmony import */ var _jitsi_logger__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @jitsi/logger */ "./node_modules/@jitsi/logger/lib/index.js");
/* harmony import */ var _jitsi_logger__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(_jitsi_logger__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var events__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! events */ "./node_modules/events/events.js");
/* harmony import */ var events__WEBPACK_IMPORTED_MODULE_1___default = /*#__PURE__*/__webpack_require__.n(events__WEBPACK_IMPORTED_MODULE_1__);
/* harmony import */ var _JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../JitsiConferenceEvents */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/JitsiConferenceEvents.js");
/* harmony import */ var _DetectionEvents__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./DetectionEvents */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/detection/DetectionEvents.js");
/* harmony import */ var _TrackVADEmitter__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./TrackVADEmitter */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/detection/TrackVADEmitter.js");





const logger = (0,_jitsi_logger__WEBPACK_IMPORTED_MODULE_0__.getLogger)(__filename);
/**
 * Sample rate of TrackVADEmitter, it defines how many audio samples are processed at a time.
 * @type {number}
 */
const VAD_EMITTER_SAMPLE_RATE = 4096;
/**
 * Connects a TrackVADEmitter to the target conference local audio track and manages various services that use
 * the data to produce audio analytics (VADTalkMutedDetection and VADNoiseDetection).
 */
class VADAudioAnalyser extends events__WEBPACK_IMPORTED_MODULE_1__.EventEmitter {
    /**
     * Creates <tt>VADAudioAnalyser</tt>
     * @param {JitsiConference} conference - JitsiConference instance that created us.
     * @param {Object} createVADProcessor - Function that creates a Voice activity detection processor. The processor
     * needs to implement the following functions:
     * - <tt>getSampleLength()</tt> - Returns the sample size accepted by getSampleLength.
     * - <tt>getRequiredPCMFrequency()</tt> - Returns the PCM frequency at which the processor operates.
     * - <tt>calculateAudioFrameVAD(pcmSample)</tt> - Process a 32 float pcm sample of getSampleLength size.
     * @constructor
     */
    constructor(conference, createVADProcessor) {
        super();
        /**
         * Member function that instantiates a VAD processor.
         */
        this._createVADProcessor = createVADProcessor;
        /**
         * Current {@link TrackVADEmitter}. VAD Emitter uses a {@link JitsiLocalTrack} and VAD processor to generate
         * period voice probability scores.
         */
        this._vadEmitter = null;
        /**
         * Current state of the _vadEmitter
         */
        this._isVADEmitterRunning = false;
        /**
         * Array of currently attached VAD processing services.
         */
        this._detectionServices = [];
        /**
         * Promise used to chain create and destroy operations associated with TRACK_ADDED and TRACK_REMOVED events
         * coming from the conference.
         * Because we have an async created component (VAD Processor) we need to make sure that it's initialized before
         * we destroy it ( when changing the device for instance), or when we use it from an external point of entry
         * i.e. (TRACK_MUTE_CHANGED event callback).
         */
        this._vadInitTracker = Promise.resolve();
        /**
         * Listens for {@link TrackVADEmitter} events and processes them.
         */
        this._processVADScore = this._processVADScore.bind(this);
        conference.on(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_2__.TRACK_ADDED, this._trackAdded.bind(this));
        conference.on(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_2__.TRACK_REMOVED, this._trackRemoved.bind(this));
        conference.on(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_2__.TRACK_MUTE_CHANGED, this._trackMuteChanged.bind(this));
    }
    /**
     * Attach a VAD detector service to the analyser and handle it's state changes.
     *
     * @param {Object} vadTMDetector
     */
    addVADDetectionService(vadService) {
        this._detectionServices.push(vadService);
        vadService.on(_DetectionEvents__WEBPACK_IMPORTED_MODULE_3__.DETECTOR_STATE_CHANGE, () => {
            // When the state of a detector changes check if there are any active detectors attached so that
            // the _vadEmitter doesn't run needlessly.
            const activeDetector = this._detectionServices.filter(detector => detector.isActive() === true);
            // If there are no active detectors running and the vadEmitter is running then stop the emitter as it is
            // uses a considerable amount of CPU. Otherwise start the service if it's stopped and there is a detector
            // that needs it.
            if (!activeDetector.length && this._isVADEmitterRunning) {
                this._stopVADEmitter();
            }
            else if (!this._isVADEmitterRunning) {
                this._startVADEmitter();
            }
        });
    }
    /**
     * Start the {@link TrackVADEmitter} and attach the event listener.
     * @returns {void}
     */
    _startVADEmitter() {
        if (this._vadEmitter) {
            this._vadEmitter.on(_DetectionEvents__WEBPACK_IMPORTED_MODULE_3__.VAD_SCORE_PUBLISHED, this._processVADScore);
            this._vadEmitter.start();
            this._isVADEmitterRunning = true;
        }
    }
    /**
     * Stop the {@link TrackVADEmitter} and detach the event listener.
     * @returns {void}
     */
    _stopVADEmitter() {
        if (this._vadEmitter) {
            this._vadEmitter.removeListener(_DetectionEvents__WEBPACK_IMPORTED_MODULE_3__.VAD_SCORE_PUBLISHED, this._processVADScore);
            this._vadEmitter.stop();
        }
        this._isVADEmitterRunning = false;
    }
    /**
     * Listens for {@link TrackVADEmitter} events and directs them to attached services as needed.
     *
     * @param {Object} vadScore -VAD score emitted by {@link TrackVADEmitter}
     * @param {Date}   vadScore.timestamp - Exact time at which processed PCM sample was generated.
     * @param {number} vadScore.score - VAD score on a scale from 0 to 1 (i.e. 0.7)
     * @param {Float32Array} pcmData - Raw PCM data with which the VAD score was calculated.
     * @param {string} vadScore.deviceId - Device id of the associated track.
     * @listens VAD_SCORE_PUBLISHED
     */
    _processVADScore(vadScore) {
        for (const detector of this._detectionServices) {
            detector.processVADScore(vadScore);
        }
    }
    /**
     * Change the isMuted state of all attached detection services.
     *
     * @param {boolean} isMuted
     */
    _changeDetectorsMuteState(isMuted) {
        for (const detector of this._detectionServices) {
            detector.changeMuteState(isMuted);
        }
    }
    /**
     * Notifies the detector that a track was added to the associated {@link JitsiConference}.
     * Only take into account local audio tracks.
     * @param {JitsiTrack} track - The added track.
     * @returns {void}
     * @listens TRACK_ADDED
     */
    _trackAdded(track) {
        if (track.isLocalAudioTrack()) {
            // Keep a track promise so we take into account successive TRACK_ADD events being generated so that we
            // destroy/create the processing context in the proper order.
            this._vadInitTracker = this._vadInitTracker.then(() => this._createVADProcessor())
                .then(vadProcessor => _TrackVADEmitter__WEBPACK_IMPORTED_MODULE_4__["default"].create(track.getDeviceId(), VAD_EMITTER_SAMPLE_RATE, vadProcessor))
                .then(vadEmitter => {
                logger.debug('Created VAD emitter for track: ', track.getTrackLabel());
                this._vadEmitter = vadEmitter;
                // Iterate through the detection services and set their appropriate mute state, depending on
                // service this will trigger a DETECTOR_STATE_CHANGE which in turn might start the _vadEmitter.
                this._changeDetectorsMuteState(track.isMuted());
            })
                .catch(error => {
                logger.warn('Failed to start VADAudioAnalyser', error);
            });
        }
    }
    /**
     * Notifies the detector that the mute state of a {@link JitsiConference} track has changed. Only takes into account
     * local audio tracks.
     * @param {JitsiTrack} track - The track whose mute state has changed.
     * @returns {void}
     * @listens TRACK_MUTE_CHANGED
     */
    _trackMuteChanged(track) {
        if (track.isLocalAudioTrack()) {
            // On a mute toggle reset the state.
            this._vadInitTracker = this._vadInitTracker.then(() => {
                // Set mute status for the attached detection services.
                this._changeDetectorsMuteState(track.isMuted());
            });
        }
    }
    /**
     * Notifies the detector that a track associated with the {@link JitsiConference} was removed. Only takes into
     * account local audio tracks. Cleans up resources associated with the track and resets the processing context.
     *
     * @param {JitsiTrack} track - The removed track.
     * @returns {void}
     * @listens TRACK_REMOVED
     */
    _trackRemoved(track) {
        if (track.isLocalAudioTrack()) {
            // Use the promise to make sure operations are in sequence.
            this._vadInitTracker = this._vadInitTracker.then(() => {
                logger.debug('Removing track from VAD detection - ', track.getTrackLabel());
                // Track was removed, clean up and set appropriate states.
                if (this._vadEmitter) {
                    this._stopVADEmitter();
                    this._vadEmitter.destroy();
                    this._vadEmitter = null;
                }
                // Reset state of detectors when active track is removed.
                for (const detector of this._detectionServices) {
                    detector.reset();
                }
            });
        }
    }
}
//# sourceMappingURL=VADAudioAnalyser.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/detection/VADNoiseDetection.js":
/*!********************************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/detection/VADNoiseDetection.js ***!
  \********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (/* binding */ VADNoiseDetection)
/* harmony export */ });
/* harmony import */ var events__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! events */ "./node_modules/events/events.js");
/* harmony import */ var events__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(events__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var _util_MathUtil__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../util/MathUtil */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/util/MathUtil.js");
/* harmony import */ var _DetectionEvents__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./DetectionEvents */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/detection/DetectionEvents.js");



/**
 * The average value VAD needs to be under over a period of time to be considered noise.
 * @type {number}
 */
const VAD_NOISE_AVG_THRESHOLD = 0.2;
/**
 * The average values that audio input need to be over to be considered loud.
 * @type {number}
 */
const NOISY_AUDIO_LEVEL_THRESHOLD = 0.040;
/**
 * The value that a VAD score needs to be under in order for processing to begin.
 * @type {number}
 */
const VAD_SCORE_TRIGGER = 0.2;
/**
 * The value that a VAD score needs to be under in order for processing to begin.
 * @type {number}
 */
const AUDIO_LEVEL_SCORE_TRIGGER = 0.020;
/**
 * Time span over which we calculate an average score used to determine if we trigger the event.
 * @type {number}
 */
const PROCESS_TIME_FRAME_SPAN_MS = 1500;
/**
 * Detect if provided VAD score and PCM data is considered noise.
 */
class VADNoiseDetection extends events__WEBPACK_IMPORTED_MODULE_0__.EventEmitter {
    /**
     * Creates <tt>VADNoiseDetection</tt>
     *
     * @constructor
     */
    constructor() {
        super();
        /**
         * Flag which denotes the current state of the detection service i.e.if there is already a processing operation
         * ongoing.
         */
        this._processing = false;
        /**
         * Buffer that keeps the VAD scores for a period of time.
         */
        this._scoreArray = [];
        /**
         * Buffer that keeps audio level samples for a period of time.
         */
        this._audioLvlArray = [];
        /**
         * Current state of the service, if it's not active no processing will occur.
         */
        this._active = false;
        this._calculateNoisyScore = this._calculateNoisyScore.bind(this);
    }
    /**
     * Compute cumulative VAD score and PCM audio levels once the PROCESS_TIME_FRAME_SPAN_MS timeout has elapsed.
     * If the score is above the set threshold fire the event.
     * @returns {void}
     * @fires VAD_NOISY_DEVICE
     */
    _calculateNoisyScore() {
        const scoreAvg = (0,_util_MathUtil__WEBPACK_IMPORTED_MODULE_1__.calculateAverage)(this._scoreArray);
        const audioLevelAvg = (0,_util_MathUtil__WEBPACK_IMPORTED_MODULE_1__.calculateAverage)(this._audioLvlArray);
        if (scoreAvg < VAD_NOISE_AVG_THRESHOLD && audioLevelAvg > NOISY_AUDIO_LEVEL_THRESHOLD) {
            this.emit(_DetectionEvents__WEBPACK_IMPORTED_MODULE_2__.VAD_NOISY_DEVICE);
            this._setActiveState(false);
        }
        // We reset the context in case a new process phase needs to be triggered.
        this.reset();
    }
    /**
     * Record the vad score and average volume in the appropriate buffers.
     *
     * @param {number} vadScore
     * @param {number} avgAudioLvl - average audio level of the PCM sample associated with the VAD score.s
     */
    _recordValues(vadScore, avgAudioLvl) {
        this._scoreArray.push(vadScore);
        this._audioLvlArray.push(avgAudioLvl);
    }
    /**
     * Set the active state of the detection service and notify any listeners.
     *
     * @param {boolean} active
     * @fires DETECTOR_STATE_CHANGE
     */
    _setActiveState(active) {
        this._active = active;
        this.emit(_DetectionEvents__WEBPACK_IMPORTED_MODULE_2__.DETECTOR_STATE_CHANGE, this._active);
    }
    /**
     * Change the state according to the muted status of the tracked device.
     *
     * @param {boolean} isMuted - Is the device muted or not.
     */
    changeMuteState(isMuted) {
        // This service only needs to run when the microphone is not muted.
        this._setActiveState(!isMuted);
        this.reset();
    }
    /**
     * Check whether or not the service is active or not.
     *
     * @returns {boolean}
     */
    isActive() {
        return this._active;
    }
    /**
     * Reset the processing context, clear buffers, cancel the timeout trigger.
     *
     * @returns {void}
     */
    reset() {
        this._processing = false;
        this._scoreArray = [];
        this._audioLvlArray = [];
        clearTimeout(this._processTimeout);
    }
    /**
     * Listens for {@link TrackVADEmitter} events and processes them.
     *
     * @param {Object} vadScore -VAD score emitted by {@link TrackVADEmitter}
     * @param {Date}   vadScore.timestamp - Exact time at which processed PCM sample was generated.
     * @param {number} vadScore.score - VAD score on a scale from 0 to 1 (i.e. 0.7)
     * @param {Float32Array} vadScore.pcmData - Raw PCM Data associated with the VAD score.
     * @param {string} vadScore.deviceId - Device id of the associated track.
     * @listens VAD_SCORE_PUBLISHED
     */
    processVADScore(vadScore) {
        if (!this._active) {
            return;
        }
        // There is a processing phase on going, add score to buffer array.
        if (this._processing) {
            // Filter and calculate sample average so we don't have to process one large array at a time.
            const posAudioLevels = (0,_util_MathUtil__WEBPACK_IMPORTED_MODULE_1__.filterPositiveValues)(vadScore.pcmData);
            this._recordValues(vadScore.score, (0,_util_MathUtil__WEBPACK_IMPORTED_MODULE_1__.calculateAverage)(posAudioLevels));
            return;
        }
        // If the VAD score for the sample is low and audio level has a high enough level we can start listening for
        // noise
        if (vadScore.score < VAD_SCORE_TRIGGER) {
            const posAudioLevels = (0,_util_MathUtil__WEBPACK_IMPORTED_MODULE_1__.filterPositiveValues)(vadScore.pcmData);
            const avgAudioLvl = (0,_util_MathUtil__WEBPACK_IMPORTED_MODULE_1__.calculateAverage)(posAudioLevels);
            if (avgAudioLvl > AUDIO_LEVEL_SCORE_TRIGGER) {
                this._processing = true;
                this._recordValues(vadScore.score, avgAudioLvl);
                // Once the preset timeout executes the final score will be calculated.
                this._processTimeout = setTimeout(this._calculateNoisyScore, PROCESS_TIME_FRAME_SPAN_MS);
            }
        }
    }
}
//# sourceMappingURL=VADNoiseDetection.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/detection/VADTalkMutedDetection.js":
/*!************************************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/detection/VADTalkMutedDetection.js ***!
  \************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (/* binding */ VADTalkMutedDetection)
/* harmony export */ });
/* harmony import */ var events__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! events */ "./node_modules/events/events.js");
/* harmony import */ var events__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(events__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var _util_MathUtil__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../util/MathUtil */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/util/MathUtil.js");
/* harmony import */ var _DetectionEvents__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./DetectionEvents */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/detection/DetectionEvents.js");



/**
 * The threshold which the average VAD values for a span of time needs to exceed to trigger an event.
 * @type {number}
 */
const VAD_AVG_THRESHOLD = 0.6;
/**
 * The VAD score needed to trigger the processing algorithm, i.e. if a sample has the VAD score >= VAD_VOICE_LEVEL
 * we start processing all scores for a time span defined by const PROCESS_TIME_FRAME_SPAN_MS.
 * @type {number}
 */
const VAD_VOICE_LEVEL = 0.9;
/**
 * Sample rate of TrackVADEmitter, it defines how many audio samples are processed at a time.
 * @type {number}
 */
/**
 * Time span over which we calculate an average score used to determine if we trigger the event.
 * @type {number}
 */
const PROCESS_TIME_FRAME_SPAN_MS = 700;
/**
 * Detect if provided VAD score which is generated on a muted device is voice and fires an event.
 */
class VADTalkMutedDetection extends events__WEBPACK_IMPORTED_MODULE_0__.EventEmitter {
    /**
     * Creates <tt>VADTalkMutedDetection</tt>
     * @constructor
     */
    constructor() {
        super();
        /**
         * Flag which denotes the current state of the detection service i.e.if there is already a processing operation
         * ongoing.
         */
        this._processing = false;
        /**
         * Buffer that keeps the VAD scores for a period of time.
         */
        this._scoreArray = [];
        /**
         * Current mute state of the audio track being monitored.
         */
        this._active = false;
        this._calculateVADScore = this._calculateVADScore.bind(this);
    }
    /**
     * Compute cumulative VAD score function called once the PROCESS_TIME_FRAME_SPAN_MS timeout has elapsed.
     * @returns {void}
     * @fires VAD_TALK_WHILE_MUTED
     */
    _calculateVADScore() {
        const score = (0,_util_MathUtil__WEBPACK_IMPORTED_MODULE_1__.calculateAverage)(this._scoreArray);
        if (score > VAD_AVG_THRESHOLD) {
            this.emit(_DetectionEvents__WEBPACK_IMPORTED_MODULE_2__.VAD_TALK_WHILE_MUTED);
            // Event was fired. Stop event emitter and remove listeners so no residue events kick off after this point
            // and a single VAD_TALK_WHILE_MUTED is generated per mic muted state.
            this._setActiveState(false);
        }
        // We reset the context in case a new process phase needs to be triggered.
        this.reset();
    }
    /**
     * Set the active state of the detection service and notify any listeners.
     *
     * @param {boolean} active
     * @fires DETECTOR_STATE_CHANGE
     */
    _setActiveState(active) {
        this._active = active;
        this.emit(_DetectionEvents__WEBPACK_IMPORTED_MODULE_2__.DETECTOR_STATE_CHANGE, this._active);
    }
    /**
     * Change the state according to the muted status of the tracked device.
     *
     * @param {boolean} isMuted - Is the device muted or not.
     */
    changeMuteState(isMuted) {
        // This service only needs to run when the microphone is muted.
        this._setActiveState(isMuted);
        this.reset();
    }
    /**
     * Check whether or not the service is active or not.
     *
     * @returns {boolean}
     */
    isActive() {
        return this._active;
    }
    /**
     * Listens for {@link TrackVADEmitter} events and processes them.
     *
     * @param {Object} vadScore -VAD score emitted by {@link TrackVADEmitter}
     * @param {Date}   vadScore.timestamp - Exact time at which processed PCM sample was generated.
     * @param {number} vadScore.score - VAD score on a scale from 0 to 1 (i.e. 0.7)
     * @param {string} vadScore.deviceId - Device id of the associated track.
     * @listens VAD_SCORE_PUBLISHED
     */
    processVADScore(vadScore) {
        if (!this._active) {
            return;
        }
        // There is a processing phase on going, add score to buffer array.
        if (this._processing) {
            this._scoreArray.push(vadScore.score);
            return;
        }
        // Because we remove all listeners on the vadEmitter once the main event is triggered,
        // there is no need to check for rogue events.
        if (vadScore.score > VAD_VOICE_LEVEL) {
            this._processing = true;
            this._scoreArray.push(vadScore.score);
            // Start gathering VAD scores for the configured period of time.
            this._processTimeout = setTimeout(this._calculateVADScore, PROCESS_TIME_FRAME_SPAN_MS);
        }
    }
    /**
     * Reset the processing context, clear buffer, cancel the timeout trigger.
     *
     * @returns {void}
     */
    reset() {
        this._processing = false;
        this._scoreArray = [];
        clearTimeout(this._processTimeout);
    }
}
//# sourceMappingURL=VADTalkMutedDetection.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/e2ee/E2EEContext.js":
/*!*********************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/e2ee/E2EEContext.js ***!
  \*********************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
var __filename = "/index.js";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (/* binding */ E2EEcontext)
/* harmony export */ });
/* harmony import */ var _jitsi_logger__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @jitsi/logger */ "./node_modules/@jitsi/logger/lib/index.js");
/* harmony import */ var _jitsi_logger__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(_jitsi_logger__WEBPACK_IMPORTED_MODULE_0__);
/* global RTCRtpScriptTransform */

const logger = (0,_jitsi_logger__WEBPACK_IMPORTED_MODULE_0__.getLogger)(__filename);
// Flag to set on senders / receivers to avoid setting up the encryption transform
// more than once.
const kJitsiE2EE = Symbol('kJitsiE2EE');
/**
 * Context encapsulating the cryptography bits required for E2EE.
 * This uses the WebRTC Insertable Streams API which is explained in
 *   https://github.com/alvestrand/webrtc-media-streams/blob/master/explainer.md
 * that provides access to the encoded frames and allows them to be transformed.
 *
 * The encoded frame format is explained below in the _encodeFunction method.
 * High level design goals were:
 * - do not require changes to existing SFUs and retain (VP8) metadata.
 * - allow the SFU to rewrite SSRCs, timestamp, pictureId.
 * - allow for the key to be rotated frequently.
 */
class E2EEcontext {
    /**
     * Build a new E2EE context instance, which will be used in a given conference.
     * @param {boolean} [options.sharedKey] - whether there is a uniques key shared amoung all participants.
     */
    constructor({ sharedKey } = {}) {
        // Determine the URL for the worker script. Relative URLs are relative to
        // the entry point, not the script that launches the worker.
        let baseUrl = '';
        const ljm = document.querySelector('script[src*="lib-jitsi-meet"]');
        if (ljm) {
            const idx = ljm.src.lastIndexOf('/');
            baseUrl = `${ljm.src.substring(0, idx)}/`;
        }
        let workerUrl = `${baseUrl}lib-jitsi-meet.e2ee-worker.js`;
        // If there is no baseUrl then we create the worker in a normal way
        // as you cant load scripts inside blobs from relative paths.
        // See: https://www.html5rocks.com/en/tutorials/workers/basics/#toc-inlineworkers-loadingscripts
        if (baseUrl && baseUrl !== '/') {
            // Initialize the E2EE worker. In order to avoid CORS issues, start the worker and have it
            // synchronously load the JS.
            const workerBlob = new Blob([`importScripts("${workerUrl}");`], { type: 'application/javascript' });
            workerUrl = window.URL.createObjectURL(workerBlob);
        }
        this._worker = new Worker(workerUrl, { name: 'E2EE Worker' });
        this._worker.onerror = e => logger.error(e);
        this._worker.postMessage({
            operation: 'initialize',
            sharedKey
        });
    }
    /**
     * Cleans up all state associated with the given participant. This is needed when a
     * participant leaves the current conference.
     *
     * @param {string} participantId - The participant that just left.
     */
    cleanup(participantId) {
        this._worker.postMessage({
            operation: 'cleanup',
            participantId
        });
    }
    /**
     * Cleans up all state associated with all participants in the conference. This is needed when disabling e2ee.
     *
     */
    cleanupAll() {
        this._worker.postMessage({
            operation: 'cleanupAll'
        });
    }
    /**
     * Handles the given {@code RTCRtpReceiver} by creating a {@code TransformStream} which will inject
     * a frame decoder.
     *
     * @param {RTCRtpReceiver} receiver - The receiver which will get the decoding function injected.
     * @param {string} kind - The kind of track this receiver belongs to.
     * @param {string} participantId - The participant id that this receiver belongs to.
     */
    handleReceiver(receiver, kind, participantId) {
        if (receiver[kJitsiE2EE]) {
            return;
        }
        receiver[kJitsiE2EE] = true;
        if (window.RTCRtpScriptTransform) {
            const options = {
                operation: 'decode',
                participantId
            };
            receiver.transform = new RTCRtpScriptTransform(this._worker, options);
        }
        else {
            const receiverStreams = receiver.createEncodedStreams();
            this._worker.postMessage({
                operation: 'decode',
                readableStream: receiverStreams.readable,
                writableStream: receiverStreams.writable,
                participantId
            }, [receiverStreams.readable, receiverStreams.writable]);
        }
    }
    /**
     * Handles the given {@code RTCRtpSender} by creating a {@code TransformStream} which will inject
     * a frame encoder.
     *
     * @param {RTCRtpSender} sender - The sender which will get the encoding function injected.
     * @param {string} kind - The kind of track this sender belongs to.
     * @param {string} participantId - The participant id that this sender belongs to.
     */
    handleSender(sender, kind, participantId) {
        if (sender[kJitsiE2EE]) {
            return;
        }
        sender[kJitsiE2EE] = true;
        if (window.RTCRtpScriptTransform) {
            const options = {
                operation: 'encode',
                participantId
            };
            sender.transform = new RTCRtpScriptTransform(this._worker, options);
        }
        else {
            const senderStreams = sender.createEncodedStreams();
            this._worker.postMessage({
                operation: 'encode',
                readableStream: senderStreams.readable,
                writableStream: senderStreams.writable,
                participantId
            }, [senderStreams.readable, senderStreams.writable]);
        }
    }
    /**
     * Set the E2EE key for the specified participant.
     *
     * @param {string} participantId - the ID of the participant who's key we are setting.
     * @param {Uint8Array | boolean} key - they key for the given participant.
     * @param {Number} keyIndex - the key index.
     */
    setKey(participantId, key, keyIndex) {
        this._worker.postMessage({
            operation: 'setKey',
            key,
            keyIndex,
            participantId
        });
    }
}
//# sourceMappingURL=E2EEContext.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/e2ee/E2EEErrors.js":
/*!********************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/e2ee/E2EEErrors.js ***!
  \********************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   E2EEErrors: () => (/* binding */ E2EEErrors)
/* harmony export */ });
var E2EEErrors;
(function (E2EEErrors) {
    E2EEErrors["E2EE_SAS_KEYS_MAC_MISMATCH"] = "e2ee.sas.keys-mac-mismatch";
    E2EEErrors["E2EE_SAS_MAC_MISMATCH"] = "e2ee.sas.mac-mismatch";
    E2EEErrors["E2EE_SAS_MISSING_KEY"] = "e2ee.sas.missing-key";
    E2EEErrors["E2EE_SAS_COMMITMENT_MISMATCHED"] = "e2ee.sas.commitment-mismatched";
    E2EEErrors["E2EE_SAS_CHANNEL_VERIFICATION_FAILED"] = "e2ee.sas.channel-verification-failed";
    E2EEErrors["E2EE_SAS_INVALID_SAS_VERIFICATION"] = "e2ee.sas.invalid-sas-verification";
})(E2EEErrors || (E2EEErrors = {}));
//# sourceMappingURL=E2EEErrors.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/e2ee/E2EEncryption.js":
/*!***********************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/e2ee/E2EEncryption.js ***!
  \***********************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   E2EEncryption: () => (/* binding */ E2EEncryption)
/* harmony export */ });
/* harmony import */ var _browser__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../browser */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/browser/index.js");
/* harmony import */ var _ExternallyManagedKeyHandler__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./ExternallyManagedKeyHandler */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/e2ee/ExternallyManagedKeyHandler.js");
/* harmony import */ var _ManagedKeyHandler__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./ManagedKeyHandler */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/e2ee/ManagedKeyHandler.js");
/* harmony import */ var _OlmAdapter__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./OlmAdapter */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/e2ee/OlmAdapter.js");
var __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {
    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};




/**
 * This module integrates {@link KeyHandler} with {@link JitsiConference} in order to enable E2E encryption.
 */
class E2EEncryption {
    /**
     * A constructor.
     * @param {JitsiConference} conference - The conference instance for which E2E encryption is to be enabled.
     */
    constructor(conference) {
        const { e2ee = {} } = conference.options.config;
        this._externallyManaged = e2ee.externallyManagedKey;
        if (this._externallyManaged) {
            this._keyHandler = new _ExternallyManagedKeyHandler__WEBPACK_IMPORTED_MODULE_1__.ExternallyManagedKeyHandler(conference);
        }
        else {
            this._keyHandler = new _ManagedKeyHandler__WEBPACK_IMPORTED_MODULE_2__.ManagedKeyHandler(conference);
        }
    }
    /**
     * Indicates if E2EE is supported in the current platform.
     *
     * @param {object} config - Global configuration.
     * @returns {boolean}
     */
    static isSupported(config) {
        const { e2ee = {} } = config;
        if (!e2ee.externallyManagedKey && !_OlmAdapter__WEBPACK_IMPORTED_MODULE_3__.OlmAdapter.isSupported()) {
            return false;
        }
        return !(config.testing && config.testing.disableE2EE)
            && (_browser__WEBPACK_IMPORTED_MODULE_0__["default"].supportsInsertableStreams()
                || (config.enableEncodedTransformSupport && _browser__WEBPACK_IMPORTED_MODULE_0__["default"].supportsEncodedTransform()));
    }
    /**
     * Indicates whether E2EE is currently enabled or not.
     *
     * @returns {boolean}
     */
    isEnabled() {
        return this._keyHandler.isEnabled();
    }
    /**
     * Enables / disables End-To-End encryption.
     *
     * @param {boolean} enabled - whether E2EE should be enabled or not.
     * @returns {void}
     */
    setEnabled(enabled) {
        return __awaiter(this, void 0, void 0, function* () {
            yield this._keyHandler.setEnabled(enabled);
        });
    }
    /**
     * Sets the key and index for End-to-End encryption.
     *
     * @param {CryptoKey} [keyInfo.encryptionKey] - encryption key.
     * @param {Number} [keyInfo.index] - the index of the encryption key.
     * @returns {void}
     */
    setEncryptionKey(keyInfo) {
        this._keyHandler.setKey(keyInfo);
    }
    /**
     * Starts the verification process of the participant
     *
     * @param {Participant} - participant to be verified.
     * @returns {void}
     */
    startVerification(participant) {
        var _a;
        (_a = this._keyHandler.sasVerification) === null || _a === void 0 ? void 0 : _a.startVerification(participant);
    }
    /**
     * Marks the channel as verified
     *
     * @param {Participant} - participant to be verified.
     * @param {boolean} isVerified - whether the verification was succesfull.
     * @returns {void}
     */
    markParticipantVerified(participant, isVerified) {
        var _a;
        (_a = this._keyHandler.sasVerification) === null || _a === void 0 ? void 0 : _a.markParticipantVerified(participant, isVerified);
    }
}
//# sourceMappingURL=E2EEncryption.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/e2ee/ExternallyManagedKeyHandler.js":
/*!*************************************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/e2ee/ExternallyManagedKeyHandler.js ***!
  \*************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   ExternallyManagedKeyHandler: () => (/* binding */ ExternallyManagedKeyHandler)
/* harmony export */ });
/* harmony import */ var _KeyHandler__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./KeyHandler */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/e2ee/KeyHandler.js");

/**
 * This module integrates {@link E2EEContext} with {external} in order to set the keys for encryption.
 */
class ExternallyManagedKeyHandler extends _KeyHandler__WEBPACK_IMPORTED_MODULE_0__.KeyHandler {
    /**
     * Build a new ExternallyManagedKeyHandler instance, which will be used in a given conference.
     * @param conference - the current conference.
     */
    constructor(conference) {
        super(conference, { sharedKey: true });
    }
    /**
     * Sets the key and index for End-to-End encryption.
     *
     * @param {CryptoKey} [keyInfo.encryptionKey] - encryption key.
     * @param {Number} [keyInfo.index] - the index of the encryption key.
     * @returns {void}
     */
    setKey(keyInfo) {
        this.e2eeCtx.setKey(undefined, { encryptionKey: keyInfo.encryptionKey }, keyInfo.index);
    }
}
//# sourceMappingURL=ExternallyManagedKeyHandler.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/e2ee/KeyHandler.js":
/*!********************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/e2ee/KeyHandler.js ***!
  \********************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
var __filename = "/index.js";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   KeyHandler: () => (/* binding */ KeyHandler)
/* harmony export */ });
/* harmony import */ var _jitsi_logger__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @jitsi/logger */ "./node_modules/@jitsi/logger/lib/index.js");
/* harmony import */ var _jitsi_logger__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(_jitsi_logger__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var _JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../JitsiConferenceEvents */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/JitsiConferenceEvents.js");
/* harmony import */ var _service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../service/RTC/RTCEvents */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/RTC/RTCEvents.js");
/* harmony import */ var _browser__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../browser */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/browser/index.js");
/* harmony import */ var _util_Deferred__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../util/Deferred */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/util/Deferred.js");
/* harmony import */ var _util_Listenable__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../util/Listenable */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/util/Listenable.js");
/* harmony import */ var _E2EEContext__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./E2EEContext */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/e2ee/E2EEContext.js");
var __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {
    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};







const logger = (0,_jitsi_logger__WEBPACK_IMPORTED_MODULE_0__.getLogger)(__filename);
/**
 * Abstract class that integrates {@link E2EEContext} with a key management system.
 */
class KeyHandler extends _util_Listenable__WEBPACK_IMPORTED_MODULE_5__["default"] {
    /**
     * Build a new KeyHandler instance, which will be used in a given conference.
     * @param {JitsiConference} conference - the current conference.
     * @param {object} options - the options passed to {E2EEContext}, see implemention.
     */
    constructor(conference, options = {}) {
        super();
        this.conference = conference;
        this.e2eeCtx = new _E2EEContext__WEBPACK_IMPORTED_MODULE_6__["default"](options);
        this.enabled = false;
        this._enabling = undefined;
        // Conference media events in order to attach the encryptor / decryptor.
        // FIXME add events to TraceablePeerConnection which will allow to see when there's new receiver or sender
        // added instead of shenanigans around conference track events and track muted.
        //
        this.conference.on(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_1__._MEDIA_SESSION_STARTED, this._onMediaSessionStarted.bind(this));
        this.conference.on(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_1__.TRACK_ADDED, track => track.isLocal() && this._onLocalTrackAdded(track));
        this.conference.rtc.on(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_2__["default"].REMOTE_TRACK_ADDED, (track, tpc) => this._setupReceiverE2EEForTrack(tpc, track));
        this.conference.on(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_1__.TRACK_MUTE_CHANGED, this._trackMuteChanged.bind(this));
    }
    /**
     * Indicates whether E2EE is currently enabled or not.
     *
     * @returns {boolean}
     */
    isEnabled() {
        return this.enabled;
    }
    /**
     * Enables / disables End-To-End encryption.
     *
     * @param {boolean} enabled - whether E2EE should be enabled or not.
     * @returns {void}
     */
    setEnabled(enabled) {
        return __awaiter(this, void 0, void 0, function* () {
            this._enabling && (yield this._enabling);
            if (enabled === this.enabled) {
                return;
            }
            this._enabling = new _util_Deferred__WEBPACK_IMPORTED_MODULE_4__["default"]();
            this.enabled = enabled;
            if (!enabled) {
                this.e2eeCtx.cleanupAll();
            }
            this._setEnabled && (yield this._setEnabled(enabled));
            this.conference.setLocalParticipantProperty('e2ee.enabled', enabled);
            this.conference._restartMediaSessions();
            this._enabling.resolve();
        });
    }
    /**
     * Sets the key for End-to-End encryption.
     *
     * @returns {void}
     */
    setEncryptionKey() {
        throw new Error('Not implemented by subclass');
    }
    /**
     * Setup E2EE on the new track that has been added to the conference, apply it on all the open peerconnections.
     * @param {JitsiLocalTrack} track - the new track that's being added to the conference.
     * @private
     */
    _onLocalTrackAdded(track) {
        for (const session of this.conference.getMediaSessions()) {
            this._setupSenderE2EEForTrack(session, track);
        }
    }
    /**
     * Setups E2E encryption for the new session.
     * @param {JingleSessionPC} session - the new media session.
     * @private
     */
    _onMediaSessionStarted(session) {
        const localTracks = this.conference.getLocalTracks();
        for (const track of localTracks) {
            this._setupSenderE2EEForTrack(session, track);
        }
    }
    /**
     * Setup E2EE for the receiving side.
     *
     * @private
     */
    _setupReceiverE2EEForTrack(tpc, track) {
        if (!this.enabled) {
            return;
        }
        const receiver = tpc.findReceiverForTrack(track.track);
        if (receiver) {
            this.e2eeCtx.handleReceiver(receiver, track.getType(), track.getParticipantId());
        }
        else {
            logger.warn(`Could not handle E2EE for ${track}: receiver not found in: ${tpc}`);
        }
    }
    /**
     * Setup E2EE for the sending side.
     *
     * @param {JingleSessionPC} session - the session which sends the media produced by the track.
     * @param {JitsiLocalTrack} track - the local track for which e2e encoder will be configured.
     * @private
     */
    _setupSenderE2EEForTrack(session, track) {
        if (!this.enabled) {
            return;
        }
        const pc = session.peerconnection;
        const sender = pc && pc.findSenderForTrack(track.track);
        if (sender) {
            this.e2eeCtx.handleSender(sender, track.getType(), track.getParticipantId());
        }
        else {
            logger.warn(`Could not handle E2EE for ${track}: sender not found in ${pc}`);
        }
    }
    /**
     * Setup E2EE on the sender that is created for the unmuted local video track.
     * @param {JitsiLocalTrack} track - the track for which muted status has changed.
     * @private
     */
    _trackMuteChanged(track) {
        if (_browser__WEBPACK_IMPORTED_MODULE_3__["default"].doesVideoMuteByStreamRemove() && track.isLocal() && track.isVideoTrack() && !track.isMuted()) {
            for (const session of this.conference.getMediaSessions()) {
                this._setupSenderE2EEForTrack(session, track);
            }
        }
    }
}
//# sourceMappingURL=KeyHandler.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/e2ee/ManagedKeyHandler.js":
/*!***************************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/e2ee/ManagedKeyHandler.js ***!
  \***************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
var __filename = "/index.js";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   ManagedKeyHandler: () => (/* binding */ ManagedKeyHandler)
/* harmony export */ });
/* harmony import */ var _jitsi_logger__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @jitsi/logger */ "./node_modules/@jitsi/logger/lib/index.js");
/* harmony import */ var _jitsi_logger__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(_jitsi_logger__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var lodash_debounce__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! lodash.debounce */ "./node_modules/lodash.debounce/index.js");
/* harmony import */ var lodash_debounce__WEBPACK_IMPORTED_MODULE_1___default = /*#__PURE__*/__webpack_require__.n(lodash_debounce__WEBPACK_IMPORTED_MODULE_1__);
/* harmony import */ var _JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../JitsiConferenceEvents */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/JitsiConferenceEvents.js");
/* harmony import */ var _KeyHandler__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./KeyHandler */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/e2ee/KeyHandler.js");
/* harmony import */ var _OlmAdapter__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./OlmAdapter */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/e2ee/OlmAdapter.js");
/* harmony import */ var _crypto_utils__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./crypto-utils */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/e2ee/crypto-utils.js");
var __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {
    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};






const logger = (0,_jitsi_logger__WEBPACK_IMPORTED_MODULE_0__.getLogger)(__filename);
// Period which we'll wait before updating / rotating our keys when a participant
// joins or leaves.
const DEBOUNCE_PERIOD = 5000;
/**
 * This module integrates {@link E2EEContext} with {@link OlmAdapter} in order to distribute the keys for encryption.
 */
class ManagedKeyHandler extends _KeyHandler__WEBPACK_IMPORTED_MODULE_3__.KeyHandler {
    /**
     * Build a new AutomaticKeyHandler instance, which will be used in a given conference.
     */
    constructor(conference) {
        super(conference);
        this._key = undefined;
        this._conferenceJoined = false;
        this._olmAdapter = new _OlmAdapter__WEBPACK_IMPORTED_MODULE_4__.OlmAdapter(conference);
        this._rotateKey = lodash_debounce__WEBPACK_IMPORTED_MODULE_1___default()(this._rotateKeyImpl, DEBOUNCE_PERIOD);
        this._ratchetKey = lodash_debounce__WEBPACK_IMPORTED_MODULE_1___default()(this._ratchetKeyImpl, DEBOUNCE_PERIOD);
        // Olm signalling events.
        this._olmAdapter.on(_OlmAdapter__WEBPACK_IMPORTED_MODULE_4__.OlmAdapter.events.PARTICIPANT_KEY_UPDATED, this._onParticipantKeyUpdated.bind(this));
        this._olmAdapter.on(_OlmAdapter__WEBPACK_IMPORTED_MODULE_4__.OlmAdapter.events.PARTICIPANT_SAS_READY, this._onParticipantSasReady.bind(this));
        this._olmAdapter.on(_OlmAdapter__WEBPACK_IMPORTED_MODULE_4__.OlmAdapter.events.PARTICIPANT_SAS_AVAILABLE, this._onParticipantSasAvailable.bind(this));
        this._olmAdapter.on(_OlmAdapter__WEBPACK_IMPORTED_MODULE_4__.OlmAdapter.events.PARTICIPANT_VERIFICATION_COMPLETED, this._onParticipantVerificationCompleted.bind(this));
        this.conference.on(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_2__.PARTICIPANT_PROPERTY_CHANGED, this._onParticipantPropertyChanged.bind(this));
        this.conference.on(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_2__.USER_JOINED, this._onParticipantJoined.bind(this));
        this.conference.on(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_2__.USER_LEFT, this._onParticipantLeft.bind(this));
        this.conference.on(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_2__.CONFERENCE_JOINED, () => {
            this._conferenceJoined = true;
        });
    }
    /**
     * Returns the sasVerficiation object.
     *
     * @returns {Object}
     */
    get sasVerification() {
        return this._olmAdapter;
    }
    /**
     * When E2EE is enabled it initializes sessions and sets the key.
     * Cleans up the sessions when disabled.
     *
     * @param {boolean} enabled - whether E2EE should be enabled or not.
     * @returns {void}
     */
    _setEnabled(enabled) {
        return __awaiter(this, void 0, void 0, function* () {
            if (enabled) {
                yield this._olmAdapter.initSessions();
            }
            else {
                this._olmAdapter.clearAllParticipantsSessions();
            }
            // Generate a random key in case we are enabling.
            this._key = enabled ? this._generateKey() : false;
            // Send it to others using the E2EE olm channel.
            const index = yield this._olmAdapter.updateKey(this._key);
            // Set our key so we begin encrypting.
            this.e2eeCtx.setKey(this.conference.myUserId(), this._key, index);
        });
    }
    /**
     * Handles an update in a participant's presence property.
     *
     * @param {JitsiParticipant} participant - The participant.
     * @param {string} name - The name of the property that changed.
     * @param {*} oldValue - The property's previous value.
     * @param {*} newValue - The property's new value.
     * @private
     */
    _onParticipantPropertyChanged(participant, name, oldValue, newValue) {
        return __awaiter(this, void 0, void 0, function* () {
            switch (name) {
                case 'e2ee.idKey':
                    logger.debug(`Participant ${participant.getId()} updated their id key: ${newValue}`);
                    break;
                case 'e2ee.enabled':
                    if (!newValue && this.enabled) {
                        this._olmAdapter.clearParticipantSession(participant);
                    }
                    break;
            }
        });
    }
    /**
     * Advances (using ratcheting) the current key when a new participant joins the conference.
     * @private
     */
    _onParticipantJoined() {
        if (this._conferenceJoined && this.enabled) {
            this._ratchetKey();
        }
    }
    /**
     * Rotates the current key when a participant leaves the conference.
     * @private
     */
    _onParticipantLeft(id) {
        this.e2eeCtx.cleanup(id);
        if (this.enabled) {
            this._rotateKey();
        }
    }
    /**
     * Rotates the local key. Rotating the key implies creating a new one, then distributing it
     * to all participants and once they all received it, start using it.
     *
     * @private
     */
    _rotateKeyImpl() {
        return __awaiter(this, void 0, void 0, function* () {
            logger.debug('Rotating key');
            this._key = this._generateKey();
            const index = yield this._olmAdapter.updateKey(this._key);
            this.e2eeCtx.setKey(this.conference.myUserId(), this._key, index);
        });
    }
    /**
     * Advances the current key by using ratcheting.
     *
     * @private
     */
    _ratchetKeyImpl() {
        return __awaiter(this, void 0, void 0, function* () {
            logger.debug('Ratchetting key');
            const material = yield (0,_crypto_utils__WEBPACK_IMPORTED_MODULE_5__.importKey)(this._key);
            const newKey = yield (0,_crypto_utils__WEBPACK_IMPORTED_MODULE_5__.ratchet)(material);
            this._key = new Uint8Array(newKey);
            const index = this._olmAdapter.updateCurrentMediaKey(this._key);
            this.e2eeCtx.setKey(this.conference.myUserId(), this._key, index);
        });
    }
    /**
     * Handles an update in a participant's key.
     *
     * @param {string} id - The participant ID.
     * @param {Uint8Array | boolean} key - The new key for the participant.
     * @param {Number} index - The new key's index.
     * @private
     */
    _onParticipantKeyUpdated(id, key, index) {
        logger.debug(`Participant ${id} updated their key`);
        this.e2eeCtx.setKey(id, key, index);
    }
    /**
     * Handles the SAS ready event.
     *
     * @param {string} pId - The participant ID.
     * @param {Uint8Array} sas - The bytes from sas.generate_bytes..
     * @private
     */
    _onParticipantSasReady(pId, sas) {
        this.conference.eventEmitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_2__.E2EE_VERIFICATION_READY, pId, sas);
    }
    /**
     * Handles the sas available event.
     *
     * @param {string} pId - The participant ID.
     * @private
     */
    _onParticipantSasAvailable(pId) {
        this.conference.eventEmitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_2__.E2EE_VERIFICATION_AVAILABLE, pId);
    }
    /**
     * Handles the SAS completed event.
     *
     * @param {string} pId - The participant ID.
     * @param {boolean} success - Wheter the verification was succesfull.
     * @private
     */
    _onParticipantVerificationCompleted(pId, success, message) {
        this.conference.eventEmitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_2__.E2EE_VERIFICATION_COMPLETED, pId, success, message);
    }
    /**
     * Generates a new 256 bit random key.
     *
     * @returns {Uint8Array}
     * @private
     */
    _generateKey() {
        return window.crypto.getRandomValues(new Uint8Array(32));
    }
}
//# sourceMappingURL=ManagedKeyHandler.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/e2ee/OlmAdapter.js":
/*!********************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/e2ee/OlmAdapter.js ***!
  \********************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
var __filename = "/index.js";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   OlmAdapter: () => (/* binding */ OlmAdapter)
/* harmony export */ });
/* harmony import */ var _jitsi_logger__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @jitsi/logger */ "./node_modules/@jitsi/logger/lib/index.js");
/* harmony import */ var _jitsi_logger__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(_jitsi_logger__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var base64_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! base64-js */ "./node_modules/base64-js/index.js");
/* harmony import */ var lodash_isequal__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! lodash.isequal */ "./node_modules/lodash.isequal/index.js");
/* harmony import */ var lodash_isequal__WEBPACK_IMPORTED_MODULE_2___default = /*#__PURE__*/__webpack_require__.n(lodash_isequal__WEBPACK_IMPORTED_MODULE_2__);
/* harmony import */ var uuid__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! uuid */ "./node_modules/uuid/wrapper.mjs");
/* harmony import */ var _JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../JitsiConferenceEvents */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/JitsiConferenceEvents.js");
/* harmony import */ var _util_Deferred__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../util/Deferred */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/util/Deferred.js");
/* harmony import */ var _util_Listenable__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../util/Listenable */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/util/Listenable.js");
/* harmony import */ var _xmpp_xmpp__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../xmpp/xmpp */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/xmpp/xmpp.js");
/* harmony import */ var _E2EEErrors__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./E2EEErrors */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/e2ee/E2EEErrors.js");
/* harmony import */ var _SAS__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ./SAS */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/e2ee/SAS.js");
/* global Olm */
var __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {
    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};










const logger = (0,_jitsi_logger__WEBPACK_IMPORTED_MODULE_0__.getLogger)(__filename);
const REQ_TIMEOUT = 5 * 1000;
const OLM_MESSAGE_TYPE = 'olm';
const OLM_MESSAGE_TYPES = {
    ERROR: 'error',
    KEY_INFO: 'key-info',
    KEY_INFO_ACK: 'key-info-ack',
    SESSION_ACK: 'session-ack',
    SESSION_INIT: 'session-init',
    SAS_START: 'sas-start',
    SAS_ACCEPT: 'sas-accept',
    SAS_KEY: 'sas-key',
    SAS_MAC: 'sas-mac'
};
const OLM_SAS_NUM_BYTES = 6;
const OLM_KEY_VERIFICATION_MAC_INFO = 'Jitsi-KEY_VERIFICATION_MAC';
const OLM_KEY_VERIFICATION_MAC_KEY_IDS = 'Jitsi-KEY_IDS';
const kOlmData = Symbol('OlmData');
const OlmAdapterEvents = {
    PARTICIPANT_E2EE_CHANNEL_READY: 'olm.participant_e2ee_channel_ready',
    PARTICIPANT_SAS_AVAILABLE: 'olm.participant_sas_available',
    PARTICIPANT_SAS_READY: 'olm.participant_sas_ready',
    PARTICIPANT_KEY_UPDATED: 'olm.partitipant_key_updated',
    PARTICIPANT_VERIFICATION_COMPLETED: 'olm.participant_verification_completed'
};
/**
 * This class implements an End-to-End Encrypted communication channel between every two peers
 * in the conference. This channel uses libolm to achieve E2EE.
 *
 * The created channel is then used to exchange the secret key that each participant will use
 * to encrypt the actual media (see {@link E2EEContext}).
 *
 * A simple JSON message based protocol is implemented, which follows a request - response model:
 * - session-init: Initiates an olm session establishment procedure. This message will be sent
 *                 by the participant who just joined, to everyone else.
 * - session-ack: Completes the olm session etablishment. This messsage may contain ancilliary
 *                encrypted data, more specifically the sender's current key.
 * - key-info: Includes the sender's most up to date key information.
 * - key-info-ack: Acknowledges the reception of a key-info request. In addition, it may contain
 *                 the sender's key information, if available.
 * - error: Indicates a request processing error has occurred.
 *
 * These requessts and responses are transport independent. Currently they are sent using XMPP
 * MUC private messages.
 */
class OlmAdapter extends _util_Listenable__WEBPACK_IMPORTED_MODULE_5__["default"] {
    /**
     * Creates an adapter instance for the given conference.
     */
    constructor(conference) {
        super();
        this._conf = conference;
        this._init = new _util_Deferred__WEBPACK_IMPORTED_MODULE_4__["default"]();
        this._mediaKey = undefined;
        this._mediaKeyIndex = -1;
        this._reqs = new Map();
        this._sessionInitialization = undefined;
        if (OlmAdapter.isSupported()) {
            this._bootstrapOlm();
            this._conf.on(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_3__.ENDPOINT_MESSAGE_RECEIVED, this._onEndpointMessageReceived.bind(this));
            this._conf.on(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_3__.CONFERENCE_LEFT, this._onConferenceLeft.bind(this));
            this._conf.on(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_3__.USER_LEFT, this._onParticipantLeft.bind(this));
            this._conf.on(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_3__.PARTICIPANT_PROPERTY_CHANGED, this._onParticipantPropertyChanged.bind(this));
        }
        else {
            this._init.reject(new Error('Olm not supported'));
        }
    }
    /**
     * Returns the current participants conference ID.
     *
     * @returns {string}
     */
    get myId() {
        return this._conf.myUserId();
    }
    /**
     * Starts new olm sessions with every other participant that has the participantId "smaller" the localParticipantId.
     */
    initSessions() {
        return __awaiter(this, void 0, void 0, function* () {
            if (this._sessionInitialization) {
                throw new Error('OlmAdapter initSessions called multiple times');
            }
            else {
                this._sessionInitialization = new _util_Deferred__WEBPACK_IMPORTED_MODULE_4__["default"]();
                yield this._init;
                const promises = [];
                const localParticipantId = this._conf.myUserId();
                for (const participant of this._conf.getParticipants()) {
                    if (participant.hasFeature(_xmpp_xmpp__WEBPACK_IMPORTED_MODULE_6__.FEATURE_E2EE) && localParticipantId < participant.getId()) {
                        promises.push(this._sendSessionInit(participant));
                    }
                }
                yield Promise.allSettled(promises);
                // TODO: retry failed ones.
                this._sessionInitialization.resolve();
                this._sessionInitialization = undefined;
            }
        });
    }
    /**
     * Indicates if olm is supported on the current platform.
     *
     * @returns {boolean}
     */
    static isSupported() {
        return typeof window.Olm !== 'undefined';
    }
    /**
     * Updates the current participant key and distributes it to all participants in the conference
     * by sending a key-info message.
     *
     * @param {Uint8Array|boolean} key - The new key.
     * @retrns {Promise<Number>}
     */
    updateKey(key) {
        return __awaiter(this, void 0, void 0, function* () {
            // Store it locally for new sessions.
            this._mediaKey = key;
            this._mediaKeyIndex++;
            // Broadcast it.
            const promises = [];
            for (const participant of this._conf.getParticipants()) {
                const pId = participant.getId();
                const olmData = this._getParticipantOlmData(participant);
                // TODO: skip those who don't support E2EE.
                if (!olmData.session) {
                    logger.warn(`Tried to send key to participant ${pId} but we have no session`);
                    // eslint-disable-next-line no-continue
                    continue;
                }
                const uuid = (0,uuid__WEBPACK_IMPORTED_MODULE_9__.v4)();
                const data = {
                    [_xmpp_xmpp__WEBPACK_IMPORTED_MODULE_6__.JITSI_MEET_MUC_TYPE]: OLM_MESSAGE_TYPE,
                    olm: {
                        type: OLM_MESSAGE_TYPES.KEY_INFO,
                        data: {
                            ciphertext: this._encryptKeyInfo(olmData.session),
                            uuid
                        }
                    }
                };
                const d = new _util_Deferred__WEBPACK_IMPORTED_MODULE_4__["default"]();
                d.setRejectTimeout(REQ_TIMEOUT);
                d.catch(() => {
                    this._reqs.delete(uuid);
                });
                this._reqs.set(uuid, d);
                promises.push(d);
                this._sendMessage(data, pId);
            }
            yield Promise.allSettled(promises);
            // TODO: retry failed ones?
            return this._mediaKeyIndex;
        });
    }
    /**
     * Updates the current participant key.
     * @param {Uint8Array|boolean} key - The new key.
     * @returns {number}
    */
    updateCurrentMediaKey(key) {
        this._mediaKey = key;
        return this._mediaKeyIndex;
    }
    /**
     * Frees the olmData session for the given participant.
     *
     */
    clearParticipantSession(participant) {
        const olmData = this._getParticipantOlmData(participant);
        if (olmData.session) {
            olmData.session.free();
            olmData.session = undefined;
        }
    }
    /**
     * Frees the olmData sessions for all participants.
     *
     */
    clearAllParticipantsSessions() {
        for (const participant of this._conf.getParticipants()) {
            this.clearParticipantSession(participant);
        }
    }
    /**
     * Sends sacMac if channel verification waas successful.
     *
     */
    markParticipantVerified(participant, isVerified) {
        const olmData = this._getParticipantOlmData(participant);
        const pId = participant.getId();
        if (!isVerified) {
            olmData.sasVerification = undefined;
            logger.warn(`Verification failed for participant ${pId}`);
            this.eventEmitter.emit(OlmAdapterEvents.PARTICIPANT_VERIFICATION_COMPLETED, pId, false, _E2EEErrors__WEBPACK_IMPORTED_MODULE_7__.E2EEErrors.E2EE_SAS_CHANNEL_VERIFICATION_FAILED);
            return;
        }
        if (!olmData.sasVerification) {
            logger.warn(`Participant ${pId} does not have valid sasVerification`);
            this.eventEmitter.emit(OlmAdapterEvents.PARTICIPANT_VERIFICATION_COMPLETED, pId, false, _E2EEErrors__WEBPACK_IMPORTED_MODULE_7__.E2EEErrors.E2EE_SAS_INVALID_SAS_VERIFICATION);
            return;
        }
        const { sas, sasMacSent } = olmData.sasVerification;
        if (sas && sas.is_their_key_set() && !sasMacSent) {
            this._sendSasMac(participant);
            // Mark the MAC as sent so we don't send it multiple times.
            olmData.sasVerification.sasMacSent = true;
        }
    }
    /**
     * Internal helper to bootstrap the olm library.
     *
     * @returns {Promise<void>}
     * @private
     */
    _bootstrapOlm() {
        return __awaiter(this, void 0, void 0, function* () {
            logger.debug('Initializing Olm...');
            try {
                yield Olm.init();
                this._olmAccount = new Olm.Account();
                this._olmAccount.create();
                this._idKeys = JSON.parse(this._olmAccount.identity_keys());
                logger.debug(`Olm ${Olm.get_library_version().join('.')} initialized`);
                this._init.resolve();
                this._onIdKeysReady(this._idKeys);
            }
            catch (e) {
                logger.error('Failed to initialize Olm', e);
                this._init.reject(e);
            }
        });
    }
    /**
     * Starts the verification process for the given participant as described here
     * https://spec.matrix.org/latest/client-server-api/#short-authentication-string-sas-verification
     *
     *    |                                 |
          | m.key.verification.start        |
          |-------------------------------->|
          |                                 |
          |       m.key.verification.accept |
          |<--------------------------------|
          |                                 |
          | m.key.verification.key          |
          |-------------------------------->|
          |                                 |
          |          m.key.verification.key |
          |<--------------------------------|
          |                                 |
          | m.key.verification.mac          |
          |-------------------------------->|
          |                                 |
          |          m.key.verification.mac |
          |<--------------------------------|
          |                                 |
     *
     * @param {JitsiParticipant} participant - The target participant.
     * @returns {Promise<void>}
     * @private
     */
    startVerification(participant) {
        const pId = participant.getId();
        const olmData = this._getParticipantOlmData(participant);
        if (!olmData.session) {
            logger.warn(`Tried to start verification with participant ${pId} but we have no session`);
            return;
        }
        if (olmData.sasVerification) {
            logger.warn(`There is already a verification in progress with participant ${pId}`);
            return;
        }
        olmData.sasVerification = {
            sas: new Olm.SAS(),
            transactionId: (0,uuid__WEBPACK_IMPORTED_MODULE_9__.v4)()
        };
        const startContent = {
            transactionId: olmData.sasVerification.transactionId
        };
        olmData.sasVerification.startContent = startContent;
        olmData.sasVerification.isInitiator = true;
        const startMessage = {
            [_xmpp_xmpp__WEBPACK_IMPORTED_MODULE_6__.JITSI_MEET_MUC_TYPE]: OLM_MESSAGE_TYPE,
            olm: {
                type: OLM_MESSAGE_TYPES.SAS_START,
                data: startContent
            }
        };
        this._sendMessage(startMessage, pId);
    }
    /**
     * Publishes our own Olmn id key in presence.
     * @private
     */
    _onIdKeysReady(idKeys) {
        logger.debug(`Olm id key ready: ${idKeys}`);
        // Publish it in presence.
        for (const keyType in idKeys) {
            if (idKeys.hasOwnProperty(keyType)) {
                const key = idKeys[keyType];
                this._conf.setLocalParticipantProperty(`e2ee.idKey.${keyType}`, key);
            }
        }
    }
    /**
     * Event posted when the E2EE signalling channel has been established with the given participant.
     * @private
     */
    _onParticipantE2EEChannelReady(id) {
        logger.debug(`E2EE channel with participant ${id} is ready`);
    }
    /**
     * Internal helper for encrypting the current key information for a given participant.
     *
     * @param {Olm.Session} session - Participant's session.
     * @returns {string} - The encrypted text with the key information.
     * @private
     */
    _encryptKeyInfo(session) {
        const keyInfo = {};
        if (this._mediaKey !== undefined) {
            keyInfo.key = this._mediaKey ? base64_js__WEBPACK_IMPORTED_MODULE_1__.fromByteArray(this._mediaKey) : false;
            keyInfo.keyIndex = this._mediaKeyIndex;
        }
        return session.encrypt(JSON.stringify(keyInfo));
    }
    /**
     * Internal helper for getting the olm related data associated with a participant.
     *
     * @param {JitsiParticipant} participant - Participant whose data wants to be extracted.
     * @returns {Object}
     * @private
     */
    _getParticipantOlmData(participant) {
        participant[kOlmData] = participant[kOlmData] || {};
        return participant[kOlmData];
    }
    /**
     * Handles leaving the conference, cleaning up olm sessions.
     *
     * @private
     */
    _onConferenceLeft() {
        return __awaiter(this, void 0, void 0, function* () {
            logger.debug('Conference left');
            yield this._init;
            for (const participant of this._conf.getParticipants()) {
                this._onParticipantLeft(participant.getId(), participant);
            }
            if (this._olmAccount) {
                this._olmAccount.free();
                this._olmAccount = undefined;
            }
        });
    }
    /**
     * Main message handler. Handles 1-to-1 messages received from other participants
     * and send the appropriate replies.
     *
     * @private
     */
    _onEndpointMessageReceived(participant, payload) {
        var _a;
        return __awaiter(this, void 0, void 0, function* () {
            if (payload[_xmpp_xmpp__WEBPACK_IMPORTED_MODULE_6__.JITSI_MEET_MUC_TYPE] !== OLM_MESSAGE_TYPE) {
                return;
            }
            if (!payload.olm) {
                logger.warn('Incorrectly formatted message');
                return;
            }
            yield this._init;
            const msg = payload.olm;
            const pId = participant.getId();
            const olmData = this._getParticipantOlmData(participant);
            switch (msg.type) {
                case OLM_MESSAGE_TYPES.SESSION_INIT: {
                    if (olmData.session) {
                        logger.warn(`Participant ${pId} already has a session`);
                        this._sendError(participant, 'Session already established');
                    }
                    else {
                        // Create a session for communicating with this participant.
                        const session = new Olm.Session();
                        session.create_outbound(this._olmAccount, msg.data.idKey, msg.data.otKey);
                        olmData.session = session;
                        // Send ACK
                        const ack = {
                            [_xmpp_xmpp__WEBPACK_IMPORTED_MODULE_6__.JITSI_MEET_MUC_TYPE]: OLM_MESSAGE_TYPE,
                            olm: {
                                type: OLM_MESSAGE_TYPES.SESSION_ACK,
                                data: {
                                    ciphertext: this._encryptKeyInfo(session),
                                    uuid: msg.data.uuid
                                }
                            }
                        };
                        this._sendMessage(ack, pId);
                        this._onParticipantE2EEChannelReady(pId);
                    }
                    break;
                }
                case OLM_MESSAGE_TYPES.SESSION_ACK: {
                    if (olmData.session) {
                        logger.warn(`Participant ${pId} already has a session`);
                        this._sendError(participant, 'No session found');
                    }
                    else if (msg.data.uuid === olmData.pendingSessionUuid) {
                        const { ciphertext } = msg.data;
                        const d = this._reqs.get(msg.data.uuid);
                        const session = new Olm.Session();
                        session.create_inbound(this._olmAccount, ciphertext.body);
                        // Remove OT keys that have been used to setup this session.
                        this._olmAccount.remove_one_time_keys(session);
                        // Decrypt first message.
                        const data = session.decrypt(ciphertext.type, ciphertext.body);
                        olmData.session = session;
                        olmData.pendingSessionUuid = undefined;
                        this._onParticipantE2EEChannelReady(pId);
                        this._reqs.delete(msg.data.uuid);
                        d.resolve();
                        const json = safeJsonParse(data);
                        if (json.key) {
                            const key = base64_js__WEBPACK_IMPORTED_MODULE_1__.toByteArray(json.key);
                            const keyIndex = json.keyIndex;
                            olmData.lastKey = key;
                            this.eventEmitter.emit(OlmAdapterEvents.PARTICIPANT_KEY_UPDATED, pId, key, keyIndex);
                        }
                    }
                    else {
                        logger.warn('Received ACK with the wrong UUID');
                        this._sendError(participant, 'Invalid UUID');
                    }
                    break;
                }
                case OLM_MESSAGE_TYPES.ERROR: {
                    logger.error(msg.data.error);
                    break;
                }
                case OLM_MESSAGE_TYPES.KEY_INFO: {
                    if (olmData.session) {
                        const { ciphertext } = msg.data;
                        const data = olmData.session.decrypt(ciphertext.type, ciphertext.body);
                        const json = safeJsonParse(data);
                        if (json.key !== undefined && json.keyIndex !== undefined) {
                            const key = json.key ? base64_js__WEBPACK_IMPORTED_MODULE_1__.toByteArray(json.key) : false;
                            const keyIndex = json.keyIndex;
                            if (!lodash_isequal__WEBPACK_IMPORTED_MODULE_2___default()(olmData.lastKey, key)) {
                                olmData.lastKey = key;
                                this.eventEmitter.emit(OlmAdapterEvents.PARTICIPANT_KEY_UPDATED, pId, key, keyIndex);
                            }
                            // Send ACK.
                            const ack = {
                                [_xmpp_xmpp__WEBPACK_IMPORTED_MODULE_6__.JITSI_MEET_MUC_TYPE]: OLM_MESSAGE_TYPE,
                                olm: {
                                    type: OLM_MESSAGE_TYPES.KEY_INFO_ACK,
                                    data: {
                                        ciphertext: this._encryptKeyInfo(olmData.session),
                                        uuid: msg.data.uuid
                                    }
                                }
                            };
                            this._sendMessage(ack, pId);
                        }
                    }
                    else {
                        logger.debug(`Received key info message from ${pId} but we have no session for them!`);
                        this._sendError(participant, 'No session found while processing key-info');
                    }
                    break;
                }
                case OLM_MESSAGE_TYPES.KEY_INFO_ACK: {
                    if (olmData.session) {
                        const { ciphertext } = msg.data;
                        const data = olmData.session.decrypt(ciphertext.type, ciphertext.body);
                        const json = safeJsonParse(data);
                        if (json.key !== undefined && json.keyIndex !== undefined) {
                            const key = json.key ? base64_js__WEBPACK_IMPORTED_MODULE_1__.toByteArray(json.key) : false;
                            const keyIndex = json.keyIndex;
                            if (!lodash_isequal__WEBPACK_IMPORTED_MODULE_2___default()(olmData.lastKey, key)) {
                                olmData.lastKey = key;
                                this.eventEmitter.emit(OlmAdapterEvents.PARTICIPANT_KEY_UPDATED, pId, key, keyIndex);
                            }
                        }
                        const d = this._reqs.get(msg.data.uuid);
                        this._reqs.delete(msg.data.uuid);
                        d.resolve();
                    }
                    else {
                        logger.debug(`Received key info ack message from ${pId} but we have no session for them!`);
                        this._sendError(participant, 'No session found while processing key-info-ack');
                    }
                    break;
                }
                case OLM_MESSAGE_TYPES.SAS_START: {
                    if (!olmData.session) {
                        logger.debug(`Received sas init message from ${pId} but we have no session for them!`);
                        this._sendError(participant, 'No session found while processing sas-init');
                        return;
                    }
                    if ((_a = olmData.sasVerification) === null || _a === void 0 ? void 0 : _a.sas) {
                        logger.warn(`SAS already created for participant ${pId}`);
                        this.eventEmitter.emit(OlmAdapterEvents.PARTICIPANT_VERIFICATION_COMPLETED, pId, false, _E2EEErrors__WEBPACK_IMPORTED_MODULE_7__.E2EEErrors.E2EE_SAS_INVALID_SAS_VERIFICATION);
                        return;
                    }
                    const { transactionId } = msg.data;
                    const sas = new Olm.SAS();
                    olmData.sasVerification = {
                        sas,
                        transactionId,
                        isInitiator: false
                    };
                    const pubKey = olmData.sasVerification.sas.get_pubkey();
                    const commitment = this._computeCommitment(pubKey, msg.data);
                    /* The first phase of the verification process, the Key agreement phase
                        https://spec.matrix.org/latest/client-server-api/#short-authentication-string-sas-verification
                    */
                    const acceptMessage = {
                        [_xmpp_xmpp__WEBPACK_IMPORTED_MODULE_6__.JITSI_MEET_MUC_TYPE]: OLM_MESSAGE_TYPE,
                        olm: {
                            type: OLM_MESSAGE_TYPES.SAS_ACCEPT,
                            data: {
                                transactionId,
                                commitment
                            }
                        }
                    };
                    this._sendMessage(acceptMessage, pId);
                    break;
                }
                case OLM_MESSAGE_TYPES.SAS_ACCEPT: {
                    if (!olmData.session) {
                        logger.debug(`Received sas accept message from ${pId} but we have no session for them!`);
                        this._sendError(participant, 'No session found while processing sas-accept');
                        return;
                    }
                    const { commitment, transactionId } = msg.data;
                    if (!olmData.sasVerification) {
                        logger.warn(`SAS_ACCEPT Participant ${pId} does not have valid sasVerification`);
                        this.eventEmitter.emit(OlmAdapterEvents.PARTICIPANT_VERIFICATION_COMPLETED, pId, false, _E2EEErrors__WEBPACK_IMPORTED_MODULE_7__.E2EEErrors.E2EE_SAS_INVALID_SAS_VERIFICATION);
                        return;
                    }
                    if (olmData.sasVerification.sasCommitment) {
                        logger.debug(`Already received sas commitment message from ${pId}!`);
                        this._sendError(participant, 'Already received sas commitment message from ${pId}!');
                        return;
                    }
                    olmData.sasVerification.sasCommitment = commitment;
                    const pubKey = olmData.sasVerification.sas.get_pubkey();
                    // Send KEY.
                    const keyMessage = {
                        [_xmpp_xmpp__WEBPACK_IMPORTED_MODULE_6__.JITSI_MEET_MUC_TYPE]: OLM_MESSAGE_TYPE,
                        olm: {
                            type: OLM_MESSAGE_TYPES.SAS_KEY,
                            data: {
                                key: pubKey,
                                transactionId
                            }
                        }
                    };
                    this._sendMessage(keyMessage, pId);
                    olmData.sasVerification.keySent = true;
                    break;
                }
                case OLM_MESSAGE_TYPES.SAS_KEY: {
                    if (!olmData.session) {
                        logger.debug(`Received sas key message from ${pId} but we have no session for them!`);
                        this._sendError(participant, 'No session found while processing sas-key');
                        return;
                    }
                    if (!olmData.sasVerification) {
                        logger.warn(`SAS_KEY Participant ${pId} does not have valid sasVerification`);
                        this.eventEmitter.emit(OlmAdapterEvents.PARTICIPANT_VERIFICATION_COMPLETED, pId, false, _E2EEErrors__WEBPACK_IMPORTED_MODULE_7__.E2EEErrors.E2EE_SAS_INVALID_SAS_VERIFICATION);
                        return;
                    }
                    const { isInitiator, sas, sasCommitment, startContent, keySent } = olmData.sasVerification;
                    if (sas.is_their_key_set()) {
                        logger.warn('SAS already has their key!');
                        return;
                    }
                    const { key: theirKey, transactionId } = msg.data;
                    if (sasCommitment) {
                        const commitment = this._computeCommitment(theirKey, startContent);
                        if (sasCommitment !== commitment) {
                            this._sendError(participant, 'OlmAdapter commitments mismatched');
                            this.eventEmitter.emit(OlmAdapterEvents.PARTICIPANT_VERIFICATION_COMPLETED, pId, false, _E2EEErrors__WEBPACK_IMPORTED_MODULE_7__.E2EEErrors.E2EE_SAS_COMMITMENT_MISMATCHED);
                            olmData.sasVerification.free();
                            return;
                        }
                    }
                    sas.set_their_key(theirKey);
                    const pubKey = sas.get_pubkey();
                    const myInfo = `${this.myId}|${pubKey}`;
                    const theirInfo = `${pId}|${theirKey}`;
                    const info = isInitiator ? `${myInfo}|${theirInfo}` : `${theirInfo}|${myInfo}`;
                    const sasBytes = sas.generate_bytes(info, OLM_SAS_NUM_BYTES);
                    const generatedSas = (0,_SAS__WEBPACK_IMPORTED_MODULE_8__.generateSas)(sasBytes);
                    this.eventEmitter.emit(OlmAdapterEvents.PARTICIPANT_SAS_READY, pId, generatedSas);
                    if (keySent) {
                        return;
                    }
                    const keyMessage = {
                        [_xmpp_xmpp__WEBPACK_IMPORTED_MODULE_6__.JITSI_MEET_MUC_TYPE]: OLM_MESSAGE_TYPE,
                        olm: {
                            type: OLM_MESSAGE_TYPES.SAS_KEY,
                            data: {
                                key: pubKey,
                                transactionId
                            }
                        }
                    };
                    this._sendMessage(keyMessage, pId);
                    olmData.sasVerification.keySent = true;
                    break;
                }
                case OLM_MESSAGE_TYPES.SAS_MAC: {
                    if (!olmData.session) {
                        logger.debug(`Received sas mac message from ${pId} but we have no session for them!`);
                        this._sendError(participant, 'No session found while processing sas-mac');
                        return;
                    }
                    const { keys, mac, transactionId } = msg.data;
                    if (!mac || !keys) {
                        logger.warn('Invalid SAS MAC message');
                        return;
                    }
                    if (!olmData.sasVerification) {
                        logger.warn(`SAS_MAC Participant ${pId} does not have valid sasVerification`);
                        return;
                    }
                    const sas = olmData.sasVerification.sas;
                    // Verify the received MACs.
                    const baseInfo = `${OLM_KEY_VERIFICATION_MAC_INFO}${pId}${this.myId}${transactionId}`;
                    const keysMac = sas.calculate_mac(Object.keys(mac).sort().join(','), // eslint-disable-line newline-per-chained-call
                    baseInfo + OLM_KEY_VERIFICATION_MAC_KEY_IDS);
                    if (keysMac !== keys) {
                        logger.error('SAS verification error: keys MAC mismatch');
                        this.eventEmitter.emit(OlmAdapterEvents.PARTICIPANT_VERIFICATION_COMPLETED, pId, false, _E2EEErrors__WEBPACK_IMPORTED_MODULE_7__.E2EEErrors.E2EE_SAS_KEYS_MAC_MISMATCH);
                        return;
                    }
                    if (!olmData.ed25519) {
                        logger.warn('SAS verification error: Missing ed25519 key');
                        this.eventEmitter.emit(OlmAdapterEvents.PARTICIPANT_VERIFICATION_COMPLETED, pId, false, _E2EEErrors__WEBPACK_IMPORTED_MODULE_7__.E2EEErrors.E2EE_SAS_MISSING_KEY);
                        return;
                    }
                    for (const [keyInfo, computedMac] of Object.entries(mac)) {
                        const ourComputedMac = sas.calculate_mac(olmData.ed25519, baseInfo + keyInfo);
                        if (computedMac !== ourComputedMac) {
                            logger.error('SAS verification error: MAC mismatch');
                            this.eventEmitter.emit(OlmAdapterEvents.PARTICIPANT_VERIFICATION_COMPLETED, pId, false, _E2EEErrors__WEBPACK_IMPORTED_MODULE_7__.E2EEErrors.E2EE_SAS_MAC_MISMATCH);
                            return;
                        }
                    }
                    logger.info(`SAS MAC verified for participant ${pId}`);
                    this.eventEmitter.emit(OlmAdapterEvents.PARTICIPANT_VERIFICATION_COMPLETED, pId, true);
                    break;
                }
            }
        });
    }
    /**
     * Handles a participant leaving. When a participant leaves their olm session is destroyed.
     *
     * @private
     */
    _onParticipantLeft(id, participant) {
        logger.debug(`Participant ${id} left`);
        this.clearParticipantSession(participant);
    }
    /**
    * Handles an update in a participant's presence property.
    *
    * @param {JitsiParticipant} participant - The participant.
    * @param {string} name - The name of the property that changed.
    * @param {*} oldValue - The property's previous value.
    * @param {*} newValue - The property's new value.
    * @private
    */
    _onParticipantPropertyChanged(participant, name, oldValue, newValue) {
        return __awaiter(this, void 0, void 0, function* () {
            const participantId = participant.getId();
            const olmData = this._getParticipantOlmData(participant);
            switch (name) {
                case 'e2ee.enabled':
                    if (newValue && this._conf.isE2EEEnabled()) {
                        const localParticipantId = this._conf.myUserId();
                        const participantFeatures = yield participant.getFeatures();
                        if (participantFeatures.has(_xmpp_xmpp__WEBPACK_IMPORTED_MODULE_6__.FEATURE_E2EE) && localParticipantId < participantId) {
                            if (this._sessionInitialization) {
                                yield this._sessionInitialization;
                            }
                            yield this._sendSessionInit(participant);
                            const uuid = (0,uuid__WEBPACK_IMPORTED_MODULE_9__.v4)();
                            const d = new _util_Deferred__WEBPACK_IMPORTED_MODULE_4__["default"]();
                            d.setRejectTimeout(REQ_TIMEOUT);
                            d.catch(() => {
                                this._reqs.delete(uuid);
                                olmData.pendingSessionUuid = undefined;
                            });
                            this._reqs.set(uuid, d);
                            const data = {
                                [_xmpp_xmpp__WEBPACK_IMPORTED_MODULE_6__.JITSI_MEET_MUC_TYPE]: OLM_MESSAGE_TYPE,
                                olm: {
                                    type: OLM_MESSAGE_TYPES.KEY_INFO,
                                    data: {
                                        ciphertext: this._encryptKeyInfo(olmData.session),
                                        uuid
                                    }
                                }
                            };
                            this._sendMessage(data, participantId);
                        }
                    }
                    break;
                case 'e2ee.idKey.ed25519':
                    olmData.ed25519 = newValue;
                    this.eventEmitter.emit(OlmAdapterEvents.PARTICIPANT_SAS_AVAILABLE, participantId);
                    break;
            }
        });
    }
    /**
     * Builds and sends an error message to the target participant.
     *
     * @param {JitsiParticipant} participant - The target participant.
     * @param {string} error - The error message.
     * @returns {void}
     */
    _sendError(participant, error) {
        const pId = participant.getId();
        const err = {
            [_xmpp_xmpp__WEBPACK_IMPORTED_MODULE_6__.JITSI_MEET_MUC_TYPE]: OLM_MESSAGE_TYPE,
            olm: {
                type: OLM_MESSAGE_TYPES.ERROR,
                data: {
                    error
                }
            }
        };
        this._sendMessage(err, pId);
    }
    /**
     * Internal helper to send the given object to the given participant ID.
     * This function merely exists so the transport can be easily swapped.
     * Currently messages are transmitted via XMPP MUC private messages.
     *
     * @param {object} data - The data that will be sent to the target participant.
     * @param {string} participantId - ID of the target participant.
     */
    _sendMessage(data, participantId) {
        this._conf.sendMessage(data, participantId);
    }
    /**
     * Builds and sends the session-init request to the target participant.
     *
     * @param {JitsiParticipant} participant - Participant to whom we'll send the request.
     * @returns {Promise} - The promise will be resolved when the session-ack is received.
     * @private
     */
    _sendSessionInit(participant) {
        const pId = participant.getId();
        const olmData = this._getParticipantOlmData(participant);
        if (olmData.session) {
            logger.warn(`Tried to send session-init to ${pId} but we already have a session`);
            return Promise.reject();
        }
        if (olmData.pendingSessionUuid !== undefined) {
            logger.warn(`Tried to send session-init to ${pId} but we already have a pending session`);
            return Promise.reject();
        }
        // Generate a One Time Key.
        this._olmAccount.generate_one_time_keys(1);
        const otKeys = JSON.parse(this._olmAccount.one_time_keys());
        const otKey = Object.values(otKeys.curve25519)[0];
        if (!otKey) {
            return Promise.reject(new Error('No one-time-keys generated'));
        }
        // Mark the OT keys (one really) as published so they are not reused.
        this._olmAccount.mark_keys_as_published();
        const uuid = (0,uuid__WEBPACK_IMPORTED_MODULE_9__.v4)();
        const init = {
            [_xmpp_xmpp__WEBPACK_IMPORTED_MODULE_6__.JITSI_MEET_MUC_TYPE]: OLM_MESSAGE_TYPE,
            olm: {
                type: OLM_MESSAGE_TYPES.SESSION_INIT,
                data: {
                    idKey: this._idKeys.curve25519,
                    otKey,
                    uuid
                }
            }
        };
        const d = new _util_Deferred__WEBPACK_IMPORTED_MODULE_4__["default"]();
        d.setRejectTimeout(REQ_TIMEOUT);
        d.catch(() => {
            this._reqs.delete(uuid);
            olmData.pendingSessionUuid = undefined;
        });
        this._reqs.set(uuid, d);
        this._sendMessage(init, pId);
        // Store the UUID for matching with the ACK.
        olmData.pendingSessionUuid = uuid;
        return d;
    }
    /**
     * Builds and sends the SAS MAC message to the given participant.
     * The second phase of the verification process, the Key verification phase
        https://spec.matrix.org/latest/client-server-api/#short-authentication-string-sas-verification
     */
    _sendSasMac(participant) {
        const pId = participant.getId();
        const olmData = this._getParticipantOlmData(participant);
        const { sas, transactionId } = olmData.sasVerification;
        // Calculate and send MAC with the keys to be verified.
        const mac = {};
        const keyList = [];
        const baseInfo = `${OLM_KEY_VERIFICATION_MAC_INFO}${this.myId}${pId}${transactionId}`;
        const deviceKeyId = `ed25519:${pId}`;
        mac[deviceKeyId] = sas.calculate_mac(this._idKeys.ed25519, baseInfo + deviceKeyId);
        keyList.push(deviceKeyId);
        const keys = sas.calculate_mac(keyList.sort().join(','), baseInfo + OLM_KEY_VERIFICATION_MAC_KEY_IDS);
        const macMessage = {
            [_xmpp_xmpp__WEBPACK_IMPORTED_MODULE_6__.JITSI_MEET_MUC_TYPE]: OLM_MESSAGE_TYPE,
            olm: {
                type: OLM_MESSAGE_TYPES.SAS_MAC,
                data: {
                    keys,
                    mac,
                    transactionId
                }
            }
        };
        this._sendMessage(macMessage, pId);
    }
    /**
     * Computes the commitment.
     */
    _computeCommitment(pubKey, data) {
        const olmUtil = new Olm.Utility();
        const commitment = olmUtil.sha256(pubKey + JSON.stringify(data));
        olmUtil.free();
        return commitment;
    }
}
/**
 * Helper to ensure JSON parsing always returns an object.
 *
 * @param {string} data - The data that needs to be parsed.
 * @returns {object} - Parsed data or empty object in case of failure.
 */
function safeJsonParse(data) {
    try {
        return JSON.parse(data);
    }
    catch (e) {
        return {};
    }
}
OlmAdapter.events = OlmAdapterEvents;
//# sourceMappingURL=OlmAdapter.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/e2ee/SAS.js":
/*!*************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/e2ee/SAS.js ***!
  \*************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   generateSas: () => (/* binding */ generateSas)
/* harmony export */ });
/* eslint-disable no-bitwise */
/* eslint-disable no-mixed-operators */
/**
 * Generates a SAS composed of decimal numbers.
 * Borrowed from the Matrix JS SDK.
 *
 * @param {Uint8Array} sasBytes - The bytes from sas.generate_bytes.
 * @returns Array<number>
 */
function generateDecimalSas(sasBytes) {
    /**
     *      +--------+--------+--------+--------+--------+
     *      | Byte 0 | Byte 1 | Byte 2 | Byte 3 | Byte 4 |
     *      +--------+--------+--------+--------+--------+
     * bits: 87654321 87654321 87654321 87654321 87654321
     *       \____________/\_____________/\____________/
     *         1st number    2nd number     3rd number
     */
    return [
        (sasBytes[0] << 5 | sasBytes[1] >> 3) + 1000,
        ((sasBytes[1] & 0x7) << 10 | sasBytes[2] << 2 | sasBytes[3] >> 6) + 1000,
        ((sasBytes[3] & 0x3f) << 7 | sasBytes[4] >> 1) + 1000
    ];
}
const emojiMapping = [
    ['', 'dog'],
    ['', 'cat'],
    ['', 'lion'],
    ['', 'horse'],
    ['', 'unicorn'],
    ['', 'pig'],
    ['', 'elephant'],
    ['', 'rabbit'],
    ['', 'panda'],
    ['', 'rooster'],
    ['', 'penguin'],
    ['', 'turtle'],
    ['', 'fish'],
    ['', 'octopus'],
    ['', 'butterfly'],
    ['', 'flower'],
    ['', 'tree'],
    ['', 'cactus'],
    ['', 'mushroom'],
    ['', 'globe'],
    ['', 'moon'],
    ['', 'cloud'],
    ['', 'fire'],
    ['', 'banana'],
    ['', 'apple'],
    ['', 'strawberry'],
    ['', 'corn'],
    ['', 'pizza'],
    ['', 'cake'],
    ['', 'heart'],
    ['', 'smiley'],
    ['', 'robot'],
    ['', 'hat'],
    ['', 'glasses'],
    ['', 'spanner'],
    ['', 'santa'],
    ['', 'thumbs up'],
    ['', 'umbrella'],
    ['', 'hourglass'],
    ['', 'clock'],
    ['', 'gift'],
    ['', 'light bulb'],
    ['', 'book'],
    ['', 'pencil'],
    ['', 'paperclip'],
    ['', 'scissors'],
    ['', 'lock'],
    ['', 'key'],
    ['', 'hammer'],
    ['', 'telephone'],
    ['', 'flag'],
    ['', 'train'],
    ['', 'bicycle'],
    ['', 'aeroplane'],
    ['', 'rocket'],
    ['', 'trophy'],
    ['', 'ball'],
    ['', 'guitar'],
    ['', 'trumpet'],
    ['', 'bell'],
    ['', 'anchor'],
    ['', 'headphones'],
    ['', 'folder'],
    ['', 'pin']
];
/**
 * Generates a SAS composed of defimal numbers.
 * Borrowed from the Matrix JS SDK.
 *
 * @param {Uint8Array} sasBytes - The bytes from sas.generate_bytes.
 * @returns Array<number>
 */
function generateEmojiSas(sasBytes) {
    // Just like base64.
    const emojis = [
        sasBytes[0] >> 2,
        (sasBytes[0] & 0x3) << 4 | sasBytes[1] >> 4,
        (sasBytes[1] & 0xf) << 2 | sasBytes[2] >> 6,
        sasBytes[2] & 0x3f,
        sasBytes[3] >> 2,
        (sasBytes[3] & 0x3) << 4 | sasBytes[4] >> 4,
        (sasBytes[4] & 0xf) << 2 | sasBytes[5] >> 6
    ];
    return emojis.map(num => emojiMapping[num]);
}
const sasGenerators = {
    decimal: generateDecimalSas,
    emoji: generateEmojiSas
};
/**
 * Generates multiple SAS for the given bytes.
 *
 * @param {Uint8Array} sasBytes - The bytes from sas.generate_bytes.
 * @returns {object}
 */
function generateSas(sasBytes) {
    const sas = {};
    for (const method in sasGenerators) {
        if (sasGenerators.hasOwnProperty(method)) {
            sas[method] = sasGenerators[method](sasBytes);
        }
    }
    return sas;
}
//# sourceMappingURL=SAS.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/e2ee/crypto-utils.js":
/*!**********************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/e2ee/crypto-utils.js ***!
  \**********************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   deriveKeys: () => (/* binding */ deriveKeys),
/* harmony export */   importKey: () => (/* binding */ importKey),
/* harmony export */   ratchet: () => (/* binding */ ratchet)
/* harmony export */ });
var __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {
    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};
/**
 * Derives a set of keys from the master key.
 * @param {CryptoKey} material - master key to derive from
 *
 * See https://tools.ietf.org/html/draft-omara-sframe-00#section-4.3.1
 */
function deriveKeys(material) {
    return __awaiter(this, void 0, void 0, function* () {
        const info = new ArrayBuffer();
        const textEncoder = new TextEncoder();
        // https://developer.mozilla.org/en-US/docs/Web/API/SubtleCrypto/deriveKey#HKDF
        // https://developer.mozilla.org/en-US/docs/Web/API/HkdfParams
        const encryptionKey = yield crypto.subtle.deriveKey({
            name: 'HKDF',
            salt: textEncoder.encode('JFrameEncryptionKey'),
            hash: 'SHA-256',
            info
        }, material, {
            name: 'AES-GCM',
            length: 128
        }, false, ['encrypt', 'decrypt']);
        return {
            material,
            encryptionKey
        };
    });
}
/**
 * Ratchets a key. See
 * https://tools.ietf.org/html/draft-omara-sframe-00#section-4.3.5.1
 * @param {CryptoKey} material - base key material
 * @returns {Promise<ArrayBuffer>} - ratcheted key material
 */
function ratchet(material) {
    return __awaiter(this, void 0, void 0, function* () {
        const textEncoder = new TextEncoder();
        // https://developer.mozilla.org/en-US/docs/Web/API/SubtleCrypto/deriveBits
        return crypto.subtle.deriveBits({
            name: 'HKDF',
            salt: textEncoder.encode('JFrameRatchetKey'),
            hash: 'SHA-256',
            info: new ArrayBuffer()
        }, material, 256);
    });
}
/**
 * Converts a raw key into a WebCrypto key object with default options
 * suitable for our usage.
 * @param {ArrayBuffer} keyBytes - raw key
 * @param {Array} keyUsages - key usages, see importKey documentation
 * @returns {Promise<CryptoKey>} - the WebCrypto key.
 */
function importKey(keyBytes) {
    return __awaiter(this, void 0, void 0, function* () {
        // https://developer.mozilla.org/en-US/docs/Web/API/SubtleCrypto/importKey
        return crypto.subtle.importKey('raw', keyBytes, 'HKDF', false, ['deriveBits', 'deriveKey']);
    });
}
//# sourceMappingURL=crypto-utils.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/e2eping/e2eping.js":
/*!********************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/e2eping/e2eping.js ***!
  \********************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
var __filename = "/index.js";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (/* binding */ E2ePing)
/* harmony export */ });
/* harmony import */ var _jitsi_logger__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @jitsi/logger */ "./node_modules/@jitsi/logger/lib/index.js");
/* harmony import */ var _jitsi_logger__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(_jitsi_logger__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var _JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../JitsiConferenceEvents */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/JitsiConferenceEvents.js");
/* harmony import */ var _service_e2eping_E2ePingEvents__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../service/e2eping/E2ePingEvents */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/e2eping/E2ePingEvents.js");



const logger = (0,_jitsi_logger__WEBPACK_IMPORTED_MODULE_0__.getLogger)(__filename);
/**
 * The 'type' of a message which designates an e2e ping request.
 * @type {string}
 */
const E2E_PING_REQUEST = 'e2e-ping-request';
/**
 * The 'type' of a message which designates an e2e ping response.
 * @type {string}
 */
const E2E_PING_RESPONSE = 'e2e-ping-response';
/**
 * The number of requests to wait for before emitting an RTT value.
 */
const DEFAULT_NUM_REQUESTS = 5;
/**
 * The maximum number of messages per second to aim for. This is for the entire
 * conference, with the assumption that all endpoints join at once.
 */
const DEFAULT_MAX_MESSAGES_PER_SECOND = 250;
/**
 * The conference size beyond which e2e pings will be disabled.
 */
const DEFAULT_MAX_CONFERENCE_SIZE = 200;
/**
 * Saves e2e ping related state for a single JitsiParticipant.
 */
class ParticipantWrapper {
    /**
     * Creates a ParticipantWrapper
     * @param {JitsiParticipant} participant - The remote participant that this
     * object wraps.
     * @param {E2ePing} e2eping
     */
    constructor(participant, e2eping) {
        // The JitsiParticipant
        this.participant = participant;
        // The E2ePing
        this.e2eping = e2eping;
        // Caches the ID
        this.id = participant.getId();
        // Recently sent requests
        this.requests = {};
        // The ID of the last sent request. We just increment it for each new
        // request. Start at 1 so we can consider only thruthy values valid.
        this.lastRequestId = 1;
        this.sendRequest = this.sendRequest.bind(this);
        this.handleResponse = this.handleResponse.bind(this);
        this.maybeLogRttAndStop = this.maybeLogRttAndStop.bind(this);
        this.scheduleNext = this.scheduleNext.bind(this);
        this.stop = this.stop.bind(this);
        this.getDelay = this.getDelay.bind(this);
        this.timeout = this.scheduleNext();
    }
    /**
     * Schedule the next ping to be sent.
     */
    scheduleNext() {
        return window.setTimeout(this.sendRequest, this.getDelay());
    }
    /**
     * Stop pinging this participant, canceling a scheduled ping, if any.
     */
    stop() {
        if (this.timeout) {
            window.clearTimeout(this.timeout);
        }
        this.e2eping.removeParticipant(this.id);
    }
    /**
     * Get the delay until the next ping in milliseconds.
     */
    getDelay() {
        const conferenceSize = this.e2eping.conference.getParticipants().length;
        const endpointPairs = conferenceSize * (conferenceSize - 1) / 2;
        const totalMessages = endpointPairs * this.e2eping.numRequests;
        const totalSeconds = totalMessages / this.e2eping.maxMessagesPerSecond;
        // Randomize between .5 and 1.5
        const r = 1.5 - Math.random();
        const delayBetweenMessages = r * Math.max(1000 * (totalSeconds / this.e2eping.numRequests), 1000);
        return delayBetweenMessages;
    }
    /**
     * Sends the next ping request.
     * @type {*}
     */
    sendRequest() {
        const requestId = this.lastRequestId++;
        const requestMessage = {
            type: E2E_PING_REQUEST,
            id: requestId
        };
        this.e2eping.sendMessage(requestMessage, this.id);
        this.requests[requestId] = {
            id: requestId,
            timeSent: window.performance.now()
        };
    }
    /**
     * Handles a response from this participant.
     * @type {*}
     */
    handleResponse(response) {
        const request = this.requests[response.id];
        if (request) {
            request.rtt = window.performance.now() - request.timeSent;
        }
        this.maybeLogRttAndStop();
    }
    /**
     * Check if we've received the pre-configured number of responses, and if
     * so log the measured RTT and stop sending requests.
     * @type {*}
     */
    maybeLogRttAndStop() {
        // The RTT we'll report is the minimum RTT measured
        let rtt = Infinity;
        let request, requestId;
        let numRequestsWithResponses = 0;
        let totalNumRequests = 0;
        for (requestId in this.requests) {
            if (this.requests.hasOwnProperty(requestId)) {
                request = this.requests[requestId];
                totalNumRequests++;
                if (request.rtt) {
                    numRequestsWithResponses++;
                    rtt = Math.min(rtt, request.rtt);
                }
            }
        }
        if (numRequestsWithResponses >= this.e2eping.numRequests) {
            logger.info(`Measured RTT=${rtt} ms to ${this.id} (in ${this.participant.getProperty('region')})`);
            this.stop();
            this.e2eping.conference.eventEmitter.emit(_service_e2eping_E2ePingEvents__WEBPACK_IMPORTED_MODULE_2__.E2E_RTT_CHANGED, this.participant, rtt);
            return;
        }
        else if (totalNumRequests > 2 * this.e2eping.numRequests) {
            logger.info(`Stopping e2eping for ${this.id} because we sent ${totalNumRequests} with only `
                + `${numRequestsWithResponses} responses.`);
            this.stop();
            return;
        }
        this.timeout = this.scheduleNext();
    }
}
/**
 * Implements end-to-end ping (from one conference participant to another) via
 * the jitsi-videobridge channel (either WebRTC data channel or web socket).
 *
 * TODO: use a broadcast message instead of individual pings to each remote
 * participant.
 *
 * This class:
 * 1. Sends periodic ping requests to all other participants in the
 * conference.
 * 2. Responds to ping requests from other participants.
 * 3. Fires events with the end-to-end RTT to each participant whenever a
 * response is received.
 * 4. Fires analytics events with the end-to-end RTT periodically.
 */
class E2ePing {
    /**
     * @param {JitsiConference} conference - The conference.
     * @param {Function} sendMessage - The function to use to send a message.
     * @param {Object} options
     */
    constructor(conference, options, sendMessage) {
        this.conference = conference;
        this.eventEmitter = conference.eventEmitter;
        this.sendMessage = sendMessage;
        // Maps a participant ID to its ParticipantWrapper
        this.participants = {};
        this.numRequests = DEFAULT_NUM_REQUESTS;
        this.maxConferenceSize = DEFAULT_MAX_CONFERENCE_SIZE;
        this.maxMessagesPerSecond = DEFAULT_MAX_MESSAGES_PER_SECOND;
        if (options && options.e2eping) {
            if (typeof options.e2eping.numRequests === 'number') {
                this.numRequests = options.e2eping.numRequests;
            }
            if (typeof options.e2eping.maxConferenceSize === 'number') {
                this.maxConferenceSize = options.e2eping.maxConferenceSize;
            }
            if (typeof options.e2eping.maxMessagesPerSecond === 'number') {
                this.maxMessagesPerSecond = options.e2eping.maxMessagesPerSecond;
            }
        }
        logger.info(`Initializing e2e ping with numRequests=${this.numRequests}, maxConferenceSize=${this.maxConferenceSize}, `
            + `maxMessagesPerSecond=${this.maxMessagesPerSecond}.`);
        this.participantJoined = this.participantJoined.bind(this);
        this.participantLeft = this.participantLeft.bind(this);
        conference.on(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_1__.USER_LEFT, this.participantLeft);
        this.messageReceived = this.messageReceived.bind(this);
        conference.on(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_1__.ENDPOINT_MESSAGE_RECEIVED, this.messageReceived);
        this.conferenceJoined = this.conferenceJoined.bind(this);
        conference.on(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_1__.CONFERENCE_JOINED, this.conferenceJoined);
    }
    /**
     * Delay processing USER_JOINED events until the MUC is fully joined,
     * otherwise the apparent conference size will be wrong.
     */
    conferenceJoined() {
        this.conference.getParticipants().forEach(p => this.participantJoined(p.getId(), p));
        this.conference.on(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_1__.USER_JOINED, this.participantJoined);
    }
    /**
     * Handles a message that was received.
     *
     * @param participant - The message sender.
     * @param payload - The payload of the message.
     */
    messageReceived(participant, payload) {
        // Listen to E2E PING requests and responses from other participants
        // in the conference.
        if (payload.type === E2E_PING_REQUEST) {
            this.handleRequest(participant.getId(), payload);
        }
        else if (payload.type === E2E_PING_RESPONSE) {
            this.handleResponse(participant.getId(), payload);
        }
    }
    /**
     * Handles a participant joining the conference. Starts to send ping
     * requests to the participant.
     *
     * @param {String} id - The ID of the participant.
     * @param {JitsiParticipant} participant - The participant that joined.
     */
    participantJoined(id, participant) {
        if (this.participants[id]) {
            logger.info(`Participant wrapper already exists for ${id}. Clearing.`);
            this.participants[id].stop();
        }
        if (this.conference.getParticipants().length > this.maxConferenceSize) {
            return;
        }
        // We don't need to send e2eping in both directions for a pair of
        // endpoints. Force only one direction with just string comparison of
        // the IDs.
        if (this.conference.myUserId() > id) {
            logger.info(`Starting e2eping for participant ${id}`);
            this.participants[id] = new ParticipantWrapper(participant, this);
        }
    }
    /**
     * Remove a participant without calling "stop".
     */
    removeParticipant(id) {
        if (this.participants[id]) {
            delete this.participants[id];
        }
    }
    /**
     * Handles a participant leaving the conference. Stops sending requests.
     *
     * @param {String} id - The ID of the participant.
     */
    participantLeft(id) {
        if (this.participants[id]) {
            this.participants[id].stop();
            delete this.participants[id];
        }
    }
    /**
     * Handles a ping request coming from another participant.
     *
     * @param {string} participantId - The ID of the participant who sent the
     * request.
     * @param {Object} request - The request.
     */
    handleRequest(participantId, request) {
        // If it's a valid request, just send a response.
        if (request && request.id) {
            const response = {
                type: E2E_PING_RESPONSE,
                id: request.id
            };
            this.sendMessage(response, participantId);
        }
        else {
            logger.info(`Received an invalid e2e ping request from ${participantId}.`);
        }
    }
    /**
     * Handles a ping response coming from another participant
     * @param {string} participantId - The ID of the participant who sent the
     * response.
     * @param {Object} response - The response.
     */
    handleResponse(participantId, response) {
        const participantWrapper = this.participants[participantId];
        if (participantWrapper) {
            participantWrapper.handleResponse(response);
        }
    }
    /**
     * Stops this E2ePing (i.e. stop sending requests).
     */
    stop() {
        logger.info('Stopping e2eping');
        this.conference.off(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_1__.USER_JOINED, this.participantJoined);
        this.conference.off(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_1__.USER_LEFT, this.participantLeft);
        this.conference.off(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_1__.ENDPOINT_MESSAGE_RECEIVED, this.messageReceived);
        for (const id in this.participants) {
            if (this.participants.hasOwnProperty(id)) {
                this.participants[id].stop();
            }
        }
        this.participants = {};
    }
}
//# sourceMappingURL=e2eping.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/event/Jvb121EventGenerator.js":
/*!*******************************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/event/Jvb121EventGenerator.js ***!
  \*******************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
var __filename = "/index.js";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (/* binding */ Jvb121EventGenerator)
/* harmony export */ });
/* harmony import */ var _jitsi_logger__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @jitsi/logger */ "./node_modules/@jitsi/logger/lib/index.js");
/* harmony import */ var _jitsi_logger__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(_jitsi_logger__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var _JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../JitsiConferenceEvents */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/JitsiConferenceEvents.js");


const logger = (0,_jitsi_logger__WEBPACK_IMPORTED_MODULE_0__.getLogger)(__filename);
/**
 * Emits {@link JitsiConferenceEvents.JVB121_STATUS} events based on the current
 * P2P status and the conference participants count. See the event description
 * for more info.
 */
class Jvb121EventGenerator {
    /**
     * Creates new <tt>Jvb121EventGenerator</tt> for the given conference.
     * @param {JitsiConference} conference
     */
    constructor(conference) {
        this._conference = conference;
        /**
         * Indicates whether it's a one to one JVB conference (<tt>true</tt>)
         * or a multiparty (<tt>false</tt>). Will be also <tt>false</tt> if
         * the conference is currently in the P2P mode.
         * @type {boolean}
         * @private
         */
        this._jvb121 = true;
        this._conference.addEventListener(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_1__.USER_JOINED, () => this.evaluateStatus());
        this._conference.addEventListener(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_1__.USER_LEFT, () => this.evaluateStatus());
        this._conference.addEventListener(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_1__.P2P_STATUS, () => this.evaluateStatus());
    }
    /**
     * Checks whether the JVB121 value should be updated and a new event
     * emitted.
     */
    evaluateStatus() {
        const oldStatus = this._jvb121;
        const newStatus = !this._conference.isP2PActive()
            && this._conference.getParticipantCount() <= 2;
        if (oldStatus !== newStatus) {
            this._jvb121 = newStatus;
            logger.debug(`JVB121 status ${oldStatus} => ${newStatus}`);
            this._conference.eventEmitter.emit(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_1__.JVB121_STATUS, oldStatus, newStatus);
        }
    }
}
//# sourceMappingURL=Jvb121EventGenerator.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/flags/FeatureFlags.js":
/*!***********************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/flags/FeatureFlags.js ***!
  \***********************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (__WEBPACK_DEFAULT_EXPORT__)
/* harmony export */ });
/* harmony import */ var _browser__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../browser */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/browser/index.js");

/**
 * A global module for accessing information about different feature flags state.
 */
class FeatureFlags {
    /**
     * Configures the module.
     *
     * @param {object} flags - The feature flags.
     * @param {boolean=} flags.runInLiteMode - Enables lite mode for testing to disable media decoding.
     * @param {boolean=} flags.ssrcRewritingEnabled - Use SSRC rewriting. Requires sourceNameSignaling to be enabled.
     * @param {boolean=} flags.enableJoinAsVisitor - Enable joining as a visitor.
     */
    init(flags) {
        var _a;
        this._runInLiteMode = Boolean(flags.runInLiteMode);
        this._ssrcRewriting = Boolean(flags.ssrcRewritingEnabled);
        this._joinAsVisitor = Boolean((_a = flags.enableJoinAsVisitor) !== null && _a !== void 0 ? _a : true);
    }
    /**
     * Checks if multiple local video streams support is enabled.
     *
     * @returns {boolean}
     */
    isMultiStreamSendSupportEnabled() {
        return _browser__WEBPACK_IMPORTED_MODULE_0__["default"].supportsUnifiedPlan();
    }
    /**
     * Checks if the run in lite mode is enabled.
     * This will cause any media to be received and not decoded. (Insertable streams are used to discard
     * all media before it is decoded). This can be used for various test scenarios.
     *
     * @returns {boolean}
     */
    isRunInLiteModeEnabled() {
        return this._runInLiteMode && _browser__WEBPACK_IMPORTED_MODULE_0__["default"].supportsInsertableStreams();
    }
    /**
     * Checks if the clients supports re-writing of the SSRCs on the media streams by the bridge.
     * @returns {boolean}
     */
    isSsrcRewritingSupported() {
        return this._ssrcRewriting;
    }
    /**
     * Checks if the clients supports joining as a visitor.
     * @returns {boolean}
     */
    isJoinAsVisitorSupported() {
        return this._joinAsVisitor;
    }
}
/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (new FeatureFlags());
//# sourceMappingURL=FeatureFlags.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/litemode/LiteModeContext.js":
/*!*****************************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/litemode/LiteModeContext.js ***!
  \*****************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
var __filename = "/index.js";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   LiteModeContext: () => (/* binding */ LiteModeContext)
/* harmony export */ });
/* harmony import */ var _jitsi_logger__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @jitsi/logger */ "./node_modules/@jitsi/logger/lib/index.js");
/* harmony import */ var _jitsi_logger__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(_jitsi_logger__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var _service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../service/RTC/RTCEvents */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/RTC/RTCEvents.js");
/* harmony import */ var _flags_FeatureFlags__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../flags/FeatureFlags */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/flags/FeatureFlags.js");
/* global TransformStream */



// Flag to set on receivers to avoid setting up the lite mode
// more than once.
const kJitsiLiteMode = Symbol('kJitsiLiteMode');
const logger = (0,_jitsi_logger__WEBPACK_IMPORTED_MODULE_0__.getLogger)(__filename);
/**
 * This module implements a discard-all insertable stream.  Use to reduce decoder CPU load for testing.
 */
class LiteModeContext {
    /**
     * A constructor.
     * @param {JitsiConference} conference - The conference instance for which lite mode is to be enabled.
     */
    constructor(conference) {
        this.enabled = _flags_FeatureFlags__WEBPACK_IMPORTED_MODULE_2__["default"].isRunInLiteModeEnabled();
        if (!this.enabled) {
            return;
        }
        conference.rtc.on(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_1__["default"].REMOTE_TRACK_ADDED, (track, tpc) => this._setupLiteModeForTrack(tpc, track));
    }
    /**
     * Setup Lite Mode for a track.
     *
     * @private
     */
    _setupLiteModeForTrack(tpc, track) {
        if (!this.enabled) {
            return;
        }
        const receiver = tpc.findReceiverForTrack(track.track);
        if (!receiver) {
            logger.warn(`Could not set up lite mode for ${track}: receiver not found in: ${tpc}`);
            return;
        }
        if (receiver[kJitsiLiteMode]) {
            return;
        }
        receiver[kJitsiLiteMode] = true;
        const receiverStreams = receiver.createEncodedStreams();
        const transformStream = new TransformStream({
            transform: () => {
                // Don't call controller.enqueue(encodedFrame), and so drop everything
            }
        });
        receiverStreams.readable.pipeThrough(transformStream).pipeTo(receiverStreams.writable);
    }
}
//# sourceMappingURL=LiteModeContext.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/proxyconnection/CustomSignalingLayer.js":
/*!*****************************************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/proxyconnection/CustomSignalingLayer.js ***!
  \*****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
var __filename = "/index.js";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (/* binding */ CustomSignalingLayer)
/* harmony export */ });
/* harmony import */ var _jitsi_logger__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @jitsi/logger */ "./node_modules/@jitsi/logger/lib/index.js");
/* harmony import */ var _jitsi_logger__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(_jitsi_logger__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var _service_RTC_SignalingLayer__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../service/RTC/SignalingLayer */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/RTC/SignalingLayer.js");


const logger = (0,_jitsi_logger__WEBPACK_IMPORTED_MODULE_0__.getLogger)(__filename);
/**
 * Custom semi-mock implementation for the Proxy connection service.
 */
class CustomSignalingLayer extends _service_RTC_SignalingLayer__WEBPACK_IMPORTED_MODULE_1__["default"] {
    /**
     * Creates new instance.
     */
    constructor() {
        super();
        /**
         * A map that stores SSRCs of remote streams.
         * @type {Map<number, string>} maps SSRC number to jid
         */
        this.ssrcOwners = new Map();
        /**
         *
         * @type {ChatRoom|null}
         */
        this.chatRoom = null;
    }
    /**
     * @inheritDoc
     */
    getPeerMediaInfo(owner, mediaType, sourceName) {
        return {};
    }
    /**
     * @inheritDoc
     */
    getPeerSourceInfo(owner, sourceName) {
        return undefined;
    }
    /**
     * @inheritDoc
     */
    getSSRCOwner(ssrc) {
        return this.ssrcOwners.get(ssrc);
    }
    /**
     * @inheritDoc
     */
    getTrackSourceName(ssrc) {
        return undefined;
    }
    /**
     * @inheritDoc
     */
    removeSSRCOwners(ssrcList) {
        if (!(ssrcList === null || ssrcList === void 0 ? void 0 : ssrcList.length)) {
            return;
        }
        for (const ssrc of ssrcList) {
            this.ssrcOwners.delete(ssrc);
        }
    }
    /**
     * Sets the <tt>ChatRoom</tt> instance used.
     * @param {ChatRoom} room
     */
    setChatRoom(room) {
        this.chatRoom = room;
    }
    /**
     * @inheritDoc
     */
    setSSRCOwner(ssrc, endpointId) {
        if (typeof ssrc !== 'number') {
            throw new TypeError(`SSRC(${ssrc}) must be a number`);
        }
        // Now signaling layer instance is shared between different JingleSessionPC instances, so although very unlikely
        // an SSRC conflict could potentially occur. Log a message to make debugging easier.
        const existingOwner = this.ssrcOwners.get(ssrc);
        if (existingOwner && existingOwner !== endpointId) {
            logger.error(`SSRC owner re-assigned from ${existingOwner} to ${endpointId}`);
        }
        this.ssrcOwners.set(ssrc, endpointId);
    }
    /**
     * @inheritDoc
     */
    setTrackMuteStatus(sourceName, muted) {
        return false;
    }
    /**
     * @inheritDoc
     */
    setTrackVideoType(sourceName, videoType) {
        return false;
    }
    /**
     * @inheritDoc
     */
    setTrackSourceName(ssrc, sourceName) {
    }
    /**
     * @inheritDoc
     */
    updateSsrcOwnersOnLeave(id) {
        const ssrcs = Array.from(this.ssrcOwners)
            .filter(entry => entry[1] === id)
            .map(entry => entry[0]);
        if (!(ssrcs === null || ssrcs === void 0 ? void 0 : ssrcs.length)) {
            return;
        }
        this.removeSSRCOwners(ssrcs);
    }
}
//# sourceMappingURL=CustomSignalingLayer.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/proxyconnection/ProxyConnectionPC.js":
/*!**************************************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/proxyconnection/ProxyConnectionPC.js ***!
  \**************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
var __filename = "/index.js";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (/* binding */ ProxyConnectionPC)
/* harmony export */ });
/* harmony import */ var _jitsi_logger__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @jitsi/logger */ "./node_modules/@jitsi/logger/lib/index.js");
/* harmony import */ var _jitsi_logger__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(_jitsi_logger__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var _service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../service/RTC/RTCEvents */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/RTC/RTCEvents.js");
/* harmony import */ var _service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../service/xmpp/XMPPEvents */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/xmpp/XMPPEvents.js");
/* harmony import */ var _RTC_RTC__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../RTC/RTC */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/RTC/RTC.js");
/* harmony import */ var _xmpp_JingleSessionPC__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../xmpp/JingleSessionPC */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/xmpp/JingleSessionPC.js");
/* harmony import */ var _xmpp_xmpp__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../xmpp/xmpp */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/xmpp/xmpp.js");
/* harmony import */ var _CustomSignalingLayer__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./CustomSignalingLayer */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/proxyconnection/CustomSignalingLayer.js");
/* harmony import */ var _constants__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./constants */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/proxyconnection/constants.js");








const logger = (0,_jitsi_logger__WEBPACK_IMPORTED_MODULE_0__.getLogger)(__filename);
/**
 * An adapter around {@code JingleSessionPC} so its logic can be re-used without
 * an XMPP connection. It is being re-used for consistency with the rest of the
 * codebase and to leverage existing peer connection event handling. Also
 * this class provides a facade to hide most of the API for
 * {@code JingleSessionPC}.
 */
class ProxyConnectionPC {
    /**
     * Initializes a new {@code ProxyConnectionPC} instance.
     *
     * @param {Object} options - Values to initialize the instance with.
     * @param {Object} [options.pcConfig] - The {@code RTCConfiguration} to use for the WebRTC peer connection.
     * @param {boolean} [options.isInitiator] - If true, the local client should send offers. If false, the local
     * client should send answers. Defaults to false.
     * @param {Function} options.onRemoteStream - Callback to invoke when a remote media stream has been received
     * through the peer connection.
     * @param {string} options.peerJid - The jid of the remote client with which the peer connection is being establish
     * and which should receive direct messages regarding peer connection updates.
     * @param {boolean} [options.receiveVideo] - Whether or not the peer connection should accept incoming video
     * streams. Defaults to false.
     * @param {Function} options.onSendMessage - Callback to invoke when a message has to be sent (signaled) out.
     */
    constructor(options = {}) {
        this._options = Object.assign({ pcConfig: {}, isInitiator: false, receiveAudio: false, receiveVideo: false }, options);
        /**
         * Instances of {@code JitsiTrack} associated with this instance of
         * {@code ProxyConnectionPC}.
         *
         * @type {Array<JitsiTrack>}
         */
        this._tracks = [];
        /**
         * The active instance of {@code JingleSessionPC}.
         *
         * @type {JingleSessionPC|null}
         */
        this._peerConnection = null;
        // Bind event handlers so they are only bound once for every instance.
        this._onError = this._onError.bind(this);
        this._onRemoteStream = this._onRemoteStream.bind(this);
        this._onSendMessage = this._onSendMessage.bind(this);
    }
    /**
     * Returns the jid of the remote peer with which this peer connection should
     * be established with.
     *
     * @returns {string}
     */
    getPeerJid() {
        return this._options.peerJid;
    }
    /**
     * Updates the peer connection based on the passed in jingle.
     *
     * @param {Object} $jingle - An XML jingle element, wrapped in query,
     * describing how the peer connection should be updated.
     * @returns {void}
     */
    processMessage($jingle) {
        switch ($jingle.attr('action')) {
            case _constants__WEBPACK_IMPORTED_MODULE_7__.ACTIONS.ACCEPT:
                this._onSessionAccept($jingle);
                break;
            case _constants__WEBPACK_IMPORTED_MODULE_7__.ACTIONS.INITIATE:
                this._onSessionInitiate($jingle);
                break;
            case _constants__WEBPACK_IMPORTED_MODULE_7__.ACTIONS.TERMINATE:
                this._onSessionTerminate($jingle);
                break;
            case _constants__WEBPACK_IMPORTED_MODULE_7__.ACTIONS.TRANSPORT_INFO:
                this._onTransportInfo($jingle);
                break;
        }
    }
    /**
     * Instantiates a peer connection and starts the offer/answer cycle to
     * establish a connection with a remote peer.
     *
     * @param {Array<JitsiLocalTrack>} localTracks - Initial local tracks to add
     * to add to the peer connection.
     * @returns {void}
     */
    start(localTracks = []) {
        if (this._peerConnection) {
            return;
        }
        this._tracks = this._tracks.concat(localTracks);
        this._peerConnection = this._createPeerConnection();
        this._peerConnection.invite(localTracks);
    }
    /**
     * Begins the process of disconnecting from a remote peer and cleaning up
     * the peer connection.
     *
     * @returns {void}
     */
    stop() {
        if (this._peerConnection) {
            this._peerConnection.terminate();
        }
        this._onSessionTerminate();
    }
    /**
     * Instantiates a new {@code JingleSessionPC} by stubbing out the various
     * dependencies of {@code JingleSessionPC}.
     *
     * @private
     * @returns {JingleSessionPC}
     */
    _createPeerConnection() {
        /**
         * {@code JingleSessionPC} takes in the entire jitsi-meet config.js
         * object, which may not be accessible from the caller.
         *
         * @type {Object}
         */
        const configStub = {};
        /**
         * {@code JingleSessionPC} assumes an XMPP/Strophe connection object is
         * passed through, which also has the jingle plugin initialized on it.
         * This connection object is used to signal out peer connection updates
         * via iqs, and those updates need to be piped back out to the remote
         * peer.
         *
         * @type {Object}
         */
        const connectionStub = {
            // At the time this is used for Spot and it's okay to say the connection is always connected, because if
            // spot has no signalling it will not be in a meeting where this is used.
            connected: true,
            jingle: {
                terminate: () => { }
            },
            sendIQ: this._onSendMessage,
            // Returns empty function, because it does not add any listeners for real
            // eslint-disable-next-line no-empty-function
            addEventListener: () => () => { }
        };
        /**
         * {@code JingleSessionPC} can take in a custom ice configuration,
         * depending on the peer connection type, peer-to-peer or other.
         * However, {@code ProxyConnectionPC} always assume a peer-to-peer
         * connection so the ice configuration is hard-coded with defaults.
         *
         * @type {Object}
         */
        const pcConfigStub = Object.assign({ iceServers: _xmpp_xmpp__WEBPACK_IMPORTED_MODULE_5__.DEFAULT_STUN_SERVERS }, this._options.pcConfig);
        /**
         * {@code JingleSessionPC} expects an instance of
         * {@code JitsiConference}, which has an event emitter that is used
         * to signal various connection updates that the local client should
         * act upon. The conference instance is not a dependency of a proxy
         * connection, but the emitted events can be relevant to the proxy
         * connection so the event emitter is stubbed.
         *
         * @param {string} event - The constant for the event type.
         * @type {Function}
         * @returns {void}
         */
        const emitter = event => {
            switch (event) {
                case _service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_2__.XMPPEvents.CONNECTION_ICE_FAILED:
                case _service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_2__.XMPPEvents.CONNECTION_FAILED:
                    this._onError(_constants__WEBPACK_IMPORTED_MODULE_7__.ACTIONS.CONNECTION_ERROR, event);
                    break;
            }
        };
        /**
         * {@link JingleSessionPC} expects an instance of
         * {@link ChatRoom} to be passed in. {@link ProxyConnectionPC}
         * is instantiated outside of the {@code JitsiConference}, so it must be
         * stubbed to prevent errors.
         *
         * @type {Object}
         */
        const roomStub = {
            addEventListener: () => { },
            addPresenceListener: () => { },
            connectionTimes: [],
            eventEmitter: { emit: emitter },
            removeEventListener: () => { },
            removePresenceListener: () => { },
            supportsRestartByTerminate: () => false
        };
        /**
         * A {@code JitsiConference} stub passed to the {@link RTC} module.
         * @type {Object}
         */
        const conferenceStub = {
            myUserId: () => ''
        };
        /**
         * Create an instance of {@code RTC} as it is required for peer
         * connection creation by {@code JingleSessionPC}. An existing instance
         * of {@code RTC} from elsewhere should not be re-used because it is
         * a stateful grouping of utilities.
         */
        this._rtc = new _RTC_RTC__WEBPACK_IMPORTED_MODULE_3__["default"](conferenceStub, {});
        /**
         * Add the remote track listener here as {@code JingleSessionPC} has
         * {@code TraceablePeerConnection} which uses {@code RTC}'s event
         * emitter.
         */
        this._rtc.addListener(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_1__["default"].REMOTE_TRACK_ADDED, this._onRemoteStream);
        const peerConnection = new _xmpp_JingleSessionPC__WEBPACK_IMPORTED_MODULE_4__["default"](undefined, // sid
        undefined, // localJid
        this._options.peerJid, // remoteJid
        connectionStub, // connection
        {
            offerToReceiveAudio: this._options.receiveAudio,
            offerToReceiveVideo: this._options.receiveVideo
        }, // mediaConstraints
        pcConfigStub, // pcConfig
        true, // isP2P
        this._options.isInitiator // isInitiator
        );
        const signalingLayer = new _CustomSignalingLayer__WEBPACK_IMPORTED_MODULE_6__["default"]();
        signalingLayer.setChatRoom(roomStub);
        /**
         * An additional initialize call is necessary to properly set instance
         * variable for calling.
         */
        peerConnection.initialize(roomStub, this._rtc, signalingLayer, configStub);
        return peerConnection;
    }
    /**
     * Invoked when a connection related issue has been encountered.
     *
     * @param {string} errorType - The constant indicating the type of the error
     * that occured.
     * @param {string} details - Optional additional data about the error.
     * @private
     * @returns {void}
     */
    _onError(errorType, details = '') {
        this._options.onError(this._options.peerJid, errorType, details);
    }
    /**
     * Callback invoked when the peer connection has received a remote media
     * stream.
     *
     * @param {JitsiRemoteTrack} jitsiRemoteTrack - The remote media stream
     * wrapped in {@code JitsiRemoteTrack}.
     * @private
     * @returns {void}
     */
    _onRemoteStream(jitsiRemoteTrack) {
        this._tracks.push(jitsiRemoteTrack);
        this._options.onRemoteStream(jitsiRemoteTrack);
    }
    /**
     * Callback invoked when {@code JingleSessionPC} needs to signal a message
     * out to the remote peer.
     *
     * @param {XML} iq - The message to signal out.
     * @private
     * @returns {void}
     */
    _onSendMessage(iq) {
        this._options.onSendMessage(this._options.peerJid, iq);
    }
    /**
     * Callback invoked in response to an agreement to start a proxy connection.
     * The passed in jingle element should contain an SDP answer to a previously
     * sent SDP offer.
     *
     * @param {Object} $jingle - The jingle element wrapped in jQuery.
     * @private
     * @returns {void}
     */
    _onSessionAccept($jingle) {
        if (!this._peerConnection) {
            logger.error('Received an answer when no peer connection exists.');
            return;
        }
        this._peerConnection.setAnswer($jingle);
    }
    /**
     * Callback invoked in response to a request to start a proxy connection.
     * The passed in jingle element should contain an SDP offer.
     *
     * @param {Object} $jingle - The jingle element wrapped in jQuery.
     * @private
     * @returns {void}
     */
    _onSessionInitiate($jingle) {
        if (this._peerConnection) {
            logger.error('Received an offer when an offer was already sent.');
            return;
        }
        this._peerConnection = this._createPeerConnection();
        this._peerConnection.acceptOffer($jingle, () => { }, () => this._onError(this._options.peerJid, _constants__WEBPACK_IMPORTED_MODULE_7__.ACTIONS.CONNECTION_ERROR, 'session initiate error'));
    }
    /**
     * Callback invoked in response to a request to disconnect an active proxy
     * connection. Cleans up tracks and the peer connection.
     *
     * @private
     * @returns {void}
     */
    _onSessionTerminate() {
        this._tracks.forEach(track => track.dispose());
        this._tracks = [];
        if (this._peerConnection) {
            this._peerConnection.onTerminated();
        }
        if (this._rtc) {
            this._rtc.removeListener(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_1__["default"].REMOTE_TRACK_ADDED, this._onRemoteStream);
            this._rtc.destroy();
        }
    }
    /**
     * Callback invoked in response to ICE candidates from the remote peer.
     * The passed in jingle element should contain an ICE candidate.
     *
     * @param {Object} $jingle - The jingle element wrapped in jQuery.
     * @private
     * @returns {void}
     */
    _onTransportInfo($jingle) {
        this._peerConnection.addIceCandidates($jingle);
    }
}
//# sourceMappingURL=ProxyConnectionPC.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/proxyconnection/ProxyConnectionService.js":
/*!*******************************************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/proxyconnection/ProxyConnectionService.js ***!
  \*******************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
var __filename = "/index.js";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (/* binding */ ProxyConnectionService)
/* harmony export */ });
/* harmony import */ var _jitsi_logger__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @jitsi/logger */ "./node_modules/@jitsi/logger/lib/index.js");
/* harmony import */ var _jitsi_logger__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(_jitsi_logger__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var jquery__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! jquery */ "./node_modules/jquery/dist/jquery.js");
/* harmony import */ var jquery__WEBPACK_IMPORTED_MODULE_1___default = /*#__PURE__*/__webpack_require__.n(jquery__WEBPACK_IMPORTED_MODULE_1__);
/* harmony import */ var strophe_js__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! strophe.js */ "./node_modules/strophe.js/dist/strophe.umd.js");
/* harmony import */ var strophe_js__WEBPACK_IMPORTED_MODULE_2___default = /*#__PURE__*/__webpack_require__.n(strophe_js__WEBPACK_IMPORTED_MODULE_2__);
/* harmony import */ var _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../service/RTC/MediaType */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/RTC/MediaType.js");
/* harmony import */ var _service_RTC_SignalingLayer__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../../service/RTC/SignalingLayer */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/RTC/SignalingLayer.js");
/* harmony import */ var _service_RTC_VideoType__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../../service/RTC/VideoType */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/RTC/VideoType.js");
/* harmony import */ var _RTC_RTC__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../RTC/RTC */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/RTC/RTC.js");
/* harmony import */ var _ProxyConnectionPC__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./ProxyConnectionPC */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/proxyconnection/ProxyConnectionPC.js");
/* harmony import */ var _constants__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ./constants */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/proxyconnection/constants.js");
var __rest = (undefined && undefined.__rest) || function (s, e) {
    var t = {};
    for (var p in s) if (Object.prototype.hasOwnProperty.call(s, p) && e.indexOf(p) < 0)
        t[p] = s[p];
    if (s != null && typeof Object.getOwnPropertySymbols === "function")
        for (var i = 0, p = Object.getOwnPropertySymbols(s); i < p.length; i++) {
            if (e.indexOf(p[i]) < 0 && Object.prototype.propertyIsEnumerable.call(s, p[i]))
                t[p[i]] = s[p[i]];
        }
    return t;
};









const logger = (0,_jitsi_logger__WEBPACK_IMPORTED_MODULE_0__.getLogger)(__filename);
/**
 * Instantiates a new ProxyConnectionPC and ensures only one exists at a given
 * time. Currently it assumes ProxyConnectionPC is used only for screensharing
 * and assumes IQs to be used for communication.
 */
class ProxyConnectionService {
    /**
     * Initializes a new {@code ProxyConnectionService} instance.
     *
     * @param {Object} options - Values to initialize the instance with.
     * @param {boolean} [options.convertVideoToDesktop] - Whether or not proxied video should be returned as a desktop
     * stream. Defaults to false.
     * @param {Object} [options.pcConfig] - The {@code RTCConfiguration} to use for the WebRTC peer connection.
     * @param {JitsiConnection} [options.jitsiConnection] - The {@code JitsiConnection} which will be used to fetch
     * TURN credentials for the P2P connection.
     * @param {Function} options.onRemoteStream - Callback to invoke when a remote video stream has been received and
     * converted to a {@code JitsiLocakTrack}. The {@code JitsiLocakTrack} will be passed in.
     * @param {Function} options.onSendMessage - Callback to invoke when a message has to be sent (signaled) out. The
     * arguments passed in are the jid to send the message to and the message.
     */
    constructor(options = {}) {
        const { jitsiConnection } = options, otherOptions = __rest(options, ["jitsiConnection"]);
        /**
         * Holds a reference to the collection of all callbacks.
         *
         * @type {Object}
         */
        this._options = Object.assign({ pcConfig: jitsiConnection && jitsiConnection.xmpp.connection.jingle.p2pIceConfig }, otherOptions);
        /**
         * The active instance of {@code ProxyConnectionService}.
         *
         * @type {ProxyConnectionPC|null}
         */
        this._peerConnection = null;
        // Bind event handlers so they are only bound once for every instance.
        this._onFatalError = this._onFatalError.bind(this);
        this._onSendMessage = this._onSendMessage.bind(this);
        this._onRemoteStream = this._onRemoteStream.bind(this);
    }
    /**
     * Parses a message object regarding a proxy connection to create a new
     * proxy connection or update and existing connection.
     *
     * @param {Object} message - A message object regarding establishing or
     * updating a proxy connection.
     * @param {Object} message.data - An object containing additional message
     * details.
     * @param {string} message.data.iq - The stringified iq which explains how
     * and what to update regarding the proxy connection.
     * @param {string} message.from - The message sender's full jid. Used for
     * sending replies.
     * @returns {void}
     */
    processMessage(message) {
        const peerJid = message.from;
        if (!peerJid) {
            return;
        }
        // If a proxy connection has already been established and messages come
        // from another peer jid then those messages should be replied to with
        // a rejection.
        if (this._peerConnection
            && this._peerConnection.getPeerJid() !== peerJid) {
            this._onFatalError(peerJid, _constants__WEBPACK_IMPORTED_MODULE_8__.ACTIONS.CONNECTION_ERROR, 'rejected');
            return;
        }
        const iq = this._convertStringToXML(message.data.iq);
        const $jingle = iq && iq.find('jingle');
        const action = $jingle && $jingle.attr('action');
        if (action === _constants__WEBPACK_IMPORTED_MODULE_8__.ACTIONS.INITIATE) {
            this._peerConnection = this._createPeerConnection(peerJid, {
                isInitiator: false,
                receiveVideo: true
            });
        }
        // Truthy check for peer connection added to protect against possibly
        // receiving actions before an ACTIONS.INITIATE.
        if (this._peerConnection) {
            this._peerConnection.processMessage($jingle);
        }
        // Take additional steps to ensure the peer connection is cleaned up
        // if it is to be closed.
        if (action === _constants__WEBPACK_IMPORTED_MODULE_8__.ACTIONS.CONNECTION_ERROR
            || action === _constants__WEBPACK_IMPORTED_MODULE_8__.ACTIONS.UNAVAILABLE
            || action === _constants__WEBPACK_IMPORTED_MODULE_8__.ACTIONS.TERMINATE) {
            this._selfCloseConnection();
        }
        return;
    }
    /**
     * Instantiates and initiates a proxy peer connection.
     *
     * @param {string} peerJid - The jid of the remote client that should
     * receive messages.
     * @param {Array<JitsiLocalTrack>} localTracks - Initial media tracks to
     * send through to the peer.
     * @returns {void}
     */
    start(peerJid, localTracks = []) {
        this._peerConnection = this._createPeerConnection(peerJid, {
            isInitiator: true,
            receiveVideo: false
        });
        localTracks.forEach((localTrack, localTrackIndex) => {
            const localSourceNameTrack = (0,_service_RTC_SignalingLayer__WEBPACK_IMPORTED_MODULE_4__.getSourceNameForJitsiTrack)('peer', localTrack.getType(), localTrackIndex);
            localTrack.setSourceName(localSourceNameTrack);
        });
        this._peerConnection.start(localTracks);
    }
    /**
     * Terminates any active proxy peer connection.
     *
     * @returns {void}
     */
    stop() {
        if (this._peerConnection) {
            this._peerConnection.stop();
        }
        this._peerConnection = null;
    }
    /**
     * Transforms a stringified xML into a XML wrapped in jQuery.
     *
     * @param {string} xml - The XML in string form.
     * @private
     * @returns {Object|null} A jQuery version of the xml. Null will be returned
     * if an error is encountered during transformation.
     */
    _convertStringToXML(xml) {
        try {
            const xmlDom = new DOMParser().parseFromString(xml, 'text/xml');
            return jquery__WEBPACK_IMPORTED_MODULE_1___default()(xmlDom);
        }
        catch (e) {
            logger.error('Attempted to convert incorrectly formatted xml');
            return null;
        }
    }
    /**
     * Helper for creating an instance of {@code ProxyConnectionPC}.
     *
     * @param {string} peerJid - The jid of the remote peer with which the
     * {@code ProxyConnectionPC} will be established with.
     * @param {Object} options - Additional defaults to instantiate the
     * {@code ProxyConnectionPC} with. See the constructor of ProxyConnectionPC
     * for more details.
     * @private
     * @returns {ProxyConnectionPC}
     */
    _createPeerConnection(peerJid, options = {}) {
        if (!peerJid) {
            throw new Error('Cannot create ProxyConnectionPC without a peer.');
        }
        const pcOptions = Object.assign({ pcConfig: this._options.pcConfig, onError: this._onFatalError, onRemoteStream: this._onRemoteStream, onSendMessage: this._onSendMessage, peerJid }, options);
        return new _ProxyConnectionPC__WEBPACK_IMPORTED_MODULE_7__["default"](pcOptions);
    }
    /**
     * Callback invoked when an error occurs that should cause
     * {@code ProxyConnectionPC} to be closed if the peer is currently
     * connected. Sends an error message/reply back to the peer.
     *
     * @param {string} peerJid - The peer jid with which the connection was
     * attempted or started, and to which an iq with error details should be
     * sent.
     * @param {string} errorType - The constant indicating the type of the error
     * that occured.
     * @param {string} details - Optional additional data about the error.
     * @private
     * @returns {void}
     */
    _onFatalError(peerJid, errorType, details = '') {
        logger.error('Received a proxy connection error', peerJid, errorType, details);
        const iq = (0,strophe_js__WEBPACK_IMPORTED_MODULE_2__.$iq)({
            to: peerJid,
            type: 'set'
        })
            .c('jingle', {
            xmlns: 'urn:xmpp:jingle:1',
            action: errorType
        })
            .c('details')
            .t(details)
            .up();
        this._onSendMessage(peerJid, iq);
        if (this._peerConnection
            && this._peerConnection.getPeerJid() === peerJid) {
            this._selfCloseConnection();
        }
    }
    /**
     * Callback invoked when the remote peer of the {@code ProxyConnectionPC}
     * has offered a media stream. The stream is converted into a
     * {@code JitsiLocalTrack} for local usage if the {@code onRemoteStream}
     * callback is defined.
     *
     * @param {JitsiRemoteTrack} jitsiRemoteTrack - The {@code JitsiRemoteTrack}
     * for the peer's media stream.
     * @private
     * @returns {void}
     */
    _onRemoteStream(jitsiRemoteTrack) {
        if (!this._options.onRemoteStream) {
            logger.error('Remote track received without callback.');
            jitsiRemoteTrack.dispose();
            return;
        }
        const isVideo = jitsiRemoteTrack.isVideoTrack();
        let videoType;
        if (isVideo) {
            videoType = this._options.convertVideoToDesktop
                ? _service_RTC_VideoType__WEBPACK_IMPORTED_MODULE_5__.VideoType.DESKTOP : _service_RTC_VideoType__WEBPACK_IMPORTED_MODULE_5__.VideoType.CAMERA;
        }
        // Grab the webrtc media stream and pipe it through the same processing
        // that would occur for a locally obtained media stream.
        const mediaStream = jitsiRemoteTrack.getOriginalStream();
        const jitsiLocalTracks = _RTC_RTC__WEBPACK_IMPORTED_MODULE_6__["default"].createLocalTracks([
            {
                deviceId: `proxy:${this._peerConnection.getPeerJid()}`,
                mediaType: isVideo ? _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_3__.MediaType.VIDEO : _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_3__.MediaType.AUDIO,
                sourceType: 'proxy',
                stream: mediaStream,
                track: mediaStream.getVideoTracks()[0],
                videoType
            }
        ]);
        this._options.onRemoteStream(jitsiLocalTracks[0]);
    }
    /**
     * Formats and forwards a message an iq to be sent to a peer jid.
     *
     * @param {string} peerJid - The jid the iq should be sent to.
     * @param {Object} iq - The iq which would be sent to the peer jid.
     * @private
     * @returns {void}
     */
    _onSendMessage(peerJid, iq) {
        if (!this._options.onSendMessage) {
            return;
        }
        try {
            const stringifiedIq = new XMLSerializer().serializeToString(iq.nodeTree || iq);
            this._options.onSendMessage(peerJid, { iq: stringifiedIq });
        }
        catch (e) {
            logger.error('Attempted to send an incorrectly formatted iq.');
        }
    }
    /**
     * Invoked when preemptively closing the {@code ProxyConnectionPC}.
     *
     * @private
     * @returns {void}
     */
    _selfCloseConnection() {
        this.stop();
        this._options.onConnectionClosed
            && this._options.onConnectionClosed();
    }
}
//# sourceMappingURL=ProxyConnectionService.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/proxyconnection/constants.js":
/*!******************************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/proxyconnection/constants.js ***!
  \******************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   ACTIONS: () => (/* binding */ ACTIONS)
/* harmony export */ });
/**
 * The know jingle actions that can be sent and should be acted upon by
 * {@code ProxyConnectionService} and {@code ProxyConnectionPC}.
 */
var ACTIONS;
(function (ACTIONS) {
    ACTIONS["ACCEPT"] = "session-accept";
    ACTIONS["CONNECTION_ERROR"] = "connection-error-encountered";
    ACTIONS["INITIATE"] = "session-initiate";
    ACTIONS["TERMINATE"] = "session-terminate";
    ACTIONS["TRANSPORT_INFO"] = "transport-info";
    ACTIONS["UNAVAILABLE"] = "unavailable";
})(ACTIONS || (ACTIONS = {}));
;
//# sourceMappingURL=constants.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/qualitycontrol/ReceiveVideoController.js":
/*!******************************************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/qualitycontrol/ReceiveVideoController.js ***!
  \******************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
var __filename = "/index.js";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (/* binding */ ReceiveVideoController)
/* harmony export */ });
/* harmony import */ var _jitsi_logger__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @jitsi/logger */ "./node_modules/@jitsi/logger/lib/index.js");
/* harmony import */ var _jitsi_logger__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(_jitsi_logger__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var lodash_isequal__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! lodash.isequal */ "./node_modules/lodash.isequal/index.js");
/* harmony import */ var lodash_isequal__WEBPACK_IMPORTED_MODULE_1___default = /*#__PURE__*/__webpack_require__.n(lodash_isequal__WEBPACK_IMPORTED_MODULE_1__);
/* harmony import */ var _JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../JitsiConferenceEvents */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/JitsiConferenceEvents.js");
/* harmony import */ var _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../service/RTC/MediaType */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/RTC/MediaType.js");




const logger = (0,_jitsi_logger__WEBPACK_IMPORTED_MODULE_0__.getLogger)(__filename);
const MAX_HEIGHT = 2160;
const LASTN_UNLIMITED = -1;
const ASSUMED_BANDWIDTH_BPS = -1;
/**
 * This class translates the legacy signaling format between the client and the bridge (that affects bandwidth
 * allocation) to the new format described here https://github.com/jitsi/jitsi-videobridge/blob/master/doc/allocation.md
 */
class ReceiverVideoConstraints {
    /**
     * Creates a new instance.
     * @param {Object} options - The instance options:
     * - lastN: Number of videos to be requested from the bridge.
     * - assumedBandwidthBps: Number of bps to be requested from the bridge.
     */
    constructor(options) {
        const { lastN, assumedBandwidthBps } = options;
        // The number of videos requested from the bridge.
        this._lastN = lastN !== null && lastN !== void 0 ? lastN : LASTN_UNLIMITED;
        // The number representing the maximum video height the local client should receive from the bridge/peer.
        this._maxFrameHeight = MAX_HEIGHT;
        // The number representing the assumed count of bps the local client should receive from the bridge.
        this._assumedBandwidthBps = assumedBandwidthBps !== null && assumedBandwidthBps !== void 0 ? assumedBandwidthBps : ASSUMED_BANDWIDTH_BPS;
        this._receiverVideoConstraints = {
            assumedBandwidthBps: this._assumedBandwidthBps,
            constraints: {},
            defaultConstraints: { 'maxHeight': this._maxFrameHeight },
            lastN: this._lastN
        };
    }
    /**
     * Returns the receiver video constraints that need to be sent on the bridge channel or to the remote peer.
     */
    get constraints() {
        this._receiverVideoConstraints.assumedBandwidthBps = this._assumedBandwidthBps;
        this._receiverVideoConstraints.lastN = this._lastN;
        const individualConstraints = this._receiverVideoConstraints.constraints;
        if (individualConstraints && Object.keys(individualConstraints).length) {
            /* eslint-disable no-unused-vars */
            for (const [key, value] of Object.entries(individualConstraints)) {
                value.maxHeight = this._maxFrameHeight;
            }
        }
        else {
            this._receiverVideoConstraints.defaultConstraints = { 'maxHeight': this._maxFrameHeight };
        }
        return this._receiverVideoConstraints;
    }
    /**
     * Updates the assumed bandwidth bps of the ReceiverVideoConstraints sent to the bridge.
     *
     * @param {number} assumedBandwidthBps
     * @requires {boolean} Returns true if the the value has been updated, false otherwise.
     */
    updateAssumedBandwidthBps(assumedBandwidthBps) {
        const changed = this._assumedBandwidthBps !== assumedBandwidthBps;
        if (changed) {
            this._assumedBandwidthBps = assumedBandwidthBps;
            logger.debug(`Updating receive assumedBandwidthBps: ${assumedBandwidthBps}`);
        }
        return changed;
    }
    /**
     * Updates the lastN field of the ReceiverVideoConstraints sent to the bridge.
     *
     * @param {number} value
     * @returns {boolean} Returns true if the the value has been updated, false otherwise.
     */
    updateLastN(value) {
        const changed = this._lastN !== value;
        if (changed) {
            this._lastN = value;
            logger.debug(`Updating ReceiverVideoConstraints lastN(${value})`);
        }
        return changed;
    }
    /**
     * Updates the resolution (height requested) in the contraints field of the ReceiverVideoConstraints
     * sent to the bridge.
     *
     * @param {number} maxFrameHeight
     * @requires {boolean} Returns true if the the value has been updated, false otherwise.
     */
    updateReceiveResolution(maxFrameHeight) {
        const changed = this._maxFrameHeight !== maxFrameHeight;
        if (changed) {
            this._maxFrameHeight = maxFrameHeight;
            logger.debug(`Updating receive maxFrameHeight: ${maxFrameHeight}`);
        }
        return changed;
    }
    /**
     * Updates the receiver constraints sent to the bridge.
     *
     * @param {Object} videoConstraints
     * @returns {boolean} Returns true if the the value has been updated, false otherwise.
     */
    updateReceiverVideoConstraints(videoConstraints) {
        var _a;
        const changed = !lodash_isequal__WEBPACK_IMPORTED_MODULE_1___default()(this._receiverVideoConstraints, videoConstraints);
        if (changed) {
            this._receiverVideoConstraints = videoConstraints;
            if ((_a = videoConstraints.defaultConstraints) === null || _a === void 0 ? void 0 : _a.maxHeight) {
                this.updateReceiveResolution(videoConstraints.defaultConstraints.maxHeight);
            }
            logger.debug(`Updating ReceiverVideoConstraints ${JSON.stringify(videoConstraints)}`);
        }
        return changed;
    }
}
/**
 * This class manages the receive video contraints for a given {@link JitsiConference}. These constraints are
 * determined by the application based on how the remote video streams need to be displayed. This class is responsible
 * for communicating these constraints to the bridge over the bridge channel.
 */
class ReceiveVideoController {
    /**
     * Creates a new instance for a given conference.
     *
     * @param {JitsiConference} conference the conference instance for which the new instance will be managing
     * the receive video quality constraints.
     * @param {RTC} rtc the rtc instance which is responsible for initializing the bridge channel.
     */
    constructor(conference, rtc) {
        var _a;
        this._conference = conference;
        this._rtc = rtc;
        const { config } = conference.options;
        // The number of videos requested from the bridge, -1 represents unlimited or all available videos.
        this._lastN = (_a = config === null || config === void 0 ? void 0 : config.startLastN) !== null && _a !== void 0 ? _a : ((config === null || config === void 0 ? void 0 : config.channelLastN) || LASTN_UNLIMITED);
        // The number representing the maximum video height the local client should receive from the bridge.
        this._maxFrameHeight = MAX_HEIGHT;
        /**
         * The map that holds the max frame height requested per remote source for p2p connection.
         *
         * @type Map<string, number>
         */
        this._sourceReceiverConstraints = new Map();
        /**
         * The number of bps requested from the bridge.
         */
        this._assumedBandwidthBps = ASSUMED_BANDWIDTH_BPS;
        // The default receiver video constraints.
        this._receiverVideoConstraints = new ReceiverVideoConstraints({
            lastN: this._lastN,
            assumedBandwidthBps: this._assumedBandwidthBps
        });
        this._conference.on(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_2__._MEDIA_SESSION_STARTED, session => this._onMediaSessionStarted(session));
    }
    /**
     * Returns a map of all the remote source names and the corresponding max frame heights.
     *
     * @param {JingleSessionPC} mediaSession - the media session.
     * @param {number} maxFrameHeight - the height to be requested for remote sources.
     * @returns
     */
    _getDefaultSourceReceiverConstraints(mediaSession, maxFrameHeight) {
        var _a;
        const height = maxFrameHeight !== null && maxFrameHeight !== void 0 ? maxFrameHeight : MAX_HEIGHT;
        const remoteVideoTracks = ((_a = mediaSession.peerconnection) === null || _a === void 0 ? void 0 : _a.getRemoteTracks(null, _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_3__.MediaType.VIDEO)) || [];
        const receiverConstraints = new Map();
        for (const track of remoteVideoTracks) {
            receiverConstraints.set(track.getSourceName(), height);
        }
        return receiverConstraints;
    }
    /**
     * Handles the {@link JitsiConferenceEvents.MEDIA_SESSION_STARTED}, that is when the conference creates new media
     * session. The preferred receive frameHeight is applied on the media session.
     *
     * @param {JingleSessionPC} mediaSession - the started media session.
     * @returns {void}
     * @private
     */
    _onMediaSessionStarted(mediaSession) {
        if (mediaSession.isP2P) {
            mediaSession.setReceiverVideoConstraint(this._getDefaultSourceReceiverConstraints(mediaSession));
        }
        else {
            this._rtc.setReceiverVideoConstraints(this._receiverVideoConstraints.constraints);
        }
    }
    /**
     * Returns the lastN value for the conference.
     *
     * @returns {number}
     */
    getLastN() {
        return this._lastN;
    }
    /**
     * Sets the assumed bandwidth bps the local participant should receive from remote participants.
     *
     * @param {number|undefined} assumedBandwidthBps - the new value.
     * @returns {void}
     */
    setAssumedBandwidthBps(assumedBandwidthBps) {
        if (this._receiverVideoConstraints.updateAssumedBandwidthBps(assumedBandwidthBps)) {
            this._rtc.setReceiverVideoConstraints(this._receiverVideoConstraints.constraints);
        }
    }
    /**
     * Selects a new value for "lastN". The requested amount of videos are going to be delivered after the value is
     * in effect. Set to -1 for unlimited or all available videos.
     *
     * @param {number} value the new value for lastN.
     * @returns {void}
     */
    setLastN(value) {
        if (this._lastN !== value) {
            this._lastN = value;
            if (this._receiverVideoConstraints.updateLastN(value)) {
                this._rtc.setReceiverVideoConstraints(this._receiverVideoConstraints.constraints);
            }
        }
    }
    /**
     * Sets the maximum video resolution the local participant should receive from remote participants.
     *
     * @param {number|undefined} maxFrameHeight - the new value.
     * @returns {void}
     */
    setPreferredReceiveMaxFrameHeight(maxFrameHeight) {
        this._maxFrameHeight = maxFrameHeight;
        for (const session of this._conference.getMediaSessions()) {
            if (session.isP2P) {
                session.setReceiverVideoConstraint(this._getDefaultSourceReceiverConstraints(session, maxFrameHeight));
            }
            else if (this._receiverVideoConstraints.updateReceiveResolution(maxFrameHeight)) {
                this._rtc.setReceiverVideoConstraints(this._receiverVideoConstraints.constraints);
            }
        }
    }
    /**
     * Sets the receiver constraints for the conference.
     *
     * @param {Object} constraints The video constraints.
     */
    setReceiverConstraints(constraints) {
        var _a, _b;
        if (!constraints) {
            return;
        }
        const isEndpointsFormat = Object.keys(constraints).includes('onStageEndpoints', 'selectedEndpoints');
        if (isEndpointsFormat) {
            throw new Error('"onStageEndpoints" and "selectedEndpoints" are not supported when sourceNameSignaling is enabled.');
        }
        const constraintsChanged = this._receiverVideoConstraints.updateReceiverVideoConstraints(constraints);
        if (constraintsChanged) {
            this._assumedBandwidthBps = (_a = constraints.assumedBandwidthBps) !== null && _a !== void 0 ? _a : this._assumedBandwidthBps;
            this._lastN = (_b = constraints.lastN) !== null && _b !== void 0 ? _b : this._lastN;
            // Send the contraints on the bridge channel.
            this._rtc.setReceiverVideoConstraints(constraints);
            const p2pSession = this._conference.getMediaSessions().find(session => session.isP2P);
            if (!p2pSession || !constraints.constraints) {
                return;
            }
            const mappedConstraints = Array.from(Object.entries(constraints.constraints))
                .map(constraint => {
                constraint[1] = constraint[1].maxHeight;
                return constraint;
            });
            this._sourceReceiverConstraints = new Map(mappedConstraints);
            // Send the receiver constraints to the peer through a "content-modify" message.
            p2pSession.setReceiverVideoConstraint(this._sourceReceiverConstraints);
        }
    }
}
//# sourceMappingURL=ReceiveVideoController.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/qualitycontrol/SendVideoController.js":
/*!***************************************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/qualitycontrol/SendVideoController.js ***!
  \***************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
var __filename = "/index.js";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (/* binding */ SendVideoController)
/* harmony export */ });
/* harmony import */ var _jitsi_logger__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @jitsi/logger */ "./node_modules/@jitsi/logger/lib/index.js");
/* harmony import */ var _jitsi_logger__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(_jitsi_logger__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var _JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../JitsiConferenceEvents */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/JitsiConferenceEvents.js");
/* harmony import */ var _service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../service/RTC/RTCEvents */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/RTC/RTCEvents.js");
/* harmony import */ var _xmpp_MediaSessionEvents__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../xmpp/MediaSessionEvents */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/xmpp/MediaSessionEvents.js");




const logger = (0,_jitsi_logger__WEBPACK_IMPORTED_MODULE_0__.getLogger)(__filename);
const MAX_LOCAL_RESOLUTION = 2160;
/**
 * The class manages send video constraints across media sessions({@link JingleSessionPC}) which belong to
 * {@link JitsiConference}. It finds the lowest common value, between the local user's send preference and
 * the remote party's receive preference. Also this module will consider only the active session's receive value,
 * because local tracks are shared and while JVB may have no preference, the remote p2p may have and they may be totally
 * different.
 */
class SendVideoController {
    /**
     * Creates new instance for a given conference.
     *
     * @param {JitsiConference} conference - the conference instance for which the new instance will be managing
     * the send video quality constraints.
     * @param {RTC} rtc - the rtc instance that is responsible for sending the messages on the bridge channel.
     */
    constructor(conference, rtc) {
        this._conference = conference;
        this._preferredSendMaxFrameHeight = MAX_LOCAL_RESOLUTION;
        this._rtc = rtc;
        /**
         * Source name based sender constraints.
         * @type {Map<string, number>};
         */
        this._sourceSenderConstraints = new Map();
        this._conference.on(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_1__._MEDIA_SESSION_STARTED, session => this._onMediaSessionStarted(session));
        this._conference.on(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_1__._MEDIA_SESSION_ACTIVE_CHANGED, () => this._configureConstraintsForLocalSources());
        this._rtc.on(_service_RTC_RTCEvents__WEBPACK_IMPORTED_MODULE_2__["default"].SENDER_VIDEO_CONSTRAINTS_CHANGED, videoConstraints => this._onSenderConstraintsReceived(videoConstraints));
    }
    /**
     * Configures the video encodings on the local sources when a media connection is established or becomes active.
     *
     * @returns {Promise<void[]>}
     * @private
     */
    _configureConstraintsForLocalSources() {
        for (const track of this._rtc.getLocalVideoTracks()) {
            const sourceName = track.getSourceName();
            sourceName && this._propagateSendMaxFrameHeight(sourceName);
        }
    }
    /**
     * Handles the {@link JitsiConferenceEvents.MEDIA_SESSION_STARTED}, that is when the conference creates new media
     * session. It doesn't mean it's already active though. For example the JVB connection may be created after
     * the conference has entered the p2p mode already.
     *
     * @param {JingleSessionPC} mediaSession - the started media session.
     * @private
     */
    _onMediaSessionStarted(mediaSession) {
        mediaSession.addListener(_xmpp_MediaSessionEvents__WEBPACK_IMPORTED_MODULE_3__["default"].REMOTE_SOURCE_CONSTRAINTS_CHANGED, (session, sourceConstraints) => {
            session === this._conference.getActiveMediaSession()
                && sourceConstraints.forEach(constraint => this._onSenderConstraintsReceived(constraint));
        });
    }
    /**
     * Propagates the video constraints if they have changed.
     *
     * @param {Object} videoConstraints - The sender video constraints received from the bridge.
     * @returns {Promise<void[]>}
     * @private
     */
    _onSenderConstraintsReceived(videoConstraints) {
        var _a;
        const { maxHeight, sourceName } = videoConstraints;
        const localVideoTracks = (_a = this._conference.getLocalVideoTracks()) !== null && _a !== void 0 ? _a : [];
        for (const track of localVideoTracks) {
            // Propagate the sender constraint only if it has changed.
            if (track.getSourceName() === sourceName
                && this._sourceSenderConstraints.get(sourceName) !== maxHeight) {
                this._sourceSenderConstraints.set(sourceName, maxHeight === -1
                    ? Math.min(MAX_LOCAL_RESOLUTION, this._preferredSendMaxFrameHeight)
                    : maxHeight);
                logger.debug(`Sender constraints for source:${sourceName} changed to maxHeight:${maxHeight}`);
                this._propagateSendMaxFrameHeight(sourceName);
            }
        }
    }
    /**
     * Figures out the send video constraint as specified by {@link _selectSendMaxFrameHeight} and sets it on all media
     * sessions for the reasons mentioned in this class description.
     *
     * @param {string} sourceName - The source for which sender constraints have changed.
     * @returns {Promise<void[]>}
     * @private
     */
    _propagateSendMaxFrameHeight(sourceName) {
        if (!sourceName) {
            throw new Error('sourceName missing for calculating the sendMaxHeight for video tracks');
        }
        const sendMaxFrameHeight = this._selectSendMaxFrameHeight(sourceName);
        const promises = [];
        if (sendMaxFrameHeight >= 0) {
            for (const session of this._conference.getMediaSessions()) {
                promises.push(session.setSenderVideoConstraint(sendMaxFrameHeight, sourceName));
            }
        }
        return Promise.all(promises);
    }
    /**
     * Selects the lowest common value for the local video send constraint by looking at local user's preference and
     * the active media session's receive preference set by the remote party.
     *
     * @param {string} sourceName - The source for which sender constraints have changed.
     * @returns {number|undefined}
     * @private
     */
    _selectSendMaxFrameHeight(sourceName) {
        if (!sourceName) {
            throw new Error('sourceName missing for calculating the sendMaxHeight for video tracks');
        }
        const activeMediaSession = this._conference.getActiveMediaSession();
        const remoteRecvMaxFrameHeight = activeMediaSession
            ? this._sourceSenderConstraints.get(sourceName)
            : undefined;
        if (this._preferredSendMaxFrameHeight >= 0 && remoteRecvMaxFrameHeight >= 0) {
            return Math.min(this._preferredSendMaxFrameHeight, remoteRecvMaxFrameHeight);
        }
        else if (remoteRecvMaxFrameHeight >= 0) {
            return remoteRecvMaxFrameHeight;
        }
        return this._preferredSendMaxFrameHeight;
    }
    /**
     * Sets local preference for max send video frame height.
     *
     * @param {number} maxFrameHeight - the new value to set.
     * @returns {Promise<void[]>} - resolved when the operation is complete.
     */
    setPreferredSendMaxFrameHeight(maxFrameHeight) {
        this._preferredSendMaxFrameHeight = maxFrameHeight;
        const promises = [];
        for (const sourceName of this._sourceSenderConstraints.keys()) {
            promises.push(this._propagateSendMaxFrameHeight(sourceName));
        }
        return Promise.allSettled(promises);
    }
}
//# sourceMappingURL=SendVideoController.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/recording/JibriSession.js":
/*!***************************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/recording/JibriSession.js ***!
  \***************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (/* binding */ JibriSession)
/* harmony export */ });
/* harmony import */ var strophe_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! strophe.js */ "./node_modules/strophe.js/dist/strophe.umd.js");
/* harmony import */ var strophe_js__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(strophe_js__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var _recordingXMLUtils__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./recordingXMLUtils */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/recording/recordingXMLUtils.js");


/**
 * Represents a recording session.
 */
class JibriSession {
    /**
     * Initializes a new JibriSession instance.
     *
     * @constructor
     */
    constructor(options = {}) {
        this._connection = options.connection;
        this._mode = options.mode;
        this._jibriJid = null;
        this._statusFromJicofo = '';
        this._setSessionID(options.sessionID);
        this.setStatus(options.status);
    }
    /**
     * Returns the error related to the session instance, if any.
     *
     * @returns {string|undefined}
     */
    getError() {
        return this._error;
    }
    /**
     * Returns the session ID of the session instance.
     *
     * @returns {string|undefined}
     */
    getID() {
        return this._sessionID;
    }
    /**
     * Returns the initiator of the session instance.
     *
     * @returns {JitsiParticipant|string} The participant that started the session.
     */
    getInitiator() {
        return this._initiator;
    }
    /**
     * Returns the streaming URL of the session.
     *
     * @returns {string|undefined}
     */
    getLiveStreamViewURL() {
        return this._liveStreamViewURL;
    }
    /**
     * Returns the current status of the session.
     *
     * @returns {string|undefined}
     */
    getStatus() {
        // If _status is not set fallback to the status reported by jicofo.
        if (this._status) {
            return this._status;
        }
        return this._statusFromJicofo;
    }
    /**
     * @returns {string|undefined} the JID of jibri associated with this session.
     */
    getJibriJid() {
        return this._jibriJid;
    }
    /**
     * Returns the jid of the participant that stopped the session.
     *
     * @returns {JitsiParticipant|string} The participant that stopped the session.
     */
    getTerminator() {
        return this._terminator;
    }
    /**
     * Returns the current recording mode of the session, such as "file".
     *
     * @returns {string}
     */
    getMode() {
        return this._mode;
    }
    /**
     * Sets the last known error message related to the session.
     *
     * @param {string} error - The error string explaining why the session
     * entered an error state.
     * @returns {void}
     */
    setError(error) {
        this._error = error;
    }
    /**
     * Sets the last live stream URL for the session instance. Usually this is
     * a YouTube URL and usually this is only set for "stream" sessions.
     *
     * @param {string} url - The live stream URL associated with the session.
     * @returns {void}
     */
    setLiveStreamViewURL(url) {
        this._liveStreamViewURL = url;
    }
    /**
     * Sets the last known status for this recording session.
     *
     * @param {string} status - The new status to set.
     * @returns {void}
     */
    setStatus(status) {
        this._status = status;
    }
    /**
     * Set the session status reported by jicofo. If a jibri is present in the room,
     * the status is always 'on'. Otherwise, we fallback to the status reported by jicofo.
     *
     * @param {string} status
     */
    setStatusFromJicofo(status) {
        this._statusFromJicofo = status;
    }
    /**
     * Set the JID of the jibri associated with this session.
     *
     * @param {*} jibriJid
     */
    setJibriJid(jibriJid) {
        this._jibriJid = jibriJid;
    }
    /**
     * Sets the participant that started the session.
     * @param {JitsiParticipant | string} participant - The participant or resource id
     * if local participant.
     */
    setInitiator(participant) {
        this._initiator = participant;
    }
    /**
     * Sets the participant that stopped the session.
     * @param {JitsiParticipant | string} participant - The participant or the resource id
     * if local participant.
     */
    setTerminator(participant) {
        this._terminator = participant;
    }
    /**
     * Sends a message to start the actual recording.
     *
     * @param {Object} options - Additional arguments for starting the
     * recording.
     * @param {string} [options.appData] - Data specific to the app/service that
     * the result file will be uploaded.
     * @param {string} [options.broadcastId] - The broadcast ID of an
     * associated YouTube stream, used for knowing the URL from which the stream
     * can be viewed.
     * @param {string} options.focusMucJid - The JID of the focus participant
     * that controls recording.
     * @param {streamId} options.streamId - Necessary for live streaming, this
     * is the stream key needed to start a live streaming session with the
     * streaming service provider.
     * @returns Promise
     */
    start({ appData, broadcastId, focusMucJid, streamId }) {
        return new Promise((resolve, reject) => {
            this._connection.sendIQ(this._createIQ({
                action: 'start',
                appData,
                focusMucJid,
                broadcastId,
                streamId
            }), result => {
                // All users will eventually receive the 'pending' status
                // from the backend, but for the user initiating the session
                // it's better to give some instant feedback that recording
                // is starting so fire 'pending' here manually.
                this.setStatus('pending');
                this._setSessionID(_recordingXMLUtils__WEBPACK_IMPORTED_MODULE_1__["default"].getSessionIdFromIq(result));
                resolve();
            }, error => {
                this._setErrorFromIq(error);
                reject(error);
            });
        });
    }
    /**
     * Sends a message to actually stop the recording session.
     *
     * @param {Object} options - Additional arguments for stopping the
     * recording.
     * @param {Object} options.focusMucJid - The JID of the focus participant
     * that controls recording.
     * @returns Promise
     */
    stop({ focusMucJid }) {
        return new Promise((resolve, reject) => {
            this._connection.sendIQ(this._createIQ({
                action: 'stop',
                focusMucJid
            }), resolve, reject);
        });
    }
    /**
     * Generates the message to change the status of the recording session.
     *
     * @param {string} status - The new status to which the recording session
     * should transition.
     * @param {string} [options.appData] - Data specific to the app/service that
     * the result file will be uploaded.
     * @param {string} [options.broadcastId] - The broadcast ID of an
     * associated YouTube stream, used for knowing the URL from which the stream
     * can be viewed.
     * @param {string} options.focusMucJid - The JID of the focus participant
     * that controls recording.
     * @param {streamId} options.streamId - Necessary for live streaming, this
     * is the stream key needed to start a live streaming session with the
     * streaming service provider.
     * @returns Object - The XMPP IQ message.
     */
    _createIQ({ action, appData, broadcastId, focusMucJid, streamId }) {
        return (0,strophe_js__WEBPACK_IMPORTED_MODULE_0__.$iq)({
            to: focusMucJid,
            type: 'set'
        })
            .c('jibri', {
            'xmlns': 'http://jitsi.org/protocol/jibri',
            'action': action,
            'app_data': appData,
            'recording_mode': this._mode,
            'streamid': streamId,
            'you_tube_broadcast_id': broadcastId
        })
            .up();
    }
    /**
     * Handles the error from an iq and stores the error.
     *
     * @param {Node} errorIq - The error response from an Iq.
     * @private
     * @returns {void}
     */
    _setErrorFromIq(errorIq) {
        const error = errorIq.getElementsByTagName('error')[0];
        this.setError(error.children[0].tagName);
    }
    /**
     * Sets the known session ID for this recording session.
     *
     * @param {string} sessionID
     * @private
     * @returns {void}
     */
    _setSessionID(sessionID) {
        this._sessionID = sessionID;
    }
}
//# sourceMappingURL=JibriSession.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/recording/RecordingManager.js":
/*!*******************************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/recording/RecordingManager.js ***!
  \*******************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
var __filename = "/index.js";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (__WEBPACK_DEFAULT_EXPORT__)
/* harmony export */ });
/* harmony import */ var _jitsi_logger__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @jitsi/logger */ "./node_modules/@jitsi/logger/lib/index.js");
/* harmony import */ var _jitsi_logger__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(_jitsi_logger__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var _service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../service/xmpp/XMPPEvents */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/xmpp/XMPPEvents.js");
/* harmony import */ var _JibriSession__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./JibriSession */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/recording/JibriSession.js");
/* harmony import */ var _recordingXMLUtils__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./recordingXMLUtils */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/recording/recordingXMLUtils.js");




const logger = (0,_jitsi_logger__WEBPACK_IMPORTED_MODULE_0__.getLogger)(__filename);
/**
 * A class responsible for starting and stopping recording sessions and emitting
 * state updates for them.
 */
class RecordingManager {
    /**
     * Initialize {@code RecordingManager} with other objects that are necessary
     * for starting a recording.
     *
     * @param {ChatRoom} chatRoom - The chat room to handle.
     * @returns {void}
     */
    constructor(chatRoom) {
        /**
         * All known recording sessions from the current conference.
         */
        this._sessions = {};
        this._chatRoom = chatRoom;
        this.onPresence = this.onPresence.bind(this);
        this.onMemberLeft = this.onMemberLeft.bind(this);
        this._chatRoom.eventEmitter.addListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_1__.XMPPEvents.PRESENCE_RECEIVED, this.onPresence);
        this._chatRoom.eventEmitter.addListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_1__.XMPPEvents.MUC_MEMBER_LEFT, this.onMemberLeft);
    }
    /**
     * Finds an existing recording session by session ID.
     *
     * @param {string} sessionID - The session ID associated with the recording.
     * @returns {JibriSession|undefined}
     */
    getSession(sessionID) {
        return this._sessions[sessionID];
    }
    /**
     * Find a session with a specific jibri JID.
     *
     * @param {string} jibriJid the JID to search for.
     * @returns
     */
    getSessionByJibriJid(jibriJid) {
        let s;
        Object.values(this._sessions).forEach(session => {
            if (session.getJibriJid() === jibriJid) {
                s = session;
            }
        });
        return s;
    }
    /**
     * Callback to invoke to parse through a presence update to find recording
     * related updates (from Jibri participant doing the recording and the
     * focus which controls recording).
     *
     * @param {Object} event - The presence data from the pubsub event.
     * @param {Node} event.presence - An XMPP presence update.
     * @param {boolean} event.fromHiddenDomain - Whether or not the update comes
     * from a participant that is trusted but not visible, as would be the case
     * with the Jibri recorder participant.
     * @returns {void}
     */
    onPresence({ fromHiddenDomain, presence }) {
        if (_recordingXMLUtils__WEBPACK_IMPORTED_MODULE_3__["default"].isFromFocus(presence)) {
            this._handleFocusPresence(presence);
        }
        else if (fromHiddenDomain) {
            this._handleJibriPresence(presence);
        }
    }
    /**
     * Handle a participant leaving the room.
     * @param {string} jid the JID of the participant that left.
     */
    onMemberLeft(jid) {
        const session = this.getSessionByJibriJid(jid);
        if (session) {
            const prevStatus = session.getStatus();
            // Setting to ''
            session.setStatus('');
            session.setJibriJid(null);
            if (session.getStatus() !== prevStatus) {
                this._emitSessionUpdate(session);
            }
        }
    }
    /**
     * Start a recording session.
     *
     * @param {Object} options - Configuration for the recording.
     * @param {string} [options.appData] - Data specific to the app/service that
     * the result file will be uploaded.
     * @param {string} [optional] options.broadcastId - The channel on which a
     * live stream will occur.
     * @param {string} options.mode - The mode in which recording should be
     * started. Recognized values are "file" and "stream".
     * @param {string} [optional] options.streamId - The stream key to be used
     * for live stream broadcasting. Required for live streaming.
     * @returns {Promise} A promise for starting a recording, which will pass
     * back the session on success. The promise resolves after receiving an
     * acknowledgment of the start request success or fail.
     */
    startRecording(options) {
        const session = new _JibriSession__WEBPACK_IMPORTED_MODULE_2__["default"](Object.assign(Object.assign({}, options), { connection: this._chatRoom.connection }));
        return session.start({
            appData: options.appData,
            broadcastId: options.broadcastId,
            focusMucJid: this._chatRoom.focusMucJid,
            streamId: options.streamId
        })
            .then(() => {
            // Only store the session and emit if the session has not been
            // added already. This is a workaround for the session getting
            // created due to a presence update to announce a "pending"
            // recording being received before JibriSession#start finishes.
            if (!this.getSession(session.getID())) {
                this._addSession(session);
                this._emitSessionUpdate(session);
            }
            return session;
        })
            .catch(error => {
            this._emitSessionUpdate(session);
            return Promise.reject(error);
        });
    }
    /**
     * Stop a recording session.
     *
     * @param {string} sessionID - The ID associated with the recording session
     * to be stopped.
     * @returns {Promise} The promise resolves after receiving an
     * acknowledgment of the stop request success or fail.
     */
    stopRecording(sessionID) {
        const session = this.getSession(sessionID);
        if (session) {
            return session.stop({ focusMucJid: this._chatRoom.focusMucJid });
        }
        return Promise.reject(new Error('Could not find session'));
    }
    /**
     * Stores a reference to the passed in JibriSession.
     *
     * @param {string} session - The JibriSession instance to store.
     * @returns {void}
     */
    _addSession(session) {
        this._sessions[session.getID()] = session;
    }
    /**
     * Create a new instance of a recording session and stores a reference to
     * it.
     *
     * @param {string} sessionID - The session ID of the recording in progress.
     * @param {string} status - The current status of the recording session.
     * @param {string} mode - The recording mode of the session.
     * @returns {JibriSession}
     */
    _createSession(sessionID, status, mode) {
        const session = new _JibriSession__WEBPACK_IMPORTED_MODULE_2__["default"]({
            connection: this._chatRoom.connection,
            focusMucJid: this._chatRoom.focusMucJid,
            mode,
            sessionID,
            status
        });
        this._addSession(session);
        return session;
    }
    /**
     * Notifies listeners of an update to a recording session.
     *
     * @param {JibriSession} session - The session that has been updated.
     * @param {string|undefined} initiator - The jid of the initiator of the update.
     */
    _emitSessionUpdate(session, initiator) {
        this._chatRoom.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_1__.XMPPEvents.RECORDER_STATE_CHANGED, session, initiator);
    }
    /**
     * Parses presence to update an existing JibriSession or to create a new
     * JibriSession.
     *
     * @param {Node} presence - An XMPP presence update.
     * @returns {void}
     */
    _handleFocusPresence(presence) {
        const jibriStatus = _recordingXMLUtils__WEBPACK_IMPORTED_MODULE_3__["default"].getFocusRecordingUpdate(presence);
        if (!jibriStatus) {
            return;
        }
        const { error, initiator, recordingMode, sessionID, status } = jibriStatus;
        // We'll look for an existing session or create one (in case we're a
        // participant joining a call with an existing recording going on).
        let session = this.getSession(sessionID);
        // Handle the case where a status update is received in presence but
        // the local participant has joined while the JibriSession has already
        // ended.
        if (!session && status === 'off') {
            logger.warn('Ignoring recording presence update', 'Received a new session with status off.');
            return;
        }
        // Jicofo sends updates via presence, and any extension in presence
        // is sent until it is explicitly removed.  It's difficult for
        // Jicofo to know when a presence has been sent once, so it won't
        // remove jibri status extension.  This means we may receive the same
        // status update more than once, so check for that here
        if (session
            && session.getStatus() === status
            && session.getError() === error) {
            logger.warn('Ignoring duplicate presence update: ', JSON.stringify(jibriStatus));
            return;
        }
        if (!session) {
            session = this._createSession(sessionID, status, recordingMode);
        }
        session.setStatusFromJicofo(status);
        if (error) {
            session.setError(error);
        }
        this._emitSessionUpdate(session, initiator);
    }
    /**
     * Handles updates from the Jibri which can broadcast a YouTube URL that
     * needs to be updated in a JibriSession.
     *
     * @param {Node} presence - An XMPP presence update.
     * @returns {void}
     */
    _handleJibriPresence(presence) {
        const { liveStreamViewURL, mode, sessionID } = _recordingXMLUtils__WEBPACK_IMPORTED_MODULE_3__["default"].getHiddenDomainUpdate(presence);
        if (!sessionID) {
            logger.warn('Ignoring potential jibri presence due to no session id.');
            return;
        }
        let session = this.getSession(sessionID);
        if (!session) {
            session = this._createSession(sessionID, 'on', mode);
        }
        // When a jibri is present the status is always 'on';
        session.setStatus('on');
        session.setJibriJid(presence.getAttribute('from'));
        session.setLiveStreamViewURL(liveStreamViewURL);
        this._emitSessionUpdate(session);
    }
}
/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (RecordingManager);
//# sourceMappingURL=RecordingManager.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/recording/recordingConstants.js":
/*!*********************************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/recording/recordingConstants.js ***!
  \*********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (__WEBPACK_DEFAULT_EXPORT__)
/* harmony export */ });
/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = ({
    error: {
        BUSY: 'busy',
        ERROR: 'error',
        RESOURCE_CONSTRAINT: 'resource-constraint',
        UNEXPECTED_REQUEST: 'unexpected-request',
        SERVICE_UNAVAILABLE: 'service-unavailable'
    },
    mode: {
        FILE: 'file',
        STREAM: 'stream'
    },
    status: {
        OFF: 'off',
        ON: 'on',
        PENDING: 'pending'
    }
});
//# sourceMappingURL=recordingConstants.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/recording/recordingXMLUtils.js":
/*!********************************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/recording/recordingXMLUtils.js ***!
  \********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (__WEBPACK_DEFAULT_EXPORT__)
/* harmony export */ });
/**
 * A collection of utility functions for taking in XML and parsing it to return
 * certain values.
 */
/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = ({
    /**
     * Parses the presence update of the focus and returns an object with the
     * statuses related to recording.
     *
     * @param {Node} presence - An XMPP presence update.
     * @returns {Object} The current presence values related to recording.
     */
    getFocusRecordingUpdate(presence) {
        const jibriStatus = presence
            && presence.getElementsByTagName('jibri-recording-status')[0];
        if (!jibriStatus) {
            return;
        }
        return {
            error: jibriStatus.getAttribute('failure_reason'),
            initiator: jibriStatus.getAttribute('initiator'),
            recordingMode: jibriStatus.getAttribute('recording_mode'),
            sessionID: jibriStatus.getAttribute('session_id'),
            status: jibriStatus.getAttribute('status')
        };
    },
    /**
     * Parses the presence update from a hidden domain participant and returns
     * an object with the statuses related to recording.
     *
     * @param {Node} presence - An XMPP presence update.
     * @returns {Object} The current presence values related to recording.
     */
    getHiddenDomainUpdate(presence) {
        const liveStreamViewURLContainer = presence.getElementsByTagName('live-stream-view-url')[0];
        const liveStreamViewURL = liveStreamViewURLContainer
            && liveStreamViewURLContainer.textContent;
        const modeContainer = presence.getElementsByTagName('mode')[0];
        const mode = modeContainer
            && modeContainer.textContent
            && modeContainer.textContent.toLowerCase();
        const sessionIDContainer = presence.getElementsByTagName('session_id')[0];
        const sessionID = sessionIDContainer && sessionIDContainer.textContent;
        return {
            liveStreamViewURL,
            mode,
            sessionID
        };
    },
    /**
     * Returns the recording session ID from a successful IQ.
     *
     * @param {Node} response - The response from the IQ.
     * @returns {string} The session ID of the recording session.
     */
    getSessionIdFromIq(response) {
        const jibri = response && response.getElementsByTagName('jibri')[0];
        return jibri && jibri.getAttribute('session_id');
    },
    /**
     * Returns the recording session ID from a presence, if it exists.
     *
     * @param {Node} presence - An XMPP presence update.
     * @returns {string|undefined} The session ID of the recording session.
     */
    getSessionId(presence) {
        const sessionIdContainer = presence.getElementsByTagName('session_id')[0];
        const sessionId = sessionIdContainer && sessionIdContainer.textContent;
        return sessionId;
    },
    /**
     * Returns whether or not a presence is from the focus.
     *
     * @param {Node} presence - An XMPP presence update.
     * @returns {boolean} True if the presence is from the focus.
     */
    isFromFocus(presence) {
        return presence.getAttribute('from').includes('focus');
    }
});
//# sourceMappingURL=recordingXMLUtils.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/sdp/LocalSdpMunger.js":
/*!***********************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/sdp/LocalSdpMunger.js ***!
  \***********************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
var __filename = "/index.js";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (/* binding */ LocalSdpMunger)
/* harmony export */ });
/* harmony import */ var _jitsi_logger__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @jitsi/logger */ "./node_modules/@jitsi/logger/lib/index.js");
/* harmony import */ var _jitsi_logger__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(_jitsi_logger__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var _service_RTC_MediaDirection__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../service/RTC/MediaDirection */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/RTC/MediaDirection.js");
/* harmony import */ var _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../service/RTC/MediaType */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/RTC/MediaType.js");
/* harmony import */ var _service_RTC_SignalingLayer__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../service/RTC/SignalingLayer */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/RTC/SignalingLayer.js");
/* harmony import */ var _service_RTC_VideoType__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../../service/RTC/VideoType */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/RTC/VideoType.js");
/* harmony import */ var _browser__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../browser */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/browser/index.js");
/* harmony import */ var _flags_FeatureFlags__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../flags/FeatureFlags */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/flags/FeatureFlags.js");
/* harmony import */ var _SdpTransformUtil__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./SdpTransformUtil */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/sdp/SdpTransformUtil.js");








const logger = (0,_jitsi_logger__WEBPACK_IMPORTED_MODULE_0__.getLogger)(__filename);
/**
 * Fakes local SDP exposed to {@link JingleSessionPC} through the local
 * description getter. Modifies the SDP, so that it will contain muted local
 * video tracks description, even though their underlying {MediaStreamTrack}s
 * are no longer in the WebRTC peerconnection. That prevents from SSRC updates
 * being sent to Jicofo/remote peer and prevents sRD/sLD cycle on the remote
 * side.
 */
class LocalSdpMunger {
    /**
     * Creates new <tt>LocalSdpMunger</tt> instance.
     *
     * @param {TraceablePeerConnection} tpc
     * @param {string} localEndpointId - The endpoint id of the local user.
     */
    constructor(tpc, localEndpointId) {
        this.tpc = tpc;
        this.localEndpointId = localEndpointId;
        this.audioSourcesToMsidMap = new Map();
        this.videoSourcesToMsidMap = new Map();
    }
    /**
     * Makes sure that muted local video tracks associated with the parent
     * {@link TraceablePeerConnection} are described in the local SDP. It's done
     * in order to prevent from sending 'source-remove'/'source-add' Jingle
     * notifications when local video track is muted (<tt>MediaStream</tt> is
     * removed from the peerconnection).
     *
     * NOTE 1 video track is assumed
     *
     * @param {SdpTransformWrap} transformer the transformer instance which will
     * be used to process the SDP.
     * @return {boolean} <tt>true</tt> if there were any modifications to
     * the SDP wrapped by <tt>transformer</tt>.
     * @private
     */
    _addMutedLocalVideoTracksToSDP(transformer) {
        var _a;
        // Go over each video tracks and check if the SDP has to be changed
        const localVideos = this.tpc.getLocalTracks(_service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_2__.MediaType.VIDEO);
        if (!localVideos.length) {
            return false;
        }
        else if (localVideos.length !== 1) {
            logger.error(`${this.tpc} there is more than 1 video track ! `
                + 'Strange things may happen !', localVideos);
        }
        const videoMLine = (_a = transformer.selectMedia(_service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_2__.MediaType.VIDEO)) === null || _a === void 0 ? void 0 : _a[0];
        if (!videoMLine) {
            logger.debug(`${this.tpc} unable to hack local video track SDP`
                + '- no "video" media');
            return false;
        }
        let modified = false;
        for (const videoTrack of localVideos) {
            const muted = videoTrack.isMuted();
            const mediaStream = videoTrack.getOriginalStream();
            const isCamera = videoTrack.videoType === _service_RTC_VideoType__WEBPACK_IMPORTED_MODULE_4__.VideoType.CAMERA;
            // During the mute/unmute operation there are periods of time when
            // the track's underlying MediaStream is not added yet to
            // the PeerConnection. The SDP needs to be munged in such case.
            const isInPeerConnection = mediaStream && this.tpc.isMediaStreamInPc(mediaStream);
            const shouldFakeSdp = isCamera && (muted || !isInPeerConnection);
            if (!shouldFakeSdp) {
                continue; // eslint-disable-line no-continue
            }
            // Inject removed SSRCs
            const requiredSSRCs = this.tpc.isSimulcastOn()
                ? this.tpc.simulcast.ssrcCache
                : [this.tpc.sdpConsistency.cachedPrimarySsrc];
            if (!requiredSSRCs.length) {
                logger.error(`No SSRCs stored for: ${videoTrack} in ${this.tpc}`);
                continue; // eslint-disable-line no-continue
            }
            modified = true;
            // We need to fake sendrecv.
            // NOTE the SDP produced here goes only to Jicofo and is never set
            // as localDescription. That's why
            // TraceablePeerConnection.mediaTransferActive is ignored here.
            videoMLine.direction = _service_RTC_MediaDirection__WEBPACK_IMPORTED_MODULE_1__.MediaDirection.SENDRECV;
            // Check if the recvonly has MSID
            const primarySSRC = requiredSSRCs[0];
            // FIXME The cname could come from the stream, but may turn out to
            // be too complex. It is fine to come up with any value, as long as
            // we only care about the actual SSRC values when deciding whether
            // or not an update should be sent.
            const primaryCname = `injected-${primarySSRC}`;
            for (const ssrcNum of requiredSSRCs) {
                // Remove old attributes
                videoMLine.removeSSRC(ssrcNum);
                // Inject
                videoMLine.addSSRCAttribute({
                    id: ssrcNum,
                    attribute: 'cname',
                    value: primaryCname
                });
                videoMLine.addSSRCAttribute({
                    id: ssrcNum,
                    attribute: 'msid',
                    value: videoTrack.storedMSID
                });
            }
            if (requiredSSRCs.length > 1) {
                const group = {
                    ssrcs: requiredSSRCs.join(' '),
                    semantics: 'SIM'
                };
                if (!videoMLine.findGroup(group.semantics, group.ssrcs)) {
                    // Inject the group
                    videoMLine.addSSRCGroup(group);
                }
            }
            // Insert RTX
            // FIXME in P2P RTX is used by Chrome regardless of config option
            // status. Because of that 'source-remove'/'source-add'
            // notifications are still sent to remove/add RTX SSRC and FID group
            if (!this.tpc.options.disableRtx) {
                this.tpc.rtxModifier.modifyRtxSsrcs2(videoMLine);
            }
        }
        return modified;
    }
    /**
     * Returns a string that can be set as the MSID attribute for a source.
     *
     * @param {string} mediaType - Media type of the source.
     * @param {string} trackId - Id of the MediaStreamTrack associated with the source.
     * @param {string} streamId - Id of the MediaStream associated with the source.
     * @returns {string|null}
     */
    _generateMsidAttribute(mediaType, trackId, streamId) {
        if (!(mediaType && trackId)) {
            logger.error(`Unable to munge local MSID - track id=${trackId} or media type=${mediaType} is missing`);
            return null;
        }
        const pcId = this.tpc.id;
        return `${streamId}-${pcId} ${trackId}-${pcId}`;
    }
    /**
     * Updates or adds a 'msid' attribute in the format '<endpoint_id>-<mediaType>-<trackIndex>-<tpcId>'
     * example - d8ff91-video-0-1
     * All other attributes like 'cname', 'label' and 'mslabel' are removed since these are not processed by Jicofo.
     *
     * @param {MLineWrap} mediaSection - The media part (audio or video) of the session description which will be
     * modified in place.
     * @returns {void}
     * @private
     */
    _transformMediaIdentifiers(mediaSection) {
        var _a, _b, _c, _d, _e;
        const mediaType = (_a = mediaSection.mLine) === null || _a === void 0 ? void 0 : _a.type;
        const mediaDirection = (_b = mediaSection.mLine) === null || _b === void 0 ? void 0 : _b.direction;
        const msidLine = (_c = mediaSection.mLine) === null || _c === void 0 ? void 0 : _c.msid;
        const sources = [...new Set((_e = (_d = mediaSection.mLine) === null || _d === void 0 ? void 0 : _d.ssrcs) === null || _e === void 0 ? void 0 : _e.map(s => s.id))];
        const streamId = `${this.localEndpointId}-${mediaType}`;
        const trackId = msidLine && msidLine.split(' ')[1];
        // Always overwrite msid since we want the msid to be in this format even if the browser generates one.
        for (const source of sources) {
            const msid = mediaSection.ssrcs.find(ssrc => ssrc.id === source && ssrc.attribute === 'msid');
            // Update the msid if the 'msid' attribute exists.
            if (msid) {
                const streamAndTrackIDs = msid.value.split(' ');
                const trackID = streamAndTrackIDs[1];
                this._updateSourcesToMsidMap(mediaType, streamId, trackID);
                // Update the msid.
                const storedStreamId = mediaType === _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_2__.MediaType.VIDEO
                    ? this.videoSourcesToMsidMap.get(trackID)
                    : this.audioSourcesToMsidMap.get(trackID);
                msid.value = this._generateMsidAttribute(mediaType, trackID, storedStreamId);
                // Generate the msid attribute using the 'trackId' from the msid line from the media description. Only
                // descriptions that have the direction set to 'sendonly' or 'sendrecv' will have the 'a=msid' line.
            }
            else if (trackId) {
                this._updateSourcesToMsidMap(mediaType, streamId, trackId);
                const storedStreamId = mediaType === _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_2__.MediaType.VIDEO
                    ? this.videoSourcesToMsidMap.get(trackId)
                    : this.audioSourcesToMsidMap.get(trackId);
                const generatedMsid = this._generateMsidAttribute(mediaType, trackId, storedStreamId);
                mediaSection.ssrcs.push({
                    id: source,
                    attribute: 'msid',
                    value: generatedMsid
                });
            }
        }
        // Ignore the 'cname', 'label' and 'mslabel' attributes and only have the 'msid' attribute.
        mediaSection.ssrcs = mediaSection.ssrcs.filter(ssrc => ssrc.attribute === 'msid');
        // On FF when the user has started muted create answer will generate a recv only SSRC. We don't want to signal
        // this SSRC in order to reduce the load of the xmpp server for large calls. Therefore the SSRC needs to be
        // removed from the SDP.
        //
        // For all other use cases (when the user has had media but then the user has stopped it) we want to keep the
        // receive only SSRCs in the SDP. Otherwise source-remove will be triggered and the next time the user add a
        // track we will reuse the SSRCs and send source-add with the same SSRCs. This is problematic because of issues
        // on Chrome and FF (https://bugzilla.mozilla.org/show_bug.cgi?id=1768729) when removing and then adding the
        // same SSRC in the remote sdp the remote track is not rendered.
        if (_browser__WEBPACK_IMPORTED_MODULE_5__["default"].isFirefox()
            && (mediaDirection === _service_RTC_MediaDirection__WEBPACK_IMPORTED_MODULE_1__.MediaDirection.RECVONLY || mediaDirection === _service_RTC_MediaDirection__WEBPACK_IMPORTED_MODULE_1__.MediaDirection.INACTIVE)
            && ((mediaType === _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_2__.MediaType.VIDEO && !this.tpc._hasHadVideoTrack)
                || (mediaType === _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_2__.MediaType.AUDIO && !this.tpc._hasHadAudioTrack))) {
            mediaSection.ssrcs = undefined;
            mediaSection.ssrcGroups = undefined;
        }
    }
    /**
     * Updates the MSID map.
     *
     * @param {string} mediaType The media type.
     * @param {string} streamId The stream id.
     * @param {string} trackId The track id.
     * @returns {void}
     */
    _updateSourcesToMsidMap(mediaType, streamId, trackId) {
        if (mediaType === _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_2__.MediaType.VIDEO) {
            if (!this.videoSourcesToMsidMap.has(trackId)) {
                const generatedStreamId = `${streamId}-${this.videoSourcesToMsidMap.size}`;
                this.videoSourcesToMsidMap.set(trackId, generatedStreamId);
            }
        }
        else if (!this.audioSourcesToMsidMap.has(trackId)) {
            const generatedStreamId = `${streamId}-${this.audioSourcesToMsidMap.size}`;
            this.audioSourcesToMsidMap.set(trackId, generatedStreamId);
        }
    }
    /**
     * Maybe modifies local description to fake local video tracks SDP when
     * those are muted.
     *
     * @param {object} desc the WebRTC SDP object instance for the local
     * description.
     * @returns {RTCSessionDescription}
     */
    maybeAddMutedLocalVideoTracksToSDP(desc) {
        if (!desc) {
            throw new Error('No local description passed in.');
        }
        const transformer = new _SdpTransformUtil__WEBPACK_IMPORTED_MODULE_7__.SdpTransformWrap(desc.sdp);
        if (this._addMutedLocalVideoTracksToSDP(transformer)) {
            return new RTCSessionDescription({
                type: desc.type,
                sdp: transformer.toRawSDP()
            });
        }
        return desc;
    }
    /**
     * This transformation will make sure that stream identifiers are unique
     * across all of the local PeerConnections even if the same stream is used
     * by multiple instances at the same time.
     * Each PeerConnection assigns different SSRCs to the same local
     * MediaStream, but the MSID remains the same as it's used to identify
     * the stream by the WebRTC backend. The transformation will append
     * {@link TraceablePeerConnection#id} at the end of each stream's identifier
     * ("cname", "msid", "label" and "mslabel").
     *
     * @param {RTCSessionDescription} sessionDesc - The local session
     * description (this instance remains unchanged).
     * @return {RTCSessionDescription} - Transformed local session description
     * (a modified copy of the one given as the input).
     */
    transformStreamIdentifiers(sessionDesc) {
        var _a;
        // FIXME similar check is probably duplicated in all other transformers
        if (!sessionDesc || !sessionDesc.sdp || !sessionDesc.type) {
            return sessionDesc;
        }
        const transformer = new _SdpTransformUtil__WEBPACK_IMPORTED_MODULE_7__.SdpTransformWrap(sessionDesc.sdp);
        const audioMLine = (_a = transformer.selectMedia(_service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_2__.MediaType.AUDIO)) === null || _a === void 0 ? void 0 : _a[0];
        if (audioMLine) {
            this._transformMediaIdentifiers(audioMLine);
            this._injectSourceNames(audioMLine);
        }
        const videoMlines = transformer.selectMedia(_service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_2__.MediaType.VIDEO);
        if (!_flags_FeatureFlags__WEBPACK_IMPORTED_MODULE_6__["default"].isMultiStreamSendSupportEnabled()) {
            videoMlines.splice(1);
        }
        for (const videoMLine of videoMlines) {
            this._transformMediaIdentifiers(videoMLine);
            this._injectSourceNames(videoMLine);
        }
        // Plan-b clients generate new SSRCs and trackIds whenever tracks are removed and added back to the
        // peerconnection, therefore local track based map for msids needs to be reset after every transformation.
        if (!this.tpc._usesUnifiedPlan) {
            this.audioSourcesToMsidMap.clear();
            this.videoSourcesToMsidMap.clear();
        }
        return new RTCSessionDescription({
            type: sessionDesc.type,
            sdp: transformer.toRawSDP()
        });
    }
    /**
     * Injects source names. Source names are need to for multiple streams per endpoint support. The final plan is to
     * use the "mid" attribute for source names, but because the SDP to Jingle conversion still operates in the Plan-B
     * semantics (one source name per media), a custom "name" attribute is injected into SSRC lines..
     *
     * @param {MLineWrap} mediaSection - The media part (audio or video) of the session description which will be
     * modified in place.
     * @returns {void}
     * @private
     */
    _injectSourceNames(mediaSection) {
        var _a, _b, _c, _d;
        const sources = [...new Set((_b = (_a = mediaSection.mLine) === null || _a === void 0 ? void 0 : _a.ssrcs) === null || _b === void 0 ? void 0 : _b.map(s => s.id))];
        const mediaType = (_c = mediaSection.mLine) === null || _c === void 0 ? void 0 : _c.type;
        if (!mediaType) {
            throw new Error('_transformMediaIdentifiers - no media type in mediaSection');
        }
        for (const source of sources) {
            const nameExists = mediaSection.ssrcs.find(ssrc => ssrc.id === source && ssrc.attribute === 'name');
            const msid = mediaSection.ssrcs.find(ssrc => ssrc.id === source && ssrc.attribute === 'msid').value;
            const streamId = msid.split(' ')[0];
            // Example stream id: d8ff91-video-8-1
            // In the example above 8 is the track index
            const trackIndexParts = streamId.split('-');
            const trackIndex = trackIndexParts[trackIndexParts.length - 2];
            const sourceName = (0,_service_RTC_SignalingLayer__WEBPACK_IMPORTED_MODULE_3__.getSourceNameForJitsiTrack)(this.localEndpointId, mediaType, trackIndex);
            if (!nameExists) {
                // Inject source names as a=ssrc:3124985624 name:endpointA-v0
                mediaSection.ssrcs.push({
                    id: source,
                    attribute: 'name',
                    value: sourceName
                });
            }
            if (mediaType === _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_2__.MediaType.VIDEO) {
                const videoType = (_d = this.tpc.getLocalVideoTracks().find(track => track.getSourceName() === sourceName)) === null || _d === void 0 ? void 0 : _d.getVideoType();
                if (videoType) {
                    // Inject videoType as a=ssrc:1234 videoType:desktop.
                    mediaSection.ssrcs.push({
                        id: source,
                        attribute: 'videoType',
                        value: videoType
                    });
                }
            }
        }
    }
}
//# sourceMappingURL=LocalSdpMunger.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/sdp/RtxModifier.js":
/*!********************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/sdp/RtxModifier.js ***!
  \********************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
var __filename = "/index.js";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (/* binding */ RtxModifier)
/* harmony export */ });
/* harmony import */ var _jitsi_logger__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @jitsi/logger */ "./node_modules/@jitsi/logger/lib/index.js");
/* harmony import */ var _jitsi_logger__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(_jitsi_logger__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var _service_RTC_MediaDirection__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../service/RTC/MediaDirection */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/RTC/MediaDirection.js");
/* harmony import */ var _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../service/RTC/MediaType */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/RTC/MediaType.js");
/* harmony import */ var _SDPUtil__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./SDPUtil */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/sdp/SDPUtil.js");
/* harmony import */ var _SdpTransformUtil__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./SdpTransformUtil */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/sdp/SdpTransformUtil.js");





const logger = (0,_jitsi_logger__WEBPACK_IMPORTED_MODULE_0__.getLogger)(__filename);
/**
 * Begin helper functions
 */
/**
 * Updates or inserts the appropriate rtx information for primarySsrc with
 *  the given rtxSsrc.  If no rtx ssrc for primarySsrc currently exists, it will
 *  add the appropriate ssrc and ssrc group lines.  If primarySsrc already has
 *  an rtx ssrc, the appropriate ssrc and group lines will be updated
 * @param {MLineWrap} mLine
 * @param {object} primarySsrcInfo the info (ssrc, msid & cname) for the
 *  primary ssrc
 * @param {number} rtxSsrc the rtx ssrc to associate with the primary ssrc
 */
function updateAssociatedRtxStream(mLine, primarySsrcInfo, rtxSsrc) {
    const primarySsrc = primarySsrcInfo.id;
    const primarySsrcMsid = primarySsrcInfo.msid;
    const primarySsrcCname = primarySsrcInfo.cname;
    const previousRtxSSRC = mLine.getRtxSSRC(primarySsrc);
    if (previousRtxSSRC === rtxSsrc) {
        return;
    }
    if (previousRtxSSRC) {
        // Stream already had an rtx ssrc that is different than the one given,
        //  remove all trace of the old one
        mLine.removeSSRC(previousRtxSSRC);
        mLine.removeGroupsWithSSRC(previousRtxSSRC);
    }
    mLine.addSSRCAttribute({
        id: rtxSsrc,
        attribute: 'cname',
        value: primarySsrcCname
    });
    mLine.addSSRCAttribute({
        id: rtxSsrc,
        attribute: 'msid',
        value: primarySsrcMsid
    });
    mLine.addSSRCGroup({
        semantics: 'FID',
        ssrcs: `${primarySsrc} ${rtxSsrc}`
    });
}
/**
 * End helper functions
 */
/**
 * Adds any missing RTX streams for video streams
 *  and makes sure that they remain consistent
 */
class RtxModifier {
    /**
     * Constructor
     */
    constructor() {
        /**
         * Map of video ssrc to corresponding RTX
         *  ssrc
         */
        this.correspondingRtxSsrcs = new Map();
    }
    /**
     * Clear the cached map of primary video ssrcs to
     *  their corresponding rtx ssrcs so that they will
     *  not be used for the next call to modifyRtxSsrcs
     */
    clearSsrcCache() {
        this.correspondingRtxSsrcs.clear();
    }
    /**
     * Explicitly set the primary video ssrc -> rtx ssrc
     *  mapping to be used in modifyRtxSsrcs
     * @param {Map} ssrcMapping a mapping of primary video
     *  ssrcs to their corresponding rtx ssrcs
     */
    setSsrcCache(ssrcMapping) {
        logger.debug('Setting ssrc cache to ', ssrcMapping);
        this.correspondingRtxSsrcs = ssrcMapping;
    }
    /**
     * Adds RTX ssrcs for any video ssrcs that don't already have them.  If the video ssrc has been seen before, and
     * already had an RTX ssrc generated, the same RTX ssrc will be used again.
     *
     * @param {string} sdpStr sdp in raw string format
     * @returns {string} The modified sdp in raw string format.
     */
    modifyRtxSsrcs(sdpStr) {
        let modified = false;
        const sdpTransformer = new _SdpTransformUtil__WEBPACK_IMPORTED_MODULE_4__.SdpTransformWrap(sdpStr);
        const videoMLines = sdpTransformer.selectMedia(_service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_2__.MediaType.VIDEO);
        if (!(videoMLines === null || videoMLines === void 0 ? void 0 : videoMLines.length)) {
            logger.debug(`No 'video' media found in the sdp: ${sdpStr}`);
            return sdpStr;
        }
        for (const videoMLine of videoMLines) {
            if (this.modifyRtxSsrcs2(videoMLine)) {
                modified = true;
            }
        }
        return modified ? sdpTransformer.toRawSDP() : sdpStr;
    }
    /**
     * Does the same thing as {@link modifyRtxSsrcs}, but takes the {@link MLineWrap} instance wrapping video media as
     * an argument.
     * @param {MLineWrap} videoMLine
     * @return {boolean} <tt>true</tt> if the SDP wrapped by {@link SdpTransformWrap} has been modified or
     * <tt>false</tt> otherwise.
     */
    modifyRtxSsrcs2(videoMLine) {
        if (videoMLine.direction === _service_RTC_MediaDirection__WEBPACK_IMPORTED_MODULE_1__.MediaDirection.RECVONLY) {
            return false;
        }
        if (videoMLine.getSSRCCount() < 1) {
            return false;
        }
        const primaryVideoSsrcs = videoMLine.getPrimaryVideoSSRCs();
        for (const ssrc of primaryVideoSsrcs) {
            const msid = videoMLine.getSSRCAttrValue(ssrc, 'msid');
            const cname = videoMLine.getSSRCAttrValue(ssrc, 'cname');
            let correspondingRtxSsrc = this.correspondingRtxSsrcs.get(ssrc);
            if (!correspondingRtxSsrc) {
                // If there's one in the sdp already for it, we'll just set
                //  that as the corresponding one
                const previousAssociatedRtxStream = videoMLine.getRtxSSRC(ssrc);
                if (previousAssociatedRtxStream) {
                    correspondingRtxSsrc = previousAssociatedRtxStream;
                }
                else {
                    correspondingRtxSsrc = _SDPUtil__WEBPACK_IMPORTED_MODULE_3__["default"].generateSsrc();
                }
                this.correspondingRtxSsrcs.set(ssrc, correspondingRtxSsrc);
            }
            updateAssociatedRtxStream(videoMLine, {
                id: ssrc,
                cname,
                msid
            }, correspondingRtxSsrc);
        }
        // FIXME we're not looking into much details whether the SDP has been
        // modified or not once the precondition requirements are met.
        return true;
    }
    /**
     * Strip all rtx streams from the given sdp.
     *
     * @param {string} sdpStr sdp in raw string format
     * @returns {string} sdp string with all rtx streams stripped
     */
    stripRtx(sdpStr) {
        const sdpTransformer = new _SdpTransformUtil__WEBPACK_IMPORTED_MODULE_4__.SdpTransformWrap(sdpStr);
        const videoMLines = sdpTransformer.selectMedia(_service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_2__.MediaType.VIDEO);
        if (!(videoMLines === null || videoMLines === void 0 ? void 0 : videoMLines.length)) {
            logger.debug(`No 'video' media found in the sdp: ${sdpStr}`);
            return sdpStr;
        }
        for (const videoMLine of videoMLines) {
            if (videoMLine.direction !== _service_RTC_MediaDirection__WEBPACK_IMPORTED_MODULE_1__.MediaDirection.RECVONLY
                && videoMLine.getSSRCCount()
                && videoMLine.containsAnySSRCGroups()) {
                const fidGroups = videoMLine.findGroups('FID');
                // Remove the fid groups from the mline
                videoMLine.removeGroupsBySemantics('FID');
                // Get the rtx ssrcs and remove them from the mline
                for (const fidGroup of fidGroups) {
                    const rtxSsrc = (0,_SdpTransformUtil__WEBPACK_IMPORTED_MODULE_4__.parseSecondarySSRC)(fidGroup);
                    videoMLine.removeSSRC(rtxSsrc);
                }
            }
        }
        return sdpTransformer.toRawSDP();
    }
}
//# sourceMappingURL=RtxModifier.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/sdp/SDP.js":
/*!************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/sdp/SDP.js ***!
  \************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (/* binding */ SDP)
/* harmony export */ });
/* harmony import */ var jquery__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! jquery */ "./node_modules/jquery/dist/jquery.js");
/* harmony import */ var jquery__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(jquery__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var lodash_clonedeep__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! lodash.clonedeep */ "./node_modules/lodash.clonedeep/index.js");
/* harmony import */ var lodash_clonedeep__WEBPACK_IMPORTED_MODULE_1___default = /*#__PURE__*/__webpack_require__.n(lodash_clonedeep__WEBPACK_IMPORTED_MODULE_1__);
/* harmony import */ var sdp_transform__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! sdp-transform */ "./node_modules/sdp-transform/lib/index.js");
/* harmony import */ var _service_RTC_MediaDirection__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../service/RTC/MediaDirection */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/RTC/MediaDirection.js");
/* harmony import */ var _browser__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../browser */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/browser/index.js");
/* harmony import */ var _SDPUtil__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./SDPUtil */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/sdp/SDPUtil.js");






/**
 *
 * @param sdp
 */
function SDP(sdp) {
    const media = sdp.split('\r\nm=');
    for (let i = 1, length = media.length; i < length; i++) {
        let mediaI = `m=${media[i]}`;
        if (i !== length - 1) {
            mediaI += '\r\n';
        }
        media[i] = mediaI;
    }
    const session = `${media.shift()}\r\n`;
    this.media = media;
    this.raw = session + media.join('');
    this.session = session;
}
/**
 * A flag will make {@link transportToJingle} and {@link jingle2media} replace
 * ICE candidates IPs with invalid value of '1.1.1.1' which will cause ICE
 * failure. The flag is used in the automated testing.
 * @type {boolean}
 */
SDP.prototype.failICE = false;
/**
 * Whether or not to remove TCP ice candidates when translating from/to jingle.
 * @type {boolean}
 */
SDP.prototype.removeTcpCandidates = false;
/**
 * Whether or not to remove UDP ice candidates when translating from/to jingle.
 * @type {boolean}
 */
SDP.prototype.removeUdpCandidates = false;
/**
 * Adds a new m-line to the description so that a new local source can then be attached to the transceiver that gets
 * added after a reneogtiation cycle.
 *
 * @param {MediaType} mediaType media type of the new source that is being added.
 */
SDP.prototype.addMlineForNewLocalSource = function (mediaType) {
    const mid = this.media.length;
    const sdp = sdp_transform__WEBPACK_IMPORTED_MODULE_2__.parse(this.raw);
    const mline = lodash_clonedeep__WEBPACK_IMPORTED_MODULE_1___default()(sdp.media.find(m => m.type === mediaType));
    // Edit media direction, mid and remove the existing ssrc lines in the m-line.
    mline.mid = mid;
    mline.direction = _service_RTC_MediaDirection__WEBPACK_IMPORTED_MODULE_3__.MediaDirection.RECVONLY;
    // Remove the ssrcs and source groups.
    mline.msid = undefined;
    mline.ssrcs = undefined;
    mline.ssrcGroups = undefined;
    sdp.media = sdp.media.concat(mline);
    // We regenerate the BUNDLE group (since we added a new m-line)
    sdp.groups.forEach(group => {
        if (group.type === 'BUNDLE') {
            const mids = group.mids.split(' ');
            mids.push(mid);
            group.mids = mids.join(' ');
        }
    });
    this.raw = sdp_transform__WEBPACK_IMPORTED_MODULE_2__.write(sdp);
};
/**
 * Returns map of MediaChannel mapped per channel idx.
 */
SDP.prototype.getMediaSsrcMap = function () {
    const mediaSSRCs = {};
    for (let mediaindex = 0; mediaindex < this.media.length; mediaindex++) {
        const mid = _SDPUtil__WEBPACK_IMPORTED_MODULE_5__["default"].parseMID(_SDPUtil__WEBPACK_IMPORTED_MODULE_5__["default"].findLine(this.media[mediaindex], 'a=mid:'));
        const media = {
            mediaindex,
            mid,
            ssrcs: {},
            ssrcGroups: []
        };
        mediaSSRCs[mediaindex] = media;
        _SDPUtil__WEBPACK_IMPORTED_MODULE_5__["default"].findLines(this.media[mediaindex], 'a=ssrc:').forEach(line => {
            const linessrc = line.substring(7).split(' ')[0];
            // allocate new ChannelSsrc
            if (!media.ssrcs[linessrc]) {
                media.ssrcs[linessrc] = {
                    ssrc: linessrc,
                    lines: []
                };
            }
            media.ssrcs[linessrc].lines.push(line);
        });
        _SDPUtil__WEBPACK_IMPORTED_MODULE_5__["default"].findLines(this.media[mediaindex], 'a=ssrc-group:').forEach(line => {
            const idx = line.indexOf(' ');
            const semantics = line.substr(0, idx).substr(13);
            const ssrcs = line.substr(14 + semantics.length).split(' ');
            if (ssrcs.length) {
                media.ssrcGroups.push({
                    semantics,
                    ssrcs
                });
            }
        });
    }
    return mediaSSRCs;
};
/**
 * Returns <tt>true</tt> if this SDP contains given SSRC.
 * @param ssrc the ssrc to check.
 * @returns {boolean} <tt>true</tt> if this SDP contains given SSRC.
 */
SDP.prototype.containsSSRC = function (ssrc) {
    // FIXME this code is really strange - improve it if you can
    const medias = this.getMediaSsrcMap();
    let result = false;
    Object.keys(medias).forEach(mediaindex => {
        if (result) {
            return;
        }
        if (medias[mediaindex].ssrcs[ssrc]) {
            result = true;
        }
    });
    return result;
};
// add content's to a jingle element
SDP.prototype.toJingle = function (elem, thecreator) {
    // https://xmpp.org/extensions/xep-0338.html
    _SDPUtil__WEBPACK_IMPORTED_MODULE_5__["default"].findLines(this.session, 'a=group:').forEach(line => {
        const parts = line.split(' ');
        const semantics = parts.shift().substr(8);
        elem.c('group', { xmlns: 'urn:xmpp:jingle:apps:grouping:0',
            semantics });
        for (let j = 0; j < parts.length; j++) {
            elem.c('content', { name: parts[j] }).up();
        }
        elem.up();
    });
    for (let i = 0; i < this.media.length; i++) {
        const mline = _SDPUtil__WEBPACK_IMPORTED_MODULE_5__["default"].parseMLine(this.media[i].split('\r\n')[0]);
        if (!(mline.media === 'audio'
            || mline.media === 'video'
            || mline.media === 'application')) {
            continue; // eslint-disable-line no-continue
        }
        let ssrc;
        const assrcline = _SDPUtil__WEBPACK_IMPORTED_MODULE_5__["default"].findLine(this.media[i], 'a=ssrc:');
        if (assrcline) {
            ssrc = assrcline.substring(7).split(' ')[0]; // take the first
        }
        else {
            ssrc = false;
        }
        elem.c('content', { creator: thecreator,
            name: mline.media });
        const amidline = _SDPUtil__WEBPACK_IMPORTED_MODULE_5__["default"].findLine(this.media[i], 'a=mid:');
        if (amidline) {
            // prefer identifier from a=mid if present
            const mid = _SDPUtil__WEBPACK_IMPORTED_MODULE_5__["default"].parseMID(amidline);
            elem.attrs({ name: mid });
        }
        if (mline.media === 'video' && typeof this.initialLastN === 'number') {
            elem.c('initial-last-n', { xmlns: 'jitsi:colibri2',
                value: this.initialLastN }).up();
        }
        if (mline.media === 'audio' || mline.media === 'video') {
            elem.c('description', { xmlns: 'urn:xmpp:jingle:apps:rtp:1',
                media: mline.media });
            if (ssrc) {
                elem.attrs({ ssrc });
            }
            for (let j = 0; j < mline.fmt.length; j++) {
                const rtpmap = _SDPUtil__WEBPACK_IMPORTED_MODULE_5__["default"].findLine(this.media[i], `a=rtpmap:${mline.fmt[j]}`);
                elem.c('payload-type', _SDPUtil__WEBPACK_IMPORTED_MODULE_5__["default"].parseRTPMap(rtpmap));
                // put any 'a=fmtp:' + mline.fmt[j] lines into <param name=foo
                // value=bar/>
                const afmtpline = _SDPUtil__WEBPACK_IMPORTED_MODULE_5__["default"].findLine(this.media[i], `a=fmtp:${mline.fmt[j]}`);
                if (afmtpline) {
                    const fmtpParameters = _SDPUtil__WEBPACK_IMPORTED_MODULE_5__["default"].parseFmtp(afmtpline);
                    // eslint-disable-next-line max-depth
                    for (let k = 0; k < fmtpParameters.length; k++) {
                        elem.c('parameter', fmtpParameters[k]).up();
                    }
                }
                // XEP-0293 -- map a=rtcp-fb
                this.rtcpFbToJingle(i, elem, mline.fmt[j]);
                elem.up();
            }
            if (ssrc) {
                const ssrcMap = _SDPUtil__WEBPACK_IMPORTED_MODULE_5__["default"].parseSSRC(this.media[i]);
                for (const [availableSsrc, ssrcParameters] of ssrcMap) {
                    const sourceName = _SDPUtil__WEBPACK_IMPORTED_MODULE_5__["default"].parseSourceNameLine(ssrcParameters);
                    const videoType = _SDPUtil__WEBPACK_IMPORTED_MODULE_5__["default"].parseVideoTypeLine(ssrcParameters);
                    elem.c('source', {
                        ssrc: availableSsrc,
                        name: sourceName,
                        videoType,
                        xmlns: 'urn:xmpp:jingle:apps:rtp:ssma:0'
                    });
                    const msid = _SDPUtil__WEBPACK_IMPORTED_MODULE_5__["default"].parseMSIDAttribute(ssrcParameters);
                    // eslint-disable-next-line max-depth
                    if (msid) {
                        elem.c('parameter');
                        elem.attrs({ name: 'msid' });
                        elem.attrs({ value: msid });
                        elem.up();
                    }
                    elem.up();
                }
                // XEP-0339 handle ssrc-group attributes
                const ssrcGroupLines = _SDPUtil__WEBPACK_IMPORTED_MODULE_5__["default"].findLines(this.media[i], 'a=ssrc-group:');
                ssrcGroupLines.forEach(line => {
                    const idx = line.indexOf(' ');
                    const semantics = line.substr(0, idx).substr(13);
                    const ssrcs = line.substr(14 + semantics.length).split(' ');
                    if (ssrcs.length) {
                        elem.c('ssrc-group', { semantics,
                            xmlns: 'urn:xmpp:jingle:apps:rtp:ssma:0' });
                        ssrcs.forEach(s => elem.c('source', { ssrc: s }).up());
                        elem.up();
                    }
                });
            }
            const ridLines = _SDPUtil__WEBPACK_IMPORTED_MODULE_5__["default"].findLines(this.media[i], 'a=rid:');
            if (ridLines.length && _browser__WEBPACK_IMPORTED_MODULE_4__["default"].usesRidsForSimulcast()) {
                // Map a line which looks like "a=rid:2 send" to just
                // the rid ("2")
                const rids = ridLines
                    .map(ridLine => ridLine.split(':')[1])
                    .map(ridInfo => ridInfo.split(' ')[0]);
                rids.forEach(rid => {
                    elem.c('source', {
                        rid,
                        xmlns: 'urn:xmpp:jingle:apps:rtp:ssma:0'
                    });
                    elem.up();
                });
                const unifiedSimulcast = _SDPUtil__WEBPACK_IMPORTED_MODULE_5__["default"].findLine(this.media[i], 'a=simulcast:');
                if (unifiedSimulcast) {
                    elem.c('rid-group', {
                        semantics: 'SIM',
                        xmlns: 'urn:xmpp:jingle:apps:rtp:ssma:0'
                    });
                    rids.forEach(rid => {
                        elem.c('source', { rid }).up();
                    });
                    elem.up();
                }
            }
            if (_SDPUtil__WEBPACK_IMPORTED_MODULE_5__["default"].findLine(this.media[i], 'a=rtcp-mux')) {
                elem.c('rtcp-mux').up();
            }
            // XEP-0293 -- map a=rtcp-fb:*
            this.rtcpFbToJingle(i, elem, '*');
            // XEP-0294
            const extmapLines = _SDPUtil__WEBPACK_IMPORTED_MODULE_5__["default"].findLines(this.media[i], 'a=extmap:', this.session);
            for (let j = 0; j < extmapLines.length; j++) {
                const extmap = _SDPUtil__WEBPACK_IMPORTED_MODULE_5__["default"].parseExtmap(extmapLines[j]);
                elem.c('rtp-hdrext', {
                    xmlns: 'urn:xmpp:jingle:apps:rtp:rtp-hdrext:0',
                    uri: extmap.uri,
                    id: extmap.value
                });
                // eslint-disable-next-line max-depth
                if (extmap.hasOwnProperty('direction')) {
                    // eslint-disable-next-line max-depth
                    switch (extmap.direction) {
                        case _service_RTC_MediaDirection__WEBPACK_IMPORTED_MODULE_3__.MediaDirection.SENDONLY:
                            elem.attrs({ senders: 'responder' });
                            break;
                        case _service_RTC_MediaDirection__WEBPACK_IMPORTED_MODULE_3__.MediaDirection.RECVONLY:
                            elem.attrs({ senders: 'initiator' });
                            break;
                        case _service_RTC_MediaDirection__WEBPACK_IMPORTED_MODULE_3__.MediaDirection.SENDRECV:
                            elem.attrs({ senders: 'both' });
                            break;
                        case _service_RTC_MediaDirection__WEBPACK_IMPORTED_MODULE_3__.MediaDirection.INACTIVE:
                            elem.attrs({ senders: 'none' });
                            break;
                    }
                }
                // TODO: handle params
                elem.up();
            }
            if (_SDPUtil__WEBPACK_IMPORTED_MODULE_5__["default"].findLine(this.media[i], 'a=extmap-allow-mixed', this.session)) {
                elem.c('extmap-allow-mixed', {
                    xmlns: 'urn:xmpp:jingle:apps:rtp:rtp-hdrext:0'
                });
                elem.up();
            }
            elem.up(); // end of description
        }
        // map ice-ufrag/pwd, dtls fingerprint, candidates
        this.transportToJingle(i, elem);
        const m = this.media[i];
        if (_SDPUtil__WEBPACK_IMPORTED_MODULE_5__["default"].findLine(m, `a=${_service_RTC_MediaDirection__WEBPACK_IMPORTED_MODULE_3__.MediaDirection.SENDRECV}`)) {
            elem.attrs({ senders: 'both' });
        }
        else if (_SDPUtil__WEBPACK_IMPORTED_MODULE_5__["default"].findLine(m, `a=${_service_RTC_MediaDirection__WEBPACK_IMPORTED_MODULE_3__.MediaDirection.SENDONLY}`)) {
            elem.attrs({ senders: 'initiator' });
        }
        else if (_SDPUtil__WEBPACK_IMPORTED_MODULE_5__["default"].findLine(m, `a=${_service_RTC_MediaDirection__WEBPACK_IMPORTED_MODULE_3__.MediaDirection.RECVONLY}`)) {
            elem.attrs({ senders: 'responder' });
        }
        else if (_SDPUtil__WEBPACK_IMPORTED_MODULE_5__["default"].findLine(m, `a=${_service_RTC_MediaDirection__WEBPACK_IMPORTED_MODULE_3__.MediaDirection.INACTIVE}`)) {
            elem.attrs({ senders: 'none' });
        }
        // Reject an m-line only when port is 0 and a=bundle-only is not present in the section.
        // The port is automatically set to 0 when bundle-only is used.
        if (mline.port === '0' && !_SDPUtil__WEBPACK_IMPORTED_MODULE_5__["default"].findLine(m, 'a=bundle-only', this.session)) {
            // estos hack to reject an m-line
            elem.attrs({ senders: 'rejected' });
        }
        elem.up(); // end of content
    }
    elem.up();
    return elem;
};
SDP.prototype.transportToJingle = function (mediaindex, elem) {
    elem.c('transport');
    // XEP-0343 DTLS/SCTP
    const sctpport = _SDPUtil__WEBPACK_IMPORTED_MODULE_5__["default"].findLine(this.media[mediaindex], 'a=sctp-port:', this.session);
    const sctpmap = _SDPUtil__WEBPACK_IMPORTED_MODULE_5__["default"].findLine(this.media[mediaindex], 'a=sctpmap:', this.session);
    if (sctpport) {
        const sctpAttrs = _SDPUtil__WEBPACK_IMPORTED_MODULE_5__["default"].parseSCTPPort(sctpport);
        elem.c('sctpmap', {
            xmlns: 'urn:xmpp:jingle:transports:dtls-sctp:1',
            number: sctpAttrs,
            protocol: 'webrtc-datachannel' /* protocol */
        });
        // The parser currently requires streams to be present
        elem.attrs({ streams: 0 });
        elem.up();
    }
    else if (sctpmap) {
        const sctpAttrs = _SDPUtil__WEBPACK_IMPORTED_MODULE_5__["default"].parseSCTPMap(sctpmap);
        elem.c('sctpmap', {
            xmlns: 'urn:xmpp:jingle:transports:dtls-sctp:1',
            number: sctpAttrs[0],
            protocol: sctpAttrs[1] /* protocol */
        });
        // Optional stream count attribute
        if (sctpAttrs.length > 2) {
            elem.attrs({ streams: sctpAttrs[2] });
        }
        else {
            elem.attrs({ streams: 0 });
        }
        elem.up();
    }
    // XEP-0320
    const fingerprints = _SDPUtil__WEBPACK_IMPORTED_MODULE_5__["default"].findLines(this.media[mediaindex], 'a=fingerprint:', this.session);
    fingerprints.forEach(line => {
        const fingerprint = _SDPUtil__WEBPACK_IMPORTED_MODULE_5__["default"].parseFingerprint(line);
        fingerprint.xmlns = 'urn:xmpp:jingle:apps:dtls:0';
        elem.c('fingerprint').t(fingerprint.fingerprint);
        delete fingerprint.fingerprint;
        const setupLine = _SDPUtil__WEBPACK_IMPORTED_MODULE_5__["default"].findLine(this.media[mediaindex], 'a=setup:', this.session);
        if (setupLine) {
            fingerprint.setup = setupLine.substr(8);
        }
        elem.attrs(fingerprint);
        elem.up(); // end of fingerprint
    });
    const iceParameters = _SDPUtil__WEBPACK_IMPORTED_MODULE_5__["default"].iceparams(this.media[mediaindex], this.session);
    if (iceParameters) {
        iceParameters.xmlns = 'urn:xmpp:jingle:transports:ice-udp:1';
        elem.attrs(iceParameters);
        // XEP-0176
        const candidateLines = _SDPUtil__WEBPACK_IMPORTED_MODULE_5__["default"].findLines(this.media[mediaindex], 'a=candidate:', this.session);
        candidateLines.forEach(line => {
            const candidate = _SDPUtil__WEBPACK_IMPORTED_MODULE_5__["default"].candidateToJingle(line);
            if (this.failICE) {
                candidate.ip = '1.1.1.1';
            }
            const protocol = candidate && typeof candidate.protocol === 'string'
                ? candidate.protocol.toLowerCase()
                : '';
            if ((this.removeTcpCandidates
                && (protocol === 'tcp' || protocol === 'ssltcp'))
                || (this.removeUdpCandidates && protocol === 'udp')) {
                return;
            }
            elem.c('candidate', candidate).up();
        });
    }
    elem.up(); // end of transport
};
// XEP-0293
SDP.prototype.rtcpFbToJingle = function (mediaindex, elem, payloadtype) {
    const lines = _SDPUtil__WEBPACK_IMPORTED_MODULE_5__["default"].findLines(this.media[mediaindex], `a=rtcp-fb:${payloadtype}`);
    lines.forEach(line => {
        const feedback = _SDPUtil__WEBPACK_IMPORTED_MODULE_5__["default"].parseRTCPFB(line);
        if (feedback.type === 'trr-int') {
            elem.c('rtcp-fb-trr-int', {
                xmlns: 'urn:xmpp:jingle:apps:rtp:rtcp-fb:0',
                value: feedback.params[0]
            });
            elem.up();
        }
        else {
            elem.c('rtcp-fb', {
                xmlns: 'urn:xmpp:jingle:apps:rtp:rtcp-fb:0',
                type: feedback.type
            });
            if (feedback.params.length > 0) {
                elem.attrs({ 'subtype': feedback.params[0] });
            }
            elem.up();
        }
    });
};
SDP.prototype.rtcpFbFromJingle = function (elem, payloadtype) {
    let sdp = '';
    const feedbackElementTrrInt = elem.find('>rtcp-fb-trr-int[xmlns="urn:xmpp:jingle:apps:rtp:rtcp-fb:0"]');
    if (feedbackElementTrrInt.length) {
        sdp += 'a=rtcp-fb:* trr-int ';
        if (feedbackElementTrrInt.attr('value')) {
            sdp += feedbackElementTrrInt.attr('value');
        }
        else {
            sdp += '0';
        }
        sdp += '\r\n';
    }
    const feedbackElements = elem.find('>rtcp-fb[xmlns="urn:xmpp:jingle:apps:rtp:rtcp-fb:0"]');
    feedbackElements.each((_, fb) => {
        sdp += `a=rtcp-fb:${payloadtype} ${fb.getAttribute('type')}`;
        if (fb.hasAttribute('subtype')) {
            sdp += ` ${fb.getAttribute('subtype')}`;
        }
        sdp += '\r\n';
    });
    return sdp;
};
// construct an SDP from a jingle stanza
SDP.prototype.fromJingle = function (jingle) {
    const sessionId = Date.now();
    // Use a unique session id for every TPC.
    this.raw = 'v=0\r\n'
        + `o=- ${sessionId} 2 IN IP4 0.0.0.0\r\n`
        + 's=-\r\n'
        + 't=0 0\r\n';
    // http://tools.ietf.org/html/draft-ietf-mmusic-sdp-bundle-negotiation-04
    // #section-8
    const groups = jquery__WEBPACK_IMPORTED_MODULE_0___default()(jingle).find('>group[xmlns="urn:xmpp:jingle:apps:grouping:0"]');
    if (groups.length) {
        groups.each((idx, group) => {
            const contents = jquery__WEBPACK_IMPORTED_MODULE_0___default()(group)
                .find('>content')
                .map((_, content) => content.getAttribute('name'))
                .get();
            if (contents.length > 0) {
                this.raw
                    += `a=group:${group.getAttribute('semantics')
                        || group.getAttribute('type')} ${contents.join(' ')}\r\n`;
            }
        });
    }
    this.session = this.raw;
    jingle.find('>content').each((_, content) => {
        const m = this.jingle2media(jquery__WEBPACK_IMPORTED_MODULE_0___default()(content));
        this.media.push(m);
    });
    // reconstruct msid-semantic -- apparently not necessary
    /*
     var msid = SDPUtil.parseSSRC(this.raw);
     if (msid.hasOwnProperty('mslabel')) {
     this.session += "a=msid-semantic: WMS " + msid.mslabel + "\r\n";
     }
     */
    this.raw = this.session + this.media.join('');
};
// translate a jingle content element into an an SDP media part
SDP.prototype.jingle2media = function (content) {
    const desc = content.find('>description');
    const transport = content.find('>transport[xmlns="urn:xmpp:jingle:transports:ice-udp:1"]');
    let sdp = '';
    const sctp = transport.find('>sctpmap[xmlns="urn:xmpp:jingle:transports:dtls-sctp:1"]');
    const media = { media: desc.attr('media') };
    media.port = '9';
    if (content.attr('senders') === 'rejected') {
        // estos hack to reject an m-line.
        media.port = '0';
    }
    if (transport.find('>fingerprint[xmlns="urn:xmpp:jingle:apps:dtls:0"]').length) {
        media.proto = sctp.length ? 'UDP/DTLS/SCTP' : 'UDP/TLS/RTP/SAVPF';
    }
    else {
        media.proto = 'UDP/TLS/RTP/SAVPF';
    }
    if (sctp.length) {
        sdp += `m=application ${media.port} UDP/DTLS/SCTP webrtc-datachannel\r\n`;
        sdp += `a=sctp-port:${sctp.attr('number')}\r\n`;
        sdp += 'a=max-message-size:262144\r\n';
    }
    else {
        media.fmt
            = desc
                .find('>payload-type')
                .map((_, payloadType) => payloadType.getAttribute('id'))
                .get();
        sdp += `${_SDPUtil__WEBPACK_IMPORTED_MODULE_5__["default"].buildMLine(media)}\r\n`;
    }
    sdp += 'c=IN IP4 0.0.0.0\r\n';
    if (!sctp.length) {
        sdp += 'a=rtcp:1 IN IP4 0.0.0.0\r\n';
    }
    // XEP-0176 ICE parameters
    if (transport.length) {
        if (transport.attr('ufrag')) {
            sdp += `${_SDPUtil__WEBPACK_IMPORTED_MODULE_5__["default"].buildICEUfrag(transport.attr('ufrag'))}\r\n`;
        }
        if (transport.attr('pwd')) {
            sdp += `${_SDPUtil__WEBPACK_IMPORTED_MODULE_5__["default"].buildICEPwd(transport.attr('pwd'))}\r\n`;
        }
        transport.find('>fingerprint[xmlns="urn:xmpp:jingle:apps:dtls:0"]').each((_, fingerprint) => {
            sdp += `a=fingerprint:${fingerprint.getAttribute('hash')}`;
            sdp += ` ${jquery__WEBPACK_IMPORTED_MODULE_0___default()(fingerprint).text()}`;
            sdp += '\r\n';
            if (fingerprint.hasAttribute('setup')) {
                sdp += `a=setup:${fingerprint.getAttribute('setup')}\r\n`;
            }
        });
    }
    // XEP-0176 ICE candidates
    transport.find('>candidate')
        .each((_, candidate) => {
        let protocol = candidate.getAttribute('protocol');
        protocol
            = typeof protocol === 'string' ? protocol.toLowerCase() : '';
        if ((this.removeTcpCandidates
            && (protocol === 'tcp' || protocol === 'ssltcp'))
            || (this.removeUdpCandidates && protocol === 'udp')) {
            return;
        }
        else if (this.failICE) {
            candidate.setAttribute('ip', '1.1.1.1');
        }
        sdp += _SDPUtil__WEBPACK_IMPORTED_MODULE_5__["default"].candidateFromJingle(candidate);
    });
    switch (content.attr('senders')) {
        case 'initiator':
            sdp += `a=${_service_RTC_MediaDirection__WEBPACK_IMPORTED_MODULE_3__.MediaDirection.SENDONLY}\r\n`;
            break;
        case 'responder':
            sdp += `a=${_service_RTC_MediaDirection__WEBPACK_IMPORTED_MODULE_3__.MediaDirection.RECVONLY}\r\n`;
            break;
        case 'none':
            sdp += `a=${_service_RTC_MediaDirection__WEBPACK_IMPORTED_MODULE_3__.MediaDirection.INACTIVE}\r\n`;
            break;
        case 'both':
            sdp += `a=${_service_RTC_MediaDirection__WEBPACK_IMPORTED_MODULE_3__.MediaDirection.SENDRECV}\r\n`;
            break;
    }
    sdp += `a=mid:${content.attr('name')}\r\n`;
    // <description><rtcp-mux/></description>
    // see http://code.google.com/p/libjingle/issues/detail?id=309 -- no spec
    // though
    // and http://mail.jabber.org/pipermail/jingle/2011-December/001761.html
    if (desc.find('>rtcp-mux').length) {
        sdp += 'a=rtcp-mux\r\n';
    }
    desc.find('>payload-type').each((_, payloadType) => {
        sdp += `${_SDPUtil__WEBPACK_IMPORTED_MODULE_5__["default"].buildRTPMap(payloadType)}\r\n`;
        if (jquery__WEBPACK_IMPORTED_MODULE_0___default()(payloadType).find('>parameter').length) {
            sdp += `a=fmtp:${payloadType.getAttribute('id')} `;
            sdp
                += jquery__WEBPACK_IMPORTED_MODULE_0___default()(payloadType)
                    .find('>parameter')
                    .map((__, parameter) => {
                    const name = parameter.getAttribute('name');
                    return ((name ? `${name}=` : '')
                        + parameter.getAttribute('value'));
                })
                    .get()
                    .join(';');
            sdp += '\r\n';
        }
        // xep-0293
        sdp += this.rtcpFbFromJingle(jquery__WEBPACK_IMPORTED_MODULE_0___default()(payloadType), payloadType.getAttribute('id'));
    });
    // xep-0293
    sdp += this.rtcpFbFromJingle(desc, '*');
    // xep-0294
    desc
        .find('>rtp-hdrext[xmlns="urn:xmpp:jingle:apps:rtp:rtp-hdrext:0"]')
        .each((_, hdrExt) => {
        sdp
            += `a=extmap:${hdrExt.getAttribute('id')} ${hdrExt.getAttribute('uri')}\r\n`;
    });
    if (desc.find('>extmap-allow-mixed[xmlns="urn:xmpp:jingle:apps:rtp:rtp-hdrext:0"]').length > 0) {
        sdp += 'a=extmap-allow-mixed\r\n';
    }
    // XEP-0339 handle ssrc-group attributes
    desc
        .find('>ssrc-group[xmlns="urn:xmpp:jingle:apps:rtp:ssma:0"]')
        .each((_, ssrcGroup) => {
        const semantics = ssrcGroup.getAttribute('semantics');
        const ssrcs = jquery__WEBPACK_IMPORTED_MODULE_0___default()(ssrcGroup)
            .find('>source')
            .map((__, source) => source.getAttribute('ssrc'))
            .get();
        if (ssrcs.length) {
            sdp += `a=ssrc-group:${semantics} ${ssrcs.join(' ')}\r\n`;
        }
    });
    // XEP-0339 handle source attributes
    let userSources = '';
    let nonUserSources = '';
    desc
        .find('>source[xmlns="urn:xmpp:jingle:apps:rtp:ssma:0"]')
        .each((_, source) => {
        const ssrc = source.getAttribute('ssrc');
        let isUserSource = true;
        let sourceStr = '';
        jquery__WEBPACK_IMPORTED_MODULE_0___default()(source)
            .find('>parameter')
            .each((__, parameter) => {
            const name = parameter.getAttribute('name');
            let value = parameter.getAttribute('value');
            value = _SDPUtil__WEBPACK_IMPORTED_MODULE_5__["default"].filterSpecialChars(value);
            sourceStr += `a=ssrc:${ssrc} ${name}`;
            if (value && value.length) {
                sourceStr += `:${value}`;
            }
            sourceStr += '\r\n';
            if (value === null || value === void 0 ? void 0 : value.includes('mixedmslabel')) {
                isUserSource = false;
            }
        });
        if (isUserSource) {
            userSources += sourceStr;
        }
        else {
            nonUserSources += sourceStr;
        }
    });
    // The sdp-interop package is relying the mixedmslabel m line to be the first one in order to set the direction
    // to sendrecv.
    sdp += nonUserSources + userSources;
    return sdp;
};
//# sourceMappingURL=SDP.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/sdp/SDPDiffer.js":
/*!******************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/sdp/SDPDiffer.js ***!
  \******************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (/* binding */ SDPDiffer)
/* harmony export */ });
/* harmony import */ var _SDPUtil__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./SDPUtil */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/sdp/SDPUtil.js");

// this could be useful in Array.prototype.
/**
 *
 * @param array1
 * @param array2
 */
function arrayEquals(array1, array2) {
    // if the other array is a falsy value, return
    if (!array2) {
        return false;
    }
    // compare lengths - can save a lot of time
    if (array1.length !== array2.length) {
        return false;
    }
    for (let i = 0, l = array1.length; i < l; i++) {
        // Check if we have nested arrays
        if (array1[i] instanceof Array && array2[i] instanceof Array) {
            // recurse into the nested arrays
            if (!array1[i].equals(array2[i])) {
                return false;
            }
        }
        else if (array1[i] !== array2[i]) {
            // Warning - two different object instances will never be
            // equal: {x:20} != {x:20}
            return false;
        }
    }
    return true;
}
/**
 *
 * @param mySDP
 * @param otherSDP
 */
function SDPDiffer(mySDP, otherSDP) {
    this.mySDP = mySDP;
    this.otherSDP = otherSDP;
    if (!mySDP) {
        throw new Error('"mySDP" is undefined!');
    }
    else if (!otherSDP) {
        throw new Error('"otherSDP" is undefined!');
    }
}
/**
 * Returns map of MediaChannel that contains media contained in
 * 'mySDP', but not contained in 'otherSdp'. Mapped by channel idx.
 */
SDPDiffer.prototype.getNewMedia = function () {
    const myMedias = this.mySDP.getMediaSsrcMap();
    const othersMedias = this.otherSDP.getMediaSsrcMap();
    const newMedia = {};
    Object.keys(othersMedias).forEach(othersMediaIdx => {
        const myMedia = myMedias[othersMediaIdx];
        const othersMedia = othersMedias[othersMediaIdx];
        if (!myMedia && othersMedia) {
            // Add whole channel
            newMedia[othersMediaIdx] = othersMedia;
            return;
        }
        // Look for new ssrcs across the channel
        Object.keys(othersMedia.ssrcs).forEach(ssrc => {
            if (Object.keys(myMedia.ssrcs).indexOf(ssrc) === -1) {
                // Allocate channel if we've found ssrc that doesn't exist in
                // our channel
                if (!newMedia[othersMediaIdx]) {
                    newMedia[othersMediaIdx] = {
                        mediaindex: othersMedia.mediaindex,
                        mid: othersMedia.mid,
                        ssrcs: {},
                        ssrcGroups: []
                    };
                }
                newMedia[othersMediaIdx].ssrcs[ssrc] = othersMedia.ssrcs[ssrc];
            }
            else if (othersMedia.ssrcs[ssrc].lines
                && myMedia.ssrcs[ssrc].lines) {
                // we want to detect just changes in adding/removing msid
                const myContainMsid = myMedia.ssrcs[ssrc].lines.find(line => line.indexOf('msid') !== -1) !== undefined;
                const newContainMsid = othersMedia.ssrcs[ssrc].lines.find(line => line.indexOf('msid') !== -1) !== undefined;
                if (myContainMsid !== newContainMsid) {
                    if (!newMedia[othersMediaIdx]) {
                        newMedia[othersMediaIdx] = {
                            mediaindex: othersMedia.mediaindex,
                            mid: othersMedia.mid,
                            ssrcs: {},
                            ssrcGroups: []
                        };
                    }
                    newMedia[othersMediaIdx].ssrcs[ssrc]
                        = othersMedia.ssrcs[ssrc];
                }
            }
        });
        // Look for new ssrc groups across the channels
        othersMedia.ssrcGroups.forEach(otherSsrcGroup => {
            // try to match the other ssrc-group with an ssrc-group of ours
            let matched = false;
            for (let i = 0; i < myMedia.ssrcGroups.length; i++) {
                const mySsrcGroup = myMedia.ssrcGroups[i];
                if (otherSsrcGroup.semantics === mySsrcGroup.semantics
                    && arrayEquals(otherSsrcGroup.ssrcs, mySsrcGroup.ssrcs)) {
                    matched = true;
                    break;
                }
            }
            if (!matched) {
                // Allocate channel if we've found an ssrc-group that doesn't
                // exist in our channel
                if (!newMedia[othersMediaIdx]) {
                    newMedia[othersMediaIdx] = {
                        mediaindex: othersMedia.mediaindex,
                        mid: othersMedia.mid,
                        ssrcs: {},
                        ssrcGroups: []
                    };
                }
                newMedia[othersMediaIdx].ssrcGroups.push(otherSsrcGroup);
            }
        });
    });
    return newMedia;
};
/**
 * TODO: document!
 */
SDPDiffer.prototype.toJingle = function (modify) {
    const sdpMediaSsrcs = this.getNewMedia();
    let modified = false;
    Object.keys(sdpMediaSsrcs).forEach(mediaindex => {
        modified = true;
        const media = sdpMediaSsrcs[mediaindex];
        modify.c('content', { name: media.mid });
        modify.c('description', { xmlns: 'urn:xmpp:jingle:apps:rtp:1',
            media: media.mid });
        // FIXME: not completely sure this operates on blocks and / or handles
        // different ssrcs correctly
        // generate sources from lines
        Object.keys(media.ssrcs).forEach(ssrcNum => {
            const mediaSsrc = media.ssrcs[ssrcNum];
            const ssrcLines = mediaSsrc.lines;
            const sourceName = _SDPUtil__WEBPACK_IMPORTED_MODULE_0__["default"].parseSourceNameLine(ssrcLines);
            const videoType = _SDPUtil__WEBPACK_IMPORTED_MODULE_0__["default"].parseVideoTypeLine(ssrcLines);
            modify.c('source', { xmlns: 'urn:xmpp:jingle:apps:rtp:ssma:0' });
            modify.attrs({
                name: sourceName,
                videoType,
                ssrc: mediaSsrc.ssrc
            });
            // Only MSID attribute is sent
            const msid = _SDPUtil__WEBPACK_IMPORTED_MODULE_0__["default"].parseMSIDAttribute(ssrcLines);
            if (msid) {
                modify.c('parameter');
                modify.attrs({ name: 'msid' });
                modify.attrs({ value: msid });
                modify.up();
            }
            modify.up(); // end of source
        });
        // generate source groups from lines
        media.ssrcGroups.forEach(ssrcGroup => {
            if (ssrcGroup.ssrcs.length) {
                modify.c('ssrc-group', {
                    semantics: ssrcGroup.semantics,
                    xmlns: 'urn:xmpp:jingle:apps:rtp:ssma:0'
                });
                ssrcGroup.ssrcs.forEach(ssrc => {
                    modify.c('source', { ssrc })
                        .up(); // end of source
                });
                modify.up(); // end of ssrc-group
            }
        });
        modify.up(); // end of description
        modify.up(); // end of content
    });
    return modified;
};
//# sourceMappingURL=SDPDiffer.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/sdp/SDPUtil.js":
/*!****************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/sdp/SDPUtil.js ***!
  \****************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
var __filename = "/index.js";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (__WEBPACK_DEFAULT_EXPORT__)
/* harmony export */ });
/* harmony import */ var _jitsi_logger__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @jitsi/logger */ "./node_modules/@jitsi/logger/lib/index.js");
/* harmony import */ var _jitsi_logger__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(_jitsi_logger__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var _service_RTC_CodecMimeType__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../service/RTC/CodecMimeType */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/RTC/CodecMimeType.js");
/* harmony import */ var _service_RTC_MediaDirection__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../service/RTC/MediaDirection */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/RTC/MediaDirection.js");
/* harmony import */ var _browser__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../browser */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/browser/index.js");
/* harmony import */ var _util_RandomUtil__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../util/RandomUtil */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/util/RandomUtil.js");
/* harmony import */ var _util_RandomUtil__WEBPACK_IMPORTED_MODULE_4___default = /*#__PURE__*/__webpack_require__.n(_util_RandomUtil__WEBPACK_IMPORTED_MODULE_4__);

const logger = (0,_jitsi_logger__WEBPACK_IMPORTED_MODULE_0__.getLogger)(__filename);




const SDPUtil = {
    filterSpecialChars(text) {
        // XXX Neither one of the falsy values (e.g. null, undefined, false,
        // "", etc.) "contain" special chars.
        // eslint-disable-next-line no-useless-escape
        return text ? text.replace(/[\\\/\{,\}\+]/g, '') : text;
    },
    iceparams(mediadesc, sessiondesc) {
        let data = null;
        let pwd, ufrag;
        if ((ufrag = SDPUtil.findLine(mediadesc, 'a=ice-ufrag:', sessiondesc))
            && (pwd
                = SDPUtil.findLine(mediadesc, 'a=ice-pwd:', sessiondesc))) {
            data = {
                ufrag: SDPUtil.parseICEUfrag(ufrag),
                pwd: SDPUtil.parseICEPwd(pwd)
            };
        }
        return data;
    },
    parseICEUfrag(line) {
        return line.substring(12);
    },
    buildICEUfrag(frag) {
        return `a=ice-ufrag:${frag}`;
    },
    parseICEPwd(line) {
        return line.substring(10);
    },
    buildICEPwd(pwd) {
        return `a=ice-pwd:${pwd}`;
    },
    parseMID(line) {
        return line.substring(6);
    },
    /**
     * Finds the MSID attribute in the given array of SSRC attribute lines and returns the value.
     *
     * @param {string[]} ssrcLines - an array of lines similar to 'a:213123 msid:stream-id track-id'.
     * @returns {undefined|string}
     */
    parseMSIDAttribute(ssrcLines) {
        const msidLine = ssrcLines.find(line => line.indexOf(' msid:') > 0);
        if (!msidLine) {
            return undefined;
        }
        const v = msidLine.substring(msidLine.indexOf(' msid:') + 6 /* the length of ' msid:' */);
        return SDPUtil.filterSpecialChars(v);
    },
    parseMLine(line) {
        const data = {};
        const parts = line.substring(2).split(' ');
        data.media = parts.shift();
        data.port = parts.shift();
        data.proto = parts.shift();
        if (parts[parts.length - 1] === '') { // trailing whitespace
            parts.pop();
        }
        data.fmt = parts;
        return data;
    },
    buildMLine(mline) {
        return (`m=${mline.media} ${mline.port} ${mline.proto} ${mline.fmt.join(' ')}`);
    },
    parseRTPMap(line) {
        const data = {};
        let parts = line.substring(9).split(' ');
        data.id = parts.shift();
        parts = parts[0].split('/');
        data.name = parts.shift();
        data.clockrate = parts.shift();
        data.channels = parts.length ? parts.shift() : '1';
        return data;
    },
    /**
     * Parses SDP line "a=sctpmap:..." and extracts SCTP port from it.
     * @param line eg. "a=sctpmap:5000 webrtc-datachannel"
     * @returns [SCTP port number, protocol, streams]
     */
    parseSCTPMap(line) {
        const parts = line.substring(10).split(' ');
        const sctpPort = parts[0];
        const protocol = parts[1];
        // Stream count is optional
        const streamCount = parts.length > 2 ? parts[2] : null;
        return [sctpPort, protocol, streamCount]; // SCTP port
    },
    parseSCTPPort(line) {
        return line.substring(12);
    },
    buildRTPMap(el) {
        let line = `a=rtpmap:${el.getAttribute('id')} ${el.getAttribute('name')}/${el.getAttribute('clockrate')}`;
        if (el.getAttribute('channels')
            && el.getAttribute('channels') !== '1') {
            line += `/${el.getAttribute('channels')}`;
        }
        return line;
    },
    parseCrypto(line) {
        const data = {};
        const parts = line.substring(9).split(' ');
        data.tag = parts.shift();
        data['crypto-suite'] = parts.shift();
        data['key-params'] = parts.shift();
        if (parts.length) {
            data['session-params'] = parts.join(' ');
        }
        return data;
    },
    parseFingerprint(line) {
        const data = {};
        const parts = line.substring(14).split(' ');
        data.hash = parts.shift();
        data.fingerprint = parts.shift();
        // TODO assert that fingerprint satisfies 2UHEX *(":" 2UHEX) ?
        return data;
    },
    parseFmtp(line) {
        const data = [];
        let parts = line.split(' ');
        parts.shift();
        parts = parts.join(' ').split(';');
        for (let i = 0; i < parts.length; i++) {
            let key = parts[i].split('=')[0];
            while (key.length && key[0] === ' ') {
                key = key.substring(1);
            }
            const value = parts[i].split('=')[1];
            if (key && value) {
                data.push({ name: key,
                    value });
            }
            else if (key) {
                // rfc 4733 (DTMF) style stuff
                data.push({ name: '',
                    value: key });
            }
        }
        return data;
    },
    parseICECandidate(line) {
        const candidate = {};
        const elems = line.split(' ');
        candidate.foundation = elems[0].substring(12);
        candidate.component = elems[1];
        candidate.protocol = elems[2].toLowerCase();
        candidate.priority = elems[3];
        candidate.ip = elems[4];
        candidate.port = elems[5];
        // elems[6] => "typ"
        candidate.type = elems[7];
        candidate.generation = 0; // default value, may be overwritten below
        for (let i = 8; i < elems.length; i += 2) {
            switch (elems[i]) {
                case 'raddr':
                    candidate['rel-addr'] = elems[i + 1];
                    break;
                case 'rport':
                    candidate['rel-port'] = elems[i + 1];
                    break;
                case 'generation':
                    candidate.generation = elems[i + 1];
                    break;
                case 'tcptype':
                    candidate.tcptype = elems[i + 1];
                    break;
                default: // TODO
                    logger.debug(`parseICECandidate not translating "${elems[i]}" = "${elems[i + 1]}"`);
            }
        }
        candidate.network = '1';
        // not applicable to SDP -- FIXME: should be unique, not just random
        // eslint-disable-next-line newline-per-chained-call
        candidate.id = Math.random().toString(36).substr(2, 10);
        return candidate;
    },
    buildICECandidate(cand) {
        let line = [
            `a=candidate:${cand.foundation}`,
            cand.component,
            cand.protocol,
            cand.priority,
            cand.ip,
            cand.port,
            'typ',
            cand.type
        ].join(' ');
        line += ' ';
        switch (cand.type) {
            case 'srflx':
            case 'prflx':
            case 'relay':
                if (cand.hasOwnAttribute('rel-addr')
                    && cand.hasOwnAttribute('rel-port')) {
                    line += 'raddr';
                    line += ' ';
                    line += cand['rel-addr'];
                    line += ' ';
                    line += 'rport';
                    line += ' ';
                    line += cand['rel-port'];
                    line += ' ';
                }
                break;
        }
        if (cand.hasOwnAttribute('tcptype')) {
            line += 'tcptype';
            line += ' ';
            line += cand.tcptype;
            line += ' ';
        }
        line += 'generation';
        line += ' ';
        line += cand.hasOwnAttribute('generation') ? cand.generation : '0';
        return line;
    },
    parseSSRC(desc) {
        // proprietary mapping of a=ssrc lines
        // TODO: see "Jingle RTP Source Description" by Juberti and P. Thatcher
        // on google docs and parse according to that
        const data = new Map();
        const lines = desc.split('\r\n');
        for (let i = 0; i < lines.length; i++) {
            if (lines[i].substring(0, 7) === 'a=ssrc:') {
                // FIXME: Use regex to smartly find the ssrc.
                const ssrc = lines[i].split('a=ssrc:')[1].split(' ')[0];
                if (!data.get(ssrc)) {
                    data.set(ssrc, []);
                }
                data.get(ssrc).push(lines[i]);
            }
        }
        return data;
    },
    /**
     * Gets the source name out of the name attribute "a=ssrc:254321 name:name1".
     *
     * @param {string[]} ssrcLines
     * @returns {string | undefined}
     */
    parseSourceNameLine(ssrcLines) {
        const sourceNameLine = ssrcLines.find(ssrcSdpLine => ssrcSdpLine.indexOf(' name:') > 0);
        // Everything past the "name:" part
        return sourceNameLine === null || sourceNameLine === void 0 ? void 0 : sourceNameLine.substring(sourceNameLine.indexOf(' name:') + 6);
    },
    /**
     * Parse the "videoType" attribute encoded in a set of SSRC attributes (e.g.
     * "a=ssrc:1234 videoType:desktop")
     *
     * @param {string[]} ssrcLines
     * @returns {string | undefined}
     */
    parseVideoTypeLine(ssrcLines) {
        const s = ' videoType:';
        const videoTypeLine = ssrcLines.find(ssrcSdpLine => ssrcSdpLine.indexOf(s) > 0);
        return videoTypeLine === null || videoTypeLine === void 0 ? void 0 : videoTypeLine.substring(videoTypeLine.indexOf(s) + s.length);
    },
    parseRTCPFB(line) {
        const parts = line.substr(10).split(' ');
        const data = {};
        data.pt = parts.shift();
        data.type = parts.shift();
        data.params = parts;
        return data;
    },
    parseExtmap(line) {
        const parts = line.substr(9).split(' ');
        const data = {};
        data.value = parts.shift();
        if (data.value.indexOf('/') === -1) {
            data.direction = 'both';
        }
        else {
            data.direction = data.value.substr(data.value.indexOf('/') + 1);
            data.value = data.value.substr(0, data.value.indexOf('/'));
        }
        data.uri = parts.shift();
        data.params = parts;
        return data;
    },
    findLine(haystack, needle, sessionpart) {
        let lines = haystack.split('\r\n');
        for (let i = 0; i < lines.length; i++) {
            if (lines[i].substring(0, needle.length) === needle) {
                return lines[i];
            }
        }
        if (!sessionpart) {
            return false;
        }
        // search session part
        lines = sessionpart.split('\r\n');
        for (let j = 0; j < lines.length; j++) {
            if (lines[j].substring(0, needle.length) === needle) {
                return lines[j];
            }
        }
        return false;
    },
    findLines(haystack, needle, sessionpart) {
        let lines = haystack.split('\r\n');
        const needles = [];
        for (let i = 0; i < lines.length; i++) {
            if (lines[i].substring(0, needle.length) === needle) {
                needles.push(lines[i]);
            }
        }
        if (needles.length || !sessionpart) {
            return needles;
        }
        // search session part
        lines = sessionpart.split('\r\n');
        for (let j = 0; j < lines.length; j++) {
            if (lines[j].substring(0, needle.length) === needle) {
                needles.push(lines[j]);
            }
        }
        return needles;
    },
    candidateToJingle(line) {
        // a=candidate:2979166662 1 udp 2113937151 192.168.2.100 57698 typ host
        // generation 0
        //      <candidate component=... foundation=... generation=... id=...
        // ip=... network=... port=... priority=... protocol=... type=.../>
        if (line.indexOf('candidate:') === 0) {
            // eslint-disable-next-line no-param-reassign
            line = `a=${line}`;
        }
        else if (line.substring(0, 12) !== 'a=candidate:') {
            logger.warn('parseCandidate called with a line that is not a candidate'
                + ' line');
            logger.warn(line);
            return null;
        }
        if (line.substring(line.length - 2) === '\r\n') { // chomp it
            // eslint-disable-next-line no-param-reassign
            line = line.substring(0, line.length - 2);
        }
        const candidate = {};
        const elems = line.split(' ');
        if (elems[6] !== 'typ') {
            logger.warn('did not find typ in the right place');
            logger.warn(line);
            return null;
        }
        candidate.foundation = elems[0].substring(12);
        candidate.component = elems[1];
        candidate.protocol = elems[2].toLowerCase();
        candidate.priority = elems[3];
        candidate.ip = elems[4];
        candidate.port = elems[5];
        // elems[6] => "typ"
        candidate.type = elems[7];
        candidate.generation = '0'; // default, may be overwritten below
        for (let i = 8; i < elems.length; i += 2) {
            switch (elems[i]) {
                case 'raddr':
                    candidate['rel-addr'] = elems[i + 1];
                    break;
                case 'rport':
                    candidate['rel-port'] = elems[i + 1];
                    break;
                case 'generation':
                    candidate.generation = elems[i + 1];
                    break;
                case 'tcptype':
                    candidate.tcptype = elems[i + 1];
                    break;
                default: // TODO
                    logger.debug(`not translating "${elems[i]}" = "${elems[i + 1]}"`);
            }
        }
        candidate.network = '1';
        // not applicable to SDP -- FIXME: should be unique, not just random
        // eslint-disable-next-line newline-per-chained-call
        candidate.id = Math.random().toString(36).substr(2, 10);
        return candidate;
    },
    candidateFromJingle(cand) {
        let line = 'a=candidate:';
        line += cand.getAttribute('foundation');
        line += ' ';
        line += cand.getAttribute('component');
        line += ' ';
        let protocol = cand.getAttribute('protocol');
        // use tcp candidates for FF
        if (_browser__WEBPACK_IMPORTED_MODULE_3__["default"].isFirefox() && protocol.toLowerCase() === 'ssltcp') {
            protocol = 'tcp';
        }
        line += protocol; // .toUpperCase(); // chrome M23 doesn't like this
        line += ' ';
        line += cand.getAttribute('priority');
        line += ' ';
        line += cand.getAttribute('ip');
        line += ' ';
        line += cand.getAttribute('port');
        line += ' ';
        line += 'typ';
        line += ` ${cand.getAttribute('type')}`;
        line += ' ';
        switch (cand.getAttribute('type')) {
            case 'srflx':
            case 'prflx':
            case 'relay':
                if (cand.getAttribute('rel-addr')
                    && cand.getAttribute('rel-port')) {
                    line += 'raddr';
                    line += ' ';
                    line += cand.getAttribute('rel-addr');
                    line += ' ';
                    line += 'rport';
                    line += ' ';
                    line += cand.getAttribute('rel-port');
                    line += ' ';
                }
                break;
        }
        if (protocol.toLowerCase() === 'tcp') {
            line += 'tcptype';
            line += ' ';
            line += cand.getAttribute('tcptype');
            line += ' ';
        }
        line += 'generation';
        line += ' ';
        line += cand.getAttribute('generation') || '0';
        return `${line}\r\n`;
    },
    /**
     * Parse the 'most' primary video ssrc from the given m line
     * @param {object} mLine object as parsed from transform.parse
     * @return {number} the primary video ssrc from the given m line
     */
    parsePrimaryVideoSsrc(videoMLine) {
        const numSsrcs = videoMLine.ssrcs
            .map(ssrcInfo => ssrcInfo.id)
            .filter((ssrc, index, array) => array.indexOf(ssrc) === index)
            .length;
        const numGroups = (videoMLine.ssrcGroups && videoMLine.ssrcGroups.length) || 0;
        if (numSsrcs > 1 && numGroups === 0) {
            // Ambiguous, can't figure out the primary
            return;
        }
        let primarySsrc = null;
        if (numSsrcs === 1) {
            primarySsrc = videoMLine.ssrcs[0].id;
        }
        else if (numSsrcs === 2) {
            // Can figure it out if there's an FID group
            const fidGroup = videoMLine.ssrcGroups.find(group => group.semantics === 'FID');
            if (fidGroup) {
                primarySsrc = fidGroup.ssrcs.split(' ')[0];
            }
        }
        else if (numSsrcs >= 3) {
            // Can figure it out if there's a sim group
            const simGroup = videoMLine.ssrcGroups.find(group => group.semantics === 'SIM');
            if (simGroup) {
                primarySsrc = simGroup.ssrcs.split(' ')[0];
            }
        }
        return primarySsrc;
    },
    /**
     * Generate an ssrc
     * @returns {number} an ssrc
     */
    generateSsrc() {
        return _util_RandomUtil__WEBPACK_IMPORTED_MODULE_4___default().randomInt(1, 0xffffffff);
    },
    /**
     * Get an attribute for the given ssrc with the given attributeName
     *  from the given mline
     * @param {object} mLine an mLine object as parsed from transform.parse
     * @param {number} ssrc the ssrc for which an attribute is desired
     * @param {string} attributeName the name of the desired attribute
     * @returns {string} the value corresponding to the given ssrc
     *  and attributeName
     */
    getSsrcAttribute(mLine, ssrc, attributeName) {
        for (let i = 0; i < mLine.ssrcs.length; ++i) {
            const ssrcLine = mLine.ssrcs[i];
            if (ssrcLine.id === ssrc
                && ssrcLine.attribute === attributeName) {
                return ssrcLine.value;
            }
        }
    },
    /**
     * Parses the ssrcs from the group sdp line and
     *  returns them as a list of numbers
     * @param {object} the ssrcGroup object as parsed from
     *  sdp-transform
     * @returns {list<number>} a list of the ssrcs in the group
     *  parsed as numbers
     */
    parseGroupSsrcs(ssrcGroup) {
        return ssrcGroup
            .ssrcs
            .split(' ')
            .map(ssrcStr => parseInt(ssrcStr, 10));
    },
    /**
     * Get the mline of the given type from the given sdp
     * @param {object} sdp sdp as parsed from transform.parse
     * @param {string} type the type of the desired mline (e.g. "video")
     * @returns {object} a media object
     */
    getMedia(sdp, type) {
        return sdp.media.find(m => m.type === type);
    },
    /**
     * Extracts the ICE username fragment from an SDP string.
     * @param {string} sdp the SDP in raw text format
     */
    getUfrag(sdp) {
        const ufragLines = sdp.split('\n').filter(line => line.startsWith('a=ice-ufrag:'));
        if (ufragLines.length > 0) {
            return ufragLines[0].substr('a=ice-ufrag:'.length);
        }
    },
    /**
     * Sets the given codecName as the preferred codec by moving it to the beginning
     * of the payload types list (modifies the given mline in place). All instances
     * of the codec are moved up.
     * @param {object} mLine the mline object from an sdp as parsed by transform.parse
     * @param {string} codecName the name of the preferred codec
     */
    preferCodec(mline, codecName) {
        if (!mline || !codecName) {
            return;
        }
        const matchingPayloadTypes = mline.rtp
            .filter(rtp => rtp.codec && rtp.codec.toLowerCase() === codecName.toLowerCase())
            .map(rtp => rtp.payload);
        if (matchingPayloadTypes) {
            // Call toString() on payloads to get around an issue within SDPTransform that sets
            // payloads as a number, instead of a string, when there is only one payload.
            const payloadTypes = mline.payloads
                .toString()
                .split(' ')
                .map(p => parseInt(p, 10));
            for (const pt of matchingPayloadTypes.reverse()) {
                const payloadIndex = payloadTypes.indexOf(pt);
                payloadTypes.splice(payloadIndex, 1);
                payloadTypes.unshift(pt);
            }
            mline.payloads = payloadTypes.join(' ');
        }
        else {
            logger.error(`No matching RTP payload type found for ${codecName}, failed to set preferred codecs`);
        }
    },
    /**
     * Strips the given codec from the given mline. All related RTX payload
     * types are also stripped. If the resulting mline would have no codecs,
     * it's disabled.
     *
     * @param {object} mLine the mline object from an sdp as parsed by transform.parse.
     * @param {string} codecName the name of the codec which will be stripped.
     * @param {boolean} highProfile determines if only the high profile H264 codec needs to be
     * stripped from the sdp when the passed codecName is H264.
     */
    stripCodec(mLine, codecName, highProfile = false) {
        if (!mLine || !codecName) {
            return;
        }
        const h264Pts = [];
        let removePts = [];
        const stripH264HighCodec = codecName.toLowerCase() === _service_RTC_CodecMimeType__WEBPACK_IMPORTED_MODULE_1__["default"].H264 && highProfile;
        for (const rtp of mLine.rtp) {
            if (rtp.codec
                && rtp.codec.toLowerCase() === codecName.toLowerCase()) {
                if (stripH264HighCodec) {
                    h264Pts.push(rtp.payload);
                }
                else {
                    removePts.push(rtp.payload);
                }
            }
        }
        // high profile H264 codecs have 64 as the first two bytes of the profile-level-id.
        if (stripH264HighCodec) {
            removePts = mLine.fmtp
                .filter(item => h264Pts.indexOf(item.payload) > -1 && item.config.includes('profile-level-id=64'))
                .map(item => item.payload);
        }
        if (removePts.length > 0) {
            // We also need to remove the payload types that are related to RTX
            // for the codecs we want to disable.
            const rtxApts = removePts.map(item => `apt=${item}`);
            const rtxPts = mLine.fmtp.filter(item => rtxApts.indexOf(item.config) !== -1);
            removePts.push(...rtxPts.map(item => item.payload));
            // Call toString() on payloads to get around an issue within
            // SDPTransform that sets payloads as a number, instead of a string,
            // when there is only one payload.
            const allPts = mLine.payloads
                .toString()
                .split(' ')
                .map(Number);
            const keepPts = allPts.filter(pt => removePts.indexOf(pt) === -1);
            if (keepPts.length === 0) {
                // There are no other codecs, disable the stream.
                mLine.port = 0;
                mLine.direction = _service_RTC_MediaDirection__WEBPACK_IMPORTED_MODULE_2__.MediaDirection.INACTIVE;
                mLine.payloads = '*';
            }
            else {
                mLine.payloads = keepPts.join(' ');
            }
            mLine.rtp = mLine.rtp.filter(item => keepPts.indexOf(item.payload) !== -1);
            mLine.fmtp = mLine.fmtp.filter(item => keepPts.indexOf(item.payload) !== -1);
            if (mLine.rtcpFb) {
                mLine.rtcpFb = mLine.rtcpFb.filter(item => keepPts.indexOf(item.payload) !== -1);
            }
        }
    }
};
/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (SDPUtil);
//# sourceMappingURL=SDPUtil.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/sdp/SdpConsistency.js":
/*!***********************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/sdp/SdpConsistency.js ***!
  \***********************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
var __filename = "/index.js";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (/* binding */ SdpConsistency)
/* harmony export */ });
/* harmony import */ var _jitsi_logger__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @jitsi/logger */ "./node_modules/@jitsi/logger/lib/index.js");
/* harmony import */ var _jitsi_logger__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(_jitsi_logger__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../service/RTC/MediaType */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/RTC/MediaType.js");
/* harmony import */ var _SdpTransformUtil__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./SdpTransformUtil */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/sdp/SdpTransformUtil.js");



const logger = (0,_jitsi_logger__WEBPACK_IMPORTED_MODULE_0__.getLogger)(__filename);
/**
 * Handles the work of keeping video ssrcs consistent across multiple
 * o/a cycles, making it such that all stream operations can be
 * kept local and do not need to be signaled.
 * NOTE: This only keeps the 'primary' video ssrc consistent: meaning
 * the primary video stream
 */
class SdpConsistency {
    /**
     * Constructor
     * @param {string} logPrefix the log prefix appended to every logged
     * message, currently used to distinguish for which
     * <tt>TraceablePeerConnection</tt> the instance works.
     */
    constructor(logPrefix) {
        this.clearVideoSsrcCache();
        this.logPrefix = logPrefix;
    }
    /**
     * Clear the cached video primary and primary rtx ssrcs so that
     *  they will not be used for the next call to
     *  makeVideoPrimarySsrcsConsistent
     */
    clearVideoSsrcCache() {
        this.cachedPrimarySsrc = null;
        this.injectRecvOnly = false;
    }
    /**
     * Explicitly set the primary ssrc to be used in
     *  makeVideoPrimarySsrcsConsistent
     * @param {number} primarySsrc the primarySsrc to be used
     *  in future calls to makeVideoPrimarySsrcsConsistent
     * @throws Error if <tt>primarySsrc</tt> is not a number
     */
    setPrimarySsrc(primarySsrc) {
        if (typeof primarySsrc !== 'number') {
            throw new Error('Primary SSRC must be a number!');
        }
        this.cachedPrimarySsrc = primarySsrc;
    }
    /**
     * Checks whether or not there is a primary video SSRC cached already.
     * @return {boolean}
     */
    hasPrimarySsrcCached() {
        return Boolean(this.cachedPrimarySsrc);
    }
    /**
     * Given an sdp string, either:
     *  1) record the primary video and primary rtx ssrcs to be
     *   used in future calls to makeVideoPrimarySsrcsConsistent or
     *  2) change the primary and primary rtx ssrcs in the given sdp
     *   to match the ones previously cached
     * @param {string} sdpStr the sdp string to (potentially)
     *  change to make the video ssrcs consistent
     * @returns {string} a (potentially) modified sdp string
     *  with ssrcs consistent with this class' cache
     */
    makeVideoPrimarySsrcsConsistent(sdpStr) {
        var _a;
        const sdpTransformer = new _SdpTransformUtil__WEBPACK_IMPORTED_MODULE_2__.SdpTransformWrap(sdpStr);
        const videoMLine = (_a = sdpTransformer.selectMedia(_service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_1__.MediaType.VIDEO)) === null || _a === void 0 ? void 0 : _a[0];
        if (!videoMLine) {
            logger.debug(`${this.logPrefix} no 'video' media found in the sdp: ${sdpStr}`);
            return sdpStr;
        }
        if (videoMLine.direction === 'recvonly') {
            // If the mline is recvonly, we'll add the primary
            //  ssrc as a recvonly ssrc
            if (this.cachedPrimarySsrc && this.injectRecvOnly) {
                videoMLine.addSSRCAttribute({
                    id: this.cachedPrimarySsrc,
                    attribute: 'cname',
                    value: `recvonly-${this.cachedPrimarySsrc}`
                });
            }
            else {
                logger.info(`${this.logPrefix} no SSRC found for the recvonly video stream!`);
            }
        }
        else {
            const newPrimarySsrc = videoMLine.getPrimaryVideoSsrc();
            if (!newPrimarySsrc) {
                logger.info(`${this.logPrefix} sdp-consistency couldn't parse new primary ssrc`);
                return sdpStr;
            }
            if (this.cachedPrimarySsrc) {
                videoMLine.replaceSSRC(newPrimarySsrc, this.cachedPrimarySsrc);
                for (const group of videoMLine.ssrcGroups) {
                    if (group.semantics === 'FID') {
                        const primarySsrc = (0,_SdpTransformUtil__WEBPACK_IMPORTED_MODULE_2__.parsePrimarySSRC)(group);
                        const rtxSsrc = (0,_SdpTransformUtil__WEBPACK_IMPORTED_MODULE_2__.parseSecondarySSRC)(group);
                        // eslint-disable-next-line max-depth
                        if (primarySsrc === newPrimarySsrc) {
                            group.ssrcs
                                = `${this.cachedPrimarySsrc} ${rtxSsrc}`;
                        }
                    }
                }
            }
            else {
                this.cachedPrimarySsrc = newPrimarySsrc;
            }
            this.injectRecvOnly = true;
        }
        return sdpTransformer.toRawSDP();
    }
}
//# sourceMappingURL=SdpConsistency.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/sdp/SdpSimulcast.js":
/*!*********************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/sdp/SdpSimulcast.js ***!
  \*********************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (/* binding */ SdpSimulcast)
/* harmony export */ });
/* harmony import */ var _service_RTC_MediaDirection__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../service/RTC/MediaDirection */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/RTC/MediaDirection.js");
/* harmony import */ var _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../service/RTC/MediaType */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/RTC/MediaType.js");
/* harmony import */ var sdp_transform__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! sdp-transform */ "./node_modules/sdp-transform/lib/index.js");



const DEFAULT_NUM_OF_LAYERS = 3;
/**
 * This class handles SDP munging for enabling simulcast for local video streams in Unified plan. A set of random SSRCs
 * are generated for the higher layer streams and they are cached for a given mid. The cached SSRCs are then reused on
 * the subsequent iterations while munging the local description. This class also handles imploding of the simulcast
 * SSRCs for remote endpoints into the primary FID group in remote description since Jicofo signals all SSRCs relevant
 * to a given endpoint.
 */
class SdpSimulcast {
    /**
     * Creates a new instance.
     *
     * @param options
     */
    constructor(options) {
        this._options = options;
        this._ssrcCache = new Map();
        if (!this._options.numOfLayers) {
            this._options.numOfLayers = DEFAULT_NUM_OF_LAYERS;
        }
    }
    /**
     * Updates the given media description using the SSRCs that were cached for the mid associated
     * with the media description and returns the modified media description.
     *
     * @param mLine
     * @returns
     */
    _fillSsrcsFromCache(mLine) {
        const mid = mLine.mid;
        const cachedSsrcs = this._ssrcCache.get(mid);
        const newSsrcs = this._parseSimLayers(mLine);
        const newMsid = this._getSsrcAttribute(mLine, newSsrcs[0], 'msid');
        const newCname = this._getSsrcAttribute(mLine, newSsrcs[0], 'cname');
        mLine.ssrcs = [];
        mLine.ssrcGroups = [];
        for (const ssrc of cachedSsrcs) {
            mLine.ssrcs.push({
                id: ssrc,
                attribute: 'msid',
                value: newMsid
            });
            mLine.ssrcs.push({
                id: ssrc,
                attribute: 'cname',
                value: newCname
            });
        }
        mLine.ssrcGroups.push({
            semantics: 'SIM',
            ssrcs: cachedSsrcs.join(' ')
        });
        return mLine;
    }
    /**
     * Generates a new set of SSRCs for the higher simulcast layers/streams and adds the attributes and SIM group to
     * the given media description and returns the modified media description.
     *
     * @param mLine
     * @param primarySsrc
     * @returns
     */
    _generateNewSsrcsForSimulcast(mLine, primarySsrc) {
        const cname = this._getSsrcAttribute(mLine, primarySsrc, 'cname');
        let msid = this._getSsrcAttribute(mLine, primarySsrc, 'msid');
        const addAssociatedAttributes = (mLine, ssrc) => {
            mLine.ssrcs.push({
                id: ssrc,
                attribute: 'cname',
                value: cname
            });
            mLine.ssrcs.push({
                id: ssrc,
                attribute: 'msid',
                value: msid
            });
        };
        // In Unified-plan mode, the a=ssrc lines with the msid attribute are not present (only cname attributes are
        // present) in the answers that Chrome and Safari generate for an offer received from Jicofo. Generate these
        // a=ssrc lines using the msid values from the a=msid line.
        if (!msid) {
            msid = mLine.msid;
            const primarySsrcs = mLine.ssrcs;
            primarySsrcs.forEach(ssrc => {
                mLine.ssrcs.push({
                    id: ssrc.id,
                    attribute: 'msid',
                    value: msid
                });
            });
        }
        // Generate SIM layers.
        const simSsrcs = [];
        for (let i = 0; i < this._options.numOfLayers - 1; ++i) {
            const simSsrc = this._generateSsrc();
            addAssociatedAttributes(mLine, simSsrc);
            simSsrcs.push(simSsrc);
        }
        mLine.ssrcGroups = mLine.ssrcGroups || [];
        mLine.ssrcGroups.push({
            semantics: 'SIM',
            ssrcs: primarySsrc + ' ' + simSsrcs.join(' ')
        });
        return mLine;
    }
    /**
     * Returns a random number to be used for the SSRC.
     *
     * @returns
     */
    _generateSsrc() {
        const max = 0xffffffff;
        return Math.floor(Math.random() * max);
    }
    /**
     * Returns the requested attribute value for a SSRC from a given media description.
     *
     * @param mLine
     * @param ssrc
     * @param attributeName
     * @returns
     */
    _getSsrcAttribute(mLine, ssrc, attributeName) {
        var _a, _b;
        return (_b = (_a = mLine.ssrcs) === null || _a === void 0 ? void 0 : _a.find(ssrcInfo => Number(ssrcInfo.id) === ssrc
            && ssrcInfo.attribute === attributeName)) === null || _b === void 0 ? void 0 : _b.value;
    }
    /**
     * Returns an array of all the primary SSRCs in the SIM group for a given media description.
     *
     * @param mLine
     * @returns
     */
    _parseSimLayers(mLine) {
        var _a, _b;
        const simGroup = (_a = mLine.ssrcGroups) === null || _a === void 0 ? void 0 : _a.find(group => group.semantics === 'SIM');
        if (simGroup) {
            return simGroup.ssrcs.split(' ').map(ssrc => Number(ssrc));
        }
        if ((_b = mLine.ssrcs) === null || _b === void 0 ? void 0 : _b.length) {
            return [Number(mLine.ssrcs[0].id)];
        }
        return null;
    }
    /**
     * Munges the given media description to enable simulcast for the video media sections that are in either have
     * SENDRECV or SENDONLY as the media direction thereby ignoring all the RECVONLY transceivers created for remote
     * endpoints.
     * NOTE: This needs to be called only when simulcast is enabled.
     *
     * @param description
     * @returns
     */
    mungeLocalDescription(description) {
        var _a, _b, _c, _d;
        if (!description || !description.sdp) {
            return description;
        }
        const session = sdp_transform__WEBPACK_IMPORTED_MODULE_2__.parse(description.sdp);
        for (let media of session.media) {
            // Ignore recvonly and inactive transceivers created for remote sources.
            if (media.direction === _service_RTC_MediaDirection__WEBPACK_IMPORTED_MODULE_0__.MediaDirection.RECVONLY || media.direction === _service_RTC_MediaDirection__WEBPACK_IMPORTED_MODULE_0__.MediaDirection.INACTIVE) {
                continue;
            }
            // Ignore audio m-lines.
            if (media.type !== _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_1__.MediaType.VIDEO) {
                continue;
            }
            const mid = media.mid;
            const numSsrcs = new Set((_a = media.ssrcs) === null || _a === void 0 ? void 0 : _a.map(ssrcInfo => ssrcInfo.id));
            const numGroups = (_c = (_b = media.ssrcGroups) === null || _b === void 0 ? void 0 : _b.length) !== null && _c !== void 0 ? _c : 0;
            let primarySsrc;
            // Do not munge if the description has no ssrcs or if simulcast is already enabled.
            if (numSsrcs.size === 0 || numSsrcs.size > 2 || (numSsrcs.size === 2 && numGroups === 0)) {
                continue;
            }
            if (numSsrcs.size === 1) {
                primarySsrc = Number((_d = media.ssrcs[0]) === null || _d === void 0 ? void 0 : _d.id);
            }
            else {
                const fidGroup = media.ssrcGroups.find(group => group.semantics === 'FID');
                if (fidGroup) {
                    primarySsrc = Number(fidGroup.ssrcs.split(' ')[0]);
                }
            }
            if (this._ssrcCache.has(mid)) {
                media = this._fillSsrcsFromCache(media);
            }
            else {
                media = this._generateNewSsrcsForSimulcast(media, primarySsrc);
                const simulcastSsrcs = this._parseSimLayers(media);
                // Update the SSRCs in the cache so that they can re-used for the same mid again.
                this._ssrcCache.set(mid, simulcastSsrcs);
            }
        }
        return new RTCSessionDescription({
            type: description.type,
            sdp: sdp_transform__WEBPACK_IMPORTED_MODULE_2__.write(session)
        });
    }
}
//# sourceMappingURL=SdpSimulcast.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/sdp/SdpTransformUtil.js":
/*!*************************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/sdp/SdpTransformUtil.js ***!
  \*************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   SdpTransformWrap: () => (/* binding */ SdpTransformWrap),
/* harmony export */   parsePrimarySSRC: () => (/* binding */ parsePrimarySSRC),
/* harmony export */   parseSecondarySSRC: () => (/* binding */ parseSecondarySSRC)
/* harmony export */ });
/* harmony import */ var sdp_transform__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! sdp-transform */ "./node_modules/sdp-transform/lib/index.js");

/**
 * Parses the primary SSRC of given SSRC group.
 * @param {object} group the SSRC group object as defined by the 'sdp-transform'
 * @return {Number} the primary SSRC number
 */
function parsePrimarySSRC(group) {
    return parseInt(group.ssrcs.split(' ')[0], 10);
}
/**
 * Parses the secondary SSRC of given SSRC group.
 * @param {object} group the SSRC group object as defined by the 'sdp-transform'
 * @return {Number} the secondary SSRC number
 */
function parseSecondarySSRC(group) {
    return parseInt(group.ssrcs.split(' ')[1], 10);
}
/**
 * Tells how many distinct SSRCs are contained in given media line.
 * @param {Object} mLine the media line object as defined by 'sdp-transform' lib
 * @return {number}
 */
function _getSSRCCount(mLine) {
    if (!mLine.ssrcs) {
        return 0;
    }
    return mLine.ssrcs
        .map(ssrcInfo => ssrcInfo.id)
        .filter((ssrc, index, array) => array.indexOf(ssrc) === index)
        .length;
}
/**
 * A wrapper around 'sdp-transform' media description object which provides
 * utility methods for common SDP/SSRC related operations.
 */
class MLineWrap {
    /**
     * Creates new <tt>MLineWrap</t>>
     * @param {Object} mLine the media line object as defined by 'sdp-transform'
     * lib.
     */
    constructor(mLine) {
        if (!mLine) {
            throw new Error('mLine is undefined');
        }
        this.mLine = mLine;
    }
    /**
     * Getter for the mLine's "ssrcs" array. If the array was undefined an empty
     * one will be preassigned.
     *
     * @return {Array<Object>} an array of 'sdp-transform' SSRC attributes
     * objects.
     */
    get ssrcs() {
        if (!this.mLine.ssrcs) {
            this.mLine.ssrcs = [];
        }
        return this.mLine.ssrcs;
    }
    /**
     * Setter for the mLine's "ssrcs" array.
     *
     * @param {Array<Object>} ssrcs an array of 'sdp-transform' SSRC attributes
     * objects.
     */
    set ssrcs(ssrcs) {
        this.mLine.ssrcs = ssrcs;
    }
    /**
     * Returns the direction of the underlying media description.
     * @return {string} the media direction name as defined in the SDP.
     */
    get direction() {
        return this.mLine.direction;
    }
    /**
     * Modifies the direction of the underlying media description.
     * @param {string} direction the new direction to be set
     */
    set direction(direction) {
        this.mLine.direction = direction;
    }
    /**
     * Exposes the SSRC group array of the underlying media description object.
     * @return {Array.<Object>}
     */
    get ssrcGroups() {
        if (!this.mLine.ssrcGroups) {
            this.mLine.ssrcGroups = [];
        }
        return this.mLine.ssrcGroups;
    }
    /**
     * Modifies the SSRC groups array of the underlying media description
     * object.
     * @param {Array.<Object>} ssrcGroups
     */
    set ssrcGroups(ssrcGroups) {
        this.mLine.ssrcGroups = ssrcGroups;
    }
    /**
     * Obtains value from SSRC attribute.
     * @param {number} ssrcNumber the SSRC number for which attribute is to be
     * found
     * @param {string} attrName the name of the SSRC attribute to be found.
     * @return {string|undefined} the value of SSRC attribute or
     * <tt>undefined</tt> if no such attribute exists.
     */
    getSSRCAttrValue(ssrcNumber, attrName) {
        const attribute = this.ssrcs.find(ssrcObj => ssrcObj.id === ssrcNumber
            && ssrcObj.attribute === attrName);
        return attribute && attribute.value;
    }
    /**
     * Removes all attributes for given SSRC number.
     * @param {number} ssrcNum the SSRC number for which all attributes will be
     * removed.
     */
    removeSSRC(ssrcNum) {
        if (!this.mLine.ssrcs || !this.mLine.ssrcs.length) {
            return;
        }
        this.mLine.ssrcs
            = this.mLine.ssrcs.filter(ssrcObj => ssrcObj.id !== ssrcNum);
    }
    /**
     * Adds SSRC attribute
     * @param {object} ssrcObj the SSRC attribute object as defined in
     * the 'sdp-transform' lib.
     */
    addSSRCAttribute(ssrcObj) {
        this.ssrcs.push(ssrcObj);
    }
    /**
     * Finds a SSRC group matching both semantics and SSRCs in order.
     * @param {string} semantics the name of the semantics
     * @param {string} [ssrcs] group SSRCs as a string (like it's defined in
     * SSRC group object of the 'sdp-transform' lib) e.g. "1232546 342344 25434"
     * @return {object|undefined} the SSRC group object or <tt>undefined</tt> if
     * not found.
     */
    findGroup(semantics, ssrcs) {
        return this.ssrcGroups.find(group => group.semantics === semantics
            && (!ssrcs || ssrcs === group.ssrcs));
    }
    /**
     * Finds all groups matching given semantic's name.
     * @param {string} semantics the name of the semantics
     * @return {Array.<object>} an array of SSRC group objects as defined by
     * the 'sdp-transform' lib.
     */
    findGroups(semantics) {
        return this.ssrcGroups.filter(group => group.semantics === semantics);
    }
    /**
     * Finds all groups matching given semantic's name and group's primary SSRC.
     * @param {string} semantics the name of the semantics
     * @param {number} primarySSRC the primary SSRC number to be matched
     * @return {Object} SSRC group object as defined by the 'sdp-transform' lib.
     */
    findGroupByPrimarySSRC(semantics, primarySSRC) {
        return this.ssrcGroups.find(group => group.semantics === semantics
            && parsePrimarySSRC(group) === primarySSRC);
    }
    /**
     * @param {string|null} msid the media stream id or <tt>null</tt> to match
     * the first SSRC object with any 'msid' value.
     * @return {Object|undefined} the SSRC object as defined by 'sdp-transform'
     * lib.
     */
    findSSRCByMSID(msid) {
        return this.ssrcs.find(ssrcObj => ssrcObj.attribute === 'msid'
            && (msid === null || ssrcObj.value === msid));
    }
    /**
     * Gets the SSRC count for the underlying media description.
     * @return {number}
     */
    getSSRCCount() {
        return _getSSRCCount(this.mLine);
    }
    /**
     * Checks whether the underlying media description contains any SSRC groups.
     * @return {boolean} <tt>true</tt> if there are any SSRC groups or
     * <tt>false</tt> otherwise.
     */
    containsAnySSRCGroups() {
        return this.mLine.ssrcGroups !== undefined;
    }
    /**
     * Finds the primary video SSRC.
     * @returns {number|undefined} the primary video ssrc
     * @throws Error if the underlying media description is not a video
     */
    getPrimaryVideoSsrc() {
        const mediaType = this.mLine.type;
        if (mediaType !== 'video') {
            throw new Error(`getPrimarySsrc doesn't work with '${mediaType}'`);
        }
        const numSsrcs = _getSSRCCount(this.mLine);
        if (numSsrcs === 1) {
            // Not using "ssrcs" getter on purpose here
            return this.mLine.ssrcs[0].id;
        }
        // Look for a SIM, FID, or FEC-FR group
        if (this.mLine.ssrcGroups) {
            const simGroup = this.findGroup('SIM');
            if (simGroup) {
                return parsePrimarySSRC(simGroup);
            }
            const fidGroup = this.findGroup('FID');
            if (fidGroup) {
                return parsePrimarySSRC(fidGroup);
            }
            const fecGroup = this.findGroup('FEC-FR');
            if (fecGroup) {
                return parsePrimarySSRC(fecGroup);
            }
        }
    }
    /**
     * Obtains RTX SSRC from the underlying video description (the
     * secondary SSRC of the first "FID" group found)
     * @param {number} primarySsrc the video ssrc for which to find the
     * corresponding rtx ssrc
     * @returns {number|undefined} the rtx ssrc (or undefined if there isn't
     * one)
     */
    getRtxSSRC(primarySsrc) {
        const fidGroup = this.findGroupByPrimarySSRC('FID', primarySsrc);
        return fidGroup && parseSecondarySSRC(fidGroup);
    }
    /**
     * Obtains all SSRCs contained in the underlying media description.
     * @return {Array.<number>} an array with all SSRC as numbers.
     */
    getSSRCs() {
        return this.ssrcs
            .map(ssrcInfo => ssrcInfo.id)
            .filter((ssrc, index, array) => array.indexOf(ssrc) === index);
    }
    /**
     * Obtains primary video SSRCs.
     * @return {Array.<number>} an array of all primary video SSRCs as numbers.
     * @throws Error if the wrapped media description is not a video.
     */
    getPrimaryVideoSSRCs() {
        const mediaType = this.mLine.type;
        if (mediaType !== 'video') {
            throw new Error(`getPrimaryVideoSSRCs doesn't work with ${mediaType}`);
        }
        const videoSSRCs = this.getSSRCs();
        for (const ssrcGroupInfo of this.ssrcGroups) {
            // Right now, FID and FEC-FR groups are the only ones we parse to
            // disqualify streams.  If/when others arise we'll
            // need to add support for them here
            if (ssrcGroupInfo.semantics === 'FID'
                || ssrcGroupInfo.semantics === 'FEC-FR') {
                // secondary streams should be filtered out
                const secondarySsrc = parseSecondarySSRC(ssrcGroupInfo);
                videoSSRCs.splice(videoSSRCs.indexOf(secondarySsrc), 1);
            }
        }
        return videoSSRCs;
    }
    /**
     * Dumps all SSRC groups of this media description to JSON.
     */
    dumpSSRCGroups() {
        return JSON.stringify(this.mLine.ssrcGroups);
    }
    /**
     * Removes all SSRC groups which contain given SSRC number at any position.
     * @param {number} ssrc the SSRC for which all matching groups are to be
     * removed.
     */
    removeGroupsWithSSRC(ssrc) {
        if (!this.mLine.ssrcGroups) {
            return;
        }
        this.mLine.ssrcGroups = this.mLine.ssrcGroups
            .filter(groupInfo => groupInfo.ssrcs.indexOf(`${ssrc}`) === -1);
    }
    /**
     * Removes groups that match given semantics.
     * @param {string} semantics e.g. "SIM" or "FID"
     */
    removeGroupsBySemantics(semantics) {
        if (!this.mLine.ssrcGroups) {
            return;
        }
        this.mLine.ssrcGroups
            = this.mLine.ssrcGroups
                .filter(groupInfo => groupInfo.semantics !== semantics);
    }
    /**
     * Replaces SSRC (does not affect SSRC groups, but only attributes).
     * @param {number} oldSSRC the old SSRC number
     * @param {number} newSSRC the new SSRC number
     */
    replaceSSRC(oldSSRC, newSSRC) {
        if (this.mLine.ssrcs) {
            this.mLine.ssrcs.forEach(ssrcInfo => {
                if (ssrcInfo.id === oldSSRC) {
                    ssrcInfo.id = newSSRC;
                }
            });
        }
    }
    /**
     * Adds given SSRC group to this media description.
     * @param {object} group the SSRC group object as defined by
     * the 'sdp-transform' lib.
     */
    addSSRCGroup(group) {
        this.ssrcGroups.push(group);
    }
}
/**
 * Utility class for SDP manipulation using the 'sdp-transform' library.
 *
 * Typical use usage scenario:
 *
 * const transformer = new SdpTransformWrap(rawSdp);
 * const videoMLine = transformer.selectMedia('video);
 * if (videoMLine) {
 *     videoMLiner.addSSRCAttribute({
 *         id: 2342343,
 *         attribute: "cname",
 *         value: "someCname"
 *     });
 *     rawSdp = transformer.toRawSdp();
 * }
 */
class SdpTransformWrap {
    /**
     * Creates new instance and parses the raw SDP into objects using
     * 'sdp-transform' lib.
     * @param {string} rawSDP the SDP in raw text format.
     */
    constructor(rawSDP) {
        this.parsedSDP = sdp_transform__WEBPACK_IMPORTED_MODULE_0__.parse(rawSDP);
    }
    /**
     * Selects all the m-lines from the SDP for a given media type.
     *
     * @param {string} mediaType the name of the media e.g. 'audio', 'video', 'data'.
     * @return {MLineWrap|null} return {@link MLineWrap} instance for the media line or <tt>null</tt> if not found. The
     * object returned references the underlying SDP state held by this <tt>SdpTransformWrap</tt> instance (it's not a
     * copy).
     */
    selectMedia(mediaType) {
        const selectedMLines = this.parsedSDP.media
            .filter(mLine => mLine.type === mediaType)
            .map(mLine => new MLineWrap(mLine));
        return selectedMLines !== null && selectedMLines !== void 0 ? selectedMLines : null;
    }
    /**
     * Converts the currently stored SDP state in this instance to raw text SDP
     * format.
     * @return {string}
     */
    toRawSDP() {
        return sdp_transform__WEBPACK_IMPORTED_MODULE_0__.write(this.parsedSDP);
    }
}
//# sourceMappingURL=SdpTransformUtil.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/settings/Settings.js":
/*!**********************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/settings/Settings.js ***!
  \**********************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
var __filename = "/index.js";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (__WEBPACK_DEFAULT_EXPORT__)
/* harmony export */ });
/* harmony import */ var _jitsi_js_utils__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @jitsi/js-utils */ "./node_modules/@jitsi/js-utils/index.js");
/* harmony import */ var _jitsi_logger__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! @jitsi/logger */ "./node_modules/@jitsi/logger/lib/index.js");
/* harmony import */ var _jitsi_logger__WEBPACK_IMPORTED_MODULE_1___default = /*#__PURE__*/__webpack_require__.n(_jitsi_logger__WEBPACK_IMPORTED_MODULE_1__);
/* harmony import */ var _util_UsernameGenerator__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../util/UsernameGenerator */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/util/UsernameGenerator.js");
/* harmony import */ var _util_UsernameGenerator__WEBPACK_IMPORTED_MODULE_2___default = /*#__PURE__*/__webpack_require__.n(_util_UsernameGenerator__WEBPACK_IMPORTED_MODULE_2__);


const logger = (0,_jitsi_logger__WEBPACK_IMPORTED_MODULE_1__.getLogger)(__filename);

let _callStatsUserName;
let _machineId;
/**
 *
 */
/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = ({
    /**
     * The storage used to store the settings.
     */
    _storage: _jitsi_js_utils__WEBPACK_IMPORTED_MODULE_0__.jitsiLocalStorage,
    /**
     * Initializes the Settings class.
     *
     * @param {Storage|undefined} externalStorage - Object that implements the Storage interface. This object will be
     * used for storing data instead of jitsiLocalStorage if specified.
     */
    init(externalStorage) {
        this._storage = externalStorage || _jitsi_js_utils__WEBPACK_IMPORTED_MODULE_0__.jitsiLocalStorage;
    },
    /**
     * Returns fake username for callstats
     * @returns {string} fake username for callstats
     */
    get callStatsUserName() {
        if (!_callStatsUserName) {
            _callStatsUserName = this._storage.getItem('callStatsUserName');
            if (!_callStatsUserName) {
                _callStatsUserName = generateCallStatsUserName();
                this._storage.setItem('callStatsUserName', _callStatsUserName);
            }
        }
        return _callStatsUserName;
    },
    /**
     * Returns current machine id.
     * @returns {string} machine id
     */
    get machineId() {
        if (!_machineId) {
            const amDid = this._storage.getItem('billingId');
            _machineId = amDid || this._storage.getItem('jitsiMeetId');
            if (amDid) {
                this._storage.setItem('jitsiMeetId', amDid);
            }
            else if (!_machineId) {
                _machineId = generateJitsiMeetId();
                this._storage.setItem('jitsiMeetId', _machineId);
            }
        }
        return _machineId;
    },
    /**
     * Returns current session id.
     * @returns {string} current session id
     */
    get sessionId() {
        // We may update sessionId in localStorage from another JitsiConference
        // instance and that's why we should always re-read it.
        return this._storage.getItem('sessionId');
    },
    /**
     * Save current session id.
     * @param {string} sessionId session id
     */
    set sessionId(sessionId) {
        if (sessionId) {
            this._storage.setItem('sessionId', sessionId);
        }
        else {
            this._storage.removeItem('sessionId');
        }
    }
});
/**
 * Generate fake username for callstats.
 * @returns {string} fake random username
 */
function generateCallStatsUserName() {
    const username = _util_UsernameGenerator__WEBPACK_IMPORTED_MODULE_2___default().generateUsername();
    logger.log('generated callstats uid', username);
    return username;
}
/**
 * Generate unique id.
 * @returns {string} random unique id
 */
function generateJitsiMeetId() {
    const jitsiMeetId = generateUniqueId();
    logger.log('generated id', jitsiMeetId);
    return jitsiMeetId;
}
/**
 *
 */
function generateUniqueId() {
    return _p8() + _p8() + _p8() + _p8();
}
/**
 *
 */
function _p8() {
    return `${Math.random().toString(16)}000000000`.substr(2, 8);
}
//# sourceMappingURL=Settings.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/statistics/AnalyticsAdapter.js":
/*!********************************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/statistics/AnalyticsAdapter.js ***!
  \********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
var __filename = "/index.js";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (__WEBPACK_DEFAULT_EXPORT__)
/* harmony export */ });
/* harmony import */ var _jitsi_logger__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @jitsi/logger */ "./node_modules/@jitsi/logger/lib/index.js");
/* harmony import */ var _jitsi_logger__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(_jitsi_logger__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var _service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../service/statistics/AnalyticsEvents */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/statistics/AnalyticsEvents.js");
/* harmony import */ var _browser__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../browser */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/browser/index.js");



const MAX_CACHE_SIZE = 100;
// eslist-disable-line no-undef
const logger = (0,_jitsi_logger__WEBPACK_IMPORTED_MODULE_0__.getLogger)(__filename);
/**
 * This class provides an API to lib-jitsi-meet and its users for sending
 * analytics events. It serves as a bridge to different backend implementations
 * ("analytics handlers") and a cache for events attempted to be sent before
 * the analytics handlers were enabled.
 *
 * The API is designed to be an easy replacement for the previous version of
 * this adapter, and is meant to be extended with more convenience methods.
 *
 *
 * The API calls are translated to objects with the following structure, which
 * are then passed to the sendEvent(event) function of the underlying handlers:
 *
 * {
 *    type,
 *
 *    action,
 *    actionSubject,
 *    actionSubjectId,
 *    attributes,
 *    categories,
 *    containerId,
 *    containerType,
 *    name,
 *    objectId,
 *    objectType,
 *    source,
 *    tags
 * }
 *
 * The 'type' is one of 'operational', 'page', 'track' or 'ui', and some of the
 * other properties are considered required according to the type.
 *
 * For events with type 'page', the required properties are: name.
 *
 * For events with type 'operational' and 'ui', the required properties are:
 * action, actionSubject, source
 *
 * For events with type 'page', the required properties are:
 * action, actionSubject, source, containerType, containerId, objectType,
 * objectId
 */
class AnalyticsAdapter {
    /**
     * Creates new AnalyticsAdapter instance.
     */
    constructor() {
        this.reset();
    }
    /**
     * Reset the state to the initial one.
     *
     * @returns {void}
     */
    reset() {
        /**
         * Whether this AnalyticsAdapter has been disposed of or not. Once this
         * is set to true, the AnalyticsAdapter is disabled and does not accept
         * any more events, and it can not be re-enabled.
         * @type {boolean}
         */
        this.disposed = false;
        /**
         * The set of handlers to which events will be sent.
         * @type {Set<any>}
         */
        this.analyticsHandlers = new Set();
        /**
         * The cache of events which are not sent yet. The cache is enabled
         * while this field is truthy, and disabled otherwise.
         * @type {Array}
         */
        this.cache = [];
        /**
         * Map of properties that will be added to every event. Note that the
         * keys will be prefixed with "permanent.".
         */
        this.permanentProperties = {};
        /**
         * The name of the conference that this AnalyticsAdapter is associated
         * with.
         * @type {null}
         */
        this.conferenceName = '';
        this.addPermanentProperties({
            'user_agent': navigator.userAgent,
            'browser_name': _browser__WEBPACK_IMPORTED_MODULE_2__["default"].getName()
        });
    }
    /**
     * Dispose analytics. Clears all handlers.
     */
    dispose() {
        logger.warn('Disposing of analytics adapter.');
        if (this.analyticsHandlers && this.analyticsHandlers.size > 0) {
            this.analyticsHandlers.forEach(handler => {
                if (typeof handler.dispose === 'function') {
                    handler.dispose();
                }
            });
        }
        this.setAnalyticsHandlers([]);
        this.disposed = true;
    }
    /**
     * Sets the handlers that are going to be used to send analytics. Sends any
     * cached events.
     * @param {Array} handlers the handlers
     */
    setAnalyticsHandlers(handlers) {
        if (this.disposed) {
            return;
        }
        this.analyticsHandlers = new Set(handlers);
        this._setUserProperties();
        // Note that we disable the cache even if the set of handlers is empty.
        const cache = this.cache;
        this.cache = null;
        if (cache) {
            cache.forEach(event => this._sendEvent(event));
        }
    }
    /**
     * Set the user properties to the analytics handlers.
     *
     * @returns {void}
     */
    _setUserProperties() {
        this.analyticsHandlers.forEach(handler => {
            try {
                handler.setUserProperties(this.permanentProperties);
            }
            catch (error) {
                logger.warn('Error in setUserProperties method of one of the '
                    + `analytics handlers: ${error}`);
            }
        });
    }
    /**
     * Adds a set of permanent properties to this this AnalyticsAdapter.
     * Permanent properties will be added as "attributes" to events sent to
     * the underlying "analytics handlers", and their keys will be prefixed
     * by "permanent_", i.e. adding a permanent property {key: "value"} will
     * result in {"permanent_key": "value"} object to be added to the
     * "attributes" field of events.
     *
     * @param {Object} properties the properties to add
     */
    addPermanentProperties(properties) {
        this.permanentProperties = Object.assign(Object.assign({}, this.permanentProperties), properties);
        this._setUserProperties();
    }
    /**
     * Sets the name of the conference that this AnalyticsAdapter is associated
     * with.
     * @param name the name to set.
     */
    setConferenceName(name) {
        this.conferenceName = name;
        this.addPermanentProperties({ 'conference_name': name });
    }
    /**
     * Sends an event with a given name and given properties. The first
     * parameter is either a string or an object. If it is a string, it is used
     * as the event name and the second parameter is used at the attributes to
     * attach to the event. If it is an object, it represents the whole event,
     * including any desired attributes, and the second parameter is ignored.
     *
     * @param {String|Object} eventName either a string to be used as the name
     * of the event, or an event object. If an event object is passed, the
     * properties parameters is ignored.
     * @param {Object} properties the properties/attributes to attach to the
     * event, if eventName is a string.
     */
    sendEvent(eventName, properties = {}) {
        if (this.disposed) {
            return;
        }
        let event = null;
        if (typeof eventName === 'string') {
            event = {
                type: _service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_1__.TYPE_OPERATIONAL,
                action: eventName,
                actionSubject: eventName,
                source: eventName,
                attributes: properties
            };
        }
        else if (typeof eventName === 'object') {
            event = eventName;
        }
        if (!this._verifyRequiredFields(event)) {
            logger.error(`Dropping a mis-formatted event: ${JSON.stringify(event)}`);
            return;
        }
        this._sendEvent(event);
    }
    /**
     * Checks whether an event has all of the required fields set, and tries
     * to fill in some of the missing fields with reasonable default values.
     * Returns true if after this operation the event has all of the required
     * fields set, and false otherwise (if some of the required fields were not
     * set and the attempt to fill them in with a default failed).
     *
     * @param event the event object.
     * @return {boolean} true if the event (after the call to this function)
     * contains all of the required fields, and false otherwise.
     * @private
     */
    _verifyRequiredFields(event) {
        if (!event) {
            return false;
        }
        if (!event.type) {
            event.type = _service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_1__.TYPE_OPERATIONAL;
        }
        const type = event.type;
        if (type !== _service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_1__.TYPE_OPERATIONAL && type !== _service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_1__.TYPE_PAGE
            && type !== _service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_1__.TYPE_UI && type !== _service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_1__.TYPE_TRACK) {
            logger.error(`Unknown event type: ${type}`);
            return false;
        }
        if (type === _service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_1__.TYPE_PAGE) {
            return Boolean(event.name);
        }
        // Try to set some reasonable default values in case some of the
        // parameters required by the handler API are missing.
        event.action = event.action || event.name || event.actionSubject;
        event.actionSubject = event.actionSubject || event.name || event.action;
        event.source = event.source || event.name || event.action
            || event.actionSubject;
        if (!event.action || !event.actionSubject || !event.source) {
            logger.error('Required field missing (action, actionSubject or source)');
            return false;
        }
        // Track events have additional required fields.
        if (type === _service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_1__.TYPE_TRACK) {
            event.objectType = event.objectType || 'generic-object-type';
            event.containerType = event.containerType || 'conference';
            if (event.containerType === 'conference' && !event.containerId) {
                event.containerId = this.conferenceName;
            }
            if (!event.objectType || !event.objectId
                || !event.containerType || !event.containerId) {
                logger.error('Required field missing (containerId, containerType, '
                    + 'objectId or objectType)');
                return false;
            }
        }
        return true;
    }
    /**
     * Saves an event to the cache, if the cache is enabled.
     * @param event the event to save.
     * @returns {boolean} true if the event was saved, and false otherwise (i.e.
     * if the cache was disabled).
     * @private
     */
    _maybeCacheEvent(event) {
        if (this.cache) {
            this.cache.push(event);
            // We limit the size of the cache, in case the user fails to ever
            // set the analytics handlers.
            if (this.cache.length > MAX_CACHE_SIZE) {
                this.cache.splice(0, 1);
            }
            return true;
        }
        return false;
    }
    /**
     *
     * @param event
     * @private
     */
    _sendEvent(event) {
        if (this._maybeCacheEvent(event)) {
            // The event was consumed by the cache.
        }
        else {
            this.analyticsHandlers.forEach(handler => {
                try {
                    handler.sendEvent(event);
                }
                catch (e) {
                    logger.warn(`Error sending analytics event: ${e}`);
                }
            });
        }
    }
}
/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (new AnalyticsAdapter());
//# sourceMappingURL=AnalyticsAdapter.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/statistics/AudioOutputProblemDetector.js":
/*!******************************************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/statistics/AudioOutputProblemDetector.js ***!
  \******************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
var __filename = "/index.js";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (/* binding */ AudioOutputProblemDetector)
/* harmony export */ });
/* harmony import */ var _jitsi_logger__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @jitsi/logger */ "./node_modules/@jitsi/logger/lib/index.js");
/* harmony import */ var _jitsi_logger__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(_jitsi_logger__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var _JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../JitsiConferenceEvents */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/JitsiConferenceEvents.js");
/* harmony import */ var _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../service/RTC/MediaType */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/RTC/MediaType.js");
/* harmony import */ var _service_connectivity_ConnectionQualityEvents__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../service/connectivity/ConnectionQualityEvents */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/connectivity/ConnectionQualityEvents.js");
/* harmony import */ var _service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../../service/statistics/AnalyticsEvents */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/statistics/AnalyticsEvents.js");
/* harmony import */ var _statistics__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./statistics */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/statistics/statistics.js");






const logger = (0,_jitsi_logger__WEBPACK_IMPORTED_MODULE_0__.getLogger)(__filename);
/**
 * Number of local samples that will be used for comparison before and after the remote sample is received.
 */
const NUMBER_OF_LOCAL_SAMPLES = 2;
/**
 * Collects the average audio levels per participant from the local stats and the stats received by every remote
 * participant and compares them to detect potential audio problem for a participant.
 */
class AudioOutputProblemDetector {
    /**
     * Creates new <tt>AudioOutputProblemDetector</tt> instance.
     *
     * @param {JitsiConference} conference - The conference instance to be monitored.
     */
    constructor(conference) {
        this._conference = conference;
        this._localAudioLevelCache = {};
        this._reportedParticipants = [];
        this._audioProblemCandidates = {};
        this._numberOfRemoteAudioLevelsReceived = {};
        this._onLocalAudioLevelsReport = this._onLocalAudioLevelsReport.bind(this);
        this._onRemoteAudioLevelReceived = this._onRemoteAudioLevelReceived.bind(this);
        this._clearUserData = this._clearUserData.bind(this);
        this._conference.on(_service_connectivity_ConnectionQualityEvents__WEBPACK_IMPORTED_MODULE_3__.REMOTE_STATS_UPDATED, this._onRemoteAudioLevelReceived);
        this._conference.statistics.addConnectionStatsListener(this._onLocalAudioLevelsReport);
        this._conference.on(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_1__.USER_LEFT, this._clearUserData);
    }
    /**
     * A listener for audio level data received by a remote participant.
     *
     * @param {string} userID - The user id of the participant that sent the data.
     * @param {number} audioLevel - The average audio level value.
     * @returns {void}
     */
    _onRemoteAudioLevelReceived(userID, { avgAudioLevels }) {
        const numberOfReports = (this._numberOfRemoteAudioLevelsReceived[userID] + 1) || 0;
        this._numberOfRemoteAudioLevelsReceived[userID] = numberOfReports;
        if (this._reportedParticipants.indexOf(userID) !== -1 || (userID in this._audioProblemCandidates)
            || avgAudioLevels <= 0 || numberOfReports < 3) {
            return;
        }
        const participant = this._conference.getParticipantById(userID);
        if (participant) {
            const tracks = participant.getTracksByMediaType(_service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_2__.MediaType.AUDIO);
            if (tracks.length > 0 && participant.isAudioMuted()) {
                // We don't need to report an error if everything seems fine with the participant and its tracks but
                // the participant is audio muted. Since those are average audio levels we potentially can receive non
                // zero values for muted track.
                return;
            }
        }
        const localAudioLevels = this._localAudioLevelCache[userID];
        if (!Array.isArray(localAudioLevels) || localAudioLevels.every(audioLevel => audioLevel === 0)) {
            this._audioProblemCandidates[userID] = {
                remoteAudioLevels: avgAudioLevels,
                localAudioLevels: []
            };
        }
    }
    /**
     * A listener for audio level data retrieved by the local stats.
     *
     * @param {TraceablePeerConnection} tpc - The <tt>TraceablePeerConnection</tt> instance used to gather the data.
     * @param {Object} avgAudioLevels - The average audio levels per participant.
     * @returns {void}
     */
    _onLocalAudioLevelsReport(tpc, { avgAudioLevels }) {
        if (tpc !== this._conference.getActivePeerConnection()) {
            return;
        }
        Object.keys(avgAudioLevels).forEach(userID => {
            if (this._reportedParticipants.indexOf(userID) !== -1) {
                return;
            }
            const localAudioLevels = this._localAudioLevelCache[userID];
            if (!Array.isArray(localAudioLevels)) {
                this._localAudioLevelCache[userID] = [];
            }
            else if (localAudioLevels.length >= NUMBER_OF_LOCAL_SAMPLES) {
                localAudioLevels.shift();
            }
            this._localAudioLevelCache[userID].push(avgAudioLevels[userID]);
        });
        Object.keys(this._audioProblemCandidates).forEach(userID => {
            const { localAudioLevels, remoteAudioLevels } = this._audioProblemCandidates[userID];
            localAudioLevels.push(avgAudioLevels[userID]);
            if (localAudioLevels.length === NUMBER_OF_LOCAL_SAMPLES) {
                if (localAudioLevels.every(audioLevel => typeof audioLevel === 'undefined' || audioLevel === 0)) {
                    const localAudioLevelsString = JSON.stringify(localAudioLevels);
                    _statistics__WEBPACK_IMPORTED_MODULE_5__["default"].sendAnalytics((0,_service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_4__.createAudioOutputProblemEvent)(userID, localAudioLevelsString, remoteAudioLevels));
                    logger.warn(`A potential problem is detected with the audio output for participant ${userID}, local audio levels: ${localAudioLevelsString}, remote audio levels: ${remoteAudioLevels}`);
                    this._reportedParticipants.push(userID);
                    this._clearUserData(userID);
                }
                delete this._audioProblemCandidates[userID];
            }
        });
    }
    /**
     * Clears the data stored for a participant.
     *
     * @param {string} userID - The id of the participant.
     * @returns {void}
     */
    _clearUserData(userID) {
        delete this._localAudioLevelCache[userID];
    }
    /**
     * Disposes the allocated resources.
     *
     * @returns {void}
     */
    dispose() {
        this._conference.off(_service_connectivity_ConnectionQualityEvents__WEBPACK_IMPORTED_MODULE_3__.REMOTE_STATS_UPDATED, this._onRemoteAudioLevelReceived);
        this._conference.off(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_1__.USER_LEFT, this._clearUserData);
        this._conference.statistics.removeConnectionStatsListener(this._onLocalAudioLevelsReport);
        this._localAudioLevelCache = undefined;
        this._audioProblemCandidates = undefined;
        this._reportedParticipants = undefined;
        this._numberOfRemoteAudioLevelsReceived = undefined;
        this._conference = undefined;
    }
}
//# sourceMappingURL=AudioOutputProblemDetector.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/statistics/AvgRTPStatsReporter.js":
/*!***********************************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/statistics/AvgRTPStatsReporter.js ***!
  \***********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
var __filename = "/index.js";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (/* binding */ AvgRTPStatsReporter)
/* harmony export */ });
/* harmony import */ var _jitsi_logger__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @jitsi/logger */ "./node_modules/@jitsi/logger/lib/index.js");
/* harmony import */ var _jitsi_logger__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(_jitsi_logger__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var lodash_isequal__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! lodash.isequal */ "./node_modules/lodash.isequal/index.js");
/* harmony import */ var lodash_isequal__WEBPACK_IMPORTED_MODULE_1___default = /*#__PURE__*/__webpack_require__.n(lodash_isequal__WEBPACK_IMPORTED_MODULE_1__);
/* harmony import */ var _JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../JitsiConferenceEvents */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/JitsiConferenceEvents.js");
/* harmony import */ var _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../service/RTC/MediaType */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/RTC/MediaType.js");
/* harmony import */ var _service_RTC_VideoType__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../../service/RTC/VideoType */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/RTC/VideoType.js");
/* harmony import */ var _service_connectivity_ConnectionQualityEvents__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../../service/connectivity/ConnectionQualityEvents */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/connectivity/ConnectionQualityEvents.js");
/* harmony import */ var _service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../../service/statistics/AnalyticsEvents */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/statistics/AnalyticsEvents.js");
/* harmony import */ var _browser__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../browser */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/browser/index.js");
/* harmony import */ var _statistics__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ./statistics */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/statistics/statistics.js");









const logger = (0,_jitsi_logger__WEBPACK_IMPORTED_MODULE_0__.getLogger)(__filename);
/**
 * This will calculate an average for one, named stat and submit it to
 * the analytics module when requested. It automatically counts the samples.
 */
class AverageStatReport {
    /**
     * Creates new <tt>AverageStatReport</tt> for given name.
     * @param {string} name that's the name of the event that will be reported
     * to the analytics module.
     */
    constructor(name) {
        this.name = name;
        this.count = 0;
        this.sum = 0;
        this.samples = [];
    }
    /**
     * Adds the next value that will be included in the average when
     * {@link calculate} is called.
     * @param {number} nextValue
     */
    addNext(nextValue) {
        if (typeof nextValue === 'undefined') {
            return;
        }
        if (typeof nextValue !== 'number') {
            logger.error(`${this.name} - invalid value for idx: ${this.count}`, nextValue);
        }
        else if (!isNaN(nextValue)) {
            this.sum += nextValue;
            this.samples.push(nextValue);
            this.count += 1;
        }
    }
    /**
     * Calculates an average for the samples collected using {@link addNext}.
     * @return {number|NaN} an average of all collected samples or <tt>NaN</tt>
     * if no samples were collected.
     */
    calculate() {
        return this.sum / this.count;
    }
    /**
     * Appends the report to the analytics "data" object. The object will be
     * set under <tt>prefix</tt> + {@link this.name} key.
     * @param {Object} report the analytics "data" object
     */
    appendReport(report) {
        report[`${this.name}_avg`] = this.calculate();
        report[`${this.name}_samples`] = JSON.stringify(this.samples);
    }
    /**
     * Clears all memory of any samples collected, so that new average can be
     * calculated using this instance.
     */
    reset() {
        this.samples = [];
        this.sum = 0;
        this.count = 0;
    }
}
/**
 * Class gathers the stats that are calculated and reported for a
 * {@link TraceablePeerConnection} even if it's not currently active. For
 * example we want to monitor RTT for the JVB connection while in P2P mode.
 */
class ConnectionAvgStats {
    /**
     * Creates new <tt>ConnectionAvgStats</tt>
     * @param {AvgRTPStatsReporter} avgRtpStatsReporter
     * @param {boolean} isP2P
     * @param {number} n the number of samples, before arithmetic mean is to be
     * calculated and values submitted to the analytics module.
     */
    constructor(avgRtpStatsReporter, isP2P, n) {
        /**
         * Is this instance for JVB or P2P connection ?
         * @type {boolean}
         */
        this.isP2P = isP2P;
        /**
         * How many samples are to be included in arithmetic mean calculation.
         * @type {number}
         * @private
         */
        this._n = n;
        /**
         * The current sample index. Starts from 0 and goes up to {@link _n})
         * when analytics report will be submitted.
         * @type {number}
         * @private
         */
        this._sampleIdx = 0;
        /**
         * Average round trip time reported by the ICE candidate pair.
         * @type {AverageStatReport}
         */
        this._avgRTT = new AverageStatReport('rtt');
        /**
         * Map stores average RTT to the JVB reported by remote participants.
         * Mapped per participant id {@link JitsiParticipant.getId}.
         *
         * This is used only when {@link ConnectionAvgStats.isP2P} equals to
         * <tt>false</tt>.
         *
         * @type {Map<string,AverageStatReport>}
         * @private
         */
        this._avgRemoteRTTMap = new Map();
        /**
         * The conference for which stats will be collected and reported.
         * @type {JitsiConference}
         * @private
         */
        this._avgRtpStatsReporter = avgRtpStatsReporter;
        /**
         * The latest average E2E RTT for the JVB connection only.
         *
         * This is used only when {@link ConnectionAvgStats.isP2P} equals to
         * <tt>false</tt>.
         *
         * @type {number}
         */
        this._avgEnd2EndRTT = undefined;
        this._onConnectionStats = (tpc, stats) => {
            if (this.isP2P === tpc.isP2P) {
                this._calculateAvgStats(stats);
            }
        };
        const conference = avgRtpStatsReporter._conference;
        conference.statistics.addConnectionStatsListener(this._onConnectionStats);
        if (!this.isP2P) {
            this._onUserLeft = id => this._avgRemoteRTTMap.delete(id);
            conference.on(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_2__.USER_LEFT, this._onUserLeft);
            this._onRemoteStatsUpdated
                = (id, data) => this._processRemoteStats(id, data);
            conference.on(_service_connectivity_ConnectionQualityEvents__WEBPACK_IMPORTED_MODULE_5__.REMOTE_STATS_UPDATED, this._onRemoteStatsUpdated);
        }
    }
    /**
     * Processes next batch of stats.
     * @param {go figure} data
     * @private
     */
    _calculateAvgStats(data) {
        if (!data) {
            logger.error('No stats');
            return;
        }
        if (_browser__WEBPACK_IMPORTED_MODULE_7__["default"].supportsRTTStatistics()) {
            if (data.transport && data.transport.length) {
                this._avgRTT.addNext(data.transport[0].rtt);
            }
        }
        this._sampleIdx += 1;
        if (this._sampleIdx >= this._n) {
            if (_browser__WEBPACK_IMPORTED_MODULE_7__["default"].supportsRTTStatistics()) {
                const conference = this._avgRtpStatsReporter._conference;
                const batchReport = {
                    p2p: this.isP2P,
                    'conference_size': conference.getParticipantCount()
                };
                if (data.transport && data.transport.length) {
                    Object.assign(batchReport, {
                        'local_candidate_type': data.transport[0].localCandidateType,
                        'remote_candidate_type': data.transport[0].remoteCandidateType,
                        'transport_type': data.transport[0].type
                    });
                }
                this._avgRTT.appendReport(batchReport);
                if (this.isP2P) {
                    // Report RTT diff only for P2P.
                    const jvbEnd2EndRTT = this
                        ._avgRtpStatsReporter.jvbStatsMonitor._avgEnd2EndRTT;
                    if (!isNaN(jvbEnd2EndRTT)) {
                        // eslint-disable-next-line dot-notation
                        batchReport['rtt_diff']
                            = this._avgRTT.calculate() - jvbEnd2EndRTT;
                    }
                }
                else {
                    // Report end to end RTT only for JVB.
                    const avgRemoteRTT = this._calculateAvgRemoteRTT();
                    const avgLocalRTT = this._avgRTT.calculate();
                    this._avgEnd2EndRTT = avgLocalRTT + avgRemoteRTT;
                    if (!isNaN(avgLocalRTT) && !isNaN(avgRemoteRTT)) {
                        // eslint-disable-next-line dot-notation
                        batchReport['end2end_rtt_avg'] = this._avgEnd2EndRTT;
                    }
                }
                _statistics__WEBPACK_IMPORTED_MODULE_8__["default"].sendAnalytics((0,_service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_6__.createRtpStatsEvent)(batchReport));
            }
            this._resetAvgStats();
        }
    }
    /**
     * Calculates arithmetic mean of all RTTs towards the JVB reported by
     * participants.
     * @return {number|NaN} NaN if not available (not enough data)
     * @private
     */
    _calculateAvgRemoteRTT() {
        let count = 0, sum = 0;
        // FIXME should we ignore RTT for participant
        // who "is having connectivity issues" ?
        for (const remoteAvg of this._avgRemoteRTTMap.values()) {
            const avg = remoteAvg.calculate();
            if (!isNaN(avg)) {
                sum += avg;
                count += 1;
                remoteAvg.reset();
            }
        }
        return sum / count;
    }
    /**
     * Processes {@link ConnectionQualityEvents.REMOTE_STATS_UPDATED} to analyse
     * RTT towards the JVB reported by each participant.
     * @param {string} id {@link JitsiParticipant.getId}
     * @param {go figure in ConnectionQuality.js} data
     * @private
     */
    _processRemoteStats(id, data) {
        const validData = typeof data.jvbRTT === 'number';
        let rttAvg = this._avgRemoteRTTMap.get(id);
        if (!rttAvg && validData) {
            rttAvg = new AverageStatReport(`${id}_stat_rtt`);
            this._avgRemoteRTTMap.set(id, rttAvg);
        }
        if (validData) {
            rttAvg.addNext(data.jvbRTT);
        }
        else if (rttAvg) {
            this._avgRemoteRTTMap.delete(id);
        }
    }
    /**
     * Reset cache of all averages and {@link _sampleIdx}.
     * @private
     */
    _resetAvgStats() {
        this._avgRTT.reset();
        if (this._avgRemoteRTTMap) {
            this._avgRemoteRTTMap.clear();
        }
        this._sampleIdx = 0;
    }
    /**
     *
     */
    dispose() {
        const conference = this._avgRtpStatsReporter._conference;
        conference.statistics.removeConnectionStatsListener(this._onConnectionStats);
        if (!this.isP2P) {
            conference.off(_service_connectivity_ConnectionQualityEvents__WEBPACK_IMPORTED_MODULE_5__.REMOTE_STATS_UPDATED, this._onRemoteStatsUpdated);
            conference.off(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_2__.USER_LEFT, this._onUserLeft);
        }
    }
}
/**
 * Reports average RTP statistics values (arithmetic mean) to the analytics
 * module for things like bit rate, bandwidth, packet loss etc. It keeps track
 * of the P2P vs JVB conference modes and submits the values under different
 * namespaces (the events for P2P mode have 'p2p.' prefix). Every switch between
 * P2P mode resets the data collected so far and averages are calculated from
 * scratch.
 */
class AvgRTPStatsReporter {
    /**
     * Creates new instance of <tt>AvgRTPStatsReporter</tt>
     * @param {JitsiConference} conference
     * @param {number} n the number of samples, before arithmetic mean is to be
     * calculated and values submitted to the analytics module.
     */
    constructor(conference, n) {
        /**
         * How many {@link ConnectionQualityEvents.LOCAL_STATS_UPDATED} samples
         * are to be included in arithmetic mean calculation.
         * @type {number}
         * @private
         */
        this._n = n;
        if (n > 0) {
            logger.info(`Avg RTP stats will be calculated every ${n} samples`);
        }
        else {
            logger.info('Avg RTP stats reports are disabled.');
            // Do not initialize
            return;
        }
        /**
         * The current sample index. Starts from 0 and goes up to {@link _n})
         * when analytics report will be submitted.
         * @type {number}
         * @private
         */
        this._sampleIdx = 0;
        /**
         * The conference for which stats will be collected and reported.
         * @type {JitsiConference}
         * @private
         */
        this._conference = conference;
        /**
         * Average audio upload bitrate
         * XXX What are the units?
         * @type {AverageStatReport}
         * @private
         */
        this._avgAudioBitrateUp
            = new AverageStatReport('bitrate_audio_upload');
        /**
         * Average audio download bitrate
         * XXX What are the units?
         * @type {AverageStatReport}
         * @private
         */
        this._avgAudioBitrateDown
            = new AverageStatReport('bitrate_audio_download');
        /**
         * Average video upload bitrate
         * XXX What are the units?
         * @type {AverageStatReport}
         * @private
         */
        this._avgVideoBitrateUp
            = new AverageStatReport('bitrate_video_upload');
        /**
         * Average video download bitrate
         * XXX What are the units?
         * @type {AverageStatReport}
         * @private
         */
        this._avgVideoBitrateDown
            = new AverageStatReport('bitrate_video_download');
        /**
         * Average upload bandwidth
         * XXX What are the units?
         * @type {AverageStatReport}
         * @private
         */
        this._avgBandwidthUp
            = new AverageStatReport('bandwidth_upload');
        /**
         * Average download bandwidth
         * XXX What are the units?
         * @type {AverageStatReport}
         * @private
         */
        this._avgBandwidthDown
            = new AverageStatReport('bandwidth_download');
        /**
         * Average total packet loss
         * XXX What are the units?
         * @type {AverageStatReport}
         * @private
         */
        this._avgPacketLossTotal
            = new AverageStatReport('packet_loss_total');
        /**
         * Average upload packet loss
         * XXX What are the units?
         * @type {AverageStatReport}
         * @private
         */
        this._avgPacketLossUp
            = new AverageStatReport('packet_loss_upload');
        /**
         * Average download packet loss
         * XXX What are the units?
         * @type {AverageStatReport}
         * @private
         */
        this._avgPacketLossDown
            = new AverageStatReport('packet_loss_download');
        /**
         * Average FPS for remote videos
         * @type {AverageStatReport}
         * @private
         */
        this._avgRemoteFPS = new AverageStatReport('framerate_remote');
        /**
         * Average FPS for remote screen streaming videos (reported only if not
         * a <tt>NaN</tt>).
         * @type {AverageStatReport}
         * @private
         */
        this._avgRemoteScreenFPS
            = new AverageStatReport('framerate_screen_remote');
        /**
         * Average FPS for local video (camera)
         * @type {AverageStatReport}
         * @private
         */
        this._avgLocalFPS = new AverageStatReport('framerate_local');
        /**
         * Average FPS for local screen streaming video (reported only if not
         * a <tt>NaN</tt>).
         * @type {AverageStatReport}
         * @private
         */
        this._avgLocalScreenFPS
            = new AverageStatReport('framerate_screen_local');
        /**
         * Average pixels for remote screen streaming videos (reported only if
         * not a <tt>NaN</tt>).
         * @type {AverageStatReport}
         * @private
         */
        this._avgRemoteCameraPixels
            = new AverageStatReport('pixels_remote');
        /**
         * Average pixels for remote screen streaming videos (reported only if
         * not a <tt>NaN</tt>).
         * @type {AverageStatReport}
         * @private
         */
        this._avgRemoteScreenPixels
            = new AverageStatReport('pixels_screen_remote');
        /**
         * Average pixels for local video (camera)
         * @type {AverageStatReport}
         * @private
         */
        this._avgLocalCameraPixels
            = new AverageStatReport('pixels_local');
        /**
         * Average pixels for local screen streaming video (reported only if not
         * a <tt>NaN</tt>).
         * @type {AverageStatReport}
         * @private
         */
        this._avgLocalScreenPixels
            = new AverageStatReport('pixels_screen_local');
        /**
         * Average connection quality as defined by
         * the {@link ConnectionQuality} module.
         * @type {AverageStatReport}
         * @private
         */
        this._avgCQ = new AverageStatReport('connection_quality');
        this._cachedTransportStats = undefined;
        this._onLocalStatsUpdated = data => {
            this._calculateAvgStats(data);
            this._maybeSendTransportAnalyticsEvent(data);
        };
        conference.on(_service_connectivity_ConnectionQualityEvents__WEBPACK_IMPORTED_MODULE_5__.LOCAL_STATS_UPDATED, this._onLocalStatsUpdated);
        this._onP2PStatusChanged = () => {
            logger.debug('Resetting average stats calculation');
            this._resetAvgStats();
            this.jvbStatsMonitor._resetAvgStats();
            this.p2pStatsMonitor._resetAvgStats();
        };
        conference.on(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_2__.P2P_STATUS, this._onP2PStatusChanged);
        this._onJvb121StatusChanged = (oldStatus, newStatus) => {
            // We want to reset only on the transition from false => true,
            // because otherwise those stats are resetted on JVB <=> P2P
            // transition.
            if (newStatus === true) {
                logger.info('Resetting JVB avg RTP stats');
                this._resetAvgJvbStats();
            }
        };
        conference.on(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_2__.JVB121_STATUS, this._onJvb121StatusChanged);
        this.jvbStatsMonitor
            = new ConnectionAvgStats(this, false /* JVB */, n);
        this.p2pStatsMonitor
            = new ConnectionAvgStats(this, true /* P2P */, n);
    }
    /**
     * Processes next batch of stats reported on
     * {@link ConnectionQualityEvents.LOCAL_STATS_UPDATED}.
     * @param {go figure} data
     * @private
     */
    _calculateAvgStats(data) {
        if (!data) {
            logger.error('No stats');
            return;
        }
        const isP2P = this._conference.isP2PActive();
        const confSize = this._conference.getParticipantCount();
        if (!isP2P && confSize < 2) {
            // There's no point in collecting stats for a JVB conference of 1.
            // That happens for short period of time after everyone leaves
            // the room, until Jicofo terminates the session.
            return;
        }
        /* Uncomment to figure out stats structure
        for (const key in data) {
            if (data.hasOwnProperty(key)) {
                logger.info(`local stat ${key}: `, data[key]);
            }
        } */
        const bitrate = data.bitrate;
        const bandwidth = data.bandwidth;
        const packetLoss = data.packetLoss;
        const frameRate = data.framerate;
        const resolution = data.resolution;
        if (!bitrate) {
            logger.error('No "bitrate"');
            return;
        }
        else if (!bandwidth) {
            logger.error('No "bandwidth"');
            return;
        }
        else if (!packetLoss) {
            logger.error('No "packetloss"');
            return;
        }
        else if (!frameRate) {
            logger.error('No "framerate"');
            return;
        }
        else if (!resolution) {
            logger.error('No resolution');
            return;
        }
        this._avgAudioBitrateUp.addNext(bitrate.audio.upload);
        this._avgAudioBitrateDown.addNext(bitrate.audio.download);
        this._avgVideoBitrateUp.addNext(bitrate.video.upload);
        this._avgVideoBitrateDown.addNext(bitrate.video.download);
        if (_browser__WEBPACK_IMPORTED_MODULE_7__["default"].supportsBandwidthStatistics()) {
            this._avgBandwidthUp.addNext(bandwidth.upload);
            this._avgBandwidthDown.addNext(bandwidth.download);
        }
        this._avgPacketLossUp.addNext(packetLoss.upload);
        this._avgPacketLossDown.addNext(packetLoss.download);
        this._avgPacketLossTotal.addNext(packetLoss.total);
        this._avgCQ.addNext(data.connectionQuality);
        if (frameRate) {
            this._avgRemoteFPS.addNext(this._calculateAvgVideoFps(frameRate, false /* remote */, _service_RTC_VideoType__WEBPACK_IMPORTED_MODULE_4__.VideoType.CAMERA));
            this._avgRemoteScreenFPS.addNext(this._calculateAvgVideoFps(frameRate, false /* remote */, _service_RTC_VideoType__WEBPACK_IMPORTED_MODULE_4__.VideoType.DESKTOP));
            this._avgLocalFPS.addNext(this._calculateAvgVideoFps(frameRate, true /* local */, _service_RTC_VideoType__WEBPACK_IMPORTED_MODULE_4__.VideoType.CAMERA));
            this._avgLocalScreenFPS.addNext(this._calculateAvgVideoFps(frameRate, true /* local */, _service_RTC_VideoType__WEBPACK_IMPORTED_MODULE_4__.VideoType.DESKTOP));
        }
        if (resolution) {
            this._avgRemoteCameraPixels.addNext(this._calculateAvgVideoPixels(resolution, false /* remote */, _service_RTC_VideoType__WEBPACK_IMPORTED_MODULE_4__.VideoType.CAMERA));
            this._avgRemoteScreenPixels.addNext(this._calculateAvgVideoPixels(resolution, false /* remote */, _service_RTC_VideoType__WEBPACK_IMPORTED_MODULE_4__.VideoType.DESKTOP));
            this._avgLocalCameraPixels.addNext(this._calculateAvgVideoPixels(resolution, true /* local */, _service_RTC_VideoType__WEBPACK_IMPORTED_MODULE_4__.VideoType.CAMERA));
            this._avgLocalScreenPixels.addNext(this._calculateAvgVideoPixels(resolution, true /* local */, _service_RTC_VideoType__WEBPACK_IMPORTED_MODULE_4__.VideoType.DESKTOP));
        }
        this._sampleIdx += 1;
        if (this._sampleIdx >= this._n) {
            const batchReport = {
                p2p: isP2P,
                'conference_size': confSize
            };
            if (data.transport && data.transport.length) {
                Object.assign(batchReport, {
                    'local_candidate_type': data.transport[0].localCandidateType,
                    'remote_candidate_type': data.transport[0].remoteCandidateType,
                    'transport_type': data.transport[0].type
                });
            }
            this._avgAudioBitrateUp.appendReport(batchReport);
            this._avgAudioBitrateDown.appendReport(batchReport);
            this._avgVideoBitrateUp.appendReport(batchReport);
            this._avgVideoBitrateDown.appendReport(batchReport);
            if (_browser__WEBPACK_IMPORTED_MODULE_7__["default"].supportsBandwidthStatistics()) {
                this._avgBandwidthUp.appendReport(batchReport);
                this._avgBandwidthDown.appendReport(batchReport);
            }
            this._avgPacketLossUp.appendReport(batchReport);
            this._avgPacketLossDown.appendReport(batchReport);
            this._avgPacketLossTotal.appendReport(batchReport);
            this._avgRemoteFPS.appendReport(batchReport);
            if (!isNaN(this._avgRemoteScreenFPS.calculate())) {
                this._avgRemoteScreenFPS.appendReport(batchReport);
            }
            this._avgLocalFPS.appendReport(batchReport);
            if (!isNaN(this._avgLocalScreenFPS.calculate())) {
                this._avgLocalScreenFPS.appendReport(batchReport);
            }
            this._avgRemoteCameraPixels.appendReport(batchReport);
            if (!isNaN(this._avgRemoteScreenPixels.calculate())) {
                this._avgRemoteScreenPixels.appendReport(batchReport);
            }
            this._avgLocalCameraPixels.appendReport(batchReport);
            if (!isNaN(this._avgLocalScreenPixels.calculate())) {
                this._avgLocalScreenPixels.appendReport(batchReport);
            }
            this._avgCQ.appendReport(batchReport);
            _statistics__WEBPACK_IMPORTED_MODULE_8__["default"].sendAnalytics((0,_service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_6__.createRtpStatsEvent)(batchReport));
            this._resetAvgStats();
        }
    }
    /**
     * Calculates average number of pixels for the report
     *
     * @param {map} peerResolutions a map of peer resolutions
     * @param {boolean} isLocal if the average is to be calculated for the local
     * video or <tt>false</tt> if for remote videos.
     * @param {VideoType} videoType
     * @return {number|NaN} average number of pixels or <tt>NaN</tt> if there
     * are no samples.
     * @private
     */
    _calculateAvgVideoPixels(peerResolutions, isLocal, videoType) {
        let peerPixelsSum = 0;
        let peerCount = 0;
        const myID = this._conference.myUserId();
        for (const peerID of Object.keys(peerResolutions)) {
            if (isLocal ? peerID === myID : peerID !== myID) {
                const participant = isLocal
                    ? null
                    : this._conference.getParticipantById(peerID);
                const videosResolution = peerResolutions[peerID];
                // Do not continue without participant for non local peerID
                if ((isLocal || participant) && videosResolution) {
                    const peerAvgPixels = this._calculatePeerAvgVideoPixels(videosResolution, participant, videoType);
                    if (!isNaN(peerAvgPixels)) {
                        peerPixelsSum += peerAvgPixels;
                        peerCount += 1;
                    }
                }
            }
        }
        return peerPixelsSum / peerCount;
    }
    /**
     * Calculate average pixels for either remote or local participant
     * @param {object} videos maps resolution per video SSRC
     * @param {JitsiParticipant|null} participant remote participant or
     * <tt>null</tt> for local video pixels calculation.
     * @param {VideoType} videoType the type of the video for which an average
     * will be calculated.
     * @return {number|NaN} average video pixels of all participant's videos or
     * <tt>NaN</tt> if currently not available
     * @private
     */
    _calculatePeerAvgVideoPixels(videos, participant, videoType) {
        let ssrcs = Object.keys(videos).map(ssrc => Number(ssrc));
        let videoTracks = null;
        // NOTE that this method is supposed to be called for the stats
        // received from the current peerconnection.
        const tpc = this._conference.getActivePeerConnection();
        if (participant) {
            videoTracks = participant.getTracksByMediaType(_service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_3__.MediaType.VIDEO);
            if (videoTracks) {
                ssrcs
                    = ssrcs.filter(ssrc => videoTracks.find(track => !track.isMuted()
                        && track.getSSRC() === ssrc
                        && track.videoType === videoType));
            }
        }
        else {
            videoTracks = this._conference.getLocalTracks(_service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_3__.MediaType.VIDEO);
            ssrcs
                = ssrcs.filter(ssrc => videoTracks.find(track => !track.isMuted()
                    && tpc.getLocalSSRC(track) === ssrc
                    && track.videoType === videoType));
        }
        let peerPixelsSum = 0;
        let peerSsrcCount = 0;
        for (const ssrc of ssrcs) {
            const peerSsrcPixels = Number(videos[ssrc].height) * Number(videos[ssrc].width);
            // FPS is reported as 0 for users with no video
            if (!isNaN(peerSsrcPixels) && peerSsrcPixels > 0) {
                peerPixelsSum += peerSsrcPixels;
                peerSsrcCount += 1;
            }
        }
        return peerPixelsSum / peerSsrcCount;
    }
    /**
     * Calculates average FPS for the report
     * @param {go figure} frameRate
     * @param {boolean} isLocal if the average is to be calculated for the local
     * video or <tt>false</tt> if for remote videos.
     * @param {VideoType} videoType
     * @return {number|NaN} average FPS or <tt>NaN</tt> if there are no samples.
     * @private
     */
    _calculateAvgVideoFps(frameRate, isLocal, videoType) {
        let peerFpsSum = 0;
        let peerCount = 0;
        const myID = this._conference.myUserId();
        for (const peerID of Object.keys(frameRate)) {
            if (isLocal ? peerID === myID : peerID !== myID) {
                const participant = isLocal
                    ? null : this._conference.getParticipantById(peerID);
                const videosFps = frameRate[peerID];
                // Do not continue without participant for non local peerID
                if ((isLocal || participant) && videosFps) {
                    const peerAvgFPS = this._calculatePeerAvgVideoFps(videosFps, participant, videoType);
                    if (!isNaN(peerAvgFPS)) {
                        peerFpsSum += peerAvgFPS;
                        peerCount += 1;
                    }
                }
            }
        }
        return peerFpsSum / peerCount;
    }
    /**
     * Calculate average FPS for either remote or local participant
     * @param {object} videos maps FPS per video SSRC
     * @param {JitsiParticipant|null} participant remote participant or
     * <tt>null</tt> for local FPS calculation.
     * @param {VideoType} videoType the type of the video for which an average
     * will be calculated.
     * @return {number|NaN} average FPS of all participant's videos or
     * <tt>NaN</tt> if currently not available
     * @private
     */
    _calculatePeerAvgVideoFps(videos, participant, videoType) {
        let ssrcs = Object.keys(videos).map(ssrc => Number(ssrc));
        let videoTracks = null;
        // NOTE that this method is supposed to be called for the stats
        // received from the current peerconnection.
        const tpc = this._conference.getActivePeerConnection();
        if (participant) {
            videoTracks = participant.getTracksByMediaType(_service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_3__.MediaType.VIDEO);
            if (videoTracks) {
                ssrcs
                    = ssrcs.filter(ssrc => videoTracks.find(track => !track.isMuted()
                        && track.getSSRC() === ssrc
                        && track.videoType === videoType));
            }
        }
        else {
            videoTracks = this._conference.getLocalTracks(_service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_3__.MediaType.VIDEO);
            ssrcs
                = ssrcs.filter(ssrc => videoTracks.find(track => !track.isMuted()
                    && tpc.getLocalSSRC(track) === ssrc
                    && track.videoType === videoType));
        }
        let peerFpsSum = 0;
        let peerSsrcCount = 0;
        for (const ssrc of ssrcs) {
            const peerSsrcFps = Number(videos[ssrc]);
            // FPS is reported as 0 for users with no video
            if (!isNaN(peerSsrcFps) && peerSsrcFps > 0) {
                peerFpsSum += peerSsrcFps;
                peerSsrcCount += 1;
            }
        }
        return peerFpsSum / peerSsrcCount;
    }
    /**
     * Sends the 'transport.stats' analytics event whenever we detect that
     * there is a change in the local or remote candidate type on the transport
     * that is currently selected.
     * @param {*} data
     * @private
     */
    _maybeSendTransportAnalyticsEvent(data) {
        if (!data || !data.transport || !data.transport.length) {
            return;
        }
        const transportStats = {
            p2p: data.transport[0].p2p,
            'local_candidate_type': data.transport[0].localCandidateType,
            'remote_candidate_type': data.transport[0].remoteCandidateType,
            'transport_type': data.transport[0].type
        };
        if (!this._cachedTransportStats || !lodash_isequal__WEBPACK_IMPORTED_MODULE_1___default()(transportStats, this._cachedTransportStats)) {
            this._cachedTransportStats = transportStats;
            _statistics__WEBPACK_IMPORTED_MODULE_8__["default"].sendAnalytics((0,_service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_6__.createTransportStatsEvent)(transportStats));
        }
    }
    /**
     * Resets the stats related to JVB connection. Must not be called when in
     * P2P mode, because then the {@link AverageStatReport} instances are
     * tracking P2P stats. Note that this should never happen unless something
     * is wrong with the P2P and JVB121 events.
     * @private
     */
    _resetAvgJvbStats() {
        this._resetAvgStats();
        this.jvbStatsMonitor._resetAvgStats();
    }
    /**
     * Reset cache of all averages and {@link _sampleIdx}.
     * @private
     */
    _resetAvgStats() {
        this._avgAudioBitrateUp.reset();
        this._avgAudioBitrateDown.reset();
        this._avgVideoBitrateUp.reset();
        this._avgVideoBitrateDown.reset();
        this._avgBandwidthUp.reset();
        this._avgBandwidthDown.reset();
        this._avgPacketLossUp.reset();
        this._avgPacketLossDown.reset();
        this._avgPacketLossTotal.reset();
        this._avgRemoteFPS.reset();
        this._avgRemoteScreenFPS.reset();
        this._avgLocalFPS.reset();
        this._avgLocalScreenFPS.reset();
        this._avgRemoteCameraPixels.reset();
        this._avgRemoteScreenPixels.reset();
        this._avgLocalCameraPixels.reset();
        this._avgLocalScreenPixels.reset();
        this._avgCQ.reset();
        this._sampleIdx = 0;
    }
    /**
     * Unregisters all event listeners and stops working.
     */
    dispose() {
        this._conference.off(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_2__.P2P_STATUS, this._onP2PStatusChanged);
        this._conference.off(_service_connectivity_ConnectionQualityEvents__WEBPACK_IMPORTED_MODULE_5__.LOCAL_STATS_UPDATED, this._onLocalStatsUpdated);
        this._conference.off(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_2__.JVB121_STATUS, this._onJvb121StatusChanged);
        this.jvbStatsMonitor.dispose();
        this.p2pStatsMonitor.dispose();
    }
}
//# sourceMappingURL=AvgRTPStatsReporter.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/statistics/CallStats.js":
/*!*************************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/statistics/CallStats.js ***!
  \*************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
var __filename = "/index.js";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (/* binding */ CallStats)
/* harmony export */ });
/* harmony import */ var _browser__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../browser */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/browser/index.js");
/* harmony import */ var _util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../util/GlobalOnErrorHandler */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/util/GlobalOnErrorHandler.js");
/* harmony import */ var _util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_1___default = /*#__PURE__*/__webpack_require__.n(_util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_1__);
/* global callstats */


const logger = (__webpack_require__(/*! @jitsi/logger */ "./node_modules/@jitsi/logger/lib/index.js").getLogger)(__filename);
/**
 * We define enumeration of wrtcFuncNames as we need them before
 * callstats is initialized to queue events.
 * @const
 * @see http://www.callstats.io/api/#enumeration-of-wrtcfuncnames
 */
const wrtcFuncNames = {
    createOffer: 'createOffer',
    createAnswer: 'createAnswer',
    setLocalDescription: 'setLocalDescription',
    setRemoteDescription: 'setRemoteDescription',
    addIceCandidate: 'addIceCandidate',
    getUserMedia: 'getUserMedia',
    iceConnectionFailure: 'iceConnectionFailure',
    signalingError: 'signalingError',
    applicationLog: 'applicationLog'
};
/**
 * We define enumeration of fabricEvent as we need them before
 * callstats is initialized to queue events.
 * @const
 * @see http://www.callstats.io/api/#enumeration-of-fabricevent
 */
const fabricEvent = {
    fabricHold: 'fabricHold',
    fabricResume: 'fabricResume',
    audioMute: 'audioMute',
    audioUnmute: 'audioUnmute',
    videoPause: 'videoPause',
    videoResume: 'videoResume',
    fabricUsageEvent: 'fabricUsageEvent',
    fabricStats: 'fabricStats',
    fabricTerminated: 'fabricTerminated',
    screenShareStart: 'screenShareStart',
    screenShareStop: 'screenShareStop',
    dominantSpeaker: 'dominantSpeaker',
    activeDeviceList: 'activeDeviceList'
};
/**
 * The user id to report to callstats as destination.
 * @type {string}
 */
const DEFAULT_REMOTE_USER = 'jitsi';
/**
 * Type of pending reports, can be event or an error.
 * @type {{ERROR: string, EVENT: string}}
 */
const reportType = {
    ERROR: 'error',
    EVENT: 'event',
    MST_WITH_USERID: 'mstWithUserID'
};
/**
 * Set of currently existing {@link CallStats} instances.
 * @type {Set<CallStats>}
 */
let _fabrics;
/**
 * An instance of this class is a wrapper for the CallStats API fabric. A fabric
 * reports one peer connection to the CallStats backend and is allocated with
 * {@link callstats.addNewFabric}. It has a bunch of instance methods for
 * reporting various events. A fabric is considered disposed when
 * {@link CallStats.sendTerminateEvent} is executed.
 *
 * Currently only one backend instance can be created ever and it's done using
 * {@link CallStats.initBackend}. At the time of this writing there is no way to
 * explicitly shutdown the backend, but it's supposed to close it's connection
 * automatically, after all fabrics have been terminated.
 */
class CallStats {
    /**
     * A callback passed to {@link callstats.addNewFabric}.
     * @param {string} error 'success' means ok
     * @param {string} msg some more details
     * @private
     */
    static _addNewFabricCallback(error, msg) {
        if (CallStats.backend && error !== 'success') {
            logger.error(`Monitoring status: ${error} msg: ${msg}`);
        }
    }
    /**
     * Callback passed to {@link callstats.initialize} (backend initialization)
     * @param {string} error 'success' means ok
     * @param {String} msg
     * @private
     */
    static _initCallback(error, msg) {
        logger.log(`CallStats Status: err=${error} msg=${msg}`);
        // there is no lib, nothing to report to
        if (error !== 'success') {
            return;
        }
        CallStats.backendInitialized = true;
        // I hate that
        let atLeastOneFabric = false;
        let defaultInstance = null;
        for (const callStatsInstance of CallStats.fabrics.values()) {
            if (!callStatsInstance.hasFabric) {
                logger.debug('addNewFabric - initCallback');
                if (callStatsInstance._addNewFabric()) {
                    atLeastOneFabric = true;
                    if (!defaultInstance) {
                        defaultInstance = callStatsInstance;
                    }
                }
            }
        }
        if (!atLeastOneFabric) {
            return;
        }
        CallStats._emptyReportQueue(defaultInstance);
    }
    /**
     * Empties report queue.
     *
     * @param {CallStats} csInstance - The callstats instance.
     * @private
     */
    static _emptyReportQueue(csInstance) {
        // There is no conference ID nor a PeerConnection available when some of
        // the events are scheduled on the reportsQueue, so those will be
        // reported on the first initialized fabric.
        const defaultConfID = csInstance.confID;
        const defaultPC = csInstance.peerconnection;
        // notify callstats about failures if there were any
        for (const report of CallStats.reportsQueue) {
            if (report.type === reportType.ERROR) {
                const errorData = report.data;
                CallStats._reportError(csInstance, errorData.type, errorData.error, errorData.pc || defaultPC);
            }
            else if (report.type === reportType.EVENT) {
                // if we have and event to report and we failed to add
                // fabric this event will not be reported anyway, returning
                // an error
                const eventData = report.data;
                CallStats.backend.sendFabricEvent(report.pc || defaultPC, eventData.event, defaultConfID, eventData.eventData);
            }
            else if (report.type === reportType.MST_WITH_USERID) {
                const data = report.data;
                CallStats.backend.associateMstWithUserID(report.pc || defaultPC, data.callStatsId, defaultConfID, data.ssrc, data.usageLabel, data.containerId);
            }
        }
        CallStats.reportsQueue.length = 0;
    }
    /* eslint-disable max-params */
    /**
     * Reports an error to callstats.
     *
     * @param {CallStats} [cs]
     * @param type the type of the error, which will be one of the wrtcFuncNames
     * @param error the error
     * @param pc the peerconnection
     * @private
     */
    static _reportError(cs, type, error, pc) {
        let _error = error;
        if (!_error) {
            logger.warn('No error is passed!');
            _error = new Error('Unknown error');
        }
        if (CallStats.backendInitialized && cs) {
            CallStats.backend.reportError(pc, cs.confID, type, _error);
        }
        else {
            CallStats.reportsQueue.push({
                type: reportType.ERROR,
                data: {
                    error: _error,
                    pc,
                    type
                }
            });
        }
        // else just ignore it
    }
    /* eslint-enable max-params */
    /**
     * Reports an error to callstats.
     *
     * @param {CallStats} cs
     * @param event the type of the event, which will be one of the fabricEvent
     * @param eventData additional data to pass to event
     * @private
     */
    static _reportEvent(cs, event, eventData) {
        const pc = cs && cs.peerconnection;
        const confID = cs && cs.confID;
        if (CallStats.backendInitialized && cs) {
            CallStats.backend.sendFabricEvent(pc, event, confID, eventData);
        }
        else {
            CallStats.reportsQueue.push({
                confID,
                pc,
                type: reportType.EVENT,
                data: { event,
                    eventData }
            });
        }
    }
    /**
     * Wraps some of the CallStats API method and logs their calls with
     * arguments on the debug logging level. Also wraps some of the backend
     * methods execution into try catch blocks to not crash the app in case
     * there is a problem with the backend itself.
     * @param {callstats} theBackend
     * @private
     */
    static _traceAndCatchBackendCalls(theBackend) {
        const tryCatchMethods = [
            'associateMstWithUserID',
            'sendFabricEvent',
            'sendUserFeedback'
            // 'reportError', - this one needs special handling - see code below
        ];
        for (const methodName of tryCatchMethods) {
            const originalMethod = theBackend[methodName];
            theBackend[methodName] = function (...theArguments) {
                try {
                    return originalMethod.apply(theBackend, theArguments);
                }
                catch (e) {
                    _util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_1___default().callErrorHandler(e);
                }
            };
        }
        const debugMethods = [
            'associateMstWithUserID',
            'sendFabricEvent',
            'sendUserFeedback'
            // 'reportError', - this one needs special handling - see code below
        ];
        for (const methodName of debugMethods) {
            const originalMethod = theBackend[methodName];
            theBackend[methodName] = function (...theArguments) {
                logger.debug(methodName, theArguments);
                originalMethod.apply(theBackend, theArguments);
            };
        }
        const originalReportError = theBackend.reportError;
        /* eslint-disable max-params */
        theBackend.reportError = function (pc, cs, type, ...args) {
            // Logs from the logger are submitted on the applicationLog event
            // "type". Logging the arguments on the logger will create endless
            // loop, because it will put all the logs to the logger queue again.
            if (type === wrtcFuncNames.applicationLog) {
                // NOTE otherArguments are not logged to the console on purpose
                // to not log the whole log batch
                // FIXME check the current logging level (currently not exposed
                // by the logger implementation)
                // NOTE it is not safe to log whole objects on react-native as
                // those contain too many circular references and may crash
                // the app.
                if (!_browser__WEBPACK_IMPORTED_MODULE_0__["default"].isReactNative()) {
                    console && console.debug('reportError', pc, cs, type);
                }
            }
            else {
                logger.debug('reportError', pc, cs, type, ...args);
            }
            try {
                originalReportError.call(theBackend, pc, cs, type, ...args);
            }
            catch (exception) {
                if (type === wrtcFuncNames.applicationLog) {
                    console && console.error('reportError', exception);
                }
                else {
                    _util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_1___default().callErrorHandler(exception);
                }
            }
        };
        /* eslint-enable max-params */
    }
    /**
     * Returns the Set with the currently existing {@link CallStats} instances.
     * Lazily initializes the Set to allow any Set polyfills to be applied.
     * @type {Set<CallStats>}
     */
    static get fabrics() {
        if (!_fabrics) {
            _fabrics = new Set();
        }
        return _fabrics;
    }
    /**
     * Initializes the CallStats backend. Should be called only if
     * {@link CallStats.isBackendInitialized} returns <tt>false</tt>.
     * @param {object} options
     * @param {String} options.callStatsID CallStats credentials - ID
     * @param {String} options.callStatsSecret CallStats credentials - secret
     * @param {string} options.aliasName the <tt>aliasName</tt> part of
     * the <tt>userID</tt> aka endpoint ID, see CallStats docs for more info.
     * @param {string} options.userName the <tt>userName</tt> part of
     * the <tt>userID</tt> aka display name, see CallStats docs for more info.
     * @param {object} options.configParams the set of parameters
     * to enable/disable certain features in the library. See CallStats docs for more info.
     *
     */
    static initBackend(options) {
        if (CallStats.backend) {
            throw new Error('CallStats backend has been initialized already!');
        }
        try {
            const CallStatsBackend = callstats;
            CallStats.backend = new CallStatsBackend();
            CallStats._traceAndCatchBackendCalls(CallStats.backend);
            CallStats.userID = {
                aliasName: options.aliasName,
                userName: options.userName
            };
            CallStats.callStatsID = options.callStatsID;
            CallStats.callStatsSecret = options.callStatsSecret;
            const configParams = Object.assign({}, options.configParams);
            if (options.applicationName) {
                configParams.applicationVersion = `${options.applicationName} (${_browser__WEBPACK_IMPORTED_MODULE_0__["default"].getName()})`;
            }
            if (options.confID) {
                // we first check is there a tenant in the confID
                const match = options.confID.match(/.*\/(.*)\/.*/);
                // if there is no tenant, we will just set '/'
                configParams.siteID = options.siteID || (match && match[1]) || '/';
            }
            // userID is generated or given by the origin server
            CallStats.backend.initialize(CallStats.callStatsID, CallStats.callStatsSecret, CallStats.userID, CallStats._initCallback, undefined, configParams);
            return true;
        }
        catch (e) {
            // The callstats.io API failed to initialize (e.g. because its
            // download did not succeed in general or on time). Further attempts
            // to utilize it cannot possibly succeed.
            _util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_1___default().callErrorHandler(e);
            CallStats.backend = null;
            logger.error(e);
            return false;
        }
    }
    /**
     * Checks if the CallStats backend has been created. It does not mean that
     * it has been initialized, but only that the API instance has been
     * allocated successfully.
     * @return {boolean} <tt>true</tt> if backend exists or <tt>false</tt>
     * otherwise
     */
    static isBackendInitialized() {
        return Boolean(CallStats.backend);
    }
    /**
     * Notifies CallStats about active device.
     * @param {{deviceList: {String:String}}} devicesData list of devices with
     * their data
     * @param {CallStats} cs callstats instance related to the event
     */
    static sendActiveDeviceListEvent(devicesData, cs) {
        CallStats._reportEvent(cs, fabricEvent.activeDeviceList, devicesData);
    }
    /**
     * Notifies CallStats that there is a log we want to report.
     *
     * @param {Error} e error to send or {String} message
     * @param {CallStats} cs callstats instance related to the error (optional)
     */
    static sendApplicationLog(e, cs) {
        try {
            CallStats._reportError(cs, wrtcFuncNames.applicationLog, e, cs && cs.peerconnection);
        }
        catch (error) {
            // If sendApplicationLog fails it should not be printed to
            // the logger, because it will try to push the logs again
            // (through sendApplicationLog) and an endless loop is created.
            if (console && (typeof console.error === 'function')) {
                // FIXME send analytics event as well
                console.error('sendApplicationLog failed', error);
            }
        }
    }
    /**
     * Sends the given feedback through CallStats.
     *
     * @param {string} conferenceID the conference ID for which the feedback
     * will be reported.
     * @param overall an integer between 1 and 5 indicating the
     * user feedback
     * @param comment detailed feedback from the user.
     */
    static sendFeedback(conferenceID, overall, comment) {
        return new Promise((resolve, reject) => {
            if (CallStats.backend) {
                CallStats.backend.sendUserFeedback(conferenceID, {
                    userID: CallStats.userID,
                    overall,
                    comment
                }, (status, message) => {
                    if (status === 'success') {
                        resolve(message);
                    }
                    else {
                        reject(message);
                    }
                });
            }
            else {
                const reason = 'Failed to submit feedback to CallStats - no backend';
                logger.error(reason);
                reject(reason);
            }
        });
    }
    /**
     * Notifies CallStats that getUserMedia failed.
     *
     * @param {Error} e error to send
     * @param {CallStats} cs callstats instance related to the error (optional)
     */
    static sendGetUserMediaFailed(e, cs) {
        CallStats._reportError(cs, wrtcFuncNames.getUserMedia, e, null);
    }
    /**
     * Notifies CallStats for mute events
     * @param mute {boolean} true for muted and false for not muted
     * @param type {String} "audio"/"video"
     * @param {CallStats} cs callstats instance related to the event
     */
    static sendMuteEvent(mute, type, cs) {
        let event;
        if (type === 'video') {
            event = mute ? fabricEvent.videoPause : fabricEvent.videoResume;
        }
        else {
            event = mute ? fabricEvent.audioMute : fabricEvent.audioUnmute;
        }
        CallStats._reportEvent(cs, event);
    }
    /**
     * Creates new CallStats instance that handles all callstats API calls for
     * given {@link TraceablePeerConnection}. Each instance is meant to handle
     * one CallStats fabric added with 'addFabric' API method for the
     * {@link TraceablePeerConnection} instance passed in the constructor.
     * @param {TraceablePeerConnection} tpc
     * @param {Object} options
     * @param {string} options.confID the conference ID that wil be used to
     * report the session.
     * @param {string} [options.remoteUserID='jitsi'] the remote user ID to
     * which given <tt>tpc</tt> is connected.
     */
    constructor(tpc, options) {
        this.confID = options.confID;
        this.tpc = tpc;
        this.peerconnection = tpc.peerconnection;
        this.remoteUserID = options.remoteUserID || DEFAULT_REMOTE_USER;
        this.hasFabric = false;
        CallStats.fabrics.add(this);
        if (CallStats.backendInitialized) {
            this._addNewFabric();
            // if this is the first fabric let's try to empty the
            // report queue. Reports all events that we recorded between
            // backend initialization and receiving the first fabric
            if (CallStats.fabrics.size === 1) {
                CallStats._emptyReportQueue(this);
            }
        }
    }
    /**
     * Initializes CallStats fabric by calling "addNewFabric" for
     * the peer connection associated with this instance.
     * @return {boolean} true if the call was successful or false otherwise.
     */
    _addNewFabric() {
        logger.info('addNewFabric', this.remoteUserID);
        try {
            const fabricAttributes = {
                remoteEndpointType: this.tpc.isP2P
                    ? CallStats.backend.endpointType.peer
                    : CallStats.backend.endpointType.server
            };
            const ret = CallStats.backend.addNewFabric(this.peerconnection, this.remoteUserID, CallStats.backend.fabricUsage.multiplex, this.confID, fabricAttributes, CallStats._addNewFabricCallback);
            this.hasFabric = true;
            const success = ret.status === 'success';
            if (!success) {
                logger.error('callstats fabric not initilized', ret.message);
            }
            return success;
        }
        catch (error) {
            _util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_1___default().callErrorHandler(error);
            return false;
        }
    }
    /* eslint-disable max-params */
    /**
     * Lets CallStats module know where is given SSRC rendered by providing
     * renderer tag ID.
     * If the lib is not initialized yet queue the call for later, when it's
     * ready.
     * @param {number} ssrc the SSRC of the stream
     * @param {boolean} isLocal indicates whether this the stream is local
     * @param {string|null} streamEndpointId if the stream is not local the it
     * needs to contain the stream owner's ID
     * @param {string} usageLabel meaningful usage label of this stream like
     *        'microphone', 'camera' or 'screen'.
     * @param {string} containerId  the id of media 'audio' or 'video' tag which
     *        renders the stream.
     */
    associateStreamWithVideoTag(ssrc, isLocal, streamEndpointId, usageLabel, containerId) {
        if (!CallStats.backend) {
            return;
        }
        const callStatsId = isLocal ? CallStats.userID : streamEndpointId;
        if (CallStats.backendInitialized) {
            CallStats.backend.associateMstWithUserID(this.peerconnection, callStatsId, this.confID, ssrc, usageLabel, containerId);
        }
        else {
            CallStats.reportsQueue.push({
                type: reportType.MST_WITH_USERID,
                pc: this.peerconnection,
                data: {
                    callStatsId,
                    containerId,
                    ssrc,
                    usageLabel
                }
            });
        }
    }
    /* eslint-enable max-params */
    /**
     * Notifies CallStats that we are the new dominant speaker in the
     * conference.
     */
    sendDominantSpeakerEvent() {
        CallStats._reportEvent(this, fabricEvent.dominantSpeaker);
    }
    /**
     * Notifies CallStats that the fabric for the underlying peerconnection was
     * closed and no evens should be reported, after this call.
     */
    sendTerminateEvent() {
        if (CallStats.backendInitialized) {
            CallStats.backend.sendFabricEvent(this.peerconnection, CallStats.backend.fabricEvent.fabricTerminated, this.confID);
        }
        CallStats.fabrics.delete(this);
    }
    /**
     * Notifies CallStats for ice connection failed
     */
    sendIceConnectionFailedEvent() {
        CallStats._reportError(this, wrtcFuncNames.iceConnectionFailure, null, this.peerconnection);
    }
    /**
     * Notifies CallStats that peer connection failed to create offer.
     *
     * @param {Error} e error to send
     */
    sendCreateOfferFailed(e) {
        CallStats._reportError(this, wrtcFuncNames.createOffer, e, this.peerconnection);
    }
    /**
     * Notifies CallStats that peer connection failed to create answer.
     *
     * @param {Error} e error to send
     */
    sendCreateAnswerFailed(e) {
        CallStats._reportError(this, wrtcFuncNames.createAnswer, e, this.peerconnection);
    }
    /**
     * Sends either resume or hold event for the fabric associated with
     * the underlying peerconnection.
     * @param {boolean} isResume true to resume or false to hold
     */
    sendResumeOrHoldEvent(isResume) {
        CallStats._reportEvent(this, isResume ? fabricEvent.fabricResume : fabricEvent.fabricHold);
    }
    /**
     * Notifies CallStats for screen sharing events
     * @param {boolean} start true for starting screen sharing and
     * false for not stopping
     * @param {string|null} ssrc - optional ssrc value, used only when
     * starting screen sharing.
     */
    sendScreenSharingEvent(start, ssrc) {
        let eventData;
        if (ssrc) {
            eventData = { ssrc };
        }
        CallStats._reportEvent(this, start ? fabricEvent.screenShareStart : fabricEvent.screenShareStop, eventData);
    }
    /**
     * Notifies CallStats that peer connection failed to set local description.
     *
     * @param {Error} e error to send
     */
    sendSetLocalDescFailed(e) {
        CallStats._reportError(this, wrtcFuncNames.setLocalDescription, e, this.peerconnection);
    }
    /**
     * Notifies CallStats that peer connection failed to set remote description.
     *
     * @param {Error} e error to send
     */
    sendSetRemoteDescFailed(e) {
        CallStats._reportError(this, wrtcFuncNames.setRemoteDescription, e, this.peerconnection);
    }
    /**
     * Notifies CallStats that peer connection failed to add ICE candidate.
     *
     * @param {Error} e error to send
     */
    sendAddIceCandidateFailed(e) {
        CallStats._reportError(this, wrtcFuncNames.addIceCandidate, e, this.peerconnection);
    }
}
/**
 * The CallStats API backend instance
 * @type {callstats}
 */
CallStats.backend = null;
// some errors/events may happen before CallStats init
// in this case we accumulate them in this array
// and send them to callstats on init
CallStats.reportsQueue = [];
/**
 * Whether the library was successfully initialized(the backend) using its
 * initialize method.
 * @type {boolean}
 */
CallStats.backendInitialized = false;
/**
 * Part of the CallStats credentials - application ID
 * @type {string}
 */
CallStats.callStatsID = null;
/**
 * Part of the CallStats credentials - application secret
 * @type {string}
 */
CallStats.callStatsSecret = null;
/**
 * Local CallStats user ID structure. Can be set only once when
 * {@link backend} is initialized, so it's static for the time being.
 * See CallStats API for more info:
 * https://www.callstats.io/api/#userid
 * @type {object}
 */
CallStats.userID = null;
//# sourceMappingURL=CallStats.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/statistics/LocalStatsCollector.js":
/*!***********************************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/statistics/LocalStatsCollector.js ***!
  \***********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
var __filename = "/index.js";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (/* binding */ LocalStatsCollector)
/* harmony export */ });
/**
 * Provides statistics for the local stream.
 */
var __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {
    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};
const logger = (__webpack_require__(/*! @jitsi/logger */ "./node_modules/@jitsi/logger/lib/index.js").getLogger)(__filename);
/**
 * Size of the webaudio analyzer buffer.
 * @type {number}
 */
const WEBAUDIO_ANALYZER_FFT_SIZE = 2048;
/**
 * Value of the webaudio analyzer smoothing time parameter.
 * @type {number}
 */
const WEBAUDIO_ANALYZER_SMOOTING_TIME = 0.8;
window.AudioContext = window.AudioContext || window.webkitAudioContext;
/**
 * The audio context.
 * @type {AudioContext}
 */
let context = null;
/**
 * Converts time domain data array to audio level.
 * @param samples the time domain data array.
 * @returns {number} the audio level
 */
function timeDomainDataToAudioLevel(samples) {
    let maxVolume = 0;
    const length = samples.length;
    for (let i = 0; i < length; i++) {
        if (maxVolume < samples[i]) {
            maxVolume = samples[i];
        }
    }
    return parseFloat(((maxVolume - 127) / 128).toFixed(3));
}
/**
 * Animates audio level change
 * @param newLevel the new audio level
 * @param lastLevel the last audio level
 * @returns {Number} the audio level to be set
 */
function animateLevel(newLevel, lastLevel) {
    let value = 0;
    const diff = lastLevel - newLevel;
    if (diff > 0.2) {
        value = lastLevel - 0.2;
    }
    else if (diff < -0.4) {
        value = lastLevel + 0.4;
    }
    else {
        value = newLevel;
    }
    return parseFloat(value.toFixed(3));
}
/**
 * <tt>LocalStatsCollector</tt> calculates statistics for the local stream.
 *
 * @param stream the local stream
 * @param interval stats refresh interval given in ms.
 * @param callback function that receives the audio levels.
 * @constructor
 */
function LocalStatsCollector(stream, interval, callback) {
    this.stream = stream;
    this.intervalId = null;
    this.intervalMilis = interval;
    this.audioLevel = 0;
    this.callback = callback;
    this.source = null;
    this.analyser = null;
}
/**
 * Starts the collecting the statistics.
 */
LocalStatsCollector.prototype.start = function () {
    if (!LocalStatsCollector.isLocalStatsSupported()) {
        return;
    }
    context.resume();
    this.analyser = context.createAnalyser();
    this.analyser.smoothingTimeConstant = WEBAUDIO_ANALYZER_SMOOTING_TIME;
    this.analyser.fftSize = WEBAUDIO_ANALYZER_FFT_SIZE;
    this.source = context.createMediaStreamSource(this.stream);
    this.source.connect(this.analyser);
    this.intervalId = setInterval(() => {
        const array = new Uint8Array(this.analyser.frequencyBinCount);
        this.analyser.getByteTimeDomainData(array);
        const audioLevel = timeDomainDataToAudioLevel(array);
        // Set the audio levels always as NoAudioSignalDetection now
        // uses audio levels from LocalStatsCollector and waits for
        // atleast 4 secs for a no audio signal before displaying the
        // notification on the UI.
        this.audioLevel = animateLevel(audioLevel, this.audioLevel);
        this.callback(this.audioLevel);
    }, this.intervalMilis);
};
/**
 * Stops collecting the statistics.
 */
LocalStatsCollector.prototype.stop = function () {
    var _a, _b;
    if (this.intervalId) {
        clearInterval(this.intervalId);
        this.intervalId = null;
    }
    (_a = this.analyser) === null || _a === void 0 ? void 0 : _a.disconnect();
    this.analyser = null;
    (_b = this.source) === null || _b === void 0 ? void 0 : _b.disconnect();
    this.source = null;
};
/**
 * Checks if the environment has the necessary conditions to support
 * collecting stats from local streams.
 *
 * @returns {boolean}
 */
LocalStatsCollector.isLocalStatsSupported = function () {
    return Boolean(window === null || window === void 0 ? void 0 : window.AudioContext);
};
/**
 * Disconnects the audio context.
 */
LocalStatsCollector.disconnectAudioContext = function () {
    return __awaiter(this, void 0, void 0, function* () {
        if (context) {
            logger.info('Disconnecting audio context');
            yield context.close();
            context = null;
        }
    });
};
/**
 * Connects the audio context.
 */
LocalStatsCollector.connectAudioContext = function () {
    if (!LocalStatsCollector.isLocalStatsSupported()) {
        return;
    }
    logger.info('Connecting audio context');
    context = new AudioContext();
    context.suspend();
};
/**
 * Initialize the audio context on startup.
 */
LocalStatsCollector.connectAudioContext();
//# sourceMappingURL=LocalStatsCollector.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/statistics/PerformanceObserverStats.js":
/*!****************************************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/statistics/PerformanceObserverStats.js ***!
  \****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
var __filename = "/index.js";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   PerformanceObserverStats: () => (/* binding */ PerformanceObserverStats)
/* harmony export */ });
/* harmony import */ var _jitsi_logger__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @jitsi/logger */ "./node_modules/@jitsi/logger/lib/index.js");
/* harmony import */ var _jitsi_logger__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(_jitsi_logger__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var _service_statistics_Events__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../service/statistics/Events */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/statistics/Events.js");
/* harmony import */ var _util_MathUtil__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../util/MathUtil */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/util/MathUtil.js");



const logger = (0,_jitsi_logger__WEBPACK_IMPORTED_MODULE_0__.getLogger)(__filename);
const MILLI_SECONDS = 1000;
const SECONDS = 60;
/**
 * This class creates an observer that monitors browser's performance measurement events
 * as they are recorded in the browser's performance timeline and computes an average and
 * a maximum value for the long task events. Tasks are classified as long tasks if they take
 * longer than 50ms to execute on the main thread.
 */
class PerformanceObserverStats {
    /**
     * Creates a new instance of Performance observer statistics.
     *
     * @param {*} emitter Event emitter for emitting stats periodically
     * @param {*} statsInterval interval for calculating the stats
     */
    constructor(emitter, statsInterval) {
        this.eventEmitter = emitter;
        this.longTasks = 0;
        this.maxDuration = 0;
        this.performanceStatsInterval = statsInterval;
        this.stats = new _util_MathUtil__WEBPACK_IMPORTED_MODULE_2__.RunningAverage();
    }
    /**
     * Obtains the average rate of long tasks observed per min and the
     * duration of the longest task recorded by the observer.
     * @returns {Object}
     */
    getLongTasksStats() {
        return {
            avgRatePerMinute: (this.stats.getAverage() * SECONDS).toFixed(2),
            maxDurationMs: this.maxDuration
        };
    }
    /**
     * Starts the performance observer by registering the callback function
     * that calculates the performance statistics periodically.
     * @returns {void}
     */
    startObserver() {
        // Create a handler for when the long task event is fired.
        this.longTaskEventHandler = list => {
            const entries = list.getEntries();
            for (const task of entries) {
                this.longTasks++;
                this.maxDuration = Math.max(this.maxDuration, task.duration).toFixed(3);
            }
        };
        // Create an observer for monitoring long tasks.
        logger.info('Creating a Performance Observer for monitoring Long Tasks');
        this.observer = new PerformanceObserver(this.longTaskEventHandler);
        this.observer.observe({ type: 'longtask',
            buffered: true });
        const startTime = Date.now();
        // Calculate the average # of events/sec and emit a stats event.
        this.longTasksIntervalId = setInterval(() => {
            const now = Date.now();
            const interval = this._lastTimeStamp
                ? (now - this._lastTimeStamp) / MILLI_SECONDS
                : (now - startTime) / MILLI_SECONDS;
            const rate = this.longTasks / interval;
            this.stats.addNext(rate);
            this.eventEmitter.emit(_service_statistics_Events__WEBPACK_IMPORTED_MODULE_1__.LONG_TASKS_STATS, this.getLongTasksStats());
            // Reset the counter and start counting events again.
            this.longTasks = 0;
            this._lastTimeStamp = Date.now();
        }, this.performanceStatsInterval);
    }
    /**
     * Stops the performance observer.
     * @returns {void}
     */
    stopObserver() {
        this.observer && this.observer.disconnect();
        this.longTaskEventHandler = null;
        if (this.longTasksIntervalId) {
            clearInterval(this.longTasksIntervalId);
            this.longTasksIntervalId = null;
        }
    }
}
//# sourceMappingURL=PerformanceObserverStats.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/statistics/PrecallTest.js":
/*!***************************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/statistics/PrecallTest.js ***!
  \***************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (__WEBPACK_DEFAULT_EXPORT__),
/* harmony export */   execute: () => (/* binding */ execute),
/* harmony export */   init: () => (/* binding */ init)
/* harmony export */ });
/* harmony import */ var events__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! events */ "./node_modules/events/events.js");
/* harmony import */ var events__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(events__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var _browser__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../browser */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/browser/index.js");
/* harmony import */ var _settings_Settings__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../settings/Settings */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/settings/Settings.js");
/* harmony import */ var _util_ScriptUtil__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../util/ScriptUtil */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/util/ScriptUtil.js");
/* harmony import */ var _util_ScriptUtil__WEBPACK_IMPORTED_MODULE_3___default = /*#__PURE__*/__webpack_require__.n(_util_ScriptUtil__WEBPACK_IMPORTED_MODULE_3__);
/* harmony import */ var _constants__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./constants */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/statistics/constants.js");
var __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {
    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};





const PRECALL_TEST_RESULTS = 'preCallTestResults';
const emitter = new (events__WEBPACK_IMPORTED_MODULE_0___default())();
let _initialized = false;
let api = null;
/**
 * Loads the callstats io script.
 *
 * @returns {Promise<void>}
 */
function _loadScript(options) {
    if (_browser__WEBPACK_IMPORTED_MODULE_1__["default"].isReactNative()) {
        return;
    }
    return new Promise(resolve => {
        _util_ScriptUtil__WEBPACK_IMPORTED_MODULE_3___default().loadScript(options.callStatsCustomScriptUrl || _constants__WEBPACK_IMPORTED_MODULE_4__.CALLSTATS_SCRIPT_URL, 
        /* async */ true, 
        /* prepend */ true, 
        /* relativeURL */ undefined, 
        /* loadCallback */ resolve);
    });
}
/**
 * Initializes the callstats lib and registers a callback to be invoked
 * when there are 'preCallTestResults'.
 *
 * @typedef PrecallTestOptions
 * @type {Object}
 * @property {string} callStatsID - Callstats credentials - the id.
 * @property {string} callStatsSecret - Callstats credentials - the secret.
 * @property {string} statisticsId - The user name to use when initializing callstats.
 * @property {string} statisticsDisplayName - The user display name.
 *
 * @param { PrecallTestOptions} options - The init options.
 * @returns {Promise<void>}
 */
function _initialize(options) {
    return new Promise((resolve, reject) => {
        const appId = options.callStatsID;
        const appSecret = options.callStatsSecret;
        const userId = options.statisticsId || options.statisticsDisplayName || _settings_Settings__WEBPACK_IMPORTED_MODULE_2__["default"].callStatsUserName;
        api.initialize(appId, appSecret, userId, (status, message) => {
            if (status === 'success') {
                api.on(PRECALL_TEST_RESULTS, (...args) => {
                    emitter.emit(PRECALL_TEST_RESULTS, ...args);
                });
                _initialized = true;
                resolve();
            }
            else {
                reject({
                    status,
                    message
                });
            }
        }, null, { disablePrecalltest: true });
    });
}
/**
 * Loads the callstats script and initializes the library.
 *
 * @param {Function} onResult - The callback to be invoked when results are received.
 * @returns {Promise<void>}
 */
function init(options) {
    return __awaiter(this, void 0, void 0, function* () {
        if (_initialized) {
            throw new Error('Precall Test already initialized');
        }
        const { callStatsID, callStatsSecret, disableThirdPartyRequests } = options;
        if (!callStatsID || !callStatsSecret || disableThirdPartyRequests) {
            throw new Error('Callstats is disabled');
        }
        yield _loadScript(options);
        // eslint-disable-next-line new-cap
        api = new window.callstats();
        return _initialize(options);
    });
}
/**
 * Executes a pre call test.
 *
 * @typedef PrecallTestResults
 * @type {Object}
 * @property {boolean} mediaConnectivity - If there is media connectivity or not.
 * @property {number} throughput  - The average throughput.
 * @property {number} fractionalLoss - The packet loss.
 * @property {number} rtt - The round trip time.
 * @property {string} provider - It is usually 'callstats'.
 *
 * @returns {Promise<{PrecallTestResults}>}
 */
function execute() {
    if (!_initialized) {
        return Promise.reject('uninitialized');
    }
    return new Promise((resolve, reject) => {
        emitter.on(PRECALL_TEST_RESULTS, (status, payload) => {
            if (status === 'success') {
                resolve(payload);
            }
            else {
                reject({
                    status,
                    payload
                });
            }
        });
        api.makePrecallTest();
    });
}
/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = ({
    init,
    execute
});
//# sourceMappingURL=PrecallTest.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/statistics/RTPStatsCollector.js":
/*!*********************************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/statistics/RTPStatsCollector.js ***!
  \*********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
var __filename = "/index.js";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (/* binding */ StatsCollector)
/* harmony export */ });
/* harmony import */ var _jitsi_logger__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @jitsi/logger */ "./node_modules/@jitsi/logger/lib/index.js");
/* harmony import */ var _jitsi_logger__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(_jitsi_logger__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../service/RTC/MediaType */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/RTC/MediaType.js");
/* harmony import */ var _service_statistics_Events__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../service/statistics/Events */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/statistics/Events.js");
/* harmony import */ var _browser__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../browser */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/browser/index.js");
/* harmony import */ var _flags_FeatureFlags__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../flags/FeatureFlags */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/flags/FeatureFlags.js");





const GlobalOnErrorHandler = __webpack_require__(/*! ../util/GlobalOnErrorHandler */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/util/GlobalOnErrorHandler.js");
const logger = (0,_jitsi_logger__WEBPACK_IMPORTED_MODULE_0__.getLogger)(__filename);
/**
 * Calculates packet lost percent using the number of lost packets and the
 * number of all packet.
 * @param lostPackets the number of lost packets
 * @param totalPackets the number of all packets.
 * @returns {number} packet loss percent
 */
function calculatePacketLoss(lostPackets, totalPackets) {
    if (!totalPackets || totalPackets <= 0
        || !lostPackets || lostPackets <= 0) {
        return 0;
    }
    return Math.round((lostPackets / totalPackets) * 100);
}
/**
 * Holds "statistics" for a single SSRC.
 * @constructor
 */
function SsrcStats() {
    this.loss = {};
    this.bitrate = {
        download: 0,
        upload: 0
    };
    this.resolution = {};
    this.framerate = 0;
    this.codec = '';
}
/**
 * Sets the "loss" object.
 * @param loss the value to set.
 */
SsrcStats.prototype.setLoss = function (loss) {
    this.loss = loss || {};
};
/**
 * Sets resolution that belong to the ssrc represented by this instance.
 * @param resolution new resolution value to be set.
 */
SsrcStats.prototype.setResolution = function (resolution) {
    this.resolution = resolution || {};
};
/**
 * Adds the "download" and "upload" fields from the "bitrate" parameter to
 * the respective fields of the "bitrate" field of this object.
 * @param bitrate an object holding the values to add.
 */
SsrcStats.prototype.addBitrate = function (bitrate) {
    this.bitrate.download += bitrate.download;
    this.bitrate.upload += bitrate.upload;
};
/**
 * Resets the bit rate for given <tt>ssrc</tt> that belong to the peer
 * represented by this instance.
 */
SsrcStats.prototype.resetBitrate = function () {
    this.bitrate.download = 0;
    this.bitrate.upload = 0;
};
/**
 * Sets the "framerate".
 * @param framerate the value to set.
 */
SsrcStats.prototype.setFramerate = function (framerate) {
    this.framerate = framerate || 0;
};
SsrcStats.prototype.setCodec = function (codec) {
    this.codec = codec || '';
};
/**
 *
 */
function ConferenceStats() {
    /**
     * The bandwidth
     * @type {{}}
     */
    this.bandwidth = {};
    /**
     * The bit rate
     * @type {{}}
     */
    this.bitrate = {};
    /**
     * The packet loss rate
     * @type {{}}
     */
    this.packetLoss = null;
    /**
     * Array with the transport information.
     * @type {Array}
     */
    this.transport = [];
}
/* eslint-disable max-params */
/**
 * <tt>StatsCollector</tt> registers for stats updates of given
 * <tt>peerconnection</tt> in given <tt>interval</tt>. On each update particular
 * stats are extracted and put in {@link SsrcStats} objects. Once the processing
 * is done <tt>audioLevelsUpdateCallback</tt> is called with <tt>this</tt>
 * instance as an event source.
 *
 * @param peerconnection WebRTC PeerConnection object.
 * @param audioLevelsInterval
 * @param statsInterval stats refresh interval given in ms.
 * @param eventEmitter
 * @constructor
 */
function StatsCollector(peerconnection, audioLevelsInterval, statsInterval, eventEmitter) {
    this.peerconnection = peerconnection;
    this.currentStatsReport = null;
    this.previousStatsReport = null;
    this.audioLevelReportHistory = {};
    this.audioLevelsIntervalId = null;
    this.eventEmitter = eventEmitter;
    this.conferenceStats = new ConferenceStats();
    // Updates stats interval
    this.audioLevelsIntervalMilis = audioLevelsInterval;
    this.speakerList = [];
    this.statsIntervalId = null;
    this.statsIntervalMilis = statsInterval;
    /**
     * Maps SSRC numbers to {@link SsrcStats}.
     * @type {Map<number,SsrcStats}
     */
    this.ssrc2stats = new Map();
}
/**
 * Set the list of the remote speakers for which audio levels are to be calculated.
 *
 * @param {Array<string>} speakerList - Endpoint ids.
 * @returns {void}
 */
StatsCollector.prototype.setSpeakerList = function (speakerList) {
    this.speakerList = speakerList;
};
/**
 * Stops stats updates.
 */
StatsCollector.prototype.stop = function () {
    if (this.audioLevelsIntervalId) {
        clearInterval(this.audioLevelsIntervalId);
        this.audioLevelsIntervalId = null;
    }
    if (this.statsIntervalId) {
        clearInterval(this.statsIntervalId);
        this.statsIntervalId = null;
    }
};
/**
 * Callback passed to <tt>getStats</tt> method.
 * @param error an error that occurred on <tt>getStats</tt> call.
 */
StatsCollector.prototype.errorCallback = function (error) {
    GlobalOnErrorHandler.callErrorHandler(error);
    logger.error('Get stats error', error);
    this.stop();
};
/**
 * Starts stats updates.
 */
StatsCollector.prototype.start = function (startAudioLevelStats) {
    if (startAudioLevelStats && _browser__WEBPACK_IMPORTED_MODULE_3__["default"].supportsReceiverStats()) {
        this.audioLevelsIntervalId = setInterval(() => {
            const audioLevels = this.peerconnection.getAudioLevels(this.speakerList);
            for (const ssrc in audioLevels) {
                if (audioLevels.hasOwnProperty(ssrc)) {
                    // Use a scaling factor of 2.5 to report the same audio levels that getStats reports.
                    const audioLevel = audioLevels[ssrc] * 2.5;
                    this.eventEmitter.emit(_service_statistics_Events__WEBPACK_IMPORTED_MODULE_2__.AUDIO_LEVEL, this.peerconnection, Number.parseInt(ssrc, 10), audioLevel, false /* isLocal */);
                }
            }
        }, this.audioLevelsIntervalMilis);
    }
    const processStats = () => {
        // Interval updates
        this.peerconnection.getStats()
            .then(report => {
            this.currentStatsReport = typeof (report === null || report === void 0 ? void 0 : report.result) === 'function'
                ? report.result()
                : report;
            try {
                this.processStatsReport();
            }
            catch (error) {
                GlobalOnErrorHandler.callErrorHandler(error);
                logger.error('Processing of RTP stats failed:', error);
            }
            this.previousStatsReport = this.currentStatsReport;
        })
            .catch(error => this.errorCallback(error));
    };
    processStats();
    this.statsIntervalId = setInterval(processStats, this.statsIntervalMilis);
};
/**
 *
 */
StatsCollector.prototype._processAndEmitReport = function () {
    var _a, _b;
    // process stats
    const totalPackets = {
        download: 0,
        upload: 0
    };
    const lostPackets = {
        download: 0,
        upload: 0
    };
    let bitrateDownload = 0;
    let bitrateUpload = 0;
    const resolutions = {};
    const framerates = {};
    const codecs = {};
    let audioBitrateDownload = 0;
    let audioBitrateUpload = 0;
    let videoBitrateDownload = 0;
    let videoBitrateUpload = 0;
    for (const [ssrc, ssrcStats] of this.ssrc2stats) {
        // process packet loss stats
        const loss = ssrcStats.loss;
        const type = loss.isDownloadStream ? 'download' : 'upload';
        totalPackets[type] += loss.packetsTotal;
        lostPackets[type] += loss.packetsLost;
        // process bitrate stats
        bitrateDownload += ssrcStats.bitrate.download;
        bitrateUpload += ssrcStats.bitrate.upload;
        ssrcStats.resetBitrate();
        // collect resolutions and framerates
        const track = this.peerconnection.getTrackBySSRC(ssrc);
        if (!track) {
            continue; // eslint-disable-line no-continue
        }
        let audioCodec;
        let videoCodec;
        if (track.isAudioTrack()) {
            audioBitrateDownload += ssrcStats.bitrate.download;
            audioBitrateUpload += ssrcStats.bitrate.upload;
            audioCodec = ssrcStats.codec;
        }
        else {
            videoBitrateDownload += ssrcStats.bitrate.download;
            videoBitrateUpload += ssrcStats.bitrate.upload;
            videoCodec = ssrcStats.codec;
        }
        const participantId = track.getParticipantId();
        if (!participantId) {
            // All tracks in ssrc-rewriting mode need not have a participant associated with it.
            if (!_flags_FeatureFlags__WEBPACK_IMPORTED_MODULE_4__["default"].isSsrcRewritingSupported()) {
                logger.error(`No participant ID returned by ${track}`);
            }
            continue; // eslint-disable-line no-continue
        }
        const userCodecs = (_a = codecs[participantId]) !== null && _a !== void 0 ? _a : {};
        userCodecs[ssrc] = {
            audio: audioCodec,
            video: videoCodec
        };
        codecs[participantId] = userCodecs;
        const { resolution } = ssrcStats;
        if (!track.isVideoTrack()
            || isNaN(resolution === null || resolution === void 0 ? void 0 : resolution.height)
            || isNaN(resolution === null || resolution === void 0 ? void 0 : resolution.width)
            || resolution.height === -1
            || resolution.width === -1) {
            continue; // eslint-disable-line no-continue
        }
        const userResolutions = resolutions[participantId] || {};
        // If simulcast (VP8) is used, there will be 3 "outbound-rtp" streams with different resolutions and 3
        // different SSRCs. Based on the requested resolution and the current cpu and available bandwidth
        // values, some of the streams might get suspended. Therefore the actual send resolution needs to be
        // calculated based on the outbound-rtp streams that are currently active for the simulcast case.
        // However for the SVC case, there will be only 1 "outbound-rtp" stream which will have the correct
        // send resolution width and height.
        if (track.isLocal() && !_browser__WEBPACK_IMPORTED_MODULE_3__["default"].supportsTrackBasedStats() && this.peerconnection.doesTrueSimulcast()) {
            const localSsrcs = this.peerconnection.getLocalVideoSSRCs(track);
            for (const localSsrc of localSsrcs) {
                const ssrcResolution = (_b = this.ssrc2stats.get(localSsrc)) === null || _b === void 0 ? void 0 : _b.resolution;
                // The code processes resolution stats only for 'outbound-rtp' streams that are currently active.
                if ((ssrcResolution === null || ssrcResolution === void 0 ? void 0 : ssrcResolution.height) && (ssrcResolution === null || ssrcResolution === void 0 ? void 0 : ssrcResolution.width)) {
                    resolution.height = Math.max(resolution.height, ssrcResolution.height);
                    resolution.width = Math.max(resolution.width, ssrcResolution.width);
                }
            }
        }
        userResolutions[ssrc] = resolution;
        resolutions[participantId] = userResolutions;
        if (ssrcStats.framerate > 0) {
            const userFramerates = framerates[participantId] || {};
            userFramerates[ssrc] = ssrcStats.framerate;
            framerates[participantId] = userFramerates;
        }
    }
    this.conferenceStats.bitrate = {
        'upload': bitrateUpload,
        'download': bitrateDownload
    };
    this.conferenceStats.bitrate.audio = {
        'upload': audioBitrateUpload,
        'download': audioBitrateDownload
    };
    this.conferenceStats.bitrate.video = {
        'upload': videoBitrateUpload,
        'download': videoBitrateDownload
    };
    this.conferenceStats.packetLoss = {
        total: calculatePacketLoss(lostPackets.download + lostPackets.upload, totalPackets.download + totalPackets.upload),
        download: calculatePacketLoss(lostPackets.download, totalPackets.download),
        upload: calculatePacketLoss(lostPackets.upload, totalPackets.upload)
    };
    const avgAudioLevels = {};
    let localAvgAudioLevels;
    Object.keys(this.audioLevelReportHistory).forEach(ssrc => {
        const { data, isLocal } = this.audioLevelReportHistory[ssrc];
        const avgAudioLevel = data.reduce((sum, currentValue) => sum + currentValue) / data.length;
        if (isLocal) {
            localAvgAudioLevels = avgAudioLevel;
        }
        else {
            const track = this.peerconnection.getTrackBySSRC(Number(ssrc));
            if (track) {
                const participantId = track.getParticipantId();
                if (participantId) {
                    avgAudioLevels[participantId] = avgAudioLevel;
                }
            }
        }
    });
    this.audioLevelReportHistory = {};
    this.eventEmitter.emit(_service_statistics_Events__WEBPACK_IMPORTED_MODULE_2__.CONNECTION_STATS, this.peerconnection, {
        'bandwidth': this.conferenceStats.bandwidth,
        'bitrate': this.conferenceStats.bitrate,
        'packetLoss': this.conferenceStats.packetLoss,
        'resolution': resolutions,
        'framerate': framerates,
        'codec': codecs,
        'transport': this.conferenceStats.transport,
        localAvgAudioLevels,
        avgAudioLevels
    });
    this.conferenceStats.transport = [];
};
/**
 * Converts the value to a non-negative number.
 * If the value is either invalid or negative then 0 will be returned.
 * @param {*} v
 * @return {number}
 * @private
 */
StatsCollector.prototype.getNonNegativeValue = function (v) {
    let value = v;
    if (typeof value !== 'number') {
        value = Number(value);
    }
    if (isNaN(value)) {
        return 0;
    }
    return Math.max(0, value);
};
/**
 * Calculates bitrate between before and now using a supplied field name and its
 * value in the stats.
 * @param {RTCInboundRtpStreamStats|RTCSentRtpStreamStats} now the current stats
 * @param {RTCInboundRtpStreamStats|RTCSentRtpStreamStats} before the
 * previous stats.
 * @param fieldName the field to use for calculations.
 * @return {number} the calculated bitrate between now and before.
 * @private
 */
StatsCollector.prototype._calculateBitrate = function (now, before, fieldName) {
    const bytesNow = this.getNonNegativeValue(now[fieldName]);
    const bytesBefore = this.getNonNegativeValue(before[fieldName]);
    const bytesProcessed = Math.max(0, bytesNow - bytesBefore);
    const timeMs = now.timestamp - before.timestamp;
    let bitrateKbps = 0;
    if (timeMs > 0) {
        // TODO is there any reason to round here?
        bitrateKbps = Math.round((bytesProcessed * 8) / timeMs);
    }
    return bitrateKbps;
};
/**
 * Calculates the frames per second rate between before and now using a supplied field name and its value in stats.
 * @param {RTCOutboundRtpStreamStats|RTCSentRtpStreamStats} now the current stats
 * @param {RTCOutboundRtpStreamStats|RTCSentRtpStreamStats} before the previous stats
 * @param {string} fieldName the field to use for calculations.
 * @returns {number} the calculated frame rate between now and before.
 */
StatsCollector.prototype._calculateFps = function (now, before, fieldName) {
    const timeMs = now.timestamp - before.timestamp;
    let frameRate = 0;
    if (timeMs > 0 && now[fieldName]) {
        const numberOfFramesSinceBefore = now[fieldName] - before[fieldName];
        frameRate = (numberOfFramesSinceBefore / timeMs) * 1000;
    }
    return frameRate;
};
/**
 * Stats processing for spec-compliant RTCPeerConnection#getStats.
 */
StatsCollector.prototype.processStatsReport = function () {
    const byteSentStats = {};
    this.currentStatsReport.forEach(now => {
        var _a;
        const before = this.previousStatsReport ? this.previousStatsReport.get(now.id) : null;
        // RTCIceCandidatePairStats - https://w3c.github.io/webrtc-stats/#candidatepair-dict*
        if (now.type === 'candidate-pair' && now.nominated && now.state === 'succeeded') {
            const availableIncomingBitrate = now.availableIncomingBitrate;
            const availableOutgoingBitrate = now.availableOutgoingBitrate;
            if (availableIncomingBitrate || availableOutgoingBitrate) {
                this.conferenceStats.bandwidth = {
                    'download': Math.round(availableIncomingBitrate / 1000),
                    'upload': Math.round(availableOutgoingBitrate / 1000)
                };
            }
            const remoteUsedCandidate = this.currentStatsReport.get(now.remoteCandidateId);
            const localUsedCandidate = this.currentStatsReport.get(now.localCandidateId);
            // RTCIceCandidateStats
            // https://w3c.github.io/webrtc-stats/#icecandidate-dict*
            if (remoteUsedCandidate && localUsedCandidate) {
                const remoteIpAddress = _browser__WEBPACK_IMPORTED_MODULE_3__["default"].isChromiumBased()
                    ? remoteUsedCandidate.ip
                    : remoteUsedCandidate.address;
                const remotePort = remoteUsedCandidate.port;
                const ip = `${remoteIpAddress}:${remotePort}`;
                const localIpAddress = _browser__WEBPACK_IMPORTED_MODULE_3__["default"].isChromiumBased()
                    ? localUsedCandidate.ip
                    : localUsedCandidate.address;
                const localPort = localUsedCandidate.port;
                const localip = `${localIpAddress}:${localPort}`;
                const type = remoteUsedCandidate.protocol;
                // Save the address unless it has been saved already.
                const conferenceStatsTransport = this.conferenceStats.transport;
                if (!conferenceStatsTransport.some(t => t.ip === ip
                    && t.type === type
                    && t.localip === localip)) {
                    conferenceStatsTransport.push({
                        ip,
                        type,
                        localip,
                        p2p: this.peerconnection.isP2P,
                        localCandidateType: localUsedCandidate.candidateType,
                        remoteCandidateType: remoteUsedCandidate.candidateType,
                        networkType: localUsedCandidate.networkType,
                        rtt: now.currentRoundTripTime * 1000
                    });
                }
            }
            // RTCReceivedRtpStreamStats
            // https://w3c.github.io/webrtc-stats/#receivedrtpstats-dict*
            // RTCSentRtpStreamStats
            // https://w3c.github.io/webrtc-stats/#sentrtpstats-dict*
        }
        else if (now.type === 'inbound-rtp' || now.type === 'outbound-rtp') {
            const ssrc = this.getNonNegativeValue(now.ssrc);
            if (!ssrc) {
                return;
            }
            let ssrcStats = this.ssrc2stats.get(ssrc);
            if (!ssrcStats) {
                ssrcStats = new SsrcStats();
                this.ssrc2stats.set(ssrc, ssrcStats);
            }
            let isDownloadStream = true;
            let key = 'packetsReceived';
            if (now.type === 'outbound-rtp') {
                isDownloadStream = false;
                key = 'packetsSent';
            }
            let packetsNow = now[key];
            if (!packetsNow || packetsNow < 0) {
                packetsNow = 0;
            }
            if (before) {
                const packetsBefore = this.getNonNegativeValue(before[key]);
                const packetsDiff = Math.max(0, packetsNow - packetsBefore);
                const packetsLostNow = this.getNonNegativeValue(now.packetsLost);
                const packetsLostBefore = this.getNonNegativeValue(before.packetsLost);
                const packetsLostDiff = Math.max(0, packetsLostNow - packetsLostBefore);
                ssrcStats.setLoss({
                    packetsTotal: packetsDiff + packetsLostDiff,
                    packetsLost: packetsLostDiff,
                    isDownloadStream
                });
            }
            let resolution;
            // Process the stats for 'inbound-rtp' streams always and 'outbound-rtp' only if the browser is
            // Chromium based and version 112 and later since 'track' based stats are no longer available there
            // for calculating send resolution and frame rate.
            if (typeof now.frameHeight !== 'undefined' && typeof now.frameWidth !== 'undefined') {
                // Assume the stream is active if the field is missing in the stats(Firefox)
                const isStreamActive = (_a = now.active) !== null && _a !== void 0 ? _a : true;
                if (now.type === 'inbound-rtp' || (!_browser__WEBPACK_IMPORTED_MODULE_3__["default"].supportsTrackBasedStats() && isStreamActive)) {
                    resolution = {
                        height: now.frameHeight,
                        width: now.frameWidth
                    };
                }
            }
            ssrcStats.setResolution(resolution);
            let frameRate = now.framesPerSecond;
            if (!frameRate && before) {
                frameRate = this._calculateFps(now, before, 'framesSent');
            }
            ssrcStats.setFramerate(Math.round(frameRate || 0));
            if (now.type === 'inbound-rtp' && before) {
                ssrcStats.addBitrate({
                    'download': this._calculateBitrate(now, before, 'bytesReceived'),
                    'upload': 0
                });
            }
            else if (before) {
                byteSentStats[ssrc] = this.getNonNegativeValue(now.bytesSent);
                ssrcStats.addBitrate({
                    'download': 0,
                    'upload': this._calculateBitrate(now, before, 'bytesSent')
                });
            }
            const codec = this.currentStatsReport.get(now.codecId);
            if (codec) {
                /**
                 * The mime type has the following form: video/VP8 or audio/ISAC,
                 * so we what to keep just the type after the '/', audio and video
                 * keys will be added on the processing side.
                 */
                const codecShortType = codec.mimeType.split('/')[1];
                codecShortType && ssrcStats.setCodec(codecShortType);
            }
            // Continue to use the 'track' based stats for Firefox and Safari and older versions of Chromium.
        }
        else if (_browser__WEBPACK_IMPORTED_MODULE_3__["default"].supportsTrackBasedStats()
            && now.type === 'track'
            && now.kind === _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_1__.MediaType.VIDEO
            && !now.remoteSource) {
            const resolution = {
                height: now.frameHeight,
                width: now.frameWidth
            };
            const localVideoTracks = this.peerconnection.getLocalTracks(_service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_1__.MediaType.VIDEO);
            if (!(localVideoTracks === null || localVideoTracks === void 0 ? void 0 : localVideoTracks.length)) {
                return;
            }
            const ssrc = this.peerconnection.getSsrcByTrackId(now.trackIdentifier);
            if (!ssrc) {
                return;
            }
            let ssrcStats = this.ssrc2stats.get(ssrc);
            if (!ssrcStats) {
                ssrcStats = new SsrcStats();
                this.ssrc2stats.set(ssrc, ssrcStats);
            }
            if (resolution.height && resolution.width) {
                ssrcStats.setResolution(resolution);
            }
            // Calculate the frame rate. 'framesSent' is the total aggregate value for all the simulcast streams.
            // Therefore, it needs to be divided by the total number of active simulcast streams.
            let frameRate = now.framesPerSecond;
            if (!frameRate && before) {
                frameRate = this._calculateFps(now, before, 'framesSent');
            }
            ssrcStats.setFramerate(frameRate);
        }
    });
    if (Object.keys(byteSentStats).length) {
        this.eventEmitter.emit(_service_statistics_Events__WEBPACK_IMPORTED_MODULE_2__.BYTE_SENT_STATS, this.peerconnection, byteSentStats);
    }
    this._processAndEmitReport();
};
//# sourceMappingURL=RTPStatsCollector.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/statistics/SpeakerStats.js":
/*!****************************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/statistics/SpeakerStats.js ***!
  \****************************************************************************************/
/***/ ((module) => {

/**
 * A model for keeping track of each user's total
 * time as a dominant speaker. The model also
 * keeps track of the user's last known name
 * in case the user has left the meeting,
 * which is also tracked.
 */
class SpeakerStats {
    /**
     * Initializes a new SpeakerStats instance.
     *
     * @constructor
     * @param {string} userId - The id of the user being tracked.
     * @param {string} displayName - The name of the user being tracked.
     * @param {boolean} isLocalStats - True if the stats model tracks
     * the local user.
     * @returns {void}
     */
    constructor(userId, displayName, isLocalStats) {
        this._userId = userId;
        this.setDisplayName(displayName);
        this._isLocalStats = isLocalStats || false;
        this.setDominantSpeaker(false);
        this.totalDominantSpeakerTime = 0;
        this._dominantSpeakerStart = 0;
        this._isDominantSpeaker = false;
        this._isSilent = false;
        this._hasLeft = false;
        this._faceLandmarks = [];
    }
    /**
     * Get the user id being tracked.
     *
     * @returns {string} The user id.
     */
    getUserId() {
        return this._userId;
    }
    /**
     * Get the name of the user being tracked.
     *
     * @returns {string} The user name.
     */
    getDisplayName() {
        return this.displayName;
    }
    /**
     * Updates the last known name of the user being tracked.
     *
     * @param {string} - The user name.
     * @returns {void}
     */
    setDisplayName(newName) {
        this.displayName = newName;
    }
    /**
     * Returns true if the stats are tracking the local user.
     *
     * @returns {boolean}
     */
    isLocalStats() {
        return this._isLocalStats;
    }
    /**
     * Returns true if the tracked user is currently a dominant speaker.
     *
     * @returns {boolean}
     */
    isDominantSpeaker() {
        return this._isDominantSpeaker;
    }
    /**
     * Returns true if the tracked user is currently a dominant speaker.
     *
     * @param {boolean} isNowDominantSpeaker - If true, the user will be accumulating time
     * as dominant speaker. If false, the user will not accumulate time
     * and will record any time accumulated since starting as dominant speaker.
     * @param {boolean} silence - Indecates whether the dominant speaker is silent or not.
     * @returns {void}
     */
    setDominantSpeaker(isNowDominantSpeaker, silence) {
        if (!this.isDominantSpeaker() && isNowDominantSpeaker && !silence) {
            this._dominantSpeakerStart = Date.now();
        }
        else if (this.isDominantSpeaker()) {
            if (!isNowDominantSpeaker) {
                if (!this._isSilent) {
                    const now = Date.now();
                    const timeElapsed = now - this._dominantSpeakerStart;
                    this.totalDominantSpeakerTime += timeElapsed;
                    this._dominantSpeakerStart = 0;
                }
            }
            else if (this._isSilent && !silence) {
                this._dominantSpeakerStart = Date.now();
            }
            else if (!this._isSilent && silence) {
                const now = Date.now();
                const timeElapsed = now - this._dominantSpeakerStart;
                this.totalDominantSpeakerTime += timeElapsed;
                this._dominantSpeakerStart = 0;
            }
        }
        this._isDominantSpeaker = isNowDominantSpeaker;
        this._isSilent = silence;
    }
    /**
     * Get how long the tracked user has been dominant speaker.
     *
     * @returns {number} - The speaker time in milliseconds.
     */
    getTotalDominantSpeakerTime() {
        let total = this.totalDominantSpeakerTime;
        if (this.isDominantSpeaker() && !this._isSilent) {
            total += Date.now() - this._dominantSpeakerStart;
        }
        return total;
    }
    /**
     * Get whether or not the user is still in the meeting.
     *
     * @returns {boolean} True if the user is no longer in the meeting.
     */
    hasLeft() {
        return this._hasLeft;
    }
    /**
     * Set the user as having left the meeting.
     *
     * @returns {void}
     */
    markAsHasLeft() {
        this._hasLeft = true;
        this.setDominantSpeaker(false);
    }
    /**
     * Gets the face landmarks of the user.
     *
     * @returns {Object}
     */
    getFaceLandmarks() {
        return this._faceLandmarks;
    }
    /**
     * Sets the face landmarks of the user.
     *
     * @param {Object} faceLandmarks - object with face expressions.
     * @returns {void}
     */
    setFaceLandmarks(faceLandmarks) {
        this._faceLandmarks = faceLandmarks;
    }
    /**
     * Adds new face landmarks to speaker stats.
     *
     * @param  {string} faceExpression
     * @param {number} duration
     */
    addFaceLandmarks(faceLandmarks) {
        this._faceLandmarks.push(faceLandmarks);
    }
}
module.exports = SpeakerStats;
//# sourceMappingURL=SpeakerStats.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/statistics/SpeakerStatsCollector.js":
/*!*************************************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/statistics/SpeakerStatsCollector.js ***!
  \*************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (/* binding */ SpeakerStatsCollector)
/* harmony export */ });
/* harmony import */ var _JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../JitsiConferenceEvents */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/JitsiConferenceEvents.js");
/* harmony import */ var _service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../service/xmpp/XMPPEvents */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/xmpp/XMPPEvents.js");
/* harmony import */ var _SpeakerStats__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./SpeakerStats */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/statistics/SpeakerStats.js");
/* harmony import */ var _SpeakerStats__WEBPACK_IMPORTED_MODULE_2___default = /*#__PURE__*/__webpack_require__.n(_SpeakerStats__WEBPACK_IMPORTED_MODULE_2__);



/**
 * The value to use for the "type" field for messages sent
 * over the data channel that contain a face landmark.
 */
const FACE_LANDMARK_MESSAGE_TYPE = 'face-landmarks';
/**
 * A collection for tracking speaker stats. Attaches listeners
 * to the conference to automatically update on tracked events.
 */
class SpeakerStatsCollector {
    /**
     * Initializes a new SpeakerStatsCollector instance.
     *
     * @constructor
     * @param {JitsiConference} conference - The conference to track.
     * @returns {void}
     */
    constructor(conference) {
        this.stats = {
            users: {
            // userId: SpeakerStats
            },
            dominantSpeakerId: null
        };
        const userId = conference.myUserId();
        this.stats.users[userId] = new (_SpeakerStats__WEBPACK_IMPORTED_MODULE_2___default())(userId, null, true);
        this.conference = conference;
        conference.addEventListener(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_0__.DOMINANT_SPEAKER_CHANGED, this._onDominantSpeaker.bind(this));
        conference.addEventListener(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_0__.USER_JOINED, this._onUserJoin.bind(this));
        conference.addEventListener(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_0__.USER_LEFT, this._onUserLeave.bind(this));
        conference.addEventListener(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_0__.DISPLAY_NAME_CHANGED, this._onDisplayNameChange.bind(this));
        conference.on(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_0__.ENDPOINT_MESSAGE_RECEIVED, (participant, { type, faceLandmarks }) => {
            if (type === FACE_LANDMARK_MESSAGE_TYPE) {
                this._onFaceLandmarkAdd(participant.getId(), faceLandmarks);
            }
        });
        if (conference.xmpp) {
            conference.xmpp.addListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_1__.XMPPEvents.SPEAKER_STATS_RECEIVED, this._updateStats.bind(this));
        }
    }
    /**
     * Reacts to dominant speaker change events by changing its speaker stats
     * models to reflect the current dominant speaker.
     *
     * @param {string} dominantSpeakerId - The user id of the new dominant speaker.
     * @param {Array[string]} previous - The array with previous speakers.
     * @param {boolean} silence - Indecates whether the dominant speaker is silent or not.
     * @returns {void}
     * @private
     */
    _onDominantSpeaker(dominantSpeakerId, previous, silence) {
        const oldDominantSpeaker = this.stats.users[this.stats.dominantSpeakerId];
        const newDominantSpeaker = this.stats.users[dominantSpeakerId];
        oldDominantSpeaker && oldDominantSpeaker.setDominantSpeaker(false);
        newDominantSpeaker && newDominantSpeaker.setDominantSpeaker(true, silence);
        this.stats.dominantSpeakerId = dominantSpeakerId;
    }
    /**
     * Reacts to user join events by creating a new SpeakerStats model.
     *
     * @param {string} userId - The user id of the new user.
     * @param {JitsiParticipant} - The JitsiParticipant model for the new user.
     * @returns {void}
     * @private
     */
    _onUserJoin(userId, participant) {
        if (participant.isHidden()) {
            return;
        }
        if (!this.stats.users[userId]) {
            this.stats.users[userId] = new (_SpeakerStats__WEBPACK_IMPORTED_MODULE_2___default())(userId, participant.getDisplayName());
        }
    }
    /**
     * Reacts to user leave events by updating the associated user's
     * SpeakerStats model.
     *
     * @param {string} userId - The user id of the user that left.
     * @returns {void}
     * @private
     */
    _onUserLeave(userId) {
        const savedUser = this.stats.users[userId];
        if (savedUser) {
            savedUser.markAsHasLeft();
        }
    }
    /**
     * Reacts to user name change events by updating the last known name
     * tracked in the associated SpeakerStats model.
     *
     * @param {string} userId - The user id of the user that left.
     * @returns {void}
     * @private
     */
    _onDisplayNameChange(userId, newName) {
        const savedUser = this.stats.users[userId];
        if (savedUser) {
            savedUser.setDisplayName(newName);
        }
    }
    /**
     * Processes a new face landmark object of a remote user.
     *
     * @param {string} userId - The user id of the user that left.
     * @param {Object} data - The face landmark object.
     * @returns {void}
     * @private
     */
    _onFaceLandmarkAdd(userId, data) {
        const savedUser = this.stats.users[userId];
        if (savedUser && data) {
            savedUser.addFaceLandmarks(data);
        }
    }
    /**
     * Return a copy of the tracked SpeakerStats models.
     *
     * @returns {Object} The keys are the user ids and the values are the
     * associated user's SpeakerStats model.
     */
    getStats() {
        return this.stats.users;
    }
    /**
     * Updates of the current stats is requested, passing the new values.
     *
     * @param {Object} newStats - The new values used to update current one.
     * @private
     */
    _updateStats(newStats) {
        for (const userId in newStats) { // eslint-disable-line guard-for-in
            let speakerStatsToUpdate;
            const newParticipant = this.conference.getParticipantById(userId);
            // we want to ignore hidden participants
            if (!newParticipant || !newParticipant.isHidden()) {
                if (this.stats.users[userId]) {
                    speakerStatsToUpdate = this.stats.users[userId];
                    if (!speakerStatsToUpdate.getDisplayName()) {
                        speakerStatsToUpdate
                            .setDisplayName(newStats[userId].displayName);
                    }
                }
                else {
                    speakerStatsToUpdate = new (_SpeakerStats__WEBPACK_IMPORTED_MODULE_2___default())(userId, newStats[userId].displayName);
                    this.stats.users[userId] = speakerStatsToUpdate;
                    speakerStatsToUpdate.markAsHasLeft();
                }
                speakerStatsToUpdate.totalDominantSpeakerTime
                    = newStats[userId].totalDominantSpeakerTime;
                if (Array.isArray(newStats[userId].faceLandmarks)) {
                    speakerStatsToUpdate.setFaceLandmarks(newStats[userId].faceLandmarks);
                }
            }
        }
    }
}
//# sourceMappingURL=SpeakerStatsCollector.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/statistics/constants.js":
/*!*************************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/statistics/constants.js ***!
  \*************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   CALLSTATS_SCRIPT_URL: () => (/* binding */ CALLSTATS_SCRIPT_URL),
/* harmony export */   SPEAKERS_AUDIO_LEVELS: () => (/* binding */ SPEAKERS_AUDIO_LEVELS)
/* harmony export */ });
const CALLSTATS_SCRIPT_URL = 'https://api.callstats.io/static/callstats-ws.min.js';
/**
 * The number of remote speakers for which the audio levels will be calculated using
 * RTCRtpReceiver#getSynchronizationSources. Limit the number of endpoints to save cpu on the client as this API call
 * is known to take longer to execute when there are many audio receivers.
 */
const SPEAKERS_AUDIO_LEVELS = 5;
//# sourceMappingURL=constants.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/statistics/statistics.js":
/*!**************************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/statistics/statistics.js ***!
  \**************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
var __filename = "/index.js";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (/* binding */ Statistics)
/* harmony export */ });
/* harmony import */ var events__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! events */ "./node_modules/events/events.js");
/* harmony import */ var events__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(events__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var _JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../JitsiConferenceEvents */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/JitsiConferenceEvents.js");
/* harmony import */ var _JitsiTrackError__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../JitsiTrackError */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/JitsiTrackError.js");
/* harmony import */ var _JitsiTrackEvents__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../JitsiTrackEvents */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/JitsiTrackEvents.js");
/* harmony import */ var _service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../../service/statistics/AnalyticsEvents */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/statistics/AnalyticsEvents.js");
/* harmony import */ var _service_statistics_Events__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../../service/statistics/Events */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/statistics/Events.js");
/* harmony import */ var _browser__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../browser */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/browser/index.js");
/* harmony import */ var _util_ScriptUtil__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../util/ScriptUtil */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/util/ScriptUtil.js");
/* harmony import */ var _util_ScriptUtil__WEBPACK_IMPORTED_MODULE_7___default = /*#__PURE__*/__webpack_require__.n(_util_ScriptUtil__WEBPACK_IMPORTED_MODULE_7__);
/* harmony import */ var _watchRTC_WatchRTC__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ../watchRTC/WatchRTC */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/watchRTC/WatchRTC.js");
/* harmony import */ var _AnalyticsAdapter__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ./AnalyticsAdapter */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/statistics/AnalyticsAdapter.js");
/* harmony import */ var _CallStats__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ./CallStats */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/statistics/CallStats.js");
/* harmony import */ var _LocalStatsCollector__WEBPACK_IMPORTED_MODULE_11__ = __webpack_require__(/*! ./LocalStatsCollector */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/statistics/LocalStatsCollector.js");
/* harmony import */ var _PerformanceObserverStats__WEBPACK_IMPORTED_MODULE_12__ = __webpack_require__(/*! ./PerformanceObserverStats */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/statistics/PerformanceObserverStats.js");
/* harmony import */ var _RTPStatsCollector__WEBPACK_IMPORTED_MODULE_13__ = __webpack_require__(/*! ./RTPStatsCollector */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/statistics/RTPStatsCollector.js");
/* harmony import */ var _constants__WEBPACK_IMPORTED_MODULE_14__ = __webpack_require__(/*! ./constants */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/statistics/constants.js");
var __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {
    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};















const logger = (__webpack_require__(/*! @jitsi/logger */ "./node_modules/@jitsi/logger/lib/index.js").getLogger)(__filename);
/**
 * Stores all active {@link Statistics} instances.
 * @type {Set<Statistics>}
 */
let _instances;
/**
 * True if callstats API is loaded
 */
let isCallstatsLoaded = false;
/**
 * Since callstats.io is a third party, we cannot guarantee the quality of their
 * service. More specifically, their server may take noticeably long time to
 * respond. Consequently, it is in our best interest (in the sense that the
 * intergration of callstats.io is pretty important to us but not enough to
 * allow it to prevent people from joining a conference) to (1) start
 * downloading their API as soon as possible and (2) do the downloading
 * asynchronously.
 *
 * @param {StatisticsOptions} options - Options to use for downloading and
 * initializing callstats backend.
 */
function loadCallStatsAPI(options) {
    if (!isCallstatsLoaded) {
        _util_ScriptUtil__WEBPACK_IMPORTED_MODULE_7___default().loadScript(options.customScriptUrl || _constants__WEBPACK_IMPORTED_MODULE_14__.CALLSTATS_SCRIPT_URL, 
        /* async */ true, 
        /* prepend */ true, 
        /* relativeURL */ undefined, 
        /* loadCallback */ () => _initCallStatsBackend(options));
        isCallstatsLoaded = true;
    }
}
/**
 * Initializes Callstats backend.
 *
 * @param {StatisticsOptions} options - The options to use for initializing
 * callstats backend.
 * @private
 */
function _initCallStatsBackend(options) {
    if (_CallStats__WEBPACK_IMPORTED_MODULE_10__["default"].isBackendInitialized()) {
        return;
    }
    if (!_CallStats__WEBPACK_IMPORTED_MODULE_10__["default"].initBackend({
        callStatsID: options.callStatsID,
        callStatsSecret: options.callStatsSecret,
        userName: options.userName,
        aliasName: options.aliasName,
        applicationName: options.applicationName,
        confID: options.confID,
        siteID: options.siteID,
        configParams: options.configParams
    })) {
        logger.error('CallStats Backend initialization failed bad');
    }
}
/**
 * callstats strips any additional fields from Error except for "name", "stack",
 * "message" and "constraintName". So we need to bundle additional information
 * from JitsiTrackError into error passed to callstats to preserve valuable
 * information about error.
 * @param {JitsiTrackError} error
 */
function formatJitsiTrackErrorForCallStats(error) {
    const err = new Error();
    // Just copy original stack from error
    err.stack = error.stack;
    // Combine name from error's name plus (possibly) name of original GUM error
    err.name = (error.name || 'Unknown error') + (error.gum && error.gum.error
        && error.gum.error.name ? ` - ${error.gum.error.name}` : '');
    // Put all constraints into this field. For constraint failed errors we will
    // still know which exactly constraint failed as it will be a part of
    // message.
    err.constraintName = error.gum && error.gum.constraints
        ? JSON.stringify(error.gum.constraints) : '';
    // Just copy error's message.
    err.message = error.message;
    return err;
}
/**
 * Init statistic options
 * @param options
 */
Statistics.init = function (options) {
    Statistics.audioLevelsEnabled = !options.disableAudioLevels;
    if (typeof options.pcStatsInterval === 'number') {
        Statistics.pcStatsInterval = options.pcStatsInterval;
    }
    if (typeof options.audioLevelsInterval === 'number') {
        Statistics.audioLevelsInterval = options.audioLevelsInterval;
    }
    if (typeof options.longTasksStatsInterval === 'number') {
        Statistics.longTasksStatsInterval = options.longTasksStatsInterval;
    }
    Statistics.disableThirdPartyRequests = options.disableThirdPartyRequests;
    // WatchRTC is not required to work for react native
    if (!_browser__WEBPACK_IMPORTED_MODULE_6__["default"].isReactNative()) {
        _watchRTC_WatchRTC__WEBPACK_IMPORTED_MODULE_8__["default"].init(options);
    }
};
/**
 * The options to configure Statistics.
 * @typedef {Object} StatisticsOptions
 * @property {string} applicationName - The application name to pass to
 * callstats.
 * @property {string} aliasName - The alias name to use when initializing callstats.
 * @property {string} userName - The user name to use when initializing callstats.
 * @property {string} confID - The callstats conference ID to use.
 * @property {string} callStatsID - Callstats credentials - the id.
 * @property {string} callStatsSecret - Callstats credentials - the secret.
 * @property {string} customScriptUrl - A custom lib url to use when downloading
 * callstats library.
 * @property {string} roomName - The room name we are currently in.
 * @property {string} configParams - The set of parameters
 * to enable/disable certain features in the library. See CallStats docs for more info.
 */
/**
 *
 * @param xmpp
 * @param {StatisticsOptions} options - The options to use creating the
 * Statistics.
 */
function Statistics(xmpp, options) {
    /**
     * {@link RTPStats} mapped by {@link TraceablePeerConnection.id} which
     * collect RTP statistics for each peerconnection.
     * @type {Map<string, RTPStats}
     */
    this.rtpStatsMap = new Map();
    this.eventEmitter = new (events__WEBPACK_IMPORTED_MODULE_0___default())();
    this.xmpp = xmpp;
    this.options = options || {};
    this.callStatsIntegrationEnabled
        = this.options.callStatsID && this.options.callStatsSecret
            // Even though AppID and AppSecret may be specified, the integration
            // of callstats.io may be disabled because of globally-disallowed
            // requests to any third parties.
            && (Statistics.disableThirdPartyRequests !== true);
    if (this.callStatsIntegrationEnabled) {
        this.callStatsApplicationLogsDisabled
            = this.options.callStatsApplicationLogsDisabled;
        if (_browser__WEBPACK_IMPORTED_MODULE_6__["default"].isReactNative()) {
            _initCallStatsBackend(this.options);
        }
        else {
            loadCallStatsAPI(this.options);
        }
        if (!this.options.confID) {
            logger.warn('"confID" is not defined');
        }
    }
    /**
     * Stores {@link CallStats} instances for each
     * {@link TraceablePeerConnection} (one {@link CallStats} instance serves
     * one TPC). The instances are mapped by {@link TraceablePeerConnection.id}.
     * @type {Map<number, CallStats>}
     */
    this.callsStatsInstances = new Map();
    Statistics.instances.add(this);
    // WatchRTC is not required to work for react native
    if (!_browser__WEBPACK_IMPORTED_MODULE_6__["default"].isReactNative()) {
        _watchRTC_WatchRTC__WEBPACK_IMPORTED_MODULE_8__["default"].start(this.options.roomName, this.options.userName);
    }
}
Statistics.audioLevelsEnabled = false;
Statistics.audioLevelsInterval = 200;
Statistics.pcStatsInterval = 10000;
Statistics.disableThirdPartyRequests = false;
Statistics.analytics = _AnalyticsAdapter__WEBPACK_IMPORTED_MODULE_9__["default"];
Object.defineProperty(Statistics, 'instances', {
    /**
     * Returns the Set holding all active {@link Statistics} instances. Lazily
     * initializes the Set to allow any Set polyfills to be applied.
     * @type {Set<Statistics>}
     */
    get() {
        if (!_instances) {
            _instances = new Set();
        }
        return _instances;
    }
});
/**
 * Starts collecting RTP stats for given peerconnection.
 * @param {TraceablePeerConnection} peerconnection
 */
Statistics.prototype.startRemoteStats = function (peerconnection) {
    this.stopRemoteStats(peerconnection);
    try {
        const rtpStats = new _RTPStatsCollector__WEBPACK_IMPORTED_MODULE_13__["default"](peerconnection, Statistics.audioLevelsInterval, Statistics.pcStatsInterval, this.eventEmitter);
        rtpStats.start(Statistics.audioLevelsEnabled);
        this.rtpStatsMap.set(peerconnection.id, rtpStats);
    }
    catch (e) {
        logger.error(`Failed to start collecting remote statistics: ${e}`);
    }
};
Statistics.localStats = [];
Statistics.startLocalStats = function (track, callback) {
    if (_browser__WEBPACK_IMPORTED_MODULE_6__["default"].isIosBrowser()) {
        // On iOS browsers audio is lost if the audio input device is in use by another app
        // https://bugs.webkit.org/show_bug.cgi?id=233473
        // The culprit was using the AudioContext, so now we close the AudioContext during
        // the track being muted, and re-instantiate it afterwards.
        track.addEventListener(_JitsiTrackEvents__WEBPACK_IMPORTED_MODULE_3__.JitsiTrackEvents.NO_DATA_FROM_SOURCE, 
        /**
         * Closes AudioContext on no audio data, and enables it on data received again.
         *
         * @param {boolean} value - Whether we receive audio data or not.
         */
        (value) => __awaiter(this, void 0, void 0, function* () {
            if (value) {
                for (const localStat of Statistics.localStats) {
                    localStat.stop();
                }
                yield _LocalStatsCollector__WEBPACK_IMPORTED_MODULE_11__["default"].disconnectAudioContext();
            }
            else {
                _LocalStatsCollector__WEBPACK_IMPORTED_MODULE_11__["default"].connectAudioContext();
                for (const localStat of Statistics.localStats) {
                    localStat.start();
                }
            }
        }));
    }
    if (!Statistics.audioLevelsEnabled) {
        return;
    }
    track.addEventListener(_JitsiTrackEvents__WEBPACK_IMPORTED_MODULE_3__.JitsiTrackEvents.LOCAL_TRACK_STOPPED, () => {
        Statistics.stopLocalStats(track);
    });
    const stream = track.getOriginalStream();
    const localStats = new _LocalStatsCollector__WEBPACK_IMPORTED_MODULE_11__["default"](stream, Statistics.audioLevelsInterval, callback);
    this.localStats.push(localStats);
    localStats.start();
};
Statistics.prototype.addAudioLevelListener = function (listener) {
    if (!Statistics.audioLevelsEnabled) {
        return;
    }
    this.eventEmitter.on(_service_statistics_Events__WEBPACK_IMPORTED_MODULE_5__.AUDIO_LEVEL, listener);
};
Statistics.prototype.removeAudioLevelListener = function (listener) {
    if (!Statistics.audioLevelsEnabled) {
        return;
    }
    this.eventEmitter.removeListener(_service_statistics_Events__WEBPACK_IMPORTED_MODULE_5__.AUDIO_LEVEL, listener);
};
Statistics.prototype.addBeforeDisposedListener = function (listener) {
    this.eventEmitter.on(_service_statistics_Events__WEBPACK_IMPORTED_MODULE_5__.BEFORE_DISPOSED, listener);
};
Statistics.prototype.removeBeforeDisposedListener = function (listener) {
    this.eventEmitter.removeListener(_service_statistics_Events__WEBPACK_IMPORTED_MODULE_5__.BEFORE_DISPOSED, listener);
};
Statistics.prototype.addConnectionStatsListener = function (listener) {
    this.eventEmitter.on(_service_statistics_Events__WEBPACK_IMPORTED_MODULE_5__.CONNECTION_STATS, listener);
};
Statistics.prototype.removeConnectionStatsListener = function (listener) {
    this.eventEmitter.removeListener(_service_statistics_Events__WEBPACK_IMPORTED_MODULE_5__.CONNECTION_STATS, listener);
};
Statistics.prototype.addByteSentStatsListener = function (listener) {
    this.eventEmitter.on(_service_statistics_Events__WEBPACK_IMPORTED_MODULE_5__.BYTE_SENT_STATS, listener);
};
Statistics.prototype.removeByteSentStatsListener = function (listener) {
    this.eventEmitter.removeListener(_service_statistics_Events__WEBPACK_IMPORTED_MODULE_5__.BYTE_SENT_STATS, listener);
};
/**
 * Add a listener that would be notified on a LONG_TASKS_STATS event.
 *
 * @param {Function} listener a function that would be called when notified.
 * @returns {void}
 */
Statistics.prototype.addLongTasksStatsListener = function (listener) {
    this.eventEmitter.on(_service_statistics_Events__WEBPACK_IMPORTED_MODULE_5__.LONG_TASKS_STATS, listener);
};
/**
 * Creates an instance of {@link PerformanceObserverStats} and starts the
 * observer that records the stats periodically.
 *
 * @returns {void}
 */
Statistics.prototype.attachLongTasksStats = function (conference) {
    if (!_browser__WEBPACK_IMPORTED_MODULE_6__["default"].supportsPerformanceObserver()) {
        logger.warn('Performance observer for long tasks not supported by browser!');
        return;
    }
    this.performanceObserverStats = new _PerformanceObserverStats__WEBPACK_IMPORTED_MODULE_12__.PerformanceObserverStats(this.eventEmitter, Statistics.longTasksStatsInterval);
    conference.on(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_1__.CONFERENCE_JOINED, () => this.performanceObserverStats.startObserver());
    conference.on(_JitsiConferenceEvents__WEBPACK_IMPORTED_MODULE_1__.CONFERENCE_LEFT, () => this.performanceObserverStats.stopObserver());
};
/**
 * Obtains the current value of the LongTasks event statistics.
 *
 * @returns {Object|null} stats object if the observer has been
 * created, null otherwise.
 */
Statistics.prototype.getLongTasksStats = function () {
    return this.performanceObserverStats
        ? this.performanceObserverStats.getLongTasksStats()
        : null;
};
/**
 * Removes the given listener for the LONG_TASKS_STATS event.
 *
 * @param {Function} listener the listener we want to remove.
 * @returns {void}
 */
Statistics.prototype.removeLongTasksStatsListener = function (listener) {
    this.eventEmitter.removeListener(_service_statistics_Events__WEBPACK_IMPORTED_MODULE_5__.LONG_TASKS_STATS, listener);
};
/**
 * Updates the list of speakers for which the audio levels are to be calculated. This is needed for the jvb pc only.
 *
 * @param {Array<string>} speakerList The list of remote endpoint ids.
 * @returns {void}
 */
Statistics.prototype.setSpeakerList = function (speakerList) {
    for (const rtpStats of Array.from(this.rtpStatsMap.values())) {
        if (!rtpStats.peerconnection.isP2P) {
            rtpStats.setSpeakerList(speakerList);
        }
    }
};
Statistics.prototype.dispose = function () {
    try {
        // NOTE Before reading this please see the comment in stopCallStats...
        //
        // Here we prevent from emitting the event twice in case it will be
        // triggered from stopCallStats.
        // If the event is triggered from here it means that the logs will not
        // be submitted anyway (because there is no CallStats instance), but
        // we're doing that for the sake of some kind of consistency.
        if (!this.callsStatsInstances.size) {
            this.eventEmitter.emit(_service_statistics_Events__WEBPACK_IMPORTED_MODULE_5__.BEFORE_DISPOSED);
        }
        for (const callStats of this.callsStatsInstances.values()) {
            this.stopCallStats(callStats.tpc);
        }
        for (const tpcId of this.rtpStatsMap.keys()) {
            this._stopRemoteStats(tpcId);
        }
        if (this.eventEmitter) {
            this.eventEmitter.removeAllListeners();
        }
    }
    finally {
        Statistics.instances.delete(this);
    }
};
Statistics.stopLocalStats = function (track) {
    if (!Statistics.audioLevelsEnabled) {
        return;
    }
    const stream = track.getOriginalStream();
    for (let i = 0; i < Statistics.localStats.length; i++) {
        if (Statistics.localStats[i].stream === stream) {
            const localStats = Statistics.localStats.splice(i, 1);
            localStats[0].stop();
            break;
        }
    }
};
/**
 * Stops remote RTP stats for given peerconnection ID.
 * @param {string} tpcId {@link TraceablePeerConnection.id}
 * @private
 */
Statistics.prototype._stopRemoteStats = function (tpcId) {
    const rtpStats = this.rtpStatsMap.get(tpcId);
    if (rtpStats) {
        rtpStats.stop();
        this.rtpStatsMap.delete(tpcId);
    }
};
/**
 * Stops collecting RTP stats for given peerconnection
 * @param {TraceablePeerConnection} tpc
 */
Statistics.prototype.stopRemoteStats = function (tpc) {
    this._stopRemoteStats(tpc.id);
};
// CALSTATS METHODS
/**
 * Initializes the callstats.io API.
 * @param {TraceablePeerConnection} tpc the {@link TraceablePeerConnection}
 * instance for which CalStats will be started.
 * @param {string} remoteUserID
 */
Statistics.prototype.startCallStats = function (tpc, remoteUserID) {
    if (!this.callStatsIntegrationEnabled) {
        return;
    }
    else if (this.callsStatsInstances.has(tpc.id)) {
        logger.error('CallStats instance for ${tpc} exists already');
        return;
    }
    let confID = this.options.confID;
    // confID - domain/tenant/roomName
    // roomName - meeting name or breakout room ID
    // For breakout rooms we change the conference ID used for callstats to use
    // the room ID instead of the meeting name
    if (!confID.endsWith(this.options.roomName)) {
        confID = `${this.options.confID.slice(0, this.options.confID.lastIndexOf('/'))}/${this.options.roomName}`;
    }
    logger.info(`Starting CallStats for ${tpc}...`);
    const newInstance = new _CallStats__WEBPACK_IMPORTED_MODULE_10__["default"](tpc, {
        confID,
        remoteUserID
    });
    this.callsStatsInstances.set(tpc.id, newInstance);
};
/**
 * Obtains the list of *all* {@link CallStats} instances collected from every
 * valid {@link Statistics} instance.
 * @return {Set<CallStats>}
 * @private
 */
Statistics._getAllCallStatsInstances = function () {
    const csInstances = new Set();
    for (const statistics of Statistics.instances) {
        for (const cs of statistics.callsStatsInstances.values()) {
            csInstances.add(cs);
        }
    }
    return csInstances;
};
/**
 * Removes the callstats.io instances.
 */
Statistics.prototype.stopCallStats = function (tpc) {
    const callStatsInstance = this.callsStatsInstances.get(tpc.id);
    if (callStatsInstance) {
        // FIXME the original purpose of adding BEFORE_DISPOSED event was to be
        // able to submit the last log batch from jitsi-meet to CallStats. After
        // recent changes we dispose the CallStats earlier
        // (before Statistics.dispose), so we need to emit this event here to
        // give this last chance for final log batch submission.
        //
        // Eventually there should be a separate module called "log storage"
        // which should emit proper events when it's underlying
        // CallStats instance is going away.
        if (this.callsStatsInstances.size === 1) {
            this.eventEmitter.emit(_service_statistics_Events__WEBPACK_IMPORTED_MODULE_5__.BEFORE_DISPOSED);
        }
        this.callsStatsInstances.delete(tpc.id);
        // The fabric needs to be terminated when being stopped
        callStatsInstance.sendTerminateEvent();
    }
};
/**
 * Returns true if the callstats integration is enabled, otherwise returns
 * false.
 *
 * @returns true if the callstats integration is enabled, otherwise returns
 * false.
 */
Statistics.prototype.isCallstatsEnabled = function () {
    return this.callStatsIntegrationEnabled;
};
/**
 * Logs either resume or hold event for the given peer connection.
 * @param {TraceablePeerConnection} tpc the connection for which event will be
 * reported
 * @param {boolean} isResume true for resume or false for hold
 */
Statistics.prototype.sendConnectionResumeOrHoldEvent = function (tpc, isResume) {
    const instance = this.callsStatsInstances.get(tpc.id);
    if (instance) {
        instance.sendResumeOrHoldEvent(isResume);
    }
};
/**
 * Notifies CallStats and analytics (if present) for ice connection failed
 * @param {TraceablePeerConnection} tpc connection on which failure occurred.
 */
Statistics.prototype.sendIceConnectionFailedEvent = function (tpc) {
    const instance = this.callsStatsInstances.get(tpc.id);
    if (instance) {
        instance.sendIceConnectionFailedEvent();
    }
};
/**
 * Notifies CallStats for mute events
 * @param {TraceablePeerConnection} tpc connection on which failure occurred.
 * @param {boolean} muted true for muted and false for not muted
 * @param {String} type "audio"/"video"
 */
Statistics.prototype.sendMuteEvent = function (tpc, muted, type) {
    const instance = tpc && this.callsStatsInstances.get(tpc.id);
    _CallStats__WEBPACK_IMPORTED_MODULE_10__["default"].sendMuteEvent(muted, type, instance);
};
/**
 * Notifies CallStats for screen sharing events
 * @param start {boolean} true for starting screen sharing and
 * false for not stopping
 * @param {string|null} ssrc - optional ssrc value, used only when
 * starting screen sharing.
 */
Statistics.prototype.sendScreenSharingEvent
    = function (start, ssrc) {
        for (const cs of this.callsStatsInstances.values()) {
            cs.sendScreenSharingEvent(start, ssrc);
        }
    };
/**
 * Notifies the statistics module that we are now the dominant speaker of the
 * conference.
 * @param {String} roomJid - The room jid where the speaker event occurred.
 * @param {boolean} silence - Whether the dominant speaker is silent or not.
 */
Statistics.prototype.sendDominantSpeakerEvent = function (roomJid, silence) {
    for (const cs of this.callsStatsInstances.values()) {
        cs.sendDominantSpeakerEvent();
    }
    // xmpp send dominant speaker event
    this.xmpp.sendDominantSpeakerEvent(roomJid, silence);
};
/**
 * Notifies about active device.
 * @param {{deviceList: {String:String}}} devicesData - list of devices with
 *      their data
 */
Statistics.sendActiveDeviceListEvent = function (devicesData) {
    const globalSet = Statistics._getAllCallStatsInstances();
    if (globalSet.size) {
        for (const cs of globalSet) {
            _CallStats__WEBPACK_IMPORTED_MODULE_10__["default"].sendActiveDeviceListEvent(devicesData, cs);
        }
    }
    else {
        _CallStats__WEBPACK_IMPORTED_MODULE_10__["default"].sendActiveDeviceListEvent(devicesData, null);
    }
};
/* eslint-disable max-params */
/**
 * Lets the underlying statistics module know where is given SSRC rendered by
 * providing renderer tag ID.
 * @param {TraceablePeerConnection} tpc the connection to which the stream
 * belongs to
 * @param {number} ssrc the SSRC of the stream
 * @param {boolean} isLocal
 * @param {string} userId
 * @param {string} usageLabel  meaningful usage label of this stream like
 *        'microphone', 'camera' or 'screen'.
 * @param {string} containerId the id of media 'audio' or 'video' tag which
 *        renders the stream.
 */
Statistics.prototype.associateStreamWithVideoTag = function (tpc, ssrc, isLocal, userId, usageLabel, containerId) {
    const instance = this.callsStatsInstances.get(tpc.id);
    if (instance) {
        instance.associateStreamWithVideoTag(ssrc, isLocal, userId, usageLabel, containerId);
    }
};
/* eslint-enable max-params */
/**
 * Notifies CallStats that getUserMedia failed.
 *
 * @param {Error} e error to send
 */
Statistics.sendGetUserMediaFailed = function (e) {
    const error = e instanceof _JitsiTrackError__WEBPACK_IMPORTED_MODULE_2__["default"]
        ? formatJitsiTrackErrorForCallStats(e) : e;
    const globalSet = Statistics._getAllCallStatsInstances();
    if (globalSet.size) {
        for (const cs of globalSet) {
            _CallStats__WEBPACK_IMPORTED_MODULE_10__["default"].sendGetUserMediaFailed(error, cs);
        }
    }
    else {
        _CallStats__WEBPACK_IMPORTED_MODULE_10__["default"].sendGetUserMediaFailed(error, null);
    }
};
/**
 * Notifies CallStats that peer connection failed to create offer.
 *
 * @param {Error} e error to send
 * @param {TraceablePeerConnection} tpc connection on which failure occurred.
 */
Statistics.prototype.sendCreateOfferFailed = function (e, tpc) {
    const instance = this.callsStatsInstances.get(tpc.id);
    if (instance) {
        instance.sendCreateOfferFailed(e);
    }
};
/**
 * Notifies CallStats that peer connection failed to create answer.
 *
 * @param {Error} e error to send
 * @param {TraceablePeerConnection} tpc connection on which failure occured.
 */
Statistics.prototype.sendCreateAnswerFailed = function (e, tpc) {
    const instance = this.callsStatsInstances.get(tpc.id);
    if (instance) {
        instance.sendCreateAnswerFailed(e);
    }
};
/**
 * Notifies CallStats that peer connection failed to set local description.
 *
 * @param {Error} e error to send
 * @param {TraceablePeerConnection} tpc connection on which failure occurred.
 */
Statistics.prototype.sendSetLocalDescFailed = function (e, tpc) {
    const instance = this.callsStatsInstances.get(tpc.id);
    if (instance) {
        instance.sendSetLocalDescFailed(e);
    }
};
/**
 * Notifies CallStats that peer connection failed to set remote description.
 *
 * @param {Error} e error to send
 * @param {TraceablePeerConnection} tpc connection on which failure occurred.
 */
Statistics.prototype.sendSetRemoteDescFailed = function (e, tpc) {
    const instance = this.callsStatsInstances.get(tpc.id);
    if (instance) {
        instance.sendSetRemoteDescFailed(e);
    }
};
/**
 * Notifies CallStats that peer connection failed to add ICE candidate.
 *
 * @param {Error} e error to send
 * @param {TraceablePeerConnection} tpc connection on which failure occurred.
 */
Statistics.prototype.sendAddIceCandidateFailed = function (e, tpc) {
    const instance = this.callsStatsInstances.get(tpc.id);
    if (instance) {
        instance.sendAddIceCandidateFailed(e);
    }
};
/**
 * Adds to CallStats an application log.
 *
 * @param {String} m a log message to send or an {Error} object to be reported
 */
Statistics.sendLog = function (m) {
    const globalSubSet = new Set();
    // FIXME we don't want to duplicate logs over P2P instance, but
    // here we should go over instances and call this method for each
    // unique conference ID rather than selecting the first one.
    // We don't have such use case though, so leaving as is for now.
    for (const stats of Statistics.instances) {
        if (stats.callStatsApplicationLogsDisabled) {
            return;
        }
        if (stats.callsStatsInstances.size) {
            globalSubSet.add(stats.callsStatsInstances.values().next().value);
        }
    }
    if (globalSubSet.size) {
        for (const csPerStats of globalSubSet) {
            _CallStats__WEBPACK_IMPORTED_MODULE_10__["default"].sendApplicationLog(m, csPerStats);
        }
    }
    else {
        _CallStats__WEBPACK_IMPORTED_MODULE_10__["default"].sendApplicationLog(m, null);
    }
};
/**
 * Sends the given feedback through CallStats.
 *
 * @param overall an integer between 1 and 5 indicating the user's rating.
 * @param comment the comment from the user.
 * @returns {Promise} Resolves when callstats feedback has been submitted
 * successfully.
 */
Statistics.prototype.sendFeedback = function (overall, comment) {
    // Statistics.analytics.sendEvent is currently fire and forget, without
    // confirmation of successful send.
    Statistics.analytics.sendEvent(_service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_4__.FEEDBACK, {
        rating: overall,
        comment
    });
    return _CallStats__WEBPACK_IMPORTED_MODULE_10__["default"].sendFeedback(this.options.confID, overall, comment);
};
Statistics.LOCAL_JID = (__webpack_require__(/*! ../../service/statistics/constants */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/statistics/constants.js").LOCAL_JID);
/**
 * Reports global error to CallStats.
 *
 * @param {Error} error
 */
Statistics.reportGlobalError = function (error) {
    if (error instanceof _JitsiTrackError__WEBPACK_IMPORTED_MODULE_2__["default"] && error.gum) {
        Statistics.sendGetUserMediaFailed(error);
    }
    else {
        Statistics.sendLog(error);
    }
};
/**
 * Sends event to analytics and logs a message to the logger/console. Console
 * messages might also be logged to callstats automatically.
 *
 * @param {string | Object} event the event name, or an object which
 * represents the entire event.
 * @param {Object} properties properties to attach to the event (if an event
 * name as opposed to an event object is provided).
 */
Statistics.sendAnalyticsAndLog = function (event, properties = {}) {
    if (!event) {
        logger.warn('No event or event name given.');
        return;
    }
    let eventToLog;
    // Also support an API with a single object as an event.
    if (typeof event === 'object') {
        eventToLog = event;
    }
    else {
        eventToLog = {
            name: event,
            properties
        };
    }
    logger.log(JSON.stringify(eventToLog));
    // We do this last, because it may modify the object which is passed.
    this.analytics.sendEvent(event, properties);
};
/**
 * Sends event to analytics.
 *
 * @param {string | Object} eventName the event name, or an object which
 * represents the entire event.
 * @param {Object} properties properties to attach to the event
 */
Statistics.sendAnalytics = function (eventName, properties = {}) {
    this.analytics.sendEvent(eventName, properties);
};
//# sourceMappingURL=statistics.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/transcription/audioRecorder.js":
/*!********************************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/transcription/audioRecorder.js ***!
  \********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (__WEBPACK_DEFAULT_EXPORT__)
/* harmony export */ });
/* harmony import */ var _recordingResult__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./recordingResult */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/transcription/recordingResult.js");
/* harmony import */ var _trackRecorder__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./trackRecorder */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/transcription/trackRecorder.js");


/**
 * Possible audio formats MIME types
 */
const AUDIO_WEBM = 'audio/webm'; // Supported in chrome
const AUDIO_OGG = 'audio/ogg'; // Supported in firefox
/**
 * Starts the recording of a JitsiTrack in a TrackRecorder object.
 * This will also define the timestamp and try to update the name
 * @param trackRecorder the TrackRecorder to start
 */
function startRecorder(trackRecorder) {
    if (trackRecorder.recorder === undefined) {
        throw new Error('Passed an object to startRecorder which is not a '
            + 'TrackRecorder object');
    }
    trackRecorder.recorder.start();
    trackRecorder.startTime = new Date();
}
/**
 * Stops the recording of a JitsiTrack in a TrackRecorder object.
 * This will also try to update the name
 * @param trackRecorder the TrackRecorder to stop
 */
function stopRecorder(trackRecorder) {
    if (trackRecorder.recorder === undefined) {
        throw new Error('Passed an object to stopRecorder which is not a '
            + 'TrackRecorder object');
    }
    trackRecorder.recorder.stop();
}
/**
 * Determines which kind of audio recording the browser supports
 * chrome supports "audio/webm" and firefox supports "audio/ogg"
 */
function determineCorrectFileType() {
    if (MediaRecorder.isTypeSupported(AUDIO_WEBM)) {
        return AUDIO_WEBM;
    }
    else if (MediaRecorder.isTypeSupported(AUDIO_OGG)) {
        return AUDIO_OGG;
    }
    throw new Error('unable to create a MediaRecorder with the right mimetype!');
}
/**
 * main exported object of the file, holding all
 * relevant functions and variables for the outside world
 * @param jitsiConference the jitsiConference which this object
 * is going to record
 */
function AudioRecorder(jitsiConference) {
    // array of TrackRecorders, where each trackRecorder
    // holds the JitsiTrack, MediaRecorder and recorder data
    this.recorders = [];
    // get which file type is supported by the current browser
    this.fileType = determineCorrectFileType();
    // boolean flag for active recording
    this.isRecording = false;
    // the jitsiconference the object is recording
    this.jitsiConference = jitsiConference;
}
/**
 * Add the exported module so that it can be accessed by other files
 */
AudioRecorder.determineCorrectFileType = determineCorrectFileType;
/**
 * Adds a new TrackRecorder object to the array.
 *
 * @param track the track potentially holding an audio stream
 */
AudioRecorder.prototype.addTrack = function (track) {
    if (track.isAudioTrack()) {
        // create the track recorder
        const trackRecorder = this.instantiateTrackRecorder(track);
        // push it to the local array of all recorders
        this.recorders.push(trackRecorder);
        // update the name of the trackRecorders
        this.updateNames();
        // If we're already recording, immediately start recording this new
        // track.
        if (this.isRecording) {
            startRecorder(trackRecorder);
        }
    }
};
/**
 * Creates a TrackRecorder object. Also creates the MediaRecorder and
 * data array for the trackRecorder.
 * @param track the JitsiTrack holding the audio MediaStream(s)
 */
AudioRecorder.prototype.instantiateTrackRecorder = function (track) {
    const trackRecorder = new _trackRecorder__WEBPACK_IMPORTED_MODULE_1__["default"](track);
    // Create a new stream which only holds the audio track
    const originalStream = trackRecorder.track.getOriginalStream();
    const stream = new MediaStream();
    originalStream.getAudioTracks().forEach(t => stream.addTrack(t));
    // Create the MediaRecorder
    trackRecorder.recorder = new MediaRecorder(stream, { mimeType: this.fileType });
    // array for holding the recorder data. Resets it when
    // audio already has been recorder once
    trackRecorder.data = [];
    // function handling a dataEvent, e.g the stream gets new data
    trackRecorder.recorder.ondataavailable = function (dataEvent) {
        if (dataEvent.data.size > 0) {
            trackRecorder.data.push(dataEvent.data);
        }
    };
    return trackRecorder;
};
/**
 * Notifies the module that a specific track has stopped, e.g participant left
 * the conference.
 * if the recording has not started yet, the TrackRecorder will be removed from
 * the array. If the recording has started, the recorder will stop recording
 * but not removed from the array so that the recorded stream can still be
 * accessed
 *
 * @param {JitsiTrack} track the JitsiTrack to remove from the recording session
 */
AudioRecorder.prototype.removeTrack = function (track) {
    if (track.isVideoTrack()) {
        return;
    }
    const array = this.recorders;
    let i;
    for (i = 0; i < array.length; i++) {
        if (array[i].track.getParticipantId() === track.getParticipantId()) {
            const recorderToRemove = array[i];
            if (this.isRecording) {
                stopRecorder(recorderToRemove);
            }
            else {
                // remove the TrackRecorder from the array
                array.splice(i, 1);
            }
        }
    }
    // make sure the names are up to date
    this.updateNames();
};
/**
 * Tries to update the name value of all TrackRecorder in the array.
 * If it hasn't changed,it will keep the exiting name. If it changes to a
 * undefined value, the old value will also be kept.
 */
AudioRecorder.prototype.updateNames = function () {
    const conference = this.jitsiConference;
    this.recorders.forEach(trackRecorder => {
        if (trackRecorder.track.isLocal()) {
            trackRecorder.name = 'the transcriber';
        }
        else {
            const id = trackRecorder.track.getParticipantId();
            const participant = conference.getParticipantById(id);
            const newName = participant.getDisplayName();
            if (newName !== 'undefined') {
                trackRecorder.name = newName;
            }
        }
    });
};
/**
 * Starts the audio recording of every local and remote track
 */
AudioRecorder.prototype.start = function () {
    if (this.isRecording) {
        throw new Error('audiorecorder is already recording');
    }
    // set boolean isRecording flag to true so if new participants join the
    // conference, that track can instantly start recording as well
    this.isRecording = true;
    // start all the mediaRecorders
    this.recorders.forEach(trackRecorder => startRecorder(trackRecorder));
    // log that recording has started
    console.log(`Started the recording of the audio. There are currently ${this.recorders.length} recorders active.`);
};
/**
 * Stops the audio recording of every local and remote track
 */
AudioRecorder.prototype.stop = function () {
    // set the boolean flag to false
    this.isRecording = false;
    // stop all recorders
    this.recorders.forEach(trackRecorder => stopRecorder(trackRecorder));
    console.log('stopped recording');
};
/**
 * link hacking to download all recorded audio streams
 */
AudioRecorder.prototype.download = function () {
    this.recorders.forEach(trackRecorder => {
        const blob = new Blob(trackRecorder.data, { type: this.fileType });
        const url = URL.createObjectURL(blob);
        const a = document.createElement('a');
        document.body.appendChild(a);
        a.style = 'display: none';
        a.href = url;
        a.download = `test.${this.fileType.split('/')[1]}`;
        a.click();
        window.URL.revokeObjectURL(url);
    });
};
/**
 * returns the audio files of all recorders as an array of objects,
 * which include the name of the owner of the track and the starting time stamp
 * @returns {Array} an array of RecordingResult objects
 */
AudioRecorder.prototype.getRecordingResults = function () {
    if (this.isRecording) {
        throw new Error('cannot get blobs because the AudioRecorder is still recording!');
    }
    // make sure the names are up to date before sending them off
    this.updateNames();
    const array = [];
    this.recorders.forEach(recorder => array.push(new _recordingResult__WEBPACK_IMPORTED_MODULE_0__["default"](new Blob(recorder.data, { type: this.fileType }), recorder.name, recorder.startTime)));
    return array;
};
/**
 * Gets the mime type of the recorder audio
 * @returns {String} the mime type of the recorder audio
 */
AudioRecorder.prototype.getFileType = function () {
    return this.fileType;
};
/**
 * export the main object AudioRecorder
 */
/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (AudioRecorder);
//# sourceMappingURL=audioRecorder.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/transcription/recordingResult.js":
/*!**********************************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/transcription/recordingResult.js ***!
  \**********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (/* binding */ RecordingResult)
/* harmony export */ });
/* eslint-disable max-params */
/**
 * This object stores variables needed around the recording of an audio stream
 * and passing this recording along with additional information along to
 * different processes
 */
class RecordingResult {
    /**
     * @param blob the recording audio stream as a single blob
     * @param name the name of the person of the audio stream
     * @param startTime the time in UTC when recording of the audiostream started
     * @param wordArray the recorder audio stream transcribed as an array of Word objects
     */
    constructor(blob, name, startTime, wordArray) {
        this.blob = blob;
        this.name = name;
        this.startTime = startTime;
        this.wordArray = wordArray;
    }
}
//# sourceMappingURL=recordingResult.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/transcription/trackRecorder.js":
/*!********************************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/transcription/trackRecorder.js ***!
  \********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (/* binding */ TrackRecorder)
/* harmony export */ });
/**
 * A TrackRecorder object holds all the information needed for recording a
 * single JitsiTrack (either remote or local)
 * @param track The JitsiTrack the object is going to hold
 */
class TrackRecorder {
    /**
     * @param track The JitsiTrack the object is going to hold
     */
    constructor(track) {
        // The JitsiTrack holding the stream
        this.track = track;
        // The MediaRecorder recording the stream
        this.recorder = null;
        // The array of data chunks recorded from the stream
        // acts as a buffer until the data is stored on disk
        this.data = null;
        // the name of the person of the JitsiTrack. This can be undefined and/or
        // not unique
        this.name = null;
        // the time of the start of the recording
        this.startTime = null;
    }
}
//# sourceMappingURL=trackRecorder.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/transcription/transcriber.js":
/*!******************************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/transcription/transcriber.js ***!
  \******************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (__WEBPACK_DEFAULT_EXPORT__)
/* harmony export */ });
/* harmony import */ var _audioRecorder__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./audioRecorder */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/transcription/audioRecorder.js");
/* harmony import */ var _transcriptionServices_SphinxTranscriptionService__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./transcriptionServices/SphinxTranscriptionService */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/transcription/transcriptionServices/SphinxTranscriptionService.js");


const BEFORE_STATE = 'before';
const RECORDING_STATE = 'recording';
const TRANSCRIBING_STATE = 'transcribing';
const FINISHED_STATE = 'finished';
// the amount of characters each line in the transcription will have
const MAXIMUM_SENTENCE_LENGTH = 80;
/**
 * This is the main object for handing the Transcription. It interacts with
 * the audioRecorder to record every person in a conference and sends the
 * recorder audio to a transcriptionService. The returned speech-to-text result
 * will be merged to create a transcript
 * @param {AudioRecorder} audioRecorder An audioRecorder recording a conference
 */
function Transcriber() {
    // the object which can record all audio in the conference
    this.audioRecorder = new _audioRecorder__WEBPACK_IMPORTED_MODULE_0__["default"]();
    // this object can send the recorder audio to a speech-to-text service
    this.transcriptionService = new _transcriptionServices_SphinxTranscriptionService__WEBPACK_IMPORTED_MODULE_1__["default"]();
    // holds a counter to keep track if merging can start
    this.counter = null;
    // holds the date when transcription started which makes it possible
    // to calculate the offset between recordings
    this.startTime = null;
    // will hold the transcription once it is completed
    this.transcription = null;
    // this will be a method which will be called once the transcription is done
    // with the transcription as parameter
    this.callback = null;
    // stores all the retrieved speech-to-text results to merge together
    // this value will store an Array<Word> object
    this.results = [];
    // Stores the current state of the transcription process
    this.state = BEFORE_STATE;
    // Used in the updateTranscription method to add a new line when the
    // sentence becomes to long
    this.lineLength = 0;
}
/**
 * Method to start the transcription process. It will tell the audioRecorder
 * to start storing all audio streams and record the start time for merging
 * purposes
 */
Transcriber.prototype.start = function start() {
    if (this.state !== BEFORE_STATE) {
        throw new Error(`The transcription can only start when it's in the "${BEFORE_STATE}" state. It's currently in the "${this.state}" state`);
    }
    this.state = RECORDING_STATE;
    this.audioRecorder.start();
    this.startTime = new Date();
};
/**
 * Method to stop the transcription process. It will tell the audioRecorder to
 * stop, and get all the recorded audio to send it to the transcription service

 * @param callback a callback which will receive the transcription
 */
Transcriber.prototype.stop = function stop(callback) {
    if (this.state !== RECORDING_STATE) {
        throw new Error(`The transcription can only stop when it's in the "${RECORDING_STATE}" state. It's currently in the "${this.state}" state`);
    }
    // stop the recording
    console.log('stopping recording and sending audio files');
    this.audioRecorder.stop();
    // and send all recorded audio to the transcription service
    const callBack = blobCallBack.bind(null, this);
    this.audioRecorder.getRecordingResults().forEach(recordingResult => {
        this.transcriptionService.send(recordingResult, callBack);
        this.counter++;
    });
    // set the state to "transcribing" so that maybeMerge() functions correctly
    this.state = TRANSCRIBING_STATE;
    // and store the callback for later
    this.callback = callback;
};
/**
 * This method gets the answer from the transcription service, calculates the
 * offset and adds is to every Word object. It will also start the merging
 * when every send request has been received
 *
 * note: Make sure to bind this as a Transcription object
 * @param {Transcriber} transcriber the transcriber instance
 * @param {RecordingResult} answer a RecordingResult object with a defined
 * WordArray
 */
function blobCallBack(transcriber, answer) {
    console.log('retrieved an answer from the transcription service. The answer has an'
        + ` array of length: ${answer.wordArray.length}`);
    // first add the offset between the start of the transcription and
    // the start of the recording to all start and end times
    if (answer.wordArray.length > 0) {
        let offset = answer.startTime.getUTCMilliseconds()
            - transcriber.startTime.getUTCMilliseconds();
        // transcriber time will always be earlier
        if (offset < 0) {
            offset = 0; // presume 0 if it somehow not earlier
        }
        let array = '[';
        answer.wordArray.forEach(wordObject => {
            wordObject.begin += offset;
            wordObject.end += offset;
            array += `${wordObject.word},`;
        });
        array += ']';
        console.log(array);
        // give a name value to the Array object so that the merging can access
        // the name value without having to use the whole recordingResult object
        // in the algorithm
        answer.wordArray.name = answer.name;
    }
    // then store the array and decrease the counter
    transcriber.results.push(answer.wordArray);
    transcriber.counter--;
    console.log(`current counter: ${transcriber.counter}`);
    // and check if all results have been received.
    transcriber.maybeMerge();
}
/**
 * this method will check if the counter is zero. If it is, it will call
 * the merging method
 */
Transcriber.prototype.maybeMerge = function () {
    if (this.state === TRANSCRIBING_STATE && this.counter === 0) {
        // make sure to include the events in the result arrays before
        // merging starts
        this.merge();
    }
};
/**
 * This method will merge all speech-to-text arrays together in one
 * readable transcription string
 */
Transcriber.prototype.merge = function () {
    console.log(`starting merge process!\n The length of the array: ${this.results.length}`);
    this.transcription = '';
    // the merging algorithm will look over all Word objects who are at pos 0 in
    // every array. It will then select the one closest in time to the
    // previously placed word, while removing the selected word from its array
    // note: words can be skipped the skipped word's begin and end time somehow
    // end up between the closest word start and end time
    const arrays = this.results;
    // arrays of Word objects
    const potentialWords = []; // array of the first Word objects
    // check if any arrays are already empty and remove them
    hasPopulatedArrays(arrays);
    // populate all the potential Words for a first time
    arrays.forEach(array => pushWordToSortedArray(potentialWords, array));
    // keep adding words to transcription until all arrays are exhausted
    while (hasPopulatedArrays(arrays)) {
        // first select the lowest array;
        let lowestWordArray = arrays[0];
        arrays.forEach(wordArray => {
            if (wordArray[0].begin < lowestWordArray[0].begin) {
                lowestWordArray = wordArray;
            }
        });
        // put the word in the transcription
        let wordToAdd = lowestWordArray.shift();
        this.updateTranscription(wordToAdd, lowestWordArray.name);
        // keep going until a word in another array has a smaller time
        // or the array is empty
        while (lowestWordArray.length > 0) {
            let foundSmaller = false;
            const wordToCompare = lowestWordArray[0].begin;
            arrays.forEach(wordArray => {
                if (wordArray[0].begin < wordToCompare) {
                    foundSmaller = true;
                }
            });
            // add next word if no smaller time has been found
            if (foundSmaller) {
                break;
            }
            wordToAdd = lowestWordArray.shift();
            this.updateTranscription(wordToAdd, null);
        }
    }
    // set the state to finished and do the necessary left-over tasks
    this.state = FINISHED_STATE;
    if (this.callback) {
        this.callback(this.transcription);
    }
};
/**
 * Appends a word object to the transcription. It will make a new line with a
 * name if a name is specified
 * @param {Word} word the Word object holding the word to append
 * @param {String|null} name the name of a new speaker. Null if not applicable
 */
Transcriber.prototype.updateTranscription = function (word, name) {
    if (name !== undefined && name !== null) {
        this.transcription += `\n${name}:`;
        this.lineLength = name.length + 1; // +1 for the semi-colon
    }
    if (this.lineLength + word.word.length > MAXIMUM_SENTENCE_LENGTH) {
        this.transcription += '\n    ';
        this.lineLength = 4; // because of the 4 spaces after the new line
    }
    this.transcription += ` ${word.word}`;
    this.lineLength += word.word.length + 1; // +1 for the space
};
/**
 * Check if the given 2 dimensional array has any non-zero Word-arrays in them.
 * All zero-element arrays inside will be removed
 * If any non-zero-element arrays are found, the method will return true.
 * otherwise it will return false
 * @param {Array<Array>} twoDimensionalArray the array to check
 * @returns {boolean} true if any non-zero arrays inside, otherwise false
 */
function hasPopulatedArrays(twoDimensionalArray) {
    for (let i = 0; i < twoDimensionalArray.length; i++) {
        if (twoDimensionalArray[i].length === 0) {
            twoDimensionalArray.splice(i, 1);
        }
    }
    return twoDimensionalArray.length > 0;
}
/**
 * Push a word to the right location in a sorted array. The array is sorted
 * from lowest to highest start time. Every word is stored in an object which
 * includes the name of the person saying the word.
 *
 * @param {Array<Word>} array the sorted array to push to
 * @param {Word} word the word to push into the array
 */
function pushWordToSortedArray(array, word) {
    if (array.length === 0) {
        array.push(word);
    }
    else {
        if (array[array.length - 1].begin <= word.begin) {
            array.push(word);
            return;
        }
        for (let i = 0; i < array.length; i++) {
            if (word.begin < array[i].begin) {
                array.splice(i, 0, word);
                return;
            }
        }
        array.push(word); // fail safe
    }
}
/**
 * Gives the transcriber a JitsiTrack holding an audioStream to transcribe.
 * The JitsiTrack is given to the audioRecorder. If it doesn't hold an
 * audiostream, it will not be added by the audioRecorder
 * @param {JitsiTrack} track the track to give to the audioRecorder
 */
Transcriber.prototype.addTrack = function (track) {
    this.audioRecorder.addTrack(track);
};
/**
 * Remove the given track from the auioRecorder
 * @param track
 */
Transcriber.prototype.removeTrack = function (track) {
    this.audioRecorder.removeTrack(track);
};
/**
 * Will return the created transcription if it's avialable or throw an error
 * when it's not done yet
 * @returns {String} the transcription as a String
 */
Transcriber.prototype.getTranscription = function () {
    if (this.state !== FINISHED_STATE) {
        throw new Error(`The transcription can only be retrieved when it's in the "${FINISHED_STATE}" state. It's currently in the "${this.state}" state`);
    }
    return this.transcription;
};
/**
 * Returns the current state of the transcription process
 */
Transcriber.prototype.getState = function () {
    return this.state;
};
/**
 * Resets the state to the "before" state, such that it's again possible to
 * call the start method
 */
Transcriber.prototype.reset = function () {
    this.state = BEFORE_STATE;
    this.counter = null;
    this.transcription = null;
    this.startTime = null;
    this.callback = null;
    this.results = [];
    this.lineLength = 0;
};
/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (Transcriber);
//# sourceMappingURL=transcriber.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/transcription/transcriptionServices/AbstractTranscriptionService.js":
/*!*********************************************************************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/transcription/transcriptionServices/AbstractTranscriptionService.js ***!
  \*********************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (/* binding */ TranscriptionService)
/* harmony export */ });
/**
 * Abstract class representing an interface to implement a speech-to-text
 * service on.
 */
class TranscriptionService {
    /**
     * Abstract class representing an interface to implement a speech-to-text
     * service on.
     */
    constructor() {
        throw new Error('TranscriptionService is abstract and cannot be created');
    }
    /**
     * This method can be used to send the recorder audio stream and
     * retrieve the answer from the transcription service from the callback
     *
     * @param {RecordingResult} recordingResult a recordingResult object which
     * includes the recorded audio stream as a blob
     * @param {Function} callback  which will retrieve the a RecordingResult with
     *        the answer as a WordArray
     */
    send(recordingResult, callback) {
        this.sendRequest(recordingResult.blob, response => {
            if (this.verify(response)) {
                recordingResult.wordArray = this.formatResponse(response);
            }
            else {
                console.log('the retrieved response from the server is not valid!');
                recordingResult.wordArray = [];
            }
            callback(recordingResult);
        });
    }
    /**
     * Abstract method which will rend the recorder audio stream to the implemented
     * transcription service and will retrieve an answer, which will be
     * called on the given callback method
     *
     * @param {Blob} audioBlob the recorded audio stream as a single Blob
     * @param {function} callback function which will retrieve the answer
     *                            from the service
     */
    sendRequest(audioBlob, callback) {
        throw new Error('TranscriptionService.sendRequest is abstract');
    }
    /**
     * Abstract method which will parse the output from the implemented
     * transcription service to the expected format
     *
     * The transcriber class expect an array of word objects, where each word
     * object is one transcribed word by the service.
     *
     * The expected output of this method is an array of word objects, in
     * the correct order. That is, the first object in the array is the first word
     * being said, and the last word in the array is the last word being said
     *
     * @param response the answer from the speech-to-text server which needs to be
     *                 formatted
     * @return {Array<Word>} an array of Word objects
     */
    formatResponse(response) {
        throw new Error('TranscriptionService.format is abstract');
    }
    /**
     * Abstract method which will verify that the response from the server is valid
     *
     * @param response the response from the server
     * @return {boolean} true if response is valid, false otherwise
     */
    verify(response) {
        throw new Error('TranscriptionService.verify is abstract');
    }
}
//# sourceMappingURL=AbstractTranscriptionService.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/transcription/transcriptionServices/SphinxTranscriptionService.js":
/*!*******************************************************************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/transcription/transcriptionServices/SphinxTranscriptionService.js ***!
  \*******************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (/* binding */ SphinxService)
/* harmony export */ });
/* harmony import */ var _word__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../word */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/transcription/word.js");
/* harmony import */ var _audioRecorder__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./../audioRecorder */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/transcription/audioRecorder.js");
/* harmony import */ var _AbstractTranscriptionService__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./AbstractTranscriptionService */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/transcription/transcriptionServices/AbstractTranscriptionService.js");
/* global config */



/**
 * Implements a TranscriptionService for a Sphinx4 http server
 */
class SphinxService extends _AbstractTranscriptionService__WEBPACK_IMPORTED_MODULE_2__["default"] {
    /**
     * Implements a TranscriptionService for a Sphinx4 http server
     */
    constructor() {
        super();
        // set the correct url
        this.url = getURL();
    }
    /**
     * Overrides the sendRequest method from AbstractTranscriptionService
     * it will send the audio stream the a Sphinx4 server to get the transcription
     *
     * @param audioFileBlob the recorder audio stream an a single Blob
     * @param callback the callback function retrieving the server response
     */
    sendRequest(audioFileBlob, callback) {
        console.log(`sending an audio file  to ${this.url}`);
        console.log(`the audio file being sent: ${audioFileBlob}`);
        const request = new XMLHttpRequest();
        request.onreadystatechange = function () {
            if (request.readyState === XMLHttpRequest.DONE
                && request.status === 200) {
                callback(request.responseText);
            }
            else if (request.readyState === XMLHttpRequest.DONE) {
                throw new Error(`unable to accept response from sphinx server. status: ${request.status}`);
            }
            // if not ready no point to throw an error
        };
        request.open('POST', this.url);
        request.setRequestHeader('Content-Type', _audioRecorder__WEBPACK_IMPORTED_MODULE_1__["default"].determineCorrectFileType());
        request.send(audioFileBlob);
        console.log(`send ${audioFileBlob}`);
    }
    /**
     * Overrides the formatResponse method from AbstractTranscriptionService
     * It will parse the answer from the server in the expected format
     *
     * @param response the JSON body retrieved from the Sphinx4 server
     */
    formatResponse(response) {
        const result = JSON.parse(response).objects;
        // make sure to delete the session id object, which is always
        // the first value in the JSON array
        result.shift();
        const array = [];
        result.forEach(word => word.filler
            || array.push(new _word__WEBPACK_IMPORTED_MODULE_0__["default"](word.word, word.start, word.end)));
        return array;
    }
    /**
     * checks wether the reply is empty, or doesn't contain a correct JSON object
     * @param response the server response
     * @return {boolean} whether the response is valid
     */
    verify(response) {
        console.log(`response from server:${response.toString()}`);
        // test if server responded with a string object
        if (typeof response !== 'string') {
            return false;
        }
        // test if the string can be parsed into valid JSON
        let json;
        try {
            json = JSON.parse(response);
        }
        catch (error) {
            console.log(error);
            return false;
        }
        // check if the JSON has a "objects" value
        if (json.objects === undefined) {
            return false;
        }
        // get the "objects" value and check for a session ID
        const array = json.objects;
        if (!(array[0] && array[0]['session-id'])) {
            return false;
        }
        // everything seems to be in order
        return true;
    }
}
/**
 * Gets the URL to the Sphinx4 server from the config file. If it's not there,
 * it will throw an error
 *
 * @returns {string} the URL to the sphinx4 server
 */
function getURL() {
    const message = 'config does not contain an url to a Sphinx4 https server';
    if (config.sphinxURL === undefined) {
        console.log(message);
    }
    else {
        const toReturn = config.sphinxURL;
        if (toReturn.includes !== undefined && toReturn.includes('https://')) {
            return toReturn;
        }
        console.log(message);
    }
}
//# sourceMappingURL=SphinxTranscriptionService.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/transcription/word.js":
/*!***********************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/transcription/word.js ***!
  \***********************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (/* binding */ Word)
/* harmony export */ });
/**
 * An object representing a transcribed word, with some additional information
 * @param word the word
 * @param begin the time the word was started being uttered
 * @param end the time the word stopped being uttered
 */
class Word {
    /**
     * @param word the word
     * @param begin the time the word was started being uttered
     * @param end the time the word stopped being uttered
     */
    constructor(word, begin, end) {
        this.word = word;
        this.begin = begin;
        this.end = end;
    }
    /**
     * Get the string representation of the word
     * @returns {*} the word as a string
     */
    getWord() {
        return this.word;
    }
    /**
     * Get the time the word started being uttered
     * @returns {*} the start time as an integer
     */
    getBeginTime() {
        return this.begin;
    }
    /**
     * Get the time the word stopped being uttered
     * @returns {*} the end time as an integer
     */
    getEndTime() {
        return this.end;
    }
}
//# sourceMappingURL=word.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/util/AsyncQueue.js":
/*!********************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/util/AsyncQueue.js ***!
  \********************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
var __filename = "/index.js";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (/* binding */ AsyncQueue)
/* harmony export */ });
/* harmony import */ var _jitsi_logger__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @jitsi/logger */ "./node_modules/@jitsi/logger/lib/index.js");
/* harmony import */ var _jitsi_logger__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(_jitsi_logger__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var async_es__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! async-es */ "./node_modules/async-es/queue.js");


const logger = (0,_jitsi_logger__WEBPACK_IMPORTED_MODULE_0__.getLogger)(__filename);
/**
 * A queue for async task execution.
 */
class AsyncQueue {
    /**
     * Creates new instance.
     */
    constructor() {
        this._queue = (0,async_es__WEBPACK_IMPORTED_MODULE_1__["default"])(this._processQueueTasks.bind(this), 1);
        this._stopped = false;
    }
    /**
     * Removes any pending tasks from the queue.
     */
    clear() {
        this._queue.kill();
    }
    /**
     * Internal task processing implementation which makes things work.
     */
    _processQueueTasks(task, finishedCallback) {
        try {
            task(finishedCallback);
        }
        catch (error) {
            logger.error(`Task failed: ${error === null || error === void 0 ? void 0 : error.stack}`);
            finishedCallback(error);
        }
    }
    /**
     * Pauses the execution of the tasks on the queue.
     */
    pause() {
        this._queue.pause();
    }
    /**
     * The 'task' function will be given a callback it MUST call with either:
     *  1) No arguments if it was successful or
     *  2) An error argument if there was an error
     * If the task wants to process the success or failure of the task, it
     * should pass the {@code callback} to the push function, e.g.:
     * queue.push(task, (err) => {
     *     if (err) {
     *         // error handling
     *     } else {
     *         // success handling
     *     }
     * });
     *
     * @param {function} task - The task to be executed. See the description above.
     * @param {function} [callback] - Optional callback to be called after the task has been executed.
     */
    push(task, callback) {
        if (this._stopped) {
            callback && callback(new Error('The queue has been stopped'));
            return;
        }
        this._queue.push(task, callback);
    }
    /**
     * Resumes the execution of the tasks on the queue.
     */
    resume() {
        this._queue.resume();
    }
    /**
     * Shutdowns the queue. All already queued tasks will execute, but no future tasks can be added. If a task is added
     * after the queue has been shutdown then the callback will be called with an error.
     */
    shutdown() {
        this._stopped = true;
    }
}
//# sourceMappingURL=AsyncQueue.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/util/AuthUtil.js":
/*!******************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/util/AuthUtil.js ***!
  \******************************************************************************/
/***/ ((module) => {

const AuthUtil = {
    /**
     * Creates the URL pointing to JWT token authentication service. It is
     * formatted from the 'urlPattern' argument which can contain the following
     * constants:
     * '{room}' - name of the conference room passed as <tt>roomName</tt>
     * argument to this method.
     * '{roleUpgrade}' - will contain 'true' if the URL will be used for
     * the role upgrade scenario, where user connects from anonymous domain and
     * then gets upgraded to the moderator by logging-in from the popup window.
     *
     * @param urlPattern a URL pattern pointing to the login service
     * @param roomName the name of the conference room for which the user will
     * be authenticated
     * @param {boolean} roleUpgrade <tt>true</tt> if the URL will be used for role
     * upgrade scenario, where the user logs-in from the popup window in order
     * to have the moderator rights granted
     *
     * @returns {string|null} the URL pointing to JWT login service or
     * <tt>null</tt> if 'urlPattern' is not a string and the URL can not be
     * constructed.
     */
    getTokenAuthUrl(urlPattern, roomName, roleUpgrade) {
        const url = urlPattern;
        if (typeof url !== 'string') {
            return null;
        }
        return url.replace('{room}', roomName)
            .replace('{roleUpgrade}', roleUpgrade === true);
    }
};
module.exports = AuthUtil;
//# sourceMappingURL=AuthUtil.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/util/Deferred.js":
/*!******************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/util/Deferred.js ***!
  \******************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (/* binding */ Deferred)
/* harmony export */ });
/**
 * Promise-like object which can be passed around for resolving it later. It
 * implements the "thenable" interface, so it can be used wherever a Promise
 * could be used.
 *
 * In addition a "reject on timeout" functionality is provided.
 */
class Deferred {
    /**
     * Instantiates a Deferred object.
     */
    constructor() {
        this.promise = new Promise((resolve, reject) => {
            this.resolve = (...args) => {
                this.clearRejectTimeout();
                resolve(...args);
            };
            this.reject = (...args) => {
                this.clearRejectTimeout();
                reject(...args);
            };
        });
        this.then = this.promise.then.bind(this.promise);
        this.catch = this.promise.catch.bind(this.promise);
    }
    /**
     * Clears the reject timeout.
     */
    clearRejectTimeout() {
        clearTimeout(this._timeout);
    }
    /**
     * Rejects the promise after the given timeout.
     */
    setRejectTimeout(ms) {
        this._timeout = setTimeout(() => {
            this.reject(new Error('timeout'));
        }, ms);
    }
}
//# sourceMappingURL=Deferred.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/util/EventEmitterForwarder.js":
/*!*******************************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/util/EventEmitterForwarder.js ***!
  \*******************************************************************************************/
/***/ ((module) => {

/**
 * Implements utility to forward events from one eventEmitter to another.
 * @param src {object} instance of EventEmitter or another class that implements
 * addListener method which will register listener to EventEmitter instance.
 * @param dest {object} instance of EventEmitter or another class that
 * implements emit method which will emit an event.
 */
function EventEmitterForwarder(src, dest) {
    if (!src || !dest || typeof src.addListener !== 'function'
        || typeof dest.emit !== 'function') {
        throw new Error('Invalid arguments passed to EventEmitterForwarder');
    }
    this.src = src;
    this.dest = dest;
}
/**
 * Adds event to be forwarded from src to dest.
 * @param srcEvent {string} the event that EventEmitterForwarder is listening
 * for.
 * @param dstEvent {string} the event that will be fired from dest.
 * @param arguments all other passed arguments are going to be fired with
 * dstEvent.
 */
EventEmitterForwarder.prototype.forward = function (...args) {
    const srcEvent = args[0];
    // This will be the "this" value for emit function.
    args[0] = this.dest;
    // Using bind.apply to pass the arguments as Array-like object ("arguments")
    this.src.addListener(srcEvent, Function.prototype.bind.apply(this.dest.emit, args));
};
module.exports = EventEmitterForwarder;
//# sourceMappingURL=EventEmitterForwarder.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/util/GlobalOnErrorHandler.js":
/*!******************************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/util/GlobalOnErrorHandler.js ***!
  \******************************************************************************************/
/***/ ((module) => {

/**
 * This utility class defines custom onerror and onunhandledrejection functions.
 * The custom error handlers respect the previously-defined error handlers.
 * GlobalOnErrorHandler class provides utilities to add many custom error
 * handlers and to execute the error handlers directly.
 */
/**
 * List with global error handlers that will be executed.
 */
const handlers = [];
// If an old handler exists, also fire its events.
const oldOnErrorHandler = window.onerror;
/**
 * Custom error handler that calls the old global error handler and executes
 * all handlers that were previously added.
 */
function JitsiGlobalErrorHandler(...args) {
    handlers.forEach(handler => handler(...args));
    oldOnErrorHandler && oldOnErrorHandler(...args);
}
// If an old handler exists, also fire its events.
const oldOnUnhandledRejection = window.onunhandledrejection;
/**
 * Custom handler that calls the old global handler and executes all handlers
 * that were previously added. This handler handles rejected Promises.
 */
function JitsiGlobalUnhandledRejection(event) {
    handlers.forEach(handler => handler(null, null, null, null, event.reason));
    oldOnUnhandledRejection && oldOnUnhandledRejection(event);
}
// Setting the custom error handlers.
window.onerror = JitsiGlobalErrorHandler;
window.onunhandledrejection = JitsiGlobalUnhandledRejection;
const GlobalOnErrorHandler = {
    /**
     * Adds new error handlers.
     * @param handler the new handler.
     */
    addHandler(handler) {
        handlers.push(handler);
    },
    /**
     * Calls the global error handler if there is one.
     * @param error the error to pass to the error handler
     */
    callErrorHandler(error) {
        const errHandler = window.onerror;
        if (!errHandler) {
            return;
        }
        errHandler(null, null, null, null, error);
    },
    /**
     * Calls the global rejection handler if there is one.
     * @param error the error to pass to the rejection handler.
     */
    callUnhandledRejectionHandler(error) {
        const errHandler = window.onunhandledrejection;
        if (!errHandler) {
            return;
        }
        errHandler(error);
    }
};
module.exports = GlobalOnErrorHandler;
//# sourceMappingURL=GlobalOnErrorHandler.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/util/Listenable.js":
/*!********************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/util/Listenable.js ***!
  \********************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (/* binding */ Listenable)
/* harmony export */ });
/* harmony import */ var events__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! events */ "./node_modules/events/events.js");
/* harmony import */ var events__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(events__WEBPACK_IMPORTED_MODULE_0__);

/**
 * The class implements basic event operations - add/remove listener.
 * NOTE: The purpose of the class is to be extended in order to add
 * this functionality to other classes.
 */
class Listenable {
    /**
     * Creates new instance.
     * @param {EventEmitter} eventEmitter
     * @constructor
     */
    constructor(eventEmitter = new (events__WEBPACK_IMPORTED_MODULE_0___default())()) {
        this.eventEmitter = eventEmitter;
        // aliases for addListener/removeListener
        this.addEventListener = this.on = this.addListener;
        this.removeEventListener = this.off = this.removeListener;
    }
    /**
     * Adds new listener.
     * @param {String} eventName the name of the event
     * @param {Function} listener the listener.
     * @returns {Function} - The unsubscribe function.
     */
    addListener(eventName, listener) {
        this.eventEmitter.addListener(eventName, listener);
        return () => this.removeEventListener(eventName, listener);
    }
    /**
     * Removes listener.
     * @param {String} eventName the name of the event that triggers the
     * listener
     * @param {Function} listener the listener.
     */
    removeListener(eventName, listener) {
        this.eventEmitter.removeListener(eventName, listener);
    }
}
//# sourceMappingURL=Listenable.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/util/MathUtil.js":
/*!******************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/util/MathUtil.js ***!
  \******************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   RunningAverage: () => (/* binding */ RunningAverage),
/* harmony export */   calculateAverage: () => (/* binding */ calculateAverage),
/* harmony export */   filterPositiveValues: () => (/* binding */ filterPositiveValues),
/* harmony export */   hashString: () => (/* binding */ hashString),
/* harmony export */   safeCounterIncrement: () => (/* binding */ safeCounterIncrement)
/* harmony export */ });
/**
 * The method will increase the given number by 1. If the given counter is equal
 * or greater to {@link Number.MAX_SAFE_INTEGER} then it will be rolled back to
 * 1.
 * @param {number} number - An integer counter value to be incremented.
 * @return {number} the next counter value increased by 1 (see the description
 * above for exception).
 */
function safeCounterIncrement(number) {
    let nextValue = number;
    if (number >= Number.MAX_SAFE_INTEGER) {
        nextValue = 0;
    }
    return nextValue + 1;
}
/**
 * Calculates the average value of am Array of numbers.
 *
 * @param {Float32Array} valueArray - Array of numbers.
 * @returns {number} - Number array average.
 */
function calculateAverage(valueArray) {
    return valueArray.length > 0 ? valueArray.reduce((a, b) => a + b) / valueArray.length : 0;
}
/**
 * Calculates a unique hash for a given string similar to Java's
 * implementation of String.hashCode()
 *
 * @param {String} string - String whose hash has to be calculated.
 * @returns {number} - Unique hash code calculated.
 */
function hashString(string) {
    let hash = 0;
    for (let i = 0; i < string.length; i++) {
        hash += Math.pow(string.charCodeAt(i) * 31, string.length - i);
        /* eslint-disable no-bitwise */
        hash = hash & hash; // Convert to 32bit integer
    }
    return Math.abs(hash);
}
/**
 * Returns only the positive values from an array of numbers.
 *
 * @param {Float32Array} valueArray - Array of vad scores.
 * @returns {Array} - Array of positive numbers.
 */
function filterPositiveValues(valueArray) {
    return valueArray.filter(value => value >= 0);
}
/**
 * This class calculates a simple running average that continually changes
 * as more data points are collected and added.
 */
class RunningAverage {
    /**
     * Creates an instance of the running average calculator.
     */
    constructor() {
        this.average = 0;
        this.n = 0;
    }
    /**
     * Adds a new data point to the existing set of values and recomputes
     * the running average.
     * @param {number} value
     * @returns {void}
     */
    addNext(value) {
        if (typeof value !== 'number') {
            return;
        }
        this.n += 1;
        this.average = this.average + ((value - this.average) / this.n);
    }
    /**
     * Obtains the average value for the current subset of values.
     * @returns {number} - computed average.
     */
    getAverage() {
        return this.average;
    }
}
//# sourceMappingURL=MathUtil.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/util/RandomUtil.js":
/*!********************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/util/RandomUtil.js ***!
  \********************************************************************************/
/***/ ((module) => {

/**
 * @const
 */
const ALPHANUM = '0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ';
/**
 * Hexadecimal digits.
 * @const
 */
const HEX_DIGITS = '0123456789abcdef';
/**
 * Generates random int within the range [min, max]
 * @param min the minimum value for the generated number
 * @param max the maximum value for the generated number
 * @returns random int number
 */
function randomInt(min, max) {
    return Math.floor(Math.random() * (max - min + 1)) + min;
}
/**
 * Get random element from array or string.
 * @param {Array|string} arr source
 * @returns array element or string character
 */
function randomElement(arr) {
    return arr[randomInt(0, arr.length - 1)];
}
/**
 * Generate random alphanumeric string.
 * @param {number} length expected string length
 * @returns {string} random string of specified length
 */
function randomAlphanumStr(length) {
    let result = '';
    for (let i = 0; i < length; i += 1) {
        result += randomElement(ALPHANUM);
    }
    return result;
}
/**
 * Exported interface.
 */
const RandomUtil = {
    /**
     * Returns a random hex digit.
     * @returns {*}
     */
    randomHexDigit() {
        return randomElement(HEX_DIGITS);
    },
    /**
     * Returns a random string of hex digits with length 'len'.
     * @param len the length.
     */
    randomHexString(len) {
        let ret = '';
        while (len--) { // eslint-disable-line no-param-reassign
            ret += this.randomHexDigit();
        }
        return ret;
    },
    randomElement,
    randomAlphanumStr,
    randomInt
};
module.exports = RandomUtil;
//# sourceMappingURL=RandomUtil.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/util/Retry.js":
/*!***************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/util/Retry.js ***!
  \***************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   getJitterDelay: () => (/* binding */ getJitterDelay)
/* harmony export */ });
/**
* Gets next timeout using the full jitter pattern.
*
* NOTE that there are no checks for argument correctness, so either do the math or use defaults.
*
* @param {number} retry - The retry number.
* @param {number} minDelay - The minimal delay in milliseconds.
* @param {number} base - The exponent base.
* @returns {number} - The amount of waiting before trying another time given in milliseconds.
* @private
*/
function getJitterDelay(retry, minDelay = 500, base = 2) {
    return Math.floor((Math.random() * ((Math.pow(base, retry) * 1000) - minDelay)) + minDelay);
}
//# sourceMappingURL=Retry.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/util/ScriptUtil.js":
/*!********************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/util/ScriptUtil.js ***!
  \********************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

const currentExecutingScript = __webpack_require__(/*! current-executing-script */ "./node_modules/current-executing-script/dist/currentExecutingScript.js");
/* eslint-disable max-params */
/**
 * Implements utility functions which facilitate the dealing with scripts such
 * as the download and execution of a JavaScript file.
 */
const ScriptUtil = {
    /**
     * Loads a script from a specific source.
     *
     * @param src the source from the which the script is to be (down)loaded
     * @param async true to asynchronously load the script or false to
     * synchronously load the script
     * @param prepend true to schedule the loading of the script as soon as
     * possible or false to schedule the loading of the script at the end of the
     * scripts known at the time
     * @param relativeURL whether we need load the library from url relative
     * to the url that lib-jitsi-meet was loaded. Useful when sourcing the
     * library from different location than the app that is using it
     * @param loadCallback on load callback function
     * @param errorCallback callback to be called on error loading the script
     */
    loadScript(src, async, prepend, relativeURL, loadCallback, errorCallback) {
        const d = document;
        const tagName = 'script';
        const script = d.createElement(tagName);
        const referenceNode = d.getElementsByTagName(tagName)[0];
        script.async = async;
        if (relativeURL) {
            // finds the src url of the current loaded script
            // and use it as base of the src supplied argument
            const scriptEl = currentExecutingScript();
            if (scriptEl) {
                const scriptSrc = scriptEl.src;
                const baseScriptSrc = scriptSrc.substring(0, scriptSrc.lastIndexOf('/') + 1);
                if (scriptSrc && baseScriptSrc) {
                    // eslint-disable-next-line no-param-reassign
                    src = baseScriptSrc + src;
                }
            }
        }
        if (loadCallback) {
            script.onload = loadCallback;
        }
        if (errorCallback) {
            script.onerror = errorCallback;
        }
        script.src = src;
        if (prepend) {
            referenceNode.parentNode.insertBefore(script, referenceNode);
        }
        else {
            referenceNode.parentNode.appendChild(script);
        }
    }
};
/* eslint-enable max-params */
module.exports = ScriptUtil;
//# sourceMappingURL=ScriptUtil.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/util/UsernameGenerator.js":
/*!***************************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/util/UsernameGenerator.js ***!
  \***************************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

const RandomUtil = __webpack_require__(/*! ./RandomUtil */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/util/RandomUtil.js");
/**
 * from faker.js - Copyright (c) 2014-2015 Matthew Bergman & Marak Squires
 * MIT License
 * http://github.com/marak/faker.js/
 *
 * @const
 */
const names = [
    'Aaliyah', 'Aaron', 'Abagail', 'Abbey', 'Abbie', 'Abbigail', 'Abby',
    'Abdiel', 'Abdul', 'Abdullah', 'Abe', 'Abel', 'Abelardo', 'Abigail',
    'Abigale', 'Abigayle', 'Abner', 'Abraham', 'Ada', 'Adah', 'Adalberto',
    'Adaline', 'Adam', 'Adan', 'Addie', 'Addison', 'Adela', 'Adelbert', 'Adele',
    'Adelia', 'Adeline', 'Adell', 'Adella', 'Adelle', 'Aditya', 'Adolf',
    'Adolfo', 'Adolph', 'Adolphus', 'Adonis', 'Adrain', 'Adrian', 'Adriana',
    'Adrianna', 'Adriel', 'Adrien', 'Adrienne', 'Afton', 'Aglae', 'Agnes',
    'Agustin', 'Agustina', 'Ahmad', 'Ahmed', 'Aida', 'Aidan', 'Aiden', 'Aileen',
    'Aisha', 'Aiyana', 'Akeem', 'Al', 'Alaina', 'Alan', 'Alana', 'Alanis',
    'Alanna', 'Alayna', 'Alba', 'Albert', 'Alberta', 'Albertha', 'Alberto',
    'Albin', 'Albina', 'Alda', 'Alden', 'Alec', 'Aleen', 'Alejandra',
    'Alejandrin', 'Alek', 'Alena', 'Alene', 'Alessandra', 'Alessandro',
    'Alessia', 'Aletha', 'Alex', 'Alexa', 'Alexander', 'Alexandra', 'Alexandre',
    'Alexandrea', 'Alexandria', 'Alexandrine', 'Alexandro', 'Alexane',
    'Alexanne', 'Alexie', 'Alexis', 'Alexys', 'Alexzander', 'Alf', 'Alfonso',
    'Alfonzo', 'Alford', 'Alfred', 'Alfreda', 'Alfredo', 'Ali', 'Alia', 'Alice',
    'Alicia', 'Alisa', 'Alisha', 'Alison', 'Alivia', 'Aliya', 'Aliyah', 'Aliza',
    'Alize', 'Allan', 'Allen', 'Allene', 'Allie', 'Allison', 'Ally', 'Alphonso',
    'Alta', 'Althea', 'Alva', 'Alvah', 'Alvena', 'Alvera', 'Alverta', 'Alvina',
    'Alvis', 'Alyce', 'Alycia', 'Alysa', 'Alysha', 'Alyson', 'Alysson',
    'Amalia', 'Amanda', 'Amani', 'Amara', 'Amari', 'Amaya', 'Amber', 'Ambrose',
    'Amelia', 'Amelie', 'Amely', 'America', 'Americo', 'Amie', 'Amina', 'Amir',
    'Amira', 'Amiya', 'Amos', 'Amparo', 'Amy', 'Amya', 'Ana', 'Anabel',
    'Anabelle', 'Anahi', 'Anais', 'Anastacio', 'Anastasia', 'Anderson', 'Andre',
    'Andreane', 'Andreanne', 'Andres', 'Andrew', 'Andy', 'Angel', 'Angela',
    'Angelica', 'Angelina', 'Angeline', 'Angelita', 'Angelo', 'Angie', 'Angus',
    'Anibal', 'Anika', 'Anissa', 'Anita', 'Aniya', 'Aniyah', 'Anjali', 'Anna',
    'Annabel', 'Annabell', 'Annabelle', 'Annalise', 'Annamae', 'Annamarie',
    'Anne', 'Annetta', 'Annette', 'Annie', 'Ansel', 'Ansley', 'Anthony',
    'Antoinette', 'Antone', 'Antonetta', 'Antonette', 'Antonia', 'Antonietta',
    'Antonina', 'Antonio', 'Antwan', 'Antwon', 'Anya', 'April', 'Ara',
    'Araceli', 'Aracely', 'Arch', 'Archibald', 'Ardella', 'Arden', 'Ardith',
    'Arely', 'Ari', 'Ariane', 'Arianna', 'Aric', 'Ariel', 'Arielle', 'Arjun',
    'Arlene', 'Arlie', 'Arlo', 'Armand', 'Armando', 'Armani', 'Arnaldo', 'Arne',
    'Arno', 'Arnold', 'Arnoldo', 'Arnulfo', 'Aron', 'Art', 'Arthur', 'Arturo',
    'Arvel', 'Arvid', 'Arvilla', 'Aryanna', 'Asa', 'Asha', 'Ashlee', 'Ashleigh',
    'Ashley', 'Ashly', 'Ashlynn', 'Ashton', 'Ashtyn', 'Asia', 'Assunta',
    'Astrid', 'Athena', 'Aubree', 'Aubrey', 'Audie', 'Audra', 'Audreanne',
    'Audrey', 'August', 'Augusta', 'Augustine', 'Augustus', 'Aurelia',
    'Aurelie', 'Aurelio', 'Aurore', 'Austen', 'Austin', 'Austyn', 'Autumn',
    'Ava', 'Avery', 'Avis', 'Axel', 'Ayana', 'Ayden', 'Ayla', 'Aylin', 'Baby',
    'Bailee', 'Bailey', 'Barbara', 'Barney', 'Baron', 'Barrett', 'Barry',
    'Bart', 'Bartholome', 'Barton', 'Baylee', 'Beatrice', 'Beau', 'Beaulah',
    'Bell', 'Bella', 'Belle', 'Ben', 'Benedict', 'Benjamin', 'Bennett',
    'Bennie', 'Benny', 'Benton', 'Berenice', 'Bernadette', 'Bernadine',
    'Bernard', 'Bernardo', 'Berneice', 'Bernhard', 'Bernice', 'Bernie',
    'Berniece', 'Bernita', 'Berry', 'Bert', 'Berta', 'Bertha', 'Bertram',
    'Bertrand', 'Beryl', 'Bessie', 'Beth', 'Bethany', 'Bethel', 'Betsy',
    'Bette', 'Bettie', 'Betty', 'Bettye', 'Beulah', 'Beverly', 'Bianka', 'Bill',
    'Billie', 'Billy', 'Birdie', 'Blair', 'Blaise', 'Blake', 'Blanca',
    'Blanche', 'Blaze', 'Bo', 'Bobbie', 'Bobby', 'Bonita', 'Bonnie', 'Boris',
    'Boyd', 'Brad', 'Braden', 'Bradford', 'Bradley', 'Bradly', 'Brady',
    'Braeden', 'Brain', 'Brandi', 'Brando', 'Brandon', 'Brandt', 'Brandy',
    'Brandyn', 'Brannon', 'Branson', 'Brant', 'Braulio', 'Braxton', 'Brayan',
    'Breana', 'Breanna', 'Breanne', 'Brenda', 'Brendan', 'Brenden', 'Brendon',
    'Brenna', 'Brennan', 'Brennon', 'Brent', 'Bret', 'Brett', 'Bria', 'Brian',
    'Briana', 'Brianne', 'Brice', 'Bridget', 'Bridgette', 'Bridie', 'Brielle',
    'Brigitte', 'Brionna', 'Brisa', 'Britney', 'Brittany', 'Brock', 'Broderick',
    'Brody', 'Brook', 'Brooke', 'Brooklyn', 'Brooks', 'Brown', 'Bruce',
    'Bryana', 'Bryce', 'Brycen', 'Bryon', 'Buck', 'Bud', 'Buddy', 'Buford',
    'Bulah', 'Burdette', 'Burley', 'Burnice', 'Buster', 'Cade', 'Caden',
    'Caesar', 'Caitlyn', 'Cale', 'Caleb', 'Caleigh', 'Cali', 'Calista',
    'Callie', 'Camden', 'Cameron', 'Camila', 'Camilla', 'Camille', 'Camren',
    'Camron', 'Camryn', 'Camylle', 'Candace', 'Candelario', 'Candice',
    'Candida', 'Candido', 'Cara', 'Carey', 'Carissa', 'Carlee', 'Carleton',
    'Carley', 'Carli', 'Carlie', 'Carlo', 'Carlos', 'Carlotta', 'Carmel',
    'Carmela', 'Carmella', 'Carmelo', 'Carmen', 'Carmine', 'Carol', 'Carolanne',
    'Carole', 'Carolina', 'Caroline', 'Carolyn', 'Carolyne', 'Carrie',
    'Carroll', 'Carson', 'Carter', 'Cary', 'Casandra', 'Casey', 'Casimer',
    'Casimir', 'Casper', 'Cassandra', 'Cassandre', 'Cassidy', 'Cassie',
    'Catalina', 'Caterina', 'Catharine', 'Catherine', 'Cathrine', 'Cathryn',
    'Cathy', 'Cayla', 'Ceasar', 'Cecelia', 'Cecil', 'Cecile', 'Cecilia',
    'Cedrick', 'Celestine', 'Celestino', 'Celia', 'Celine', 'Cesar', 'Chad',
    'Chadd', 'Chadrick', 'Chaim', 'Chance', 'Chandler', 'Chanel', 'Chanelle',
    'Charity', 'Charlene', 'Charles', 'Charley', 'Charlie', 'Charlotte',
    'Chase', 'Chasity', 'Chauncey', 'Chaya', 'Chaz', 'Chelsea', 'Chelsey',
    'Chelsie', 'Chesley', 'Chester', 'Chet', 'Cheyanne', 'Cheyenne', 'Chloe',
    'Chris', 'Christ', 'Christa', 'Christelle', 'Christian', 'Christiana',
    'Christina', 'Christine', 'Christop', 'Christophe', 'Christopher',
    'Christy', 'Chyna', 'Ciara', 'Cicero', 'Cielo', 'Cierra', 'Cindy',
    'Citlalli', 'Clair', 'Claire', 'Clara', 'Clarabelle', 'Clare', 'Clarissa',
    'Clark', 'Claud', 'Claude', 'Claudia', 'Claudie', 'Claudine', 'Clay',
    'Clemens', 'Clement', 'Clementina', 'Clementine', 'Clemmie', 'Cleo',
    'Cleora', 'Cleta', 'Cletus', 'Cleve', 'Cleveland', 'Clifford', 'Clifton',
    'Clint', 'Clinton', 'Clotilde', 'Clovis', 'Cloyd', 'Clyde', 'Coby', 'Cody',
    'Colby', 'Cole', 'Coleman', 'Colin', 'Colleen', 'Collin', 'Colt', 'Colten',
    'Colton', 'Columbus', 'Concepcion', 'Conner', 'Connie', 'Connor', 'Conor',
    'Conrad', 'Constance', 'Constantin', 'Consuelo', 'Cooper', 'Cora',
    'Coralie', 'Corbin', 'Cordelia', 'Cordell', 'Cordia', 'Cordie', 'Corene',
    'Corine', 'Cornelius', 'Cornell', 'Corrine', 'Cortez', 'Cortney', 'Cory',
    'Coty', 'Courtney', 'Coy', 'Craig', 'Crawford', 'Creola', 'Cristal',
    'Cristian', 'Cristina', 'Cristobal', 'Cristopher', 'Cruz', 'Crystal',
    'Crystel', 'Cullen', 'Curt', 'Curtis', 'Cydney', 'Cynthia', 'Cyril',
    'Cyrus', 'Dagmar', 'Dahlia', 'Daija', 'Daisha', 'Daisy', 'Dakota', 'Dale',
    'Dallas', 'Dallin', 'Dalton', 'Damaris', 'Dameon', 'Damian', 'Damien',
    'Damion', 'Damon', 'Dan', 'Dana', 'Dandre', 'Dane', 'D\'angelo', 'Dangelo',
    'Danial', 'Daniela', 'Daniella', 'Danielle', 'Danika', 'Dannie', 'Danny',
    'Dante', 'Danyka', 'Daphne', 'Daphnee', 'Daphney', 'Darby', 'Daren',
    'Darian', 'Dariana', 'Darien', 'Dario', 'Darion', 'Darius', 'Darlene',
    'Daron', 'Darrel', 'Darrell', 'Darren', 'Darrick', 'Darrin', 'Darrion',
    'Darron', 'Darryl', 'Darwin', 'Daryl', 'Dashawn', 'Dasia', 'Dave', 'David',
    'Davin', 'Davion', 'Davon', 'Davonte', 'Dawn', 'Dawson', 'Dax', 'Dayana',
    'Dayna', 'Dayne', 'Dayton', 'Dean', 'Deangelo', 'Deanna', 'Deborah',
    'Declan', 'Dedric', 'Dedrick', 'Dee', 'Deion', 'Deja', 'Dejah', 'Dejon',
    'Dejuan', 'Delaney', 'Delbert', 'Delfina', 'Delia', 'Delilah', 'Dell',
    'Della', 'Delmer', 'Delores', 'Delpha', 'Delphia', 'Delphine', 'Delta',
    'Demarco', 'Demarcus', 'Demario', 'Demetris', 'Demetrius', 'Demond', 'Dena',
    'Denis', 'Dennis', 'Deon', 'Deondre', 'Deontae', 'Deonte', 'Dereck',
    'Derek', 'Derick', 'Deron', 'Derrick', 'Deshaun', 'Deshawn', 'Desiree',
    'Desmond', 'Dessie', 'Destany', 'Destin', 'Destinee', 'Destiney', 'Destini',
    'Destiny', 'Devan', 'Devante', 'Deven', 'Devin', 'Devon', 'Devonte',
    'Devyn', 'Dewayne', 'Dewitt', 'Dexter', 'Diamond', 'Diana', 'Dianna',
    'Diego', 'Dillan', 'Dillon', 'Dimitri', 'Dina', 'Dino', 'Dion', 'Dixie',
    'Dock', 'Dolly', 'Dolores', 'Domenic', 'Domenica', 'Domenick', 'Domenico',
    'Domingo', 'Dominic', 'Dominique', 'Don', 'Donald', 'Donato', 'Donavon',
    'Donna', 'Donnell', 'Donnie', 'Donny', 'Dora', 'Dorcas', 'Dorian', 'Doris',
    'Dorothea', 'Dorothy', 'Dorris', 'Dortha', 'Dorthy', 'Doug', 'Douglas',
    'Dovie', 'Doyle', 'Drake', 'Drew', 'Duane', 'Dudley', 'Dulce', 'Duncan',
    'Durward', 'Dustin', 'Dusty', 'Dwight', 'Dylan', 'Earl', 'Earlene',
    'Earline', 'Earnest', 'Earnestine', 'Easter', 'Easton', 'Ebba', 'Ebony',
    'Ed', 'Eda', 'Edd', 'Eddie', 'Eden', 'Edgar', 'Edgardo', 'Edison', 'Edmond',
    'Edmund', 'Edna', 'Eduardo', 'Edward', 'Edwardo', 'Edwin', 'Edwina',
    'Edyth', 'Edythe', 'Effie', 'Efrain', 'Efren', 'Eileen', 'Einar', 'Eino',
    'Eladio', 'Elaina', 'Elbert', 'Elda', 'Eldon', 'Eldora', 'Eldred',
    'Eldridge', 'Eleanora', 'Eleanore', 'Eleazar', 'Electa', 'Elena', 'Elenor',
    'Elenora', 'Eleonore', 'Elfrieda', 'Eli', 'Elian', 'Eliane', 'Elias',
    'Eliezer', 'Elijah', 'Elinor', 'Elinore', 'Elisa', 'Elisabeth', 'Elise',
    'Eliseo', 'Elisha', 'Elissa', 'Eliza', 'Elizabeth', 'Ella', 'Ellen',
    'Ellie', 'Elliot', 'Elliott', 'Ellis', 'Ellsworth', 'Elmer', 'Elmira',
    'Elmo', 'Elmore', 'Elna', 'Elnora', 'Elody', 'Eloisa', 'Eloise', 'Elouise',
    'Eloy', 'Elroy', 'Elsa', 'Else', 'Elsie', 'Elta', 'Elton', 'Elva', 'Elvera',
    'Elvie', 'Elvis', 'Elwin', 'Elwyn', 'Elyse', 'Elyssa', 'Elza', 'Emanuel',
    'Emelia', 'Emelie', 'Emely', 'Emerald', 'Emerson', 'Emery', 'Emie', 'Emil',
    'Emile', 'Emilia', 'Emiliano', 'Emilie', 'Emilio', 'Emily', 'Emma',
    'Emmalee', 'Emmanuel', 'Emmanuelle', 'Emmet', 'Emmett', 'Emmie', 'Emmitt',
    'Emmy', 'Emory', 'Ena', 'Enid', 'Enoch', 'Enola', 'Enos', 'Enrico',
    'Enrique', 'Ephraim', 'Era', 'Eriberto', 'Eric', 'Erica', 'Erich', 'Erick',
    'Ericka', 'Erik', 'Erika', 'Erin', 'Erling', 'Erna', 'Ernest', 'Ernestina',
    'Ernestine', 'Ernesto', 'Ernie', 'Ervin', 'Erwin', 'Eryn', 'Esmeralda',
    'Esperanza', 'Esta', 'Esteban', 'Estefania', 'Estel', 'Estell', 'Estella',
    'Estelle', 'Estevan', 'Esther', 'Estrella', 'Etha', 'Ethan', 'Ethel',
    'Ethelyn', 'Ethyl', 'Ettie', 'Eudora', 'Eugene', 'Eugenia', 'Eula', 'Eulah',
    'Eulalia', 'Euna', 'Eunice', 'Eusebio', 'Eva', 'Evalyn', 'Evan',
    'Evangeline', 'Evans', 'Eve', 'Eveline', 'Evelyn', 'Everardo', 'Everett',
    'Everette', 'Evert', 'Evie', 'Ewald', 'Ewell', 'Ezekiel', 'Ezequiel',
    'Ezra', 'Fabian', 'Fabiola', 'Fae', 'Fannie', 'Fanny', 'Fatima', 'Faustino',
    'Fausto', 'Favian', 'Fay', 'Faye', 'Federico', 'Felicia', 'Felicita',
    'Felicity', 'Felipa', 'Felipe', 'Felix', 'Felton', 'Fermin', 'Fern',
    'Fernando', 'Ferne', 'Fidel', 'Filiberto', 'Filomena', 'Finn', 'Fiona',
    'Flavie', 'Flavio', 'Fleta', 'Fletcher', 'Flo', 'Florence', 'Florencio',
    'Florian', 'Florida', 'Florine', 'Flossie', 'Floy', 'Floyd', 'Ford',
    'Forest', 'Forrest', 'Foster', 'Frances', 'Francesca', 'Francesco',
    'Francis', 'Francisca', 'Francisco', 'Franco', 'Frank', 'Frankie', 'Franz',
    'Fred', 'Freda', 'Freddie', 'Freddy', 'Frederic', 'Frederick', 'Frederik',
    'Frederique', 'Fredrick', 'Fredy', 'Freeda', 'Freeman', 'Freida', 'Frida',
    'Frieda', 'Friedrich', 'Fritz', 'Furman', 'Gabe', 'Gabriel', 'Gabriella',
    'Gabrielle', 'Gaetano', 'Gage', 'Gail', 'Gardner', 'Garett', 'Garfield',
    'Garland', 'Garnet', 'Garnett', 'Garret', 'Garrett', 'Garrick', 'Garrison',
    'Garry', 'Garth', 'Gaston', 'Gavin', 'Gay', 'Gayle', 'Gaylord', 'Gene',
    'General', 'Genesis', 'Genevieve', 'Gennaro', 'Genoveva', 'Geo', 'Geoffrey',
    'George', 'Georgette', 'Georgiana', 'Georgianna', 'Geovanni', 'Geovanny',
    'Geovany', 'Gerald', 'Geraldine', 'Gerard', 'Gerardo', 'Gerda', 'Gerhard',
    'Germaine', 'German', 'Gerry', 'Gerson', 'Gertrude', 'Gia', 'Gianni',
    'Gideon', 'Gilbert', 'Gilberto', 'Gilda', 'Giles', 'Gillian', 'Gina',
    'Gino', 'Giovani', 'Giovanna', 'Giovanni', 'Giovanny', 'Gisselle',
    'Giuseppe', 'Gladyce', 'Gladys', 'Glen', 'Glenda', 'Glenna', 'Glennie',
    'Gloria', 'Godfrey', 'Golda', 'Golden', 'Gonzalo', 'Gordon', 'Grace',
    'Gracie', 'Graciela', 'Grady', 'Graham', 'Grant', 'Granville', 'Grayce',
    'Grayson', 'Green', 'Greg', 'Gregg', 'Gregoria', 'Gregorio', 'Gregory',
    'Greta', 'Gretchen', 'Greyson', 'Griffin', 'Grover', 'Guadalupe', 'Gudrun',
    'Guido', 'Guillermo', 'Guiseppe', 'Gunnar', 'Gunner', 'Gus', 'Gussie',
    'Gust', 'Gustave', 'Guy', 'Gwen', 'Gwendolyn', 'Hadley', 'Hailee', 'Hailey',
    'Hailie', 'Hal', 'Haleigh', 'Haley', 'Halie', 'Halle', 'Hallie', 'Hank',
    'Hanna', 'Hannah', 'Hans', 'Hardy', 'Harley', 'Harmon', 'Harmony', 'Harold',
    'Harrison', 'Harry', 'Harvey', 'Haskell', 'Hassan', 'Hassie', 'Hattie',
    'Haven', 'Hayden', 'Haylee', 'Hayley', 'Haylie', 'Hazel', 'Hazle', 'Heath',
    'Heather', 'Heaven', 'Heber', 'Hector', 'Heidi', 'Helen', 'Helena',
    'Helene', 'Helga', 'Hellen', 'Helmer', 'Heloise', 'Henderson', 'Henri',
    'Henriette', 'Henry', 'Herbert', 'Herman', 'Hermann', 'Hermina', 'Herminia',
    'Herminio', 'Hershel', 'Herta', 'Hertha', 'Hester', 'Hettie', 'Hilario',
    'Hilbert', 'Hilda', 'Hildegard', 'Hillard', 'Hillary', 'Hilma', 'Hilton',
    'Hipolito', 'Hiram', 'Hobart', 'Holden', 'Hollie', 'Hollis', 'Holly',
    'Hope', 'Horace', 'Horacio', 'Hortense', 'Hosea', 'Houston', 'Howard',
    'Howell', 'Hoyt', 'Hubert', 'Hudson', 'Hugh', 'Hulda', 'Humberto', 'Hunter',
    'Hyman', 'Ian', 'Ibrahim', 'Icie', 'Ida', 'Idell', 'Idella', 'Ignacio',
    'Ignatius', 'Ike', 'Ila', 'Ilene', 'Iliana', 'Ima', 'Imani', 'Imelda',
    'Immanuel', 'Imogene', 'Ines', 'Irma', 'Irving', 'Irwin', 'Isaac', 'Isabel',
    'Isabell', 'Isabella', 'Isabelle', 'Isac', 'Isadore', 'Isai', 'Isaiah',
    'Isaias', 'Isidro', 'Ismael', 'Isobel', 'Isom', 'Israel', 'Issac', 'Itzel',
    'Iva', 'Ivah', 'Ivory', 'Ivy', 'Izabella', 'Izaiah', 'Jabari', 'Jace',
    'Jacey', 'Jacinthe', 'Jacinto', 'Jack', 'Jackeline', 'Jackie', 'Jacklyn',
    'Jackson', 'Jacky', 'Jaclyn', 'Jacquelyn', 'Jacques', 'Jacynthe', 'Jada',
    'Jade', 'Jaden', 'Jadon', 'Jadyn', 'Jaeden', 'Jaida', 'Jaiden', 'Jailyn',
    'Jaime', 'Jairo', 'Jakayla', 'Jake', 'Jakob', 'Jaleel', 'Jalen', 'Jalon',
    'Jalyn', 'Jamaal', 'Jamal', 'Jamar', 'Jamarcus', 'Jamel', 'Jameson',
    'Jamey', 'Jamie', 'Jamil', 'Jamir', 'Jamison', 'Jammie', 'Jan', 'Jana',
    'Janae', 'Jane', 'Janelle', 'Janessa', 'Janet', 'Janice', 'Janick', 'Janie',
    'Janis', 'Janiya', 'Jannie', 'Jany', 'Jaquan', 'Jaquelin', 'Jaqueline',
    'Jared', 'Jaren', 'Jarod', 'Jaron', 'Jarred', 'Jarrell', 'Jarret',
    'Jarrett', 'Jarrod', 'Jarvis', 'Jasen', 'Jasmin', 'Jason', 'Jasper',
    'Jaunita', 'Javier', 'Javon', 'Javonte', 'Jay', 'Jayce', 'Jaycee', 'Jayda',
    'Jayde', 'Jayden', 'Jaydon', 'Jaylan', 'Jaylen', 'Jaylin', 'Jaylon',
    'Jayme', 'Jayne', 'Jayson', 'Jazlyn', 'Jazmin', 'Jazmyn', 'Jazmyne', 'Jean',
    'Jeanette', 'Jeanie', 'Jeanne', 'Jed', 'Jedediah', 'Jedidiah', 'Jeff',
    'Jefferey', 'Jeffery', 'Jeffrey', 'Jeffry', 'Jena', 'Jenifer', 'Jennie',
    'Jennifer', 'Jennings', 'Jennyfer', 'Jensen', 'Jerad', 'Jerald', 'Jeramie',
    'Jeramy', 'Jerel', 'Jeremie', 'Jeremy', 'Jermain', 'Jermaine', 'Jermey',
    'Jerod', 'Jerome', 'Jeromy', 'Jerrell', 'Jerrod', 'Jerrold', 'Jerry',
    'Jess', 'Jesse', 'Jessica', 'Jessie', 'Jessika', 'Jessy', 'Jessyca',
    'Jesus', 'Jett', 'Jettie', 'Jevon', 'Jewel', 'Jewell', 'Jillian', 'Jimmie',
    'Jimmy', 'Jo', 'Joan', 'Joana', 'Joanie', 'Joanne', 'Joannie', 'Joanny',
    'Joany', 'Joaquin', 'Jocelyn', 'Jodie', 'Jody', 'Joe', 'Joel', 'Joelle',
    'Joesph', 'Joey', 'Johan', 'Johann', 'Johanna', 'Johathan', 'John',
    'Johnathan', 'Johnathon', 'Johnnie', 'Johnny', 'Johnpaul', 'Johnson',
    'Jolie', 'Jon', 'Jonas', 'Jonatan', 'Jonathan', 'Jonathon', 'Jordan',
    'Jordane', 'Jordi', 'Jordon', 'Jordy', 'Jordyn', 'Jorge', 'Jose', 'Josefa',
    'Josefina', 'Joseph', 'Josephine', 'Josh', 'Joshua', 'Joshuah', 'Josiah',
    'Josiane', 'Josianne', 'Josie', 'Josue', 'Jovan', 'Jovani', 'Jovanny',
    'Jovany', 'Joy', 'Joyce', 'Juana', 'Juanita', 'Judah', 'Judd', 'Jude',
    'Judge', 'Judson', 'Judy', 'Jules', 'Julia', 'Julian', 'Juliana',
    'Julianne', 'Julie', 'Julien', 'Juliet', 'Julio', 'Julius', 'June',
    'Junior', 'Junius', 'Justen', 'Justice', 'Justina', 'Justine', 'Juston',
    'Justus', 'Justyn', 'Juvenal', 'Juwan', 'Kacey', 'Kaci', 'Kacie', 'Kade',
    'Kaden', 'Kadin', 'Kaela', 'Kaelyn', 'Kaia', 'Kailee', 'Kailey', 'Kailyn',
    'Kaitlin', 'Kaitlyn', 'Kale', 'Kaleb', 'Kaleigh', 'Kaley', 'Kali', 'Kallie',
    'Kameron', 'Kamille', 'Kamren', 'Kamron', 'Kamryn', 'Kane', 'Kara',
    'Kareem', 'Karelle', 'Karen', 'Kari', 'Kariane', 'Karianne', 'Karina',
    'Karine', 'Karl', 'Karlee', 'Karley', 'Karli', 'Karlie', 'Karolann',
    'Karson', 'Kasandra', 'Kasey', 'Kassandra', 'Katarina', 'Katelin',
    'Katelyn', 'Katelynn', 'Katharina', 'Katherine', 'Katheryn', 'Kathleen',
    'Kathlyn', 'Kathryn', 'Kathryne', 'Katlyn', 'Katlynn', 'Katrina', 'Katrine',
    'Kattie', 'Kavon', 'Kay', 'Kaya', 'Kaycee', 'Kayden', 'Kayla', 'Kaylah',
    'Kaylee', 'Kayleigh', 'Kayley', 'Kayli', 'Kaylie', 'Kaylin', 'Keagan',
    'Keanu', 'Keara', 'Keaton', 'Keegan', 'Keeley', 'Keely', 'Keenan', 'Keira',
    'Keith', 'Kellen', 'Kelley', 'Kelli', 'Kellie', 'Kelly', 'Kelsi', 'Kelsie',
    'Kelton', 'Kelvin', 'Ken', 'Kendall', 'Kendra', 'Kendrick', 'Kenna',
    'Kennedi', 'Kennedy', 'Kenneth', 'Kennith', 'Kenny', 'Kenton', 'Kenya',
    'Kenyatta', 'Kenyon', 'Keon', 'Keshaun', 'Keshawn', 'Keven', 'Kevin',
    'Kevon', 'Keyon', 'Keyshawn', 'Khalid', 'Khalil', 'Kian', 'Kiana', 'Kianna',
    'Kiara', 'Kiarra', 'Kiel', 'Kiera', 'Kieran', 'Kiley', 'Kim', 'Kimberly',
    'King', 'Kip', 'Kira', 'Kirk', 'Kirsten', 'Kirstin', 'Kitty', 'Kobe',
    'Koby', 'Kody', 'Kolby', 'Kole', 'Korbin', 'Korey', 'Kory', 'Kraig', 'Kris',
    'Krista', 'Kristian', 'Kristin', 'Kristina', 'Kristofer', 'Kristoffer',
    'Kristopher', 'Kristy', 'Krystal', 'Krystel', 'Krystina', 'Kurt', 'Kurtis',
    'Kyla', 'Kyle', 'Kylee', 'Kyleigh', 'Kyler', 'Kylie', 'Kyra', 'Lacey',
    'Lacy', 'Ladarius', 'Lafayette', 'Laila', 'Laisha', 'Lamar', 'Lambert',
    'Lamont', 'Lance', 'Landen', 'Lane', 'Laney', 'Larissa', 'Laron', 'Larry',
    'Larue', 'Laura', 'Laurel', 'Lauren', 'Laurence', 'Lauretta', 'Lauriane',
    'Laurianne', 'Laurie', 'Laurine', 'Laury', 'Lauryn', 'Lavada', 'Lavern',
    'Laverna', 'Laverne', 'Lavina', 'Lavinia', 'Lavon', 'Lavonne', 'Lawrence',
    'Lawson', 'Layla', 'Layne', 'Lazaro', 'Lea', 'Leann', 'Leanna', 'Leanne',
    'Leatha', 'Leda', 'Lee', 'Leif', 'Leila', 'Leilani', 'Lela', 'Lelah',
    'Leland', 'Lelia', 'Lempi', 'Lemuel', 'Lenna', 'Lennie', 'Lenny', 'Lenora',
    'Lenore', 'Leo', 'Leola', 'Leon', 'Leonard', 'Leonardo', 'Leone', 'Leonel',
    'Leonie', 'Leonor', 'Leonora', 'Leopold', 'Leopoldo', 'Leora', 'Lera',
    'Lesley', 'Leslie', 'Lesly', 'Lessie', 'Lester', 'Leta', 'Letha', 'Letitia',
    'Levi', 'Lew', 'Lewis', 'Lexi', 'Lexie', 'Lexus', 'Lia', 'Liam', 'Liana',
    'Libbie', 'Libby', 'Lila', 'Lilian', 'Liliana', 'Liliane', 'Lilla',
    'Lillian', 'Lilliana', 'Lillie', 'Lilly', 'Lily', 'Lilyan', 'Lina',
    'Lincoln', 'Linda', 'Lindsay', 'Lindsey', 'Linnea', 'Linnie', 'Linwood',
    'Lionel', 'Lisa', 'Lisandro', 'Lisette', 'Litzy', 'Liza', 'Lizeth',
    'Lizzie', 'Llewellyn', 'Lloyd', 'Logan', 'Lois', 'Lola', 'Lolita', 'Loma',
    'Lon', 'London', 'Lonie', 'Lonnie', 'Lonny', 'Lonzo', 'Lora', 'Loraine',
    'Loren', 'Lorena', 'Lorenz', 'Lorenza', 'Lorenzo', 'Lori', 'Lorine',
    'Lorna', 'Lottie', 'Lou', 'Louie', 'Louisa', 'Lourdes', 'Louvenia',
    'Lowell', 'Loy', 'Loyal', 'Loyce', 'Lucas', 'Luciano', 'Lucie', 'Lucienne',
    'Lucile', 'Lucinda', 'Lucio', 'Lucious', 'Lucius', 'Lucy', 'Ludie',
    'Ludwig', 'Lue', 'Luella', 'Luigi', 'Luis', 'Luisa', 'Lukas', 'Lula',
    'Lulu', 'Luna', 'Lupe', 'Lura', 'Lurline', 'Luther', 'Luz', 'Lyda', 'Lydia',
    'Lyla', 'Lynn', 'Lyric', 'Lysanne', 'Mabel', 'Mabelle', 'Mable', 'Mac',
    'Macey', 'Maci', 'Macie', 'Mack', 'Mackenzie', 'Macy', 'Madaline',
    'Madalyn', 'Maddison', 'Madeline', 'Madelyn', 'Madelynn', 'Madge', 'Madie',
    'Madilyn', 'Madisen', 'Madison', 'Madisyn', 'Madonna', 'Madyson', 'Mae',
    'Maegan', 'Maeve', 'Mafalda', 'Magali', 'Magdalen', 'Magdalena', 'Maggie',
    'Magnolia', 'Magnus', 'Maia', 'Maida', 'Maiya', 'Major', 'Makayla',
    'Makenna', 'Makenzie', 'Malachi', 'Malcolm', 'Malika', 'Malinda', 'Mallie',
    'Mallory', 'Malvina', 'Mandy', 'Manley', 'Manuel', 'Manuela', 'Mara',
    'Marc', 'Marcel', 'Marcelina', 'Marcelino', 'Marcella', 'Marcelle',
    'Marcellus', 'Marcelo', 'Marcia', 'Marco', 'Marcos', 'Marcus', 'Margaret',
    'Margarete', 'Margarett', 'Margaretta', 'Margarette', 'Margarita', 'Marge',
    'Margie', 'Margot', 'Margret', 'Marguerite', 'Maria', 'Mariah', 'Mariam',
    'Marian', 'Mariana', 'Mariane', 'Marianna', 'Marianne', 'Mariano',
    'Maribel', 'Marie', 'Mariela', 'Marielle', 'Marietta', 'Marilie', 'Marilou',
    'Marilyne', 'Marina', 'Mario', 'Marion', 'Marisa', 'Marisol', 'Maritza',
    'Marjolaine', 'Marjorie', 'Marjory', 'Mark', 'Markus', 'Marlee', 'Marlen',
    'Marlene', 'Marley', 'Marlin', 'Marlon', 'Marques', 'Marquis', 'Marquise',
    'Marshall', 'Marta', 'Martin', 'Martina', 'Martine', 'Marty', 'Marvin',
    'Mary', 'Maryam', 'Maryjane', 'Maryse', 'Mason', 'Mateo', 'Mathew',
    'Mathias', 'Mathilde', 'Matilda', 'Matilde', 'Matt', 'Matteo', 'Mattie',
    'Maud', 'Maude', 'Maudie', 'Maureen', 'Maurice', 'Mauricio', 'Maurine',
    'Maverick', 'Mavis', 'Max', 'Maxie', 'Maxime', 'Maximilian', 'Maximillia',
    'Maximillian', 'Maximo', 'Maximus', 'Maxine', 'Maxwell', 'May', 'Maya',
    'Maybell', 'Maybelle', 'Maye', 'Maymie', 'Maynard', 'Mayra', 'Mazie',
    'Mckayla', 'Mckenna', 'Mckenzie', 'Meagan', 'Meaghan', 'Meda', 'Megane',
    'Meggie', 'Meghan', 'Mekhi', 'Melany', 'Melba', 'Melisa', 'Melissa',
    'Mellie', 'Melody', 'Melvin', 'Melvina', 'Melyna', 'Melyssa', 'Mercedes',
    'Meredith', 'Merl', 'Merle', 'Merlin', 'Merritt', 'Mertie', 'Mervin',
    'Meta', 'Mia', 'Micaela', 'Micah', 'Michael', 'Michaela', 'Michale',
    'Micheal', 'Michel', 'Michele', 'Michelle', 'Miguel', 'Mikayla', 'Mike',
    'Mikel', 'Milan', 'Miles', 'Milford', 'Miller', 'Millie', 'Milo', 'Milton',
    'Mina', 'Minerva', 'Minnie', 'Miracle', 'Mireille', 'Mireya', 'Misael',
    'Missouri', 'Misty', 'Mitchel', 'Mitchell', 'Mittie', 'Modesta', 'Modesto',
    'Mohamed', 'Mohammad', 'Mohammed', 'Moises', 'Mollie', 'Molly', 'Mona',
    'Monica', 'Monique', 'Monroe', 'Monserrat', 'Monserrate', 'Montana',
    'Monte', 'Monty', 'Morgan', 'Moriah', 'Morris', 'Mortimer', 'Morton',
    'Mose', 'Moses', 'Moshe', 'Mossie', 'Mozell', 'Mozelle', 'Muhammad',
    'Muriel', 'Murl', 'Murphy', 'Murray', 'Mustafa', 'Mya', 'Myah', 'Mylene',
    'Myles', 'Myra', 'Myriam', 'Myrl', 'Myrna', 'Myron', 'Myrtice', 'Myrtie',
    'Myrtis', 'Myrtle', 'Nadia', 'Nakia', 'Name', 'Nannie', 'Naomi', 'Naomie',
    'Napoleon', 'Narciso', 'Nash', 'Nasir', 'Nat', 'Natalia', 'Natalie',
    'Natasha', 'Nathan', 'Nathanael', 'Nathanial', 'Nathaniel', 'Nathen',
    'Nayeli', 'Neal', 'Ned', 'Nedra', 'Neha', 'Neil', 'Nelda', 'Nella', 'Nelle',
    'Nellie', 'Nels', 'Nelson', 'Neoma', 'Nestor', 'Nettie', 'Neva', 'Newell',
    'Newton', 'Nia', 'Nicholas', 'Nicholaus', 'Nichole', 'Nick', 'Nicklaus',
    'Nickolas', 'Nico', 'Nicola', 'Nicolas', 'Nicole', 'Nicolette', 'Nigel',
    'Nikita', 'Nikki', 'Nikko', 'Niko', 'Nikolas', 'Nils', 'Nina', 'Noah',
    'Noble', 'Noe', 'Noel', 'Noelia', 'Noemi', 'Noemie', 'Noemy', 'Nola',
    'Nolan', 'Nona', 'Nora', 'Norbert', 'Norberto', 'Norene', 'Norma', 'Norris',
    'Norval', 'Norwood', 'Nova', 'Novella', 'Nya', 'Nyah', 'Nyasia', 'Obie',
    'Oceane', 'Ocie', 'Octavia', 'Oda', 'Odell', 'Odessa', 'Odie', 'Ofelia',
    'Okey', 'Ola', 'Olaf', 'Ole', 'Olen', 'Oleta', 'Olga', 'Olin', 'Oliver',
    'Ollie', 'Oma', 'Omari', 'Omer', 'Ona', 'Onie', 'Opal', 'Ophelia', 'Ora',
    'Oral', 'Oran', 'Oren', 'Orie', 'Orin', 'Orion', 'Orland', 'Orlando',
    'Orlo', 'Orpha', 'Orrin', 'Orval', 'Orville', 'Osbaldo', 'Osborne', 'Oscar',
    'Osvaldo', 'Oswald', 'Oswaldo', 'Otha', 'Otho', 'Otilia', 'Otis', 'Ottilie',
    'Ottis', 'Otto', 'Ova', 'Owen', 'Ozella', 'Pablo', 'Paige', 'Palma',
    'Pamela', 'Pansy', 'Paolo', 'Paris', 'Parker', 'Pascale', 'Pasquale', 'Pat',
    'Patience', 'Patricia', 'Patrick', 'Patsy', 'Pattie', 'Paul', 'Paula',
    'Pauline', 'Paxton', 'Payton', 'Pearl', 'Pearlie', 'Pearline', 'Pedro',
    'Peggie', 'Penelope', 'Percival', 'Percy', 'Perry', 'Pete', 'Peter',
    'Petra', 'Peyton', 'Philip', 'Phoebe', 'Phyllis', 'Pierce', 'Pierre',
    'Pietro', 'Pink', 'Pinkie', 'Piper', 'Polly', 'Porter', 'Precious',
    'Presley', 'Preston', 'Price', 'Prince', 'Princess', 'Priscilla',
    'Providenci', 'Prudence', 'Queen', 'Queenie', 'Quentin', 'Quincy', 'Quinn',
    'Quinten', 'Quinton', 'Rachael', 'Rachel', 'Rachelle', 'Rae', 'Raegan',
    'Rafael', 'Rafaela', 'Raheem', 'Rahsaan', 'Rahul', 'Raina', 'Raleigh',
    'Ralph', 'Ramiro', 'Ramon', 'Ramona', 'Randal', 'Randall', 'Randi', 'Randy',
    'Ransom', 'Raoul', 'Raphael', 'Raphaelle', 'Raquel', 'Rashad', 'Rashawn',
    'Rasheed', 'Raul', 'Raven', 'Ray', 'Raymond', 'Raymundo', 'Reagan',
    'Reanna', 'Reba', 'Rebeca', 'Rebecca', 'Rebeka', 'Rebekah', 'Reece', 'Reed',
    'Reese', 'Regan', 'Reggie', 'Reginald', 'Reid', 'Reilly', 'Reina',
    'Reinhold', 'Remington', 'Rene', 'Renee', 'Ressie', 'Reta', 'Retha',
    'Retta', 'Reuben', 'Reva', 'Rex', 'Rey', 'Reyes', 'Reymundo', 'Reyna',
    'Reynold', 'Rhea', 'Rhett', 'Rhianna', 'Rhiannon', 'Rhoda', 'Ricardo',
    'Richard', 'Richie', 'Richmond', 'Rick', 'Rickey', 'Rickie', 'Ricky',
    'Rico', 'Rigoberto', 'Riley', 'Rita', 'River', 'Robb', 'Robbie', 'Robert',
    'Roberta', 'Roberto', 'Robin', 'Robyn', 'Rocio', 'Rocky', 'Rod', 'Roderick',
    'Rodger', 'Rodolfo', 'Rodrick', 'Rodrigo', 'Roel', 'Rogelio', 'Roger',
    'Rogers', 'Rolando', 'Rollin', 'Roma', 'Romaine', 'Roman', 'Ron', 'Ronaldo',
    'Ronny', 'Roosevelt', 'Rory', 'Rosa', 'Rosalee', 'Rosalia', 'Rosalind',
    'Rosalinda', 'Rosalyn', 'Rosamond', 'Rosanna', 'Rosario', 'Roscoe', 'Rose',
    'Rosella', 'Roselyn', 'Rosemarie', 'Rosemary', 'Rosendo', 'Rosetta',
    'Rosie', 'Rosina', 'Roslyn', 'Ross', 'Rossie', 'Rowan', 'Rowena', 'Rowland',
    'Roxane', 'Roxanne', 'Roy', 'Royal', 'Royce', 'Rozella', 'Ruben', 'Rubie',
    'Ruby', 'Rubye', 'Rudolph', 'Rudy', 'Rupert', 'Russ', 'Russel', 'Russell',
    'Rusty', 'Ruth', 'Ruthe', 'Ruthie', 'Ryan', 'Ryann', 'Ryder', 'Rylan',
    'Rylee', 'Ryleigh', 'Ryley', 'Sabina', 'Sabrina', 'Sabryna', 'Sadie',
    'Sadye', 'Sage', 'Saige', 'Sallie', 'Sally', 'Salma', 'Salvador',
    'Salvatore', 'Sam', 'Samanta', 'Samantha', 'Samara', 'Samir', 'Sammie',
    'Sammy', 'Samson', 'Sandra', 'Sandrine', 'Sandy', 'Sanford', 'Santa',
    'Santiago', 'Santina', 'Santino', 'Santos', 'Sarah', 'Sarai', 'Sarina',
    'Sasha', 'Saul', 'Savanah', 'Savanna', 'Savannah', 'Savion', 'Scarlett',
    'Schuyler', 'Scot', 'Scottie', 'Scotty', 'Seamus', 'Sean', 'Sebastian',
    'Sedrick', 'Selena', 'Selina', 'Selmer', 'Serena', 'Serenity', 'Seth',
    'Shad', 'Shaina', 'Shakira', 'Shana', 'Shane', 'Shanel', 'Shanelle',
    'Shania', 'Shanie', 'Shaniya', 'Shanna', 'Shannon', 'Shanny', 'Shanon',
    'Shany', 'Sharon', 'Shaun', 'Shawn', 'Shawna', 'Shaylee', 'Shayna',
    'Shayne', 'Shea', 'Sheila', 'Sheldon', 'Shemar', 'Sheridan', 'Sherman',
    'Sherwood', 'Shirley', 'Shyann', 'Shyanne', 'Sibyl', 'Sid', 'Sidney',
    'Sienna', 'Sierra', 'Sigmund', 'Sigrid', 'Sigurd', 'Silas', 'Sim', 'Simeon',
    'Simone', 'Sincere', 'Sister', 'Skye', 'Skyla', 'Skylar', 'Sofia',
    'Soledad', 'Solon', 'Sonia', 'Sonny', 'Sonya', 'Sophia', 'Sophie',
    'Spencer', 'Stacey', 'Stacy', 'Stan', 'Stanford', 'Stanley', 'Stanton',
    'Stefan', 'Stefanie', 'Stella', 'Stephan', 'Stephania', 'Stephanie',
    'Stephany', 'Stephen', 'Stephon', 'Sterling', 'Steve', 'Stevie', 'Stewart',
    'Stone', 'Stuart', 'Summer', 'Sunny', 'Susan', 'Susana', 'Susanna', 'Susie',
    'Suzanne', 'Sven', 'Syble', 'Sydnee', 'Sydney', 'Sydni', 'Sydnie', 'Sylvan',
    'Sylvester', 'Sylvia', 'Tabitha', 'Tad', 'Talia', 'Talon', 'Tamara',
    'Tamia', 'Tania', 'Tanner', 'Tanya', 'Tara', 'Taryn', 'Tate', 'Tatum',
    'Tatyana', 'Taurean', 'Tavares', 'Taya', 'Taylor', 'Teagan', 'Ted', 'Telly',
    'Terence', 'Teresa', 'Terrance', 'Terrell', 'Terrence', 'Terrill', 'Terry',
    'Tess', 'Tessie', 'Tevin', 'Thad', 'Thaddeus', 'Thalia', 'Thea', 'Thelma',
    'Theo', 'Theodora', 'Theodore', 'Theresa', 'Therese', 'Theresia', 'Theron',
    'Thomas', 'Thora', 'Thurman', 'Tia', 'Tiana', 'Tianna', 'Tiara', 'Tierra',
    'Tiffany', 'Tillman', 'Timmothy', 'Timmy', 'Timothy', 'Tina', 'Tito',
    'Titus', 'Tobin', 'Toby', 'Tod', 'Tom', 'Tomas', 'Tomasa', 'Tommie',
    'Toney', 'Toni', 'Tony', 'Torey', 'Torrance', 'Torrey', 'Toy', 'Trace',
    'Tracey', 'Tracy', 'Travis', 'Travon', 'Tre', 'Tremaine', 'Tremayne',
    'Trent', 'Trenton', 'Tressa', 'Tressie', 'Treva', 'Trever', 'Trevion',
    'Trevor', 'Trey', 'Trinity', 'Trisha', 'Tristian', 'Tristin', 'Triston',
    'Troy', 'Trudie', 'Trycia', 'Trystan', 'Turner', 'Twila', 'Tyler', 'Tyra',
    'Tyree', 'Tyreek', 'Tyrel', 'Tyrell', 'Tyrese', 'Tyrique', 'Tyshawn',
    'Tyson', 'Ubaldo', 'Ulices', 'Ulises', 'Una', 'Unique', 'Urban', 'Uriah',
    'Uriel', 'Ursula', 'Vada', 'Valentin', 'Valentina', 'Valentine', 'Valerie',
    'Vallie', 'Van', 'Vance', 'Vanessa', 'Vaughn', 'Veda', 'Velda', 'Vella',
    'Velma', 'Velva', 'Vena', 'Verda', 'Verdie', 'Vergie', 'Verla', 'Verlie',
    'Vern', 'Verna', 'Verner', 'Vernice', 'Vernie', 'Vernon', 'Verona',
    'Veronica', 'Vesta', 'Vicenta', 'Vicente', 'Vickie', 'Vicky', 'Victor',
    'Victoria', 'Vida', 'Vidal', 'Vilma', 'Vince', 'Vincent', 'Vincenza',
    'Vincenzo', 'Vinnie', 'Viola', 'Violet', 'Violette', 'Virgie', 'Virgil',
    'Virginia', 'Virginie', 'Vita', 'Vito', 'Viva', 'Vivian', 'Viviane',
    'Vivianne', 'Vivien', 'Vivienne', 'Vladimir', 'Wade', 'Waino', 'Waldo',
    'Walker', 'Wallace', 'Walter', 'Walton', 'Wanda', 'Ward', 'Warren',
    'Watson', 'Wava', 'Waylon', 'Wayne', 'Webster', 'Weldon', 'Wellington',
    'Wendell', 'Wendy', 'Werner', 'Westley', 'Weston', 'Whitney', 'Wilber',
    'Wilbert', 'Wilburn', 'Wiley', 'Wilford', 'Wilfred', 'Wilfredo', 'Wilfrid',
    'Wilhelm', 'Wilhelmine', 'Will', 'Willa', 'Willard', 'William', 'Willie',
    'Willis', 'Willow', 'Willy', 'Wilma', 'Wilmer', 'Wilson', 'Wilton',
    'Winfield', 'Winifred', 'Winnifred', 'Winona', 'Winston', 'Woodrow',
    'Wyatt', 'Wyman', 'Xander', 'Xavier', 'Xzavier', 'Yadira', 'Yasmeen',
    'Yasmin', 'Yasmine', 'Yazmin', 'Yesenia', 'Yessenia', 'Yolanda', 'Yoshiko',
    'Yvette', 'Yvonne', 'Zachariah', 'Zachary', 'Zachery', 'Zack', 'Zackary',
    'Zackery', 'Zakary', 'Zander', 'Zane', 'Zaria', 'Zechariah', 'Zelda',
    'Zella', 'Zelma', 'Zena', 'Zetta', 'Zion', 'Zita', 'Zoe', 'Zoey', 'Zoie',
    'Zoila', 'Zola', 'Zora', 'Zula'
];
/**
 * Generate random username.
 * @returns {string} random username
 */
function generateUsername() {
    const name = RandomUtil.randomElement(names);
    const suffix = RandomUtil.randomAlphanumStr(3);
    return `${name}-${suffix}`;
}
module.exports = {
    generateUsername
};
//# sourceMappingURL=UsernameGenerator.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/version/ComponentsVersions.js":
/*!*******************************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/version/ComponentsVersions.js ***!
  \*******************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
var __filename = "/index.js";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (/* binding */ ComponentsVersions)
/* harmony export */ });
/* harmony import */ var _statistics_statistics__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../statistics/statistics */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/statistics/statistics.js");

const logger = (__webpack_require__(/*! @jitsi/logger */ "./node_modules/@jitsi/logger/lib/index.js").getLogger)(__filename);
/**
 * Creates new instance of <tt>ComponentsVersions</tt> which will be discovering
 * the versions of conferencing system components in given
 * <tt>JitsiConference</tt>.
 * @param conference <tt>JitsiConference</tt> instance which will be used to
 *        listen for focus presence updates.
 * @constructor
 */
function ComponentsVersions(conference) {
    this.versions = {};
    this.conference = conference;
    this.conference.addCommandListener('versions', this.processVersions.bind(this));
}
ComponentsVersions.prototype.processVersions
    = function (versions, mucResource, mucJid) {
        if (!this.conference.isFocus(mucJid)) {
            logger.warn(`Received versions not from the focus user: ${versions}`, mucJid);
            return;
        }
        const log = [];
        versions.children.forEach(component => {
            const name = component.attributes.name;
            const version = component.value;
            if (this.versions[name] !== version) {
                this.versions[name] = version;
                logger.info(`Got ${name} version: ${version}`);
                log.push({
                    id: 'component_version',
                    component: name,
                    version
                });
            }
        });
        // logs versions to stats
        if (log.length > 0) {
            _statistics_statistics__WEBPACK_IMPORTED_MODULE_0__["default"].sendLog(JSON.stringify(log));
        }
    };
/**
 * Obtains the version of conferencing system component.
 * @param componentName the name of the component for which we want to obtain
 *        the version.
 * @returns {String} which describes the version of the component identified by
 *          given <tt>componentName</tt> or <tt>undefined</tt> if not found.
 */
ComponentsVersions.prototype.getComponentVersion = function (componentName) {
    return this.versions[componentName];
};
//# sourceMappingURL=ComponentsVersions.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/videosipgw/JitsiVideoSIPGWSession.js":
/*!**************************************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/videosipgw/JitsiVideoSIPGWSession.js ***!
  \**************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
var __filename = "/index.js";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (/* binding */ JitsiVideoSIPGWSession)
/* harmony export */ });
/* harmony import */ var _jitsi_logger__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @jitsi/logger */ "./node_modules/@jitsi/logger/lib/index.js");
/* harmony import */ var _jitsi_logger__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(_jitsi_logger__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var strophe_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! strophe.js */ "./node_modules/strophe.js/dist/strophe.umd.js");
/* harmony import */ var strophe_js__WEBPACK_IMPORTED_MODULE_1___default = /*#__PURE__*/__webpack_require__.n(strophe_js__WEBPACK_IMPORTED_MODULE_1__);
/* harmony import */ var _util_Listenable__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../util/Listenable */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/util/Listenable.js");
/* harmony import */ var _VideoSIPGWConstants__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./VideoSIPGWConstants */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/videosipgw/VideoSIPGWConstants.js");




const logger = (0,_jitsi_logger__WEBPACK_IMPORTED_MODULE_0__.getLogger)(__filename);
/**
 * The event name for current sip video session state changed.
 * @type {string} event name for sip video session state changed.
 */
const STATE_CHANGED = 'STATE_CHANGED';
/**
 * Jitsi video SIP GW session. Holding its state and able to start/stop it.
 * When session is in OFF or FAILED stated it cannot be used anymore.
 */
class JitsiVideoSIPGWSession extends _util_Listenable__WEBPACK_IMPORTED_MODULE_2__["default"] {
    /**
     * Creates new session with the desired sip address and display name.
     *
     * @param {string} sipAddress - The sip address to use when
     * starting the session.
     * @param {string} displayName - The display name to use for
     * that participant.
     * @param {ChatRoom} chatRoom - The chat room this session is bound to.
     */
    constructor(sipAddress, displayName, chatRoom) {
        super();
        this.sipAddress = sipAddress;
        this.displayName = displayName;
        this.chatRoom = chatRoom;
        /*
         * The initial state is undefined. Initial state cannot be STATE_OFF,
         * the session enters this state when it was in STATE_ON and was stopped
         * and such session cannot be used anymore.
         *
         * @type {VideoSIPGWConstants|undefined}
         */
        this.state = undefined;
    }
    /**
     * Stops the current session.
     */
    stop() {
        if (this.state === _VideoSIPGWConstants__WEBPACK_IMPORTED_MODULE_3__.STATE_OFF
            || this.state === _VideoSIPGWConstants__WEBPACK_IMPORTED_MODULE_3__.STATE_FAILED) {
            logger.warn('Video SIP GW session already stopped or failed!');
            return;
        }
        this._sendJibriIQ('stop');
    }
    /**
     * Starts a new session. Sends an iq to the focus.
     */
    start() {
        // if state is off, this session was active for some reason
        // and we should create new one, rather than reusing it
        if (this.state === _VideoSIPGWConstants__WEBPACK_IMPORTED_MODULE_3__.STATE_ON
            || this.state === _VideoSIPGWConstants__WEBPACK_IMPORTED_MODULE_3__.STATE_OFF
            || this.state === _VideoSIPGWConstants__WEBPACK_IMPORTED_MODULE_3__.STATE_PENDING
            || this.state === _VideoSIPGWConstants__WEBPACK_IMPORTED_MODULE_3__.STATE_RETRYING) {
            logger.warn('Video SIP GW session already started!');
            return;
        }
        this._sendJibriIQ('start');
    }
    /**
     * Changes the state of this session.
     *
     * @param {string} newState - The new {VideoSIPGWConstants} state to set.
     * @param {string} [optional] failureReason - The reason why a failure state
     * was entered.
     * @returns {void}
     */
    setState(newState, failureReason) {
        if (newState === this.state) {
            return;
        }
        const oldState = this.state;
        this.state = newState;
        this.eventEmitter.emit(STATE_CHANGED, {
            address: this.sipAddress,
            failureReason,
            oldState,
            newState: this.state,
            displayName: this.displayName
        });
    }
    /**
     * Subscribes the passed listener to the event for state change of this
     * session.
     *
     * @param {Function} listener - The function that will receive the event.
     */
    addStateListener(listener) {
        this.addListener(STATE_CHANGED, listener);
    }
    /**
     * Unsubscribes the passed handler.
     *
     * @param {Function} listener - The function to be removed.
     */
    removeStateListener(listener) {
        this.removeListener(STATE_CHANGED, listener);
    }
    /**
     * Sends a jibri command using an iq.
     *
     * @private
     * @param {string} action - The action to send ('start' or 'stop').
     */
    _sendJibriIQ(action) {
        const attributes = {
            'xmlns': 'http://jitsi.org/protocol/jibri',
            'action': action,
            sipaddress: this.sipAddress
        };
        attributes.displayname = this.displayName;
        const iq = (0,strophe_js__WEBPACK_IMPORTED_MODULE_1__.$iq)({
            to: this.chatRoom.focusMucJid,
            type: 'set'
        })
            .c('jibri', attributes)
            .up();
        logger.debug(`${action} video SIP GW session`, iq.nodeTree);
        this.chatRoom.connection.sendIQ(iq, () => { }, // eslint-disable-line no-empty-function
        // eslint-disable-line no-empty-function
        error => {
            logger.error(`Failed to ${action} video SIP GW session, error: `, error);
            this.setState(_VideoSIPGWConstants__WEBPACK_IMPORTED_MODULE_3__.STATE_FAILED);
        });
    }
}
//# sourceMappingURL=JitsiVideoSIPGWSession.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/videosipgw/VideoSIPGW.js":
/*!**************************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/videosipgw/VideoSIPGW.js ***!
  \**************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
var __filename = "/index.js";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (/* binding */ VideoSIPGW)
/* harmony export */ });
/* harmony import */ var _jitsi_logger__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @jitsi/logger */ "./node_modules/@jitsi/logger/lib/index.js");
/* harmony import */ var _jitsi_logger__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(_jitsi_logger__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var _service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../service/xmpp/XMPPEvents */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/xmpp/XMPPEvents.js");
/* harmony import */ var _JitsiVideoSIPGWSession__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./JitsiVideoSIPGWSession */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/videosipgw/JitsiVideoSIPGWSession.js");
/* harmony import */ var _VideoSIPGWConstants__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./VideoSIPGWConstants */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/videosipgw/VideoSIPGWConstants.js");

const logger = (0,_jitsi_logger__WEBPACK_IMPORTED_MODULE_0__.getLogger)(__filename);



/**
 * Main video SIP GW handler. Stores references of all created sessions.
 */
class VideoSIPGW {
    /**
     * Creates new handler.
     *
     * @param {ChatRoom} chatRoom - Tha chat room to handle.
     */
    constructor(chatRoom) {
        this.chatRoom = chatRoom;
        this.eventEmitter = chatRoom.eventEmitter;
        logger.debug('creating VideoSIPGW');
        this.sessions = {};
        this.sessionStateChangeListener = this.sessionStateChanged.bind(this);
        // VideoSIPGW, JitsiConference and ChatRoom are not reusable and no
        // more than one VideoSIPGW can be created per JitsiConference,
        // so we don't bother to cleanup
        chatRoom.addPresenceListener('jibri-sip-call-state', this.handleJibriSIPState.bind(this));
    }
    /**
     * Handles presence nodes with name: jibri-sip-call-state.
     *
     * @param {Object} node the presence node Object to handle.
     * Object representing part of the presence received over xmpp.
     */
    handleJibriSIPState(node) {
        const attributes = node.attributes;
        if (!attributes) {
            return;
        }
        logger.debug('Handle video sip gw state : ', attributes);
        const newState = attributes.state;
        if (newState === this.state) {
            return;
        }
        switch (newState) {
            case _VideoSIPGWConstants__WEBPACK_IMPORTED_MODULE_3__.STATE_ON:
            case _VideoSIPGWConstants__WEBPACK_IMPORTED_MODULE_3__.STATE_OFF:
            case _VideoSIPGWConstants__WEBPACK_IMPORTED_MODULE_3__.STATE_PENDING:
            case _VideoSIPGWConstants__WEBPACK_IMPORTED_MODULE_3__.STATE_RETRYING:
            case _VideoSIPGWConstants__WEBPACK_IMPORTED_MODULE_3__.STATE_FAILED: {
                const address = attributes.sipaddress;
                if (!address) {
                    return;
                }
                // find the corresponding session and set its state
                const session = this.sessions[address];
                if (session) {
                    session.setState(newState, attributes.failure_reason);
                }
                else {
                    logger.warn('Video SIP GW session not found:', address);
                }
            }
        }
    }
    /**
     * Creates new session and stores its reference if it does not exist or
     * returns an error otherwise.
     *
     * @param {string} sipAddress - The sip address to use.
     * @param {string} displayName - The display name to use.
     * @returns {JitsiVideoSIPGWSession|Error}
     */
    createVideoSIPGWSession(sipAddress, displayName) {
        if (this.sessions[sipAddress]) {
            logger.warn('There was already a Video SIP GW session for address', sipAddress);
            return new Error(_VideoSIPGWConstants__WEBPACK_IMPORTED_MODULE_3__.ERROR_SESSION_EXISTS);
        }
        const session = new _JitsiVideoSIPGWSession__WEBPACK_IMPORTED_MODULE_2__["default"](sipAddress, displayName, this.chatRoom);
        session.addStateListener(this.sessionStateChangeListener);
        this.sessions[sipAddress] = session;
        return session;
    }
    /**
     * Listener for session state changed. When a session goes to off or failed
     * we delete its reference.
     *
     * @param {options} event - { address, oldState, newState, displayName }
     */
    sessionStateChanged(event) {
        const address = event.address;
        if (event.newState === _VideoSIPGWConstants__WEBPACK_IMPORTED_MODULE_3__.STATE_OFF
            || event.newState === _VideoSIPGWConstants__WEBPACK_IMPORTED_MODULE_3__.STATE_FAILED) {
            const session = this.sessions[address];
            if (!session) {
                logger.error('Missing Video SIP GW session with address:', address);
                return;
            }
            session.removeStateListener(this.sessionStateChangeListener);
            delete this.sessions[address];
        }
        this.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_1__.XMPPEvents.VIDEO_SIP_GW_SESSION_STATE_CHANGED, event);
    }
}
//# sourceMappingURL=VideoSIPGW.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/videosipgw/VideoSIPGWConstants.js":
/*!***********************************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/videosipgw/VideoSIPGWConstants.js ***!
  \***********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   ERROR_NO_CONNECTION: () => (/* binding */ ERROR_NO_CONNECTION),
/* harmony export */   ERROR_SESSION_EXISTS: () => (/* binding */ ERROR_SESSION_EXISTS),
/* harmony export */   STATE_FAILED: () => (/* binding */ STATE_FAILED),
/* harmony export */   STATE_OFF: () => (/* binding */ STATE_OFF),
/* harmony export */   STATE_ON: () => (/* binding */ STATE_ON),
/* harmony export */   STATE_PENDING: () => (/* binding */ STATE_PENDING),
/* harmony export */   STATE_RETRYING: () => (/* binding */ STATE_RETRYING),
/* harmony export */   STATUS_AVAILABLE: () => (/* binding */ STATUS_AVAILABLE),
/* harmony export */   STATUS_BUSY: () => (/* binding */ STATUS_BUSY),
/* harmony export */   STATUS_UNDEFINED: () => (/* binding */ STATUS_UNDEFINED),
/* harmony export */   VideoSIPGWErrorConstants: () => (/* binding */ VideoSIPGWErrorConstants),
/* harmony export */   VideoSIPGWStateConstants: () => (/* binding */ VideoSIPGWStateConstants),
/* harmony export */   VideoSIPGWStatusConstants: () => (/* binding */ VideoSIPGWStatusConstants)
/* harmony export */ });
var VideoSIPGWStatusConstants;
(function (VideoSIPGWStatusConstants) {
    /**
     * Status that video SIP GW service is available.
     */
    VideoSIPGWStatusConstants["STATUS_AVAILABLE"] = "available";
    /**
     * Status that video SIP GW service is not available.
     */
    VideoSIPGWStatusConstants["STATUS_UNDEFINED"] = "undefined";
    /**
     * Status that video SIP GW service is available but there are no free nodes
     * at the moment to serve new requests.
     */
    VideoSIPGWStatusConstants["STATUS_BUSY"] = "busy";
})(VideoSIPGWStatusConstants || (VideoSIPGWStatusConstants = {}));
;
var VideoSIPGWStateConstants;
(function (VideoSIPGWStateConstants) {
    /**
     * Video SIP GW session state, currently running.
     */
    VideoSIPGWStateConstants["STATE_ON"] = "on";
    /**
     * Video SIP GW session state, currently stopped and not running.
     */
    VideoSIPGWStateConstants["STATE_OFF"] = "off";
    /**
     * Video SIP GW session state, currently is starting.
     */
    VideoSIPGWStateConstants["STATE_PENDING"] = "pending";
    /**
     * Video SIP GW session state, has observed some issues and is retrying at the
     * moment.
     */
    VideoSIPGWStateConstants["STATE_RETRYING"] = "retrying";
    /**
     * Video SIP GW session state, tried to start but it failed.
     */
    VideoSIPGWStateConstants["STATE_FAILED"] = "failed";
})(VideoSIPGWStateConstants || (VideoSIPGWStateConstants = {}));
;
var VideoSIPGWErrorConstants;
(function (VideoSIPGWErrorConstants) {
    /**
     * Error on trying to create video SIP GW session in conference where
     * there is no room connection (hasn't joined or has left the room).
     */
    VideoSIPGWErrorConstants["ERROR_NO_CONNECTION"] = "error_no_connection";
    /**
     * Error on trying to create video SIP GW session with address for which
     * there is an already created session.
     */
    VideoSIPGWErrorConstants["ERROR_SESSION_EXISTS"] = "error_session_already_exists";
})(VideoSIPGWErrorConstants || (VideoSIPGWErrorConstants = {}));
;
// exported for backward compatibility
const STATUS_AVAILABLE = VideoSIPGWStatusConstants.STATUS_AVAILABLE;
const STATUS_UNDEFINED = VideoSIPGWStatusConstants.STATUS_UNDEFINED;
const STATUS_BUSY = VideoSIPGWStatusConstants.STATUS_BUSY;
const STATE_ON = VideoSIPGWStateConstants.STATE_ON;
const STATE_OFF = VideoSIPGWStateConstants.STATE_OFF;
const STATE_PENDING = VideoSIPGWStateConstants.STATE_PENDING;
const STATE_RETRYING = VideoSIPGWStateConstants.STATE_RETRYING;
const STATE_FAILED = VideoSIPGWStateConstants.STATE_FAILED;
const ERROR_NO_CONNECTION = VideoSIPGWErrorConstants.ERROR_NO_CONNECTION;
const ERROR_SESSION_EXISTS = VideoSIPGWErrorConstants.ERROR_SESSION_EXISTS;
//# sourceMappingURL=VideoSIPGWConstants.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/watchRTC/WatchRTC.js":
/*!**********************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/watchRTC/WatchRTC.js ***!
  \**********************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
var __filename = "/index.js";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (__WEBPACK_DEFAULT_EXPORT__)
/* harmony export */ });
/* harmony import */ var _jitsi_logger__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @jitsi/logger */ "./node_modules/@jitsi/logger/lib/index.js");
/* harmony import */ var _jitsi_logger__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(_jitsi_logger__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var _testrtc_watchrtc_sdk__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! @testrtc/watchrtc-sdk */ "./node_modules/@testrtc/watchrtc-sdk/lib/index.js");
/* harmony import */ var _testrtc_watchrtc_sdk__WEBPACK_IMPORTED_MODULE_1___default = /*#__PURE__*/__webpack_require__.n(_testrtc_watchrtc_sdk__WEBPACK_IMPORTED_MODULE_1__);
/* harmony import */ var _functions__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./functions */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/watchRTC/functions.js");



const logger = _jitsi_logger__WEBPACK_IMPORTED_MODULE_0___default().getLogger(__filename);
/**
 * Class that controls the watchRTC flow, because it overwrites and proxies global function it should only be
 * initialized once.
 */
class WatchRTCHandler {
    /**
     * Initialize watchRTC, it overwrites GUM and PeerConnection global functions and adds a proxy over them
     * used to capture stats.
     *
     * @param {Object} options - Init options.
     * @returns {void}
     */
    init(options) {
        var _a;
        if ((0,_functions__WEBPACK_IMPORTED_MODULE_2__.isWatchRTCEnabled)(options)) {
            if (!(0,_functions__WEBPACK_IMPORTED_MODULE_2__.isAnalyticsEnabled)(options)) {
                logger.error('Cannot initialize WatchRTC when analytics or third party requests are disabled.');
                return;
            }
            if ((0,_functions__WEBPACK_IMPORTED_MODULE_2__.isRtcstatsEnabled)(options)) {
                logger.error('Cannot initialize WatchRTC when RTCStats is enabled.');
                return;
            }
            try {
                if ((_a = options === null || options === void 0 ? void 0 : options.watchRTCConfigParams) === null || _a === void 0 ? void 0 : _a.rtcApiKey) {
                    _testrtc_watchrtc_sdk__WEBPACK_IMPORTED_MODULE_1___default().init({
                        rtcApiKey: options.watchRTCConfigParams.rtcApiKey,
                    });
                    this.options = options.watchRTCConfigParams;
                    logger.info('WatchRTC initialized.');
                }
                else {
                    logger.error('WatchRTC is enabled but missing API key.');
                }
            }
            catch (error) {
                logger.error('Failed to initialize WatchRTC: ', error);
            }
        }
    }
    /**
     * Begin watchRTC session considering roomName and userName if already not available
     *
     * @param {string} roomName - The room name we are currently in.
     * @param {string} userName - The user name. This value is obtained from
     * JitsiConference.prototype.myUserId
     * @returns {void}
     */
    start(roomName, userName) {
        try {
            if (this.options) {
                this.options.rtcRoomId = this.options.rtcRoomId ? this.options.rtcRoomId : roomName;
                this.options.rtcPeerId = this.options.rtcPeerId ? this.options.rtcPeerId : userName;
                _testrtc_watchrtc_sdk__WEBPACK_IMPORTED_MODULE_1___default().persistentEnd();
                _testrtc_watchrtc_sdk__WEBPACK_IMPORTED_MODULE_1___default().setConfig(this.options);
                logger.info('WatchRTC setConfig.');
            }
        }
        catch (error) {
            logger.error('Failed to start WatchRTC session: ', error);
        }
    }
}
/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (new WatchRTCHandler());
//# sourceMappingURL=WatchRTC.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/watchRTC/functions.js":
/*!***********************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/watchRTC/functions.js ***!
  \***********************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   isAnalyticsEnabled: () => (/* binding */ isAnalyticsEnabled),
/* harmony export */   isRtcstatsEnabled: () => (/* binding */ isRtcstatsEnabled),
/* harmony export */   isWatchRTCEnabled: () => (/* binding */ isWatchRTCEnabled)
/* harmony export */ });
/**
 * Checks whether analytics is enabled or not.
 *
 * @param {Object} options - Init options.
 * @returns {boolean}
 */
function isAnalyticsEnabled(options) {
    const { analytics, disableThirdPartyRequests } = options;
    return !((analytics === null || analytics === void 0 ? void 0 : analytics.disabled) || disableThirdPartyRequests);
}
/**
 * Checks whether rtcstats is enabled or not.
 *
 * @param {Object} options - Init options.
 * @returns {boolean}
 */
function isRtcstatsEnabled(options) {
    var _a;
    const { analytics } = options;
    return (_a = analytics === null || analytics === void 0 ? void 0 : analytics.rtcstatsEnabled) !== null && _a !== void 0 ? _a : false;
}
/**
 * Checks whether watchrtc is enabled or not.
 *
 * @param {Object} options - Init options.
 * @returns {boolean}
 */
function isWatchRTCEnabled(options) {
    var _a;
    const { analytics } = options;
    return (_a = analytics === null || analytics === void 0 ? void 0 : analytics.watchRTCEnabled) !== null && _a !== void 0 ? _a : false;
}
//# sourceMappingURL=functions.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/webaudio/AudioMixer.js":
/*!************************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/webaudio/AudioMixer.js ***!
  \************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
var __filename = "/index.js";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (/* binding */ AudioMixer)
/* harmony export */ });
/* harmony import */ var _jitsi_logger__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @jitsi/logger */ "./node_modules/@jitsi/logger/lib/index.js");
/* harmony import */ var _jitsi_logger__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(_jitsi_logger__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var _WebAudioUtils__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./WebAudioUtils */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/webaudio/WebAudioUtils.js");


const logger = (0,_jitsi_logger__WEBPACK_IMPORTED_MODULE_0__.getLogger)(__filename);
/**
 * The AudioMixer, as the name implies, mixes a number of MediaStreams containing audio tracks into a single
 * MediaStream.
 */
class AudioMixer {
    /**
     * Create AudioMixer instance.
     */
    constructor() {
        this._started = false;
        this._streamsToMix = [];
        this._streamMSSArray = [];
    }
    /**
     * Add audio MediaStream to be mixed, if the stream doesn't contain any audio tracks it will be ignored.
     *
     * @param {MediaStream} stream - MediaStream to be mixed.
     */
    addMediaStream(stream) {
        if (!stream.getAudioTracks()) {
            logger.warn('Added MediaStream doesn\'t contain audio tracks.');
        }
        this._streamsToMix.push(stream);
    }
    /**
     * At this point a WebAudio ChannelMergerNode is created and and the two associated MediaStreams are connected to
     * it; the resulting mixed MediaStream is returned.
     *
     * @returns {MediaStream} - MediaStream containing added streams mixed together, or null if no MediaStream
     * is added.
     */
    start() {
        // If the mixer was already started just return the existing mixed stream.
        if (this._started) {
            return this._mixedMSD.stream;
        }
        this._audioContext = (0,_WebAudioUtils__WEBPACK_IMPORTED_MODULE_1__.createAudioContext)();
        if (!this._streamsToMix.length) {
            logger.warn('No MediaStream\'s added to AudioMixer, nothing will happen.');
            return null;
        }
        this._started = true;
        this._mixedMSD = this._audioContext.createMediaStreamDestination();
        for (const stream of this._streamsToMix) {
            const streamMSS = this._audioContext.createMediaStreamSource(stream);
            streamMSS.connect(this._mixedMSD);
            // Maintain a list of MediaStreamAudioSourceNode so we can disconnect them on reset.
            this._streamMSSArray.push(streamMSS);
        }
        return this._mixedMSD.stream;
    }
    /**
     * Disconnect MediaStreamAudioSourceNode and clear references.
     *
     * @returns {void}
     */
    reset() {
        this._started = false;
        this._streamsToMix = [];
        // Clean up created MediaStreamAudioSourceNode.
        for (const streamMSS of this._streamMSSArray) {
            streamMSS.disconnect();
        }
        this._streamMSSArray = [];
        if (this._audioContext) {
            this._audioContext = undefined;
        }
    }
}
//# sourceMappingURL=AudioMixer.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/webaudio/WebAudioUtils.js":
/*!***************************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/webaudio/WebAudioUtils.js ***!
  \***************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   createAudioContext: () => (/* binding */ createAudioContext)
/* harmony export */ });
/**
 * Adapter that creates AudioContext objects depending on the browser.
 *
 * @returns {AudioContext} - Return a new AudioContext or undefined if the browser does not support it.
 */
function createAudioContext(options) {
    const AudioContextImpl = window.AudioContext || window.webkitAudioContext;
    if (!AudioContextImpl) {
        return undefined;
    }
    return new AudioContextImpl(options);
}
//# sourceMappingURL=WebAudioUtils.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/xmpp/AVModeration.js":
/*!**********************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/xmpp/AVModeration.js ***!
  \**********************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
var __filename = "/index.js";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (/* binding */ AVModeration)
/* harmony export */ });
/* harmony import */ var _jitsi_logger__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @jitsi/logger */ "./node_modules/@jitsi/logger/lib/index.js");
/* harmony import */ var _jitsi_logger__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(_jitsi_logger__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var strophe_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! strophe.js */ "./node_modules/strophe.js/dist/strophe.umd.js");
/* harmony import */ var strophe_js__WEBPACK_IMPORTED_MODULE_1___default = /*#__PURE__*/__webpack_require__.n(strophe_js__WEBPACK_IMPORTED_MODULE_1__);
/* harmony import */ var _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../service/RTC/MediaType */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/RTC/MediaType.js");
/* harmony import */ var _service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../service/xmpp/XMPPEvents */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/xmpp/XMPPEvents.js");




const logger = (0,_jitsi_logger__WEBPACK_IMPORTED_MODULE_0__.getLogger)(__filename);
/**
 * The AVModeration logic.
 */
class AVModeration {
    /**
     * Constructs AV moderation room.
     *
     * @param {ChatRoom} room the main room.
     */
    constructor(room) {
        this._xmpp = room.xmpp;
        this._mainRoom = room;
        this._moderationEnabledByType = {
            [_service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_2__.MediaType.AUDIO]: false,
            [_service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_2__.MediaType.VIDEO]: false
        };
        this._whitelistAudio = [];
        this._whitelistVideo = [];
        this._onMessage = this._onMessage.bind(this);
        this._xmpp.addListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_3__.XMPPEvents.AV_MODERATION_RECEIVED, this._onMessage);
    }
    /**
     * Stops listening for events.
     */
    dispose() {
        this._xmpp.removeListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_3__.XMPPEvents.AV_MODERATION_RECEIVED, this._onMessage);
    }
    /**
     * Whether AV moderation is supported on backend.
     *
     * @returns {boolean} whether AV moderation is supported on backend.
     */
    isSupported() {
        return Boolean(this._xmpp.avModerationComponentAddress);
    }
    /**
     * Enables or disables AV Moderation by sending a msg with command to the component.
     */
    enable(state, mediaType) {
        if (!this.isSupported() || !this._mainRoom.isModerator()) {
            logger.error(`Cannot enable:${state} AV moderation supported:${this.isSupported()},
                moderator:${this._mainRoom.isModerator()}`);
            return;
        }
        if (state === this._moderationEnabledByType[mediaType]) {
            logger.warn(`Moderation already in state:${state} for mediaType:${mediaType}`);
            return;
        }
        // send the enable/disable message
        const msg = (0,strophe_js__WEBPACK_IMPORTED_MODULE_1__.$msg)({ to: this._xmpp.avModerationComponentAddress });
        msg.c('av_moderation', {
            enable: state,
            mediaType
        }).up();
        this._xmpp.connection.send(msg);
    }
    /**
     * Approves that a participant can unmute by sending a msg with its jid to the component.
     */
    approve(mediaType, jid) {
        if (!this.isSupported() || !this._mainRoom.isModerator()) {
            logger.error(`Cannot approve in AV moderation supported:${this.isSupported()},
                moderator:${this._mainRoom.isModerator()}`);
            return;
        }
        // send a message to whitelist the jid and approve it to unmute
        const msg = (0,strophe_js__WEBPACK_IMPORTED_MODULE_1__.$msg)({ to: this._xmpp.avModerationComponentAddress });
        msg.c('av_moderation', {
            mediaType,
            jidToWhitelist: jid
        }).up();
        this._xmpp.connection.send(msg);
    }
    /**
     * Rejects that a participant can unmute by sending a msg with its jid to the component.
     */
    reject(mediaType, jid) {
        if (!this.isSupported() || !this._mainRoom.isModerator()) {
            logger.error(`Cannot reject in AV moderation supported:${this.isSupported()},
                moderator:${this._mainRoom.isModerator()}`);
            return;
        }
        // send a message to remove from whitelist the jid and reject it to unmute
        const msg = (0,strophe_js__WEBPACK_IMPORTED_MODULE_1__.$msg)({ to: this._xmpp.avModerationComponentAddress });
        msg.c('av_moderation', {
            mediaType,
            jidToBlacklist: jid
        }).up();
        this._xmpp.connection.send(msg);
    }
    /**
     * Receives av_moderation parsed messages as json.
     * @param obj the parsed json content of the message to process.
     * @private
     */
    _onMessage(obj) {
        const { removed, mediaType: media, enabled, approved, actor, whitelists: newWhitelists } = obj;
        if (newWhitelists) {
            const oldList = media === _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_2__.MediaType.AUDIO
                ? this._whitelistAudio
                : this._whitelistVideo;
            const newList = Array.isArray(newWhitelists[media]) ? newWhitelists[media] : [];
            if (removed) {
                oldList.filter(x => !newList.includes(x))
                    .forEach(jid => this._xmpp.eventEmitter
                    .emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_3__.XMPPEvents.AV_MODERATION_PARTICIPANT_REJECTED, media, jid));
            }
            else {
                newList.filter(x => !oldList.includes(x))
                    .forEach(jid => this._xmpp.eventEmitter
                    .emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_3__.XMPPEvents.AV_MODERATION_PARTICIPANT_APPROVED, media, jid));
            }
            if (media === _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_2__.MediaType.AUDIO) {
                this._whitelistAudio = newList;
            }
            else {
                this._whitelistVideo = newList;
            }
        }
        else if (enabled !== undefined && this._moderationEnabledByType[media] !== enabled) {
            this._moderationEnabledByType[media] = enabled;
            this._xmpp.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_3__.XMPPEvents.AV_MODERATION_CHANGED, enabled, media, actor);
        }
        else if (removed) {
            this._xmpp.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_3__.XMPPEvents.AV_MODERATION_REJECTED, media);
        }
        else if (approved) {
            this._xmpp.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_3__.XMPPEvents.AV_MODERATION_APPROVED, media);
        }
    }
}
//# sourceMappingURL=AVModeration.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/xmpp/BreakoutRooms.js":
/*!***********************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/xmpp/BreakoutRooms.js ***!
  \***********************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
var __filename = "/index.js";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (/* binding */ BreakoutRooms)
/* harmony export */ });
/* harmony import */ var _jitsi_logger__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @jitsi/logger */ "./node_modules/@jitsi/logger/lib/index.js");
/* harmony import */ var _jitsi_logger__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(_jitsi_logger__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var strophe_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! strophe.js */ "./node_modules/strophe.js/dist/strophe.umd.js");
/* harmony import */ var strophe_js__WEBPACK_IMPORTED_MODULE_1___default = /*#__PURE__*/__webpack_require__.n(strophe_js__WEBPACK_IMPORTED_MODULE_1__);
/* harmony import */ var _service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../service/xmpp/XMPPEvents */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/xmpp/XMPPEvents.js");



const FEATURE_KEY = 'features/breakout-rooms';
const BREAKOUT_ROOM_ACTIONS = {
    ADD: `${FEATURE_KEY}/add`,
    REMOVE: `${FEATURE_KEY}/remove`,
    MOVE_TO_ROOM: `${FEATURE_KEY}/move-to-room`
};
const BREAKOUT_ROOM_EVENTS = {
    MOVE_TO_ROOM: `${FEATURE_KEY}/move-to-room`,
    UPDATE: `${FEATURE_KEY}/update`
};
const logger = (0,_jitsi_logger__WEBPACK_IMPORTED_MODULE_0__.getLogger)(__filename);
/**
 * Helper class for handling breakout rooms.
 */
class BreakoutRooms {
    /**
     * Constructs lobby room.
     *
     * @param {ChatRoom} room the room we are in.
     */
    constructor(room) {
        this.room = room;
        this._handleMessages = this._handleMessages.bind(this);
        this.room.xmpp.addListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_2__.XMPPEvents.BREAKOUT_ROOMS_EVENT, this._handleMessages);
        this._rooms = {};
    }
    /**
     * Stops listening for events.
     */
    dispose() {
        this.room.xmpp.removeListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_2__.XMPPEvents.BREAKOUT_ROOMS_EVENT, this._handleMessages);
    }
    /**
     * Creates a breakout room with the given subject.
     *
     * @param {string} subject - A subject for the breakout room.
     */
    createBreakoutRoom(subject) {
        if (!this.isSupported() || !this.room.isModerator()) {
            logger.error(`Cannot create breakout room - supported:${this.isSupported()},
                moderator:${this.room.isModerator()}`);
            return;
        }
        const message = {
            type: BREAKOUT_ROOM_ACTIONS.ADD,
            subject
        };
        this._sendMessage(message);
    }
    /**
     * Removes a breakout room.
     *
     * @param {string} breakoutRoomJid - JID of the room to be removed.
     */
    removeBreakoutRoom(breakoutRoomJid) {
        if (!this.isSupported() || !this.room.isModerator()) {
            logger.error(`Cannot remove breakout room - supported:${this.isSupported()},
                moderator:${this.room.isModerator()}`);
            return;
        }
        const message = {
            type: BREAKOUT_ROOM_ACTIONS.REMOVE,
            breakoutRoomJid
        };
        this._sendMessage(message);
    }
    /**
     * Sends the given participant to the given room.
     *
     * @param {string} participantJid - JID of the participant to be sent to a room.
     * @param {string} roomJid - JID of the target room.
     */
    sendParticipantToRoom(participantJid, roomJid) {
        if (!this.isSupported() || !this.room.isModerator()) {
            logger.error(`Cannot send participant to room - supported:${this.isSupported()},
                moderator:${this.room.isModerator()}`);
            return;
        }
        const message = {
            type: BREAKOUT_ROOM_ACTIONS.MOVE_TO_ROOM,
            participantJid,
            roomJid
        };
        this._sendMessage(message);
    }
    /**
     * Whether Breakout Rooms support is enabled in the backend or not.
     */
    isSupported() {
        return Boolean(this.getComponentAddress());
    }
    /**
     * Gets the address of the Breakout Rooms XMPP component.
     *
     * @returns The address of the component.
     */
    getComponentAddress() {
        return this.room.xmpp.breakoutRoomsComponentAddress;
    }
    /**
     * Stores if the current room is a breakout room.
     *
     * @param {boolean} isBreakoutRoom - Whether this room is a breakout room.
     */
    _setIsBreakoutRoom(isBreakoutRoom) {
        this._isBreakoutRoom = isBreakoutRoom;
    }
    /**
     * Checks whether this room is a breakout room.
     *
     * @returns True if the room is a breakout room, false otherwise.
     */
    isBreakoutRoom() {
        if (typeof this._isBreakoutRoom !== 'undefined') {
            return this._isBreakoutRoom;
        }
        // Use heuristic, helpful for checking in the MUC_JOINED event.
        return strophe_js__WEBPACK_IMPORTED_MODULE_1__.Strophe.getDomainFromJid(this.room.myroomjid) === this.getComponentAddress();
    }
    /**
     * Sets the main room JID associated with this breakout room. Only applies when
     * in a breakout room.
     *
     * @param {string} jid - The main room JID.
     */
    _setMainRoomJid(jid) {
        this._mainRoomJid = jid;
    }
    /**
     * Gets the main room's JID associated with this breakout room.
     *
     * @returns The main room JID.
     */
    getMainRoomJid() {
        return this._mainRoomJid;
    }
    /**
     * Handles a message for managing breakout rooms.
     *
     * @param {object} payload - Arbitrary data.
     */
    _handleMessages(payload) {
        switch (payload.event) {
            case BREAKOUT_ROOM_EVENTS.MOVE_TO_ROOM:
                this.room.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_2__.XMPPEvents.BREAKOUT_ROOMS_MOVE_TO_ROOM, payload.roomJid);
                break;
            case BREAKOUT_ROOM_EVENTS.UPDATE: {
                const filteredPayload = this._filterUpdatePayload(payload);
                this._rooms = filteredPayload.rooms;
                this.room.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_2__.XMPPEvents.BREAKOUT_ROOMS_UPDATED, filteredPayload);
                break;
            }
        }
    }
    /**
     * Filters the hidden participants from the payload.
     *
     * @param {Object} payload - The payload of the update message.
     * @return {Object} - The filtered payload.
     */
    _filterUpdatePayload(payload) {
        const hiddenDomain = this.room.options.hiddenDomain;
        const { rooms } = payload;
        const filteredRooms = {};
        Object.entries(rooms).forEach(([key, room]) => {
            const { participants = {} } = room;
            const filteredParticipants = {};
            Object.entries(participants).forEach(([k, participant]) => {
                if (strophe_js__WEBPACK_IMPORTED_MODULE_1__.Strophe.getDomainFromJid(participant.jid) !== hiddenDomain) {
                    filteredParticipants[k] = participant;
                }
            });
            filteredRooms[key] = Object.assign(Object.assign({}, room), { participants: filteredParticipants });
        });
        return Object.assign(Object.assign({}, payload), { rooms: filteredRooms });
    }
    /**
     * Helper to send a breakout rooms message to the component.
     *
     * @param {Object} message - Command that needs to be sent.
     */
    _sendMessage(message) {
        const msg = (0,strophe_js__WEBPACK_IMPORTED_MODULE_1__.$msg)({ to: this.getComponentAddress() });
        msg.c('breakout_rooms', message).up();
        this.room.xmpp.connection.send(msg);
    }
}
//# sourceMappingURL=BreakoutRooms.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/xmpp/Caps.js":
/*!**************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/xmpp/Caps.js ***!
  \**************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (/* binding */ Caps),
/* harmony export */   parseDiscoInfo: () => (/* binding */ parseDiscoInfo)
/* harmony export */ });
/* harmony import */ var jquery__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! jquery */ "./node_modules/jquery/dist/jquery.js");
/* harmony import */ var jquery__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(jquery__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var strophe_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! strophe.js */ "./node_modules/strophe.js/dist/strophe.umd.js");
/* harmony import */ var strophe_js__WEBPACK_IMPORTED_MODULE_1___default = /*#__PURE__*/__webpack_require__.n(strophe_js__WEBPACK_IMPORTED_MODULE_1__);
/* harmony import */ var _service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../service/xmpp/XMPPEvents */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/xmpp/XMPPEvents.js");
/* harmony import */ var _util_Listenable__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../util/Listenable */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/util/Listenable.js");
/* harmony import */ var _sha1__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./sha1 */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/xmpp/sha1.js");

 // eslint-disable-line camelcase



/**
 * The property
 */
const IDENTITY_PROPERTIES = ['category', 'type', 'lang', 'name'];
const IDENTITY_PROPERTIES_FOR_COMPARE = ['category', 'type', 'lang'];
const HASH = 'sha-1';
/**
 *
 * @param a
 * @param b
 */
function compareIdentities(a, b) {
    let res = 0;
    IDENTITY_PROPERTIES_FOR_COMPARE.some(key => (res = ((a[key] > b[key]) && 1) || ((a[key] < b[key]) && -1)) !== 0);
    return res;
}
/**
 * Produces a sha-1 from provided identity and features values.
 *
 * @param {Array<Object>} identities - The identity objects.
 * @param {Array<string>} features - The features.
 * @returns {string}
 */
function generateSha(identities, features) {
    const sortedIdentities = identities.sort(compareIdentities).reduce((accumulatedValue, identity) => `${IDENTITY_PROPERTIES.reduce((tmp, key, idx) => tmp
        + (idx === 0 ? '' : '/')
        + (identity[key] ? identity[key] : ''), '')}<`, '');
    const sortedFeatures = features.sort().reduce((tmp, feature) => `${tmp + feature}<`, '');
    return _sha1__WEBPACK_IMPORTED_MODULE_4__["default"].b64_sha1(sortedIdentities + sortedFeatures);
}
/**
 * Parses the disco-info node and returns the sets of features and identities.
 * @param {String} node The node with results to parse.
 * @returns {{features: Set<any>, identities: Set<any>}}
 */
function parseDiscoInfo(node) {
    const features = new Set();
    const identities = new Set();
    jquery__WEBPACK_IMPORTED_MODULE_0___default()(node).find('>query>feature')
        .each((_, el) => features.add(el.getAttribute('var')));
    jquery__WEBPACK_IMPORTED_MODULE_0___default()(node).find('>query>identity')
        .each((_, el) => identities.add({
        type: el.getAttribute('type'),
        name: el.getAttribute('name'),
        category: el.getAttribute('category')
    }));
    return {
        features,
        identities
    };
}
/**
 * Implements xep-0115 ( http://xmpp.org/extensions/xep-0115.html )
 */
class Caps extends _util_Listenable__WEBPACK_IMPORTED_MODULE_3__["default"] {
    /**
     * Constructs new Caps instance.
     * @param {Strophe.Connection} connection the strophe connection object
     * @param {String} node the value of the node attribute of the "c" xml node
     * that will be sent to the other participants
     */
    constructor(connection = {}, node = 'http://jitsi.org/jitsimeet') {
        super();
        this.node = node;
        this.disco = connection.disco;
        if (!this.disco) {
            throw new Error('Missing strophe-plugins '
                + '(disco plugin is required)!');
        }
        this.version = '';
        this.rooms = new Set();
        // We keep track of features added outside the library and we publish them
        // in the presence of the participant for simplicity, avoiding the disco info request-response.
        this.externalFeatures = new Set();
        const emuc = connection.emuc;
        emuc.addListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_2__.XMPPEvents.EMUC_ROOM_ADDED, room => this._addChatRoom(room));
        emuc.addListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_2__.XMPPEvents.EMUC_ROOM_REMOVED, room => this._removeChatRoom(room));
        Object.keys(emuc.rooms).forEach(jid => {
            this._addChatRoom(emuc.rooms[jid]);
        });
        strophe_js__WEBPACK_IMPORTED_MODULE_1__.Strophe.addNamespace('CAPS', 'http://jabber.org/protocol/caps');
        this.disco.addFeature(strophe_js__WEBPACK_IMPORTED_MODULE_1__.Strophe.NS.CAPS);
    }
    /**
     * Adds new feature to the list of supported features for the local
     * participant
     * @param {String} feature the name of the feature.
     * @param {boolean} submit if true - new presence with updated "c" node
     * will be sent.
     * @param {boolean} external whether this feature was added externally to the library.
     * We put features used directly by the clients (is jibri, remote-control enabled etc.) in the presence
     * to avoid additional disco-info queries by those clients.
     */
    addFeature(feature, submit = false, external = false) {
        this.disco.addFeature(feature);
        this._generateVersion();
        if (external && !this.externalFeatures.has(feature)) {
            this.externalFeatures.add(feature);
            this.rooms.forEach(room => this._updateRoomWithExternalFeatures(room));
        }
        if (submit) {
            this.submit();
        }
    }
    /**
     * Removes a feature from the list of supported features for the local
     * participant
     * @param {String} feature the name of the feature.
     * @param {boolean} submit if true - new presence with updated "c" node
     * will be sent.
     * @param {boolean} external whether this feature was added externally to the library.
     */
    removeFeature(feature, submit = false, external = false) {
        this.disco.removeFeature(feature);
        this._generateVersion();
        if (external && this.externalFeatures.has(feature)) {
            this.externalFeatures.delete(feature);
            this.rooms.forEach(room => this._updateRoomWithExternalFeatures(room));
        }
        if (submit) {
            this.submit();
        }
    }
    /**
     * Sends new presence stanza for every room from the list of rooms.
     */
    submit() {
        this.rooms.forEach(room => room.sendPresence());
    }
    /**
     * Updates the presences in the room based on the current values in externalFeatures.
     * @param {ChatRoom} room the room to update.
     * @private
     */
    _updateRoomWithExternalFeatures(room) {
        if (this.externalFeatures.size === 0) {
            room.removeFromPresence('features');
        }
        else {
            const children = [];
            this.externalFeatures.forEach(f => {
                children.push({
                    'tagName': 'feature',
                    attributes: { 'var': f }
                });
            });
            room.addOrReplaceInPresence('features', { children });
        }
    }
    /**
     * Returns a set with the features for a host.
     * @param {String} jid the jid of the host
     * @param {int} timeout the timeout in ms for reply from the host.
     * @returns {Promise<Set<String>, Error>}
     */
    getFeaturesAndIdentities(jid, node, timeout = 5000) {
        return this._getDiscoInfo(jid, node, timeout);
    }
    /**
     * Returns a set with the features and identities for a host.
     * @param {String} jid the jid of the host
     * @param {String|null} node the node to query
     * @param {int} timeout the timeout in ms for reply from the host.
     * @returns {Promise<Object>}
     * @private
     */
    _getDiscoInfo(jid, node, timeout) {
        return new Promise((resolve, reject) => this.disco.info(jid, node, response => {
            resolve(parseDiscoInfo(response));
        }, reject, timeout));
    }
    /**
     * Adds ChatRoom instance to the list of rooms. Adds listeners to the room
     * and adds "c" element to the presences of the room.
     * @param {ChatRoom} room the room.
     */
    _addChatRoom(room) {
        this.rooms.add(room);
        this._fixChatRoomPresenceMap(room);
        this._updateRoomWithExternalFeatures(room);
    }
    /**
     * Removes ChatRoom instance from the list of rooms. Removes listeners
     * added from the Caps class.
     * @param {ChatRoom} room the room.
     */
    _removeChatRoom(room) {
        this.rooms.delete(room);
    }
    /**
     * Creates/updates the "c" xml node into the presence of the passed room.
     * @param {ChatRoom} room the room.
     */
    _fixChatRoomPresenceMap(room) {
        room.addOrReplaceInPresence('c', {
            attributes: {
                xmlns: strophe_js__WEBPACK_IMPORTED_MODULE_1__.Strophe.NS.CAPS,
                hash: HASH,
                node: this.node,
                ver: this.version
            }
        });
    }
    /**
     * Handles this.version changes.
     */
    _notifyVersionChanged() {
        // update the version for all rooms
        this.rooms.forEach(room => this._fixChatRoomPresenceMap(room));
    }
    /**
     * Generates the value for the "ver" attribute.
     */
    _generateVersion() {
        this.version
            = generateSha(this.disco._identities, this.disco._features);
        this._notifyVersionChanged();
    }
}
//# sourceMappingURL=Caps.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/xmpp/ChatRoom.js":
/*!******************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/xmpp/ChatRoom.js ***!
  \******************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
var __filename = "/index.js";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (/* binding */ ChatRoom),
/* harmony export */   filterNodeFromPresenceJSON: () => (/* binding */ filterNodeFromPresenceJSON),
/* harmony export */   parser: () => (/* binding */ parser)
/* harmony export */ });
/* harmony import */ var _jitsi_logger__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @jitsi/logger */ "./node_modules/@jitsi/logger/lib/index.js");
/* harmony import */ var _jitsi_logger__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(_jitsi_logger__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var jquery__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! jquery */ "./node_modules/jquery/dist/jquery.js");
/* harmony import */ var jquery__WEBPACK_IMPORTED_MODULE_1___default = /*#__PURE__*/__webpack_require__.n(jquery__WEBPACK_IMPORTED_MODULE_1__);
/* harmony import */ var lodash_isequal__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! lodash.isequal */ "./node_modules/lodash.isequal/index.js");
/* harmony import */ var lodash_isequal__WEBPACK_IMPORTED_MODULE_2___default = /*#__PURE__*/__webpack_require__.n(lodash_isequal__WEBPACK_IMPORTED_MODULE_2__);
/* harmony import */ var strophe_js__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! strophe.js */ "./node_modules/strophe.js/dist/strophe.umd.js");
/* harmony import */ var strophe_js__WEBPACK_IMPORTED_MODULE_3___default = /*#__PURE__*/__webpack_require__.n(strophe_js__WEBPACK_IMPORTED_MODULE_3__);
/* harmony import */ var _JitsiTranscriptionStatus__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../../JitsiTranscriptionStatus */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/JitsiTranscriptionStatus.js");
/* harmony import */ var _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../../service/RTC/MediaType */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/RTC/MediaType.js");
/* harmony import */ var _service_RTC_VideoType__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../../service/RTC/VideoType */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/RTC/VideoType.js");
/* harmony import */ var _service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../../service/xmpp/XMPPEvents */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/xmpp/XMPPEvents.js");
/* harmony import */ var _util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ../util/GlobalOnErrorHandler */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/util/GlobalOnErrorHandler.js");
/* harmony import */ var _util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_8___default = /*#__PURE__*/__webpack_require__.n(_util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_8__);
/* harmony import */ var _util_Listenable__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ../util/Listenable */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/util/Listenable.js");
/* harmony import */ var _AVModeration__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ./AVModeration */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/xmpp/AVModeration.js");
/* harmony import */ var _BreakoutRooms__WEBPACK_IMPORTED_MODULE_11__ = __webpack_require__(/*! ./BreakoutRooms */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/xmpp/BreakoutRooms.js");
/* harmony import */ var _Lobby__WEBPACK_IMPORTED_MODULE_12__ = __webpack_require__(/*! ./Lobby */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/xmpp/Lobby.js");
/* harmony import */ var _RoomMetadata__WEBPACK_IMPORTED_MODULE_13__ = __webpack_require__(/*! ./RoomMetadata */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/xmpp/RoomMetadata.js");
/* harmony import */ var _XmppConnection__WEBPACK_IMPORTED_MODULE_14__ = __webpack_require__(/*! ./XmppConnection */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/xmpp/XmppConnection.js");
/* harmony import */ var _moderator__WEBPACK_IMPORTED_MODULE_15__ = __webpack_require__(/*! ./moderator */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/xmpp/moderator.js");
















const logger = (0,_jitsi_logger__WEBPACK_IMPORTED_MODULE_0__.getLogger)(__filename);
const parser = {
    packet2JSON(xmlElement, nodes) {
        for (const child of Array.from(xmlElement.children)) {
            const node = {
                attributes: {},
                children: [],
                tagName: child.tagName
            };
            for (const attr of Array.from(child.attributes)) {
                node.attributes[attr.name] = attr.value;
            }
            const text = strophe_js__WEBPACK_IMPORTED_MODULE_3__.Strophe.getText(child);
            if (text) {
                // Using Strophe.getText will do work for traversing all direct
                // child text nodes but returns an escaped value, which is not
                // desirable at this point.
                node.value = strophe_js__WEBPACK_IMPORTED_MODULE_3__.Strophe.xmlunescape(text);
            }
            nodes.push(node);
            this.packet2JSON(child, node.children);
        }
    },
    json2packet(nodes, packet) {
        for (let i = 0; i < nodes.length; i++) {
            const node = nodes[i];
            if (node) {
                packet.c(node.tagName, node.attributes);
                if (node.value) {
                    packet.t(node.value);
                }
                if (node.children) {
                    this.json2packet(node.children, packet);
                }
                packet.up();
            }
        }
        // packet.up();
    }
};
/**
 * Returns array of JS objects from the presence JSON associated with the passed
 / nodeName
 * @param pres the presence JSON
 * @param nodeName the name of the node (videomuted, audiomuted, etc)
 */
function filterNodeFromPresenceJSON(pres, nodeName) {
    const res = [];
    for (let i = 0; i < pres.length; i++) {
        if (pres[i].tagName === nodeName) {
            res.push(pres[i]);
        }
    }
    return res;
}
// XXX As ChatRoom constructs XMPP stanzas and Strophe is build around the idea
// of chaining function calls, allow long function call chains.
/* eslint-disable newline-per-chained-call */
/**
 * Array of affiliations that are allowed in members only room.
 * @type {string[]}
 */
const MEMBERS_AFFILIATIONS = ['owner', 'admin', 'member'];
/**
 * Process nodes to extract data needed for MUC_JOINED and MUC_MEMBER_JOINED events.
 *
 */
function extractIdentityInformation(node, hiddenFromRecorderFeatureEnabled) {
    const identity = {};
    const userInfo = node.children.find(c => c.tagName === 'user');
    if (userInfo) {
        identity.user = {};
        const tags = ['id', 'name', 'avatar'];
        if (hiddenFromRecorderFeatureEnabled) {
            tags.push('hidden-from-recorder');
        }
        for (const tag of tags) {
            const child = userInfo.children.find(c => c.tagName === tag);
            if (child) {
                identity.user[tag] = child.value;
            }
        }
    }
    const groupInfo = node.children.find(c => c.tagName === 'group');
    if (groupInfo) {
        identity.group = groupInfo.value;
    }
    return identity;
}
/**
 *
 */
class ChatRoom extends _util_Listenable__WEBPACK_IMPORTED_MODULE_9__["default"] {
    /* eslint-disable max-params */
    /**
     *
     * @param {XmppConnection} connection - The XMPP connection instance.
     * @param jid
     * @param password
     * @param XMPP
     * @param options
     * @param {boolean} options.disableFocus - when set to {@code false} will
     * not invite Jicofo into the room.
     * @param {boolean} options.disableDiscoInfo - when set to {@code false} will skip disco info.
     * This is intended to be used only for lobby rooms.
     * @param {boolean} options.enableLobby - when set to {@code false} will skip creating lobby room.
     * @param {boolean} options.hiddenFromRecorderFeatureEnabled - when set to {@code true} we will check identity tag
     * for node presence.
     */
    constructor(connection, jid, password, xmpp, options) {
        super();
        this.xmpp = xmpp;
        this.connection = connection;
        this.roomjid = strophe_js__WEBPACK_IMPORTED_MODULE_3__.Strophe.getBareJidFromJid(jid);
        this.myroomjid = jid;
        this.password = password;
        this.replaceParticipant = false;
        logger.info(`Joining MUC as ${this.myroomjid}`);
        this.members = {};
        this.presMap = {};
        this.presHandlers = {};
        this._removeConnListeners = [];
        this.joined = false;
        this.inProgressEmitted = false;
        this.role = null;
        this.focusMucJid = null;
        this.noBridgeAvailable = false;
        this.options = options || {};
        this.moderator = new _moderator__WEBPACK_IMPORTED_MODULE_15__["default"](this.roomjid, this.xmpp, this.eventEmitter, xmpp.options);
        if (typeof this.options.enableLobby === 'undefined' || this.options.enableLobby) {
            this.lobby = new _Lobby__WEBPACK_IMPORTED_MODULE_12__["default"](this);
        }
        this.avModeration = new _AVModeration__WEBPACK_IMPORTED_MODULE_10__["default"](this);
        this.breakoutRooms = new _BreakoutRooms__WEBPACK_IMPORTED_MODULE_11__["default"](this);
        this.roomMetadata = new _RoomMetadata__WEBPACK_IMPORTED_MODULE_13__["default"](this);
        this.initPresenceMap(options);
        this.lastPresences = {};
        this.phoneNumber = null;
        this.phonePin = null;
        this.connectionTimes = {};
        this.participantPropertyListener = null;
        this.locked = false;
        this.transcriptionStatus = _JitsiTranscriptionStatus__WEBPACK_IMPORTED_MODULE_4__.OFF;
    }
    /* eslint-enable max-params */
    /**
     *
     */
    initPresenceMap(options = {}) {
        this.presMap.to = this.myroomjid;
        this.presMap.xns = 'http://jabber.org/protocol/muc';
        this.presMap.nodes = [];
        if (options.statsId) {
            this.presMap.nodes.push({
                'tagName': 'stats-id',
                'value': options.statsId
            });
        }
        this.presenceUpdateTime = Date.now();
    }
    /**
     * Joins the chat room.
     * @param {string} password - Password to unlock room on joining.
     * @returns {Promise} - resolved when join completes. At the time of this
     * writing it's never rejected.
     */
    join(password, replaceParticipant) {
        this.password = password;
        this.replaceParticipant = replaceParticipant;
        return new Promise(resolve => {
            this.options.disableFocus
                && logger.info(`Conference focus disabled for ${this.roomjid}`);
            // there is no point of sending conference iq when in visitor mode
            const preJoin = this.options.disableFocus
                ? Promise.resolve()
                : this.moderator.sendConferenceRequest();
            preJoin.then(() => {
                this.sendPresence(true);
                this._removeConnListeners.push(this.connection.addEventListener(_XmppConnection__WEBPACK_IMPORTED_MODULE_14__["default"].Events.CONN_STATUS_CHANGED, this.onConnStatusChanged.bind(this)));
                resolve();
            });
        });
    }
    /**
     *
     * @param fromJoin - Whether this is initial presence to join the room.
     */
    sendPresence(fromJoin) {
        const to = this.presMap.to;
        if (!this.connection || !this.connection.connected || !to || (!this.joined && !fromJoin)) {
            // Too early to send presence - not initialized
            return;
        }
        const pres = (0,strophe_js__WEBPACK_IMPORTED_MODULE_3__.$pres)({ to });
        // xep-0045 defines: "including in the initial presence stanza an empty
        // <x/> element qualified by the 'http://jabber.org/protocol/muc'
        // namespace" and subsequent presences should not include that or it can
        // be considered as joining, and server can send us the message history
        // for the room on every presence
        if (fromJoin) {
            if (this.replaceParticipant) {
                pres.c('flip_device').up();
            }
            pres.c('x', { xmlns: this.presMap.xns });
            if (this.password) {
                pres.c('password').t(this.password).up();
            }
            if (this.options.billingId) {
                pres.c('billingid').t(this.options.billingId).up();
            }
            pres.up();
        }
        parser.json2packet(this.presMap.nodes, pres);
        // we store time we last synced presence state
        this.presenceSyncTime = Date.now();
        this.connection.send(pres);
        if (fromJoin) {
            // XXX We're pressed for time here because we're beginning a complex
            // and/or lengthy conference-establishment process which supposedly
            // involves multiple RTTs. We don't have the time to wait for
            // Strophe to decide to send our IQ.
            this.connection.flush();
        }
    }
    /**
     * Sends the presence unavailable, signaling the server
     * we want to leave the room.
     */
    doLeave(reason) {
        logger.log('do leave', this.myroomjid);
        const pres = (0,strophe_js__WEBPACK_IMPORTED_MODULE_3__.$pres)({
            to: this.myroomjid,
            type: 'unavailable'
        });
        if (reason) {
            pres.c('status').t(reason).up();
        }
        this.presMap.length = 0;
        // XXX Strophe is asynchronously sending by default. Unfortunately, that
        // means that there may not be enough time to send the unavailable
        // presence. Switching Strophe to synchronous sending is not much of an
        // option because it may lead to a noticeable delay in navigating away
        // from the current location. As a compromise, we will try to increase
        // the chances of sending the unavailable presence within the short time
        // span that we have upon unloading by invoking flush() on the
        // connection. We flush() once before sending/queuing the unavailable
        // presence in order to attemtp to have the unavailable presence at the
        // top of the send queue. We flush() once more after sending/queuing the
        // unavailable presence in order to attempt to have it sent as soon as
        // possible.
        // FIXME do not use Strophe.Connection in the ChatRoom directly
        !this.connection.isUsingWebSocket && this.connection.flush();
        this.connection.send(pres);
        this.connection.flush();
    }
    /**
     *
     */
    discoRoomInfo() {
        // https://xmpp.org/extensions/xep-0045.html#disco-roominfo
        const getInfo = (0,strophe_js__WEBPACK_IMPORTED_MODULE_3__.$iq)({
            type: 'get',
            to: this.roomjid
        })
            .c('query', { xmlns: strophe_js__WEBPACK_IMPORTED_MODULE_3__.Strophe.NS.DISCO_INFO });
        this.connection.sendIQ(getInfo, result => {
            const locked = jquery__WEBPACK_IMPORTED_MODULE_1___default()(result).find('>query>feature[var="muc_passwordprotected"]')
                .length
                === 1;
            if (locked !== this.locked) {
                this.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_7__.XMPPEvents.MUC_LOCK_CHANGED, locked);
                this.locked = locked;
            }
            const meetingIdValEl = jquery__WEBPACK_IMPORTED_MODULE_1___default()(result).find('>query>x[type="result"]>field[var="muc#roominfo_meetingId"]>value');
            if (meetingIdValEl.length) {
                this.setMeetingId(meetingIdValEl.text());
            }
            else {
                logger.warn('No meeting ID from backend');
            }
            const membersOnly = jquery__WEBPACK_IMPORTED_MODULE_1___default()(result).find('>query>feature[var="muc_membersonly"]').length === 1;
            const lobbyRoomField = jquery__WEBPACK_IMPORTED_MODULE_1___default()(result).find('>query>x[type="result"]>field[var="muc#roominfo_lobbyroom"]>value');
            if (this.lobby) {
                this.lobby.setLobbyRoomJid(lobbyRoomField && lobbyRoomField.length ? lobbyRoomField.text() : undefined);
            }
            const isBreakoutField = jquery__WEBPACK_IMPORTED_MODULE_1___default()(result).find('>query>x[type="result"]>field[var="muc#roominfo_isbreakout"]>value');
            const isBreakoutRoom = Boolean(isBreakoutField === null || isBreakoutField === void 0 ? void 0 : isBreakoutField.text());
            this.breakoutRooms._setIsBreakoutRoom(isBreakoutRoom);
            const breakoutMainRoomField = jquery__WEBPACK_IMPORTED_MODULE_1___default()(result).find('>query>x[type="result"]>field[var="muc#roominfo_breakout_main_room"]>value');
            if (breakoutMainRoomField === null || breakoutMainRoomField === void 0 ? void 0 : breakoutMainRoomField.length) {
                this.breakoutRooms._setMainRoomJid(breakoutMainRoomField.text());
            }
            if (membersOnly !== this.membersOnlyEnabled) {
                this.membersOnlyEnabled = membersOnly;
                this.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_7__.XMPPEvents.MUC_MEMBERS_ONLY_CHANGED, membersOnly);
            }
            const roomMetadataEl = jquery__WEBPACK_IMPORTED_MODULE_1___default()(result).find('>query>x[type="result"]>field[var="muc#roominfo_jitsimetadata"]>value');
            const roomMetadataText = roomMetadataEl === null || roomMetadataEl === void 0 ? void 0 : roomMetadataEl.text();
            if (roomMetadataText) {
                try {
                    this.roomMetadata._handleMessages(JSON.parse(roomMetadataText));
                }
                catch (e) {
                    logger.warn('Failed to set room metadata', e);
                }
            }
        }, error => {
            _util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_8___default().callErrorHandler(error);
            logger.error('Error getting room info: ', error);
        });
    }
    /**
     * Sets the meeting unique Id (received from the backend).
     *
     * @param {string} meetingId - The new meetings id.
     * @returns {void}
     */
    setMeetingId(meetingId) {
        if (this.meetingId !== meetingId) {
            if (this.meetingId) {
                logger.warn(`Meeting Id changed from:${this.meetingId} to:${meetingId}`);
            }
            this.meetingId = meetingId;
            this.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_7__.XMPPEvents.MEETING_ID_SET, meetingId);
        }
    }
    /**
     *
     */
    createNonAnonymousRoom() {
        // http://xmpp.org/extensions/xep-0045.html#createroom-reserved
        if (this.options.disableDiscoInfo) {
            return;
        }
        const getForm = (0,strophe_js__WEBPACK_IMPORTED_MODULE_3__.$iq)({ type: 'get',
            to: this.roomjid })
            .c('query', { xmlns: 'http://jabber.org/protocol/muc#owner' })
            .c('x', { xmlns: 'jabber:x:data',
            type: 'submit' });
        this.connection.sendIQ(getForm, form => {
            if (!jquery__WEBPACK_IMPORTED_MODULE_1___default()(form).find('>query>x[xmlns="jabber:x:data"]'
                + '>field[var="muc#roomconfig_whois"]').length) {
                const errmsg = 'non-anonymous rooms not supported';
                _util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_8___default().callErrorHandler(new Error(errmsg));
                logger.error(errmsg);
                return;
            }
            const formSubmit = (0,strophe_js__WEBPACK_IMPORTED_MODULE_3__.$iq)({ to: this.roomjid,
                type: 'set' })
                .c('query', { xmlns: 'http://jabber.org/protocol/muc#owner' });
            formSubmit.c('x', { xmlns: 'jabber:x:data',
                type: 'submit' });
            formSubmit.c('field', { 'var': 'FORM_TYPE' })
                .c('value')
                .t('http://jabber.org/protocol/muc#roomconfig').up().up();
            formSubmit.c('field', { 'var': 'muc#roomconfig_whois' })
                .c('value').t('anyone').up().up();
            this.connection.sendIQ(formSubmit);
        }, error => {
            _util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_8___default().callErrorHandler(error);
            logger.error('Error getting room configuration form: ', error);
        });
    }
    /**
     * Handles Xmpp Connection status updates.
     *
     * @param {Strophe.Status} status - The Strophe connection status.
     */
    onConnStatusChanged(status) {
        // Send cached presence when the XMPP connection is re-established, only if needed
        if (status === _XmppConnection__WEBPACK_IMPORTED_MODULE_14__["default"].Status.CONNECTED && this.presenceUpdateTime > this.presenceSyncTime) {
            this.sendPresence();
        }
    }
    /**
     *
     * @param pres
     */
    onPresence(pres) {
        const from = pres.getAttribute('from');
        const member = {};
        const statusEl = pres.getElementsByTagName('status')[0];
        if (statusEl) {
            member.status = statusEl.textContent || '';
        }
        let hasStatusUpdate = false;
        let hasVersionUpdate = false;
        const xElement = pres.getElementsByTagNameNS('http://jabber.org/protocol/muc#user', 'x')[0];
        const mucUserItem = xElement && xElement.getElementsByTagName('item')[0];
        member.isReplaceParticipant
            = pres.getElementsByTagName('flip_device').length;
        member.affiliation
            = mucUserItem && mucUserItem.getAttribute('affiliation');
        member.role = mucUserItem && mucUserItem.getAttribute('role');
        // Focus recognition
        const jid = mucUserItem && mucUserItem.getAttribute('jid');
        member.jid = jid;
        member.isFocus = this.moderator.isFocusJid(jid);
        member.isHiddenDomain
            = jid && jid.indexOf('@') > 0
                && this.options.hiddenDomain
                    === jid.substring(jid.indexOf('@') + 1, jid.indexOf('/'));
        this.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_7__.XMPPEvents.PRESENCE_RECEIVED, {
            fromHiddenDomain: member.isHiddenDomain,
            presence: pres
        });
        const xEl = pres.querySelector('x');
        if (xEl) {
            xEl.remove();
        }
        const nodes = [];
        parser.packet2JSON(pres, nodes);
        this.lastPresences[from] = nodes;
        for (let i = 0; i < nodes.length; i++) {
            const node = nodes[i];
            switch (node.tagName) {
                case 'bot': {
                    const { attributes } = node;
                    if (!attributes) {
                        break;
                    }
                    const { type } = attributes;
                    member.botType = type;
                    break;
                }
                case 'nick':
                    member.nick = node.value;
                    break;
                case 'userId':
                    member.id = node.value;
                    break;
                case 'stats-id':
                    member.statsID = node.value;
                    break;
                case 'identity':
                    member.identity = extractIdentityInformation(node, this.options.hiddenFromRecorderFeatureEnabled);
                    break;
                case 'features': {
                    member.features = this._extractFeatures(node);
                    break;
                }
                case 'stat': {
                    const { attributes } = node;
                    if (!attributes) {
                        break;
                    }
                    const { name } = attributes;
                    if (name === 'version') {
                        member.version = attributes.value;
                    }
                    break;
                }
            }
        }
        if (!this.joined && !this.inProgressEmitted) {
            const now = this.connectionTimes['muc.join.started'] = window.performance.now();
            logger.log('(TIME) MUC join started:\t', now);
            this.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_7__.XMPPEvents.MUC_JOIN_IN_PROGRESS);
            this.inProgressEmitted = true;
        }
        if (from === this.myroomjid) {
            const newRole = member.affiliation === 'owner' ? member.role : 'none';
            if (this.role !== newRole) {
                this.role = newRole;
                this.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_7__.XMPPEvents.LOCAL_ROLE_CHANGED, this.role);
            }
            if (!this.joined) {
                this.joined = true;
                const now = this.connectionTimes['muc.joined']
                    = window.performance.now();
                logger.log('(TIME) MUC joined:\t', now);
                // set correct initial state of locked
                if (this.password) {
                    this.locked = true;
                }
                // Re-send presence in case any presence updates were added,
                // but blocked from sending, during the join process.
                // send the presence only if there was a modification after we had synced it
                if (this.presenceUpdateTime >= this.presenceSyncTime) {
                    this.sendPresence();
                }
                this.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_7__.XMPPEvents.MUC_JOINED);
                // Now let's check the disco-info to retrieve the
                // meeting Id if any
                !this.options.disableDiscoInfo && this.discoRoomInfo();
            }
        }
        else if (jid === undefined) {
            logger.info('Ignoring member with undefined JID');
        }
        else if (this.members[from] === undefined) {
            // new participant
            this.members[from] = member;
            logger.log('entered', from, member);
            hasStatusUpdate = member.status !== undefined;
            hasVersionUpdate = member.version !== undefined;
            if (member.isFocus) {
                this._initFocus(from, member.features);
            }
            else {
                // identity is being added to member joined, so external
                // services can be notified for that (currently identity is
                // not used inside library)
                this.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_7__.XMPPEvents.MUC_MEMBER_JOINED, from, member.nick, member.role, member.isHiddenDomain, member.statsID, member.status, member.identity, member.botType, member.jid, member.features, member.isReplaceParticipant);
                // we are reporting the status with the join
                // so we do not want a second event about status update
                hasStatusUpdate = false;
            }
        }
        else {
            // Presence update for existing participant
            // Watch role change:
            const memberOfThis = this.members[from];
            if (memberOfThis.role !== member.role) {
                memberOfThis.role = member.role;
                this.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_7__.XMPPEvents.MUC_ROLE_CHANGED, from, member.role);
            }
            // affiliation changed
            if (memberOfThis.affiliation !== member.affiliation) {
                memberOfThis.affiliation = member.affiliation;
            }
            // fire event that botType had changed
            if (memberOfThis.botType !== member.botType) {
                memberOfThis.botType = member.botType;
                this.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_7__.XMPPEvents.MUC_MEMBER_BOT_TYPE_CHANGED, from, member.botType);
            }
            if (member.isFocus) {
                // From time to time first few presences of the focus are not
                // containing it's jid. That way we can mark later the focus
                // member instead of not marking it at all and not starting the
                // conference.
                // FIXME: Maybe there is a better way to handle this issue. It
                // seems there is some period of time in prosody that the
                // configuration form is received but not applied. And if any
                // participant joins during that period of time the first
                // presence from the focus won't contain
                // <item jid="focus..." />.
                // By default we are disabling the waiting for form submission in order to use the room
                // and we had enabled by default that jids are public in the room ,
                // so this case should not happen, if public jid is turned off we will receive the jid
                // when we become moderator in the room
                memberOfThis.isFocus = true;
                this._initFocus(from, member.features);
            }
            // store the new display name
            if (member.displayName) {
                memberOfThis.displayName = member.displayName;
            }
            // update stored status message to be able to detect changes
            if (memberOfThis.status !== member.status) {
                hasStatusUpdate = true;
                memberOfThis.status = member.status;
            }
            if (memberOfThis.version !== member.version) {
                hasVersionUpdate = true;
                memberOfThis.version = member.version;
            }
            if (!lodash_isequal__WEBPACK_IMPORTED_MODULE_2___default()(memberOfThis.features, member.features)) {
                memberOfThis.features = member.features;
                this.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_7__.XMPPEvents.PARTICIPANT_FEATURES_CHANGED, from, member.features);
            }
        }
        // after we had fired member or room joined events, lets fire events
        // for the rest info we got in presence
        for (let i = 0; i < nodes.length; i++) {
            const node = nodes[i];
            switch (node.tagName) {
                case 'nick':
                    if (!member.isFocus) {
                        const displayName = this.xmpp.options.displayJids
                            ? strophe_js__WEBPACK_IMPORTED_MODULE_3__.Strophe.getResourceFromJid(from)
                            : member.nick;
                        this.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_7__.XMPPEvents.DISPLAY_NAME_CHANGED, from, displayName);
                    }
                    break;
                case 'bridgeNotAvailable':
                    if (member.isFocus && !this.noBridgeAvailable) {
                        this.noBridgeAvailable = true;
                        this.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_7__.XMPPEvents.BRIDGE_DOWN);
                    }
                    break;
                case 'conference-properties':
                    if (member.isFocus) {
                        const properties = {};
                        for (let j = 0; j < node.children.length; j++) {
                            const { attributes } = node.children[j];
                            if (attributes && attributes.key) {
                                properties[attributes.key] = attributes.value;
                            }
                        }
                        this.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_7__.XMPPEvents.CONFERENCE_PROPERTIES_CHANGED, properties);
                        // Log if Jicofo supports restart by terminate only once. This conference property does not change
                        // during the call.
                        if (typeof this.restartByTerminateSupported === 'undefined') {
                            this.restartByTerminateSupported = properties['support-terminate-restart'] === 'true';
                            logger.info(`Jicofo supports restart by terminate: ${this.supportsRestartByTerminate()}`);
                        }
                    }
                    break;
                case 'transcription-status': {
                    const { attributes } = node;
                    if (!attributes) {
                        break;
                    }
                    const { status } = attributes;
                    if (status && status !== this.transcriptionStatus) {
                        this.transcriptionStatus = status;
                        this.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_7__.XMPPEvents.TRANSCRIPTION_STATUS_CHANGED, status);
                    }
                    break;
                }
                case 'call-control': {
                    const att = node.attributes;
                    if (!att) {
                        break;
                    }
                    this.phoneNumber = att.phone || null;
                    this.phonePin = att.pin || null;
                    this.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_7__.XMPPEvents.PHONE_NUMBER_CHANGED);
                    break;
                }
                default:
                    this.processNode(node, from);
            }
        }
        // Trigger status message update if necessary
        if (hasStatusUpdate) {
            this.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_7__.XMPPEvents.PRESENCE_STATUS, from, member.status);
        }
        if (hasVersionUpdate) {
            logger.info(`Received version for ${jid}: ${member.version}`);
        }
    }
    /**
     * Extracts the features from the presence.
     * @param node the node to process.
     * @return features the Set of features where extracted data is added.
     * @private
     */
    _extractFeatures(node) {
        const features = new Set();
        for (let j = 0; j < node.children.length; j++) {
            const { attributes } = node.children[j];
            if (attributes && attributes.var) {
                features.add(attributes.var);
            }
        }
        return features;
    }
    /**
     * Initialize some properties when the focus participant is verified.
     * @param from jid of the focus
     * @param features the features reported in jicofo presence
     */
    _initFocus(from, features) {
        this.focusMucJid = from;
        this.focusFeatures = features;
    }
    /**
     * Sets the special listener to be used for "command"s whose name starts
     * with "jitsi_participant_".
     */
    setParticipantPropertyListener(listener) {
        this.participantPropertyListener = listener;
    }
    /**
     * Checks if Jicofo supports restarting Jingle session after 'session-terminate'.
     * @returns {boolean}
     */
    supportsRestartByTerminate() {
        return this.restartByTerminateSupported;
    }
    /**
     *
     * @param node
     * @param from
     */
    processNode(node, from) {
        // make sure we catch all errors coming from any handler
        // otherwise we can remove the presence handler from strophe
        try {
            let tagHandlers = this.presHandlers[node.tagName];
            if (node.tagName.startsWith('jitsi_participant_')) {
                tagHandlers = [this.participantPropertyListener];
            }
            if (tagHandlers) {
                tagHandlers.forEach(handler => {
                    handler(node, strophe_js__WEBPACK_IMPORTED_MODULE_3__.Strophe.getResourceFromJid(from), from);
                });
            }
        }
        catch (e) {
            _util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_8___default().callErrorHandler(e);
            logger.error(`Error processing:${node.tagName} node.`, e);
        }
    }
    /**
     * Send text message to the other participants in the conference
     * @param message
     * @param elementName
     */
    sendMessage(message, elementName) {
        const msg = (0,strophe_js__WEBPACK_IMPORTED_MODULE_3__.$msg)({ to: this.roomjid,
            type: 'groupchat' });
        // We are adding the message in a packet extension. If this element
        // is different from 'body', we add a custom namespace.
        // e.g. for 'json-message' extension of message stanza.
        if (elementName === 'body') {
            msg.c(elementName, {}, message);
        }
        else {
            msg.c(elementName, { xmlns: 'http://jitsi.org/jitmeet' }, message);
        }
        this.connection.send(msg);
        this.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_7__.XMPPEvents.SENDING_CHAT_MESSAGE, message);
    }
    /* eslint-disable max-params */
    /**
     * Send private text message to another participant of the conference
     * @param id id/muc resource of the receiver
     * @param message
     * @param elementName
     */
    sendPrivateMessage(id, message, elementName) {
        const msg = (0,strophe_js__WEBPACK_IMPORTED_MODULE_3__.$msg)({ to: `${this.roomjid}/${id}`,
            type: 'chat' });
        // We are adding the message in packet. If this element is different
        // from 'body', we add our custom namespace for the same.
        // e.g. for 'json-message' message extension.
        if (elementName === 'body') {
            msg.c(elementName, message).up();
        }
        else {
            msg.c(elementName, { xmlns: 'http://jitsi.org/jitmeet' }, message)
                .up();
        }
        this.connection.send(msg);
        this.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_7__.XMPPEvents.SENDING_PRIVATE_CHAT_MESSAGE, message);
    }
    /* eslint-enable max-params */
    /**
     *
     * @param subject
     */
    setSubject(subject) {
        const msg = (0,strophe_js__WEBPACK_IMPORTED_MODULE_3__.$msg)({ to: this.roomjid,
            type: 'groupchat' });
        msg.c('subject', subject);
        this.connection.send(msg);
    }
    /**
     *
     * @param pres
     * @param from
     */
    onPresenceUnavailable(pres, from) {
        // ignore presence
        if (jquery__WEBPACK_IMPORTED_MODULE_1___default()(pres).find('>ignore[xmlns="http://jitsi.org/jitmeet/"]').length) {
            return true;
        }
        // room destroyed ?
        const destroySelect = jquery__WEBPACK_IMPORTED_MODULE_1___default()(pres).find('>x[xmlns="http://jabber.org/protocol/muc#user"]>destroy');
        if (destroySelect.length) {
            let reason;
            const reasonSelect = jquery__WEBPACK_IMPORTED_MODULE_1___default()(pres).find('>x[xmlns="http://jabber.org/protocol/muc#user"]'
                + '>destroy>reason');
            if (reasonSelect.length) {
                reason = reasonSelect.text();
            }
            this.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_7__.XMPPEvents.MUC_DESTROYED, reason, destroySelect.attr('jid'));
            this.connection.emuc.doLeave(this.roomjid);
            return true;
        }
        // Status code 110 indicates that this notification is "self-presence".
        const isSelfPresence = jquery__WEBPACK_IMPORTED_MODULE_1___default()(pres)
            .find('>x[xmlns="http://jabber.org/protocol/muc#user"]>'
            + 'status[code="110"]')
            .length;
        const isKick = jquery__WEBPACK_IMPORTED_MODULE_1___default()(pres)
            .find('>x[xmlns="http://jabber.org/protocol/muc#user"]'
            + '>status[code="307"]')
            .length;
        const membersKeys = Object.keys(this.members);
        const isReplaceParticipant = jquery__WEBPACK_IMPORTED_MODULE_1___default()(pres).find('flip_device').length;
        if (isKick) {
            const actorSelect = jquery__WEBPACK_IMPORTED_MODULE_1___default()(pres)
                .find('>x[xmlns="http://jabber.org/protocol/muc#user"]>item>actor');
            let actorNick;
            if (actorSelect.length) {
                actorNick = actorSelect.attr('nick');
            }
            let reason;
            const reasonSelect = jquery__WEBPACK_IMPORTED_MODULE_1___default()(pres).find('>x[xmlns="http://jabber.org/protocol/muc#user"]'
                + '>item>reason');
            if (reasonSelect.length) {
                reason = reasonSelect.text();
            }
            // we first fire the kicked so we can show the participant
            // who kicked, before notifying that participant left
            // we fire kicked for us and for any participant kicked
            this.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_7__.XMPPEvents.KICKED, isSelfPresence, actorNick, strophe_js__WEBPACK_IMPORTED_MODULE_3__.Strophe.getResourceFromJid(from), reason, isReplaceParticipant);
        }
        if (isSelfPresence) {
            // If the status code is 110 this means we're leaving and we would
            // like to remove everyone else from our view, so we trigger the
            // event.
            membersKeys.forEach(jid => {
                const member = this.members[jid];
                delete this.members[jid];
                delete this.lastPresences[jid];
                if (!member.isFocus) {
                    this.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_7__.XMPPEvents.MUC_MEMBER_LEFT, jid);
                }
            });
            this.connection.emuc.doLeave(this.roomjid);
            // we fire muc_left only if this is not a kick,
            // kick has both statuses 110 and 307.
            if (!isKick) {
                this.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_7__.XMPPEvents.MUC_LEFT);
            }
        }
        else {
            const reasonSelect = jquery__WEBPACK_IMPORTED_MODULE_1___default()(pres).find('>status');
            const member = this.members[from];
            let reason;
            if (reasonSelect.length) {
                reason = reasonSelect.text();
            }
            delete this.members[from];
            delete this.lastPresences[from];
            // In this case we *do* fire MUC_MEMBER_LEFT for the focus?
            this.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_7__.XMPPEvents.MUC_MEMBER_LEFT, from, reason);
            if (member === null || member === void 0 ? void 0 : member.isFocus) {
                logger.info('Focus has left the room - leaving conference');
                this.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_7__.XMPPEvents.FOCUS_LEFT);
            }
        }
    }
    /**
     *
     * @param msg
     * @param from
     */
    onMessage(msg, from) {
        const type = msg.getAttribute('type');
        if (type === 'error') {
            const settingsErrorMsg = jquery__WEBPACK_IMPORTED_MODULE_1___default()(msg).find('>settings-error>text').text();
            if (settingsErrorMsg.length) {
                this.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_7__.XMPPEvents.SETTINGS_ERROR_RECEIVED, settingsErrorMsg);
                return true;
            }
            const errorMsg = jquery__WEBPACK_IMPORTED_MODULE_1___default()(msg).find('>error>text').text();
            this.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_7__.XMPPEvents.CHAT_ERROR_RECEIVED, errorMsg);
            return true;
        }
        const txt = jquery__WEBPACK_IMPORTED_MODULE_1___default()(msg).find('>body').text();
        const subject = jquery__WEBPACK_IMPORTED_MODULE_1___default()(msg).find('>subject');
        if (subject.length) {
            const subjectText = subject.text();
            if (subjectText || subjectText === '') {
                this.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_7__.XMPPEvents.SUBJECT_CHANGED, subjectText);
                logger.log(`Subject is changed to ${subjectText}`);
            }
        }
        // xep-0203 delay
        let stamp = jquery__WEBPACK_IMPORTED_MODULE_1___default()(msg).find('>delay').attr('stamp');
        if (!stamp) {
            // or xep-0091 delay, UTC timestamp
            stamp = jquery__WEBPACK_IMPORTED_MODULE_1___default()(msg).find('>[xmlns="jabber:x:delay"]').attr('stamp');
            if (stamp) {
                // the format is CCYYMMDDThh:mm:ss
                const dateParts = stamp.match(/(\d{4})(\d{2})(\d{2}T\d{2}:\d{2}:\d{2})/);
                stamp = `${dateParts[1]}-${dateParts[2]}-${dateParts[3]}Z`;
            }
        }
        if (from === this.roomjid) {
            let invite;
            if (jquery__WEBPACK_IMPORTED_MODULE_1___default()(msg).find('>x[xmlns="http://jabber.org/protocol/muc#user"]>status[code="104"]').length) {
                this.discoRoomInfo();
            }
            else if ((invite = jquery__WEBPACK_IMPORTED_MODULE_1___default()(msg).find('>x[xmlns="http://jabber.org/protocol/muc#user"]>invite'))
                && invite.length) {
                const passwordSelect = jquery__WEBPACK_IMPORTED_MODULE_1___default()(msg).find('>x[xmlns="http://jabber.org/protocol/muc#user"]>password');
                let password;
                if (passwordSelect && passwordSelect.length) {
                    password = passwordSelect.text();
                }
                this.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_7__.XMPPEvents.INVITE_MESSAGE_RECEIVED, from, invite.attr('from'), txt, password);
            }
        }
        const jsonMessage = jquery__WEBPACK_IMPORTED_MODULE_1___default()(msg).find('>json-message').text();
        if (jsonMessage) {
            const parsedJson = this.xmpp.tryParseJSONAndVerify(jsonMessage);
            // We emit this event if the message is a valid json, and is not
            // delivered after a delay, i.e. stamp is undefined.
            // e.g. - subtitles should not be displayed if delayed.
            if (parsedJson && stamp === undefined) {
                this.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_7__.XMPPEvents.JSON_MESSAGE_RECEIVED, from, parsedJson);
                return;
            }
        }
        if (txt) {
            if (type === 'chat') {
                this.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_7__.XMPPEvents.PRIVATE_MESSAGE_RECEIVED, from, txt, this.myroomjid, stamp);
            }
            else if (type === 'groupchat') {
                const nickEl = jquery__WEBPACK_IMPORTED_MODULE_1___default()(msg).find('>nick');
                let nick;
                if (nickEl.length > 0) {
                    nick = nickEl.text();
                }
                // we will fire explicitly that this is a guest(isGuest:true) to the conference
                // informing that this is probably a message from a guest to the conference (visitor)
                // a message with explicit name set
                this.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_7__.XMPPEvents.MESSAGE_RECEIVED, from, txt, this.myroomjid, stamp, nick, Boolean(nick));
            }
        }
    }
    /**
     *
     * @param pres
     * @param from
     */
    onPresenceError(pres, from) {
        var _a;
        let errorDescriptionNode;
        if (jquery__WEBPACK_IMPORTED_MODULE_1___default()(pres)
            .find('>error[type="auth"]'
            + '>not-authorized['
            + 'xmlns="urn:ietf:params:xml:ns:xmpp-stanzas"]')
            .length) {
            logger.log('on password required', from);
            this.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_7__.XMPPEvents.PASSWORD_REQUIRED);
        }
        else if (jquery__WEBPACK_IMPORTED_MODULE_1___default()(pres)
            .find('>error[type="cancel"]'
            + '>not-allowed['
            + 'xmlns="urn:ietf:params:xml:ns:xmpp-stanzas"]')
            .length) {
            const toDomain = strophe_js__WEBPACK_IMPORTED_MODULE_3__.Strophe.getDomainFromJid(pres.getAttribute('to'));
            if (toDomain === this.xmpp.options.hosts.anonymousdomain) {
                // enter the room by replying with 'not-authorized'. This would
                // result in reconnection from authorized domain.
                // We're either missing Jicofo/Prosody config for anonymous
                // domains or something is wrong.
                this.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_7__.XMPPEvents.ROOM_JOIN_ERROR);
            }
            else {
                logger.warn('onPresError ', pres);
                this.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_7__.XMPPEvents.ROOM_CONNECT_NOT_ALLOWED_ERROR);
            }
        }
        else if (jquery__WEBPACK_IMPORTED_MODULE_1___default()(pres).find('>error>service-unavailable').length) {
            logger.warn('Maximum users limit for the room has been reached', pres);
            this.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_7__.XMPPEvents.ROOM_MAX_USERS_ERROR);
        }
        else if (jquery__WEBPACK_IMPORTED_MODULE_1___default()(pres)
            .find('>error[type="auth"]'
            + '>registration-required['
            + 'xmlns="urn:ietf:params:xml:ns:xmpp-stanzas"]').length) {
            // let's extract the lobby jid from the custom field
            const lobbyRoomNode = jquery__WEBPACK_IMPORTED_MODULE_1___default()(pres).find('>error[type="auth"]>lobbyroom');
            let lobbyRoomJid;
            if (lobbyRoomNode.length) {
                lobbyRoomJid = lobbyRoomNode.text();
            }
            const waitingForHost = jquery__WEBPACK_IMPORTED_MODULE_1___default()(pres).find('>error[type="auth"]>waiting-for-host').length > 0;
            this.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_7__.XMPPEvents.ROOM_CONNECT_MEMBERS_ONLY_ERROR, lobbyRoomJid, waitingForHost);
        }
        else if ((errorDescriptionNode = jquery__WEBPACK_IMPORTED_MODULE_1___default()(pres).find('>error[type="modify"]>displayname-required[xmlns="http://jitsi.org/jitmeet"]')).length) {
            logger.warn('display name required ', pres);
            this.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_7__.XMPPEvents.DISPLAY_NAME_REQUIRED, (_a = errorDescriptionNode[0].attributes.lobby) === null || _a === void 0 ? void 0 : _a.value);
        }
        else {
            logger.warn('onPresError ', pres);
            this.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_7__.XMPPEvents.ROOM_CONNECT_ERROR);
        }
    }
    /**
     *
     * @param jid
     * @param affiliation
     */
    setAffiliation(jid, affiliation) {
        const grantIQ = (0,strophe_js__WEBPACK_IMPORTED_MODULE_3__.$iq)({
            to: this.roomjid,
            type: 'set'
        })
            .c('query', { xmlns: 'http://jabber.org/protocol/muc#admin' })
            .c('item', {
            affiliation,
            jid: strophe_js__WEBPACK_IMPORTED_MODULE_3__.Strophe.getBareJidFromJid(jid)
        })
            .c('reason').t(`Your affiliation has been changed to '${affiliation}'.`)
            .up().up().up();
        this.connection.sendIQ(grantIQ, result => logger.log('Set affiliation of participant with jid: ', jid, 'to', affiliation, result), error => logger.log('Set affiliation of participant error: ', error));
    }
    /**
     *
     * @param jid
     * @param reason
     */
    kick(jid, reason = 'You have been kicked.') {
        const kickIQ = (0,strophe_js__WEBPACK_IMPORTED_MODULE_3__.$iq)({ to: this.roomjid,
            type: 'set' })
            .c('query', { xmlns: 'http://jabber.org/protocol/muc#admin' })
            .c('item', { nick: strophe_js__WEBPACK_IMPORTED_MODULE_3__.Strophe.getResourceFromJid(jid),
            role: 'none' })
            .c('reason').t(reason).up().up().up();
        this.connection.sendIQ(kickIQ, result => logger.log('Kick participant with jid: ', jid, result), error => logger.log('Kick participant error: ', error));
    }
    /* eslint-disable max-params */
    /**
     *
     * @param key
     * @param onSuccess
     * @param onError
     * @param onNotSupported
     */
    lockRoom(key, onSuccess, onError, onNotSupported) {
        // http://xmpp.org/extensions/xep-0045.html#roomconfig
        this.connection.sendIQ((0,strophe_js__WEBPACK_IMPORTED_MODULE_3__.$iq)({
            to: this.roomjid,
            type: 'get'
        })
            .c('query', { xmlns: 'http://jabber.org/protocol/muc#owner' }), res => {
            if (jquery__WEBPACK_IMPORTED_MODULE_1___default()(res)
                .find('>query>x[xmlns="jabber:x:data"]'
                + '>field[var="muc#roomconfig_roomsecret"]')
                .length) {
                const formsubmit = (0,strophe_js__WEBPACK_IMPORTED_MODULE_3__.$iq)({
                    to: this.roomjid,
                    type: 'set'
                })
                    .c('query', {
                    xmlns: 'http://jabber.org/protocol/muc#owner'
                });
                formsubmit.c('x', {
                    xmlns: 'jabber:x:data',
                    type: 'submit'
                });
                formsubmit
                    .c('field', { 'var': 'FORM_TYPE' })
                    .c('value')
                    .t('http://jabber.org/protocol/muc#roomconfig')
                    .up()
                    .up();
                formsubmit
                    .c('field', { 'var': 'muc#roomconfig_roomsecret' })
                    .c('value')
                    .t(key)
                    .up()
                    .up();
                formsubmit
                    .c('field', { 'var': 'muc#roomconfig_passwordprotectedroom' })
                    .c('value')
                    .t(key === null || key.length === 0 ? '0' : '1')
                    .up()
                    .up();
                // if members only enabled
                if (this.membersOnlyEnabled) {
                    formsubmit
                        .c('field', { 'var': 'muc#roomconfig_membersonly' })
                        .c('value')
                        .t('true')
                        .up()
                        .up();
                }
                // Fixes a bug in prosody 0.9.+
                // https://prosody.im/issues/issue/373
                formsubmit
                    .c('field', { 'var': 'muc#roomconfig_whois' })
                    .c('value')
                    .t('anyone')
                    .up()
                    .up();
                this.connection.sendIQ(formsubmit, () => {
                    // we set the password in chat room so we can use it
                    // later when dialing out
                    this.password = key;
                    onSuccess();
                }, onError);
            }
            else {
                onNotSupported();
            }
        }, onError);
    }
    /* eslint-enable max-params */
    /**
     * Turns off or on the members only config for the main room.
     *
     * @param {boolean} enabled - Whether to turn it on or off.
     * @param onSuccess - optional callback.
     * @param onError - optional callback.
     */
    setMembersOnly(enabled, onSuccess, onError) {
        if (enabled && Object.values(this.members).filter(m => !m.isFocus).length) {
            // first grant membership to all that are in the room
            // currently there is a bug in prosody where it handles only the first item
            // that's why we will send iq per member
            Object.values(this.members).forEach(m => {
                if (m.jid && !MEMBERS_AFFILIATIONS.includes(m.affiliation)) {
                    this.xmpp.connection.sendIQ((0,strophe_js__WEBPACK_IMPORTED_MODULE_3__.$iq)({
                        to: this.roomjid,
                        type: 'set'
                    })
                        .c('query', {
                        xmlns: 'http://jabber.org/protocol/muc#admin'
                    })
                        .c('item', {
                        'affiliation': 'member',
                        'jid': strophe_js__WEBPACK_IMPORTED_MODULE_3__.Strophe.getBareJidFromJid(m.jid)
                    }).up().up());
                }
            });
        }
        const errorCallback = onError ? onError : () => { }; // eslint-disable-line no-empty-function
        this.xmpp.connection.sendIQ((0,strophe_js__WEBPACK_IMPORTED_MODULE_3__.$iq)({
            to: this.roomjid,
            type: 'get'
        }).c('query', { xmlns: 'http://jabber.org/protocol/muc#owner' }), res => {
            if (jquery__WEBPACK_IMPORTED_MODULE_1___default()(res).find('>query>x[xmlns="jabber:x:data"]>field[var="muc#roomconfig_membersonly"]').length) {
                const formToSubmit = (0,strophe_js__WEBPACK_IMPORTED_MODULE_3__.$iq)({
                    to: this.roomjid,
                    type: 'set'
                }).c('query', { xmlns: 'http://jabber.org/protocol/muc#owner' });
                formToSubmit.c('x', {
                    xmlns: 'jabber:x:data',
                    type: 'submit'
                });
                formToSubmit
                    .c('field', { 'var': 'FORM_TYPE' })
                    .c('value')
                    .t('http://jabber.org/protocol/muc#roomconfig')
                    .up()
                    .up();
                formToSubmit
                    .c('field', { 'var': 'muc#roomconfig_membersonly' })
                    .c('value')
                    .t(enabled ? 'true' : 'false')
                    .up()
                    .up();
                // if room is locked from other participant or we are locking it
                if (this.locked) {
                    formToSubmit
                        .c('field', { 'var': 'muc#roomconfig_passwordprotectedroom' })
                        .c('value')
                        .t('1')
                        .up()
                        .up();
                }
                this.xmpp.connection.sendIQ(formToSubmit, onSuccess, errorCallback);
            }
            else {
                errorCallback(new Error('Setting members only room not supported!'));
            }
        }, errorCallback);
    }
    /**
     * Adds the key to the presence map, overriding any previous value.
     * This method is used by jibri.
     *
     * @param key The key to add or replace.
     * @param values The new values.
     * @returns {boolean|null} <tt>true</tt> if the operation succeeded or <tt>false</tt> when no add or replce was
     * performed as the value was already there.
     * @deprecated Use 'addOrReplaceInPresence' instead. TODO: remove it from here and jibri.
     */
    addToPresence(key, values) {
        return this.addOrReplaceInPresence(key, values);
    }
    /**
     * Adds the key to the presence map, overriding any previous value.
     * @param key The key to add or replace.
     * @param values The new values.
     * @returns {boolean|null} <tt>true</tt> if the operation succeeded or <tt>false</tt> when no add or replace was
     * performed as the value was already there.
     */
    addOrReplaceInPresence(key, values) {
        values.tagName = key;
        const matchingNodes = this.presMap.nodes.filter(node => key === node.tagName);
        // if we have found just one, let's check is it the same
        if (matchingNodes.length === 1 && lodash_isequal__WEBPACK_IMPORTED_MODULE_2___default()(matchingNodes[0], values)) {
            return false;
        }
        this.removeFromPresence(key);
        this.presMap.nodes.push(values);
        this.presenceUpdateTime = Date.now();
        return true;
    }
    /**
     * Retrieves a value from the presence map.
     *
     * @param {string} key - The key to find the value for.
     * @returns {Object?}
     */
    getFromPresence(key) {
        return this.presMap.nodes.find(node => key === node.tagName);
    }
    /**
     * Removes a key from the presence map.
     * @param key
     */
    removeFromPresence(key) {
        const nodes = this.presMap.nodes.filter(node => key !== node.tagName);
        this.presMap.nodes = nodes;
        this.presenceUpdateTime = Date.now();
    }
    /**
     *
     * @param name
     * @param handler
     */
    addPresenceListener(name, handler) {
        if (typeof handler !== 'function') {
            throw new Error('"handler" is not a function');
        }
        let tagHandlers = this.presHandlers[name];
        if (!tagHandlers) {
            this.presHandlers[name] = tagHandlers = [];
        }
        if (tagHandlers.indexOf(handler) === -1) {
            tagHandlers.push(handler);
        }
        else {
            logger.warn(`Trying to add the same handler more than once for: ${name}`);
        }
    }
    /**
     *
     * @param name
     * @param handler
     */
    removePresenceListener(name, handler) {
        const tagHandlers = this.presHandlers[name];
        const handlerIdx = tagHandlers ? tagHandlers.indexOf(handler) : -1;
        // eslint-disable-next-line no-negated-condition
        if (handlerIdx !== -1) {
            tagHandlers.splice(handlerIdx, 1);
        }
        else {
            logger.warn(`Handler for: ${name} was not registered`);
        }
    }
    /**
     * Checks if the user identified by given <tt>mucJid</tt> is the conference
     * focus.
     * @param mucJid the full MUC address of the user to be checked.
     * @returns {boolean|null} <tt>true</tt> if MUC user is the conference focus
     * or <tt>false</tt> if is not. When given <tt>mucJid</tt> does not exist in
     * the MUC then <tt>null</tt> is returned.
     */
    isFocus(mucJid) {
        const member = this.members[mucJid];
        if (member) {
            return member.isFocus;
        }
        return null;
    }
    /**
     *
     */
    isModerator() {
        return this.role === 'moderator';
    }
    /**
     * Redirected back.
     * @param iq The received iq.
     */
    onVisitorIQ(iq) {
        const visitors = jquery__WEBPACK_IMPORTED_MODULE_1___default()(iq).find('>visitors[xmlns="jitsi:visitors"]');
        const response = jquery__WEBPACK_IMPORTED_MODULE_1___default()(iq).find('promotion-response');
        if (visitors.length && response.length
            && String(response.attr('allow')).toLowerCase() === 'true') {
            logger.warn('Redirected back to main room.');
            this.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_7__.XMPPEvents.REDIRECTED, undefined, visitors.attr('focusjid'), response.attr('username'));
        }
    }
    /**
     * Obtains the info about given media advertised (in legacy format) in the MUC presence of the participant
     * identified by the given endpoint JID. This is for mantining interop with endpoints that do not support
     * source-name signaling (Jigasi and very old mobile clients).
     *
     * @param {string} endpointId the endpoint ID mapped to the participant which corresponds to MUC nickname.
     * @param {MediaType} mediaType the type of the media for which presence info will be obtained.
     * @return {PeerMediaInfo} presenceInfo an object with media presence info or <tt>null</tt> either if there
     * is no presence available or if the media type given is invalid.
     */
    getMediaPresenceInfo(endpointId, mediaType) {
        // Will figure out current muted status by looking up owner's presence
        const pres = this.lastPresences[`${this.roomjid}/${endpointId}`];
        if (!pres) {
            // No presence available
            return null;
        }
        const data = {
            muted: true,
            videoType: mediaType === _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_5__.MediaType.VIDEO ? _service_RTC_VideoType__WEBPACK_IMPORTED_MODULE_6__.VideoType.CAMERA : undefined // 'camera' by default
        };
        let mutedNode = null;
        if (mediaType === _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_5__.MediaType.AUDIO) {
            mutedNode = filterNodeFromPresenceJSON(pres, 'audiomuted');
        }
        else if (mediaType === _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_5__.MediaType.VIDEO) {
            mutedNode = filterNodeFromPresenceJSON(pres, 'videomuted');
            const codecTypeNode = filterNodeFromPresenceJSON(pres, 'jitsi_participant_codecType');
            const videoTypeNode = filterNodeFromPresenceJSON(pres, 'videoType');
            if (videoTypeNode.length > 0) {
                data.videoType = videoTypeNode[0].value;
            }
            if (codecTypeNode.length > 0) {
                data.codecType = codecTypeNode[0].value;
            }
        }
        else {
            logger.error(`Unsupported media type: ${mediaType}`);
            return null;
        }
        if (mutedNode.length > 0) {
            data.muted = mutedNode[0].value === 'true';
        }
        return data;
    }
    /**
     *
     * @param peerJid
     */
    getMemberRole(peerJid) {
        if (this.members[peerJid]) {
            return this.members[peerJid].role;
        }
        return null;
    }
    /**
     * Returns the last presence advertised by a MUC member.
     * @param {string} mucNick
     * @returns {*}
     */
    getLastPresence(mucNick) {
        return this.lastPresences[`${this.roomjid}/${mucNick}`];
    }
    /**
     * Dials a number.
     * @param number the number
     */
    dial(number) {
        return this.connection.rayo.dial(number, 'fromnumber', strophe_js__WEBPACK_IMPORTED_MODULE_3__.Strophe.getBareJidFromJid(this.myroomjid), this.password, this.focusMucJid);
    }
    /**
     * Hangup an existing call
     */
    hangup() {
        return this.connection.rayo.hangup();
    }
    /**
     *
     * @returns {Lobby}
     */
    getLobby() {
        return this.lobby;
    }
    /**
     * @returns {AVModeration}
     */
    getAVModeration() {
        return this.avModeration;
    }
    /**
     * @returns {BreakoutRooms}
     */
    getBreakoutRooms() {
        return this.breakoutRooms;
    }
    /**
     * @returns {RoomMetadata}
     */
    getMetadataHandler() {
        return this.roomMetadata;
    }
    /**
     * Returns the phone number for joining the conference.
     */
    getPhoneNumber() {
        return this.phoneNumber;
    }
    /**
     * Returns the pin for joining the conference with phone.
     */
    getPhonePin() {
        return this.phonePin;
    }
    /**
     * Returns the meeting unique ID if any came from backend.
     *
     * @returns {string} - The meeting ID.
     */
    getMeetingId() {
        return this.meetingId;
    }
    /**
     * Mutes remote participant.
     * @param jid of the participant
     * @param mute
     * @param mediaType
     */
    muteParticipant(jid, mute, mediaType) {
        logger.info('set mute', mute, jid);
        const iqToFocus = (0,strophe_js__WEBPACK_IMPORTED_MODULE_3__.$iq)({ to: this.focusMucJid,
            type: 'set' })
            .c('mute', {
            xmlns: `http://jitsi.org/jitmeet/${mediaType}`,
            jid
        })
            .t(mute.toString())
            .up();
        this.connection.sendIQ(iqToFocus, result => logger.log('set mute', result), error => logger.log('set mute error', error));
    }
    /**
     * TODO: Document
     * @param iq
     */
    onMute(iq) {
        const from = iq.getAttribute('from');
        if (from !== this.focusMucJid) {
            logger.warn('Ignored mute from non focus peer');
            return;
        }
        const mute = jquery__WEBPACK_IMPORTED_MODULE_1___default()(iq).find('mute');
        if (mute.length && mute.text() === 'true') {
            this.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_7__.XMPPEvents.AUDIO_MUTED_BY_FOCUS, mute.attr('actor'));
        }
        else {
            // XXX Why do we support anything but muting? Why do we encode the
            // value in the text of the element? Why do we use a separate XML
            // namespace?
            logger.warn('Ignoring a mute request which does not explicitly '
                + 'specify a positive mute command.');
        }
    }
    /**
     * TODO: Document
     * @param iq
     */
    onMuteVideo(iq) {
        const from = iq.getAttribute('from');
        if (from !== this.focusMucJid) {
            logger.warn('Ignored mute from non focus peer');
            return;
        }
        const mute = jquery__WEBPACK_IMPORTED_MODULE_1___default()(iq).find('mute');
        if (mute.length && mute.text() === 'true') {
            this.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_7__.XMPPEvents.VIDEO_MUTED_BY_FOCUS, mute.attr('actor'));
        }
        else {
            // XXX Why do we support anything but muting? Why do we encode the
            // value in the text of the element? Why do we use a separate XML
            // namespace?
            logger.warn('Ignoring a mute request which does not explicitly '
                + 'specify a positive mute command.');
        }
    }
    /**
     * Clean any listeners or resources, executed on leaving.
     */
    clean() {
        this._removeConnListeners.forEach(remove => remove());
        this._removeConnListeners = [];
        this.joined = false;
        this.inProgressEmitted = false;
    }
    /**
     * Leaves the room. Closes the jingle session.
     * @returns {Promise} which is resolved if XMPPEvents.MUC_LEFT is received
     * less than 5s after sending presence unavailable. Otherwise the promise is
     * rejected.
     */
    leave(reason) {
        var _a;
        this.avModeration.dispose();
        this.breakoutRooms.dispose();
        this.roomMetadata.dispose();
        const promises = [];
        ((_a = this.lobby) === null || _a === void 0 ? void 0 : _a.lobbyRoom) && promises.push(this.lobby.leave());
        promises.push(new Promise((resolve, reject) => {
            let timeout = -1;
            const onMucLeft = (doReject = false) => {
                this.eventEmitter.removeListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_7__.XMPPEvents.MUC_LEFT, onMucLeft);
                clearTimeout(timeout);
                if (doReject) {
                    // The timeout expired. Make sure we clean the EMUC state.
                    this.connection.emuc.doLeave(this.roomjid);
                    reject(new Error('The timeout for the confirmation about leaving the room expired.'));
                }
                else {
                    resolve();
                }
            };
            if (this.joined) {
                timeout = setTimeout(() => onMucLeft(true), 5000);
                this.clean();
                this.eventEmitter.on(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_7__.XMPPEvents.MUC_LEFT, onMucLeft);
                this.doLeave(reason);
            }
            else {
                // we are clearing up, and we haven't joined the room
                // there is no point of sending presence unavailable and check for timeout
                // let's just clean
                this.connection.emuc.doLeave(this.roomjid);
                this.clean();
            }
        }));
        return Promise.allSettled(promises);
    }
    /**
     * Ends the conference for all participants.
     */
    end() {
        if (this.breakoutRooms.isBreakoutRoom()) {
            logger.warn('Cannot end conference: this is a breakout room.');
            return;
        }
        // Send the end conference message.
        const msg = (0,strophe_js__WEBPACK_IMPORTED_MODULE_3__.$msg)({ to: this.xmpp.endConferenceComponentAddress });
        msg.c('end_conference').up();
        this.xmpp.connection.send(msg);
    }
}
/* eslint-enable newline-per-chained-call */
//# sourceMappingURL=ChatRoom.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/xmpp/ConnectionPlugin.js":
/*!**************************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/xmpp/ConnectionPlugin.js ***!
  \**************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   ConnectionPluginListenable: () => (/* binding */ ConnectionPluginListenable),
/* harmony export */   "default": () => (__WEBPACK_DEFAULT_EXPORT__)
/* harmony export */ });
/* harmony import */ var _util_Listenable__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../util/Listenable */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/util/Listenable.js");

/**
 * Creates ConnectionPlugin class that extends the passed class.
 * @param {Class} base the definition of the class that will be extended by
 * ConnectionPlugin
 */
function getConnectionPluginDefinition(base = class {
}) {
    /**
     * Base class for strophe connection plugins.
     */
    return class extends base {
        /**
         *
         */
        constructor(...args) {
            super(...args);
            this.connection = null;
        }
        /**
         *
         * @param connection
         */
        init(connection) {
            this.connection = connection;
        }
    };
}
/**
 * ConnectionPlugin class.
 */
/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (getConnectionPluginDefinition());
/**
 * ConnectionPlugin class that extends Listenable.
 */
const ConnectionPluginListenable = getConnectionPluginDefinition(_util_Listenable__WEBPACK_IMPORTED_MODULE_0__["default"]);
//# sourceMappingURL=ConnectionPlugin.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/xmpp/JingleHelperFunctions.js":
/*!*******************************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/xmpp/JingleHelperFunctions.js ***!
  \*******************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
var __filename = "/index.js";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   expandSourcesFromJson: () => (/* binding */ expandSourcesFromJson)
/* harmony export */ });
/* harmony import */ var _jitsi_logger__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @jitsi/logger */ "./node_modules/@jitsi/logger/lib/index.js");
/* harmony import */ var _jitsi_logger__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(_jitsi_logger__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var jquery__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! jquery */ "./node_modules/jquery/dist/jquery.js");
/* harmony import */ var jquery__WEBPACK_IMPORTED_MODULE_1___default = /*#__PURE__*/__webpack_require__.n(jquery__WEBPACK_IMPORTED_MODULE_1__);
/* harmony import */ var strophe_js__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! strophe.js */ "./node_modules/strophe.js/dist/strophe.umd.js");
/* harmony import */ var strophe_js__WEBPACK_IMPORTED_MODULE_2___default = /*#__PURE__*/__webpack_require__.n(strophe_js__WEBPACK_IMPORTED_MODULE_2__);
/* harmony import */ var _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../service/RTC/MediaType */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/RTC/MediaType.js");




const logger = (0,_jitsi_logger__WEBPACK_IMPORTED_MODULE_0__.getLogger)(__filename);
/**
 * Creates a "source" XML element for the source described in compact JSON format in [sourceCompactJson].
 * @param {*} owner the endpoint ID of the owner of the source.
 * @param {*} sourceCompactJson the compact JSON representation of the source.
 * @returns the created "source" XML element.
 */
function _createSourceExtension(owner, sourceCompactJson) {
    const node = (0,strophe_js__WEBPACK_IMPORTED_MODULE_2__.$build)('source', {
        xmlns: 'urn:xmpp:jingle:apps:rtp:ssma:0',
        ssrc: sourceCompactJson.s,
        name: sourceCompactJson.n
    });
    if (sourceCompactJson.m) {
        node.c('parameter', {
            name: 'msid',
            value: sourceCompactJson.m
        }).up();
    }
    node.c('ssrc-info', {
        xmlns: 'http://jitsi.org/jitmeet',
        owner
    }).up();
    return node.node;
}
/**
 * Creates an "ssrc-group" XML element for the SSRC group described in compact JSON format in [ssrcGroupCompactJson].
 * @param {*} ssrcGroupCompactJson the compact JSON representation of the SSRC group.
 * @returns the created "ssrc-group" element.
 */
function _createSsrcGroupExtension(ssrcGroupCompactJson) {
    const node = (0,strophe_js__WEBPACK_IMPORTED_MODULE_2__.$build)('ssrc-group', {
        xmlns: 'urn:xmpp:jingle:apps:rtp:ssma:0',
        semantics: _getSemantics(ssrcGroupCompactJson[0])
    });
    for (let i = 1; i < ssrcGroupCompactJson.length; i++) {
        node.c('source', {
            xmlns: 'urn:xmpp:jingle:apps:rtp:ssma:0',
            ssrc: ssrcGroupCompactJson[i]
        }).up();
    }
    return node.node;
}
/**
 * Finds in a Jingle IQ the RTP description element with the given media type. If one does not exists, create it (as
 *  well as the required  "content" parent element) and adds it to the IQ.
 * @param {*} iq
 * @param {*} mediaType The media type, "audio" or "video".
 * @returns the RTP description element with the given media type.
 */
function _getOrCreateRtpDescription(iq, mediaType) {
    const jingle = jquery__WEBPACK_IMPORTED_MODULE_1___default()(iq).find('jingle')[0];
    let content = jquery__WEBPACK_IMPORTED_MODULE_1___default()(jingle).find(`content[name="${mediaType}"]`);
    let description;
    if (content.length) {
        content = content[0];
    }
    else {
        // I'm not suree if "creator" and "senders" are required.
        content = (0,strophe_js__WEBPACK_IMPORTED_MODULE_2__.$build)('content', {
            name: mediaType
        }).node;
        jingle.appendChild(content);
    }
    description = jquery__WEBPACK_IMPORTED_MODULE_1___default()(content).find('description');
    if (description.length) {
        description = description[0];
    }
    else {
        description = (0,strophe_js__WEBPACK_IMPORTED_MODULE_2__.$build)('description', {
            xmlns: 'urn:xmpp:jingle:apps:rtp:1',
            media: mediaType
        }).node;
        content.appendChild(description);
    }
    return description;
}
/**
 * Converts the short string representing SSRC group semantics in compact JSON format to the standard representation
 * (i.e. convert "f" to "FID" and "s" to "SIM").
 * @param {*} str the compact JSON format representation of an SSRC group's semantics.
 * @returns the SSRC group semantics corresponding to [str].
 */
function _getSemantics(str) {
    if (str === 'f') {
        return 'FID';
    }
    else if (str === 's') {
        return 'SIM';
    }
    return null;
}
/**
 * Reads a JSON-encoded message (from a "json-message" element) and extracts source descriptions. Adds the extracted
 * source descriptions to the given Jingle IQ in the standard Jingle format.
 *
 * Encoding sources in this compact JSON format instead of standard Jingle was introduced in order to reduce the
 * network traffic and load on the XMPP server. The format is described in Jicofo [TODO: insert link].
 *
 * @param {*} iq the IQ to which source descriptions will be added.
 * @param {*} jsonMessageXml The XML node for the "json-message" element.
 * @returns {Map<string, Array<string>} The audio and video ssrcs extracted from the JSON-encoded message with remote
 * endpoint id as the key.
 */
function expandSourcesFromJson(iq, jsonMessageXml) {
    var _a, _b;
    let json;
    try {
        json = JSON.parse(jsonMessageXml.textContent);
    }
    catch (error) {
        logger.error(`json-message XML contained invalid JSON, ignoring: ${jsonMessageXml.textContent}`);
        return null;
    }
    if (!(json === null || json === void 0 ? void 0 : json.sources)) {
        // It might be a message of a different type, no need to log.
        return null;
    }
    // This is where we'll add "source" and "ssrc-group" elements. Create them elements if they don't exist.
    const audioRtpDescription = _getOrCreateRtpDescription(iq, _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_3__.MediaType.AUDIO);
    const videoRtpDescription = _getOrCreateRtpDescription(iq, _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_3__.MediaType.VIDEO);
    const ssrcMap = new Map();
    for (const owner in json.sources) {
        if (json.sources.hasOwnProperty(owner)) {
            const ssrcs = [];
            const ownerSources = json.sources[owner];
            // The video sources, video ssrc-groups, audio sources and audio ssrc-groups are encoded in that order in
            // the elements of the array.
            const videoSources = (ownerSources === null || ownerSources === void 0 ? void 0 : ownerSources.length) && ownerSources[0];
            const videoSsrcGroups = (ownerSources === null || ownerSources === void 0 ? void 0 : ownerSources.length) > 1 && ownerSources[1];
            const audioSources = (ownerSources === null || ownerSources === void 0 ? void 0 : ownerSources.length) > 2 && ownerSources[2];
            const audioSsrcGroups = (ownerSources === null || ownerSources === void 0 ? void 0 : ownerSources.length) > 3 && ownerSources[3];
            if (videoSources === null || videoSources === void 0 ? void 0 : videoSources.length) {
                for (let i = 0; i < videoSources.length; i++) {
                    videoRtpDescription.appendChild(_createSourceExtension(owner, videoSources[i]));
                    ssrcs.push((_a = videoSources[i]) === null || _a === void 0 ? void 0 : _a.s);
                }
            }
            if (videoSsrcGroups === null || videoSsrcGroups === void 0 ? void 0 : videoSsrcGroups.length) {
                for (let i = 0; i < videoSsrcGroups.length; i++) {
                    videoRtpDescription.appendChild(_createSsrcGroupExtension(videoSsrcGroups[i]));
                }
            }
            if (audioSources === null || audioSources === void 0 ? void 0 : audioSources.length) {
                for (let i = 0; i < audioSources.length; i++) {
                    audioRtpDescription.appendChild(_createSourceExtension(owner, audioSources[i]));
                    ssrcs.push((_b = audioSources[i]) === null || _b === void 0 ? void 0 : _b.s);
                }
            }
            if (audioSsrcGroups === null || audioSsrcGroups === void 0 ? void 0 : audioSsrcGroups.length) {
                for (let i = 0; i < audioSsrcGroups.length; i++) {
                    audioRtpDescription.appendChild(_createSsrcGroupExtension(audioSsrcGroups[i]));
                }
            }
            ssrcMap.set(owner, ssrcs);
        }
    }
    return ssrcMap;
}
//# sourceMappingURL=JingleHelperFunctions.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/xmpp/JingleSession.js":
/*!***********************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/xmpp/JingleSession.js ***!
  \***********************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
var __filename = "/index.js";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (/* binding */ JingleSession)
/* harmony export */ });
/* harmony import */ var _jitsi_logger__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @jitsi/logger */ "./node_modules/@jitsi/logger/lib/index.js");
/* harmony import */ var _jitsi_logger__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(_jitsi_logger__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var _util_Listenable__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../util/Listenable */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/util/Listenable.js");
/* harmony import */ var _JingleSessionState__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./JingleSessionState */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/xmpp/JingleSessionState.js");



const logger = (0,_jitsi_logger__WEBPACK_IMPORTED_MODULE_0__.getLogger)(__filename);
/**
 * JingleSession provides an API to manage a single Jingle session. We will
 * have different implementations depending on the underlying interface used
 * (i.e. WebRTC and ORTC) and here we hold the code common to all of them.
 */
class JingleSession extends _util_Listenable__WEBPACK_IMPORTED_MODULE_1__["default"] {
    /* eslint-disable max-params */
    /**
     * Creates new <tt>JingleSession</tt>.
     * @param {string} sid the Jingle session identifier
     * @param {string} localJid our JID
     * @param {string} remoteJid the JID of the remote peer
     * @param {XmppConnection} connection the XMPP connection
     * @param {Object} mediaConstraints the media constraints object passed to the PeerConnection onCreateAnswer/Offer.
     * @param {Object} pcConfig The {@code RTCConfiguration} object passed to the PeerConnection's constructor.
     * @param {boolean} isInitiator indicates if it will be the side which initiates the session.
     */
    constructor(sid, localJid, remoteJid, connection, mediaConstraints, pcConfig, isInitiator) {
        super();
        this.sid = sid;
        this.localJid = localJid;
        this.remoteJid = remoteJid;
        this.connection = connection;
        this.mediaConstraints = mediaConstraints;
        this.pcConfig = pcConfig;
        /**
         * Indicates whether this instance is an initiator or an answerer of
         * the Jingle session.
         * @type {boolean}
         */
        this.isInitiator = isInitiator;
        /**
         * Whether to use dripping or not. Dripping is sending trickle
         * candidates not one-by-one.
         */
        this.usedrip = true;
        /**
         *  When dripping is used, stores ICE candidates which are to be sent.
         */
        this.dripContainer = [];
        /**
         * The chat room instance associated with the session.
         * @type {ChatRoom}
         */
        this.room = null;
        /**
         * The signaling layer.
         * @type {SignalingLayerImpl | null}
         * @private
         */
        this._signalingLayer = null;
        /**
         * Jingle session state - uninitialized until {@link initialize} is
         * called @type {JingleSessionState}
         */
        this.state = null;
        /**
         * The RTC service instance
         * @type {RTC}
         */
        this.rtc = null;
    }
    /**
     * Returns XMPP address of this session's initiator.
     * @return {string}
     */
    get initiatorJid() {
        return this.isInitiator ? this.localJid : this.remoteJid;
    }
    /**
     * Returns XMPP address of this session's responder.
     * @return {string}
     */
    get responderJid() {
        return this.isInitiator ? this.remoteJid : this.localJid;
    }
    /* eslint-enable max-params */
    /**
     * Prepares this object to initiate a session.
     * @param {ChatRoom} room the chat room for the conference associated with
     * this session
     * @param {RTC} rtc the RTC service instance
     * @param {SignalingLayerImpl} signalingLayer - The signaling layer instance.
     * @param {object} options - the options, see implementing class's
     * {@link #doInitialize} description for more details.
     */
    initialize(room, rtc, signalingLayer, options) {
        if (this.state !== null) {
            const errmsg = `attempt to initiate on session ${this.sid}
                   in state ${this.state}`;
            logger.error(errmsg);
            throw new Error(errmsg);
        }
        // TODO decouple from room
        this.room = room;
        this.rtc = rtc;
        this._signalingLayer = signalingLayer;
        this.state = _JingleSessionState__WEBPACK_IMPORTED_MODULE_2__.PENDING;
        this.doInitialize(options);
    }
    /**
     * The implementing class finishes initialization here. Called at the end of
     * {@link initialize}.
     * @param {Object} options - The options specific to the implementing class.
     * @protected
     */
    doInitialize(options) { } // eslint-disable-line no-unused-vars, no-empty-function, max-len
    /* eslint-disable no-unused-vars, no-empty-function */
    /**
     * Adds the ICE candidates found in the 'contents' array as remote
     * candidates?
     * Note: currently only used on transport-info
     *
     * @param contents
     */
    addIceCandidates(contents) { }
    /* eslint-enable no-unused-vars, no-empty-function */
    /**
     * Returns current state of this <tt>JingleSession</tt> instance.
     * @returns {JingleSessionState} the current state of this session instance.
     */
    getState() {
        return this.state;
    }
    /* eslint-disable no-unused-vars, no-empty-function */
    /**
     * Handles an 'add-source' event.
     *
     * @param contents an array of Jingle 'content' elements.
     */
    addSources(contents) { }
    /**
     * Handles a 'remove-source' event.
     *
     * @param contents an array of Jingle 'content' elements.
     */
    removeSources(contents) { }
    /**
     * Terminates this Jingle session by sending session-terminate
     * @param success a callback called once the 'session-terminate' packet has
     * been acknowledged with RESULT.
     * @param failure a callback called when either timeout occurs or ERROR
     * response is received.
     * @param {Object} options
     * @param {string} [options.reason] XMPP Jingle error condition
     * @param {string} [options.reasonDescription] some meaningful error message
     * @param {boolean} [options.requestRestart=false] set to true to ask Jicofo to start a new session one this once is
     * terminated.
     * @param {boolean} [options.sendSessionTerminate=true] set to false to skip
     * sending session-terminate. It may not make sense to send it if the XMPP
     * connection has been closed already or if the remote peer has disconnected
     */
    terminate(success, failure, options) { }
    /**
     * Handles an offer from the remote peer (prepares to accept a session).
     * @param jingle the 'jingle' XML element.
     * @param success callback called when we the incoming session has been
     * accepted
     * @param failure callback called when we fail for any reason, will supply
     * error object with details(which is meant more to be printed to the logger
     * than analysed in the code, as the error is unrecoverable anyway)
     */
    acceptOffer(jingle, success, failure) { }
}
//# sourceMappingURL=JingleSession.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/xmpp/JingleSessionPC.js":
/*!*************************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/xmpp/JingleSessionPC.js ***!
  \*************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
var __filename = "/index.js";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (/* binding */ JingleSessionPC)
/* harmony export */ });
/* harmony import */ var _jitsi_logger__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @jitsi/logger */ "./node_modules/@jitsi/logger/lib/index.js");
/* harmony import */ var _jitsi_logger__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(_jitsi_logger__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var jquery__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! jquery */ "./node_modules/jquery/dist/jquery.js");
/* harmony import */ var jquery__WEBPACK_IMPORTED_MODULE_1___default = /*#__PURE__*/__webpack_require__.n(jquery__WEBPACK_IMPORTED_MODULE_1__);
/* harmony import */ var strophe_js__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! strophe.js */ "./node_modules/strophe.js/dist/strophe.umd.js");
/* harmony import */ var strophe_js__WEBPACK_IMPORTED_MODULE_2___default = /*#__PURE__*/__webpack_require__.n(strophe_js__WEBPACK_IMPORTED_MODULE_2__);
/* harmony import */ var _JitsiTrackEvents__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../JitsiTrackEvents */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/JitsiTrackEvents.js");
/* harmony import */ var _service_RTC_CodecMimeType__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../../service/RTC/CodecMimeType */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/RTC/CodecMimeType.js");
/* harmony import */ var _service_RTC_MediaDirection__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../../service/RTC/MediaDirection */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/RTC/MediaDirection.js");
/* harmony import */ var _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../../service/RTC/MediaType */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/RTC/MediaType.js");
/* harmony import */ var _service_RTC_VideoType__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../../service/RTC/VideoType */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/RTC/VideoType.js");
/* harmony import */ var _service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ../../service/statistics/AnalyticsEvents */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/statistics/AnalyticsEvents.js");
/* harmony import */ var _service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ../../service/xmpp/XMPPEvents */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/xmpp/XMPPEvents.js");
/* harmony import */ var _RTC_ScreenObtainer__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ../RTC/ScreenObtainer */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/RTC/ScreenObtainer.js");
/* harmony import */ var _flags_FeatureFlags__WEBPACK_IMPORTED_MODULE_11__ = __webpack_require__(/*! ../flags/FeatureFlags */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/flags/FeatureFlags.js");
/* harmony import */ var _sdp_SDP__WEBPACK_IMPORTED_MODULE_12__ = __webpack_require__(/*! ../sdp/SDP */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/sdp/SDP.js");
/* harmony import */ var _sdp_SDPDiffer__WEBPACK_IMPORTED_MODULE_13__ = __webpack_require__(/*! ../sdp/SDPDiffer */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/sdp/SDPDiffer.js");
/* harmony import */ var _sdp_SDPUtil__WEBPACK_IMPORTED_MODULE_14__ = __webpack_require__(/*! ../sdp/SDPUtil */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/sdp/SDPUtil.js");
/* harmony import */ var _statistics_statistics__WEBPACK_IMPORTED_MODULE_15__ = __webpack_require__(/*! ../statistics/statistics */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/statistics/statistics.js");
/* harmony import */ var _util_AsyncQueue__WEBPACK_IMPORTED_MODULE_16__ = __webpack_require__(/*! ../util/AsyncQueue */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/util/AsyncQueue.js");
/* harmony import */ var _util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_17__ = __webpack_require__(/*! ../util/GlobalOnErrorHandler */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/util/GlobalOnErrorHandler.js");
/* harmony import */ var _util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_17___default = /*#__PURE__*/__webpack_require__.n(_util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_17__);
/* harmony import */ var _browser__WEBPACK_IMPORTED_MODULE_18__ = __webpack_require__(/*! ./../browser */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/browser/index.js");
/* harmony import */ var _JingleSession__WEBPACK_IMPORTED_MODULE_19__ = __webpack_require__(/*! ./JingleSession */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/xmpp/JingleSession.js");
/* harmony import */ var _JingleSessionState__WEBPACK_IMPORTED_MODULE_20__ = __webpack_require__(/*! ./JingleSessionState */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/xmpp/JingleSessionState.js");
/* harmony import */ var _MediaSessionEvents__WEBPACK_IMPORTED_MODULE_21__ = __webpack_require__(/*! ./MediaSessionEvents */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/xmpp/MediaSessionEvents.js");
/* harmony import */ var _XmppConnection__WEBPACK_IMPORTED_MODULE_22__ = __webpack_require__(/*! ./XmppConnection */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/xmpp/XmppConnection.js");























const logger = (0,_jitsi_logger__WEBPACK_IMPORTED_MODULE_0__.getLogger)(__filename);
/**
 * Constant tells how long we're going to wait for IQ response, before timeout
 * error is  triggered.
 * @type {number}
 */
const IQ_TIMEOUT = 10000;
/*
 * The default number of samples (per stat) to keep when webrtc stats gathering
 * is enabled in TraceablePeerConnection.
 */
const DEFAULT_MAX_STATS = 300;
/**
 * The time duration for which the client keeps gathering ICE candidates to be sent out in a single IQ.
 * @type {number} timeout in ms.
 */
const ICE_CAND_GATHERING_TIMEOUT = 150;
/**
 * Reads the endpoint ID given a string which represents either the endpoint's full JID, or the endpoint ID itself.
 * @param {String} jidOrEndpointId A string which is either the full JID of a participant, or the ID of an
 * endpoint/participant.
 * @returns The endpoint ID associated with 'jidOrEndpointId'.
 */
function getEndpointId(jidOrEndpointId) {
    return strophe_js__WEBPACK_IMPORTED_MODULE_2__.Strophe.getResourceFromJid(jidOrEndpointId) || jidOrEndpointId;
}
/**
 * Add "source" element as a child of "description" element.
 * @param {Object} description The "description" element to add to.
 * @param {Object} s Contains properties of the source being added.
 * @param {Number} ssrc_ The SSRC.
 * @param {String} msid The "msid" attribute.
 */
function _addSourceElement(description, s, ssrc_, msid) {
    description.c('source', {
        xmlns: 'urn:xmpp:jingle:apps:rtp:ssma:0',
        ssrc: ssrc_,
        name: s.source
    })
        .c('parameter', {
        name: 'msid',
        value: msid
    })
        .up()
        .c('ssrc-info', {
        xmlns: 'http://jitsi.org/jitmeet',
        owner: s.owner
    })
        .up()
        .up();
}
/**
 * @typedef {Object} JingleSessionPCOptions
 * video test ?(ask George).
 * @property {boolean} disableRtx - Described in the config.js[1].
 * @property {boolean} disableSimulcast - Described in the config.js[1].
 * @property {boolean} enableInsertableStreams - Set to true when the insertable streams constraints is to be enabled
 * on the PeerConnection.
 * @property {boolean} failICE - it's an option used in the tests. Set to
 * <tt>true</tt> to block any real candidates and make the ICE fail.
 * @property {boolean} gatherStats - Described in the config.js[1].
 * @property {object} p2p - Peer to peer related options (FIXME those could be
 * fetched from config.p2p on the upper level).
 * @property {boolean} preferH264 - Described in the config.js[1].
 * @property {Object} testing - Testing and/or experimental options.
 * @property {boolean} webrtcIceUdpDisable - Described in the config.js[1].
 * @property {boolean} webrtcIceTcpDisable - Described in the config.js[1].
 *
 * [1]: https://github.com/jitsi/jitsi-meet/blob/master/config.js
 */
/**
 *
 */
class JingleSessionPC extends _JingleSession__WEBPACK_IMPORTED_MODULE_19__["default"] {
    /**
     * Parses 'senders' attribute of the video content.
     * @param {jQuery} jingleContents
     * @return {string|null} one of the values of content "senders" attribute
     * defined by Jingle. If there is no "senders" attribute or if the value is
     * invalid then <tt>null</tt> will be returned.
     * @private
     */
    static parseVideoSenders(jingleContents) {
        const videoContents = jingleContents.find('>content[name="video"]');
        if (videoContents.length) {
            const senders = videoContents[0].getAttribute('senders');
            if (senders === 'both'
                || senders === 'initiator'
                || senders === 'responder'
                || senders === 'none') {
                return senders;
            }
        }
        return null;
    }
    /**
     * Parses the source-name and max frame height value of the 'content-modify' IQ when source-name signaling
     * is enabled.
     *
     * @param {jQuery} jingleContents - A jQuery selector pointing to the '>jingle' element.
     * @returns {Object|null}
     */
    static parseSourceMaxFrameHeight(jingleContents) {
        const receiverConstraints = [];
        const sourceFrameHeightSel = jingleContents.find('>content[name="video"]>source-frame-height');
        let maxHeight, sourceName;
        if (sourceFrameHeightSel.length) {
            sourceFrameHeightSel.each((_, source) => {
                sourceName = source.getAttribute('sourceName');
                maxHeight = source.getAttribute('maxHeight');
                receiverConstraints.push({
                    maxHeight,
                    sourceName
                });
            });
            return receiverConstraints;
        }
        return null;
    }
    /* eslint-disable max-params */
    /**
     * Creates new <tt>JingleSessionPC</tt>
     * @param {string} sid the Jingle Session ID - random string which identifies the session
     * @param {string} localJid our JID
     * @param {string} remoteJid remote peer JID
     * @param {XmppConnection} connection - The XMPP connection instance.
     * @param mediaConstraints the media constraints object passed to createOffer/Answer, as defined
     * by the WebRTC standard
     * @param pcConfig The {@code RTCConfiguration} to use for the WebRTC peer connection.
     * @param {boolean} isP2P indicates whether this instance is meant to be used in a direct, peer to
     * peer connection or <tt>false</tt> if it's a JVB connection.
     * @param {boolean} isInitiator indicates if it will be the side which initiates the session.
     * @constructor
     *
     * @implements {SignalingLayer}
     */
    constructor(sid, localJid, remoteJid, connection, mediaConstraints, pcConfig, isP2P, isInitiator) {
        super(sid, localJid, remoteJid, connection, mediaConstraints, pcConfig, isInitiator);
        /**
         * The bridge session's identifier. One Jingle session can during
         * it's lifetime participate in multiple bridge sessions managed by
         * Jicofo. A new bridge session is started whenever Jicofo sends
         * 'session-initiate' or 'transport-replace'.
         *
         * @type {?string}
         * @private
         */
        this._bridgeSessionId = null;
        /**
         * The oldest SDP passed to {@link notifyMySSRCUpdate} while the XMPP connection was offline that will be
         * used to update Jicofo once the XMPP connection goes back online.
         * @type {SDP|undefined}
         * @private
         */
        this._cachedOldLocalSdp = undefined;
        /**
         * The latest SDP passed to {@link notifyMySSRCUpdate} while the XMPP connection was offline that will be
         * used to update Jicofo once the XMPP connection goes back online.
         * @type {SDP|undefined}
         * @private
         */
        this._cachedNewLocalSdp = undefined;
        /**
         * Stores result of {@link window.performance.now()} at the time when
         * ICE enters 'checking' state.
         * @type {number|null} null if no value has been stored yet
         * @private
         */
        this._iceCheckingStartedTimestamp = null;
        /**
         * Stores result of {@link window.performance.now()} at the time when
         * first ICE candidate is spawned by the peerconnection to mark when
         * ICE gathering started. That's, because ICE gathering state changed
         * events are not supported by most of the browsers, so we try something
         * that will work everywhere. It may not be as accurate, but given that
         * 'host' candidate usually comes first, the delay should be minimal.
         * @type {number|null} null if no value has been stored yet
         * @private
         */
        this._gatheringStartedTimestamp = null;
        /**
         * Receiver constraints (max height) set by the application per remote source. Will be used for p2p connection.
         *
         * @type {Map<string, number>}
         */
        this._sourceReceiverConstraints = undefined;
        /**
         * Indicates whether or not this session is willing to send/receive
         * video media. When set to <tt>false</tt> the underlying peer
         * connection will disable local video transfer and the remote peer will
         * be will be asked to stop sending video via 'content-modify' IQ
         * (the senders attribute of video contents will be adjusted
         * accordingly). Note that this notification is sent only in P2P
         * session, because Jicofo does not support it yet. Obviously when
         * the value is changed from <tt>false</tt> to <tt>true</tt> another
         * notification will be sent to resume video transfer on the remote
         * side.
         * @type {boolean}
         * @private
         */
        this._localVideoActive = true;
        /**
         * Indicates whether or not the remote peer has video transfer active.
         * When set to <tt>true</tt> it means that remote peer is neither
         * sending nor willing to receive video. In such case we'll ask
         * our peerconnection to stop sending video by calling
         * {@link TraceablePeerConnection.setVideoTransferActive} with
         * <tt>false</tt>.
         * @type {boolean}
         * @private
         */
        this._remoteVideoActive = true;
        /**
         * Marks that ICE gathering duration has been reported already. That
         * prevents reporting it again, after eventual 'transport-replace' (JVB
         * conference migration/ICE restart).
         * @type {boolean}
         * @private
         */
        this._gatheringReported = false;
        this.lasticecandidate = false;
        this.closed = false;
        /**
         * Indicates whether or not this <tt>JingleSessionPC</tt> is used in
         * a peer to peer type of session.
         * @type {boolean} <tt>true</tt> if it's a peer to peer
         * session or <tt>false</tt> if it's a JVB session
         */
        this.isP2P = isP2P;
        /**
         * Remote preference for the receive video max frame height.
         *
         * @type {Number|undefined}
         */
        this.remoteRecvMaxFrameHeight = undefined;
        /**
         * Number of remote video sources, in SSRC rewriting mode.
         * Used to generate next unique msid attribute.
         *
         * @type {Number}
         */
        this.numRemoteVideoSources = 0;
        /**
         * Number of remote audio sources, in SSRC rewriting mode.
         * Used to generate next unique msid attribute.
         *
         * @type {Number}
         */
        this.numRemoteAudioSources = 0;
        /**
         * Remote preference for the receive video max frame heights when source-name signaling is enabled.
         *
         * @type {Map<string, number>|undefined}
         */
        this.remoteSourceMaxFrameHeights = undefined;
        /**
         * The queue used to serialize operations done on the peerconnection after the session is established.
         * The queue is paused until the first offer/answer cycle is complete. Only track or codec related
         * operations which necessitate a renegotiation cycle need to be pushed to the modification queue.
         * These tasks will be executed after the session has been established.
         *
         * @type {AsyncQueue}
         */
        this.modificationQueue = new _util_AsyncQueue__WEBPACK_IMPORTED_MODULE_16__["default"]();
        this.modificationQueue.pause();
        /**
         * Flag used to guarantee that the connection established event is
         * triggered just once.
         * @type {boolean}
         */
        this.wasConnected = false;
        /**
         * Keeps track of how long (in ms) it took from ICE start to ICE
         * connect.
         *
         * @type {number}
         */
        this.establishmentDuration = undefined;
        this._xmppListeners = [];
        this._xmppListeners.push(connection.addEventListener(_XmppConnection__WEBPACK_IMPORTED_MODULE_22__["default"].Events.CONN_STATUS_CHANGED, this.onXmppStatusChanged.bind(this)));
        this._removeSenderVideoConstraintsChangeListener = undefined;
    }
    /* eslint-enable max-params */
    /**
     * Checks whether or not this session instance is still operational.
     * @private
     * @returns {boolean} {@code true} if operation or {@code false} otherwise.
     */
    _assertNotEnded() {
        return this.state !== _JingleSessionState__WEBPACK_IMPORTED_MODULE_20__.ENDED;
    }
    /**
     * @inheritDoc
     * @param {JingleSessionPCOptions} options  - a set of config options.
     */
    doInitialize(options) {
        var _a, _b, _c;
        this.failICE = Boolean(options.failICE);
        this.lasticecandidate = false;
        this.options = options;
        /**
         * {@code true} if reconnect is in progress.
         * @type {boolean}
         */
        this.isReconnect = false;
        /**
         * Set to {@code true} if the connection was ever stable
         * @type {boolean}
         */
        this.wasstable = false;
        this.webrtcIceUdpDisable = Boolean(options.webrtcIceUdpDisable);
        this.webrtcIceTcpDisable = Boolean(options.webrtcIceTcpDisable);
        const pcOptions = { disableRtx: options.disableRtx };
        if (options.gatherStats) {
            pcOptions.maxstats = DEFAULT_MAX_STATS;
        }
        pcOptions.capScreenshareBitrate = false;
        pcOptions.codecSettings = options.codecSettings;
        pcOptions.enableInsertableStreams = options.enableInsertableStreams;
        pcOptions.videoQuality = options.videoQuality;
        pcOptions.forceTurnRelay = options.forceTurnRelay;
        pcOptions.audioQuality = options.audioQuality;
        pcOptions.usesUnifiedPlan = this.usesUnifiedPlan = _browser__WEBPACK_IMPORTED_MODULE_18__["default"].supportsUnifiedPlan();
        if (this.isP2P) {
            // simulcast needs to be disabled for P2P (121) calls
            pcOptions.disableSimulcast = true;
        }
        else {
            // H264 scalability is not supported on jvb, so simulcast needs to be disabled when H264 is preferred.
            pcOptions.disableSimulcast
                = options.disableSimulcast || ((_a = options.videoQuality) === null || _a === void 0 ? void 0 : _a.preferredCodec) === _service_RTC_CodecMimeType__WEBPACK_IMPORTED_MODULE_4__["default"].H264;
            // Do not send lower spatial layers for low fps screenshare and enable them only for high fps screenshare.
            pcOptions.capScreenshareBitrate = pcOptions.disableSimulcast
                || !(typeof ((_b = options.desktopSharingFrameRate) === null || _b === void 0 ? void 0 : _b.max) === 'number'
                    && ((_c = options.desktopSharingFrameRate) === null || _c === void 0 ? void 0 : _c.max) > _RTC_ScreenObtainer__WEBPACK_IMPORTED_MODULE_10__.SS_DEFAULT_FRAME_RATE);
        }
        if (options.startSilent) {
            pcOptions.startSilent = true;
        }
        this.peerconnection
            = this.rtc.createPeerConnection(this._signalingLayer, this.pcConfig, this.isP2P, pcOptions);
        this.peerconnection.onicecandidate = ev => {
            if (!ev) {
                // There was an incomplete check for ev before which left
                // the last line of the function unprotected from a potential
                // throw of an exception. Consequently, it may be argued that
                // the check is unnecessary. Anyway, I'm leaving it and making
                // the check complete.
                return;
            }
            // XXX this is broken, candidate is not parsed.
            const candidate = ev.candidate;
            const now = window.performance.now();
            if (candidate) {
                if (this._gatheringStartedTimestamp === null) {
                    this._gatheringStartedTimestamp = now;
                }
                // Discard candidates of disabled protocols.
                let protocol = candidate.protocol;
                if (typeof protocol === 'string') {
                    protocol = protocol.toLowerCase();
                    if (protocol === 'tcp' || protocol === 'ssltcp') {
                        if (this.webrtcIceTcpDisable) {
                            return;
                        }
                    }
                    else if (protocol === 'udp') {
                        if (this.webrtcIceUdpDisable) {
                            return;
                        }
                    }
                }
            }
            else if (!this._gatheringReported) {
                // End of gathering
                _statistics_statistics__WEBPACK_IMPORTED_MODULE_15__["default"].sendAnalytics(_service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_8__.ICE_DURATION, {
                    phase: 'gathering',
                    value: now - this._gatheringStartedTimestamp,
                    p2p: this.isP2P,
                    initiator: this.isInitiator
                });
                this._gatheringReported = true;
            }
            if (this.isP2P) {
                this.sendIceCandidate(candidate);
            }
        };
        // Note there is a change in the spec about closed:
        // This value moved into the RTCPeerConnectionState enum in
        // the May 13, 2016 draft of the specification, as it reflects the state
        // of the RTCPeerConnection, not the signaling connection. You now
        // detect a closed connection by checking for connectionState to be
        // "closed" instead.
        // I suppose at some point this will be moved to onconnectionstatechange
        this.peerconnection.onsignalingstatechange = () => {
            if (this.peerconnection.signalingState === 'stable') {
                this.wasstable = true;
            }
            else if (this.peerconnection.signalingState === 'closed'
                || this.peerconnection.connectionState === 'closed') {
                this.room.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_9__.XMPPEvents.SUSPEND_DETECTED, this);
            }
        };
        /**
         * The oniceconnectionstatechange event handler contains the code to
         * execute when the iceconnectionstatechange event, of type Event,
         * is received by this RTCPeerConnection. Such an event is sent when
         * the value of RTCPeerConnection.iceConnectionState changes.
         */
        this.peerconnection.oniceconnectionstatechange = () => {
            const now = window.performance.now();
            let isStable = false;
            if (!this.isP2P) {
                this.room.connectionTimes[`ice.state.${this.peerconnection.iceConnectionState}`]
                    = now;
            }
            logger.log(`(TIME) ICE ${this.peerconnection.iceConnectionState} ${this.isP2P ? 'P2P' : 'JVB'}:\t`, now);
            _statistics_statistics__WEBPACK_IMPORTED_MODULE_15__["default"].sendAnalytics(_service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_8__.ICE_STATE_CHANGED, {
                p2p: this.isP2P,
                state: this.peerconnection.iceConnectionState,
                'signaling_state': this.peerconnection.signalingState,
                reconnect: this.isReconnect,
                value: now
            });
            this.room.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_9__.XMPPEvents.ICE_CONNECTION_STATE_CHANGED, this, this.peerconnection.iceConnectionState);
            switch (this.peerconnection.iceConnectionState) {
                case 'checking':
                    this._iceCheckingStartedTimestamp = now;
                    break;
                case 'connected':
                    // Informs interested parties that the connection has been restored. This includes the case when
                    // media connection to the bridge has been restored after an ICE failure by using session-terminate.
                    if (this.peerconnection.signalingState === 'stable') {
                        isStable = true;
                        const usesTerminateForRestart = !this.options.enableIceRestart
                            && this.room.supportsRestartByTerminate();
                        if (this.isReconnect || usesTerminateForRestart) {
                            this.room.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_9__.XMPPEvents.CONNECTION_RESTORED, this);
                        }
                    }
                    // Add a workaround for an issue on chrome in Unified plan when the local endpoint is the offerer.
                    // The 'signalingstatechange' event for 'stable' is handled after the 'iceconnectionstatechange' event
                    // for 'completed' is handled by the client. This prevents the client from firing a
                    // CONNECTION_ESTABLISHED event for the p2p session. As a result, the offerer continues to stay on the
                    // jvb connection while the remote peer switches to the p2p connection breaking the media flow between
                    // the endpoints.
                    // TODO - file a chromium bug and add the information here.
                    if (!this.wasConnected
                        && (this.wasstable
                            || isStable
                            || (this.usesUnifiedPlan && this.isInitiator
                                && (_browser__WEBPACK_IMPORTED_MODULE_18__["default"].isChromiumBased() || _browser__WEBPACK_IMPORTED_MODULE_18__["default"].isReactNative())))) {
                        _statistics_statistics__WEBPACK_IMPORTED_MODULE_15__["default"].sendAnalytics(_service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_8__.ICE_DURATION, {
                            phase: 'checking',
                            value: now - this._iceCheckingStartedTimestamp,
                            p2p: this.isP2P,
                            initiator: this.isInitiator
                        });
                        // Switch between ICE gathering and ICE checking whichever
                        // started first (scenarios are different for initiator
                        // vs responder)
                        const iceStarted = Math.min(this._iceCheckingStartedTimestamp, this._gatheringStartedTimestamp);
                        this.establishmentDuration = now - iceStarted;
                        _statistics_statistics__WEBPACK_IMPORTED_MODULE_15__["default"].sendAnalytics(_service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_8__.ICE_DURATION, {
                            phase: 'establishment',
                            value: this.establishmentDuration,
                            p2p: this.isP2P,
                            initiator: this.isInitiator
                        });
                        this.wasConnected = true;
                        this.room.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_9__.XMPPEvents.CONNECTION_ESTABLISHED, this);
                    }
                    this.isReconnect = false;
                    break;
                case 'disconnected':
                    this.isReconnect = true;
                    // Informs interested parties that the connection has been
                    // interrupted.
                    if (this.wasstable) {
                        this.room.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_9__.XMPPEvents.CONNECTION_INTERRUPTED, this);
                    }
                    break;
                case 'failed':
                    this.room.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_9__.XMPPEvents.CONNECTION_ICE_FAILED, this);
                    break;
            }
        };
        /**
         * The connection state event is fired whenever the aggregate of underlying
         * transports change their state.
         */
        this.peerconnection.onconnectionstatechange = () => {
            const icestate = this.peerconnection.iceConnectionState;
            switch (this.peerconnection.connectionState) {
                case 'failed':
                    // Since version 76 Chrome no longer switches ICE connection
                    // state to failed (see
                    // https://bugs.chromium.org/p/chromium/issues/detail?id=982793
                    // for details) we use this workaround to recover from lost connections
                    if (icestate === 'disconnected') {
                        this.room.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_9__.XMPPEvents.CONNECTION_ICE_FAILED, this);
                    }
                    break;
            }
        };
        /**
         * The negotiationneeded event is fired whenever we shake the media on the
         * RTCPeerConnection object.
         */
        this.peerconnection.onnegotiationneeded = () => {
            const state = this.peerconnection.signalingState;
            const remoteDescription = this.peerconnection.remoteDescription;
            if (this.usesUnifiedPlan
                && !this.isP2P
                && state === 'stable'
                && remoteDescription
                && typeof remoteDescription.sdp === 'string') {
                logger.info(`${this} onnegotiationneeded fired on ${this.peerconnection}`);
                const workFunction = finishedCallback => {
                    this._renegotiate()
                        .then(() => finishedCallback(), error => finishedCallback(error));
                };
                this.modificationQueue.push(workFunction, error => {
                    if (error) {
                        logger.error(`${this} onnegotiationneeded error`, error);
                    }
                    else {
                        logger.debug(`${this} onnegotiationneeded executed - OK`);
                    }
                });
            }
        };
    }
    /**
     * Remote preference for receive video max frame height.
     *
     * @returns {Number|undefined}
     */
    getRemoteRecvMaxFrameHeight() {
        if (this.isP2P) {
            return this.remoteRecvMaxFrameHeight;
        }
        return undefined;
    }
    /**
     * Remote preference for receive video max frame heights when source-name signaling is enabled.
     *
     * @returns {Map<string, number>|undefined}
     */
    getRemoteSourcesRecvMaxFrameHeight() {
        if (this.isP2P) {
            return this.remoteSourceMaxFrameHeights;
        }
        return undefined;
    }
    /**
     * Sends given candidate in Jingle 'transport-info' message.
     * @param {RTCIceCandidate} candidate the WebRTC ICE candidate instance
     * @private
     */
    sendIceCandidate(candidate) {
        const localSDP = new _sdp_SDP__WEBPACK_IMPORTED_MODULE_12__["default"](this.peerconnection.localDescription.sdp);
        if (candidate && candidate.candidate.length && !this.lasticecandidate) {
            const ice = _sdp_SDPUtil__WEBPACK_IMPORTED_MODULE_14__["default"].iceparams(localSDP.media[candidate.sdpMLineIndex], localSDP.session);
            const jcand = _sdp_SDPUtil__WEBPACK_IMPORTED_MODULE_14__["default"].candidateToJingle(candidate.candidate);
            if (!(ice && jcand)) {
                const errorMesssage = 'failed to get ice && jcand';
                _util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_17___default().callErrorHandler(new Error(errorMesssage));
                logger.error(errorMesssage);
                return;
            }
            ice.xmlns = 'urn:xmpp:jingle:transports:ice-udp:1';
            if (this.usedrip) {
                if (this.dripContainer.length === 0) {
                    setTimeout(() => {
                        if (this.dripContainer.length === 0) {
                            return;
                        }
                        this.sendIceCandidates(this.dripContainer);
                        this.dripContainer = [];
                    }, ICE_CAND_GATHERING_TIMEOUT);
                }
                this.dripContainer.push(candidate);
            }
            else {
                this.sendIceCandidates([candidate]);
            }
        }
        else {
            logger.log(`${this} sendIceCandidate: last candidate`);
            // FIXME: remember to re-think in ICE-restart
            this.lasticecandidate = true;
        }
    }
    /**
     * Sends given candidates in Jingle 'transport-info' message.
     * @param {Array<RTCIceCandidate>} candidates an array of the WebRTC ICE
     * candidate instances
     * @private
     */
    sendIceCandidates(candidates) {
        if (!this._assertNotEnded('sendIceCandidates')) {
            return;
        }
        logger.log(`${this} sendIceCandidates ${JSON.stringify(candidates)}`);
        const cand = (0,strophe_js__WEBPACK_IMPORTED_MODULE_2__.$iq)({ to: this.remoteJid,
            type: 'set' })
            .c('jingle', { xmlns: 'urn:xmpp:jingle:1',
            action: 'transport-info',
            initiator: this.initiatorJid,
            sid: this.sid });
        const localSDP = new _sdp_SDP__WEBPACK_IMPORTED_MODULE_12__["default"](this.peerconnection.localDescription.sdp);
        for (let mid = 0; mid < localSDP.media.length; mid++) {
            const cands = candidates.filter(el => el.sdpMLineIndex === mid);
            const mline = _sdp_SDPUtil__WEBPACK_IMPORTED_MODULE_14__["default"].parseMLine(localSDP.media[mid].split('\r\n')[0]);
            if (cands.length > 0) {
                const ice = _sdp_SDPUtil__WEBPACK_IMPORTED_MODULE_14__["default"].iceparams(localSDP.media[mid], localSDP.session);
                ice.xmlns = 'urn:xmpp:jingle:transports:ice-udp:1';
                cand.c('content', {
                    creator: this.initiatorJid === this.localJid
                        ? 'initiator' : 'responder',
                    name: cands[0].sdpMid ? cands[0].sdpMid : mline.media
                }).c('transport', ice);
                for (let i = 0; i < cands.length; i++) {
                    const candidate = _sdp_SDPUtil__WEBPACK_IMPORTED_MODULE_14__["default"].candidateToJingle(cands[i].candidate);
                    // Mangle ICE candidate if 'failICE' test option is enabled
                    if (this.failICE) {
                        candidate.ip = '1.1.1.1';
                    }
                    cand.c('candidate', candidate).up();
                }
                // add fingerprint
                const fingerprintLine = _sdp_SDPUtil__WEBPACK_IMPORTED_MODULE_14__["default"].findLine(localSDP.media[mid], 'a=fingerprint:', localSDP.session);
                if (fingerprintLine) {
                    const tmp = _sdp_SDPUtil__WEBPACK_IMPORTED_MODULE_14__["default"].parseFingerprint(fingerprintLine);
                    tmp.required = true;
                    cand.c('fingerprint', { xmlns: 'urn:xmpp:jingle:apps:dtls:0' })
                        .t(tmp.fingerprint);
                    delete tmp.fingerprint;
                    cand.attrs(tmp);
                    cand.up();
                }
                cand.up(); // transport
                cand.up(); // content
            }
        }
        // might merge last-candidate notification into this, but it is called
        // a lot later. See webrtc issue #2340
        // logger.log('was this the last candidate', this.lasticecandidate);
        this.connection.sendIQ(cand, null, this.newJingleErrorHandler(cand), IQ_TIMEOUT);
    }
    /**
     * Sends Jingle 'session-info' message which includes custom Jitsi Meet
     * 'ice-state' element with the text value 'failed' to let Jicofo know
     * that the ICE connection has entered the failed state. It can then
     * choose to re-create JVB channels and send 'transport-replace' to
     * retry the connection.
     */
    sendIceFailedNotification() {
        const sessionInfo = (0,strophe_js__WEBPACK_IMPORTED_MODULE_2__.$iq)({
            to: this.remoteJid,
            type: 'set'
        })
            .c('jingle', { xmlns: 'urn:xmpp:jingle:1',
            action: 'session-info',
            initiator: this.initiatorJid,
            sid: this.sid })
            .c('ice-state', { xmlns: 'http://jitsi.org/protocol/focus' })
            .t('failed')
            .up();
        this._bridgeSessionId
            && sessionInfo.c('bridge-session', {
                xmlns: 'http://jitsi.org/protocol/focus',
                id: this._bridgeSessionId
            });
        this.connection.sendIQ2(sessionInfo, {
            /*
             * This message will be often sent when there are connectivity
             * issues, so make it slightly longer than Prosody's default BOSH
             * inactivity timeout of 60 seconds.
             */
            timeout: 65
        })
            .catch(this.newJingleErrorHandler(sessionInfo));
    }
    /**
     * {@inheritDoc}
     */
    addIceCandidates(elem) {
        if (this.peerconnection.signalingState === 'closed') {
            logger.warn(`${this} Ignored add ICE candidate when in closed state`);
            return;
        }
        const iceCandidates = [];
        elem.find('>content>transport>candidate')
            .each((idx, candidate) => {
            let line = _sdp_SDPUtil__WEBPACK_IMPORTED_MODULE_14__["default"].candidateFromJingle(candidate);
            line = line.replace('\r\n', '').replace('a=', '');
            // FIXME this code does not care to handle
            // non-bundle transport
            const rtcCandidate = new RTCIceCandidate({
                sdpMLineIndex: 0,
                // FF comes up with more complex names like audio-23423,
                // Given that it works on both Chrome and FF without
                // providing it, let's leave it like this for the time
                // being...
                // sdpMid: 'audio',
                sdpMid: '',
                candidate: line
            });
            iceCandidates.push(rtcCandidate);
        });
        if (!iceCandidates.length) {
            logger.error(`${this} No ICE candidates to add ?`, elem[0] && elem[0].outerHTML);
            return;
        }
        // We want to have this task queued, so that we know it is executed,
        // after the initial sRD/sLD offer/answer cycle was done (based on
        // the assumption that candidates are spawned after the offer/answer
        // and XMPP preserves order).
        const workFunction = finishedCallback => {
            for (const iceCandidate of iceCandidates) {
                this.peerconnection.addIceCandidate(iceCandidate)
                    .then(() => logger.debug(`${this} addIceCandidate ok!`), err => logger.error(`${this} addIceCandidate failed!`, err));
            }
            finishedCallback();
            logger.debug(`${this} ICE candidates task finished`);
        };
        logger.debug(`${this} Queued add (${iceCandidates.length}) ICE candidates task`);
        this.modificationQueue.push(workFunction);
    }
    /**
     *
     * @param contents
     */
    readSsrcInfo(contents) {
        const ssrcs = jquery__WEBPACK_IMPORTED_MODULE_1___default()(contents).find('>description>source[xmlns="urn:xmpp:jingle:apps:rtp:ssma:0"]');
        ssrcs.each((i, ssrcElement) => {
            const ssrc = Number(ssrcElement.getAttribute('ssrc'));
            if (ssrcElement.hasAttribute('name')) {
                const sourceName = ssrcElement.getAttribute('name');
                this._signalingLayer.setTrackSourceName(ssrc, sourceName);
            }
            if (this.isP2P) {
                // In P2P all SSRCs are owner by the remote peer
                this._signalingLayer.setSSRCOwner(ssrc, strophe_js__WEBPACK_IMPORTED_MODULE_2__.Strophe.getResourceFromJid(this.remoteJid));
            }
            else {
                jquery__WEBPACK_IMPORTED_MODULE_1___default()(ssrcElement)
                    .find('>ssrc-info[xmlns="http://jitsi.org/jitmeet"]')
                    .each((i3, ssrcInfoElement) => {
                    const owner = ssrcInfoElement.getAttribute('owner');
                    if (owner === null || owner === void 0 ? void 0 : owner.length) {
                        if (isNaN(ssrc) || ssrc < 0) {
                            logger.warn(`${this} Invalid SSRC ${ssrc} value received for ${owner}`);
                        }
                        else {
                            this._signalingLayer.setSSRCOwner(ssrc, getEndpointId(owner));
                        }
                    }
                });
            }
        });
    }
    /**
     * Makes the underlying TraceablePeerConnection generate new SSRC for
     * the recvonly video stream.
     * @deprecated
     */
    generateRecvonlySsrc() {
        if (this.peerconnection) {
            this.peerconnection.generateRecvonlySsrc();
        }
        else {
            logger.error(`${this} Unable to generate recvonly SSRC - no peerconnection`);
        }
    }
    /**
     * Returns the video codec configured as the preferred codec on the peerconnection.
     */
    getConfiguredVideoCodec() {
        return this.peerconnection.getConfiguredVideoCodec();
    }
    /**
     * Accepts incoming Jingle 'session-initiate' and should send 'session-accept' in result.
     *
     * @param jingleOffer jQuery selector pointing to the jingle element of the offer IQ
     * @param success callback called when we accept incoming session successfully and receive RESULT packet to
     * 'session-accept' sent.
     * @param failure function(error) called if for any reason we fail to accept the incoming offer. 'error' argument
     * can be used to log some details about the error.
     * @param {Array<JitsiLocalTrack>} [localTracks] the optional list of the local tracks that will be added, before
     * the offer/answer cycle executes. We allow the localTracks to optionally be passed in so that the addition of the
     * local tracks and the processing of the initial offer can all be done atomically. We want to make sure that any
     * other operations which originate in the XMPP Jingle messages related with this session to be executed with an
     * assumption that the initial offer/answer cycle has been executed already.
     */
    acceptOffer(jingleOffer, success, failure, localTracks) {
        this.setOfferAnswerCycle(jingleOffer, () => {
            // FIXME we may not care about RESULT packet for session-accept
            // then we should either call 'success' here immediately or
            // modify sendSessionAccept method to do that
            this.sendSessionAccept(() => {
                // Start processing tasks on the modification queue.
                logger.debug('Resuming the modification queue after session is established!');
                this.modificationQueue.resume();
                success();
                this.room.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_9__.XMPPEvents.SESSION_ACCEPT, this);
                // The first video track is added to the peerconnection and signaled as part of the session-accept.
                // Add secondary video tracks (that were already added to conference) to the peerconnection here.
                // This will happen when someone shares a secondary source to a two people call, the other user
                // leaves and joins the call again, a new peerconnection is created for p2p/jvb connection. At this
                // point, there are 2 video tracks which need to be signaled to the remote peer.
                const videoTracks = localTracks.filter(track => track.getType() === _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_6__.MediaType.VIDEO);
                videoTracks.length && videoTracks.splice(0, 1);
                if (_flags_FeatureFlags__WEBPACK_IMPORTED_MODULE_11__["default"].isMultiStreamSendSupportEnabled() && videoTracks.length) {
                    this.addTracks(videoTracks);
                }
            }, error => {
                failure(error);
                this.room.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_9__.XMPPEvents.SESSION_ACCEPT_ERROR, this, error);
            });
        }, failure, localTracks);
    }
    /**
     * Creates an offer and sends Jingle 'session-initiate' to the remote peer.
     *
     * @param {Array<JitsiLocalTrack>} localTracks the local tracks that will be added, before the offer/answer cycle
     * executes (for the local track addition to be an atomic operation together with the offer/answer).
     */
    invite(localTracks = []) {
        if (!this.isInitiator) {
            throw new Error('Trying to invite from the responder session');
        }
        logger.debug(`${this} Executing invite task`);
        const addTracks = [];
        for (const track of localTracks) {
            addTracks.push(this.peerconnection.addTrack(track, this.isInitiator));
        }
        Promise.all(addTracks)
            .then(() => this.peerconnection.createOffer(this.mediaConstraints))
            .then(offerSdp => this.peerconnection.setLocalDescription(offerSdp))
            .then(() => {
            this.peerconnection.processLocalSdpForTransceiverInfo(localTracks);
            let localDescription = this.peerconnection.localDescription;
            // Munge the codec order on the outgoing offer for clients that don't support
            // RTCRtpTransceiver#setCodecPreferences.
            if (!_browser__WEBPACK_IMPORTED_MODULE_18__["default"].supportsCodecPreferences()) {
                localDescription = this.peerconnection._mungeCodecOrder(localDescription);
            }
            this.sendSessionInitiate(localDescription.sdp);
        })
            .then(() => {
            logger.debug(`${this} invite executed - OK`);
        })
            .catch(error => {
            logger.error(`${this} invite error`, error);
        });
    }
    /**
     * Sends 'session-initiate' to the remote peer.
     *
     * NOTE this method is synchronous and we're not waiting for the RESULT
     * response which would delay the startup process.
     *
     * @param {string} offerSdp  - The local session description which will be
     * used to generate an offer.
     * @private
     */
    sendSessionInitiate(offerSdp) {
        let init = (0,strophe_js__WEBPACK_IMPORTED_MODULE_2__.$iq)({
            to: this.remoteJid,
            type: 'set'
        }).c('jingle', {
            xmlns: 'urn:xmpp:jingle:1',
            action: 'session-initiate',
            initiator: this.initiatorJid,
            sid: this.sid
        });
        new _sdp_SDP__WEBPACK_IMPORTED_MODULE_12__["default"](offerSdp).toJingle(init, this.isInitiator ? 'initiator' : 'responder');
        init = init.tree();
        logger.debug(`${this} Session-initiate: `, init);
        this.connection.sendIQ(init, () => {
            logger.info(`${this} Got RESULT for "session-initiate"`);
        }, error => {
            logger.error(`${this} "session-initiate" error`, error);
        }, IQ_TIMEOUT);
    }
    /**
     * Sets the answer received from the remote peer as the remote description.
     *
     * @param jingleAnswer
     */
    setAnswer(jingleAnswer) {
        if (!this.isInitiator) {
            throw new Error('Trying to set an answer on the responder session');
        }
        logger.debug(`${this} Executing setAnswer task`);
        const newRemoteSdp = this._processNewJingleOfferIq(jingleAnswer);
        const oldLocalSdp = new _sdp_SDP__WEBPACK_IMPORTED_MODULE_12__["default"](this.peerconnection.localDescription.sdp);
        const remoteDescription = new RTCSessionDescription({
            type: 'answer',
            sdp: newRemoteSdp.raw
        });
        this.peerconnection.setRemoteDescription(remoteDescription)
            .then(() => {
            if (this.state === _JingleSessionState__WEBPACK_IMPORTED_MODULE_20__.PENDING) {
                this.state = _JingleSessionState__WEBPACK_IMPORTED_MODULE_20__.ACTIVE;
                // Start processing tasks on the modification queue.
                logger.debug('Resuming the modification queue after session is established!');
                this.modificationQueue.resume();
                const newLocalSdp = new _sdp_SDP__WEBPACK_IMPORTED_MODULE_12__["default"](this.peerconnection.localDescription.sdp);
                this.sendContentModify();
                this.notifyMySSRCUpdate(oldLocalSdp, newLocalSdp);
            }
        })
            .then(() => {
            logger.debug(`${this} setAnswer task done`);
        })
            .catch(error => {
            logger.error(`${this} setAnswer task failed: ${error}`);
        });
    }
    /**
     * This is a setRemoteDescription/setLocalDescription cycle which starts at converting Strophe Jingle IQ into
     * remote offer SDP. Once converted, setRemoteDescription, createAnswer and setLocalDescription calls follow.
     *
     * @param jingleOfferAnswerIq jQuery selector pointing to the jingle element of the offer (or answer) IQ
     * @param success callback called when sRD/sLD cycle finishes successfully.
     * @param failure callback called with an error object as an argument if we fail at any point during setRD,
     * createAnswer, setLD.
     * @param {Array<JitsiLocalTrack>} [localTracks] the optional list of the local tracks that will be added, before
     * the offer/answer cycle executes (for the local track addition to be an atomic operation together with the
     * offer/answer).
     */
    setOfferAnswerCycle(jingleOfferAnswerIq, success, failure, localTracks = []) {
        logger.debug(`${this} Executing setOfferAnswerCycle task`);
        const addTracks = [];
        const audioTracks = localTracks.filter(track => track.getType() === _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_6__.MediaType.AUDIO);
        const videoTracks = localTracks.filter(track => track.getType() === _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_6__.MediaType.VIDEO);
        let tracks = localTracks;
        // Add only 1 video track at a time. Adding 2 or more video tracks to the peerconnection at the same time
        // makes the browser go into a renegotiation loop by firing 'negotiationneeded' event after every
        // renegotiation.
        if (_flags_FeatureFlags__WEBPACK_IMPORTED_MODULE_11__["default"].isMultiStreamSendSupportEnabled() && videoTracks.length > 1) {
            tracks = [...audioTracks, videoTracks[0]];
        }
        for (const track of tracks) {
            addTracks.push(this.peerconnection.addTrack(track, this.isInitiator));
        }
        const newRemoteSdp = this._processNewJingleOfferIq(jingleOfferAnswerIq);
        const oldLocalSdp = this.peerconnection.localDescription.sdp;
        const bridgeSession = jquery__WEBPACK_IMPORTED_MODULE_1___default()(jingleOfferAnswerIq).find('>bridge-session[xmlns="http://jitsi.org/protocol/focus"]');
        const bridgeSessionId = bridgeSession.attr('id');
        if (bridgeSessionId !== this._bridgeSessionId) {
            this._bridgeSessionId = bridgeSessionId;
        }
        const remoteDescription = new RTCSessionDescription({
            type: 'offer',
            sdp: newRemoteSdp.raw
        });
        Promise.all(addTracks)
            .then(() => this._responderRenegotiate(remoteDescription))
            .then(() => {
            this.peerconnection.processLocalSdpForTransceiverInfo(tracks);
            if (this.state === _JingleSessionState__WEBPACK_IMPORTED_MODULE_20__.PENDING) {
                this.state = _JingleSessionState__WEBPACK_IMPORTED_MODULE_20__.ACTIVE;
                // #1 Sync up video transfer active/inactive only after the initial O/A cycle. We want to
                // adjust the video media direction only in the local SDP and the Jingle contents direction
                // included in the initial offer/answer is mapped to the remote SDP. Jingle 'content-modify'
                // IQ is processed in a way that it will only modify local SDP when remote peer is no longer
                // interested in receiving video content. Changing media direction in the remote SDP will mess
                // up our SDP translation chain (simulcast, video mute, RTX etc.)
                // #2 Sends the max frame height if it was set, before the session-initiate/accept
                if (this.isP2P
                    && (!this._localVideoActive || this._sourceReceiverConstraints)) {
                    this.sendContentModify();
                }
            }
            // Old local SDP will be available when we're setting answer for the first time, but not when offer
            // and it's fine since we're generating an answer now it will contain all our SSRCs.
            if (oldLocalSdp) {
                const newLocalSdp = new _sdp_SDP__WEBPACK_IMPORTED_MODULE_12__["default"](this.peerconnection.localDescription.sdp);
                this.notifyMySSRCUpdate(new _sdp_SDP__WEBPACK_IMPORTED_MODULE_12__["default"](oldLocalSdp), newLocalSdp);
            }
        })
            .then(() => {
            logger.debug(`${this} setOfferAnswerCycle task done`);
            success();
        })
            .catch(error => {
            logger.error(`${this} setOfferAnswerCycle task failed: ${error}`);
            failure(error);
        });
    }
    /**
     * Updates the codecs on the peerconnection and initiates a renegotiation for the
     * new codec config to take effect.
     *
     * @param {CodecMimeType} preferred the preferred codec.
     * @param {CodecMimeType} disabled the codec that needs to be disabled.
     */
    setVideoCodecs(codecList) {
        if (this._assertNotEnded()) {
            logger.info(`${this} setVideoCodecs: ${codecList}`);
            this.peerconnection.setVideoCodecs(codecList);
            // Initiate a renegotiate for the codec setting to take effect.
            const workFunction = finishedCallback => {
                this._renegotiate().then(() => {
                    logger.debug(`${this} setVideoCodecs task is done`);
                    return finishedCallback();
                }, error => {
                    logger.error(`${this} setVideoCodecs task failed: ${error}`);
                    return finishedCallback(error);
                });
            };
            logger.debug(`${this} Queued setVideoCodecs task`);
            // Queue and execute
            this.modificationQueue.push(workFunction);
        }
    }
    /* eslint-enable max-params */
    /**
     * Although it states "replace transport" it does accept full Jingle offer
     * which should contain new ICE transport details.
     * @param jingleOfferElem an element Jingle IQ that contains new offer and
     *        transport info.
     * @param success callback called when we succeed to accept new offer.
     * @param failure function(error) called when we fail to accept new offer.
     */
    replaceTransport(jingleOfferElem, success, failure) {
        if (this.options.enableForcedReload) {
            const sdp = new _sdp_SDP__WEBPACK_IMPORTED_MODULE_12__["default"](this.peerconnection.localDescription.sdp);
            this.sendTransportAccept(sdp, success, failure);
            this.room.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_9__.XMPPEvents.CONNECTION_RESTARTED, this);
            return;
        }
        this.room.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_9__.XMPPEvents.ICE_RESTARTING, this);
        // We need to first reject the 'data' section to have the SCTP stack
        // cleaned up to signal the known data channel is now invalid. After
        // that the original offer is set to have the SCTP connection
        // established with the new bridge.
        const originalOffer = jingleOfferElem.clone();
        jingleOfferElem
            .find('>content[name=\'data\']')
            .attr('senders', 'rejected');
        // Remove all remote sources in order to reset the client's state
        // for the remote MediaStreams. When a conference is moved to
        // another bridge it will start streaming with a sequence number
        // that is not in sync with the most recently seen by the client.
        // The symptoms include frozen or black video and lots of "failed to
        // unprotect SRTP packets" in Chrome logs.
        jingleOfferElem
            .find('>content>description>source')
            .remove();
        jingleOfferElem
            .find('>content>description>ssrc-group')
            .remove();
        // On the JVB it's not a real ICE restart and all layers are re-initialized from scratch as Jicofo does
        // the restart by re-allocating new channels. Chrome (or WebRTC stack) needs to have the DTLS transport layer
        // reset to start a new handshake with fresh DTLS transport on the bridge. Make it think that the DTLS
        // fingerprint has changed by setting an all zeros key.
        const newFingerprint = jingleOfferElem.find('>content>transport>fingerprint');
        newFingerprint.attr('hash', 'sha-1');
        newFingerprint.text('00:00:00:00:00:00:00:00:00:00:00:00:00:00:00:00:00:00:00:00');
        const workFunction = finishedCallback => {
            // First set an offer with a rejected 'data' section
            this.setOfferAnswerCycle(jingleOfferElem, () => {
                // Now set the original offer(with the 'data' section)
                this.setOfferAnswerCycle(originalOffer, () => {
                    const localSDP = new _sdp_SDP__WEBPACK_IMPORTED_MODULE_12__["default"](this.peerconnection.localDescription.sdp);
                    if (typeof this.options.channelLastN === 'number' && this.options.channelLastN >= 0) {
                        localSDP.initialLastN = this.options.channelLastN;
                    }
                    this.sendTransportAccept(localSDP, success, failure);
                    this.room.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_9__.XMPPEvents.ICE_RESTART_SUCCESS, this, originalOffer);
                    finishedCallback();
                }, error => finishedCallback(error));
            }, error => finishedCallback(error));
        };
        logger.debug(`${this} Queued ICE restart task`);
        // Queue and execute
        this.modificationQueue.push(workFunction, error => {
            if (error) {
                logger.error(`${this} ICE restart task failed: ${error}`);
                failure(error);
            }
            else {
                logger.debug(`${this} ICE restart task done`);
                success();
            }
        });
    }
    /**
     * Sends Jingle 'session-accept' message.
     * @param {function()} success callback called when we receive 'RESULT'
     *        packet for the 'session-accept'
     * @param {function(error)} failure called when we receive an error response
     *        or when the request has timed out.
     * @private
     */
    sendSessionAccept(success, failure) {
        // NOTE: since we're just reading from it, we don't need to be within
        //  the modification queue to access the local description
        const localSDP = new _sdp_SDP__WEBPACK_IMPORTED_MODULE_12__["default"](this.peerconnection.localDescription.sdp);
        const accept = (0,strophe_js__WEBPACK_IMPORTED_MODULE_2__.$iq)({ to: this.remoteJid,
            type: 'set' })
            .c('jingle', { xmlns: 'urn:xmpp:jingle:1',
            action: 'session-accept',
            initiator: this.initiatorJid,
            responder: this.responderJid,
            sid: this.sid });
        if (this.webrtcIceTcpDisable) {
            localSDP.removeTcpCandidates = true;
        }
        if (this.webrtcIceUdpDisable) {
            localSDP.removeUdpCandidates = true;
        }
        if (this.failICE) {
            localSDP.failICE = true;
        }
        if (typeof this.options.channelLastN === 'number' && this.options.channelLastN >= 0) {
            localSDP.initialLastN = this.options.channelLastN;
        }
        localSDP.toJingle(accept, this.initiatorJid === this.localJid ? 'initiator' : 'responder');
        logger.info(`${this} Sending session-accept`);
        logger.debug(accept.tree());
        this.connection.sendIQ(accept, success, this.newJingleErrorHandler(accept, error => {
            failure(error);
            // 'session-accept' is a critical timeout and we'll
            // have to restart
            this.room.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_9__.XMPPEvents.SESSION_ACCEPT_TIMEOUT, this);
        }), IQ_TIMEOUT);
        // XXX Videobridge needs WebRTC's answer (ICE ufrag and pwd, DTLS
        // fingerprint and setup) ASAP in order to start the connection
        // establishment.
        //
        // FIXME Flushing the connection at this point triggers an issue with
        // BOSH request handling in Prosody on slow connections.
        //
        // The problem is that this request will be quite large and it may take
        // time before it reaches Prosody. In the meantime Strophe may decide
        // to send the next one. And it was observed that a small request with
        // 'transport-info' usually follows this one. It does reach Prosody
        // before the previous one was completely received. 'rid' on the server
        // is increased and Prosody ignores the request with 'session-accept'.
        // It will never reach Jicofo and everything in the request table is
        // lost. Removing the flush does not guarantee it will never happen, but
        // makes it much less likely('transport-info' is bundled with
        // 'session-accept' and any immediate requests).
        //
        // this.connection.flush();
    }
    /**
     * Will send 'content-modify' IQ in order to ask the remote peer to
     * either stop or resume sending video media or to adjust sender's video constraints.
     * @private
     */
    sendContentModify() {
        const senders = this._localVideoActive ? 'both' : 'none';
        const sessionModify = (0,strophe_js__WEBPACK_IMPORTED_MODULE_2__.$iq)({
            to: this.remoteJid,
            type: 'set'
        })
            .c('jingle', {
            xmlns: 'urn:xmpp:jingle:1',
            action: 'content-modify',
            initiator: this.initiatorJid,
            sid: this.sid
        })
            .c('content', {
            name: _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_6__.MediaType.VIDEO,
            senders
        });
        if (typeof this._sourceReceiverConstraints !== 'undefined') {
            this._sourceReceiverConstraints.forEach((maxHeight, sourceName) => {
                sessionModify
                    .c('source-frame-height', { xmlns: 'http://jitsi.org/jitmeet/video' })
                    .attrs({
                    sourceName,
                    maxHeight
                });
                sessionModify.up();
                logger.info(`${this} sending content-modify for source-name: ${sourceName}, maxHeight: ${maxHeight}`);
            });
        }
        logger.debug(sessionModify.tree());
        this.connection.sendIQ(sessionModify, null, this.newJingleErrorHandler(sessionModify), IQ_TIMEOUT);
    }
    /**
     * Adjust the preference for max video frame height that the local party is willing to receive. Signals
     * the remote p2p peer.
     *
     * @param {Map<string, number>} sourceReceiverConstraints - The receiver constraints per source.
     */
    setReceiverVideoConstraint(sourceReceiverConstraints) {
        logger.info(`${this} setReceiverVideoConstraint - constraints: ${JSON.stringify(sourceReceiverConstraints)}`);
        this._sourceReceiverConstraints = sourceReceiverConstraints;
        if (this.isP2P) {
            // Tell the remote peer about our receive constraint. If Jingle session is not yet active the state will
            // be synced after offer/answer.
            if (this.state === _JingleSessionState__WEBPACK_IMPORTED_MODULE_20__.ACTIVE) {
                this.sendContentModify();
            }
        }
    }
    /**
     * Sends Jingle 'transport-accept' message which is a response to
     * 'transport-replace'.
     * @param localSDP the 'SDP' object with local session description
     * @param success callback called when we receive 'RESULT' packet for
     *        'transport-replace'
     * @param failure function(error) called when we receive an error response
     *        or when the request has timed out.
     * @private
     */
    sendTransportAccept(localSDP, success, failure) {
        const transportAccept = (0,strophe_js__WEBPACK_IMPORTED_MODULE_2__.$iq)({ to: this.remoteJid,
            type: 'set' })
            .c('jingle', {
            xmlns: 'urn:xmpp:jingle:1',
            action: 'transport-accept',
            initiator: this.initiatorJid,
            sid: this.sid
        });
        localSDP.media.forEach((medialines, idx) => {
            const mline = _sdp_SDPUtil__WEBPACK_IMPORTED_MODULE_14__["default"].parseMLine(medialines.split('\r\n')[0]);
            transportAccept.c('content', {
                creator: this.initiatorJid === this.localJid
                    ? 'initiator'
                    : 'responder',
                name: mline.media
            });
            localSDP.transportToJingle(idx, transportAccept);
            transportAccept.up();
        });
        logger.info(`${this} Sending transport-accept`);
        logger.debug(transportAccept.tree());
        this.connection.sendIQ(transportAccept, success, this.newJingleErrorHandler(transportAccept, failure), IQ_TIMEOUT);
    }
    /**
     * Sends Jingle 'transport-reject' message which is a response to
     * 'transport-replace'.
     * @param success callback called when we receive 'RESULT' packet for
     *        'transport-replace'
     * @param failure function(error) called when we receive an error response
     *        or when the request has timed out.
     *
     * FIXME method should be marked as private, but there's some spaghetti that
     *       needs to be fixed prior doing that
     */
    sendTransportReject(success, failure) {
        // Send 'transport-reject', so that the focus will
        // know that we've failed
        const transportReject = (0,strophe_js__WEBPACK_IMPORTED_MODULE_2__.$iq)({ to: this.remoteJid,
            type: 'set' })
            .c('jingle', {
            xmlns: 'urn:xmpp:jingle:1',
            action: 'transport-reject',
            initiator: this.initiatorJid,
            sid: this.sid
        });
        logger.info(`${this} Sending 'transport-reject'`);
        logger.debug(transportReject.tree());
        this.connection.sendIQ(transportReject, success, this.newJingleErrorHandler(transportReject, failure), IQ_TIMEOUT);
    }
    /**
     * Sets the resolution constraint on the local camera track.
     * @param {number} maxFrameHeight - The user preferred max frame height.
     * @param {string} sourceName - The source name of the track.
     * @returns {Promise} promise that will be resolved when the operation is
     * successful and rejected otherwise.
     */
    setSenderVideoConstraint(maxFrameHeight, sourceName = null) {
        if (this._assertNotEnded()) {
            logger.info(`${this} setSenderVideoConstraint: ${maxFrameHeight}, sourceName: ${sourceName}`);
            const jitsiLocalTrack = sourceName
                ? this.rtc.getLocalVideoTracks().find(track => track.getSourceName() === sourceName)
                : this.rtc.getLocalVideoTrack();
            return this.peerconnection.setSenderVideoConstraints(maxFrameHeight, jitsiLocalTrack);
        }
        return Promise.resolve();
    }
    /**
     * @inheritDoc
     */
    terminate(success, failure, options) {
        if (this.state === _JingleSessionState__WEBPACK_IMPORTED_MODULE_20__.ENDED) {
            return;
        }
        if (!options || Boolean(options.sendSessionTerminate)) {
            const sessionTerminate = (0,strophe_js__WEBPACK_IMPORTED_MODULE_2__.$iq)({
                to: this.remoteJid,
                type: 'set'
            })
                .c('jingle', {
                xmlns: 'urn:xmpp:jingle:1',
                action: 'session-terminate',
                initiator: this.initiatorJid,
                sid: this.sid
            })
                .c('reason')
                .c((options && options.reason) || 'success')
                .up();
            if (options && options.reasonDescription) {
                sessionTerminate
                    .c('text')
                    .t(options.reasonDescription)
                    .up()
                    .up();
            }
            else {
                sessionTerminate.up();
            }
            this._bridgeSessionId
                && sessionTerminate.c('bridge-session', {
                    xmlns: 'http://jitsi.org/protocol/focus',
                    id: this._bridgeSessionId,
                    restart: options && options.requestRestart === true
                }).up();
            logger.info(`${this} Sending session-terminate`);
            logger.debug(sessionTerminate.tree());
            this.connection.sendIQ(sessionTerminate, success, this.newJingleErrorHandler(sessionTerminate, failure), IQ_TIMEOUT);
        }
        else {
            logger.info(`${this} Skipped sending session-terminate`);
        }
        // this should result in 'onTerminated' being called by strope.jingle.js
        this.connection.jingle.terminate(this.sid);
    }
    /**
     *
     * @param reasonCondition
     * @param reasonText
     */
    onTerminated(reasonCondition, reasonText) {
        // Do something with reason and reasonCondition when we start to care
        // this.reasonCondition = reasonCondition;
        // this.reasonText = reasonText;
        logger.info(`${this} Session terminated`, reasonCondition, reasonText);
        this._xmppListeners.forEach(removeListener => removeListener());
        this._xmppListeners = [];
        if (this._removeSenderVideoConstraintsChangeListener) {
            this._removeSenderVideoConstraintsChangeListener();
        }
        if (_flags_FeatureFlags__WEBPACK_IMPORTED_MODULE_11__["default"].isSsrcRewritingSupported() && this.peerconnection) {
            this.peerconnection.getRemoteTracks().forEach(track => {
                this.room.eventEmitter.emit(_JitsiTrackEvents__WEBPACK_IMPORTED_MODULE_3__.JitsiTrackEvents.TRACK_REMOVED, track);
            });
        }
        this.close();
    }
    /**
     * Handles XMPP connection state changes.
     *
     * @param {XmppConnection.Status} status - The new status.
     */
    onXmppStatusChanged(status) {
        if (status === _XmppConnection__WEBPACK_IMPORTED_MODULE_22__["default"].Status.CONNECTED && this._cachedOldLocalSdp) {
            logger.info(`${this} Sending SSRC update on reconnect`);
            this.notifyMySSRCUpdate(this._cachedOldLocalSdp, this._cachedNewLocalSdp);
        }
    }
    /**
     * Parse the information from the xml sourceAddElem and translate it
     *  into sdp lines
     * @param {jquery xml element} sourceAddElem the source-add
     *  element from jingle
     * @param {SDP object} currentRemoteSdp the current remote
     *  sdp (as of this new source-add)
     * @returns {list} a list of SDP line strings that should
     *  be added to the remote SDP
     */
    _parseSsrcInfoFromSourceAdd(sourceAddElem, currentRemoteSdp) {
        const addSsrcInfo = [];
        const self = this;
        jquery__WEBPACK_IMPORTED_MODULE_1___default()(sourceAddElem).each((i1, content) => {
            const name = jquery__WEBPACK_IMPORTED_MODULE_1___default()(content).attr('name');
            let lines = '';
            jquery__WEBPACK_IMPORTED_MODULE_1___default()(content)
                .find('ssrc-group[xmlns="urn:xmpp:jingle:apps:rtp:ssma:0"]')
                .each(function () {
                // eslint-disable-next-line no-invalid-this
                const semantics = this.getAttribute('semantics');
                const ssrcs = jquery__WEBPACK_IMPORTED_MODULE_1___default()(this) // eslint-disable-line no-invalid-this
                    .find('>source')
                    .map(function () {
                    // eslint-disable-next-line no-invalid-this
                    return this.getAttribute('ssrc');
                })
                    .get();
                if (ssrcs.length) {
                    lines += `a=ssrc-group:${semantics} ${ssrcs.join(' ')}\r\n`;
                }
            });
            // handles both >source and >description>source
            const tmp = jquery__WEBPACK_IMPORTED_MODULE_1___default()(content).find('source[xmlns="urn:xmpp:jingle:apps:rtp:ssma:0"]');
            /* eslint-disable no-invalid-this */
            tmp.each(function () {
                const ssrc = jquery__WEBPACK_IMPORTED_MODULE_1___default()(this).attr('ssrc');
                if (currentRemoteSdp.containsSSRC(ssrc)) {
                    // Do not print the warning for unified plan p2p case since ssrcs are never removed from the SDP.
                    !(self.usesUnifiedPlan && self.isP2P)
                        && logger.warn(`${self} Source-add request for existing SSRC: ${ssrc}`);
                    return;
                }
                // eslint-disable-next-line newline-per-chained-call
                jquery__WEBPACK_IMPORTED_MODULE_1___default()(this).find('>parameter').each(function () {
                    lines += `a=ssrc:${ssrc} ${jquery__WEBPACK_IMPORTED_MODULE_1___default()(this).attr('name')}`;
                    if (jquery__WEBPACK_IMPORTED_MODULE_1___default()(this).attr('value') && jquery__WEBPACK_IMPORTED_MODULE_1___default()(this).attr('value').length) {
                        lines += `:${jquery__WEBPACK_IMPORTED_MODULE_1___default()(this).attr('value')}`;
                    }
                    lines += '\r\n';
                });
            });
            let midFound = false;
            /* eslint-enable no-invalid-this */
            currentRemoteSdp.media.forEach((media, i2) => {
                if (!_sdp_SDPUtil__WEBPACK_IMPORTED_MODULE_14__["default"].findLine(media, `a=mid:${name}`)) {
                    return;
                }
                if (!addSsrcInfo[i2]) {
                    addSsrcInfo[i2] = '';
                }
                addSsrcInfo[i2] += lines;
                midFound = true;
            });
            // In p2p unified mode with multi-stream enabled, the new sources will have content name that doesn't exist
            // in the current remote description. Add a new m-line for this newly signaled source.
            if (!midFound && this.isP2P) {
                addSsrcInfo[name] = lines;
            }
        });
        return addSsrcInfo;
    }
    /**
     * Handles a Jingle source-add message for this Jingle session.
     * @param elem An array of Jingle "content" elements.
     */
    addRemoteStream(elem) {
        this._addOrRemoveRemoteStream(true /* add */, elem);
    }
    /**
     * Handles a Jingle source-remove message for this Jingle session.
     * @param elem An array of Jingle "content" elements.
     */
    removeRemoteStream(elem) {
        this._addOrRemoveRemoteStream(false /* remove */, elem);
    }
    /**
     * Processes the source map message received from the bridge and creates a new remote track for newly signaled
     * SSRCs or updates the source-name and owner on the remote track for an existing SSRC.
     *
     * @param {Object} message - The source map message.
     * @param {string} mediaType - The media type, 'audio' or 'video'.
     * @returns {void}
     */
    processSourceMap(message, mediaType) {
        const newSsrcs = [];
        for (const src of message.mappedSources) {
            // eslint-disable-next-line prefer-const
            let { owner, source, ssrc, videoType } = src;
            const isNewSsrc = this.peerconnection.addRemoteSsrc(ssrc, source);
            let lookupSsrc = ssrc;
            if (isNewSsrc) {
                newSsrcs.push(src);
                // Check if there is an old mapping for the given source and clear the owner on the associated track.
                const oldSsrc = this.peerconnection.remoteSources.get(source);
                if (oldSsrc) {
                    lookupSsrc = oldSsrc;
                    owner = undefined;
                    source = undefined;
                }
            }
            const track = this.peerconnection.getTrackBySSRC(lookupSsrc);
            if (track) {
                logger.debug(`Existing SSRC ${ssrc}: new owner=${owner}, source-name=${source}`);
                // Update the SSRC owner.
                this._signalingLayer.setSSRCOwner(ssrc, owner);
                // Update the track with all the relevant info.
                track.setSourceName(source);
                track.setOwner(owner);
                if (mediaType === _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_6__.MediaType.VIDEO) {
                    const type = videoType === 'CAMERA' ? _service_RTC_VideoType__WEBPACK_IMPORTED_MODULE_7__.VideoType.CAMERA : _service_RTC_VideoType__WEBPACK_IMPORTED_MODULE_7__.VideoType.DESKTOP;
                    track._setVideoType(type);
                }
                // Update the muted state on the track since the presence for this track could have been received
                // before the updated source map is received on the bridge channel.
                const peerMediaInfo = this._signalingLayer.getPeerMediaInfo(owner, mediaType, source);
                peerMediaInfo && this.peerconnection._sourceMutedChanged(source, peerMediaInfo.muted);
            }
        }
        // Add the new SSRCs to the remote description by generating a source message.
        if (newSsrcs.length) {
            let node = (0,strophe_js__WEBPACK_IMPORTED_MODULE_2__.$build)('content', {
                xmlns: 'urn:xmpp:jingle:1',
                name: mediaType
            }).c('description', {
                xmlns: 'urn:xmpp:jingle:apps:rtp:1',
                media: mediaType
            });
            for (const src of newSsrcs) {
                const { rtx, ssrc, source } = src;
                let msid;
                if (mediaType === _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_6__.MediaType.VIDEO) {
                    const idx = ++this.numRemoteVideoSources;
                    msid = `remote-video-${idx} remote-video-${idx}`;
                    if (rtx !== '-1') {
                        _addSourceElement(node, src, rtx, msid);
                        node.c('ssrc-group', {
                            xmlns: 'urn:xmpp:jingle:apps:rtp:ssma:0',
                            semantics: 'FID'
                        })
                            .c('source', {
                            xmlns: 'urn:xmpp:jingle:apps:rtp:ssma:0',
                            ssrc
                        })
                            .up()
                            .c('source', {
                            xmlns: 'urn:xmpp:jingle:apps:rtp:ssma:0',
                            ssrc: rtx
                        })
                            .up()
                            .up();
                    }
                }
                else {
                    const idx = ++this.numRemoteAudioSources;
                    msid = `remote-audio-${idx} remote-audio-${idx}`;
                }
                _addSourceElement(node, src, ssrc, msid);
                this.peerconnection.remoteSources.set(source, ssrc);
            }
            node = node.up();
            this._addOrRemoveRemoteStream(true /* add */, node.node);
        }
    }
    /**
     * Handles the deletion of SSRCs associated with a remote user from the remote description when the user leaves.
     *
     * @param {string} id Endpoint id of the participant that has left the call.
     * @returns {void}
     */
    removeRemoteStreamsOnLeave(id) {
        const workFunction = finishCallback => {
            const removeSsrcInfo = this.peerconnection.getRemoteSourceInfoByParticipant(id);
            if (removeSsrcInfo.length) {
                const newRemoteSdp = this._processRemoteRemoveSource(removeSsrcInfo);
                this._renegotiate(newRemoteSdp.raw)
                    .then(() => finishCallback(), error => finishCallback(error));
            }
            else {
                finishCallback();
            }
        };
        logger.debug(`${this} Queued removeRemoteStreamsOnLeave task for participant ${id}`);
        this.modificationQueue.push(workFunction, error => {
            if (error) {
                logger.error(`${this} removeRemoteStreamsOnLeave error:`, error);
            }
            else {
                logger.info(`${this} removeRemoteStreamsOnLeave done!`);
            }
        });
    }
    /**
     * Handles either Jingle 'source-add' or 'source-remove' message for this
     * Jingle session.
     * @param {boolean} isAdd <tt>true</tt> for 'source-add' or <tt>false</tt>
     * otherwise.
     * @param {Array<Element>} elem an array of Jingle "content" elements.
     * @private
     */
    _addOrRemoveRemoteStream(isAdd, elem) {
        const logPrefix = isAdd ? 'addRemoteStream' : 'removeRemoteStream';
        if (isAdd) {
            this.readSsrcInfo(elem);
        }
        const workFunction = finishedCallback => {
            if (!this.peerconnection.localDescription
                || !this.peerconnection.localDescription.sdp) {
                const errMsg = `${logPrefix} - localDescription not ready yet`;
                logger.error(errMsg);
                finishedCallback(errMsg);
                return;
            }
            logger.log(`${this} Processing ${logPrefix}`);
            const oldLocalSdp = new _sdp_SDP__WEBPACK_IMPORTED_MODULE_12__["default"](this.peerconnection.localDescription.sdp);
            const sdp = new _sdp_SDP__WEBPACK_IMPORTED_MODULE_12__["default"](this.peerconnection.remoteDescription.sdp);
            const addOrRemoveSsrcInfo = isAdd
                ? this._parseSsrcInfoFromSourceAdd(elem, sdp)
                : this._parseSsrcInfoFromSourceRemove(elem, sdp);
            const newRemoteSdp = isAdd
                ? this._processRemoteAddSource(addOrRemoveSsrcInfo)
                : this._processRemoteRemoveSource(addOrRemoveSsrcInfo);
            const remoteDescription = new RTCSessionDescription({
                type: 'offer',
                sdp: newRemoteSdp.raw
            });
            // Always initiate a sRD->cA->sLD cycle when a remote source is added or removed irrespective of whether
            // the local endpoint is an initiator or responder. Fixes bugs on Chromium where decoders are not created
            // when sLD->cO->sRD cycle is initiated for p2p cases when remote sources are received.
            this._responderRenegotiate(remoteDescription).then(() => {
                const newLocalSdp = new _sdp_SDP__WEBPACK_IMPORTED_MODULE_12__["default"](this.peerconnection.localDescription.sdp);
                logger.log(`${this} ${logPrefix} - OK`);
                this.notifyMySSRCUpdate(oldLocalSdp, newLocalSdp);
                finishedCallback();
            }, error => {
                logger.error(`${this} ${logPrefix} failed:`, error);
                finishedCallback(error);
            });
        };
        logger.debug(`${this} Queued ${logPrefix} task`);
        // Queue and execute
        this.modificationQueue.push(workFunction);
    }
    /**
     * Takes in a jingle offer iq, returns the new sdp offer
     * @param {jquery xml element} offerIq the incoming offer
     * @returns {SDP object} the jingle offer translated to SDP
     */
    _processNewJingleOfferIq(offerIq) {
        const remoteSdp = new _sdp_SDP__WEBPACK_IMPORTED_MODULE_12__["default"]('');
        if (this.webrtcIceTcpDisable) {
            remoteSdp.removeTcpCandidates = true;
        }
        if (this.webrtcIceUdpDisable) {
            remoteSdp.removeUdpCandidates = true;
        }
        if (this.failICE) {
            remoteSdp.failICE = true;
        }
        remoteSdp.fromJingle(offerIq);
        this.readSsrcInfo(jquery__WEBPACK_IMPORTED_MODULE_1___default()(offerIq).find('>content'));
        return remoteSdp;
    }
    /**
     * Remove the given ssrc lines from the current remote sdp
     * @param {list} removeSsrcInfo a list of SDP line strings that
     *  should be removed from the remote SDP
     * @returns type {SDP Object} the new remote SDP (after removing the lines
     *  in removeSsrcInfo
     */
    _processRemoteRemoveSource(removeSsrcInfo) {
        const remoteSdp = this.usesUnifiedPlan
            ? new _sdp_SDP__WEBPACK_IMPORTED_MODULE_12__["default"](this.peerconnection.peerconnection.remoteDescription.sdp)
            : new _sdp_SDP__WEBPACK_IMPORTED_MODULE_12__["default"](this.peerconnection.remoteDescription.sdp);
        let ssrcs;
        removeSsrcInfo.forEach((lines, idx) => {
            // eslint-disable-next-line no-param-reassign
            lines = lines.split('\r\n');
            lines.pop(); // remove empty last element;
            ssrcs = lines.map(line => { var _a; return Number((_a = line.split('a=ssrc:')[1]) === null || _a === void 0 ? void 0 : _a.split(' ')[0]); });
            if (this.usesUnifiedPlan) {
                let mid;
                lines.forEach(line => {
                    var _a;
                    mid = remoteSdp.media.findIndex(mLine => mLine.includes(line));
                    if (mid > -1) {
                        remoteSdp.media[mid] = remoteSdp.media[mid].replace(`${line}\r\n`, '');
                        if (this.isP2P) {
                            const mediaType = (_a = _sdp_SDPUtil__WEBPACK_IMPORTED_MODULE_14__["default"].parseMLine(remoteSdp.media[mid].split('\r\n')[0])) === null || _a === void 0 ? void 0 : _a.media;
                            const desiredDirection = this.peerconnection.getDesiredMediaDirection(mediaType, false);
                            [_service_RTC_MediaDirection__WEBPACK_IMPORTED_MODULE_5__.MediaDirection.SENDRECV, _service_RTC_MediaDirection__WEBPACK_IMPORTED_MODULE_5__.MediaDirection.SENDONLY].forEach(direction => {
                                remoteSdp.media[mid] = remoteSdp.media[mid]
                                    .replace(`a=${direction}`, `a=${desiredDirection}`);
                            });
                        }
                        else {
                            // Jvb connections will have direction set to 'sendonly' for the remote sources.
                            remoteSdp.media[mid] = remoteSdp.media[mid]
                                .replace(`a=${_service_RTC_MediaDirection__WEBPACK_IMPORTED_MODULE_5__.MediaDirection.SENDONLY}`, `a=${_service_RTC_MediaDirection__WEBPACK_IMPORTED_MODULE_5__.MediaDirection.INACTIVE}`);
                            // Reject the m-line so that the browser removes the associated transceiver from the list
                            // of available transceivers. This will prevent the client from trying to re-use these
                            // inactive transceivers when additional video sources are added to the peerconnection.
                            const { media, port } = _sdp_SDPUtil__WEBPACK_IMPORTED_MODULE_14__["default"].parseMLine(remoteSdp.media[mid].split('\r\n')[0]);
                            remoteSdp.media[mid] = remoteSdp.media[mid].replace(`m=${media} ${port}`, `m=${media} 0`);
                        }
                    }
                });
            }
            else {
                lines.forEach(line => {
                    remoteSdp.media[idx] = remoteSdp.media[idx].replace(`${line}\r\n`, '');
                });
            }
        });
        // Update the ssrc owners list.
        (ssrcs === null || ssrcs === void 0 ? void 0 : ssrcs.length) && this._signalingLayer.removeSSRCOwners(ssrcs);
        remoteSdp.raw = remoteSdp.session + remoteSdp.media.join('');
        return remoteSdp;
    }
    /**
     * Add the given ssrc lines to the current remote sdp
     * @param {list} addSsrcInfo a list of SDP line strings that
     *  should be added to the remote SDP
     * @returns type {SDP Object} the new remote SDP (after removing the lines
     *  in removeSsrcInfo
     */
    _processRemoteAddSource(addSsrcInfo) {
        let remoteSdp = new _sdp_SDP__WEBPACK_IMPORTED_MODULE_12__["default"](this.peerconnection.remoteDescription.sdp);
        // Add a new m-line in the remote description if the source info for a secondary video source is recceived from
        // the remote p2p peer when multi-stream support is enabled.
        if (addSsrcInfo.length > remoteSdp.media.length
            && this.isP2P
            && this.usesUnifiedPlan) {
            remoteSdp.addMlineForNewLocalSource(_service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_6__.MediaType.VIDEO);
            remoteSdp = new _sdp_SDP__WEBPACK_IMPORTED_MODULE_12__["default"](remoteSdp.raw);
        }
        addSsrcInfo.forEach((lines, idx) => {
            var _a;
            remoteSdp.media[idx] += lines;
            // Make sure to change the direction to 'sendrecv/sendonly' only for p2p connections. For jvb connections,
            // a new m-line is added for the new remote sources.
            if (this.isP2P && this.usesUnifiedPlan) {
                const mediaType = (_a = _sdp_SDPUtil__WEBPACK_IMPORTED_MODULE_14__["default"].parseMLine(remoteSdp.media[idx].split('\r\n')[0])) === null || _a === void 0 ? void 0 : _a.media;
                const desiredDirection = this.peerconnection.getDesiredMediaDirection(mediaType, true);
                [_service_RTC_MediaDirection__WEBPACK_IMPORTED_MODULE_5__.MediaDirection.RECVONLY, _service_RTC_MediaDirection__WEBPACK_IMPORTED_MODULE_5__.MediaDirection.INACTIVE].forEach(direction => {
                    remoteSdp.media[idx] = remoteSdp.media[idx]
                        .replace(`a=${direction}`, `a=${desiredDirection}`);
                });
            }
        });
        remoteSdp.raw = remoteSdp.session + remoteSdp.media.join('');
        return remoteSdp;
    }
    /**
     * Do a new o/a flow using the existing remote description
     * @param {string} [optionalRemoteSdp] optional, raw remote sdp
     *  to use.  If not provided, the remote sdp from the
     *  peerconnection will be used
     * @returns {Promise} promise which resolves when the
     *  o/a flow is complete with no arguments or
     *  rejects with an error {string}
     */
    _renegotiate(optionalRemoteSdp) {
        if (this.peerconnection.signalingState === 'closed') {
            const error = new Error('Attempted to renegotiate in state closed');
            this.room.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_9__.XMPPEvents.RENEGOTIATION_FAILED, error, this);
            return Promise.reject(error);
        }
        const remoteSdp = optionalRemoteSdp || this.peerconnection.remoteDescription.sdp;
        if (!remoteSdp) {
            const error = new Error(`Can not renegotiate without remote description, current state: ${this.state}`);
            this.room.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_9__.XMPPEvents.RENEGOTIATION_FAILED, error, this);
            return Promise.reject(error);
        }
        const remoteDescription = new RTCSessionDescription({
            type: this.isInitiator ? 'answer' : 'offer',
            sdp: remoteSdp
        });
        const promise = this.isInitiator
            ? this._initiatorRenegotiate(remoteDescription)
            : this._responderRenegotiate(remoteDescription);
        const oldLocalSDP = new _sdp_SDP__WEBPACK_IMPORTED_MODULE_12__["default"](this.peerconnection.localDescription.sdp);
        return promise.then(() => {
            const newLocalSDP = new _sdp_SDP__WEBPACK_IMPORTED_MODULE_12__["default"](this.peerconnection.localDescription.sdp);
            // Send the source updates after every renegotiation cycle.
            oldLocalSDP && this.notifyMySSRCUpdate(oldLocalSDP, newLocalSDP);
        });
    }
    /**
     * Renegotiate cycle implementation for the responder case.
     * @param {object} remoteDescription the SDP object as defined by the WebRTC
     * which will be used as remote description in the cycle.
     * @private
     */
    _responderRenegotiate(remoteDescription) {
        logger.debug(`${this} Renegotiate: setting remote description`);
        return this.peerconnection.setRemoteDescription(remoteDescription)
            .then(() => {
            logger.debug(`${this} Renegotiate: creating answer`);
            return this.peerconnection.createAnswer(this.mediaConstraints)
                .then(answer => {
                logger.debug(`${this} Renegotiate: setting local description`);
                return this.peerconnection.setLocalDescription(answer);
            });
        });
    }
    /**
     * Renegotiate cycle implementation for the initiator's case.
     * @param {object} remoteDescription the SDP object as defined by the WebRTC
     * which will be used as remote description in the cycle.
     * @private
     */
    _initiatorRenegotiate(remoteDescription) {
        logger.debug(`${this} Renegotiate: creating offer`);
        return this.peerconnection.createOffer(this.mediaConstraints)
            .then(offer => {
            logger.debug(`${this} Renegotiate: setting local description`);
            return this.peerconnection.setLocalDescription(offer)
                .then(() => {
                logger.debug(`${this} Renegotiate: setting remote description`);
                // eslint-disable-next-line max-len
                return this.peerconnection.setRemoteDescription(remoteDescription);
            });
        });
    }
    /**
     * Adds a new track to the peerconnection. This method needs to be called only when a secondary JitsiLocalTrack is
     * being added to the peerconnection for the first time.
     *
     * @param {Array<JitsiLocalTrack>} localTracks - Tracks to be added to the peer connection.
     * @returns {Promise<void>} that resolves when the track is successfully added to the peerconnection, rejected
     * otherwise.
     */
    addTracks(localTracks = null) {
        if (!_flags_FeatureFlags__WEBPACK_IMPORTED_MODULE_11__["default"].isMultiStreamSendSupportEnabled()
            || !(localTracks === null || localTracks === void 0 ? void 0 : localTracks.length)
            || localTracks.find(track => track.getType() !== _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_6__.MediaType.VIDEO)) {
            return Promise.reject(new Error('Multiple tracks of the given media type are not supported'));
        }
        const replaceTracks = [];
        const workFunction = finishedCallback => {
            const remoteSdp = new _sdp_SDP__WEBPACK_IMPORTED_MODULE_12__["default"](this.peerconnection.peerconnection.remoteDescription.sdp);
            const recvOnlyTransceiver = this.peerconnection.peerconnection.getTransceivers()
                .find(t => t.receiver.track.kind === _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_6__.MediaType.VIDEO
                && t.direction === _service_RTC_MediaDirection__WEBPACK_IMPORTED_MODULE_5__.MediaDirection.RECVONLY
                && t.currentDirection === _service_RTC_MediaDirection__WEBPACK_IMPORTED_MODULE_5__.MediaDirection.RECVONLY);
            // Add transceivers by adding a new mline in the remote description for each track. Do not create a new
            // m-line if a recv-only transceiver exists in the p2p case. The new track will be attached to the
            // existing one in that case.
            for (const track of localTracks) {
                if (!this.isP2P || !recvOnlyTransceiver) {
                    remoteSdp.addMlineForNewLocalSource(track.getType());
                }
            }
            const remoteDescription = new RTCSessionDescription({
                type: 'offer',
                sdp: remoteSdp.raw
            });
            // Always initiate a responder renegotiate since the new m-line is added to remote SDP.
            this._responderRenegotiate(remoteDescription)
                .then(() => {
                // Replace the tracks on the newly generated transceivers.
                for (const track of localTracks) {
                    replaceTracks.push(this.peerconnection.replaceTrack(null, track));
                }
                return Promise.all(replaceTracks);
            })
                // Trigger a renegotiation here since renegotiations are suppressed at TPC.replaceTrack for screenshare
                // tracks. This is done here so that presence for screenshare tracks is sent before signaling.
                .then(() => this._renegotiate())
                .then(() => finishedCallback(), error => finishedCallback(error));
        };
        return new Promise((resolve, reject) => {
            logger.debug(`${this} Queued renegotiation after addTrack`);
            this.modificationQueue.push(workFunction, error => {
                if (error) {
                    logger.error(`${this} renegotiation after addTrack error`, error);
                    reject(error);
                }
                else {
                    logger.debug(`${this} renegotiation after addTrack executed - OK`);
                    resolve();
                }
            });
        });
    }
    /**
     * Resumes or suspends media transfer over the underlying peer connection.
     *
     * @param {boolean} active - <tt>true</tt> to enable media transfer or <tt>false</tt> to suspend media transmission
     * @returns {Promise}
     */
    setMediaTransferActive(active) {
        return this.peerconnection.tpcUtils.setMediaTransferActive(active)
            .then(() => {
            this.peerconnection.audioTransferActive = active;
            this.peerconnection.videoTransferActive = active;
            // Reconfigure the video tracks so that only the correct encodings are active.
            const promises = [];
            for (const track of this.rtc.getLocalVideoTracks()) {
                promises.push(this.peerconnection.configureSenderVideoEncodings(track));
            }
            return Promise.allSettled(promises);
        });
    }
    /**
     * Replaces <tt>oldTrack</tt> with <tt>newTrack</tt> and performs a single
     * offer/answer cycle after both operations are done. Either
     * <tt>oldTrack</tt> or <tt>newTrack</tt> can be null; replacing a valid
     * <tt>oldTrack</tt> with a null <tt>newTrack</tt> effectively just removes
     * <tt>oldTrack</tt>
     * @param {JitsiLocalTrack|null} oldTrack the current track in use to be
     * replaced
     * @param {JitsiLocalTrack|null} newTrack the new track to use
     * @returns {Promise} which resolves once the replacement is complete
     *  with no arguments or rejects with an error {string}
     */
    replaceTrack(oldTrack, newTrack) {
        const workFunction = finishedCallback => {
            logger.debug(`${this} replaceTrack worker started. oldTrack = ${oldTrack}, newTrack = ${newTrack}`);
            const oldLocalSdp = this.peerconnection.localDescription.sdp;
            if (!this.usesUnifiedPlan) {
                // NOTE the code below assumes that no more than 1 video track
                // can be added to the peer connection.
                // Transition from camera to desktop share
                // or transition from one camera source to another.
                if (this.peerconnection.options.capScreenshareBitrate
                    && oldTrack && newTrack && newTrack.isVideoTrack()) {
                    // Clearing current primary SSRC will make
                    // the SdpConsistency generate a new one which will result
                    // with:
                    // 1. source-remove for the old video stream.
                    // 2. source-add for the new video stream.
                    this.peerconnection.clearRecvonlySsrc();
                }
                // Transition from no video to video (unmute).
                if (!oldTrack && newTrack && newTrack.isVideoTrack()) {
                    // Clearing current primary SSRC will make
                    // the SdpConsistency generate a new one which will result
                    // with:
                    // 1. source-remove for the recvonly
                    // 2. source-add for the new video stream
                    this.peerconnection.clearRecvonlySsrc();
                    // Transition from video to no video
                }
                else if (oldTrack && oldTrack.isVideoTrack() && !newTrack) {
                    // Clearing current primary SSRC and generating the recvonly
                    // will result in:
                    // 1. source-remove for the old video stream
                    // 2. source-add for the recvonly stream
                    this.peerconnection.clearRecvonlySsrc();
                    this.peerconnection.generateRecvonlySsrc();
                }
            }
            this.peerconnection.replaceTrack(oldTrack, newTrack)
                .then(shouldRenegotiate => {
                let promise = Promise.resolve();
                logger.debug(`${this} TPC.replaceTrack finished. shouldRenegotiate = ${shouldRenegotiate}, JingleSessionState = ${this.state}`);
                if (shouldRenegotiate
                    && (oldTrack || newTrack)
                    && this.state === _JingleSessionState__WEBPACK_IMPORTED_MODULE_20__.ACTIVE) {
                    const remoteSdp = this.peerconnection.remoteDescription.sdp;
                    const remoteDescription = new RTCSessionDescription({
                        type: 'offer',
                        sdp: remoteSdp
                    });
                    // Always initiate a sRD->cA->sLD cycle since renegotiation fails in the following scenario.
                    // In a p2p call when channelLastN=0, the direction on the video tranceiver is set to
                    // 'inactive'. At this point, if the user unmutes, the track is replaced on the video sender.
                    // If a cO->sLD->sRD is triggered, the browser adds a third m-line which isn't expected and
                    // possibly is a bug. All renegotiations fail as a result. However, the browser does not add a
                    // third m-line in the answer it generates and renegotiation succeeds.
                    promise = this._responderRenegotiate(remoteDescription).then(() => {
                        const newLocalSDP = new _sdp_SDP__WEBPACK_IMPORTED_MODULE_12__["default"](this.peerconnection.localDescription.sdp);
                        this.notifyMySSRCUpdate(new _sdp_SDP__WEBPACK_IMPORTED_MODULE_12__["default"](oldLocalSdp), newLocalSDP);
                    });
                }
                return promise.then(() => {
                    // Set the source name of the new track.
                    if (oldTrack
                        && newTrack
                        && oldTrack.isVideoTrack()) {
                        newTrack.setSourceName(oldTrack.getSourceName());
                    }
                });
            })
                .then(() => finishedCallback(), error => finishedCallback(error));
        };
        return new Promise((resolve, reject) => {
            logger.debug(`${this} Queued replaceTrack task. Old track = ${oldTrack}, new track = ${newTrack}`);
            this.modificationQueue.push(workFunction, error => {
                if (error) {
                    logger.error(`${this} Replace track error:`, error);
                    reject(error);
                }
                else {
                    logger.info(`${this}  Replace track done!`);
                    resolve();
                }
            });
        });
    }
    /**
     * Parse the information from the xml sourceRemoveElem and translate it
     *  into sdp lines
     * @param {jquery xml element} sourceRemoveElem the source-remove
     *  element from jingle
     * @param {SDP object} currentRemoteSdp the current remote
     *  sdp (as of this new source-remove)
     * @returns {list} a list of SDP line strings that should
     *  be removed from the remote SDP
     */
    _parseSsrcInfoFromSourceRemove(sourceRemoveElem, currentRemoteSdp) {
        const removeSsrcInfo = [];
        jquery__WEBPACK_IMPORTED_MODULE_1___default()(sourceRemoveElem).each((i1, content) => {
            const name = jquery__WEBPACK_IMPORTED_MODULE_1___default()(content).attr('name');
            let lines = '';
            jquery__WEBPACK_IMPORTED_MODULE_1___default()(content)
                .find('ssrc-group[xmlns="urn:xmpp:jingle:apps:rtp:ssma:0"]')
                .each(function () {
                /* eslint-disable no-invalid-this */
                const semantics = this.getAttribute('semantics');
                const ssrcs = jquery__WEBPACK_IMPORTED_MODULE_1___default()(this)
                    .find('>source')
                    .map(function () {
                    return this.getAttribute('ssrc');
                })
                    .get();
                if (ssrcs.length) {
                    lines
                        += `a=ssrc-group:${semantics} ${ssrcs.join(' ')}\r\n`;
                }
                /* eslint-enable no-invalid-this */
            });
            const ssrcs = [];
            // handles both >source and >description>source versions
            const tmp = jquery__WEBPACK_IMPORTED_MODULE_1___default()(content).find('source[xmlns="urn:xmpp:jingle:apps:rtp:ssma:0"]');
            tmp.each(function () {
                // eslint-disable-next-line no-invalid-this
                const ssrc = jquery__WEBPACK_IMPORTED_MODULE_1___default()(this).attr('ssrc');
                ssrcs.push(ssrc);
            });
            currentRemoteSdp.media.forEach((media, i2) => {
                if (!_sdp_SDPUtil__WEBPACK_IMPORTED_MODULE_14__["default"].findLine(media, `a=mid:${name}`)) {
                    return;
                }
                if (!removeSsrcInfo[i2]) {
                    removeSsrcInfo[i2] = '';
                }
                ssrcs.forEach(ssrc => {
                    const ssrcLines = _sdp_SDPUtil__WEBPACK_IMPORTED_MODULE_14__["default"].findLines(media, `a=ssrc:${ssrc}`);
                    if (ssrcLines.length) {
                        removeSsrcInfo[i2] += `${ssrcLines.join('\r\n')}\r\n`;
                    }
                });
                removeSsrcInfo[i2] += lines;
            });
        });
        return removeSsrcInfo;
    }
    /**
     * Will print an error if there is any difference, between the SSRCs given
     * in the <tt>oldSDP</tt> and the ones currently described in
     * the peerconnection's local description.
     * @param {string} operationName the operation's name which will be printed
     * in the error message.
     * @param {SDP} oldSDP the old local SDP which will be compared with
     * the current one.
     * @return {boolean} <tt>true</tt> if there was any change or <tt>false</tt>
     * otherwise.
     * @private
     */
    _verifyNoSSRCChanged(operationName, oldSDP) {
        const currentLocalSDP = new _sdp_SDP__WEBPACK_IMPORTED_MODULE_12__["default"](this.peerconnection.localDescription.sdp);
        let sdpDiff = new _sdp_SDPDiffer__WEBPACK_IMPORTED_MODULE_13__["default"](oldSDP, currentLocalSDP);
        const addedMedia = sdpDiff.getNewMedia();
        if (Object.keys(addedMedia).length) {
            logger.error(`${this} - some SSRC were added on ${operationName}`, addedMedia);
            return false;
        }
        sdpDiff = new _sdp_SDPDiffer__WEBPACK_IMPORTED_MODULE_13__["default"](currentLocalSDP, oldSDP);
        const removedMedia = sdpDiff.getNewMedia();
        if (Object.keys(removedMedia).length) {
            logger.error(`${this} - some SSRCs were removed on ${operationName}`, removedMedia);
            return false;
        }
        return true;
    }
    /**
     * Adds local track back to the peerconnection associated with this session.
     * @param {JitsiLocalTrack} track
     * @return {Promise} a promise that will resolve once the local track is added back to this session and
     * renegotiation succeeds (if its warranted). Will be rejected with a <tt>string</tt> that provides some error
     * details in case something goes wrong.
     */
    addTrackToPc(track) {
        return this._addRemoveTrack(false /* add */, track)
            .then(() => {
            // Configure the video encodings after the track is unmuted. If the user joins the call muted and
            // unmutes it the first time, all the parameters need to be configured.
            if (track.isVideoTrack()) {
                return this.peerconnection.configureSenderVideoEncodings(track);
            }
        });
    }
    /**
     * Remove local track as part of the mute operation.
     * @param {JitsiLocalTrack} track the local track to be removed
     * @return {Promise} a promise which will be resolved once the local track
     * is removed from this session and the renegotiation is performed.
     * The promise will be rejected with a <tt>string</tt> that the describes
     * the error if anything goes wrong.
     */
    removeTrackFromPc(track) {
        return this._addRemoveTrack(true /* remove */, track);
    }
    /**
     * See {@link addTrackToPc} and {@link removeTrackFromPc}.
     * @param {boolean} isRemove <tt>true</tt> for "remove" operation or <tt>false</tt> for "add" operation.
     * @param {JitsiLocalTrack} track the track that will be added/removed
     * @private
     */
    _addRemoveTrack(isRemove, track) {
        if (!track) {
            return Promise.reject('invalid "track" argument value');
        }
        const operationName = isRemove ? 'removeTrack' : 'addTrack';
        const workFunction = finishedCallback => {
            const tpc = this.peerconnection;
            if (!tpc) {
                finishedCallback(`Error:  tried ${operationName} track with no active peer connection`);
                return;
            }
            const oldLocalSDP = tpc.localDescription.sdp;
            const operationPromise = isRemove
                ? tpc.removeTrackFromPc(track)
                : tpc.addTrackToPc(track);
            operationPromise
                .then(shouldRenegotiate => {
                if (shouldRenegotiate && oldLocalSDP && tpc.remoteDescription.sdp) {
                    this._renegotiate()
                        .then(() => {
                        // The results are ignored, as this check failure is not enough to fail the whole
                        // operation. It will log an error inside for plan-b.
                        !this.usesUnifiedPlan && this._verifyNoSSRCChanged(operationName, new _sdp_SDP__WEBPACK_IMPORTED_MODULE_12__["default"](oldLocalSDP));
                        finishedCallback();
                    });
                }
                else {
                    finishedCallback();
                }
            }, finishedCallback /* will be called with an error */);
        };
        logger.debug(`${this} Queued ${operationName} task`);
        return new Promise((resolve, reject) => {
            this.modificationQueue.push(workFunction, error => {
                if (error) {
                    logger.error(`${this} ${operationName} failed`);
                    reject(error);
                }
                else {
                    logger.debug(`${this} ${operationName} done`);
                    resolve();
                }
            });
        });
    }
    /**
     * Resumes or suspends video media transfer over the p2p peer connection.
     *
     * @param {boolean} videoActive <tt>true</tt> to enable video media transfer or <tt>false</tt> to suspend video
     * media transmission.
     * @return {Promise} a <tt>Promise</tt> which will resolve once the operation is done. It will be rejected with
     * an error description as a string in case anything goes wrong.
     */
    setP2pVideoTransferActive(videoActive) {
        if (!this.peerconnection) {
            return Promise.reject('Can not modify video transfer active state,'
                + ' before "initialize" is called');
        }
        const logVideoStr = videoActive ? 'video active' : 'video inactive';
        logger.info(`${this} Queued make ${logVideoStr} task`);
        const workFunction = finishedCallback => {
            const isSessionActive = this.state === _JingleSessionState__WEBPACK_IMPORTED_MODULE_20__.ACTIVE;
            if (this._localVideoActive !== videoActive) {
                this._localVideoActive = videoActive;
                if (this.isP2P && isSessionActive) {
                    this.sendContentModify();
                }
            }
            this.peerconnection.setVideoTransferActive(this._localVideoActive && this._remoteVideoActive);
            // Always initiate a renegotiation cycle for p2p connection when the media direction is changed.
            this._renegotiate()
                .then(() => finishedCallback())
                .catch(error => finishedCallback(error));
        };
        return new Promise((resolve, reject) => {
            this.modificationQueue.push(workFunction, error => {
                if (error) {
                    logger.error(`${this} Make ${logVideoStr} task failed!`);
                    reject(error);
                }
                else {
                    logger.debug(`${this} Make ${logVideoStr} task done!`);
                    resolve();
                }
            });
        });
    }
    /**
     * Will put and execute on the queue a session modify task. It checks if the sourceMaxFrameHeight (as requested by
     * the p2p peer) or the senders attribute of the video content has changed and modifies the local video sources
     * accordingly.
     */
    modifyContents(jingleContents) {
        const newVideoSenders = JingleSessionPC.parseVideoSenders(jingleContents);
        const sourceMaxFrameHeights = JingleSessionPC.parseSourceMaxFrameHeight(jingleContents);
        if (sourceMaxFrameHeights) {
            this.remoteSourceMaxFrameHeights = sourceMaxFrameHeights;
            this.eventEmitter.emit(_MediaSessionEvents__WEBPACK_IMPORTED_MODULE_21__["default"].REMOTE_SOURCE_CONSTRAINTS_CHANGED, this, sourceMaxFrameHeights);
        }
        if (newVideoSenders === null) {
            logger.error(`${this} - failed to parse video "senders" attribute in "content-modify" action`);
            return;
        }
        const workFunction = finishedCallback => {
            if (this._assertNotEnded() && this._modifyRemoteVideoActive(newVideoSenders)) {
                // Will do the sRD/sLD cycle to update SDPs and adjust the media direction.
                this._renegotiate()
                    .then(finishedCallback, finishedCallback /* (error) */);
            }
            else {
                finishedCallback();
            }
        };
        logger.debug(`${this} queued "content-modify" task(video senders="${newVideoSenders}")`);
        this.modificationQueue.push(workFunction, error => {
            if (error) {
                logger.error(`${this} "content-modify" failed`, error);
            }
            else {
                logger.debug(`${this} "content-modify" task(video senders="${newVideoSenders}") done`);
            }
        });
    }
    /**
     * Processes new value of remote video "senders" Jingle attribute and tries to apply it for
     * {@link _remoteVideoActive}.
     * @param {string} remoteVideoSenders the value of "senders" attribute of Jingle video content element advertised
     * by remote peer.
     * @return {boolean} <tt>true</tt> if the change affected state of the underlying peerconnection and renegotiation
     * is required for the changes to take effect.
     * @private
     */
    _modifyRemoteVideoActive(remoteVideoSenders) {
        const isRemoteVideoActive = remoteVideoSenders === 'both'
            || (remoteVideoSenders === 'initiator' && this.isInitiator)
            || (remoteVideoSenders === 'responder' && !this.isInitiator);
        if (isRemoteVideoActive !== this._remoteVideoActive) {
            logger.debug(`${this} new remote video active: ${isRemoteVideoActive}`);
            this._remoteVideoActive = isRemoteVideoActive;
            return this.peerconnection.setVideoTransferActive(this._localVideoActive && this._remoteVideoActive);
        }
        return false;
    }
    /**
     * Figures out added/removed ssrcs and send update IQs.
     * @param oldSDP SDP object for old description.
     * @param newSDP SDP object for new description.
     */
    notifyMySSRCUpdate(oldSDP, newSDP) {
        if (this.state !== _JingleSessionState__WEBPACK_IMPORTED_MODULE_20__.ACTIVE) {
            logger.warn(`${this} Skipping SSRC update in '${this.state} ' state.`);
            return;
        }
        if (!this.connection.connected) {
            // The goal is to compare the oldest SDP with the latest one upon reconnect
            if (!this._cachedOldLocalSdp) {
                this._cachedOldLocalSdp = oldSDP;
            }
            this._cachedNewLocalSdp = newSDP;
            logger.warn(`${this} Not sending SSRC update while the signaling is disconnected`);
            return;
        }
        this._cachedOldLocalSdp = undefined;
        this._cachedNewLocalSdp = undefined;
        const getSignaledSourceInfo = sdpDiffer => {
            const newMedia = sdpDiffer.getNewMedia();
            let ssrcs = [];
            let mediaType = null;
            // It is assumed that sources are signaled one at a time.
            Object.keys(newMedia).forEach(mediaIndex => {
                const signaledSsrcs = Object.keys(newMedia[mediaIndex].ssrcs);
                mediaType = newMedia[mediaIndex].mid;
                if (signaledSsrcs === null || signaledSsrcs === void 0 ? void 0 : signaledSsrcs.length) {
                    ssrcs = ssrcs.concat(signaledSsrcs);
                }
            });
            return {
                mediaType,
                ssrcs
            };
        };
        // send source-remove IQ.
        let sdpDiffer = new _sdp_SDPDiffer__WEBPACK_IMPORTED_MODULE_13__["default"](newSDP, oldSDP);
        const remove = (0,strophe_js__WEBPACK_IMPORTED_MODULE_2__.$iq)({ to: this.remoteJid,
            type: 'set' })
            .c('jingle', {
            xmlns: 'urn:xmpp:jingle:1',
            action: 'source-remove',
            initiator: this.initiatorJid,
            sid: this.sid
        });
        sdpDiffer.toJingle(remove);
        // context a common object for one run of ssrc update (source-add and source-remove) so we can match them if we
        // need to
        const ctx = {};
        const removedSsrcInfo = getSignaledSourceInfo(sdpDiffer);
        if (removedSsrcInfo.ssrcs.length) {
            // Log only the SSRCs instead of the full IQ.
            logger.info(`${this} Sending source-remove for ${removedSsrcInfo.mediaType}`
                + ` ssrcs=${removedSsrcInfo.ssrcs}`);
            this.connection.sendIQ(remove, () => {
                this.room.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_9__.XMPPEvents.SOURCE_REMOVE, this, ctx);
            }, this.newJingleErrorHandler(remove, error => {
                this.room.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_9__.XMPPEvents.SOURCE_REMOVE_ERROR, this, error, ctx);
            }), IQ_TIMEOUT);
        }
        // send source-add IQ.
        sdpDiffer = new _sdp_SDPDiffer__WEBPACK_IMPORTED_MODULE_13__["default"](oldSDP, newSDP);
        const add = (0,strophe_js__WEBPACK_IMPORTED_MODULE_2__.$iq)({ to: this.remoteJid,
            type: 'set' })
            .c('jingle', {
            xmlns: 'urn:xmpp:jingle:1',
            action: 'source-add',
            initiator: this.initiatorJid,
            sid: this.sid
        });
        sdpDiffer.toJingle(add);
        const addedSsrcInfo = getSignaledSourceInfo(sdpDiffer);
        if (addedSsrcInfo.ssrcs.length) {
            // Log only the SSRCs instead of the full IQ.
            logger.info(`${this} Sending source-add for ${addedSsrcInfo.mediaType} ssrcs=${addedSsrcInfo.ssrcs}`);
            this.connection.sendIQ(add, () => {
                this.room.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_9__.XMPPEvents.SOURCE_ADD, this, ctx);
            }, this.newJingleErrorHandler(add, error => {
                this.room.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_9__.XMPPEvents.SOURCE_ADD_ERROR, this, error, addedSsrcInfo.mediaType, ctx);
            }), IQ_TIMEOUT);
        }
    }
    /**
     * Method returns function(errorResponse) which is a callback to be passed
     * to Strophe connection.sendIQ method. An 'error' structure is created that
     * is passed as 1st argument to given <tt>failureCb</tt>. The format of this
     * structure is as follows:
     * {
     *  code: {XMPP error response code}
     *  reason: {the name of XMPP error reason element or 'timeout' if the
      *          request has timed out within <tt>IQ_TIMEOUT</tt> milliseconds}
     *  source: {request.tree() that provides original request}
     *  session: {this JingleSessionPC.toString()}
     * }
     * @param request Strophe IQ instance which is the request to be dumped into
     *        the error structure
     * @param failureCb function(error) called when error response was returned
     *        or when a timeout has occurred.
     * @returns {function(this:JingleSessionPC)}
     */
    newJingleErrorHandler(request, failureCb) {
        return errResponse => {
            const error = {};
            // Get XMPP error code and condition(reason)
            const errorElSel = jquery__WEBPACK_IMPORTED_MODULE_1___default()(errResponse).find('error');
            if (errorElSel.length) {
                error.code = errorElSel.attr('code');
                const errorReasonSel = jquery__WEBPACK_IMPORTED_MODULE_1___default()(errResponse).find('error :first');
                if (errorReasonSel.length) {
                    error.reason = errorReasonSel[0].tagName;
                }
                const errorMsgSel = errorElSel.find('>text');
                if (errorMsgSel.length) {
                    error.msg = errorMsgSel.text();
                }
            }
            if (!errResponse) {
                error.reason = 'timeout';
            }
            error.session = this.toString();
            if (failureCb) {
                failureCb(error);
            }
            else if (this.state === _JingleSessionState__WEBPACK_IMPORTED_MODULE_20__.ENDED
                && error.reason === 'item-not-found') {
                // When remote peer decides to terminate the session, but it
                // still have few messages on the queue for processing,
                // it will first send us 'session-terminate' (we enter ENDED)
                // and then follow with 'item-not-found' for the queued requests
                // We don't want to have that logged on error level.
                logger.debug(`${this} Jingle error: ${JSON.stringify(error)}`);
            }
            else {
                _util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_17___default().callErrorHandler(new Error(`Jingle error: ${JSON.stringify(error)}`));
            }
        };
    }
    /**
     * Returns the ice connection state for the peer connection.
     * @returns the ice connection state for the peer connection.
     */
    getIceConnectionState() {
        return this.peerconnection.getConnectionState();
    }
    /**
     * Closes the peerconnection.
     */
    close() {
        this.state = _JingleSessionState__WEBPACK_IMPORTED_MODULE_20__.ENDED;
        this.establishmentDuration = undefined;
        if (this.peerconnection) {
            this.peerconnection.onicecandidate = null;
            this.peerconnection.oniceconnectionstatechange = null;
            this.peerconnection.onnegotiationneeded = null;
            this.peerconnection.onsignalingstatechange = null;
        }
        logger.debug(`${this} Clearing modificationQueue`);
        // Remove any pending tasks from the queue
        this.modificationQueue.clear();
        logger.debug(`${this} Queued PC close task`);
        this.modificationQueue.push(finishCallback => {
            // do not try to close if already closed.
            this.peerconnection && this.peerconnection.close();
            finishCallback();
            logger.debug(`${this} PC close task done!`);
        });
        logger.debug(`${this} Shutdown modificationQueue!`);
        // No more tasks can go in after the close task
        this.modificationQueue.shutdown();
    }
    /**
     * Converts to string with minor summary.
     * @return {string}
     */
    toString() {
        return `JingleSessionPC[session=${this.isP2P ? 'P2P' : 'JVB'},initiator=${this.isInitiator},sid=${this.sid}]`;
    }
}
//# sourceMappingURL=JingleSessionPC.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/xmpp/JingleSessionState.js":
/*!****************************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/xmpp/JingleSessionState.js ***!
  \****************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   ACTIVE: () => (/* binding */ ACTIVE),
/* harmony export */   ENDED: () => (/* binding */ ENDED),
/* harmony export */   JingleSessionState: () => (/* binding */ JingleSessionState),
/* harmony export */   PENDING: () => (/* binding */ PENDING)
/* harmony export */ });
var JingleSessionState;
(function (JingleSessionState) {
    /**
     * The pending Jingle session state which means the session as defined in
     * XEP-0166(before 'session-invite/session-accept' took place).
     */
    JingleSessionState["PENDING"] = "pending";
    /**
     * The active Jingle session state as defined in XEP-0166
     * (after 'session-invite'/'session-accept').
     */
    JingleSessionState["ACTIVE"] = "active";
    /**
     * The ended Jingle session state as defined in XEP-0166
     * (after 'session-terminate').
     */
    JingleSessionState["ENDED"] = "ended";
})(JingleSessionState || (JingleSessionState = {}));
;
// exported for backward compatibility
const PENDING = JingleSessionState.PENDING;
const ACTIVE = JingleSessionState.ACTIVE;
const ENDED = JingleSessionState.ENDED;
//# sourceMappingURL=JingleSessionState.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/xmpp/Lobby.js":
/*!***************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/xmpp/Lobby.js ***!
  \***************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
var __filename = "/index.js";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (/* binding */ Lobby)
/* harmony export */ });
/* harmony import */ var _jitsi_logger__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @jitsi/logger */ "./node_modules/@jitsi/logger/lib/index.js");
/* harmony import */ var _jitsi_logger__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(_jitsi_logger__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var strophe_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! strophe.js */ "./node_modules/strophe.js/dist/strophe.umd.js");
/* harmony import */ var strophe_js__WEBPACK_IMPORTED_MODULE_1___default = /*#__PURE__*/__webpack_require__.n(strophe_js__WEBPACK_IMPORTED_MODULE_1__);
/* harmony import */ var _service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../service/xmpp/XMPPEvents */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/xmpp/XMPPEvents.js");



const logger = (0,_jitsi_logger__WEBPACK_IMPORTED_MODULE_0__.getLogger)(__filename);
/**
 * The command type for updating a lobby participant's e-mail address.
 *
 * @type {string}
 */
const EMAIL_COMMAND = 'email';
/**
 * The Lobby room implementation. Setting a room to members only, joining the lobby room
 * approving or denying access to participants from the lobby room.
 */
class Lobby {
    /**
     * Constructs lobby room.
     *
     * @param {ChatRoom} room the main room.
     */
    constructor(room) {
        this.xmpp = room.xmpp;
        this.mainRoom = room;
        const maybeJoinLobbyRoom = this._maybeJoinLobbyRoom.bind(this);
        this.mainRoom.addEventListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_2__.XMPPEvents.LOCAL_ROLE_CHANGED, maybeJoinLobbyRoom);
        this.mainRoom.addEventListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_2__.XMPPEvents.MUC_MEMBERS_ONLY_CHANGED, maybeJoinLobbyRoom);
        this.mainRoom.addEventListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_2__.XMPPEvents.ROOM_CONNECT_MEMBERS_ONLY_ERROR, jid => {
            this.lobbyRoomJid = jid;
        });
    }
    /**
     * Whether lobby is supported on backend.
     *
     * @returns {boolean} whether lobby is supported on backend.
     */
    isSupported() {
        return this.xmpp.lobbySupported;
    }
    /**
     * Enables lobby by setting the main room to be members only and joins the lobby chat room.
     *
     * @returns {Promise}
     */
    enable() {
        if (!this.isSupported()) {
            return Promise.reject(new Error('Lobby not supported!'));
        }
        return new Promise((resolve, reject) => {
            this.mainRoom.setMembersOnly(true, resolve, reject);
        });
    }
    /**
     * Disable lobby by setting the main room to be non members only and levaes the lobby chat room if joined.
     *
     * @returns {void}
     */
    disable() {
        if (!this.isSupported() || !this.mainRoom.isModerator()
            || !this.lobbyRoom || !this.mainRoom.membersOnlyEnabled) {
            return;
        }
        this.mainRoom.setMembersOnly(false);
    }
    /**
     * Broadcast a message to all participants in the lobby room
     * @param {Object} message The message to send
     *
     * @returns {void}
     */
    sendMessage(message) {
        if (this.lobbyRoom) {
            this.lobbyRoom.sendMessage(JSON.stringify(message), 'json-message');
        }
    }
    /**
     * Sends a private message to a participant in a lobby room.
     * @param {string} id The message to send
     * @param {Object} message The message to send
     *
     * @returns {void}
     */
    sendPrivateMessage(id, message) {
        if (this.lobbyRoom) {
            this.lobbyRoom.sendPrivateMessage(id, JSON.stringify(message), 'json-message');
        }
    }
    /**
     * Gets the local id for a participant in a lobby room.
     * This is used for lobby room private chat messages.
     *
     * @returns {string}
     */
    getLocalId() {
        if (this.lobbyRoom) {
            return strophe_js__WEBPACK_IMPORTED_MODULE_1__.Strophe.getResourceFromJid(this.lobbyRoom.myroomjid);
        }
    }
    /**
     * Adds a message listener to the lobby room.
     * @param {Function} listener The listener function,
     * called when a new message is received in the lobby room.
     *
     * @returns {Function} Handler returned to be able to remove it later.
     */
    addMessageListener(listener) {
        if (this.lobbyRoom) {
            const handler = (participantId, message) => {
                listener(message, strophe_js__WEBPACK_IMPORTED_MODULE_1__.Strophe.getResourceFromJid(participantId));
            };
            this.lobbyRoom.on(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_2__.XMPPEvents.JSON_MESSAGE_RECEIVED, handler);
            return handler;
        }
    }
    /**
     * Remove a message handler from the lobby room.
     * @param {Function} handler The handler function to remove.
     *
     * @returns {void}
     */
    removeMessageHandler(handler) {
        if (this.lobbyRoom) {
            this.lobbyRoom.off(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_2__.XMPPEvents.JSON_MESSAGE_RECEIVED, handler);
        }
    }
    /**
     * Leaves the lobby room.
     *
     * @returns {Promise}
     */
    leave() {
        if (this.lobbyRoom) {
            return this.lobbyRoom.leave()
                .then(() => {
                this.lobbyRoom = undefined;
                logger.info('Lobby room left!');
            })
                .catch(() => { }); // eslint-disable-line no-empty-function
        }
        return Promise.reject(new Error('The lobby has already been left'));
    }
    /**
     * We had received a jid for the lobby room.
     *
     * @param jid the lobby room jid to join.
     */
    setLobbyRoomJid(jid) {
        this.lobbyRoomJid = jid;
    }
    /**
     * Checks the state of mainRoom, lobbyRoom and current user role to decide whether to join lobby room.
     * @private
     */
    _maybeJoinLobbyRoom() {
        if (!this.isSupported()) {
            return;
        }
        const isModerator = this.mainRoom.joined && this.mainRoom.isModerator();
        if (isModerator && this.mainRoom.membersOnlyEnabled && !this.lobbyRoom) {
            // join the lobby
            this.join()
                .then(() => logger.info('Joined lobby room'))
                .catch(e => logger.error('Failed joining lobby', e));
        }
    }
    /**
     * Joins a lobby room setting display name and eventually avatar(using the email provided).
     *
     * @param {string} username is required.
     * @param {string} email is optional.
     * @returns {Promise} resolves once we join the room.
     */
    join(displayName, email) {
        const isModerator = this.mainRoom.joined && this.mainRoom.isModerator();
        if (!this.lobbyRoomJid) {
            return Promise.reject(new Error('Missing lobbyRoomJid, cannot join lobby room.'));
        }
        const roomName = strophe_js__WEBPACK_IMPORTED_MODULE_1__.Strophe.getNodeFromJid(this.lobbyRoomJid);
        const customDomain = strophe_js__WEBPACK_IMPORTED_MODULE_1__.Strophe.getDomainFromJid(this.lobbyRoomJid);
        this.lobbyRoom = this.xmpp.createRoom(roomName, {
            customDomain,
            disableDiscoInfo: true,
            disableFocus: true,
            enableLobby: false
        });
        if (displayName) {
            // remove previously set nickname
            this.lobbyRoom.addOrReplaceInPresence('nick', {
                attributes: { xmlns: 'http://jabber.org/protocol/nick' },
                value: displayName
            });
        }
        if (isModerator) {
            this.lobbyRoom.addPresenceListener(EMAIL_COMMAND, (node, from) => {
                this.mainRoom.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_2__.XMPPEvents.MUC_LOBBY_MEMBER_UPDATED, from, { email: node.value });
            });
            this.lobbyRoom.addEventListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_2__.XMPPEvents.MUC_MEMBER_JOINED, 
            // eslint-disable-next-line max-params
            (from, nick, role, isHiddenDomain, statsID, status, identity, botType, jid) => {
                // we need to ignore joins on lobby for participants that are already in the main room
                if (Object.values(this.mainRoom.members).find(m => m.jid === jid)) {
                    return;
                }
                // Check if the user is a member if any breakout room.
                for (const room of Object.values(this.mainRoom.getBreakoutRooms()._rooms)) {
                    if (Object.values(room.participants).find(p => p.jid === jid)) {
                        return;
                    }
                }
                // we emit the new event on the main room so we can propagate
                // events to the conference
                this.mainRoom.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_2__.XMPPEvents.MUC_LOBBY_MEMBER_JOINED, strophe_js__WEBPACK_IMPORTED_MODULE_1__.Strophe.getResourceFromJid(from), nick, identity ? identity.avatar : undefined);
            });
            this.lobbyRoom.addEventListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_2__.XMPPEvents.MUC_MEMBER_LEFT, from => {
                // we emit the new event on the main room so we can propagate
                // events to the conference
                this.mainRoom.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_2__.XMPPEvents.MUC_LOBBY_MEMBER_LEFT, strophe_js__WEBPACK_IMPORTED_MODULE_1__.Strophe.getResourceFromJid(from));
            });
            this.lobbyRoom.addEventListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_2__.XMPPEvents.MUC_DESTROYED, () => {
                // let's make sure we emit that all lobby users had left
                Object.keys(this.lobbyRoom.members)
                    .forEach(j => this.mainRoom.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_2__.XMPPEvents.MUC_LOBBY_MEMBER_LEFT, strophe_js__WEBPACK_IMPORTED_MODULE_1__.Strophe.getResourceFromJid(j)));
                this.lobbyRoom.clean();
                this.lobbyRoom = undefined;
                logger.info('Lobby room left(destroyed)!');
            });
        }
        else {
            // this should only be handled by those waiting in lobby
            this.lobbyRoom.addEventListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_2__.XMPPEvents.KICKED, isSelfPresence => {
                if (isSelfPresence) {
                    this.mainRoom.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_2__.XMPPEvents.MUC_DENIED_ACCESS);
                    this.lobbyRoom.clean();
                    return;
                }
            });
            // As there is still reference of the main room
            // the invite will be detected and addressed to its eventEmitter, even though we are not in it
            // the invite message should be received directly to the xmpp conn in general
            this.mainRoom.addEventListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_2__.XMPPEvents.INVITE_MESSAGE_RECEIVED, (roomJid, from, txt, invitePassword) => {
                logger.debug(`Received approval to join ${roomJid} ${from} ${txt}`);
                if (roomJid === this.mainRoom.roomjid) {
                    // we are now allowed, so let's join
                    this.mainRoom.join(invitePassword);
                }
            });
            this.lobbyRoom.addEventListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_2__.XMPPEvents.MUC_DESTROYED, (reason, jid) => {
                // we are receiving the jid of the main room
                // means we are invited to join, maybe lobby was disabled
                if (jid) {
                    this.mainRoom.join();
                    return;
                }
                this.lobbyRoom.clean();
                this.mainRoom.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_2__.XMPPEvents.MUC_DESTROYED, reason);
            });
            // If participant retries joining shared password while waiting in the lobby
            // and succeeds make sure we leave lobby
            this.mainRoom.addEventListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_2__.XMPPEvents.MUC_JOINED, () => {
                this.leave();
            });
        }
        return new Promise((resolve, reject) => {
            this.lobbyRoom.addEventListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_2__.XMPPEvents.MUC_JOINED, () => {
                resolve();
                // send our email, as we do not handle this on initial presence we need a second one
                if (email && !isModerator) {
                    this.lobbyRoom.addOrReplaceInPresence(EMAIL_COMMAND, { value: email })
                        && this.lobbyRoom.sendPresence();
                }
            });
            this.lobbyRoom.addEventListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_2__.XMPPEvents.ROOM_JOIN_ERROR, reject);
            this.lobbyRoom.addEventListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_2__.XMPPEvents.ROOM_CONNECT_NOT_ALLOWED_ERROR, reject);
            this.lobbyRoom.addEventListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_2__.XMPPEvents.ROOM_CONNECT_ERROR, reject);
            this.lobbyRoom.join();
        });
    }
    /**
     * Should be possible only for moderators.
     * @param id
     */
    denyAccess(id) {
        if (!this.isSupported() || !this.mainRoom.isModerator()) {
            return;
        }
        const jid = Object.keys(this.lobbyRoom.members)
            .find(j => strophe_js__WEBPACK_IMPORTED_MODULE_1__.Strophe.getResourceFromJid(j) === id);
        if (jid) {
            this.lobbyRoom.kick(jid);
        }
        else {
            logger.error(`Not found member for ${id} in lobby room.`);
        }
    }
    /**
     * Should be possible only for moderators.
     * @param id
     */
    approveAccess(id) {
        if (!this.isSupported() || !this.mainRoom.isModerator()) {
            return;
        }
        // Get the main room JID. If we are in a breakout room we'll use the main
        // room's lobby.
        let mainRoomJid = this.mainRoom.roomjid;
        if (this.mainRoom.getBreakoutRooms().isBreakoutRoom()) {
            mainRoomJid = this.mainRoom.getBreakoutRooms().getMainRoomJid();
        }
        const memberRoomJid = Object.keys(this.lobbyRoom.members)
            .find(j => strophe_js__WEBPACK_IMPORTED_MODULE_1__.Strophe.getResourceFromJid(j) === id);
        if (memberRoomJid) {
            const jid = this.lobbyRoom.members[memberRoomJid].jid;
            const msgToSend = (0,strophe_js__WEBPACK_IMPORTED_MODULE_1__.$msg)({ to: mainRoomJid })
                .c('x', { xmlns: 'http://jabber.org/protocol/muc#user' })
                .c('invite', { to: jid });
            this.xmpp.connection.sendIQ(msgToSend, () => { }, // eslint-disable-line no-empty-function
            // eslint-disable-line no-empty-function
            e => {
                logger.error(`Error sending invite for ${jid}`, e);
            });
        }
        else {
            logger.error(`Not found member for ${memberRoomJid} in lobby room.`);
        }
    }
}
//# sourceMappingURL=Lobby.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/xmpp/MediaSessionEvents.js":
/*!****************************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/xmpp/MediaSessionEvents.js ***!
  \****************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (__WEBPACK_DEFAULT_EXPORT__)
/* harmony export */ });
var MediaSessionEvents;
(function (MediaSessionEvents) {
    /**
     * Event triggered when the remote party signals video max frame heights for its local sources.
     */
    MediaSessionEvents["REMOTE_SOURCE_CONSTRAINTS_CHANGED"] = "media_session.REMOTE_SOURCE_CONSTRAINTS_CHANGED";
})(MediaSessionEvents || (MediaSessionEvents = {}));
;
/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (MediaSessionEvents);
//# sourceMappingURL=MediaSessionEvents.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/xmpp/ResumeTask.js":
/*!********************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/xmpp/ResumeTask.js ***!
  \********************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
var __filename = "/index.js";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (/* binding */ ResumeTask)
/* harmony export */ });
/* harmony import */ var _jitsi_logger__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @jitsi/logger */ "./node_modules/@jitsi/logger/lib/index.js");
/* harmony import */ var _jitsi_logger__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(_jitsi_logger__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var _connectivity_NetworkInfo__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../connectivity/NetworkInfo */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/connectivity/NetworkInfo.js");
/* harmony import */ var _util_Retry__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../util/Retry */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/util/Retry.js");



const logger = (0,_jitsi_logger__WEBPACK_IMPORTED_MODULE_0__.getLogger)(__filename);
/**
 * The class contains the logic for triggering connection resume via XEP-0198 stream management.
 * It does two things, the first one is it tracks the internet online/offline status and it makes sure that
 * the reconnect is attempted only while online. The seconds thing is that it tracks the retry attempts and extends
 * the retry interval using the full jitter pattern.
 */
class ResumeTask {
    /**
     * Initializes new {@code RetryTask}.
     * @param {Strophe.Connection} stropheConnection - The Strophe connection instance.
     */
    constructor(stropheConnection) {
        this._stropheConn = stropheConnection;
        /**
         * The counter increased before each resume retry attempt, used to calculate exponential backoff.
         * @type {number}
         * @private
         */
        this._resumeRetryN = 0;
        this._retryDelay = undefined;
    }
    /**
     * @returns {number|undefined} - How much the app will wait before trying to resume the XMPP connection. When
     * 'undefined' it means that no resume task was not scheduled.
     */
    get retryDelay() {
        return this._retryDelay;
    }
    /**
     * Called by {@link XmppConnection} when the connection drops and it's a signal it wants to schedule a reconnect.
     *
     * @returns {void}
     */
    schedule() {
        this._cancelResume();
        this._resumeRetryN += 1;
        this._networkOnlineListener
            = _connectivity_NetworkInfo__WEBPACK_IMPORTED_MODULE_1__["default"].addEventListener(_connectivity_NetworkInfo__WEBPACK_IMPORTED_MODULE_1__.NETWORK_INFO_EVENT, ({ isOnline }) => {
                if (isOnline) {
                    this._scheduleResume();
                }
                else {
                    this._cancelResume();
                }
            });
        _connectivity_NetworkInfo__WEBPACK_IMPORTED_MODULE_1__["default"].isOnline() && this._scheduleResume();
    }
    /**
     * Schedules a delayed timeout which will execute the resume action.
     * @private
     * @returns {void}
     */
    _scheduleResume() {
        if (this._resumeTimeout) {
            // NO-OP
            return;
        }
        // The retry delay will be:
        //   1st retry: 1.5s - 3s
        //   2nd retry: 3s - 9s
        //   3rd and next retry: 4.5s - 27s
        this._resumeRetryN = Math.min(3, this._resumeRetryN);
        this._retryDelay = (0,_util_Retry__WEBPACK_IMPORTED_MODULE_2__.getJitterDelay)(
        /* retry */ this._resumeRetryN, 
        /* minDelay */ this._resumeRetryN * 1500, 3);
        logger.info(`Will try to resume the XMPP connection in ${this.retryDelay}ms`);
        this._resumeTimeout = setTimeout(() => this._resumeConnection(), this.retryDelay);
    }
    /**
     * Cancels the delayed resume task.
     *
     * @private
     * @returns {void}
     */
    _cancelResume() {
        if (this._resumeTimeout) {
            logger.info('Canceling connection resume task');
            clearTimeout(this._resumeTimeout);
            this._resumeTimeout = undefined;
            this._retryDelay = undefined;
        }
    }
    /**
     * Resumes the XMPP connection using the stream management plugin.
     *
     * @private
     * @returns {void}
     */
    _resumeConnection() {
        const { streamManagement } = this._stropheConn;
        const resumeToken = streamManagement.getResumeToken();
        // Things may have changed since when the task was scheduled
        if (!resumeToken) {
            return;
        }
        logger.info('Trying to resume the XMPP connection');
        const url = new URL(this._stropheConn.service);
        let { search } = url;
        const pattern = /(previd=)([\w-]+)/;
        const oldToken = search.match(pattern);
        // Replace previd if the previd value has changed.
        if (oldToken && oldToken.indexOf(resumeToken) === -1) {
            search = search.replace(pattern, `$1${resumeToken}`);
            // Append previd if it doesn't exist.
        }
        else if (!oldToken) {
            search += search.indexOf('?') === -1 ? `?previd=${resumeToken}` : `&previd=${resumeToken}`;
        }
        url.search = search;
        this._stropheConn.service = url.toString();
        streamManagement.resume();
    }
    /**
     * Cancels the retry task. It's called by {@link XmppConnection} when it's no longer interested in reconnecting for
     * example when the disconnect method is called.
     *
     * @returns {void}
     */
    cancel() {
        this._cancelResume();
        this._resumeRetryN = 0;
        if (this._networkOnlineListener) {
            this._networkOnlineListener();
            this._networkOnlineListener = null;
        }
    }
}
//# sourceMappingURL=ResumeTask.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/xmpp/RoomMetadata.js":
/*!**********************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/xmpp/RoomMetadata.js ***!
  \**********************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
var __filename = "/index.js";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (/* binding */ RoomMetadata)
/* harmony export */ });
/* harmony import */ var _jitsi_logger__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @jitsi/logger */ "./node_modules/@jitsi/logger/lib/index.js");
/* harmony import */ var _jitsi_logger__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(_jitsi_logger__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var lodash_isequal__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! lodash.isequal */ "./node_modules/lodash.isequal/index.js");
/* harmony import */ var lodash_isequal__WEBPACK_IMPORTED_MODULE_1___default = /*#__PURE__*/__webpack_require__.n(lodash_isequal__WEBPACK_IMPORTED_MODULE_1__);
/* harmony import */ var strophe_js__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! strophe.js */ "./node_modules/strophe.js/dist/strophe.umd.js");
/* harmony import */ var strophe_js__WEBPACK_IMPORTED_MODULE_2___default = /*#__PURE__*/__webpack_require__.n(strophe_js__WEBPACK_IMPORTED_MODULE_2__);
/* harmony import */ var _service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../service/xmpp/XMPPEvents */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/xmpp/XMPPEvents.js");
/* harmony import */ var _xmpp__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./xmpp */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/xmpp/xmpp.js");





const logger = (0,_jitsi_logger__WEBPACK_IMPORTED_MODULE_0__.getLogger)(__filename);
/**
 * Helper class for handling room metadata.
 */
class RoomMetadata {
    /**
     * Constructs lobby room.
     *
     * @param {ChatRoom} room the room we are in.
     */
    constructor(room) {
        this.room = room;
        this._handleMessages = this._handleMessages.bind(this);
        this.room.xmpp.addListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_3__.XMPPEvents.ROOM_METADATA_EVENT, this._handleMessages);
        this._metadata = {};
    }
    /**
     * Stops listening for events.
     */
    dispose() {
        this.room.xmpp.removeListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_3__.XMPPEvents.ROOM_METADATA_EVENT, this._handleMessages);
    }
    /**
     * Sets metadata for the given key.
     *
     * @param {string} key - key under which the metadata will be stored.
     * @param {object} data - data to be stored.
     */
    setMetadata(key, data) {
        if (!this.isSupported() || !this.room.isModerator()) {
            logger.error(`Cannot set room metadata - supported:${this.isSupported()},
                moderator:${this.room.isModerator()}`);
            return;
        }
        const message = {
            key,
            data
        };
        this._sendMessage(message);
    }
    /**
     * Gets the stored metadata (all of it).
     *
     * @returns The stored metadata.
     */
    getMetadata() {
        return this._metadata;
    }
    /**
     * Whether Breakout Rooms support is enabled in the backend or not.
     */
    isSupported() {
        return Boolean(this.getComponentAddress());
    }
    /**
     * Gets the address of the Breakout Rooms XMPP component.
     *
     * @returns The address of the component.
     */
    getComponentAddress() {
        return this.room.xmpp.roomMetadataComponentAddress;
    }
    /**
     * Handles a message with metadata updates.
     *
     * @param {object} payload - Arbitrary data.
     */
    _handleMessages(payload) {
        const { metadata } = payload;
        if (!metadata || lodash_isequal__WEBPACK_IMPORTED_MODULE_1___default()(this._metadata, metadata)) {
            return;
        }
        this._metadata = metadata;
        this.room.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_3__.XMPPEvents.ROOM_METADATA_UPDATED, metadata);
    }
    /**
     * Helper to send a breakout rooms message to the component.
     *
     * @param {Object} message - Command that needs to be sent.
     */
    _sendMessage(message) {
        message[_xmpp__WEBPACK_IMPORTED_MODULE_4__.JITSI_MEET_MUC_TYPE] = 'room_metadata';
        const msg = (0,strophe_js__WEBPACK_IMPORTED_MODULE_2__.$msg)({ to: this.getComponentAddress() });
        msg.c('room_metadata', {
            room: this.room.roomjid,
            xmlns: 'http://jitsi.org/jitmeet'
        }, JSON.stringify(message)).up();
        this.room.xmpp.connection.send(msg);
    }
}
//# sourceMappingURL=RoomMetadata.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/xmpp/SignalingLayerImpl.js":
/*!****************************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/xmpp/SignalingLayerImpl.js ***!
  \****************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
var __filename = "/index.js";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   SOURCE_INFO_PRESENCE_ELEMENT: () => (/* binding */ SOURCE_INFO_PRESENCE_ELEMENT),
/* harmony export */   "default": () => (/* binding */ SignalingLayerImpl)
/* harmony export */ });
/* harmony import */ var _jitsi_logger__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @jitsi/logger */ "./node_modules/@jitsi/logger/lib/index.js");
/* harmony import */ var _jitsi_logger__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(_jitsi_logger__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var strophe_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! strophe.js */ "./node_modules/strophe.js/dist/strophe.umd.js");
/* harmony import */ var strophe_js__WEBPACK_IMPORTED_MODULE_1___default = /*#__PURE__*/__webpack_require__.n(strophe_js__WEBPACK_IMPORTED_MODULE_1__);
/* harmony import */ var _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../service/RTC/MediaType */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/RTC/MediaType.js");
/* harmony import */ var _service_RTC_SignalingEvents__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../service/RTC/SignalingEvents */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/RTC/SignalingEvents.js");
/* harmony import */ var _service_RTC_SignalingLayer__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../../service/RTC/SignalingLayer */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/RTC/SignalingLayer.js");
/* harmony import */ var _service_RTC_VideoType__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../../service/RTC/VideoType */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/RTC/VideoType.js");
/* harmony import */ var _service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../../service/xmpp/XMPPEvents */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/xmpp/XMPPEvents.js");
/* harmony import */ var _flags_FeatureFlags__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../flags/FeatureFlags */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/flags/FeatureFlags.js");
/* harmony import */ var _ChatRoom__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ./ChatRoom */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/xmpp/ChatRoom.js");









const logger = (0,_jitsi_logger__WEBPACK_IMPORTED_MODULE_0__.getLogger)(__filename);
const SOURCE_INFO_PRESENCE_ELEMENT = 'SourceInfo';
/**
 * Default XMPP implementation of the {@link SignalingLayer} interface. Obtains
 * the data from the MUC presence.
 */
class SignalingLayerImpl extends _service_RTC_SignalingLayer__WEBPACK_IMPORTED_MODULE_4__["default"] {
    /**
     * Creates new instance.
     */
    constructor() {
        super();
        /**
         * A map that stores SSRCs of remote streams. And is used only locally
         * We store the mapping when jingle is received, and later is used
         * onaddstream webrtc event where we have only the ssrc
         * FIXME: This map got filled and never cleaned and can grow during long
         * conference
         * @type {Map<number, string>} maps SSRC number to jid
         */
        this.ssrcOwners = new Map();
        /**
         *
         * @type {ChatRoom|null}
         */
        this.chatRoom = null;
        /**
         * @type {Map<SourceName, SourceInfo>}
         * @private
         */
        this._localSourceState = {};
        /**
         * @type {Map<EndpointId, Map<SourceName, SourceInfo>>}
         * @private
         */
        this._remoteSourceState = {};
        /**
         * A map that stores the source name of a track identified by it's ssrc.
         * We store the mapping when jingle is received, and later is used
         * onaddstream webrtc event where we have only the ssrc
         * FIXME: This map got filled and never cleaned and can grow during long
         * conference
         * @type {Map<number, string>} maps SSRC number to source name
         */
        this._sourceNames = new Map();
    }
    /**
     * Adds <SourceInfo> element to the local presence.
     *
     * @returns {void}
     * @private
     */
    _addLocalSourceInfoToPresence() {
        if (this.chatRoom) {
            return this.chatRoom.addOrReplaceInPresence(SOURCE_INFO_PRESENCE_ELEMENT, { value: JSON.stringify(this._localSourceState) });
        }
        return false;
    }
    /**
     * Binds event listeners to the chat room instance.
     * @param {ChatRoom} room
     * @private
     * @returns {void}
     */
    _bindChatRoomEventHandlers(room) {
        // Add handlers for 'audiomuted', 'videomuted' and 'videoType' fields in presence in order to support interop
        // with very old versions of mobile clients and jigasi that do not support source-name signaling.
        const emitAudioMutedEvent = (endpointId, muted) => {
            this.eventEmitter.emit(_service_RTC_SignalingEvents__WEBPACK_IMPORTED_MODULE_3__.PEER_MUTED_CHANGED, endpointId, _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_2__.MediaType.AUDIO, muted);
        };
        this._audioMuteHandler = (node, from) => {
            if (!this._doesEndpointSendNewSourceInfo(from)) {
                emitAudioMutedEvent(from, node.value === 'true');
            }
        };
        room.addPresenceListener('audiomuted', this._audioMuteHandler);
        const emitVideoMutedEvent = (endpointId, muted) => {
            this.eventEmitter.emit(_service_RTC_SignalingEvents__WEBPACK_IMPORTED_MODULE_3__.PEER_MUTED_CHANGED, endpointId, _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_2__.MediaType.VIDEO, muted);
        };
        this._videoMuteHandler = (node, from) => {
            if (!this._doesEndpointSendNewSourceInfo(from)) {
                emitVideoMutedEvent(from, node.value === 'true');
            }
        };
        room.addPresenceListener('videomuted', this._videoMuteHandler);
        const emitVideoTypeEvent = (endpointId, videoType) => {
            this.eventEmitter.emit(_service_RTC_SignalingEvents__WEBPACK_IMPORTED_MODULE_3__.PEER_VIDEO_TYPE_CHANGED, endpointId, videoType);
        };
        this._videoTypeHandler = (node, from) => {
            if (!this._doesEndpointSendNewSourceInfo(from)) {
                emitVideoTypeEvent(from, node.value);
            }
        };
        room.addPresenceListener('videoType', this._videoTypeHandler);
        // Add handlers for presence in the new format.
        this._sourceInfoHandler = (node, mucNick) => {
            var _a;
            const endpointId = mucNick;
            const { value } = node;
            const sourceInfoJSON = JSON.parse(value);
            const emitEventsFromHere = this._doesEndpointSendNewSourceInfo(endpointId);
            const endpointSourceState = this._remoteSourceState[endpointId] || (this._remoteSourceState[endpointId] = {});
            for (const sourceName of Object.keys(sourceInfoJSON)) {
                let sourceChanged = false;
                const mediaType = (0,_service_RTC_SignalingLayer__WEBPACK_IMPORTED_MODULE_4__.getMediaTypeFromSourceName)(sourceName);
                const newMutedState = Boolean(sourceInfoJSON[sourceName].muted);
                const oldSourceState = endpointSourceState[sourceName]
                    || (endpointSourceState[sourceName] = { sourceName });
                if (oldSourceState.muted !== newMutedState) {
                    sourceChanged = true;
                    oldSourceState.muted = newMutedState;
                    if (emitEventsFromHere && !this._localSourceState[sourceName]) {
                        this.eventEmitter.emit(_service_RTC_SignalingEvents__WEBPACK_IMPORTED_MODULE_3__.SOURCE_MUTED_CHANGED, sourceName, newMutedState);
                    }
                }
                // Assume a default videoType of 'camera' for video sources.
                const newVideoType = mediaType === _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_2__.MediaType.VIDEO
                    ? (_a = sourceInfoJSON[sourceName].videoType) !== null && _a !== void 0 ? _a : _service_RTC_VideoType__WEBPACK_IMPORTED_MODULE_5__.VideoType.CAMERA
                    : undefined;
                if (oldSourceState.videoType !== newVideoType) {
                    oldSourceState.videoType = newVideoType;
                    sourceChanged = true;
                    // Since having a mix of eps that do/don't support multi-stream in the same call is supported, emit
                    // SOURCE_VIDEO_TYPE_CHANGED event when the remote source changes videoType.
                    if (emitEventsFromHere && !this._localSourceState[sourceName]) {
                        this.eventEmitter.emit(_service_RTC_SignalingEvents__WEBPACK_IMPORTED_MODULE_3__.SOURCE_VIDEO_TYPE_CHANGED, sourceName, newVideoType);
                    }
                }
                if (sourceChanged && _flags_FeatureFlags__WEBPACK_IMPORTED_MODULE_7__["default"].isSsrcRewritingSupported()) {
                    this.eventEmitter.emit(_service_RTC_SignalingEvents__WEBPACK_IMPORTED_MODULE_3__.SOURCE_UPDATED, sourceName, mucNick, newMutedState, newVideoType);
                }
            }
            // Cleanup removed source names
            const newSourceNames = Object.keys(sourceInfoJSON);
            for (const sourceName of Object.keys(endpointSourceState)) {
                if (newSourceNames.indexOf(sourceName) === -1) {
                    delete endpointSourceState[sourceName];
                }
            }
        };
        room.addPresenceListener('SourceInfo', this._sourceInfoHandler);
        // Cleanup when participant leaves
        this._memberLeftHandler = jid => {
            const endpointId = strophe_js__WEBPACK_IMPORTED_MODULE_1__.Strophe.getResourceFromJid(jid);
            delete this._remoteSourceState[endpointId];
            for (const [key, value] of this.ssrcOwners.entries()) {
                if (value === endpointId) {
                    delete this._sourceNames[key];
                }
            }
        };
        room.addEventListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_6__.XMPPEvents.MUC_MEMBER_LEFT, this._memberLeftHandler);
    }
    /**
     * Check is given endpoint has advertised <SourceInfo/> in it's presence which means that the source name signaling
     * is used by this endpoint.
     *
     * @param {EndpointId} endpointId
     * @returns {boolean}
     */
    _doesEndpointSendNewSourceInfo(endpointId) {
        var _a;
        const presence = (_a = this.chatRoom) === null || _a === void 0 ? void 0 : _a.getLastPresence(endpointId);
        return Boolean(presence && presence.find(node => node.tagName === SOURCE_INFO_PRESENCE_ELEMENT));
    }
    /**
     * Logs a debug or error message to console depending on whether SSRC rewriting is enabled or not.
     * Owner changes are permitted only when SSRC rewriting is enabled.
     *
     * @param {string} message - The message to be logged.
     * @returns {void}
     */
    _logOwnerChangedMessage(message) {
        if (_flags_FeatureFlags__WEBPACK_IMPORTED_MODULE_7__["default"].isSsrcRewritingSupported()) {
            logger.debug(message);
        }
        else {
            logger.error(message);
        }
    }
    /**
     * @inheritDoc
     */
    getPeerMediaInfo(owner, mediaType, sourceName) {
        var _a, _b, _c;
        const legacyGetPeerMediaInfo = () => {
            if (this.chatRoom) {
                return this.chatRoom.getMediaPresenceInfo(owner, mediaType);
            }
            logger.warn('Requested peer media info, before room was set');
        };
        const lastPresence = (_a = this.chatRoom) === null || _a === void 0 ? void 0 : _a.getLastPresence(owner);
        if (!lastPresence) {
            logger.warn(`getPeerMediaInfo - no presence stored for: ${owner}`);
            return;
        }
        if (!this._doesEndpointSendNewSourceInfo(owner)) {
            return legacyGetPeerMediaInfo();
        }
        if (sourceName) {
            return this.getPeerSourceInfo(owner, sourceName);
        }
        const mediaInfo = {
            muted: true
        };
        if (mediaType === _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_2__.MediaType.VIDEO) {
            mediaInfo.videoType = undefined;
            const codecListNode = (0,_ChatRoom__WEBPACK_IMPORTED_MODULE_8__.filterNodeFromPresenceJSON)(lastPresence, 'jitsi_participant_codecList');
            const codecTypeNode = (0,_ChatRoom__WEBPACK_IMPORTED_MODULE_8__.filterNodeFromPresenceJSON)(lastPresence, 'jitsi_participant_codecType');
            if (codecListNode.length) {
                mediaInfo.codecList = (_c = (_b = codecListNode[0].value) === null || _b === void 0 ? void 0 : _b.split(',')) !== null && _c !== void 0 ? _c : [];
            }
            else if (codecTypeNode.length > 0) {
                mediaInfo.codecType = codecTypeNode[0].value;
            }
        }
        return mediaInfo;
    }
    /**
     * @inheritDoc
     */
    getPeerSourceInfo(owner, sourceName) {
        var _a;
        const mediaType = (0,_service_RTC_SignalingLayer__WEBPACK_IMPORTED_MODULE_4__.getMediaTypeFromSourceName)(sourceName);
        const mediaInfo = {
            muted: true,
            videoType: mediaType === _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_2__.MediaType.VIDEO ? _service_RTC_VideoType__WEBPACK_IMPORTED_MODULE_5__.VideoType.CAMERA : undefined // 'camera' by default
        };
        return this._remoteSourceState[owner]
            ? (_a = this._remoteSourceState[owner][sourceName]) !== null && _a !== void 0 ? _a : mediaInfo
            : undefined;
    }
    /**
     * @inheritDoc
     */
    getSSRCOwner(ssrc) {
        return this.ssrcOwners.get(ssrc);
    }
    /**
     * @inheritDoc
     */
    getTrackSourceName(ssrc) {
        return this._sourceNames.get(ssrc);
    }
    /**
     * @inheritDoc
     */
    removeSSRCOwners(ssrcList) {
        if (!(ssrcList === null || ssrcList === void 0 ? void 0 : ssrcList.length)) {
            return;
        }
        for (const ssrc of ssrcList) {
            this.ssrcOwners.delete(ssrc);
        }
    }
    /**
     * Sets the <tt>ChatRoom</tt> instance used and binds presence listeners.
     * @param {ChatRoom} room
     */
    setChatRoom(room) {
        const oldChatRoom = this.chatRoom;
        this.chatRoom = room;
        if (oldChatRoom) {
            oldChatRoom.removePresenceListener('audiomuted', this._audioMuteHandler);
            oldChatRoom.removePresenceListener('videomuted', this._videoMuteHandler);
            oldChatRoom.removePresenceListener('videoType', this._videoTypeHandler);
            this._sourceInfoHandler
                && oldChatRoom.removePresenceListener(SOURCE_INFO_PRESENCE_ELEMENT, this._sourceInfoHandler);
            this._memberLeftHandler
                && oldChatRoom.removeEventListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_6__.XMPPEvents.MUC_MEMBER_LEFT, this._memberLeftHandler);
        }
        if (room) {
            this._bindChatRoomEventHandlers(room);
            this._addLocalSourceInfoToPresence();
        }
    }
    /**
     * @inheritDoc
     */
    setSSRCOwner(ssrc, endpointId) {
        if (typeof ssrc !== 'number') {
            throw new TypeError(`SSRC(${ssrc}) must be a number`);
        }
        // Now signaling layer instance is shared between different JingleSessionPC instances, so although very unlikely
        // an SSRC conflict could potentially occur. Log a message to make debugging easier.
        const existingOwner = this.ssrcOwners.get(ssrc);
        if (existingOwner && existingOwner !== endpointId) {
            this._logOwnerChangedMessage(`SSRC owner re-assigned from ${existingOwner} to ${endpointId}`);
        }
        this.ssrcOwners.set(ssrc, endpointId);
    }
    /**
     * @inheritDoc
     */
    setTrackMuteStatus(sourceName, muted) {
        if (!this._localSourceState[sourceName]) {
            this._localSourceState[sourceName] = {};
        }
        this._localSourceState[sourceName].muted = muted;
        logger.debug(`Mute state of ${sourceName} changed to muted=${muted}`);
        if (this.chatRoom) {
            return this._addLocalSourceInfoToPresence();
        }
        return false;
    }
    /**
     * @inheritDoc
     */
    setTrackSourceName(ssrc, sourceName) {
        if (typeof ssrc !== 'number') {
            throw new TypeError(`SSRC(${ssrc}) must be a number`);
        }
        // Now signaling layer instance is shared between different JingleSessionPC instances, so although very unlikely
        // an SSRC conflict could potentially occur. Log a message to make debugging easier.
        const existingName = this._sourceNames.get(ssrc);
        if (existingName && existingName !== sourceName) {
            this._logOwnerChangedMessage(`SSRC(${ssrc}) sourceName re-assigned from ${existingName} to ${sourceName}`);
        }
        this._sourceNames.set(ssrc, sourceName);
    }
    /**
     * @inheritDoc
     */
    setTrackVideoType(sourceName, videoType) {
        if (!this._localSourceState[sourceName]) {
            this._localSourceState[sourceName] = {};
        }
        if (this._localSourceState[sourceName].videoType !== videoType) {
            // Include only if not a camera (default)
            this._localSourceState[sourceName].videoType = videoType === _service_RTC_VideoType__WEBPACK_IMPORTED_MODULE_5__.VideoType.CAMERA ? undefined : videoType;
            return this._addLocalSourceInfoToPresence();
        }
        return false;
    }
    /**
     * @inheritDoc
     */
    updateSsrcOwnersOnLeave(id) {
        const ssrcs = Array.from(this.ssrcOwners)
            .filter(entry => entry[1] === id)
            .map(entry => entry[0]);
        if (!(ssrcs === null || ssrcs === void 0 ? void 0 : ssrcs.length)) {
            return;
        }
        this.removeSSRCOwners(ssrcs);
    }
}
//# sourceMappingURL=SignalingLayerImpl.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/xmpp/StropheLastSuccess.js":
/*!****************************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/xmpp/StropheLastSuccess.js ***!
  \****************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (/* binding */ LastRequestTracker)
/* harmony export */ });
/**
 * Attaches to the {@link Strophe.Connection.rawInput} which is called whenever any data is received from the server.
 */
class LastRequestTracker {
    /**
     * Initializes new instance.
     */
    constructor() {
        this._lastSuccess = null;
        this._lastFailedMessage = null;
    }
    /**
     * Starts tracking requests on the given connection.
     *
     * @param {XmppConnection} xmppConnection - The XMPP connection which manages the given {@code stropheConnection}.
     * @param {Object} stropheConnection - Strophe connection instance.
     */
    startTracking(xmppConnection, stropheConnection) {
        const originalRawInput = stropheConnection.rawInput;
        stropheConnection.rawInput = (...args) => {
            const rawMessage = args[0];
            if (rawMessage.includes('failure')) {
                this._lastFailedMessage = rawMessage;
            }
            // It's okay to use rawInput callback only once the connection has been established, otherwise it will
            // treat 'item-not-found' or other connection error on websocket reconnect as successful stanza received.
            if (xmppConnection.connected) {
                this._lastSuccess = Date.now();
            }
            originalRawInput.apply(stropheConnection, args);
        };
    }
    /**
     * Returns the last raw failed incoming message on the xmpp connection.
     *
     * @returns {string|null}
     */
    getLastFailedMessage() {
        return this._lastFailedMessage;
    }
    /**
     * Returns how many milliseconds have passed since the last successful BOSH request.
     *
     * @returns {number|null}
     */
    getTimeSinceLastSuccess() {
        return this._lastSuccess
            ? Date.now() - this._lastSuccess
            : null;
    }
}
//# sourceMappingURL=StropheLastSuccess.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/xmpp/XmppConnection.js":
/*!************************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/xmpp/XmppConnection.js ***!
  \************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
var __filename = "/index.js";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (/* binding */ XmppConnection)
/* harmony export */ });
/* harmony import */ var _jitsi_logger__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @jitsi/logger */ "./node_modules/@jitsi/logger/lib/index.js");
/* harmony import */ var _jitsi_logger__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(_jitsi_logger__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var strophe_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! strophe.js */ "./node_modules/strophe.js/dist/strophe.umd.js");
/* harmony import */ var strophe_js__WEBPACK_IMPORTED_MODULE_1___default = /*#__PURE__*/__webpack_require__.n(strophe_js__WEBPACK_IMPORTED_MODULE_1__);
/* harmony import */ var strophejs_plugin_stream_management__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! strophejs-plugin-stream-management */ "./node_modules/strophejs-plugin-stream-management/lib/strophe.stream-management.js");
/* harmony import */ var strophejs_plugin_stream_management__WEBPACK_IMPORTED_MODULE_2___default = /*#__PURE__*/__webpack_require__.n(strophejs_plugin_stream_management__WEBPACK_IMPORTED_MODULE_2__);
/* harmony import */ var _util_Listenable__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../util/Listenable */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/util/Listenable.js");
/* harmony import */ var _ResumeTask__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./ResumeTask */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/xmpp/ResumeTask.js");
/* harmony import */ var _StropheLastSuccess__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./StropheLastSuccess */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/xmpp/StropheLastSuccess.js");
/* harmony import */ var _strophe_ping__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./strophe.ping */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/xmpp/strophe.ping.js");







const logger = (0,_jitsi_logger__WEBPACK_IMPORTED_MODULE_0__.getLogger)(__filename);
/**
 * The lib-jitsi-meet layer for {@link Strophe.Connection}.
 */
class XmppConnection extends _util_Listenable__WEBPACK_IMPORTED_MODULE_3__["default"] {
    /**
     * The list of {@link XmppConnection} events.
     *
     * @returns {Object}
     */
    static get Events() {
        return {
            CONN_STATUS_CHANGED: 'CONN_STATUS_CHANGED',
            CONN_SHARD_CHANGED: 'CONN_SHARD_CHANGED'
        };
    }
    /**
     * The list of Xmpp connection statuses.
     *
     * @returns {Strophe.Status}
     */
    static get Status() {
        return strophe_js__WEBPACK_IMPORTED_MODULE_1__.Strophe.Status;
    }
    /**
     * Initializes new connection instance.
     *
     * @param {Object} options
     * @param {String} options.serviceUrl - The BOSH or WebSocket service URL.
     * @param {String} options.shard - The BOSH or WebSocket is connecting to this shard.
     * Useful for detecting when shard changes.
     * @param {String} [options.enableWebsocketResume=true] - True/false to control the stream resumption functionality.
     * It will enable automatically by default if supported by the XMPP server.
     * @param {Number} [options.websocketKeepAlive=60000] - The websocket keep alive interval.
     * It's the interval + a up to a minute of jitter. Pass -1 to disable.
     * The keep alive is HTTP GET request to {@link options.serviceUrl} or to {@link options.websocketKeepAliveUrl}.
     * @param {Number} [options.websocketKeepAliveUrl] - The websocket keep alive url to use if any,
     * if missing the serviceUrl url will be used.
     * @param {Object} [options.xmppPing] - The xmpp ping settings.
     */
    constructor({ enableWebsocketResume, websocketKeepAlive, websocketKeepAliveUrl, serviceUrl, shard, xmppPing }) {
        super();
        this._options = {
            enableWebsocketResume: typeof enableWebsocketResume === 'undefined' ? true : enableWebsocketResume,
            pingOptions: xmppPing,
            shard,
            websocketKeepAlive: typeof websocketKeepAlive === 'undefined' ? 60 * 1000 : Number(websocketKeepAlive),
            websocketKeepAliveUrl
        };
        this._stropheConn = new strophe_js__WEBPACK_IMPORTED_MODULE_1__.Strophe.Connection(serviceUrl);
        this._usesWebsocket = serviceUrl.startsWith('ws:') || serviceUrl.startsWith('wss:');
        // The default maxRetries is 5, which is too long.
        this._stropheConn.maxRetries = 3;
        this._rawInputTracker = new _StropheLastSuccess__WEBPACK_IMPORTED_MODULE_5__["default"]();
        this._rawInputTracker.startTracking(this, this._stropheConn);
        this._resumeTask = new _ResumeTask__WEBPACK_IMPORTED_MODULE_4__["default"](this._stropheConn);
        /**
         * @typedef DeferredSendIQ Object
         * @property {Element} iq - The IQ to send.
         * @property {function} resolve - The resolve method of the deferred Promise.
         * @property {function} reject - The reject method of the deferred Promise.
         * @property {number} timeout - The ID of the timeout task that needs to be cleared, before sending the IQ.
         */
        /**
         * Deferred IQs to be sent upon reconnect.
         * @type {Array<DeferredSendIQ>}
         * @private
         */
        this._deferredIQs = [];
        // Ping plugin is mandatory for the Websocket mode to work correctly. It's used to detect when the connection
        // is broken (WebSocket/TCP connection not closed gracefully).
        this.addConnectionPlugin('ping', new _strophe_ping__WEBPACK_IMPORTED_MODULE_6__["default"]({
            getTimeSinceLastServerResponse: () => this.getTimeSinceLastSuccess(),
            onPingThresholdExceeded: () => this._onPingErrorThresholdExceeded(),
            pingOptions: xmppPing
        }));
        // tracks whether this is the initial connection or a reconnect
        this._oneSuccessfulConnect = false;
    }
    /**
     * A getter for the connected state.
     *
     * @returns {boolean}
     */
    get connected() {
        const websocket = this._stropheConn && this._stropheConn._proto && this._stropheConn._proto.socket;
        return (this._status === strophe_js__WEBPACK_IMPORTED_MODULE_1__.Strophe.Status.CONNECTED || this._status === strophe_js__WEBPACK_IMPORTED_MODULE_1__.Strophe.Status.ATTACHED)
            && (!this.isUsingWebSocket || (websocket && websocket.readyState === WebSocket.OPEN));
    }
    /**
     * Retrieves the feature discovery plugin instance.
     *
     * @returns {Strophe.Connection.disco}
     */
    get disco() {
        return this._stropheConn.disco;
    }
    /**
     * A getter for the disconnecting state.
     *
     * @returns {boolean}
     */
    get disconnecting() {
        return this._stropheConn.disconnecting === true;
    }
    /**
     * A getter for the domain.
     *
     * @returns {string|null}
     */
    get domain() {
        return this._stropheConn.domain;
    }
    /**
     * Tells if Websocket is used as the transport for the current XMPP connection. Returns true for Websocket or false
     * for BOSH.
     * @returns {boolean}
     */
    get isUsingWebSocket() {
        return this._usesWebsocket;
    }
    /**
     * A getter for the JID.
     *
     * @returns {string|null}
     */
    get jid() {
        return this._stropheConn.jid;
    }
    /**
     * Returns headers for the last BOSH response received.
     *
     * @returns {string}
     */
    get lastResponseHeaders() {
        return this._stropheConn._proto && this._stropheConn._proto.lastResponseHeaders;
    }
    /**
     * A getter for the logger plugin instance.
     *
     * @returns {*}
     */
    get logger() {
        return this._stropheConn.logger;
    }
    /**
     * A getter for the connection options.
     *
     * @returns {*}
     */
    get options() {
        return this._stropheConn.options;
    }
    /**
     * A getter for the domain to be used for ping.
     */
    get pingDomain() {
        var _a;
        return ((_a = this._options.pingOptions) === null || _a === void 0 ? void 0 : _a.domain) || this.domain;
    }
    /**
     * A getter for the service URL.
     *
     * @returns {string}
     */
    get service() {
        return this._stropheConn.service;
    }
    /**
     * Sets new value for shard.
     * @param value the new shard value.
     */
    set shard(value) {
        this._options.shard = value;
        // shard setting changed so let's schedule a new keep-alive check if connected
        if (this._oneSuccessfulConnect) {
            this._maybeStartWSKeepAlive();
        }
    }
    /**
     * Returns the current connection status.
     *
     * @returns {Strophe.Status}
     */
    get status() {
        return this._status;
    }
    /**
     * Adds a connection plugin to this instance.
     *
     * @param {string} name - The name of the plugin or rather a key under which it will be stored on this connection
     * instance.
     * @param {ConnectionPluginListenable} plugin - The plugin to add.
     */
    addConnectionPlugin(name, plugin) {
        this[name] = plugin;
        plugin.init(this);
    }
    /**
     * See {@link Strophe.Connection.addHandler}
     *
     * @returns {Object} - handler for the connection.
     */
    addHandler(...args) {
        return this._stropheConn.addHandler(...args);
    }
    /**
     * See {@link Strophe.Connection.deleteHandler}
     *
     * @returns {void}
     */
    deleteHandler(...args) {
        this._stropheConn.deleteHandler(...args);
    }
    /* eslint-disable max-params */
    /**
     * Wraps {@link Strophe.Connection.attach} method in order to intercept the connection status updates.
     * See {@link Strophe.Connection.attach} for the params description.
     *
     * @returns {void}
     */
    attach(jid, sid, rid, callback, ...args) {
        this._stropheConn.attach(jid, sid, rid, this._stropheConnectionCb.bind(this, callback), ...args);
    }
    /**
     * Wraps Strophe.Connection.connect method in order to intercept the connection status updates.
     * See {@link Strophe.Connection.connect} for the params description.
     *
     * @returns {void}
     */
    connect(jid, pass, callback, ...args) {
        this._stropheConn.connect(jid, pass, this._stropheConnectionCb.bind(this, callback), ...args);
    }
    /* eslint-enable max-params */
    /**
     * Handles {@link Strophe.Status} updates for the current connection.
     *
     * @param {function} targetCallback - The callback passed by the {@link XmppConnection} consumer to one of
     * the connect methods.
     * @param {Strophe.Status} status - The new connection status.
     * @param {*} args - The rest of the arguments passed by Strophe.
     * @private
     */
    _stropheConnectionCb(targetCallback, status, ...args) {
        var _a;
        this._status = status;
        let blockCallback = false;
        if (status === strophe_js__WEBPACK_IMPORTED_MODULE_1__.Strophe.Status.CONNECTED || status === strophe_js__WEBPACK_IMPORTED_MODULE_1__.Strophe.Status.ATTACHED) {
            this._maybeEnableStreamResume();
            // after connecting - immediately check whether shard changed,
            // we need this only when using websockets as bosh checks headers from every response
            if (this._usesWebsocket && this._oneSuccessfulConnect) {
                this._keepAliveAndCheckShard();
            }
            this._oneSuccessfulConnect = true;
            this._maybeStartWSKeepAlive();
            this._processDeferredIQs();
            this._resumeTask.cancel();
            this.ping.startInterval(((_a = this._options.pingOptions) === null || _a === void 0 ? void 0 : _a.domain) || this.domain);
        }
        else if (status === strophe_js__WEBPACK_IMPORTED_MODULE_1__.Strophe.Status.DISCONNECTED) {
            this.ping.stopInterval();
            // FIXME add RECONNECTING state instead of blocking the DISCONNECTED update
            blockCallback = this._tryResumingConnection();
            if (!blockCallback) {
                clearTimeout(this._wsKeepAlive);
            }
        }
        if (!blockCallback) {
            targetCallback(status, ...args);
            this.eventEmitter.emit(XmppConnection.Events.CONN_STATUS_CHANGED, status);
        }
    }
    /**
     * Clears the list of IQs and rejects deferred Promises with an error.
     *
     * @private
     */
    _clearDeferredIQs() {
        for (const deferred of this._deferredIQs) {
            deferred.reject(new Error('disconnect'));
        }
        this._deferredIQs = [];
    }
    /**
     * The method is meant to be used for testing. It's a shortcut for closing the WebSocket.
     *
     * @returns {void}
     */
    closeWebsocket() {
        if (this._stropheConn && this._stropheConn._proto) {
            this._stropheConn._proto._closeSocket();
            this._stropheConn._proto._onClose(null);
        }
    }
    /**
     * See {@link Strophe.Connection.disconnect}.
     *
     * @returns {void}
     */
    disconnect(...args) {
        this._resumeTask.cancel();
        clearTimeout(this._wsKeepAlive);
        this._clearDeferredIQs();
        this._stropheConn.disconnect(...args);
    }
    /**
     * See {@link Strophe.Connection.flush}.
     *
     * @returns {void}
     */
    flush(...args) {
        this._stropheConn.flush(...args);
    }
    /**
     * See {@link LastRequestTracker.getTimeSinceLastSuccess}.
     *
     * @returns {number|null}
     */
    getTimeSinceLastSuccess() {
        return this._rawInputTracker.getTimeSinceLastSuccess();
    }
    /**
     * See {@link LastRequestTracker.getLastFailedMessage}.
     *
     * @returns {string|null}
     */
    getLastFailedMessage() {
        return this._rawInputTracker.getLastFailedMessage();
    }
    /**
     * Requests a resume token from the server if enabled and all requirements are met.
     *
     * @private
     */
    _maybeEnableStreamResume() {
        if (!this._options.enableWebsocketResume) {
            return;
        }
        const { streamManagement } = this._stropheConn;
        if (!this.isUsingWebSocket) {
            logger.warn('Stream resume enabled, but WebSockets are not enabled');
        }
        else if (!streamManagement) {
            logger.warn('Stream resume enabled, but Strophe streamManagement plugin is not installed');
        }
        else if (!streamManagement.isSupported()) {
            logger.warn('Stream resume enabled, but XEP-0198 is not supported by the server');
        }
        else if (!streamManagement.getResumeToken()) {
            logger.info('Enabling XEP-0198 stream management');
            streamManagement.enable(/* resume */ true);
        }
    }
    /**
     * Starts the Websocket keep alive if enabled.
     *
     * @private
     * @returns {void}
     */
    _maybeStartWSKeepAlive() {
        const { websocketKeepAlive } = this._options;
        if (this._usesWebsocket && websocketKeepAlive > 0) {
            this._wsKeepAlive || logger.info(`WebSocket keep alive interval: ${websocketKeepAlive}ms`);
            clearTimeout(this._wsKeepAlive);
            const intervalWithJitter = /* base */ websocketKeepAlive + /* jitter */ (Math.random() * 60 * 1000);
            logger.debug(`Scheduling next WebSocket keep-alive in ${intervalWithJitter}ms`);
            this._wsKeepAlive = setTimeout(() => this._keepAliveAndCheckShard()
                .then(() => this._maybeStartWSKeepAlive()), intervalWithJitter);
        }
    }
    /**
     * Do a http GET to the shard and if shard change will throw an event.
     *
     * @private
     * @returns {Promise}
     */
    _keepAliveAndCheckShard() {
        const { shard, websocketKeepAliveUrl } = this._options;
        const url = websocketKeepAliveUrl ? websocketKeepAliveUrl
            : this.service.replace('wss://', 'https://').replace('ws://', 'http://');
        return fetch(url)
            .then(response => {
            // skips header checking if there is no info in options
            if (!shard) {
                return;
            }
            const responseShard = response.headers.get('x-jitsi-shard');
            if (responseShard !== shard) {
                logger.error(`Detected that shard changed from ${shard} to ${responseShard}`);
                this.eventEmitter.emit(XmppConnection.Events.CONN_SHARD_CHANGED);
            }
        })
            .catch(error => {
            logger.error(`Websocket Keep alive failed for url: ${url}`, { error });
        });
    }
    /**
     * Goes over the list of {@link DeferredSendIQ} tasks and sends them.
     *
     * @private
     * @returns {void}
     */
    _processDeferredIQs() {
        for (const deferred of this._deferredIQs) {
            if (deferred.iq) {
                clearTimeout(deferred.timeout);
                const timeLeft = Date.now() - deferred.start;
                this.sendIQ(deferred.iq, result => deferred.resolve(result), error => deferred.reject(error), timeLeft);
            }
        }
        this._deferredIQs = [];
    }
    /**
     * Send a stanza. This function is called to push data onto the send queue to go out over the wire.
     *
     * @param {Element|Strophe.Builder} stanza - The stanza to send.
     * @returns {void}
     */
    send(stanza) {
        var _a, _b, _c;
        if (!this.connected) {
            logger.error(`Trying to send stanza while not connected. Status:${this._status} Proto:${this.isUsingWebSocket ? (_c = (_b = (_a = this._stropheConn) === null || _a === void 0 ? void 0 : _a._proto) === null || _b === void 0 ? void 0 : _b.socket) === null || _c === void 0 ? void 0 : _c.readyState : 'bosh'}`);
            throw new Error('Not connected');
        }
        this._stropheConn.send(stanza);
    }
    /**
     * Helper function to send IQ stanzas.
     *
     * @param {Element} elem - The stanza to send.
     * @param {Function} callback - The callback function for a successful request.
     * @param {Function} errback - The callback function for a failed or timed out request.  On timeout, the stanza will
     * be null.
     * @param {number} timeout - The time specified in milliseconds for a timeout to occur.
     * @returns {number} - The id used to send the IQ.
     */
    sendIQ(elem, callback, errback, timeout) {
        if (!this.connected) {
            errback('Not connected');
            return;
        }
        return this._stropheConn.sendIQ(elem, callback, errback, timeout);
    }
    /**
     * Sends an IQ immediately if connected or puts it on the send queue otherwise(in contrary to other send methods
     * which would fail immediately if disconnected).
     *
     * @param {Element} iq - The IQ to send.
     * @param {number} timeout - How long to wait for the response. The time when the connection is reconnecting is
     * included, which means that the IQ may never be sent and still fail with a timeout.
     */
    sendIQ2(iq, { timeout }) {
        return new Promise((resolve, reject) => {
            if (this.connected) {
                this.sendIQ(iq, result => resolve(result), error => reject(error), timeout);
            }
            else {
                const deferred = {
                    iq,
                    resolve,
                    reject,
                    start: Date.now(),
                    timeout: setTimeout(() => {
                        // clears the IQ on timeout and invalidates the deferred task
                        deferred.iq = undefined;
                        // Strophe calls with undefined on timeout
                        reject(undefined);
                    }, timeout)
                };
                this._deferredIQs.push(deferred);
            }
        });
    }
    /**
     * Called by the ping plugin when ping fails too many times.
     *
     * @returns {void}
     */
    _onPingErrorThresholdExceeded() {
        if (this.isUsingWebSocket) {
            logger.warn('Ping error threshold exceeded - killing the WebSocket');
            this.closeWebsocket();
        }
    }
    /**
     *  Helper function to send presence stanzas. The main benefit is for sending presence stanzas for which you expect
     *  a responding presence stanza with the same id (for example when leaving a chat room).
     *
     * @param {Element} elem - The stanza to send.
     * @param {Function} callback - The callback function for a successful request.
     * @param {Function} errback - The callback function for a failed or timed out request. On timeout, the stanza will
     * be null.
     * @param {number} timeout - The time specified in milliseconds for a timeout to occur.
     * @returns {number} - The id used to send the presence.
     */
    sendPresence(elem, callback, errback, timeout) {
        if (!this.connected) {
            errback('Not connected');
            return;
        }
        this._stropheConn.sendPresence(elem, callback, errback, timeout);
    }
    /**
     * The method gracefully closes the BOSH connection by using 'navigator.sendBeacon'.
     *
     * @returns {boolean} - true if the beacon was sent.
     */
    sendUnavailableBeacon() {
        if (!navigator.sendBeacon || this._stropheConn.disconnecting || !this._stropheConn.connected) {
            return false;
        }
        this._stropheConn._changeConnectStatus(strophe_js__WEBPACK_IMPORTED_MODULE_1__.Strophe.Status.DISCONNECTING);
        this._stropheConn.disconnecting = true;
        const body = this._stropheConn._proto._buildBody()
            .attrs({
            type: 'terminate'
        });
        const pres = (0,strophe_js__WEBPACK_IMPORTED_MODULE_1__.$pres)({
            xmlns: strophe_js__WEBPACK_IMPORTED_MODULE_1__.Strophe.NS.CLIENT,
            type: 'unavailable'
        });
        body.cnode(pres.tree());
        const res = navigator.sendBeacon(this.service.indexOf('https://') === -1 ? `https:${this.service}` : this.service, strophe_js__WEBPACK_IMPORTED_MODULE_1__.Strophe.serialize(body.tree()));
        logger.info(`Successfully send unavailable beacon ${res}`);
        this._stropheConn._proto._abortAllRequests();
        this._stropheConn._doDisconnect();
        return true;
    }
    /**
     * Tries to use stream management plugin to resume dropped XMPP connection. The streamManagement plugin clears
     * the resume token if any connection error occurs which would put it in unrecoverable state, so as long as
     * the token is present it means the connection can be resumed.
     *
     * @private
     * @returns {boolean}
     */
    _tryResumingConnection() {
        const { streamManagement } = this._stropheConn;
        const resumeToken = streamManagement && streamManagement.getResumeToken();
        if (resumeToken) {
            this._resumeTask.schedule();
            return true;
        }
        return false;
    }
}
//# sourceMappingURL=XmppConnection.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/xmpp/moderator.js":
/*!*******************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/xmpp/moderator.js ***!
  \*******************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
var __filename = "/index.js";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (/* binding */ Moderator)
/* harmony export */ });
/* harmony import */ var _jitsi_logger__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @jitsi/logger */ "./node_modules/@jitsi/logger/lib/index.js");
/* harmony import */ var _jitsi_logger__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(_jitsi_logger__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var jquery__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! jquery */ "./node_modules/jquery/dist/jquery.js");
/* harmony import */ var jquery__WEBPACK_IMPORTED_MODULE_1___default = /*#__PURE__*/__webpack_require__.n(jquery__WEBPACK_IMPORTED_MODULE_1__);
/* harmony import */ var strophe_js__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! strophe.js */ "./node_modules/strophe.js/dist/strophe.umd.js");
/* harmony import */ var strophe_js__WEBPACK_IMPORTED_MODULE_2___default = /*#__PURE__*/__webpack_require__.n(strophe_js__WEBPACK_IMPORTED_MODULE_2__);
/* harmony import */ var _flags_FeatureFlags__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../flags/FeatureFlags */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/flags/FeatureFlags.js");
/* harmony import */ var _settings_Settings__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../settings/Settings */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/settings/Settings.js");
/* eslint-disable newline-per-chained-call */





const AuthenticationEvents = __webpack_require__(/*! ../../service/authentication/AuthenticationEvents */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/authentication/AuthenticationEvents.js");
const { XMPPEvents } = __webpack_require__(/*! ../../service/xmpp/XMPPEvents */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/xmpp/XMPPEvents.js");
const GlobalOnErrorHandler = __webpack_require__(/*! ../util/GlobalOnErrorHandler */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/util/GlobalOnErrorHandler.js");
const logger = (0,_jitsi_logger__WEBPACK_IMPORTED_MODULE_0__.getLogger)(__filename);
/**
 *
 * @param step
 */
function createExpBackoffTimer(step) {
    let count = 1;
    const maxTimeout = 120000;
    return function (reset) {
        // Reset call
        if (reset) {
            count = 1;
            return;
        }
        // Calculate next timeout
        const timeout = Math.pow(2, count - 1);
        count += 1;
        return Math.min(timeout * step, maxTimeout);
    };
}
/**
 *
 * @param roomName
 * @param xmpp
 * @param emitter
 * @param options
 */
function Moderator(roomName, xmpp, emitter, options) {
    var _a, _b;
    this.roomName = roomName;
    this.getNextTimeout = createExpBackoffTimer(1000);
    this.getNextErrorTimeout = createExpBackoffTimer(1000);
    this.options = options;
    // External authentication stuff
    this.externalAuthEnabled = false;
    // Whether SIP gateway (jigasi) support is enabled. TODO: use presence so it can be changed based on jigasi
    // availability.
    this.sipGatewayEnabled = false;
    this.eventEmitter = emitter;
    this.connection = xmpp.connection;
    // The JID to which conference-iq requests are sent over XMPP.
    this.targetJid = (_a = this.options.hosts) === null || _a === void 0 ? void 0 : _a.focus;
    // If not specified default to 'focus.domain'
    if (!this.targetJid) {
        this.targetJid = `focus.${(_b = this.options.hosts) === null || _b === void 0 ? void 0 : _b.domain}`;
    }
    this.targetUrl = this.options.conferenceRequestUrl;
    // Whether to send conference requests over HTTP or XMPP
    this.mode = this.targetUrl ? 'http' : 'xmpp';
    logger.info(`Using ${this.mode} for conference requests.`);
    // The set of JIDs known to belong to jicofo. Populated from configuration
    // and responses from conference requests.
    this.focusUserJids = new Set();
    if (options.focusUserJid) {
        this.focusUserJids.add(options.focusUserJid);
    }
    // FIXME: Message listener that talks to POPUP window
    /**
     *
     * @param event
     */
    function listener(event) {
        if (event.data && event.data.sessionId) {
            if (event.origin !== window.location.origin) {
                logger.warn(`Ignoring sessionId from different origin: ${event.origin}`);
                return;
            }
            _settings_Settings__WEBPACK_IMPORTED_MODULE_4__["default"].sessionId = event.data.sessionId;
            // After popup is closed we will authenticate
        }
    }
    // Register
    if (window.addEventListener) {
        window.addEventListener('message', listener, false);
    }
    else {
        window.attachEvent('onmessage', listener);
    }
}
Moderator.prototype.isFocusJid = function (jid) {
    if (!jid) {
        return false;
    }
    for (const focusJid of this.focusUserJids) {
        // jid may be a full JID, and focusUserJids may be bare JIDs
        if (jid.indexOf(`${focusJid}/`) === 0) {
            return true;
        }
    }
    return false;
};
Moderator.prototype.isExternalAuthEnabled = function () {
    return this.externalAuthEnabled;
};
Moderator.prototype.isSipGatewayEnabled = function () {
    return this.sipGatewayEnabled;
};
/**
 * Create a conference request based on the configured options and saved Settings.
 *
 * A conference request has the following format:
 * {
 *   room: "room@example.com",
 *   sessionId: "foo", // optional
 *   machineUdi: "bar", // optional
 *   identity: "baz", // optional
 *   properties: { } // map string to string
 * }
 *
 * It can be encoded in either JSON or and IQ.
 *
 * @returns the created conference request.
 */
Moderator.prototype._createConferenceRequest = function () {
    var _a, _b;
    // Session Id used for authentication
    const { sessionId } = _settings_Settings__WEBPACK_IMPORTED_MODULE_4__["default"];
    const config = this.options;
    const properties = {};
    if (config.startAudioMuted !== undefined) {
        properties.startAudioMuted = config.startAudioMuted;
    }
    if (config.startVideoMuted !== undefined) {
        properties.startVideoMuted = config.startVideoMuted;
    }
    // this flag determines whether the bridge will include this call in its
    // rtcstats reporting or not. If the site admin hasn't set the flag in
    // config.js, then the client defaults to false (see
    // react/features/rtcstats/functions.js in jitsi-meet). The server-side
    // components default to true to match the pre-existing behavior so we only
    // signal if false.
    const rtcstatsEnabled = (_b = (_a = config === null || config === void 0 ? void 0 : config.analytics) === null || _a === void 0 ? void 0 : _a.rtcstatsEnabled) !== null && _b !== void 0 ? _b : false;
    if (!rtcstatsEnabled) {
        properties.rtcstatsEnabled = false;
    }
    const conferenceRequest = {
        properties,
        machineUid: _settings_Settings__WEBPACK_IMPORTED_MODULE_4__["default"].machineId,
        room: this.roomName
    };
    if (sessionId) {
        conferenceRequest.sessionId = sessionId;
    }
    return conferenceRequest;
};
/**
 * Create a conference request and encode it as an IQ.
 */
Moderator.prototype._createConferenceIq = function () {
    const conferenceRequest = this._createConferenceRequest();
    // Generate create conference IQ
    const elem = (0,strophe_js__WEBPACK_IMPORTED_MODULE_2__.$iq)({ to: this.targetJid,
        type: 'set' });
    elem.c('conference', {
        xmlns: 'http://jitsi.org/protocol/focus',
        room: this.roomName,
        'machine-uid': conferenceRequest.machineUid
    });
    if (conferenceRequest.sessionId) {
        elem.attrs({ 'session-id': conferenceRequest.sessionId });
    }
    for (const k in conferenceRequest.properties) {
        if (conferenceRequest.properties.hasOwnProperty(k)) {
            elem.c('property', {
                name: k,
                value: conferenceRequest.properties[k]
            }).up();
        }
    }
    if (_flags_FeatureFlags__WEBPACK_IMPORTED_MODULE_3__["default"].isJoinAsVisitorSupported()) {
        elem.c('property', {
            name: 'visitors-version',
            value: 1
        }).up();
    }
    return elem;
};
Moderator.prototype._parseConferenceIq = function (resultIq) {
    const conferenceRequest = { properties: {} };
    conferenceRequest.focusJid = jquery__WEBPACK_IMPORTED_MODULE_1___default()(resultIq).find('conference').attr('focusjid');
    conferenceRequest.sessionId = jquery__WEBPACK_IMPORTED_MODULE_1___default()(resultIq).find('conference').attr('session-id');
    conferenceRequest.identity = jquery__WEBPACK_IMPORTED_MODULE_1___default()(resultIq).find('>conference').attr('identity');
    conferenceRequest.ready = jquery__WEBPACK_IMPORTED_MODULE_1___default()(resultIq).find('conference').attr('ready') === 'true';
    conferenceRequest.vnode = jquery__WEBPACK_IMPORTED_MODULE_1___default()(resultIq).find('conference').attr('vnode');
    if (jquery__WEBPACK_IMPORTED_MODULE_1___default()(resultIq).find('>conference>property[name=\'authentication\'][value=\'true\']').length > 0) {
        conferenceRequest.properties.authentication = 'true';
    }
    if (jquery__WEBPACK_IMPORTED_MODULE_1___default()(resultIq).find('>conference>property[name=\'externalAuth\'][value=\'true\']').length > 0) {
        conferenceRequest.properties.externalAuth = 'true';
    }
    // Check if jicofo has jigasi support enabled.
    if (jquery__WEBPACK_IMPORTED_MODULE_1___default()(resultIq).find('>conference>property[name=\'sipGatewayEnabled\'][value=\'true\']').length > 0) {
        conferenceRequest.properties.sipGatewayEnabled = 'true';
    }
    return conferenceRequest;
};
// FIXME We need to show the fact that we're waiting for the focus to the user
// (or that the focus is not available)
/**
 * Allocates the conference focus.
 *
 * @param {Function} callback - the function to be called back upon the
 * successful allocation of the conference focus
 * @returns {Promise} - Resolved when Jicofo allows to join the room. It's never
 * rejected and it'll keep on pinging Jicofo forever.
 */
Moderator.prototype.sendConferenceRequest = function () {
    return new Promise(resolve => {
        if (this.mode === 'xmpp') {
            logger.info(`Sending conference request over XMPP to ${this.targetJid}`);
            this.connection.sendIQ(this._createConferenceIq(), result => this._handleIqSuccess(result, resolve), error => this._handleIqError(error, resolve));
            // XXX We're pressed for time here because we're beginning a complex
            // and/or lengthy conference-establishment process which supposedly
            // involves multiple RTTs. We don't have the time to wait for Strophe to
            // decide to send our IQ.
            this.connection.flush();
        }
        else {
            logger.info(`Sending conference request over HTTP to ${this.targetUrl}`);
            fetch(this.targetUrl, {
                method: 'POST',
                body: JSON.stringify(this._createConferenceRequest()),
                headers: { 'Content-Type': 'application/json' }
            })
                .then(response => {
                if (!response.ok) {
                    response.text().then(text => {
                        logger.warn(`Received HTTP ${response.status} ${response.statusText}. Body: ${text}`);
                        const sessionError = response.status === 400 && text.indexOf('400 invalid-session') > 0;
                        const notAuthorized = response.status === 403;
                        this._handleError(sessionError, notAuthorized, resolve);
                    })
                        .catch(error => {
                        logger.warn(`Error: ${error}`);
                        this._handleError();
                    });
                    // _handleError has either scheduled a retry or fired an event indicating failure.
                    return;
                }
                response.json().then(resultJson => {
                    this._handleSuccess(resultJson, resolve);
                });
            })
                .catch(error => {
                logger.warn(`Error: ${error}`);
                this._handleError();
            });
        }
    });
};
Moderator.prototype._handleSuccess = function (conferenceRequest, callback) {
    // Reset the error timeout (because we haven't failed here).
    this.getNextErrorTimeout(true);
    if (conferenceRequest.focusJid) {
        logger.info(`Adding focus JID: ${conferenceRequest.focusJid}`);
        this.focusUserJids.add(conferenceRequest.focusJid);
    }
    else {
        logger.warn('Conference request response contained no focusJid.');
    }
    const authenticationEnabled = conferenceRequest.properties.authentication === 'true';
    logger.info(`Authentication enabled: ${authenticationEnabled}`);
    this.externalAuthEnabled = conferenceRequest.properties.externalAuth === 'true';
    logger.info(`External authentication enabled: ${this.externalAuthEnabled}`);
    if (!this.externalAuthEnabled && conferenceRequest.sessionId) {
        logger.info(`Received sessionId: ${conferenceRequest.sessionId}`);
        _settings_Settings__WEBPACK_IMPORTED_MODULE_4__["default"].sessionId = conferenceRequest.sessionId;
    }
    this.eventEmitter.emit(AuthenticationEvents.IDENTITY_UPDATED, authenticationEnabled, conferenceRequest.identity);
    this.sipGatewayEnabled = conferenceRequest.properties.sipGatewayEnabled;
    logger.info(`Sip gateway enabled: ${this.sipGatewayEnabled}`);
    if (conferenceRequest.ready) {
        // Reset the non-error timeout (because we've succeeded here).
        this.getNextTimeout(true);
        // we want to ignore redirects when this is jibri (record/live-stream or a sip jibri)
        if (conferenceRequest.vnode && !this.options.iAmRecorder && !this.options.iAmSipGateway) {
            logger.warn(`Redirected to: ${conferenceRequest.vnode} with focusJid ${conferenceRequest.focusJid} }`);
            this.eventEmitter.emit(XMPPEvents.REDIRECTED, conferenceRequest.vnode, conferenceRequest.focusJid);
            return;
        }
        logger.info('Conference-request successful, ready to join the MUC.');
        callback();
    }
    else {
        const waitMs = this.getNextTimeout();
        // This was a successful response, but the "ready" flag is not set. Retry after a timeout.
        logger.info(`Not ready yet, will retry in ${waitMs} ms.`);
        window.setTimeout(() => this.sendConferenceRequest().then(callback), waitMs);
    }
};
Moderator.prototype._handleError = function (sessionError, notAuthorized, callback) {
    // If the session is invalid, remove and try again without session ID to get
    // a new one
    if (sessionError) {
        logger.info('Session expired! - removing');
        _settings_Settings__WEBPACK_IMPORTED_MODULE_4__["default"].sessionId = undefined;
    }
    // Not authorized to create new room
    if (notAuthorized) {
        logger.warn('Unauthorized to start the conference');
        this.eventEmitter.emit(XMPPEvents.AUTHENTICATION_REQUIRED);
        return;
    }
    const waitMs = this.getNextErrorTimeout();
    if (sessionError && waitMs < 60000) {
        // If the session is invalid, retry a limited number of times and then fire an error.
        logger.info(`Invalid session, will retry after ${waitMs} ms.`);
        this.getNextTimeout(true);
        window.setTimeout(() => this.sendConferenceRequest().then(callback), waitMs);
    }
    else {
        const errmsg = 'Failed to get a successful response, giving up.';
        const error = new Error(errmsg);
        logger.error(errmsg, error);
        GlobalOnErrorHandler.callErrorHandler(error);
        // This is a "fatal" error and the user of the lib should handle it accordingly.
        // TODO: change the event name to something accurate.
        this.eventEmitter.emit(XMPPEvents.FOCUS_DISCONNECTED);
    }
};
/**
 * Invoked by {@link #sendConferenecRequest} upon its request receiving an
 * error result.
 *
 * @param error - the error result of the request that {@link sendConferenceRequest} sent
 * @param {Function} callback - the function to be called back upon the
 * successful allocation of the conference focus
 */
Moderator.prototype._handleIqError = function (error, callback) {
    // The reservation system only works over XMPP. Handle the error separately.
    // Check for error returned by the reservation system
    const reservationErr = jquery__WEBPACK_IMPORTED_MODULE_1___default()(error).find('>error>reservation-error');
    if (reservationErr.length) {
        // Trigger error event
        const errorCode = reservationErr.attr('error-code');
        const errorTextNode = jquery__WEBPACK_IMPORTED_MODULE_1___default()(error).find('>error>text');
        let errorMsg;
        if (errorTextNode) {
            errorMsg = errorTextNode.text();
        }
        this.eventEmitter.emit(XMPPEvents.RESERVATION_ERROR, errorCode, errorMsg);
        return;
    }
    const invalidSession = Boolean(jquery__WEBPACK_IMPORTED_MODULE_1___default()(error).find('>error>session-invalid').length
        || jquery__WEBPACK_IMPORTED_MODULE_1___default()(error).find('>error>not-acceptable').length);
    // Not authorized to create new room
    const notAuthorized = jquery__WEBPACK_IMPORTED_MODULE_1___default()(error).find('>error>not-authorized').length > 0;
    if (notAuthorized && strophe_js__WEBPACK_IMPORTED_MODULE_2__.Strophe.getDomainFromJid(error.getAttribute('to')) !== this.options.hosts.anonymousdomain) {
        // FIXME "is external" should come either from the focus or
        // config.js
        this.externalAuthEnabled = true;
    }
    this._handleError(invalidSession, notAuthorized, callback);
};
/**
 * Invoked by {@link #sendConferenecRequest} upon its request receiving a
 * success (i.e. non-error) result.
 *
 * @param result - the success (i.e. non-error) result of the request that {@link #sendConferenecRequest} sent
 * @param {Function} callback - the function to be called back upon the
 * successful allocation of the conference focus
 */
Moderator.prototype._handleIqSuccess = function (result, callback) {
    // Setup config options
    const conferenceRequest = this._parseConferenceIq(result);
    this._handleSuccess(conferenceRequest, callback);
};
Moderator.prototype.authenticate = function () {
    return new Promise((resolve, reject) => {
        this.connection.sendIQ(this._createConferenceIq(), result => {
            const sessionId = jquery__WEBPACK_IMPORTED_MODULE_1___default()(result).find('conference').attr('session-id');
            if (sessionId) {
                logger.info(`Received sessionId:  ${sessionId}`);
                _settings_Settings__WEBPACK_IMPORTED_MODULE_4__["default"].sessionId = sessionId;
            }
            else {
                logger.warn('Response did not contain a session-id');
            }
            resolve();
        }, errorIq => reject({
            error: jquery__WEBPACK_IMPORTED_MODULE_1___default()(errorIq).find('iq>error :first').prop('tagName'),
            message: jquery__WEBPACK_IMPORTED_MODULE_1___default()(errorIq).find('iq>error>text').text()
        }));
    });
};
Moderator.prototype.getLoginUrl = function (urlCallback, failureCallback) {
    this._getLoginUrl(/* popup */ false, urlCallback, failureCallback);
};
/**
 *
 * @param {boolean} popup false for {@link Moderator#getLoginUrl} or true for
 * {@link Moderator#getPopupLoginUrl}
 * @param urlCb
 * @param failureCb
 */
Moderator.prototype._getLoginUrl = function (popup, urlCb, failureCb) {
    const iq = (0,strophe_js__WEBPACK_IMPORTED_MODULE_2__.$iq)({ to: this.targetJid,
        type: 'get' });
    const attrs = {
        xmlns: 'http://jitsi.org/protocol/focus',
        room: this.roomName,
        'machine-uid': _settings_Settings__WEBPACK_IMPORTED_MODULE_4__["default"].machineId
    };
    let str = 'auth url'; // for logger
    if (popup) {
        attrs.popup = true;
        str = `POPUP ${str}`;
    }
    iq.c('login-url', attrs);
    /**
     * Implements a failure callback which reports an error message and an error
     * through (1) GlobalOnErrorHandler, (2) logger, and (3) failureCb.
     *
     * @param {string} errmsg the error messsage to report
     * @param {*} error the error to report (in addition to errmsg)
     */
    function reportError(errmsg, err) {
        GlobalOnErrorHandler.callErrorHandler(new Error(errmsg));
        logger.error(errmsg, err);
        failureCb(err);
    }
    this.connection.sendIQ(iq, result => {
        let url = jquery__WEBPACK_IMPORTED_MODULE_1___default()(result).find('login-url').attr('url');
        url = decodeURIComponent(url);
        if (url) {
            logger.info(`Got ${str}: ${url}`);
            urlCb(url);
        }
        else {
            reportError(`Failed to get ${str} from the focus`, result);
        }
    }, reportError.bind(undefined, `Get ${str} error`));
};
Moderator.prototype.getPopupLoginUrl = function (urlCallback, failureCallback) {
    this._getLoginUrl(/* popup */ true, urlCallback, failureCallback);
};
Moderator.prototype.logout = function (callback) {
    const iq = (0,strophe_js__WEBPACK_IMPORTED_MODULE_2__.$iq)({ to: this.targetJid,
        type: 'set' });
    const { sessionId } = _settings_Settings__WEBPACK_IMPORTED_MODULE_4__["default"];
    if (!sessionId) {
        callback();
        return;
    }
    iq.c('logout', {
        xmlns: 'http://jitsi.org/protocol/focus',
        'session-id': sessionId
    });
    this.connection.sendIQ(iq, result => {
        let logoutUrl = jquery__WEBPACK_IMPORTED_MODULE_1___default()(result).find('logout').attr('logout-url');
        if (logoutUrl) {
            logoutUrl = decodeURIComponent(logoutUrl);
        }
        logger.info(`Log out OK, url: ${logoutUrl}`, result);
        _settings_Settings__WEBPACK_IMPORTED_MODULE_4__["default"].sessionId = undefined;
        callback(logoutUrl);
    }, error => {
        const errmsg = 'Logout error';
        GlobalOnErrorHandler.callErrorHandler(new Error(errmsg));
        logger.error(errmsg, error);
    });
};
//# sourceMappingURL=moderator.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/xmpp/sha1.js":
/*!**************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/xmpp/sha1.js ***!
  \**************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (/* binding */ SHA1)
/* harmony export */ });
/* eslint-disable */
/*
 * A JavaScript implementation of the Secure Hash Algorithm, SHA-1, as defined
 * in FIPS PUB 180-1
 * Version 2.1a Copyright Paul Johnston 2000 - 2002.
 * Other contributors: Greg Holt, Andrew Kepert, Ydnar, Lostinet
 * Distributed under the BSD License
 * See http://pajhome.org.uk/crypt/md5 for details.
 */
/* global define */
/* Some functions and variables have been stripped for use with Strophe */
/*
 * Calculate the SHA-1 of an array of big-endian words, and a bit length
 */
function core_sha1(x, len) {
    /* append padding */
    x[len >> 5] |= 0x80 << (24 - len % 32);
    x[((len + 64 >> 9) << 4) + 15] = len;
    var w = new Array(80);
    var a = 1732584193;
    var b = -271733879;
    var c = -1732584194;
    var d = 271733878;
    var e = -1009589776;
    var i, j, t, olda, oldb, oldc, oldd, olde;
    for (i = 0; i < x.length; i += 16) {
        olda = a;
        oldb = b;
        oldc = c;
        oldd = d;
        olde = e;
        for (j = 0; j < 80; j++) {
            if (j < 16) {
                w[j] = x[i + j];
            }
            else {
                w[j] = rol(w[j - 3] ^ w[j - 8] ^ w[j - 14] ^ w[j - 16], 1);
            }
            t = safe_add(safe_add(rol(a, 5), sha1_ft(j, b, c, d)), safe_add(safe_add(e, w[j]), sha1_kt(j)));
            e = d;
            d = c;
            c = rol(b, 30);
            b = a;
            a = t;
        }
        a = safe_add(a, olda);
        b = safe_add(b, oldb);
        c = safe_add(c, oldc);
        d = safe_add(d, oldd);
        e = safe_add(e, olde);
    }
    return [a, b, c, d, e];
}
/*
 * Perform the appropriate triplet combination function for the current
 * iteration
 */
function sha1_ft(t, b, c, d) {
    if (t < 20) {
        return (b & c) | ((~b) & d);
    }
    if (t < 40) {
        return b ^ c ^ d;
    }
    if (t < 60) {
        return (b & c) | (b & d) | (c & d);
    }
    return b ^ c ^ d;
}
/*
 * Determine the appropriate additive constant for the current iteration
 */
function sha1_kt(t) {
    return (t < 20) ? 1518500249 : (t < 40) ? 1859775393 : (t < 60) ? -1894007588 : -899497514;
}
/*
 * Calculate the HMAC-SHA1 of a key and some data
 */
function core_hmac_sha1(key, data) {
    var bkey = str2binb(key);
    if (bkey.length > 16) {
        bkey = core_sha1(bkey, key.length * 8);
    }
    var ipad = new Array(16), opad = new Array(16);
    for (var i = 0; i < 16; i++) {
        ipad[i] = bkey[i] ^ 0x36363636;
        opad[i] = bkey[i] ^ 0x5C5C5C5C;
    }
    var hash = core_sha1(ipad.concat(str2binb(data)), 512 + data.length * 8);
    return core_sha1(opad.concat(hash), 512 + 160);
}
/*
 * Add integers, wrapping at 2^32. This uses 16-bit operations internally
 * to work around bugs in some JS interpreters.
 */
function safe_add(x, y) {
    var lsw = (x & 0xFFFF) + (y & 0xFFFF);
    var msw = (x >> 16) + (y >> 16) + (lsw >> 16);
    return (msw << 16) | (lsw & 0xFFFF);
}
/*
 * Bitwise rotate a 32-bit number to the left.
 */
function rol(num, cnt) {
    return (num << cnt) | (num >>> (32 - cnt));
}
/*
 * Convert an 8-bit or 16-bit string to an array of big-endian words
 * In 8-bit function, characters >255 have their hi-byte silently ignored.
 */
function str2binb(str) {
    var bin = [];
    var mask = 255;
    for (var i = 0; i < str.length * 8; i += 8) {
        bin[i >> 5] |= (str.charCodeAt(i / 8) & mask) << (24 - i % 32);
    }
    return bin;
}
/*
 * Convert an array of big-endian words to a base-64 string
 */
function binb2b64(binarray) {
    var tab = "ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/";
    var str = "";
    var triplet, j;
    for (var i = 0; i < binarray.length * 4; i += 3) {
        triplet = (((binarray[i >> 2] >> 8 * (3 - i % 4)) & 0xFF) << 16) |
            (((binarray[i + 1 >> 2] >> 8 * (3 - (i + 1) % 4)) & 0xFF) << 8) |
            ((binarray[i + 2 >> 2] >> 8 * (3 - (i + 2) % 4)) & 0xFF);
        for (j = 0; j < 4; j++) {
            if (i * 8 + j * 6 > binarray.length * 32) {
                str += "=";
            }
            else {
                str += tab.charAt((triplet >> 6 * (3 - j)) & 0x3F);
            }
        }
    }
    return str;
}
/*
 * Convert an array of big-endian words to a string
 */
function binb2str(bin) {
    var str = "";
    var mask = 255;
    for (var i = 0; i < bin.length * 32; i += 8) {
        str += String.fromCharCode((bin[i >> 5] >>> (24 - i % 32)) & mask);
    }
    return str;
}
/*
 * These are the functions you'll usually want to call
 * They take string arguments and return either hex or base-64 encoded strings
 */
const SHA1 = {
    b64_hmac_sha1: function (key, data) { return binb2b64(core_hmac_sha1(key, data)); },
    b64_sha1: function (s) { return binb2b64(core_sha1(str2binb(s), s.length * 8)); },
    binb2str: binb2str,
    core_hmac_sha1: core_hmac_sha1,
    str_hmac_sha1: function (key, data) { return binb2str(core_hmac_sha1(key, data)); },
    str_sha1: function (s) { return binb2str(core_sha1(str2binb(s), s.length * 8)); },
};

//# sourceMappingURL=sha1.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/xmpp/strophe.emuc.js":
/*!**********************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/xmpp/strophe.emuc.js ***!
  \**********************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
var __filename = "/index.js";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (/* binding */ MucConnectionPlugin)
/* harmony export */ });
/* harmony import */ var _jitsi_logger__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @jitsi/logger */ "./node_modules/@jitsi/logger/lib/index.js");
/* harmony import */ var _jitsi_logger__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(_jitsi_logger__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var jquery__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! jquery */ "./node_modules/jquery/dist/jquery.js");
/* harmony import */ var jquery__WEBPACK_IMPORTED_MODULE_1___default = /*#__PURE__*/__webpack_require__.n(jquery__WEBPACK_IMPORTED_MODULE_1__);
/* harmony import */ var strophe_js__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! strophe.js */ "./node_modules/strophe.js/dist/strophe.umd.js");
/* harmony import */ var strophe_js__WEBPACK_IMPORTED_MODULE_2___default = /*#__PURE__*/__webpack_require__.n(strophe_js__WEBPACK_IMPORTED_MODULE_2__);
/* harmony import */ var _service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../service/xmpp/XMPPEvents */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/xmpp/XMPPEvents.js");
/* harmony import */ var _ChatRoom__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./ChatRoom */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/xmpp/ChatRoom.js");
/* harmony import */ var _ConnectionPlugin__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./ConnectionPlugin */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/xmpp/ConnectionPlugin.js");






const logger = (0,_jitsi_logger__WEBPACK_IMPORTED_MODULE_0__.getLogger)(__filename);
/**
 * MUC connection plugin.
 */
class MucConnectionPlugin extends _ConnectionPlugin__WEBPACK_IMPORTED_MODULE_5__.ConnectionPluginListenable {
    /**
     *
     * @param xmpp
     */
    constructor(xmpp) {
        super();
        this.xmpp = xmpp;
        this.rooms = {};
    }
    /**
     *
     * @param connection
     */
    init(connection) {
        super.init(connection);
        // add handlers (just once)
        this.connection.addHandler(this.onPresence.bind(this), null, 'presence', null, null, null, null);
        this.connection.addHandler(this.onPresenceUnavailable.bind(this), null, 'presence', 'unavailable', null);
        this.connection.addHandler(this.onPresenceError.bind(this), null, 'presence', 'error', null);
        this.connection.addHandler(this.onMessage.bind(this), null, 'message', null, null);
        this.connection.addHandler(this.onMute.bind(this), 'http://jitsi.org/jitmeet/audio', 'iq', 'set', null, null);
        this.connection.addHandler(this.onMuteVideo.bind(this), 'http://jitsi.org/jitmeet/video', 'iq', 'set', null, null);
        this.connection.addHandler(this.onVisitors.bind(this), 'jitsi:visitors', 'iq', 'set', null, null);
    }
    /**
     *
     * @param jid
     * @param password
     * @param options
     */
    createRoom(jid, password, options) {
        const roomJid = strophe_js__WEBPACK_IMPORTED_MODULE_2__.Strophe.getBareJidFromJid(jid);
        if (this.isRoomCreated(roomJid)) {
            const errmsg = 'You are already in the room!';
            logger.error(errmsg);
            throw new Error(errmsg);
        }
        this.rooms[roomJid] = new _ChatRoom__WEBPACK_IMPORTED_MODULE_4__["default"](this.connection, jid, password, this.xmpp, options);
        this.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_3__.XMPPEvents.EMUC_ROOM_ADDED, this.rooms[roomJid]);
        return this.rooms[roomJid];
    }
    /**
     *  Check if a room with the passed JID is already created.
     *
     * @param {string} roomJid - The JID of the room.
     * @returns {boolean}
     */
    isRoomCreated(roomJid) {
        return roomJid in this.rooms;
    }
    /**
     *
     * @param jid
     */
    doLeave(jid) {
        this.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_3__.XMPPEvents.EMUC_ROOM_REMOVED, this.rooms[jid]);
        delete this.rooms[jid];
    }
    /**
     *
     * @param pres
     */
    onPresence(pres) {
        const from = pres.getAttribute('from');
        // What is this for? A workaround for something?
        if (pres.getAttribute('type')) {
            return true;
        }
        const room = this.rooms[strophe_js__WEBPACK_IMPORTED_MODULE_2__.Strophe.getBareJidFromJid(from)];
        if (!room) {
            return true;
        }
        // Parse status.
        if (jquery__WEBPACK_IMPORTED_MODULE_1___default()(pres).find('>x[xmlns="http://jabber.org/protocol/muc#user"]'
            + '>status[code="201"]').length) {
            room.createNonAnonymousRoom();
        }
        room.onPresence(pres);
        return true;
    }
    /**
     *
     * @param pres
     */
    onPresenceUnavailable(pres) {
        const from = pres.getAttribute('from');
        const room = this.rooms[strophe_js__WEBPACK_IMPORTED_MODULE_2__.Strophe.getBareJidFromJid(from)];
        if (!room) {
            return true;
        }
        room.onPresenceUnavailable(pres, from);
        return true;
    }
    /**
     *
     * @param pres
     */
    onPresenceError(pres) {
        const from = pres.getAttribute('from');
        const room = this.rooms[strophe_js__WEBPACK_IMPORTED_MODULE_2__.Strophe.getBareJidFromJid(from)];
        if (!room) {
            return true;
        }
        room.onPresenceError(pres, from);
        return true;
    }
    /**
     *
     * @param msg
     */
    onMessage(msg) {
        // FIXME: this is a hack. but jingle on muc makes nickchanges hard
        const from = msg.getAttribute('from');
        const room = this.rooms[strophe_js__WEBPACK_IMPORTED_MODULE_2__.Strophe.getBareJidFromJid(from)];
        if (!room) {
            return true;
        }
        room.onMessage(msg, from);
        return true;
    }
    /**
     * TODO: Document
     * @param iq
     */
    onMute(iq) {
        const from = iq.getAttribute('from');
        const room = this.rooms[strophe_js__WEBPACK_IMPORTED_MODULE_2__.Strophe.getBareJidFromJid(from)];
        // Returning false would result in the listener being deregistered by Strophe
        if (!room) {
            return true;
        }
        room.onMute(iq);
        return true;
    }
    /**
     * TODO: Document
     * @param iq
     */
    onMuteVideo(iq) {
        const from = iq.getAttribute('from');
        const room = this.rooms[strophe_js__WEBPACK_IMPORTED_MODULE_2__.Strophe.getBareJidFromJid(from)];
        // Returning false would result in the listener being deregistered by Strophe
        if (!room) {
            return true;
        }
        room.onMuteVideo(iq);
        return true;
    }
    /**
     * A visitor IQ is received, pass it to the room.
     * @param iq The received iq.
     * @returns {boolean}
     */
    onVisitors(iq) {
        const from = iq.getAttribute('from');
        const room = this.rooms[strophe_js__WEBPACK_IMPORTED_MODULE_2__.Strophe.getBareJidFromJid(from)];
        room === null || room === void 0 ? void 0 : room.onVisitorIQ(iq);
        return true;
    }
}
//# sourceMappingURL=strophe.emuc.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/xmpp/strophe.jingle.js":
/*!************************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/xmpp/strophe.jingle.js ***!
  \************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
var __filename = "/index.js";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (/* binding */ JingleConnectionPlugin)
/* harmony export */ });
/* harmony import */ var _jitsi_logger__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @jitsi/logger */ "./node_modules/@jitsi/logger/lib/index.js");
/* harmony import */ var _jitsi_logger__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(_jitsi_logger__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var jquery__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! jquery */ "./node_modules/jquery/dist/jquery.js");
/* harmony import */ var jquery__WEBPACK_IMPORTED_MODULE_1___default = /*#__PURE__*/__webpack_require__.n(jquery__WEBPACK_IMPORTED_MODULE_1__);
/* harmony import */ var strophe_js__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! strophe.js */ "./node_modules/strophe.js/dist/strophe.umd.js");
/* harmony import */ var strophe_js__WEBPACK_IMPORTED_MODULE_2___default = /*#__PURE__*/__webpack_require__.n(strophe_js__WEBPACK_IMPORTED_MODULE_2__);
/* harmony import */ var _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../service/RTC/MediaType */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/RTC/MediaType.js");
/* harmony import */ var _service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../../service/statistics/AnalyticsEvents */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/statistics/AnalyticsEvents.js");
/* harmony import */ var _service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../../service/xmpp/XMPPEvents */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/xmpp/XMPPEvents.js");
/* harmony import */ var _statistics_statistics__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../statistics/statistics */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/statistics/statistics.js");
/* harmony import */ var _util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../util/GlobalOnErrorHandler */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/util/GlobalOnErrorHandler.js");
/* harmony import */ var _util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_7___default = /*#__PURE__*/__webpack_require__.n(_util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_7__);
/* harmony import */ var _util_RandomUtil__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ../util/RandomUtil */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/util/RandomUtil.js");
/* harmony import */ var _util_RandomUtil__WEBPACK_IMPORTED_MODULE_8___default = /*#__PURE__*/__webpack_require__.n(_util_RandomUtil__WEBPACK_IMPORTED_MODULE_8__);
/* harmony import */ var _ConnectionPlugin__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ./ConnectionPlugin */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/xmpp/ConnectionPlugin.js");
/* harmony import */ var _JingleHelperFunctions__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ./JingleHelperFunctions */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/xmpp/JingleHelperFunctions.js");
/* harmony import */ var _JingleSessionPC__WEBPACK_IMPORTED_MODULE_11__ = __webpack_require__(/*! ./JingleSessionPC */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/xmpp/JingleSessionPC.js");












const logger = (0,_jitsi_logger__WEBPACK_IMPORTED_MODULE_0__.getLogger)(__filename);
// XXX Strophe is build around the idea of chaining function calls so allow long
// function call chains.
/* eslint-disable newline-per-chained-call */
/**
 * Parses the transport XML element and returns the list of ICE candidates formatted as text.
 *
 * @param {*} transport Transport XML element extracted from the IQ.
 * @returns {Array<string>}
 */
function _parseIceCandidates(transport) {
    const candidates = jquery__WEBPACK_IMPORTED_MODULE_1___default()(transport).find('>candidate');
    const parseCandidates = [];
    // Extract the candidate information from the IQ.
    candidates.each((_, candidate) => {
        const attributes = candidate.attributes;
        const candidateAttrs = [];
        for (let i = 0; i < attributes.length; i++) {
            const attr = attributes[i];
            candidateAttrs.push(`${attr.name}: ${attr.value}`);
        }
        parseCandidates.push(candidateAttrs.join(' '));
    });
    return parseCandidates;
}
/**
 *
 */
class JingleConnectionPlugin extends _ConnectionPlugin__WEBPACK_IMPORTED_MODULE_9__["default"] {
    /**
     * Creates new <tt>JingleConnectionPlugin</tt>
     * @param {XMPP} xmpp
     * @param {EventEmitter} eventEmitter
     * @param {Object} iceConfig an object that holds the iceConfig to be passed
     * to the p2p and the jvb <tt>PeerConnection</tt>.
     */
    constructor(xmpp, eventEmitter, iceConfig) {
        super();
        this.xmpp = xmpp;
        this.eventEmitter = eventEmitter;
        this.sessions = {};
        this.jvbIceConfig = iceConfig.jvb;
        this.p2pIceConfig = iceConfig.p2p;
        this.mediaConstraints = {
            offerToReceiveAudio: true,
            offerToReceiveVideo: true
        };
    }
    /**
     *
     * @param connection
     */
    init(connection) {
        super.init(connection);
        this.connection.addHandler(this.onJingle.bind(this), 'urn:xmpp:jingle:1', 'iq', 'set', null, null);
    }
    /**
     *
     * @param iq
     */
    onJingle(iq) {
        var _a;
        const sid = jquery__WEBPACK_IMPORTED_MODULE_1___default()(iq).find('jingle').attr('sid');
        const action = jquery__WEBPACK_IMPORTED_MODULE_1___default()(iq).find('jingle').attr('action');
        const fromJid = iq.getAttribute('from');
        // send ack first
        const ack = (0,strophe_js__WEBPACK_IMPORTED_MODULE_2__.$iq)({ type: 'result',
            to: fromJid,
            id: iq.getAttribute('id')
        });
        let sess = this.sessions[sid];
        if (action !== 'session-initiate') {
            if (!sess) {
                ack.attrs({ type: 'error' });
                ack.c('error', { type: 'cancel' })
                    .c('item-not-found', {
                    xmlns: 'urn:ietf:params:xml:ns:xmpp-stanzas'
                })
                    .up()
                    .c('unknown-session', {
                    xmlns: 'urn:xmpp:jingle:errors:1'
                });
                logger.warn(`invalid session id: ${sid}`);
                logger.debug(iq);
                this.connection.send(ack);
                return true;
            }
            // local jid is not checked
            if (fromJid !== sess.remoteJid) {
                logger.warn('jid mismatch for session id', sid, sess.remoteJid, iq);
                ack.attrs({ type: 'error' });
                ack.c('error', { type: 'cancel' })
                    .c('item-not-found', {
                    xmlns: 'urn:ietf:params:xml:ns:xmpp-stanzas'
                })
                    .up()
                    .c('unknown-session', {
                    xmlns: 'urn:xmpp:jingle:errors:1'
                });
                this.connection.send(ack);
                return true;
            }
        }
        else if (sess !== undefined) {
            // Existing session with same session id. This might be out-of-order
            // if the sess.remoteJid is the same as from.
            ack.attrs({ type: 'error' });
            ack.c('error', { type: 'cancel' })
                .c('service-unavailable', {
                xmlns: 'urn:ietf:params:xml:ns:xmpp-stanzas'
            })
                .up();
            logger.warn('duplicate session id', sid, iq);
            this.connection.send(ack);
            return true;
        }
        const now = window.performance.now();
        // FIXME that should work most of the time, but we'd have to
        // think how secure it is to assume that user with "focus"
        // nickname is Jicofo.
        const isP2P = strophe_js__WEBPACK_IMPORTED_MODULE_2__.Strophe.getResourceFromJid(fromJid) !== 'focus';
        // see http://xmpp.org/extensions/xep-0166.html#concepts-session
        const jsonMessages = jquery__WEBPACK_IMPORTED_MODULE_1___default()(iq).find('jingle>json-message');
        if (jsonMessages === null || jsonMessages === void 0 ? void 0 : jsonMessages.length) {
            let audioVideoSsrcs;
            logger.info(`Found a JSON-encoded element in ${action}, translating to standard Jingle.`);
            for (let i = 0; i < jsonMessages.length; i++) {
                // Currently there is always a single json-message in the IQ with the source information.
                audioVideoSsrcs = (0,_JingleHelperFunctions__WEBPACK_IMPORTED_MODULE_10__.expandSourcesFromJson)(iq, jsonMessages[i]);
            }
            if (audioVideoSsrcs === null || audioVideoSsrcs === void 0 ? void 0 : audioVideoSsrcs.size) {
                const logMessage = [];
                for (const endpoint of audioVideoSsrcs.keys()) {
                    logMessage.push(`${endpoint}:[${audioVideoSsrcs.get(endpoint)}]`);
                }
                logger.debug(`Received ${action} from ${fromJid} with sources=${logMessage.join(', ')}`);
            }
            // TODO: is there a way to remove the json-message elements once we've extracted the information?
            // removeChild doesn't seem to work.
        }
        switch (action) {
            case 'session-initiate': {
                logger.log('(TIME) received session-initiate:\t', now);
                const startMuted = jquery__WEBPACK_IMPORTED_MODULE_1___default()(iq).find('jingle>startmuted');
                isP2P && logger.debug(`Received ${action} from ${fromJid}`);
                if (startMuted === null || startMuted === void 0 ? void 0 : startMuted.length) {
                    const audioMuted = startMuted.attr(_service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_3__.MediaType.AUDIO);
                    const videoMuted = startMuted.attr(_service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_3__.MediaType.VIDEO);
                    this.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_5__.XMPPEvents.START_MUTED_FROM_FOCUS, audioMuted === 'true', videoMuted === 'true');
                }
                const pcConfig = isP2P ? this.p2pIceConfig : this.jvbIceConfig;
                sess
                    = new _JingleSessionPC__WEBPACK_IMPORTED_MODULE_11__["default"](jquery__WEBPACK_IMPORTED_MODULE_1___default()(iq).find('jingle').attr('sid'), jquery__WEBPACK_IMPORTED_MODULE_1___default()(iq).attr('to'), fromJid, this.connection, this.mediaConstraints, 
                    // Makes a copy in order to prevent exception thrown on RN when either this.p2pIceConfig or
                    // this.jvbIceConfig is modified and there's a PeerConnection instance holding a reference
                    JSON.parse(JSON.stringify(pcConfig)), isP2P, 
                    /* initiator */ false);
                this.sessions[sess.sid] = sess;
                this.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_5__.XMPPEvents.CALL_INCOMING, sess, jquery__WEBPACK_IMPORTED_MODULE_1___default()(iq).find('>jingle'), now);
                break;
            }
            case 'session-accept': {
                const ssrcs = [];
                const contents = jquery__WEBPACK_IMPORTED_MODULE_1___default()(iq).find('jingle>content');
                // Extract the SSRCs from the session-accept received from a p2p peer.
                for (const content of contents) {
                    const ssrc = jquery__WEBPACK_IMPORTED_MODULE_1___default()(content).find('description').attr('ssrc');
                    ssrc && ssrcs.push(ssrc);
                }
                logger.debug(`Received ${action} from ${fromJid} with ssrcs=${ssrcs}`);
                this.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_5__.XMPPEvents.CALL_ACCEPTED, sess, jquery__WEBPACK_IMPORTED_MODULE_1___default()(iq).find('>jingle'));
                break;
            }
            case 'content-modify': {
                logger.debug(`Received ${action} from ${fromJid}`);
                sess.modifyContents(jquery__WEBPACK_IMPORTED_MODULE_1___default()(iq).find('>jingle'));
                break;
            }
            case 'transport-info': {
                const candidates = _parseIceCandidates(jquery__WEBPACK_IMPORTED_MODULE_1___default()(iq).find('jingle>content>transport'));
                logger.debug(`Received ${action} from ${fromJid} for candidates=${candidates.join(', ')}`);
                this.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_5__.XMPPEvents.TRANSPORT_INFO, sess, jquery__WEBPACK_IMPORTED_MODULE_1___default()(iq).find('>jingle'));
                break;
            }
            case 'session-terminate': {
                logger.log('terminating...', sess.sid);
                let reasonCondition = null;
                let reasonText = null;
                if (jquery__WEBPACK_IMPORTED_MODULE_1___default()(iq).find('>jingle>reason').length) {
                    reasonCondition
                        = jquery__WEBPACK_IMPORTED_MODULE_1___default()(iq).find('>jingle>reason>:first')[0].tagName;
                    reasonText = jquery__WEBPACK_IMPORTED_MODULE_1___default()(iq).find('>jingle>reason>text').text();
                }
                logger.debug(`Received ${action} from ${fromJid} disconnect reason=${reasonText}`);
                this.terminate(sess.sid, reasonCondition, reasonText);
                this.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_5__.XMPPEvents.CALL_ENDED, sess, reasonCondition, reasonText);
                break;
            }
            case 'transport-replace': {
                logger.info('(TIME) Start transport replace:\t', now);
                const transport = jquery__WEBPACK_IMPORTED_MODULE_1___default()(iq).find('jingle>content>transport');
                const candidates = _parseIceCandidates(transport);
                const iceUfrag = jquery__WEBPACK_IMPORTED_MODULE_1___default()(transport).attr('ufrag');
                const icePwd = jquery__WEBPACK_IMPORTED_MODULE_1___default()(transport).attr('pwd');
                const dtlsFingerprint = (_a = jquery__WEBPACK_IMPORTED_MODULE_1___default()(transport).find('>fingerprint')) === null || _a === void 0 ? void 0 : _a.text();
                logger.debug(`Received ${action} from ${fromJid} with iceUfrag=${iceUfrag},`
                    + ` icePwd=${icePwd}, DTLS fingerprint=${dtlsFingerprint}, candidates=${candidates.join(', ')}`);
                _statistics_statistics__WEBPACK_IMPORTED_MODULE_6__["default"].sendAnalytics((0,_service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_4__.createJingleEvent)(_service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_4__.ACTION_JINGLE_TR_RECEIVED, {
                    p2p: isP2P,
                    value: now
                }));
                sess.replaceTransport(jquery__WEBPACK_IMPORTED_MODULE_1___default()(iq).find('>jingle'), () => {
                    const successTime = window.performance.now();
                    logger.info('(TIME) Transport replace success:\t', successTime);
                    _statistics_statistics__WEBPACK_IMPORTED_MODULE_6__["default"].sendAnalytics((0,_service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_4__.createJingleEvent)(_service_statistics_AnalyticsEvents__WEBPACK_IMPORTED_MODULE_4__.ACTION_JINGLE_TR_SUCCESS, {
                        p2p: isP2P,
                        value: successTime
                    }));
                }, error => {
                    _util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_7___default().callErrorHandler(error);
                    logger.error('Transport replace failed', error);
                    sess.sendTransportReject();
                });
                break;
            }
            case 'source-add':
                sess.addRemoteStream(jquery__WEBPACK_IMPORTED_MODULE_1___default()(iq).find('>jingle>content'));
                break;
            case 'source-remove':
                sess.removeRemoteStream(jquery__WEBPACK_IMPORTED_MODULE_1___default()(iq).find('>jingle>content'));
                break;
            default:
                logger.warn('jingle action not implemented', action);
                ack.attrs({ type: 'error' });
                ack.c('error', { type: 'cancel' })
                    .c('bad-request', { xmlns: 'urn:ietf:params:xml:ns:xmpp-stanzas' })
                    .up();
                break;
        }
        this.connection.send(ack);
        return true;
    }
    /**
     * Creates new <tt>JingleSessionPC</tt> meant to be used in a direct P2P
     * connection, configured as 'initiator'.
     * @param {string} me our JID
     * @param {string} peer remote participant's JID
     * @return {JingleSessionPC}
     */
    newP2PJingleSession(me, peer) {
        const sess = new _JingleSessionPC__WEBPACK_IMPORTED_MODULE_11__["default"](_util_RandomUtil__WEBPACK_IMPORTED_MODULE_8___default().randomHexString(12), me, peer, this.connection, this.mediaConstraints, this.p2pIceConfig, 
        /* P2P */ true, 
        /* initiator */ true);
        this.sessions[sess.sid] = sess;
        return sess;
    }
    /**
     *
     * @param sid
     * @param reasonCondition
     * @param reasonText
     */
    terminate(sid, reasonCondition, reasonText) {
        if (this.sessions.hasOwnProperty(sid)) {
            if (this.sessions[sid].state !== 'ended') {
                this.sessions[sid].onTerminated(reasonCondition, reasonText);
            }
            delete this.sessions[sid];
        }
    }
    /**
     *
     */
    getStunAndTurnCredentials() {
        // get stun and turn configuration from server via xep-0215
        // uses time-limited credentials as described in
        // http://tools.ietf.org/html/draft-uberti-behave-turn-rest-00
        //
        // See https://modules.prosody.im/mod_turncredentials.html
        // for a prosody module which implements this.
        // Or the new implementation https://modules.prosody.im/mod_external_services which will be in prosody 0.12
        //
        // Currently, this doesn't work with updateIce and therefore credentials
        // with a long validity have to be fetched before creating the
        // peerconnection.
        // TODO: implement refresh via updateIce as described in
        //      https://code.google.com/p/webrtc/issues/detail?id=1650
        this.connection.sendIQ((0,strophe_js__WEBPACK_IMPORTED_MODULE_2__.$iq)({ type: 'get',
            to: this.xmpp.options.hosts.domain })
            .c('services', { xmlns: 'urn:xmpp:extdisco:2' }), v2Res => this.onReceiveStunAndTurnCredentials(v2Res), () => {
            logger.warn('getting turn credentials with extdisco:2 failed, trying extdisco:1');
            this.connection.sendIQ((0,strophe_js__WEBPACK_IMPORTED_MODULE_2__.$iq)({ type: 'get',
                to: this.xmpp.options.hosts.domain })
                .c('services', { xmlns: 'urn:xmpp:extdisco:1' }), v1Res => this.onReceiveStunAndTurnCredentials(v1Res), () => {
                logger.warn('getting turn credentials failed');
                logger.warn('is mod_turncredentials or similar installed and configured?');
            });
        });
    }
    /**
     * Parses response when querying for services using urn:xmpp:extdisco:1 or urn:xmpp:extdisco:2.
     * Stores results in jvbIceConfig and p2pIceConfig.
     * @param res The response iq.
     * @return {boolean} Whether something was processed from the supplied message.
     */
    onReceiveStunAndTurnCredentials(res) {
        const iceservers = [];
        jquery__WEBPACK_IMPORTED_MODULE_1___default()(res).find('>services>service').each((idx, el) => {
            // eslint-disable-next-line no-param-reassign
            el = jquery__WEBPACK_IMPORTED_MODULE_1___default()(el);
            const dict = {};
            const type = el.attr('type');
            switch (type) {
                case 'stun':
                    dict.urls = `stun:${el.attr('host')}`;
                    if (el.attr('port')) {
                        dict.urls += `:${el.attr('port')}`;
                    }
                    iceservers.push(dict);
                    break;
                case 'turn':
                case 'turns': {
                    dict.urls = `${type}:`;
                    dict.username = el.attr('username');
                    dict.urls += el.attr('host');
                    const port = el.attr('port');
                    if (port) {
                        dict.urls += `:${el.attr('port')}`;
                    }
                    const transport = el.attr('transport');
                    if (transport && transport !== 'udp') {
                        dict.urls += `?transport=${transport}`;
                    }
                    dict.credential = el.attr('password')
                        || dict.credential;
                    iceservers.push(dict);
                    break;
                }
            }
        });
        const options = this.xmpp.options;
        // Shuffle ICEServers for loadbalancing
        for (let i = iceservers.length - 1; i > 0; i--) {
            const j = Math.floor(Math.random() * (i + 1));
            const temp = iceservers[i];
            iceservers[i] = iceservers[j];
            iceservers[j] = temp;
        }
        let filter;
        if (options.useTurnUdp) {
            filter = s => s.urls.startsWith('turn');
        }
        else {
            // By default we filter out STUN and TURN/UDP and leave only TURN/TCP.
            filter = s => s.urls.startsWith('turn') && (s.urls.indexOf('transport=tcp') >= 0);
        }
        this.jvbIceConfig.iceServers = iceservers.filter(filter);
        this.p2pIceConfig.iceServers = iceservers;
        return iceservers.length > 0;
    }
    /**
     * Returns the data saved in 'updateLog' in a format to be logged.
     */
    getLog() {
        const data = {};
        Object.keys(this.sessions).forEach(sid => {
            const session = this.sessions[sid];
            const pc = session.peerconnection;
            if (pc && pc.updateLog) {
                // FIXME: should probably be a .dump call
                data[`jingle_${sid}`] = {
                    updateLog: pc.updateLog,
                    stats: pc.stats,
                    url: window.location.href
                };
            }
        });
        return data;
    }
}
/* eslint-enable newline-per-chained-call */
//# sourceMappingURL=strophe.jingle.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/xmpp/strophe.logger.js":
/*!************************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/xmpp/strophe.logger.js ***!
  \************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (/* export default binding */ __WEBPACK_DEFAULT_EXPORT__)
/* harmony export */ });
/* harmony import */ var strophe_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! strophe.js */ "./node_modules/strophe.js/dist/strophe.umd.js");
/* harmony import */ var strophe_js__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(strophe_js__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var _ConnectionPlugin__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./ConnectionPlugin */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/xmpp/ConnectionPlugin.js");


/**
 *  Logs raw stanzas and makes them available for download as JSON
 */
class StropheLogger extends _ConnectionPlugin__WEBPACK_IMPORTED_MODULE_1__["default"] {
    /**
     *
     */
    constructor() {
        super();
        this.log = [];
    }
    /**
     *
     * @param connection
     */
    init(connection) {
        super.init(connection);
        this.connection.rawInput = this.logIncoming.bind(this);
        this.connection.rawOutput = this.logOutgoing.bind(this);
    }
    /**
     *
     * @param stanza
     */
    logIncoming(stanza) {
        this.log.push([new Date().getTime(), 'incoming', stanza]);
    }
    /**
     *
     * @param stanza
     */
    logOutgoing(stanza) {
        this.log.push([new Date().getTime(), 'outgoing', stanza]);
    }
}
/**
 *
 */
/* harmony default export */ function __WEBPACK_DEFAULT_EXPORT__() {
    strophe_js__WEBPACK_IMPORTED_MODULE_0__.Strophe.addConnectionPlugin('logger', new StropheLogger());
}
//# sourceMappingURL=strophe.logger.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/xmpp/strophe.ping.js":
/*!**********************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/xmpp/strophe.ping.js ***!
  \**********************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
var __filename = "/index.js";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (/* binding */ PingConnectionPlugin)
/* harmony export */ });
/* harmony import */ var _jitsi_logger__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @jitsi/logger */ "./node_modules/@jitsi/logger/lib/index.js");
/* harmony import */ var _jitsi_logger__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(_jitsi_logger__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var strophe_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! strophe.js */ "./node_modules/strophe.js/dist/strophe.umd.js");
/* harmony import */ var strophe_js__WEBPACK_IMPORTED_MODULE_1___default = /*#__PURE__*/__webpack_require__.n(strophe_js__WEBPACK_IMPORTED_MODULE_1__);
/* harmony import */ var _util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../util/GlobalOnErrorHandler */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/util/GlobalOnErrorHandler.js");
/* harmony import */ var _util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_2___default = /*#__PURE__*/__webpack_require__.n(_util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_2__);
/* harmony import */ var _ConnectionPlugin__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./ConnectionPlugin */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/xmpp/ConnectionPlugin.js");




const logger = (0,_jitsi_logger__WEBPACK_IMPORTED_MODULE_0__.getLogger)(__filename);
/**
 * Default ping every 10 sec
 */
const PING_DEFAULT_INTERVAL = 10000;
/**
 * Default ping timeout error after 5 sec of waiting.
 */
const PING_DEFAULT_TIMEOUT = 5000;
/**
 * Default value for how many ping failures will be tolerated before the WebSocket connection is killed.
 * The worst case scenario in case of ping timing out without a response is (25 seconds at the time of this writing):
 * PING_THRESHOLD * PING_INTERVAL + PING_TIMEOUT
 */
const PING_DEFAULT_THRESHOLD = 2;
/**
 * XEP-0199 ping plugin.
 *
 * Registers "urn:xmpp:ping" namespace under Strophe.NS.PING.
 */
class PingConnectionPlugin extends _ConnectionPlugin__WEBPACK_IMPORTED_MODULE_3__["default"] {
    /**
     * Constructs new object
     * @param {Object} options
     * @param {Function} options.onPingThresholdExceeded - Callback called when ping fails too many times (controlled
     * by the {@link PING_THRESHOLD} constant).
     * @param {Function} options._getTimeSinceLastServerResponse - A function to obtain the last seen
     * response from the server.
     * @param {Object} options.pingOptions - The ping options if any.
     * @constructor
     */
    constructor({ getTimeSinceLastServerResponse, onPingThresholdExceeded, pingOptions = {} }) {
        super();
        this.failedPings = 0;
        this._onPingThresholdExceeded = onPingThresholdExceeded;
        this._getTimeSinceLastServerResponse = getTimeSinceLastServerResponse;
        this.pingInterval = typeof pingOptions.interval === 'number' ? pingOptions.interval : PING_DEFAULT_INTERVAL;
        this.pingTimeout = typeof pingOptions.timeout === 'number' ? pingOptions.timeout : PING_DEFAULT_TIMEOUT;
        this.pingThreshold = typeof pingOptions.threshold === 'number'
            ? pingOptions.threshold : PING_DEFAULT_THRESHOLD;
        // The number of timestamps of send pings to keep.
        // The current value is 2 minutes.
        this.pingTimestampsToKeep = Math.round(120000 / this.pingInterval);
        this.pingExecIntervals = new Array(this.pingTimestampsToKeep);
    }
    /**
     * Initializes the plugin. Method called by Strophe.
     * @param connection Strophe connection instance.
     */
    init(connection) {
        super.init(connection);
        strophe_js__WEBPACK_IMPORTED_MODULE_1__.Strophe.addNamespace('PING', 'urn:xmpp:ping');
    }
    /* eslint-disable max-params */
    /**
     * Sends "ping" to given <tt>jid</tt>
     * @param jid the JID to which ping request will be sent.
     * @param success callback called on success.
     * @param error callback called on error.
     * @param timeout ms how long are we going to wait for the response. On
     * timeout <tt>error<//t> callback is called with undefined error argument.
     */
    ping(jid, success, error, timeout) {
        this._addPingExecutionTimestamp();
        const iq = (0,strophe_js__WEBPACK_IMPORTED_MODULE_1__.$iq)({
            type: 'get',
            to: jid
        });
        iq.c('ping', { xmlns: strophe_js__WEBPACK_IMPORTED_MODULE_1__.Strophe.NS.PING });
        this.connection.sendIQ2(iq, { timeout })
            .then(success, error);
    }
    /* eslint-enable max-params */
    /**
     * Starts to send ping in given interval to specified remote JID.
     * This plugin supports only one such task and <tt>stopInterval</tt>
     * must be called before starting a new one.
     * @param remoteJid remote JID to which ping requests will be sent to.
     */
    startInterval(remoteJid) {
        clearInterval(this.intervalId);
        this.intervalId = window.setInterval(() => {
            // when there were some server responses in the interval since the last time we checked (_lastServerCheck)
            // let's skip the ping
            const now = Date.now();
            if (this._getTimeSinceLastServerResponse() < now - this._lastServerCheck) {
                // do this just to keep in sync the intervals so we can detect suspended device
                this._addPingExecutionTimestamp();
                this._lastServerCheck = now;
                this.failedPings = 0;
                return;
            }
            this.ping(remoteJid, () => {
                // server response is measured on raw input and ping response time is measured after all the xmpp
                // processing is done in js, so there can be some misalignment when we do the check above.
                // That's why we store the last time we got the response
                this._lastServerCheck = this._getTimeSinceLastServerResponse() + Date.now();
                this.failedPings = 0;
            }, error => {
                this.failedPings += 1;
                const errmsg = `Ping ${error ? 'error' : 'timeout'}`;
                if (this.failedPings >= this.pingThreshold) {
                    _util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_2___default().callErrorHandler(new Error(errmsg));
                    logger.error(errmsg, error);
                    this._onPingThresholdExceeded && this._onPingThresholdExceeded();
                }
                else {
                    logger.warn(errmsg, error);
                }
            }, this.pingTimeout);
        }, this.pingInterval);
        logger.info(`XMPP pings will be sent every ${this.pingInterval} ms`);
    }
    /**
     * Stops current "ping"  interval task.
     */
    stopInterval() {
        if (this.intervalId) {
            window.clearInterval(this.intervalId);
            this.intervalId = null;
            this.failedPings = 0;
            logger.info('Ping interval cleared');
        }
    }
    /**
     * Adds the current time to the array of send ping timestamps.
     * @private
     */
    _addPingExecutionTimestamp() {
        this.pingExecIntervals.push(new Date().getTime());
        // keep array length to PING_TIMESTAMPS_TO_KEEP
        if (this.pingExecIntervals.length > this.pingTimestampsToKeep) {
            this.pingExecIntervals.shift();
        }
    }
    /**
     * Returns the maximum time between the recent sent pings, if there is a
     * big value it means the computer was inactive for some time(suspended).
     * Checks the maximum gap between sending pings, considering and the
     * current time. Trying to detect computer inactivity (sleep).
     *
     * @returns {int} the time ping was suspended, if it was not 0 is returned.
     */
    getPingSuspendTime() {
        const pingIntervals = this.pingExecIntervals.slice();
        // we need current time, as if ping was sent now
        // if computer sleeps we will get correct interval after next
        // scheduled ping, bet we sometimes need that interval before waiting
        // for the next ping, on closing the connection on error.
        pingIntervals.push(new Date().getTime());
        let maxInterval = 0;
        let previousTS = pingIntervals[0];
        pingIntervals.forEach(e => {
            const currentInterval = e - previousTS;
            if (currentInterval > maxInterval) {
                maxInterval = currentInterval;
            }
            previousTS = e;
        });
        // remove the interval between the ping sent
        // this way in normal execution there is no suspend and the return
        // will be 0 or close to 0.
        maxInterval -= this.pingInterval;
        // make sure we do not return less than 0
        return Math.max(maxInterval, 0);
    }
}
//# sourceMappingURL=strophe.ping.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/xmpp/strophe.rayo.js":
/*!**********************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/xmpp/strophe.rayo.js ***!
  \**********************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
var __filename = "/index.js";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (/* binding */ RayoConnectionPlugin)
/* harmony export */ });
/* harmony import */ var _jitsi_logger__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @jitsi/logger */ "./node_modules/@jitsi/logger/lib/index.js");
/* harmony import */ var _jitsi_logger__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(_jitsi_logger__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var jquery__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! jquery */ "./node_modules/jquery/dist/jquery.js");
/* harmony import */ var jquery__WEBPACK_IMPORTED_MODULE_1___default = /*#__PURE__*/__webpack_require__.n(jquery__WEBPACK_IMPORTED_MODULE_1__);
/* harmony import */ var strophe_js__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! strophe.js */ "./node_modules/strophe.js/dist/strophe.umd.js");
/* harmony import */ var strophe_js__WEBPACK_IMPORTED_MODULE_2___default = /*#__PURE__*/__webpack_require__.n(strophe_js__WEBPACK_IMPORTED_MODULE_2__);
/* harmony import */ var _ConnectionPlugin__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./ConnectionPlugin */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/xmpp/ConnectionPlugin.js");




const logger = (0,_jitsi_logger__WEBPACK_IMPORTED_MODULE_0__.getLogger)(__filename);
const RAYO_XMLNS = 'urn:xmpp:rayo:1';
/**
 *
 */
class RayoConnectionPlugin extends _ConnectionPlugin__WEBPACK_IMPORTED_MODULE_3__["default"] {
    /**
     *
     * @param connection
     */
    init(connection) {
        super.init(connection);
        this.connection.addHandler(this.onRayo.bind(this), RAYO_XMLNS, 'iq', 'set', null, null);
    }
    /**
     *
     * @param iq
     */
    onRayo(iq) {
        logger.info('Rayo IQ', iq);
    }
    /* eslint-disable max-params */
    /**
     *
     * @param to
     * @param from
     * @param roomName
     * @param roomPass
     * @param focusMucJid
     */
    dial(to, from, roomName, roomPass, focusMucJid) {
        return new Promise((resolve, reject) => {
            if (!focusMucJid) {
                reject(new Error('Internal error!'));
                return;
            }
            const req = (0,strophe_js__WEBPACK_IMPORTED_MODULE_2__.$iq)({
                type: 'set',
                to: focusMucJid
            });
            req.c('dial', {
                xmlns: RAYO_XMLNS,
                to,
                from
            });
            req.c('header', {
                name: 'JvbRoomName',
                value: roomName
            }).up();
            if (roomPass && roomPass.length) {
                req.c('header', {
                    name: 'JvbRoomPassword',
                    value: roomPass
                }).up();
            }
            this.connection.sendIQ(req, result => {
                logger.info('Dial result ', result);
                // eslint-disable-next-line newline-per-chained-call
                const resource = jquery__WEBPACK_IMPORTED_MODULE_1___default()(result).find('ref').attr('uri');
                this.callResource = resource.substr('xmpp:'.length);
                logger.info(`Received call resource: ${this.callResource}`);
                resolve();
            }, error => {
                logger.info('Dial error ', error);
                reject(error);
            });
        });
    }
    /* eslint-enable max-params */
    /**
     *
     */
    hangup() {
        return new Promise((resolve, reject) => {
            if (!this.callResource) {
                reject(new Error('No call in progress'));
                logger.warn('No call in progress');
                return;
            }
            const req = (0,strophe_js__WEBPACK_IMPORTED_MODULE_2__.$iq)({
                type: 'set',
                to: this.callResource
            });
            req.c('hangup', {
                xmlns: RAYO_XMLNS
            });
            this.connection.sendIQ(req, result => {
                logger.info('Hangup result ', result);
                this.callResource = null;
                resolve();
            }, error => {
                logger.info('Hangup error ', error);
                this.callResource = null;
                reject(new Error('Hangup error '));
            });
        });
    }
}
//# sourceMappingURL=strophe.rayo.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/xmpp/strophe.util.js":
/*!**********************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/xmpp/strophe.util.js ***!
  \**********************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
var __filename = "/index.js";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (/* export default binding */ __WEBPACK_DEFAULT_EXPORT__)
/* harmony export */ });
/* harmony import */ var _jitsi_logger__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @jitsi/logger */ "./node_modules/@jitsi/logger/lib/index.js");
/* harmony import */ var _jitsi_logger__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(_jitsi_logger__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var strophe_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! strophe.js */ "./node_modules/strophe.js/dist/strophe.umd.js");
/* harmony import */ var strophe_js__WEBPACK_IMPORTED_MODULE_1___default = /*#__PURE__*/__webpack_require__.n(strophe_js__WEBPACK_IMPORTED_MODULE_1__);
/* harmony import */ var _util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../util/GlobalOnErrorHandler */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/util/GlobalOnErrorHandler.js");
/* harmony import */ var _util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_2___default = /*#__PURE__*/__webpack_require__.n(_util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_2__);
/**
 * Strophe logger implementation. Logs from level WARN and above.
 */



const logger = (0,_jitsi_logger__WEBPACK_IMPORTED_MODULE_0__.getLogger)(__filename);
/**
 * This is the last HTTP error status captured from Strophe debug logs.
 * The purpose of storing it is to distinguish between the network and
 * infrastructure reason for connection being dropped (see connectionHandler in
 * xmpp.js). The value will be cleared (-1) if the subsequent request succeeds
 * which means that the failure could be transient.
 *
 * FIXME in the latest Strophe (not released on npm) there is API to handle
 * particular HTTP errors, but there is no way to learn if the subsequent
 * request succeeded in order to tell if the error was one time incident or if
 * it was the reason for dropping the connection by Strophe (the connection is
 * dropped after 5 subsequent failures). Ideally Strophe should provide more
 * details about the reason on why the connection stopped.
 *
 * @type {number}
 */
let lastErrorStatus = -1;
/**
 * A regular expression used to catch Strophe's log message indicating that the
 * last BOSH request was successful. When there is such message seen the
 * {@link lastErrorStatus} will be set back to '-1'.
 * @type {RegExp}
 */
const resetLastErrorStatusRegExpr = /request id \d+.\d+ got 200/;
/**
 * A regular expression used to capture the current value of the BOSH request
 * error status (HTTP error code or '0' or something else).
 * @type {RegExp}
 */
const lastErrorStatusRegExpr = /request errored, status: (\d+), number of errors: \d+/;
/**
 *
 */
/* harmony default export */ function __WEBPACK_DEFAULT_EXPORT__() {
    strophe_js__WEBPACK_IMPORTED_MODULE_1__.Strophe.log = function (level, msg) {
        // Our global handler reports uncaught errors to the stats which may
        // interpret those as partial call failure.
        // Strophe log entry about secondary request timeout does not mean that
        // it's a final failure(the request will be restarted), so we lower it's
        // level here to a warning.
        logger.trace('Strophe', level, msg);
        if (typeof msg === 'string'
            && msg.indexOf('Request ') !== -1
            && msg.indexOf('timed out (secondary), restarting') !== -1) {
            // eslint-disable-next-line no-param-reassign
            level = strophe_js__WEBPACK_IMPORTED_MODULE_1__.Strophe.LogLevel.WARN;
        }
        /* eslint-disable no-case-declarations */
        switch (level) {
            case strophe_js__WEBPACK_IMPORTED_MODULE_1__.Strophe.LogLevel.DEBUG:
                // The log message which reports successful status is logged on
                // Strophe's DEBUG level.
                if (lastErrorStatus !== -1
                    && resetLastErrorStatusRegExpr.test(msg)) {
                    logger.debug('Reset lastErrorStatus');
                    lastErrorStatus = -1;
                }
                break;
            case strophe_js__WEBPACK_IMPORTED_MODULE_1__.Strophe.LogLevel.WARN:
                logger.warn(`Strophe: ${msg}`);
                const errStatusCapture = lastErrorStatusRegExpr.exec(msg);
                if (errStatusCapture && errStatusCapture.length === 2) {
                    lastErrorStatus = parseInt(errStatusCapture[1], 10);
                    logger.debug(`lastErrorStatus set to: ${lastErrorStatus}`);
                }
                break;
            case strophe_js__WEBPACK_IMPORTED_MODULE_1__.Strophe.LogLevel.ERROR:
            case strophe_js__WEBPACK_IMPORTED_MODULE_1__.Strophe.LogLevel.FATAL:
                // eslint-disable-next-line no-param-reassign
                msg = `Strophe: ${msg}`;
                _util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_2___default().callErrorHandler(new Error(msg));
                logger.error(msg);
                break;
        }
        /* eslint-enable no-case-declarations */
    };
    /**
     * Returns error status (HTTP error code) of the last BOSH request.
     *
     * @return {number} HTTP error code, '0' for unknown or "god knows what"
     * (this is a hack).
     */
    strophe_js__WEBPACK_IMPORTED_MODULE_1__.Strophe.getLastErrorStatus = function () {
        return lastErrorStatus;
    };
    strophe_js__WEBPACK_IMPORTED_MODULE_1__.Strophe.getStatusString = function (status) {
        switch (status) {
            case strophe_js__WEBPACK_IMPORTED_MODULE_1__.Strophe.Status.BINDREQUIRED:
                return 'BINDREQUIRED';
            case strophe_js__WEBPACK_IMPORTED_MODULE_1__.Strophe.Status.ERROR:
                return 'ERROR';
            case strophe_js__WEBPACK_IMPORTED_MODULE_1__.Strophe.Status.CONNECTING:
                return 'CONNECTING';
            case strophe_js__WEBPACK_IMPORTED_MODULE_1__.Strophe.Status.CONNFAIL:
                return 'CONNFAIL';
            case strophe_js__WEBPACK_IMPORTED_MODULE_1__.Strophe.Status.AUTHENTICATING:
                return 'AUTHENTICATING';
            case strophe_js__WEBPACK_IMPORTED_MODULE_1__.Strophe.Status.AUTHFAIL:
                return 'AUTHFAIL';
            case strophe_js__WEBPACK_IMPORTED_MODULE_1__.Strophe.Status.CONNECTED:
                return 'CONNECTED';
            case strophe_js__WEBPACK_IMPORTED_MODULE_1__.Strophe.Status.DISCONNECTED:
                return 'DISCONNECTED';
            case strophe_js__WEBPACK_IMPORTED_MODULE_1__.Strophe.Status.DISCONNECTING:
                return 'DISCONNECTING';
            case strophe_js__WEBPACK_IMPORTED_MODULE_1__.Strophe.Status.ATTACHED:
                return 'ATTACHED';
            default:
                return 'unknown';
        }
    };
}
//# sourceMappingURL=strophe.util.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/xmpp/xmpp.js":
/*!**************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/xmpp/xmpp.js ***!
  \**************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
var __filename = "/index.js";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   DEFAULT_STUN_SERVERS: () => (/* binding */ DEFAULT_STUN_SERVERS),
/* harmony export */   FEATURE_E2EE: () => (/* binding */ FEATURE_E2EE),
/* harmony export */   FEATURE_JIGASI: () => (/* binding */ FEATURE_JIGASI),
/* harmony export */   JITSI_MEET_MUC_TYPE: () => (/* binding */ JITSI_MEET_MUC_TYPE),
/* harmony export */   "default": () => (/* binding */ XMPP)
/* harmony export */ });
/* harmony import */ var _jitsi_logger__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @jitsi/logger */ "./node_modules/@jitsi/logger/lib/index.js");
/* harmony import */ var _jitsi_logger__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(_jitsi_logger__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var jquery__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! jquery */ "./node_modules/jquery/dist/jquery.js");
/* harmony import */ var jquery__WEBPACK_IMPORTED_MODULE_1___default = /*#__PURE__*/__webpack_require__.n(jquery__WEBPACK_IMPORTED_MODULE_1__);
/* harmony import */ var strophe_js__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! strophe.js */ "./node_modules/strophe.js/dist/strophe.umd.js");
/* harmony import */ var strophe_js__WEBPACK_IMPORTED_MODULE_2___default = /*#__PURE__*/__webpack_require__.n(strophe_js__WEBPACK_IMPORTED_MODULE_2__);
/* harmony import */ var strophejs_plugin_disco__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! strophejs-plugin-disco */ "./node_modules/strophejs-plugin-disco/lib/strophe.disco.js");
/* harmony import */ var strophejs_plugin_disco__WEBPACK_IMPORTED_MODULE_3___default = /*#__PURE__*/__webpack_require__.n(strophejs_plugin_disco__WEBPACK_IMPORTED_MODULE_3__);
/* harmony import */ var _JitsiConnectionErrors__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../../JitsiConnectionErrors */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/JitsiConnectionErrors.js");
/* harmony import */ var _JitsiConnectionEvents__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../../JitsiConnectionEvents */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/JitsiConnectionEvents.js");
/* harmony import */ var _service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../../service/xmpp/XMPPEvents */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/xmpp/XMPPEvents.js");
/* harmony import */ var _browser__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../browser */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/browser/index.js");
/* harmony import */ var _e2ee_E2EEncryption__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ../e2ee/E2EEncryption */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/e2ee/E2EEncryption.js");
/* harmony import */ var _flags_FeatureFlags__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ../flags/FeatureFlags */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/flags/FeatureFlags.js");
/* harmony import */ var _statistics_statistics__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ../statistics/statistics */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/statistics/statistics.js");
/* harmony import */ var _util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_11__ = __webpack_require__(/*! ../util/GlobalOnErrorHandler */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/util/GlobalOnErrorHandler.js");
/* harmony import */ var _util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_11___default = /*#__PURE__*/__webpack_require__.n(_util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_11__);
/* harmony import */ var _util_Listenable__WEBPACK_IMPORTED_MODULE_12__ = __webpack_require__(/*! ../util/Listenable */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/util/Listenable.js");
/* harmony import */ var _util_RandomUtil__WEBPACK_IMPORTED_MODULE_13__ = __webpack_require__(/*! ../util/RandomUtil */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/util/RandomUtil.js");
/* harmony import */ var _util_RandomUtil__WEBPACK_IMPORTED_MODULE_13___default = /*#__PURE__*/__webpack_require__.n(_util_RandomUtil__WEBPACK_IMPORTED_MODULE_13__);
/* harmony import */ var _Caps__WEBPACK_IMPORTED_MODULE_14__ = __webpack_require__(/*! ./Caps */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/xmpp/Caps.js");
/* harmony import */ var _XmppConnection__WEBPACK_IMPORTED_MODULE_15__ = __webpack_require__(/*! ./XmppConnection */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/xmpp/XmppConnection.js");
/* harmony import */ var _strophe_emuc__WEBPACK_IMPORTED_MODULE_16__ = __webpack_require__(/*! ./strophe.emuc */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/xmpp/strophe.emuc.js");
/* harmony import */ var _strophe_jingle__WEBPACK_IMPORTED_MODULE_17__ = __webpack_require__(/*! ./strophe.jingle */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/xmpp/strophe.jingle.js");
/* harmony import */ var _strophe_logger__WEBPACK_IMPORTED_MODULE_18__ = __webpack_require__(/*! ./strophe.logger */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/xmpp/strophe.logger.js");
/* harmony import */ var _strophe_rayo__WEBPACK_IMPORTED_MODULE_19__ = __webpack_require__(/*! ./strophe.rayo */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/xmpp/strophe.rayo.js");
/* harmony import */ var _strophe_util__WEBPACK_IMPORTED_MODULE_20__ = __webpack_require__(/*! ./strophe.util */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/xmpp/strophe.util.js");





















const logger = (0,_jitsi_logger__WEBPACK_IMPORTED_MODULE_0__.getLogger)(__filename);
/**
* Regex to extract exact error message on jwt error.
*/
const FAILURE_REGEX = /<failure.*><not-allowed\/><text>(.*)<\/text><\/failure>/gi;
/**
 * Creates XMPP connection.
 *
 * @param {Object} options
 * @param {string} [options.token] - JWT token used for authentication(JWT authentication module must be enabled in
 * Prosody).
 * @param {string} options.serviceUrl - The service URL for XMPP connection.
 * @param {string} options.shard - The shard where XMPP connection initially landed.
 * @param {string} options.enableWebsocketResume - True to enable stream resumption.
 * @param {number} [options.websocketKeepAlive] - See {@link XmppConnection} constructor.
 * @param {number} [options.websocketKeepAliveUrl] - See {@link XmppConnection} constructor.
 * @param {Object} [options.xmppPing] - See {@link XmppConnection} constructor.
 * @returns {XmppConnection}
 */
function createConnection({ enableWebsocketResume, serviceUrl = '/http-bind', shard, token, websocketKeepAlive, websocketKeepAliveUrl, xmppPing }) {
    // Append token as URL param
    if (token) {
        // eslint-disable-next-line no-param-reassign
        serviceUrl += `${serviceUrl.indexOf('?') === -1 ? '?' : '&'}token=${token}`;
    }
    return new _XmppConnection__WEBPACK_IMPORTED_MODULE_15__["default"]({
        enableWebsocketResume,
        serviceUrl,
        websocketKeepAlive,
        websocketKeepAliveUrl,
        xmppPing,
        shard
    });
}
/**
 * Initializes Strophe plugins that need to work with Strophe.Connection directly rather than the lib-jitsi-meet's
 * {@link XmppConnection} wrapper.
 *
 * @returns {void}
 */
function initStropheNativePlugins() {
    (0,_strophe_util__WEBPACK_IMPORTED_MODULE_20__["default"])();
    (0,_strophe_logger__WEBPACK_IMPORTED_MODULE_18__["default"])();
}
// FIXME: remove once we have a default config template. -saghul
/**
 * A list of ice servers to use by default for P2P.
 */
const DEFAULT_STUN_SERVERS = [
    { urls: 'stun:meet-jit-si-turnrelay.jitsi.net:443' }
];
/**
 * The name of the field used to recognize a chat message as carrying a JSON
 * payload from another endpoint.
 * If the json-message of a chat message contains a valid JSON object, and
 * the JSON has this key, then it is a valid json-message to be sent.
 */
const JITSI_MEET_MUC_TYPE = 'type';
/**
 * The feature used by jigasi participants.
 * @type {string}
 */
const FEATURE_JIGASI = 'http://jitsi.org/protocol/jigasi';
/**
 * The feature used by the lib to mark support for e2ee. We use the feature by putting it in the presence
 * to avoid additional signaling (disco-info).
 * @type {string}
 */
const FEATURE_E2EE = 'https://jitsi.org/meet/e2ee';
/**
 *
 */
class XMPP extends _util_Listenable__WEBPACK_IMPORTED_MODULE_12__["default"] {
    /**
     * FIXME describe all options
     * @param {Object} options
     * @param {String} options.serviceUrl - URL passed to the XMPP client which will be used to establish XMPP
     * connection with the server.
     * @param {String} options.bosh - Deprecated, use {@code serviceUrl}.
     * @param {boolean} options.enableWebsocketResume - Enables XEP-0198 stream management which will make the XMPP
     * module try to resume the session in case the Websocket connection breaks.
     * @param {number} [options.websocketKeepAlive] - The websocket keep alive interval. See {@link XmppConnection}
     * constructor for more details.
     * @param {number} [options.websocketKeepAliveUrl] - The websocket keep alive url. See {@link XmppConnection}
     * constructor for more details.
     * @param {Object} [options.xmppPing] - The xmpp ping settings.
     * @param {Array<Object>} options.p2pStunServers see {@link JingleConnectionPlugin} for more details.
     * @param token
     */
    constructor(options, token) {
        super();
        this.connection = null;
        this.disconnectInProgress = false;
        this.connectionTimes = {};
        this.options = options;
        this.token = token;
        this.authenticatedUser = false;
        if (!this.options.deploymentInfo) {
            this.options.deploymentInfo = {};
        }
        // Cache of components used for certain features.
        this._components = [];
        initStropheNativePlugins();
        const xmppPing = options.xmppPing || {};
        // let's ping the main domain (in case a guest one is used for the connection)
        xmppPing.domain = options.hosts.domain;
        this.connection = createConnection({
            enableWebsocketResume: options.enableWebsocketResume,
            // FIXME remove deprecated bosh option at some point
            serviceUrl: options.serviceUrl || options.bosh,
            token,
            websocketKeepAlive: options.websocketKeepAlive,
            websocketKeepAliveUrl: options.websocketKeepAliveUrl,
            xmppPing,
            shard: options.deploymentInfo.shard
        });
        // forwards the shard changed event
        this.connection.on(_XmppConnection__WEBPACK_IMPORTED_MODULE_15__["default"].Events.CONN_SHARD_CHANGED, () => {
            /* eslint-disable camelcase */
            const details = {
                shard_changed: true,
                suspend_time: this.connection.ping.getPingSuspendTime(),
                time_since_last_success: this.connection.getTimeSinceLastSuccess()
            };
            /* eslint-enable camelcase */
            this.eventEmitter.emit(_JitsiConnectionEvents__WEBPACK_IMPORTED_MODULE_5__.CONNECTION_FAILED, _JitsiConnectionErrors__WEBPACK_IMPORTED_MODULE_4__.OTHER_ERROR, undefined, undefined, details);
        });
        this._initStrophePlugins();
        this.caps = new _Caps__WEBPACK_IMPORTED_MODULE_14__["default"](this.connection, /* clientNode */ 'https://jitsi.org/jitsi-meet');
        // Initialize features advertised in disco-info
        this.initFeaturesList();
        // Setup a disconnect on unload as a way to facilitate API consumers. It
        // sounds like they would want that. A problem for them though may be if
        // they wanted to utilize the connected connection in an unload handler
        // of their own. However, it should be fairly easy for them to do that
        // by registering their unload handler before us.
        jquery__WEBPACK_IMPORTED_MODULE_1___default()(window).on(`${this.options.disableBeforeUnloadHandlers ? '' : 'beforeunload '}unload`, ev => {
            this.disconnect(ev).catch(() => {
                // ignore errors in order to not brake the unload.
            });
        });
    }
    /**
     * Initializes the list of feature advertised through the disco-info
     * mechanism.
     */
    initFeaturesList() {
        // http://xmpp.org/extensions/xep-0167.html#support
        // http://xmpp.org/extensions/xep-0176.html#support
        this.caps.addFeature('urn:xmpp:jingle:1');
        this.caps.addFeature('urn:xmpp:jingle:apps:rtp:1');
        this.caps.addFeature('urn:xmpp:jingle:transports:ice-udp:1');
        this.caps.addFeature('urn:xmpp:jingle:apps:dtls:0');
        this.caps.addFeature('urn:xmpp:jingle:transports:dtls-sctp:1');
        this.caps.addFeature('urn:xmpp:jingle:apps:rtp:audio');
        this.caps.addFeature('urn:xmpp:jingle:apps:rtp:video');
        this.caps.addFeature('http://jitsi.org/json-encoded-sources');
        if (!(this.options.disableRtx || !_browser__WEBPACK_IMPORTED_MODULE_7__["default"].supportsRTX())) {
            this.caps.addFeature('urn:ietf:rfc:4588');
        }
        if (this.options.enableOpusRed === true && _browser__WEBPACK_IMPORTED_MODULE_7__["default"].supportsAudioRed()) {
            this.caps.addFeature('http://jitsi.org/opus-red');
        }
        if (typeof this.options.enableRemb === 'undefined' || this.options.enableRemb) {
            this.caps.addFeature('http://jitsi.org/remb');
        }
        // Disable TCC on Firefox because of a known issue where BWE is halved on every renegotiation.
        if (!_browser__WEBPACK_IMPORTED_MODULE_7__["default"].isFirefox() && (typeof this.options.enableTcc === 'undefined' || this.options.enableTcc)) {
            this.caps.addFeature('http://jitsi.org/tcc');
        }
        // this is dealt with by SDP O/A so we don't need to announce this
        // XEP-0293
        // this.caps.addFeature('urn:xmpp:jingle:apps:rtp:rtcp-fb:0');
        // XEP-0294
        // this.caps.addFeature('urn:xmpp:jingle:apps:rtp:rtp-hdrext:0');
        // this.caps.addFeature('urn:ietf:rfc:5576'); // a=ssrc
        // Enable Lipsync ?
        if (_browser__WEBPACK_IMPORTED_MODULE_7__["default"].isChromiumBased() && this.options.enableLipSync === true) {
            logger.info('Lip-sync enabled !');
            this.caps.addFeature('http://jitsi.org/meet/lipsync');
        }
        if (this.connection.rayo) {
            this.caps.addFeature('urn:xmpp:rayo:client:1');
        }
        if (_e2ee_E2EEncryption__WEBPACK_IMPORTED_MODULE_8__.E2EEncryption.isSupported(this.options)) {
            this.caps.addFeature(FEATURE_E2EE, false, true);
        }
        // Advertise source-name signaling when the endpoint supports it.
        logger.debug('Source-name signaling is enabled');
        this.caps.addFeature('http://jitsi.org/source-name');
        logger.debug('Receiving multiple video streams is enabled');
        this.caps.addFeature('http://jitsi.org/receive-multiple-video-streams');
        // Advertise support for ssrc-rewriting.
        if (_flags_FeatureFlags__WEBPACK_IMPORTED_MODULE_9__["default"].isSsrcRewritingSupported()) {
            this.caps.addFeature('http://jitsi.org/ssrc-rewriting-1');
        }
        // Use "-1" as a version that we can bump later. This should match
        // the version added in moderator.js, this one here is mostly defined
        // for keeping stats, since it is not made available to jocofo at
        // the time of the initial conference-request.
        if (_flags_FeatureFlags__WEBPACK_IMPORTED_MODULE_9__["default"].isJoinAsVisitorSupported()) {
            this.caps.addFeature('http://jitsi.org/visitors-1');
        }
    }
    /**
     *
     */
    getConnection() {
        return this.connection;
    }
    /**
     * Receive connection status changes and handles them.
     *
     * @param {Object} credentials
     * @param {string} credentials.jid - The user's XMPP ID passed to the
     * connect method. For example, 'user@xmpp.com'.
     * @param {string} credentials.password - The password passed to the connect
     * method.
     * @param {string} status - One of Strophe's connection status strings.
     * @param {string} [msg] - The connection error message provided by Strophe.
     */
    connectionHandler(credentials = {}, status, msg) {
        const now = window.performance.now();
        const statusStr = strophe_js__WEBPACK_IMPORTED_MODULE_2__.Strophe.getStatusString(status).toLowerCase();
        this.connectionTimes[statusStr] = now;
        logger.log(`(TIME) Strophe ${statusStr}${msg ? `[${msg}]` : ''}:\t`, now);
        this.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_6__.XMPPEvents.CONNECTION_STATUS_CHANGED, credentials, status, msg);
        this._maybeSendDeploymentInfoStat();
        if (status === strophe_js__WEBPACK_IMPORTED_MODULE_2__.Strophe.Status.CONNECTED || status === strophe_js__WEBPACK_IMPORTED_MODULE_2__.Strophe.Status.ATTACHED) {
            // once connected or attached we no longer need this handle, drop it if it exist
            if (this._sysMessageHandler) {
                this.connection._stropheConn.deleteHandler(this._sysMessageHandler);
                this._sysMessageHandler = null;
            }
            this.sendDiscoInfo && this.connection.jingle.getStunAndTurnCredentials();
            logger.info(`My Jabber ID: ${this.connection.jid}`);
            // XmppConnection emits CONNECTED again on reconnect - a good opportunity to clear any "last error" flags
            this._resetState();
            // make sure we will send the info after the features request succeeds or fails
            this.sendDeploymentInfo = false;
            this.sendDiscoInfo && this.caps.getFeaturesAndIdentities(this.options.hosts.domain)
                .then(({ features, identities }) => {
                if (!features.has(strophe_js__WEBPACK_IMPORTED_MODULE_2__.Strophe.NS.PING)) {
                    logger.error(`Ping NOT supported by ${this.options.hosts.domain} - please enable ping in your XMPP server config`);
                }
                this._processDiscoInfoIdentities(identities, undefined /* when querying we will query for features */);
            })
                .catch(error => {
                const errmsg = 'Feature discovery error';
                _util_GlobalOnErrorHandler__WEBPACK_IMPORTED_MODULE_11___default().callErrorHandler(new Error(`${errmsg}: ${error}`));
                logger.error(errmsg, error);
                this._maybeSendDeploymentInfoStat(true);
            });
            // make sure we don't query again
            this.sendDiscoInfo = false;
            if (credentials.password) {
                this.authenticatedUser = true;
            }
            if (this.connection && this.connection.connected
                && strophe_js__WEBPACK_IMPORTED_MODULE_2__.Strophe.getResourceFromJid(this.connection.jid)) {
                // .connected is true while connecting?
                // this.connection.send($pres());
                this.eventEmitter.emit(_JitsiConnectionEvents__WEBPACK_IMPORTED_MODULE_5__.CONNECTION_ESTABLISHED, strophe_js__WEBPACK_IMPORTED_MODULE_2__.Strophe.getResourceFromJid(this.connection.jid));
            }
        }
        else if (status === strophe_js__WEBPACK_IMPORTED_MODULE_2__.Strophe.Status.CONNFAIL) {
            if (msg === 'x-strophe-bad-non-anon-jid') {
                this.anonymousConnectionFailed = true;
            }
            else {
                this.connectionFailed = true;
            }
            this.lastErrorMsg = msg;
            if (msg === 'giving-up') {
                this.eventEmitter.emit(_JitsiConnectionEvents__WEBPACK_IMPORTED_MODULE_5__.CONNECTION_FAILED, _JitsiConnectionErrors__WEBPACK_IMPORTED_MODULE_4__.OTHER_ERROR, msg);
            }
        }
        else if (status === strophe_js__WEBPACK_IMPORTED_MODULE_2__.Strophe.Status.ERROR) {
            this.lastErrorMsg = msg;
        }
        else if (status === strophe_js__WEBPACK_IMPORTED_MODULE_2__.Strophe.Status.DISCONNECTED) {
            // Stop ping interval
            this.connection.ping.stopInterval();
            const wasIntentionalDisconnect = Boolean(this.disconnectInProgress);
            const errMsg = msg || this.lastErrorMsg;
            if (this.anonymousConnectionFailed) {
                // prompt user for username and password
                this.eventEmitter.emit(_JitsiConnectionEvents__WEBPACK_IMPORTED_MODULE_5__.CONNECTION_FAILED, _JitsiConnectionErrors__WEBPACK_IMPORTED_MODULE_4__.PASSWORD_REQUIRED);
            }
            else if (this.connectionFailed) {
                this.eventEmitter.emit(_JitsiConnectionEvents__WEBPACK_IMPORTED_MODULE_5__.CONNECTION_FAILED, _JitsiConnectionErrors__WEBPACK_IMPORTED_MODULE_4__.OTHER_ERROR, errMsg, undefined, /* credentials */ this._getConnectionFailedReasonDetails());
            }
            else if (wasIntentionalDisconnect) {
                this.eventEmitter.emit(_JitsiConnectionEvents__WEBPACK_IMPORTED_MODULE_5__.CONNECTION_DISCONNECTED, errMsg);
            }
            else {
                // XXX if Strophe drops the connection while not being asked to,
                // it means that most likely some serious error has occurred.
                // One currently known case is when a BOSH request fails for
                // more than 4 times. The connection is dropped without
                // supplying a reason(error message/event) through the API.
                logger.error('XMPP connection dropped!');
                // XXX if the last request error is within 5xx range it means it
                // was a server failure
                const lastErrorStatus = strophe_js__WEBPACK_IMPORTED_MODULE_2__.Strophe.getLastErrorStatus();
                if (lastErrorStatus >= 500 && lastErrorStatus < 600) {
                    this.eventEmitter.emit(_JitsiConnectionEvents__WEBPACK_IMPORTED_MODULE_5__.CONNECTION_FAILED, _JitsiConnectionErrors__WEBPACK_IMPORTED_MODULE_4__.SERVER_ERROR, errMsg || 'server-error', 
                    /* credentials */ undefined, this._getConnectionFailedReasonDetails());
                }
                else {
                    this.eventEmitter.emit(_JitsiConnectionEvents__WEBPACK_IMPORTED_MODULE_5__.CONNECTION_FAILED, _JitsiConnectionErrors__WEBPACK_IMPORTED_MODULE_4__.CONNECTION_DROPPED_ERROR, errMsg || 'connection-dropped-error', 
                    /* credentials */ undefined, this._getConnectionFailedReasonDetails());
                }
            }
        }
        else if (status === strophe_js__WEBPACK_IMPORTED_MODULE_2__.Strophe.Status.AUTHFAIL) {
            const lastFailedRawMessage = this.getConnection().getLastFailedMessage();
            // wrong password or username, prompt user
            this.eventEmitter.emit(_JitsiConnectionEvents__WEBPACK_IMPORTED_MODULE_5__.CONNECTION_FAILED, _JitsiConnectionErrors__WEBPACK_IMPORTED_MODULE_4__.PASSWORD_REQUIRED, msg || this._parseConnectionFailedMessage(lastFailedRawMessage), credentials);
        }
    }
    /**
     * Process received identities.
     * @param {Set<String>} identities The identities to process.
     * @param {Set<String>} features The features to process, optional. If missing lobby component will be queried
     * for more features.
     * @private
     */
    _processDiscoInfoIdentities(identities, features) {
        // check for speakerstats
        identities.forEach(identity => {
            if (identity.type === 'av_moderation') {
                this.avModerationComponentAddress = identity.name;
                this._components.push(this.avModerationComponentAddress);
            }
            if (identity.type === 'end_conference') {
                this.endConferenceComponentAddress = identity.name;
                this._components.push(this.endConferenceComponentAddress);
            }
            if (identity.type === 'speakerstats') {
                this.speakerStatsComponentAddress = identity.name;
                this._components.push(this.speakerStatsComponentAddress);
            }
            if (identity.type === 'conference_duration') {
                this.conferenceDurationComponentAddress = identity.name;
                this._components.push(this.conferenceDurationComponentAddress);
            }
            if (identity.type === 'lobbyrooms') {
                this.lobbySupported = true;
                const processLobbyFeatures = f => {
                    f.forEach(fr => {
                        if (fr.endsWith('#displayname_required')) {
                            this.eventEmitter.emit(_JitsiConnectionEvents__WEBPACK_IMPORTED_MODULE_5__.DISPLAY_NAME_REQUIRED);
                        }
                    });
                };
                if (features) {
                    processLobbyFeatures(features);
                }
                else {
                    identity.name && this.caps.getFeaturesAndIdentities(identity.name, identity.type)
                        .then(({ features: f }) => processLobbyFeatures(f))
                        .catch(e => logger.warn('Error getting features from lobby.', e && e.message));
                }
            }
            if (identity.type === 'shard') {
                this.options.deploymentInfo.shard = this.connection.shard = identity.name;
            }
            if (identity.type === 'region') {
                this.options.deploymentInfo.region = this.connection.region = identity.name;
            }
            if (identity.type === 'release') {
                this.options.deploymentInfo.backendRelease = identity.name;
            }
            if (identity.type === 'breakout_rooms') {
                this.breakoutRoomsComponentAddress = identity.name;
                this._components.push(this.breakoutRoomsComponentAddress);
            }
            if (identity.type === 'room_metadata') {
                this.roomMetadataComponentAddress = identity.name;
                this._components.push(this.roomMetadataComponentAddress);
            }
        });
        this._maybeSendDeploymentInfoStat(true);
        if (this._components.length > 0) {
            this.connection.addHandler(this._onPrivateMessage.bind(this), null, 'message', null, null);
        }
    }
    /**
    * Parses a raw failure xmpp xml message received on auth failed.
    *
    * @param {string} msg - The raw failure message from xmpp.
    * @returns {string|null} - The parsed message from the raw xmpp message.
    */
    _parseConnectionFailedMessage(msg) {
        if (!msg) {
            return null;
        }
        const matches = FAILURE_REGEX.exec(msg);
        return matches ? matches[1] : null;
    }
    /**
     *
     * @param jid
     * @param password
     */
    _connect(jid, password) {
        // connection.connect() starts the connection process.
        //
        // As the connection process proceeds, the user supplied callback will
        // be triggered multiple times with status updates. The callback should
        // take two arguments - the status code and the error condition.
        //
        // The status code will be one of the values in the Strophe.Status
        // constants. The error condition will be one of the conditions defined
        // in RFC 3920 or the condition strophe-parsererror.
        //
        // The Parameters wait, hold and route are optional and only relevant
        // for BOSH connections. Please see XEP 124 for a more detailed
        // explanation of the optional parameters.
        //
        // Connection status constants for use by the connection handler
        // callback.
        //
        //  Status.ERROR - An error has occurred (websockets specific)
        //  Status.CONNECTING - The connection is currently being made
        //  Status.CONNFAIL - The connection attempt failed
        //  Status.AUTHENTICATING - The connection is authenticating
        //  Status.AUTHFAIL - The authentication attempt failed
        //  Status.CONNECTED - The connection has succeeded
        //  Status.DISCONNECTED - The connection has been terminated
        //  Status.DISCONNECTING - The connection is currently being terminated
        //  Status.ATTACHED - The connection has been attached
        this._resetState();
        // we want to send this only on the initial connect
        this.sendDiscoInfo = true;
        this.sendDeploymentInfo = true;
        if (this.connection._stropheConn && this.connection._stropheConn._addSysHandler) {
            this._sysMessageHandler = this.connection._stropheConn._addSysHandler(this._onSystemMessage.bind(this), null, 'message');
        }
        else {
            logger.warn('Cannot attach strophe system handler, jiconop cannot operate');
        }
        this.connection.connect(jid, password, this.connectionHandler.bind(this, {
            jid,
            password
        }));
    }
    /**
     * Receives system messages during the connect/login process and checks for services or
     * @param msg The received message.
     * @returns {void}
     * @private
     */
    _onSystemMessage(msg) {
        // proceed only if the message has any of the expected information
        if (jquery__WEBPACK_IMPORTED_MODULE_1___default()(msg).find('>services').length === 0 && jquery__WEBPACK_IMPORTED_MODULE_1___default()(msg).find('>query').length === 0) {
            return;
        }
        this.sendDiscoInfo = false;
        const foundIceServers = this.connection.jingle.onReceiveStunAndTurnCredentials(msg);
        const { features, identities } = (0,_Caps__WEBPACK_IMPORTED_MODULE_14__.parseDiscoInfo)(msg);
        this._processDiscoInfoIdentities(identities, features);
        if (foundIceServers || identities.size > 0 || features.size > 0) {
            this.connection._stropheConn.deleteHandler(this._sysMessageHandler);
            this._sysMessageHandler = null;
        }
    }
    /**
     * Attach to existing connection. Can be used for optimizations. For
     * example: if the connection is created on the server we can attach to it
     * and start using it.
     *
     * @param options {object} connecting options - rid, sid, jid and password.
     */
    attach(options) {
        this._resetState();
        // we want to send this only on the initial connect
        this.sendDiscoInfo = true;
        const now = this.connectionTimes.attaching = window.performance.now();
        logger.log('(TIME) Strophe Attaching:\t', now);
        this.connection.attach(options.jid, options.sid, parseInt(options.rid, 10) + 1, this.connectionHandler.bind(this, {
            jid: options.jid,
            password: options.password
        }));
    }
    /**
     * Resets any state/flag before starting a new connection.
     * @private
     */
    _resetState() {
        this.anonymousConnectionFailed = false;
        this.connectionFailed = false;
        this.lastErrorMsg = undefined;
        this.disconnectInProgress = undefined;
    }
    /**
     *
     * @param jid
     * @param password
     */
    connect(jid, password) {
        if (!jid) {
            const { anonymousdomain, domain } = this.options.hosts;
            let configDomain = anonymousdomain || domain;
            // Force authenticated domain if room is appended with '?login=true'
            // or if we're joining with the token
            // FIXME Do not rely on window.location because (1) React Native
            // does not have a window.location by default and (2) here we cannot
            // know for sure that query/search has not be stripped from
            // window.location by the time the following executes.
            const { location } = window;
            if (anonymousdomain) {
                const search = location && location.search;
                if ((search && search.indexOf('login=true') !== -1)
                    || this.token) {
                    configDomain = domain;
                }
            }
            // eslint-disable-next-line no-param-reassign
            jid = configDomain || (location && location.hostname);
        }
        return this._connect(jid, password);
    }
    /**
     * Joins or creates a muc with the provided jid, created from the passed
     * in room name and muc host and onCreateResource result.
     *
     * @param {string} roomName - The name of the muc to join.
     * @param {Object} options - Configuration for how to join the muc.
     * @param {Function} [onCreateResource] - Callback to invoke when a resource
     * is to be added to the jid.
     * @returns {Promise} Resolves with an instance of a strophe muc.
     */
    createRoom(roomName, options, onCreateResource) {
        // Support passing the domain in a String object as part of the room name.
        const domain = roomName.domain || options.customDomain;
        // There are cases (when using subdomain) where muc can hold an uppercase part
        let roomjid = `${this.getRoomJid(roomName, domain)}/`;
        const mucNickname = onCreateResource
            ? onCreateResource(this.connection.jid, this.authenticatedUser)
            : _util_RandomUtil__WEBPACK_IMPORTED_MODULE_13___default().randomHexString(8).toLowerCase();
        logger.info(`JID ${this.connection.jid} using MUC nickname ${mucNickname}`);
        roomjid += mucNickname;
        return this.connection.emuc.createRoom(roomjid, null, options);
    }
    /**
     * Returns the room JID based on the passed room name and domain.
     *
     * @param {string} roomName - The room name.
     * @param {string} domain - The domain.
     * @returns {string} - The room JID.
     */
    getRoomJid(roomName, domain) {
        return `${roomName}@${domain ? domain : this.options.hosts.muc.toLowerCase()}`;
    }
    /**
     * Check if a room with the passed JID is already created.
     *
     * @param {string} roomJid - The JID of the room.
     * @returns {boolean}
     */
    isRoomCreated(roomName, domain) {
        return this.connection.emuc.isRoomCreated(this.getRoomJid(roomName, domain));
    }
    /**
     * Returns the jid of the participant associated with the Strophe connection.
     *
     * @returns {string} The jid of the participant.
     */
    getJid() {
        return this.connection.jid;
    }
    /**
     * Returns the logs from strophe.jingle.
     * @returns {Object}
     */
    getJingleLog() {
        const jingle = this.connection.jingle;
        return jingle ? jingle.getLog() : {};
    }
    /**
     * Returns the logs from strophe.
     */
    getXmppLog() {
        return (this.connection.logger || {}).log || null;
    }
    /**
     *
     */
    dial(...args) {
        this.connection.rayo.dial(...args);
    }
    /**
     * Pings the server.
     * @param timeout how many ms before a timeout should occur.
     * @returns {Promise} resolved on ping success and reject on an error or
     * a timeout.
     */
    ping(timeout) {
        return new Promise((resolve, reject) => {
            this.connection.ping.ping(this.connection.pingDomain, resolve, reject, timeout);
        });
    }
    /**
     *
     */
    getSessions() {
        return this.connection.jingle.sessions;
    }
    /**
     * Disconnects this from the XMPP server (if this is connected).
     *
     * @param {Object} ev - Optionally, the event which triggered the necessity to
     * disconnect from the XMPP server (e.g. beforeunload, unload).
     * @returns {Promise} - Resolves when the disconnect process is finished or rejects with an error.
     */
    disconnect(ev) {
        if (this.disconnectInProgress) {
            return this.disconnectInProgress;
        }
        else if (!this.connection) {
            return Promise.resolve();
        }
        this.disconnectInProgress = new Promise(resolve => {
            const disconnectListener = (credentials, status) => {
                if (status === strophe_js__WEBPACK_IMPORTED_MODULE_2__.Strophe.Status.DISCONNECTED) {
                    this.eventEmitter.removeListener(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_6__.XMPPEvents.CONNECTION_STATUS_CHANGED, disconnectListener);
                    resolve();
                }
            };
            this.eventEmitter.on(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_6__.XMPPEvents.CONNECTION_STATUS_CHANGED, disconnectListener);
        });
        this._cleanupXmppConnection(ev);
        return this.disconnectInProgress;
    }
    /**
     * The method is supposed to gracefully close the XMPP connection and the main goal is to make sure that the current
     * participant will be removed from the conference XMPP MUC, so that it doesn't leave a "ghost" participant behind.
     *
     * @param {Object} ev - Optionally, the event which triggered the necessity to disconnect from the XMPP server
     * (e.g. beforeunload, unload).
     * @private
     * @returns {void}
     */
    _cleanupXmppConnection(ev) {
        // XXX Strophe is asynchronously sending by default. Unfortunately, that means that there may not be enough time
        // to send an unavailable presence or disconnect at all. Switching Strophe to synchronous sending is not much of
        // an option because it may lead to a noticeable delay in navigating away from the current location. As
        // a compromise, we will try to increase the chances of sending an unavailable presence and/or disconnecting
        // within the short time span that we have upon unloading by invoking flush() on the connection. We flush() once
        // before disconnect() in order to attempt to have its unavailable presence at the top of the send queue. We
        // flush() once more after disconnect() in order to attempt to have its unavailable presence sent as soon as
        // possible.
        !this.connection.isUsingWebSocket && this.connection.flush();
        if (!this.connection.isUsingWebSocket && ev !== null && typeof ev !== 'undefined') {
            const evType = ev.type;
            if (evType === 'beforeunload' || evType === 'unload') {
                // XXX Whatever we said above, synchronous sending is the best (known) way to properly disconnect from
                // the XMPP server. Consequently, it may be fine to have the source code and comment it in or out
                // depending on whether we want to run with it for some time.
                this.connection.options.sync = true;
                // This is needed in some browsers where sync xhr sending is disabled by default on unload.
                if (this.connection.sendUnavailableBeacon()) {
                    return;
                }
            }
        }
        this.connection.disconnect();
        if (this.connection.options.sync !== true) {
            this.connection.flush();
        }
    }
    /**
     *
     */
    _initStrophePlugins() {
        const iceConfig = {
            jvb: { iceServers: [] },
            p2p: { iceServers: [] }
        };
        const p2pStunServers = (this.options.p2p
            && this.options.p2p.stunServers) || DEFAULT_STUN_SERVERS;
        if (Array.isArray(p2pStunServers)) {
            logger.info('P2P STUN servers: ', p2pStunServers);
            iceConfig.p2p.iceServers = p2pStunServers;
        }
        if (this.options.p2p && this.options.p2p.iceTransportPolicy) {
            logger.info('P2P ICE transport policy: ', this.options.p2p.iceTransportPolicy);
            iceConfig.p2p.iceTransportPolicy
                = this.options.p2p.iceTransportPolicy;
        }
        this.connection.addConnectionPlugin('emuc', new _strophe_emuc__WEBPACK_IMPORTED_MODULE_16__["default"](this));
        this.connection.addConnectionPlugin('jingle', new _strophe_jingle__WEBPACK_IMPORTED_MODULE_17__["default"](this, this.eventEmitter, iceConfig));
        this.connection.addConnectionPlugin('rayo', new _strophe_rayo__WEBPACK_IMPORTED_MODULE_19__["default"]());
    }
    /**
     * Returns details about connection failure. Shard change or is it after
     * suspend.
     * @returns {object} contains details about a connection failure.
     * @private
     */
    _getConnectionFailedReasonDetails() {
        const details = {};
        // check for moving between shard if information is available
        if (this.options.deploymentInfo
            && this.options.deploymentInfo.shard
            && this.connection.lastResponseHeaders) {
            // split headers by line
            const headersArr = this.connection.lastResponseHeaders
                .trim().split(/[\r\n]+/);
            const headers = {};
            headersArr.forEach(line => {
                const parts = line.split(': ');
                const header = parts.shift();
                const value = parts.join(': ');
                headers[header] = value;
            });
            /* eslint-disable camelcase */
            details.shard_changed
                = this.options.deploymentInfo.shard
                    !== headers['x-jitsi-shard'];
            /* eslint-enable camelcase */
        }
        /* eslint-disable camelcase */
        // check for possible suspend
        details.suspend_time = this.connection.ping.getPingSuspendTime();
        details.time_since_last_success = this.connection.getTimeSinceLastSuccess();
        /* eslint-enable camelcase */
        return details;
    }
    /**
     * Notifies speaker stats component if available that we are the new
     * dominant speaker in the conference.
     * @param {String} roomJid - The room jid where the speaker event occurred.
     * @param {boolean} silence - Whether the dominant speaker is silent or not.
     */
    sendDominantSpeakerEvent(roomJid, silence) {
        // no speaker stats component advertised
        if (!this.speakerStatsComponentAddress || !roomJid) {
            return;
        }
        const msg = (0,strophe_js__WEBPACK_IMPORTED_MODULE_2__.$msg)({ to: this.speakerStatsComponentAddress });
        msg.c('speakerstats', {
            xmlns: 'http://jitsi.org/jitmeet',
            room: roomJid,
            silence
        })
            .up();
        this.connection.send(msg);
    }
    /**
     * Sends face landmarks to speaker stats component.
     * @param {String} roomJid - The room jid where the speaker event occurred.
     * @param {Object} payload - The expression to be sent to the speaker stats.
     */
    sendFaceLandmarksEvent(roomJid, payload) {
        // no speaker stats component advertised
        if (!this.speakerStatsComponentAddress || !roomJid) {
            return;
        }
        const msg = (0,strophe_js__WEBPACK_IMPORTED_MODULE_2__.$msg)({ to: this.speakerStatsComponentAddress });
        msg.c('faceLandmarks', {
            xmlns: 'http://jitsi.org/jitmeet',
            room: roomJid,
            faceExpression: payload.faceExpression,
            timestamp: payload.timestamp,
            duration: payload.duration
        }).up();
        this.connection.send(msg);
    }
    /**
     * Check if the given argument is a valid JSON ENDPOINT_MESSAGE string by
     * parsing it and checking if it has a field called 'type'.
     *
     * @param {string} jsonString check if this string is a valid json string
     * and contains the special structure.
     * @returns {boolean, object} if given object is a valid JSON string, return
     * the json object. Otherwise, returns false.
     */
    tryParseJSONAndVerify(jsonString) {
        // ignore empty strings, like message errors
        if (!jsonString) {
            return false;
        }
        try {
            const json = JSON.parse(jsonString);
            // Handle non-exception-throwing cases:
            // Neither JSON.parse(false) or JSON.parse(1234) throw errors,
            // hence the type-checking,
            // but... JSON.parse(null) returns null, and
            // typeof null === "object",
            // so we must check for that, too.
            // Thankfully, null is falsey, so this suffices:
            if (json && typeof json === 'object') {
                const type = json[JITSI_MEET_MUC_TYPE];
                if (typeof type !== 'undefined') {
                    return json;
                }
                logger.debug('parsing valid json but does not have correct '
                    + 'structure', 'topic: ', type);
            }
        }
        catch (e) {
            logger.error(`Error parsing json ${jsonString}`, e);
            return false;
        }
        return false;
    }
    /**
     * A private message is received, message that is not addressed to the muc.
     * We expect private message coming from plugins component if it is
     * enabled and running.
     *
     * @param {string} msg - The message.
     */
    _onPrivateMessage(msg) {
        const from = msg.getAttribute('from');
        if (!this._components.includes(from)) {
            return true;
        }
        const jsonMessage = jquery__WEBPACK_IMPORTED_MODULE_1___default()(msg).find('>json-message')
            .text();
        const parsedJson = this.tryParseJSONAndVerify(jsonMessage);
        if (!parsedJson) {
            return true;
        }
        if (parsedJson[JITSI_MEET_MUC_TYPE] === 'speakerstats' && parsedJson.users) {
            this.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_6__.XMPPEvents.SPEAKER_STATS_RECEIVED, parsedJson.users);
        }
        else if (parsedJson[JITSI_MEET_MUC_TYPE] === 'conference_duration' && parsedJson.created_timestamp) {
            this.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_6__.XMPPEvents.CONFERENCE_TIMESTAMP_RECEIVED, parsedJson.created_timestamp);
        }
        else if (parsedJson[JITSI_MEET_MUC_TYPE] === 'av_moderation') {
            this.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_6__.XMPPEvents.AV_MODERATION_RECEIVED, parsedJson);
        }
        else if (parsedJson[JITSI_MEET_MUC_TYPE] === 'breakout_rooms') {
            this.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_6__.XMPPEvents.BREAKOUT_ROOMS_EVENT, parsedJson);
        }
        else if (parsedJson[JITSI_MEET_MUC_TYPE] === 'room_metadata') {
            this.eventEmitter.emit(_service_xmpp_XMPPEvents__WEBPACK_IMPORTED_MODULE_6__.XMPPEvents.ROOM_METADATA_EVENT, parsedJson);
        }
        return true;
    }
    /**
     * Sends deployment info to stats if not sent already.
     * We want to try sending it on failure to connect
     * or when we get a sys message(from jiconop2)
     * or after success or failure of disco-info
     * @param force Whether to force sending without checking anything.
     * @private
     */
    _maybeSendDeploymentInfoStat(force) {
        const acceptedStatuses = [
            strophe_js__WEBPACK_IMPORTED_MODULE_2__.Strophe.Status.ERROR,
            strophe_js__WEBPACK_IMPORTED_MODULE_2__.Strophe.Status.CONNFAIL,
            strophe_js__WEBPACK_IMPORTED_MODULE_2__.Strophe.Status.AUTHFAIL,
            strophe_js__WEBPACK_IMPORTED_MODULE_2__.Strophe.Status.DISCONNECTED,
            strophe_js__WEBPACK_IMPORTED_MODULE_2__.Strophe.Status.CONNTIMEOUT
        ];
        if (!force && !(acceptedStatuses.includes(this.connection.status) && this.sendDeploymentInfo)) {
            return;
        }
        // Log deployment-specific information, if available. Defined outside
        // the application by individual deployments
        const aprops = this.options.deploymentInfo;
        if (aprops && Object.keys(aprops).length > 0) {
            const logObject = {};
            for (const attr in aprops) {
                if (aprops.hasOwnProperty(attr)) {
                    logObject[attr] = aprops[attr];
                }
            }
            // Let's push to analytics any updates that may have come from the backend
            _statistics_statistics__WEBPACK_IMPORTED_MODULE_10__["default"].analytics.addPermanentProperties(Object.assign({}, logObject));
            logObject.id = 'deployment_info';
            const entry = JSON.stringify(logObject);
            _statistics_statistics__WEBPACK_IMPORTED_MODULE_10__["default"].sendLog(entry);
            logger.info(entry);
        }
        this.sendDeploymentInfo = false;
    }
}
//# sourceMappingURL=xmpp.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/RTC/BridgeVideoType.js":
/*!************************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/service/RTC/BridgeVideoType.js ***!
  \************************************************************************************/
/***/ ((module) => {

/**
 * Enumeration of the video types that are signaled to the bridge
 * @type {{CAMERA: string, DESKTOP: string, DESKTOP_HIGH_FPS: string, NONE: string}}
 */
const BridgeVideoType = {
    /**
     * The camera video type.
     */
    CAMERA: 'camera',
    /**
     * The low fps desktop video type.
     */
    DESKTOP: 'desktop',
    /**
     * The high fps desktop video type.
     */
    DESKTOP_HIGH_FPS: 'desktop_high_fps',
    /**
     * Video type when no local source is present.
     */
    NONE: 'none'
};
module.exports = BridgeVideoType;
//# sourceMappingURL=BridgeVideoType.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/RTC/CameraFacingMode.js":
/*!*************************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/service/RTC/CameraFacingMode.js ***!
  \*************************************************************************************/
/***/ ((module) => {

/**
 * The possible camera facing modes. For now support only 'user' and
 * 'environment' because 'left' and 'right' are not used anywhere in our
 * projects at the time of this writing. For more information please refer to
 * https://w3c.github.io/mediacapture-main/getusermedia.html
 * #def-constraint-facingMode.
 *
 * @enum {string}
 */
const CameraFacingMode = {
    /**
     * The mode which specifies the environment-facing camera.
     */
    ENVIRONMENT: 'environment',
    /**
     * The mode which specifies the user-facing camera.
     */
    USER: 'user'
};
module.exports = CameraFacingMode;
//# sourceMappingURL=CameraFacingMode.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/RTC/CodecMimeType.js":
/*!**********************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/service/RTC/CodecMimeType.js ***!
  \**********************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   CodecMimeType: () => (/* binding */ CodecMimeType),
/* harmony export */   "default": () => (__WEBPACK_DEFAULT_EXPORT__)
/* harmony export */ });
/**
 * Enumeration of the codec mime types
 * @type {{AV1: string, H264: string, OPUS: string, ULPFEC: string, VP8: string, VP9: string}}
 */
const CodecMimeType = {
    /**
     * AV1 codec mime type.
     */
    AV1: 'av1',
    /**
     * The h264 codec mime type.
     */
    H264: 'h264',
    /**
     * The opus codec mime type.
     */
    OPUS: 'opus',
    /**
     * The ulpfec codec mime type.
     */
    ULPFEC: 'ulpfec',
    /**
     * The vp8 codec mime type.
     */
    VP8: 'vp8',
    /**
     * The vp9 codec mime type.
     */
    VP9: 'vp9'
};
/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (CodecMimeType);
//# sourceMappingURL=CodecMimeType.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/RTC/MediaDirection.js":
/*!***********************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/service/RTC/MediaDirection.js ***!
  \***********************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   MediaDirection: () => (/* binding */ MediaDirection)
/* harmony export */ });
/**
 * Enumeration of the media direction types.
 */
var MediaDirection;
(function (MediaDirection) {
    /**
     * Media is send and receive is suspended.
     */
    MediaDirection["INACTIVE"] = "inactive";
    /**
     * Media is only received from remote peer.
     */
    MediaDirection["RECVONLY"] = "recvonly";
    /**
     * Media is only sent to the remote peer.
     */
    MediaDirection["SENDONLY"] = "sendonly";
    /**
     * Media is sent and received.
     */
    MediaDirection["SENDRECV"] = "sendrecv";
})(MediaDirection || (MediaDirection = {}));
;
//# sourceMappingURL=MediaDirection.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/RTC/MediaType.js":
/*!******************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/service/RTC/MediaType.js ***!
  \******************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   MediaType: () => (/* binding */ MediaType)
/* harmony export */ });
var MediaType;
(function (MediaType) {
    /**
     * The audio type.
     */
    MediaType["AUDIO"] = "audio";
    /**
     * The video type.
     */
    MediaType["VIDEO"] = "video";
})(MediaType || (MediaType = {}));
//# sourceMappingURL=MediaType.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/RTC/RTCEvents.js":
/*!******************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/service/RTC/RTCEvents.js ***!
  \******************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   AUDIO_OUTPUT_DEVICE_CHANGED: () => (/* binding */ AUDIO_OUTPUT_DEVICE_CHANGED),
/* harmony export */   AUDIO_SSRCS_REMAPPED: () => (/* binding */ AUDIO_SSRCS_REMAPPED),
/* harmony export */   CREATE_ANSWER_FAILED: () => (/* binding */ CREATE_ANSWER_FAILED),
/* harmony export */   CREATE_OFFER_FAILED: () => (/* binding */ CREATE_OFFER_FAILED),
/* harmony export */   DATA_CHANNEL_CLOSED: () => (/* binding */ DATA_CHANNEL_CLOSED),
/* harmony export */   DATA_CHANNEL_OPEN: () => (/* binding */ DATA_CHANNEL_OPEN),
/* harmony export */   DEVICE_LIST_AVAILABLE: () => (/* binding */ DEVICE_LIST_AVAILABLE),
/* harmony export */   DEVICE_LIST_CHANGED: () => (/* binding */ DEVICE_LIST_CHANGED),
/* harmony export */   DEVICE_LIST_WILL_CHANGE: () => (/* binding */ DEVICE_LIST_WILL_CHANGE),
/* harmony export */   DOMINANT_SPEAKER_CHANGED: () => (/* binding */ DOMINANT_SPEAKER_CHANGED),
/* harmony export */   ENDPOINT_CONN_STATUS_CHANGED: () => (/* binding */ ENDPOINT_CONN_STATUS_CHANGED),
/* harmony export */   ENDPOINT_MESSAGE_RECEIVED: () => (/* binding */ ENDPOINT_MESSAGE_RECEIVED),
/* harmony export */   ENDPOINT_STATS_RECEIVED: () => (/* binding */ ENDPOINT_STATS_RECEIVED),
/* harmony export */   FORWARDED_SOURCES_CHANGED: () => (/* binding */ FORWARDED_SOURCES_CHANGED),
/* harmony export */   LASTN_VALUE_CHANGED: () => (/* binding */ LASTN_VALUE_CHANGED),
/* harmony export */   LOCAL_TRACK_MAX_ENABLED_RESOLUTION_CHANGED: () => (/* binding */ LOCAL_TRACK_MAX_ENABLED_RESOLUTION_CHANGED),
/* harmony export */   LOCAL_TRACK_SSRC_UPDATED: () => (/* binding */ LOCAL_TRACK_SSRC_UPDATED),
/* harmony export */   LOCAL_UFRAG_CHANGED: () => (/* binding */ LOCAL_UFRAG_CHANGED),
/* harmony export */   PERMISSIONS_CHANGED: () => (/* binding */ PERMISSIONS_CHANGED),
/* harmony export */   REMOTE_TRACK_ADDED: () => (/* binding */ REMOTE_TRACK_ADDED),
/* harmony export */   REMOTE_TRACK_MUTE: () => (/* binding */ REMOTE_TRACK_MUTE),
/* harmony export */   REMOTE_TRACK_REMOVED: () => (/* binding */ REMOTE_TRACK_REMOVED),
/* harmony export */   REMOTE_TRACK_UNMUTE: () => (/* binding */ REMOTE_TRACK_UNMUTE),
/* harmony export */   REMOTE_UFRAG_CHANGED: () => (/* binding */ REMOTE_UFRAG_CHANGED),
/* harmony export */   RTCEvents: () => (/* binding */ RTCEvents),
/* harmony export */   SENDER_VIDEO_CONSTRAINTS_CHANGED: () => (/* binding */ SENDER_VIDEO_CONSTRAINTS_CHANGED),
/* harmony export */   SET_LOCAL_DESCRIPTION_FAILED: () => (/* binding */ SET_LOCAL_DESCRIPTION_FAILED),
/* harmony export */   SET_REMOTE_DESCRIPTION_FAILED: () => (/* binding */ SET_REMOTE_DESCRIPTION_FAILED),
/* harmony export */   TRACK_ATTACHED: () => (/* binding */ TRACK_ATTACHED),
/* harmony export */   VIDEO_SSRCS_REMAPPED: () => (/* binding */ VIDEO_SSRCS_REMAPPED),
/* harmony export */   "default": () => (__WEBPACK_DEFAULT_EXPORT__)
/* harmony export */ });
var RTCEvents;
(function (RTCEvents) {
    /**
     * Indicates error while create answer call.
     */
    RTCEvents["CREATE_ANSWER_FAILED"] = "rtc.create_answer_failed";
    /**
     * Indicates error while create offer call.
     */
    RTCEvents["CREATE_OFFER_FAILED"] = "rtc.create_offer_failed";
    RTCEvents["DATA_CHANNEL_OPEN"] = "rtc.data_channel_open";
    RTCEvents["DATA_CHANNEL_CLOSED"] = "rtc.data_channel_closed";
    RTCEvents["ENDPOINT_CONN_STATUS_CHANGED"] = "rtc.endpoint_conn_status_changed";
    RTCEvents["DOMINANT_SPEAKER_CHANGED"] = "rtc.dominant_speaker_changed";
    RTCEvents["FORWARDED_SOURCES_CHANGED"] = "rtc.forwarded_sources_changed";
    /**
     * Event emitted when the user granted/blocked a permission for the camera / mic.
     * Used to keep track of the granted permissions on browsers which don't
     * support the Permissions API.
     */
    RTCEvents["PERMISSIONS_CHANGED"] = "rtc.permissions_changed";
    RTCEvents["SENDER_VIDEO_CONSTRAINTS_CHANGED"] = "rtc.sender_video_constraints_changed";
    /**
     * Event emitted when {@link RTC.setLastN} method is called to update with
     * the new value set.
     * The first argument is the value passed to {@link RTC.setLastN}.
     */
    RTCEvents["LASTN_VALUE_CHANGED"] = "rtc.lastn_value_changed";
    /**
     * Event emitted when ssrc for a local track is extracted and stored
     * in {@link TraceablePeerConnection}.
     * @param {JitsiLocalTrack} track which ssrc was updated
     * @param {string} ssrc that was stored
     */
    RTCEvents["LOCAL_TRACK_SSRC_UPDATED"] = "rtc.local_track_ssrc_updated";
    /**
     * The max enabled resolution of a local video track was changed.
     */
    RTCEvents["LOCAL_TRACK_MAX_ENABLED_RESOLUTION_CHANGED"] = "rtc.local_track_max_enabled_resolution_changed";
    RTCEvents["TRACK_ATTACHED"] = "rtc.track_attached";
    /**
     * Event fired when we remote track is added to the conference.
     * 1st event argument is the added <tt>JitsiRemoteTrack</tt> instance.
     **/
    RTCEvents["REMOTE_TRACK_ADDED"] = "rtc.remote_track_added";
    // FIXME get rid of this event in favour of NO_DATA_FROM_SOURCE event
    // (currently implemented for local tracks only)
    RTCEvents["REMOTE_TRACK_MUTE"] = "rtc.remote_track_mute";
    /**
     * Indicates that the remote track has been removed from the conference.
     * 1st event argument is the removed {@link JitsiRemoteTrack} instance.
     */
    RTCEvents["REMOTE_TRACK_REMOVED"] = "rtc.remote_track_removed";
    // FIXME get rid of this event in favour of NO_DATA_FROM_SOURCE event
    // (currently implemented for local tracks only)
    RTCEvents["REMOTE_TRACK_UNMUTE"] = "rtc.remote_track_unmute";
    /**
     * Indicates error while set local description.
     */
    RTCEvents["SET_LOCAL_DESCRIPTION_FAILED"] = "rtc.set_local_description_failed";
    /**
     * Indicates error while set remote description.
     */
    RTCEvents["SET_REMOTE_DESCRIPTION_FAILED"] = "rtc.set_remote_description_failed";
    RTCEvents["AUDIO_OUTPUT_DEVICE_CHANGED"] = "rtc.audio_output_device_changed";
    RTCEvents["DEVICE_LIST_CHANGED"] = "rtc.device_list_changed";
    /**
     * Indicates that the list with available devices will change.
     */
    RTCEvents["DEVICE_LIST_WILL_CHANGE"] = "rtc.device_list_will_change";
    RTCEvents["DEVICE_LIST_AVAILABLE"] = "rtc.device_list_available";
    /**
     * Indicates that a message from another participant is received on
     * data channel.
     */
    RTCEvents["ENDPOINT_MESSAGE_RECEIVED"] = "rtc.endpoint_message_received";
    /**
     * Indicates that the remote endpoint stats have been received on data channel.
     */
    RTCEvents["ENDPOINT_STATS_RECEIVED"] = "rtc.endpoint_stats_received";
    /**
     * Designates an event indicating that the local ICE username fragment of
     * the jingle session has changed.
     * The first argument of the vent is <tt>TraceablePeerConnection</tt> which
     * is the source of the event.
     * The second argument is the actual "ufrag" string.
     */
    RTCEvents["LOCAL_UFRAG_CHANGED"] = "rtc.local_ufrag_changed";
    /**
     * Designates an event indicating that the local ICE username fragment of
     * the jingle session has changed.
     * The first argument of the vent is <tt>TraceablePeerConnection</tt> which
     * is the source of the event.
     * The second argument is the actual "ufrag" string.
     */
    RTCEvents["REMOTE_UFRAG_CHANGED"] = "rtc.remote_ufrag_changed";
    /**
     * Designates an event indicating that some received video SSRCs will now map to
     * new remote sources.
     */
    RTCEvents["VIDEO_SSRCS_REMAPPED"] = "rtc.video_ssrcs_remapped";
    /**
     * Designates an event indicating that some received audio SSRCs will now map to
     * new remote sources.
     */
    RTCEvents["AUDIO_SSRCS_REMAPPED"] = "rtc.audio_ssrcs_remapped";
})(RTCEvents || (RTCEvents = {}));
;
const CREATE_ANSWER_FAILED = RTCEvents.CREATE_ANSWER_FAILED;
const CREATE_OFFER_FAILED = RTCEvents.CREATE_OFFER_FAILED;
const DATA_CHANNEL_OPEN = RTCEvents.DATA_CHANNEL_OPEN;
const DATA_CHANNEL_CLOSED = RTCEvents.DATA_CHANNEL_CLOSED;
const ENDPOINT_CONN_STATUS_CHANGED = RTCEvents.ENDPOINT_CONN_STATUS_CHANGED;
const DOMINANT_SPEAKER_CHANGED = RTCEvents.DOMINANT_SPEAKER_CHANGED;
const FORWARDED_SOURCES_CHANGED = RTCEvents.FORWARDED_SOURCES_CHANGED;
const PERMISSIONS_CHANGED = RTCEvents.PERMISSIONS_CHANGED;
const SENDER_VIDEO_CONSTRAINTS_CHANGED = RTCEvents.SENDER_VIDEO_CONSTRAINTS_CHANGED;
const LASTN_VALUE_CHANGED = RTCEvents.LASTN_VALUE_CHANGED;
const LOCAL_TRACK_SSRC_UPDATED = RTCEvents.LOCAL_TRACK_SSRC_UPDATED;
const LOCAL_TRACK_MAX_ENABLED_RESOLUTION_CHANGED = RTCEvents.LOCAL_TRACK_MAX_ENABLED_RESOLUTION_CHANGED;
const TRACK_ATTACHED = RTCEvents.TRACK_ATTACHED;
const REMOTE_TRACK_ADDED = RTCEvents.REMOTE_TRACK_ADDED;
const REMOTE_TRACK_MUTE = RTCEvents.REMOTE_TRACK_MUTE;
const REMOTE_TRACK_REMOVED = RTCEvents.REMOTE_TRACK_REMOVED;
const REMOTE_TRACK_UNMUTE = RTCEvents.REMOTE_TRACK_UNMUTE;
const SET_LOCAL_DESCRIPTION_FAILED = RTCEvents.SET_LOCAL_DESCRIPTION_FAILED;
const SET_REMOTE_DESCRIPTION_FAILED = RTCEvents.SET_REMOTE_DESCRIPTION_FAILED;
const AUDIO_OUTPUT_DEVICE_CHANGED = RTCEvents.AUDIO_OUTPUT_DEVICE_CHANGED;
const DEVICE_LIST_CHANGED = RTCEvents.DEVICE_LIST_CHANGED;
const DEVICE_LIST_WILL_CHANGE = RTCEvents.DEVICE_LIST_WILL_CHANGE;
const DEVICE_LIST_AVAILABLE = RTCEvents.DEVICE_LIST_AVAILABLE;
const ENDPOINT_MESSAGE_RECEIVED = RTCEvents.ENDPOINT_MESSAGE_RECEIVED;
const ENDPOINT_STATS_RECEIVED = RTCEvents.ENDPOINT_STATS_RECEIVED;
const LOCAL_UFRAG_CHANGED = RTCEvents.LOCAL_UFRAG_CHANGED;
const REMOTE_UFRAG_CHANGED = RTCEvents.REMOTE_UFRAG_CHANGED;
const VIDEO_SSRCS_REMAPPED = RTCEvents.VIDEO_SSRCS_REMAPPED;
const AUDIO_SSRCS_REMAPPED = RTCEvents.AUDIO_SSRCS_REMAPPED;
// TODO: this was a pre-ES6 module using module.exports = RTCEvents which doesn't translate well
// it is used in a number of places and should be updated to use the named export
/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (RTCEvents);
//# sourceMappingURL=RTCEvents.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/RTC/Resolutions.js":
/*!********************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/service/RTC/Resolutions.js ***!
  \********************************************************************************/
/***/ ((module) => {

const Resolutions = {
    '2160': {
        width: 3840,
        height: 2160
    },
    '4k': {
        width: 3840,
        height: 2160
    },
    '1080': {
        width: 1920,
        height: 1080
    },
    'fullhd': {
        width: 1920,
        height: 1080
    },
    '720': {
        width: 1280,
        height: 720
    },
    'hd': {
        width: 1280,
        height: 720
    },
    '540': {
        width: 960,
        height: 540
    },
    'qhd': {
        width: 960,
        height: 540
    },
    '480': {
        width: 640,
        height: 480
    },
    'vga': {
        width: 640,
        height: 480
    },
    '360': {
        width: 640,
        height: 360
    },
    '240': {
        width: 320,
        height: 240
    },
    '180': {
        width: 320,
        height: 180
    }
};
module.exports = Resolutions;
//# sourceMappingURL=Resolutions.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/RTC/SignalingEvents.js":
/*!************************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/service/RTC/SignalingEvents.js ***!
  \************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   PEER_MUTED_CHANGED: () => (/* binding */ PEER_MUTED_CHANGED),
/* harmony export */   PEER_VIDEO_TYPE_CHANGED: () => (/* binding */ PEER_VIDEO_TYPE_CHANGED),
/* harmony export */   SOURCE_MUTED_CHANGED: () => (/* binding */ SOURCE_MUTED_CHANGED),
/* harmony export */   SOURCE_UPDATED: () => (/* binding */ SOURCE_UPDATED),
/* harmony export */   SOURCE_VIDEO_TYPE_CHANGED: () => (/* binding */ SOURCE_VIDEO_TYPE_CHANGED),
/* harmony export */   SignalingEvents: () => (/* binding */ SignalingEvents)
/* harmony export */ });
var SignalingEvents;
(function (SignalingEvents) {
    /**
     * Event triggered when participant's muted status changes.
     *
     * @param {string} endpointId the track owner's identifier (MUC nickname)
     * @param {MediaType} mediaType "audio" or "video"
     * @param {boolean} isMuted the new muted state
     */
    SignalingEvents["PEER_MUTED_CHANGED"] = "signaling.peerMuted";
    /**
     * Event triggered when participant's video type changes.
     *
     * @param {string} endpointId the video owner's ID (MUC nickname)
     * @param {VideoType} videoType the new value
     */
    SignalingEvents["PEER_VIDEO_TYPE_CHANGED"] = "signaling.peerVideoType";
    /**
     * Event triggered when source's muted status changes.
     *
     * @param {string} sourceName - The name of the source.
     * @param {boolean} isMuted - The new muted state.
     */
    SignalingEvents["SOURCE_MUTED_CHANGED"] = "signaling.sourceMuted";
    /**
     * Event triggered when presence for a source is received.
     *
     * @param {string} sourceName - The name of the source.
     * @param {string} endpointId - The endpoint id.
     * @param {boolean} muted - The new muted state.
     * @param {string} videoType - The video type of the source.
     */
    SignalingEvents["SOURCE_UPDATED"] = "signaling.sourceUpdated";
    /**
     * Event triggered when source's video type changes.
     *
     * @param {string} source - The name of the source.
     * @param {VideoType} videoType - The new value.
     */
    SignalingEvents["SOURCE_VIDEO_TYPE_CHANGED"] = "signaling.sourceVideoType";
})(SignalingEvents || (SignalingEvents = {}));
// exported for backward compatibility
const PEER_MUTED_CHANGED = SignalingEvents.PEER_MUTED_CHANGED;
const PEER_VIDEO_TYPE_CHANGED = SignalingEvents.PEER_VIDEO_TYPE_CHANGED;
const SOURCE_MUTED_CHANGED = SignalingEvents.SOURCE_MUTED_CHANGED;
const SOURCE_UPDATED = SignalingEvents.SOURCE_UPDATED;
const SOURCE_VIDEO_TYPE_CHANGED = SignalingEvents.SOURCE_VIDEO_TYPE_CHANGED;
//# sourceMappingURL=SignalingEvents.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/RTC/SignalingLayer.js":
/*!***********************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/service/RTC/SignalingLayer.js ***!
  \***********************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (/* binding */ SignalingLayer),
/* harmony export */   getMediaTypeFromSourceName: () => (/* binding */ getMediaTypeFromSourceName),
/* harmony export */   getSourceIndexFromSourceName: () => (/* binding */ getSourceIndexFromSourceName),
/* harmony export */   getSourceNameForJitsiTrack: () => (/* binding */ getSourceNameForJitsiTrack)
/* harmony export */ });
/* harmony import */ var _modules_util_Listenable__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../modules/util/Listenable */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/modules/util/Listenable.js");
/* harmony import */ var _service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../service/RTC/MediaType */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/RTC/MediaType.js");


/**
 * @typedef {string} EndpointId
 */
/**
 * @typedef {string} SourceName
 */
/**
 * @typedef {Object} SourceInfo
 *
 * @property {SourceName} sourceName - Name of the media source.
 * @property {boolean} [muted=false] - Tells if the source is muted (paused?).
 * @property {string} [videoType] - Type of the video for video type.
 */
/**
 * Generates a source name.
 *
 * @param {EndpointId} endpointId - Jitsi Endpoint Id.
 * @param {MediaType} mediaType - the media type string.
 * @param {number} trackIdx - Track index (or sender idx? - to be figured out) starting from 0.
 * @returns {SourceName} eg. endpointA-v0
 */
function getSourceNameForJitsiTrack(endpointId, mediaType, trackIdx) {
    const firstLetterOfMediaType = mediaType.substring(0, 1);
    return `${endpointId}-${firstLetterOfMediaType}${trackIdx}`;
}
/**
 * Extracts MediaType from give source name (must be in the correct format as generated by
 * {@link getSourceNameForJitsiTrack}).
 *
 * @param {SourceName} sourceName - the source name.
 * @returns {MediaType}
 */
function getMediaTypeFromSourceName(sourceName) {
    const firstLetterOfMediaTypeIdx = sourceName.lastIndexOf('-') + 1;
    if (firstLetterOfMediaTypeIdx <= 0) {
        throw new Error(`Invalid source name: ${sourceName}`);
    }
    const firstLetterOfMediaType = sourceName.substr(firstLetterOfMediaTypeIdx, 1);
    for (const type of Object.values(_service_RTC_MediaType__WEBPACK_IMPORTED_MODULE_1__.MediaType)) {
        if (type.substr(0, 1) === firstLetterOfMediaType) {
            return type;
        }
    }
    throw new Error(`Invalid source name: ${sourceName}`);
}
/**
 * Extracts source index (zero based) from a given source name (must be in the correct format as generated by
 * {@link getSourceNameForJitsiTrack}).
 *
 * @param {SourceName} sourceName - the source name, eg. endpointA-v0.
 * @returns {number}
 */
function getSourceIndexFromSourceName(sourceName) {
    const nameParts = sourceName.split('-');
    const trackIdx = Number(nameParts[nameParts.length - 1].substring(1));
    if (Number.isNaN(trackIdx)) {
        throw new Error(`Failed to parse track idx for source name: ${sourceName}`);
    }
    return trackIdx;
}
/**
 * An object that carries the info about specific media type advertised by
 * participant in the signaling channel.
 * @typedef {Object} PeerMediaInfo
 * @property {boolean} muted indicates if the media is currently muted
 * @property {VideoType|undefined} videoType the type of the video if applicable
 */
/**
 * Interface used to expose the information carried over the signaling channel
 * which is not available to the RTC module in the media SDP.
 *
 * @interface SignalingLayer
 */
class SignalingLayer extends _modules_util_Listenable__WEBPACK_IMPORTED_MODULE_0__["default"] {
    /**
     * Obtains the info about given media advertised in the MUC presence of
     * the participant identified by the given MUC JID.
     * @param {string} owner the MUC jid of the participant for whom
     * {@link PeerMediaInfo} will be obtained.
     * @param {MediaType} mediaType the type of the media for which presence
     * @param {SourceName} sourceName - The name of the source for which the info is to be obtained.
     * info will be obtained.
     * @return {PeerMediaInfo|null} presenceInfo an object with media presence
     * info or <tt>null</tt> either if there is no presence available for given
     * JID or if the media type given is invalid.
     *
     * @deprecated This method is to be replaced with getPeerSourceInfo.
     */
    getPeerMediaInfo(owner, mediaType, sourceName) {
        throw new Error('not implemented');
    }
    /**
     * Obtains the info about a source for given name and endpoint ID.
     * @param {EndpointId} owner - The owner's endpoint ID.
     * @param {SourceName} sourceName - The name of the source for which the info is to be obtained.
     * @returns {SourceInfo | undefined}
     */
    getPeerSourceInfo(owner, sourceName) {
        throw new Error('not implemented');
    }
    /**
     * Obtains the endpoint ID for given SSRC.
     * @param {number} ssrc the SSRC number.
     * @return {string|null} the endpoint ID for given media SSRC.
     */
    getSSRCOwner(ssrc) {
        throw new Error('not implemented');
    }
    /**
     * Obtains the source name for given SSRC.
     * @param {number} ssrc the track's SSRC identifier.
     * @returns {SourceName | undefined} the track's source name.
     */
    getTrackSourceName(ssrc) {
        throw new Error('not implemented');
    }
    /**
     * Removes the association between a given SSRC and its current owner so that it can re-used when the SSRC gets
     * remapped to another source from a different endpoint.
     * @param {number} ssrc a list of SSRCs.
     */
    removeSSRCOwners(ssrcList) {
    }
    /**
     * Set an SSRC owner.
     * @param {number} ssrc an SSRC to be owned
     * @param {string} endpointId owner's ID (MUC nickname)
     * @throws TypeError if <tt>ssrc</tt> is not a number
     */
    setSSRCOwner(ssrc, endpointId) {
    }
    /**
     * Adjusts muted status of given track.
     *
     * @param {SourceName} sourceName - the name of the track's source.
     * @param {boolean} muted - the new muted status.
     * @returns {boolean}
     */
    setTrackMuteStatus(sourceName, muted) {
    }
    /**
     * Saves the source name for a track identified by it's ssrc.
     * @param {number} ssrc the ssrc of the target track.
     * @param {SourceName} sourceName the track's source name to save.
     * @throws TypeError if <tt>ssrc</tt> is not a number
     */
    setTrackSourceName(ssrc, sourceName) {
    }
    /**
     * Sets track's video type.
     * @param {SourceName} sourceName - the track's source name.
     * @param {VideoType} videoType - the new video type.
     * @returns {boolean}
     */
    setTrackVideoType(sourceName, videoType) {
    }
    /**
     * Removes the SSRCs associated with a given endpoint from the SSRC owners.
     *
     * @param {string} id endpoint id of the participant leaving the call.
     * @returns {void}
     */
    updateSsrcOwnersOnLeave(id) {
    }
}
//# sourceMappingURL=SignalingLayer.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/RTC/VideoType.js":
/*!******************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/service/RTC/VideoType.js ***!
  \******************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   VideoType: () => (/* binding */ VideoType)
/* harmony export */ });
/**
 * Enumeration of the video types
 */
var VideoType;
(function (VideoType) {
    /**
     * The camera video type.
     */
    VideoType["CAMERA"] = "camera";
    /**
     * The desktop video type.
     */
    VideoType["DESKTOP"] = "desktop";
})(VideoType || (VideoType = {}));
;
//# sourceMappingURL=VideoType.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/authentication/AuthenticationEvents.js":
/*!****************************************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/service/authentication/AuthenticationEvents.js ***!
  \****************************************************************************************************/
/***/ ((module) => {

const AuthenticationEvents = {
    /**
     * Event callback arguments:
     * function(authenticationEnabled, userIdentity)
     * authenticationEnabled - indicates whether authentication has been enabled
     *                         in this session
     * userIdentity - if user has been logged in then it contains user name. If
     *                contains 'null' or 'undefined' then user is not logged in.
     */
    IDENTITY_UPDATED: 'authentication.identity_updated'
};
module.exports = AuthenticationEvents;
//# sourceMappingURL=AuthenticationEvents.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/connectivity/ConnectionQualityEvents.js":
/*!*****************************************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/service/connectivity/ConnectionQualityEvents.js ***!
  \*****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   ConnectionQualityEvents: () => (/* binding */ ConnectionQualityEvents),
/* harmony export */   LOCAL_STATS_UPDATED: () => (/* binding */ LOCAL_STATS_UPDATED),
/* harmony export */   REMOTE_STATS_UPDATED: () => (/* binding */ REMOTE_STATS_UPDATED)
/* harmony export */ });
var ConnectionQualityEvents;
(function (ConnectionQualityEvents) {
    /**
     * Indicates that the local connection statistics were updated.
     */
    ConnectionQualityEvents["LOCAL_STATS_UPDATED"] = "cq.local_stats_updated";
    /**
     * Indicates that the connection statistics for a particular remote participant
     * were updated.
     */
    ConnectionQualityEvents["REMOTE_STATS_UPDATED"] = "cq.remote_stats_updated";
})(ConnectionQualityEvents || (ConnectionQualityEvents = {}));
;
// exported for backward compatibility
const LOCAL_STATS_UPDATED = ConnectionQualityEvents.LOCAL_STATS_UPDATED;
const REMOTE_STATS_UPDATED = ConnectionQualityEvents.REMOTE_STATS_UPDATED;
//# sourceMappingURL=ConnectionQualityEvents.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/e2eping/E2ePingEvents.js":
/*!**************************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/service/e2eping/E2ePingEvents.js ***!
  \**************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   E2E_RTT_CHANGED: () => (/* binding */ E2E_RTT_CHANGED),
/* harmony export */   E2ePingEvents: () => (/* binding */ E2ePingEvents)
/* harmony export */ });
var E2ePingEvents;
(function (E2ePingEvents) {
    /**
     * Indicates that the end-to-end round-trip-time for a participant has changed.
     */
    E2ePingEvents["E2E_RTT_CHANGED"] = "e2eping.e2e_rtt_changed";
})(E2ePingEvents || (E2ePingEvents = {}));
;
// exported for backward compatibility
const E2E_RTT_CHANGED = E2ePingEvents.E2E_RTT_CHANGED;
//# sourceMappingURL=E2ePingEvents.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/statistics/AnalyticsEvents.js":
/*!*******************************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/service/statistics/AnalyticsEvents.js ***!
  \*******************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   ACTION_JINGLE_RESTART: () => (/* binding */ ACTION_JINGLE_RESTART),
/* harmony export */   ACTION_JINGLE_SA_TIMEOUT: () => (/* binding */ ACTION_JINGLE_SA_TIMEOUT),
/* harmony export */   ACTION_JINGLE_SI_RECEIVED: () => (/* binding */ ACTION_JINGLE_SI_RECEIVED),
/* harmony export */   ACTION_JINGLE_SI_TIMEOUT: () => (/* binding */ ACTION_JINGLE_SI_TIMEOUT),
/* harmony export */   ACTION_JINGLE_TERMINATE: () => (/* binding */ ACTION_JINGLE_TERMINATE),
/* harmony export */   ACTION_JINGLE_TR_RECEIVED: () => (/* binding */ ACTION_JINGLE_TR_RECEIVED),
/* harmony export */   ACTION_JINGLE_TR_SUCCESS: () => (/* binding */ ACTION_JINGLE_TR_SUCCESS),
/* harmony export */   ACTION_P2P_DECLINED: () => (/* binding */ ACTION_P2P_DECLINED),
/* harmony export */   ACTION_P2P_ESTABLISHED: () => (/* binding */ ACTION_P2P_ESTABLISHED),
/* harmony export */   ACTION_P2P_FAILED: () => (/* binding */ ACTION_P2P_FAILED),
/* harmony export */   ACTION_P2P_SWITCH_TO_JVB: () => (/* binding */ ACTION_P2P_SWITCH_TO_JVB),
/* harmony export */   AVAILABLE_DEVICE: () => (/* binding */ AVAILABLE_DEVICE),
/* harmony export */   AnalyticsEvents: () => (/* binding */ AnalyticsEvents),
/* harmony export */   CONNECTION_DISCONNECTED: () => (/* binding */ CONNECTION_DISCONNECTED),
/* harmony export */   FEEDBACK: () => (/* binding */ FEEDBACK),
/* harmony export */   ICE_DURATION: () => (/* binding */ ICE_DURATION),
/* harmony export */   ICE_ESTABLISHMENT_DURATION_DIFF: () => (/* binding */ ICE_ESTABLISHMENT_DURATION_DIFF),
/* harmony export */   ICE_STATE_CHANGED: () => (/* binding */ ICE_STATE_CHANGED),
/* harmony export */   NO_BYTES_SENT: () => (/* binding */ NO_BYTES_SENT),
/* harmony export */   TRACK_UNMUTED: () => (/* binding */ TRACK_UNMUTED),
/* harmony export */   TYPE_OPERATIONAL: () => (/* binding */ TYPE_OPERATIONAL),
/* harmony export */   TYPE_PAGE: () => (/* binding */ TYPE_PAGE),
/* harmony export */   TYPE_TRACK: () => (/* binding */ TYPE_TRACK),
/* harmony export */   TYPE_UI: () => (/* binding */ TYPE_UI),
/* harmony export */   createAudioOutputProblemEvent: () => (/* binding */ createAudioOutputProblemEvent),
/* harmony export */   createBridgeChannelClosedEvent: () => (/* binding */ createBridgeChannelClosedEvent),
/* harmony export */   createBridgeDownEvent: () => (/* binding */ createBridgeDownEvent),
/* harmony export */   createConferenceEvent: () => (/* binding */ createConferenceEvent),
/* harmony export */   createConnectionFailedEvent: () => (/* binding */ createConnectionFailedEvent),
/* harmony export */   createConnectionStageReachedEvent: () => (/* binding */ createConnectionStageReachedEvent),
/* harmony export */   createE2eRttEvent: () => (/* binding */ createE2eRttEvent),
/* harmony export */   createFocusLeftEvent: () => (/* binding */ createFocusLeftEvent),
/* harmony export */   createGetUserMediaEvent: () => (/* binding */ createGetUserMediaEvent),
/* harmony export */   createJingleEvent: () => (/* binding */ createJingleEvent),
/* harmony export */   createNoDataFromSourceEvent: () => (/* binding */ createNoDataFromSourceEvent),
/* harmony export */   createP2PEvent: () => (/* binding */ createP2PEvent),
/* harmony export */   createParticipantConnectionStatusEvent: () => (/* binding */ createParticipantConnectionStatusEvent),
/* harmony export */   createRemotelyMutedEvent: () => (/* binding */ createRemotelyMutedEvent),
/* harmony export */   createRtpStatsEvent: () => (/* binding */ createRtpStatsEvent),
/* harmony export */   createRttByRegionEvent: () => (/* binding */ createRttByRegionEvent),
/* harmony export */   createTrackStreamingStatusEvent: () => (/* binding */ createTrackStreamingStatusEvent),
/* harmony export */   createTransportStatsEvent: () => (/* binding */ createTransportStatsEvent),
/* harmony export */   createTtfmEvent: () => (/* binding */ createTtfmEvent)
/* harmony export */ });
/**
 * This class exports constants and factory methods related to the analytics
 * API provided by AnalyticsAdapter. In order for entries in a database to be
 * somewhat easily traceable back to the code which produced them, events sent
 * through analytics should be defined here.
 *
 * Since the AnalyticsAdapter API can be used in different ways, for some events
 * it is more convenient to just define the event name as a constant. For other
 * events a factory function is easier.
 *
 * A general approach for adding a new event:
 * 1. Determine the event type: track, UI, page, or operational. If in doubt use
 * operational.
 * 2. Determine whether the event is related to other existing events, and
 * which fields are desired to be set: name, action, actionSubject, source.
 * 3. If the name is sufficient (the other fields are not important), use a
 * constant. Otherwise use a factory function.
 *
 * Note that the AnalyticsAdapter uses the events passed to its functions for
 * its own purposes, and might modify them. Because of this, factory functions
 * should create new objects.
 *
 */
var AnalyticsEvents;
(function (AnalyticsEvents) {
    /**
     * The constant which identifies an event of type "operational".
     */
    AnalyticsEvents["TYPE_OPERATIONAL"] = "operational";
    /**
     * The constant which identifies an event of type "page".
     */
    AnalyticsEvents["TYPE_PAGE"] = "page";
    /**
     * The constant which identifies an event of type "track".
     */
    AnalyticsEvents["TYPE_TRACK"] = "track";
    /**
     * The constant which identifies an event of type "ui".
     */
    AnalyticsEvents["TYPE_UI"] = "ui";
    /**
     * The "action" value for Jingle events which indicates that the Jingle session
     * was restarted (TODO: verify/fix the documentation)
     */
    AnalyticsEvents["ACTION_JINGLE_RESTART"] = "restart";
    /**
     * The "action" value for Jingle events which indicates that a session-accept
     * timed out (TODO: verify/fix the documentation)
     */
    AnalyticsEvents["ACTION_JINGLE_SA_TIMEOUT"] = "session-accept.timeout";
    /**
     * The "action" value for Jingle events which indicates that a session-initiate
     * was received.
     */
    AnalyticsEvents["ACTION_JINGLE_SI_RECEIVED"] = "session-initiate.received";
    /**
     * The "action" value for Jingle events which indicates that a session-initiate
     * not arrived within a timeout (the value is specified in
     * the {@link JingleSessionPC}.
     */
    AnalyticsEvents["ACTION_JINGLE_SI_TIMEOUT"] = "session-initiate.timeout";
    /**
     * A constant for the "terminate" action for Jingle events. TODO: verify/fix
     * the documentation)
     */
    AnalyticsEvents["ACTION_JINGLE_TERMINATE"] = "terminate";
    /**
     * The "action" value for Jingle events which indicates that a transport-replace
     * was received.
     */
    AnalyticsEvents["ACTION_JINGLE_TR_RECEIVED"] = "transport-replace.received";
    /**
     * The "action" value for Jingle events which indicates that a transport-replace
     * succeeded (TODO: verify/fix the documentation)
     */
    AnalyticsEvents["ACTION_JINGLE_TR_SUCCESS"] = "transport-replace.success";
    /**
     * The "action" value for P2P events which indicates that P2P session initiate message has been rejected by the client
     * because the mandatory requirements were not met.
     */
    AnalyticsEvents["ACTION_P2P_DECLINED"] = "decline";
    /**
     * The "action" value for P2P events which indicates that a connection was
     * established (TODO: verify/fix the documentation)
     */
    AnalyticsEvents["ACTION_P2P_ESTABLISHED"] = "established";
    /**
     * The "action" value for P2P events which indicates that something failed.
     */
    AnalyticsEvents["ACTION_P2P_FAILED"] = "failed";
    /**
     * The "action" value for P2P events which indicates that a switch to
     * jitsi-videobridge happened.
     */
    AnalyticsEvents["ACTION_P2P_SWITCH_TO_JVB"] = "switch.to.jvb";
    /**
     * The name of an event which indicates an available device. We send one such
     * event per available device once when the available devices are first known,
     * and every time that they change
     *
     * Properties:
     *      audio_input_device_count: the number of audio input devices available at
     *          the time the event was sent.
     *      audio_output_device_count: the number of audio output devices available
     *          at the time the event was sent.
     *      video_input_device_count: the number of video input devices available at
     *          the time the event was sent.
     *      video_output_device_count: the number of video output devices available
     *          at the time the event was sent.
     *      device_id: an identifier of the device described in this event.
     *      device_group_id:
     *      device_kind: one of 'audioinput', 'audiooutput', 'videoinput' or
     *          'videooutput'.
     *      device_label: a string which describes the device.
     */
    AnalyticsEvents["AVAILABLE_DEVICE"] = "available.device";
    /**
     * This appears to be fired only in certain cases when the XMPP connection
     * disconnects (and it was intentional?). It is currently never observed to
     * fire in production.
     *
     * TODO: document
     *
     * Properties:
     *      message: an error message
     */
    AnalyticsEvents["CONNECTION_DISCONNECTED"] = "connection.disconnected";
    /**
     * Indicates that the user of the application provided feedback in terms of a
     * rating (an integer from 1 to 5) and an optional comment.
     * Properties:
     *      value: the user's rating (an integer from 1 to 5)
     *      comment: the user's comment
     */
    AnalyticsEvents["FEEDBACK"] = "feedback";
    /**
     * Indicates the duration of a particular phase of the ICE connectivity
     * establishment.
     *
     * Properties:
     *      phase: the ICE phase (e.g. 'gathering', 'checking', 'establishment')
     *      value: the duration in milliseconds.
     *      p2p: whether the associated ICE connection is p2p or towards a
     *          jitsi-videobridge
     *      initiator: whether the local Jingle peer is the initiator or responder
     *          in the Jingle session. XXX we probably actually care about the ICE
     *          role (controlling vs controlled), and we assume that this correlates
     *          with the Jingle initiator.
     */
    AnalyticsEvents["ICE_DURATION"] = "ice.duration";
    /**
     * Indicates the difference in milliseconds between the ICE establishment time
     * for the P2P and JVB connections (e.g. a value of 10 would indicate that the
     * P2P connection took 10ms more than JVB connection to establish).
     *
     * Properties:
     *      value: the difference in establishment durations in milliseconds.
     *
     */
    AnalyticsEvents["ICE_ESTABLISHMENT_DURATION_DIFF"] = "ice.establishment.duration.diff";
    /**
     * Indicates that the ICE state has changed.
     *
     * Properties:
     *      state: the ICE state which was entered (e.g. 'checking', 'connected',
     *          'completed', etc).
     *      value: the time in milliseconds (as reported by
     *          window.performance.now()) that the state change occurred.
     *      p2p: whether the associated ICE connection is p2p or towards a
     *          jitsi-videobridge
     *      signalingState: The signaling state of the associated PeerConnection
     *      reconnect: whether the associated Jingle session is in the process of
     *          reconnecting (or is it ICE? TODO: verify/fix the documentation)
     */
    AnalyticsEvents["ICE_STATE_CHANGED"] = "ice.state.changed";
    /**
     * Indicates that no bytes have been sent for the track.
     *
     * Properties:
     *      mediaType: the media type of the local track ('audio' or 'video').
     */
    AnalyticsEvents["NO_BYTES_SENT"] = "track.no-bytes-sent";
    /**
     * Indicates that a track was unmuted (?).
     *
     * Properties:
     *      mediaType: the media type of the local track ('audio' or 'video').
     *      trackType: the type of the track ('local' or 'remote').
     *      value: TODO: document
     */
    AnalyticsEvents["TRACK_UNMUTED"] = "track.unmuted";
})(AnalyticsEvents || (AnalyticsEvents = {}));
// exported for backward compatibility
const TYPE_OPERATIONAL = AnalyticsEvents.TYPE_OPERATIONAL;
const TYPE_PAGE = AnalyticsEvents.TYPE_PAGE;
const TYPE_TRACK = AnalyticsEvents.TYPE_TRACK;
const TYPE_UI = AnalyticsEvents.TYPE_UI;
const ACTION_JINGLE_RESTART = AnalyticsEvents.ACTION_JINGLE_RESTART;
const ACTION_JINGLE_SA_TIMEOUT = AnalyticsEvents.ACTION_JINGLE_SA_TIMEOUT;
const ACTION_JINGLE_SI_RECEIVED = AnalyticsEvents.ACTION_JINGLE_SI_RECEIVED;
const ACTION_JINGLE_SI_TIMEOUT = AnalyticsEvents.ACTION_JINGLE_SI_TIMEOUT;
const ACTION_JINGLE_TERMINATE = AnalyticsEvents.ACTION_JINGLE_TERMINATE;
const ACTION_JINGLE_TR_RECEIVED = AnalyticsEvents.ACTION_JINGLE_TR_RECEIVED;
const ACTION_JINGLE_TR_SUCCESS = AnalyticsEvents.ACTION_JINGLE_TR_SUCCESS;
const ACTION_P2P_DECLINED = AnalyticsEvents.ACTION_P2P_DECLINED;
const ACTION_P2P_ESTABLISHED = AnalyticsEvents.ACTION_P2P_ESTABLISHED;
const ACTION_P2P_FAILED = AnalyticsEvents.ACTION_P2P_FAILED;
const ACTION_P2P_SWITCH_TO_JVB = AnalyticsEvents.ACTION_P2P_SWITCH_TO_JVB;
const AVAILABLE_DEVICE = AnalyticsEvents.AVAILABLE_DEVICE;
const CONNECTION_DISCONNECTED = AnalyticsEvents.CONNECTION_DISCONNECTED;
const FEEDBACK = AnalyticsEvents.FEEDBACK;
const ICE_DURATION = AnalyticsEvents.ICE_DURATION;
const ICE_ESTABLISHMENT_DURATION_DIFF = AnalyticsEvents.ICE_ESTABLISHMENT_DURATION_DIFF;
const ICE_STATE_CHANGED = AnalyticsEvents.ICE_STATE_CHANGED;
const NO_BYTES_SENT = AnalyticsEvents.NO_BYTES_SENT;
const TRACK_UNMUTED = AnalyticsEvents.TRACK_UNMUTED;
/**
 * Creates an operational event which indicates that we have received a
 * "bridge down" event from jicofo.
 */
const createBridgeDownEvent = () => ({
    action: 'bridge.down',
    actionSubject: 'bridge.down',
    type: TYPE_OPERATIONAL
});
/**
 * Creates an event which indicates that the XMPP connection failed
 * @param errorType TODO
 * @param errorMessage TODO
 * @param detail connection failed details.
 */
const createConnectionFailedEvent = (errorType, errorMessage, details) => ({
    type: AnalyticsEvents.TYPE_OPERATIONAL,
    action: 'connection.failed',
    attributes: Object.assign({ 'error_type': errorType, 'error_message': errorMessage }, details)
});
/**
 * Creates a conference event.
 *
 * @param action - The action of the event.
 * @param attributes - The attributes to be added to the event.
 */
const createConferenceEvent = (action, attributes) => ({
    action,
    attributes,
    source: 'conference',
    type: AnalyticsEvents.TYPE_OPERATIONAL
});
/**
 * Creates an operational event which indicates that a particular connection
 * stage was reached (i.e. the XMPP connection transitioned to the "connected"
 * state).
 *
 * @param stage the stage which was reached
 * @param attributes additional attributes for the event. This should be an
 * object with a "value" property indicating a timestamp in milliseconds
 * relative to the beginning of the document's lifetime.
 *
 */
const createConnectionStageReachedEvent = (stage, attributes) => ({
    action: 'connection.stage.reached',
    actionSubject: stage,
    attributes,
    source: 'connection.stage.reached',
    type: AnalyticsEvents.TYPE_OPERATIONAL
});
/**
 * Creates an operational event for the end-to-end round trip time to a
 * specific remote participant.
 * @param participantId the ID of the remote participant.
 * @param region the region of the remote participant
 * @param rtt the rtt
 */
const createE2eRttEvent = (participantId, region, rtt) => ({
    attributes: {
        'participant_id': participantId,
        region,
        rtt
    },
    name: 'e2e_rtt',
    type: AnalyticsEvents.TYPE_OPERATIONAL
});
/**
 * Creates an event which indicates that the focus has left the MUC.
 */
const createFocusLeftEvent = () => ({
    action: 'focus.left',
    actionSubject: 'focus.left',
    type: AnalyticsEvents.TYPE_OPERATIONAL
});
/**
 * Creates an event related to a getUserMedia call.
 *
 * @param action the type of the result that the event represents: 'error',
 * 'success', 'warning', etc.
 * @param attributes the attributes to attach to the event.
 */
const createGetUserMediaEvent = (action, attributes = {}) => ({
    type: AnalyticsEvents.TYPE_OPERATIONAL,
    source: 'get.user.media',
    action,
    attributes
});
/**
 * Creates an event related to remote participant connection status changes.
 *
 * @param attributes the attributes to attach to the event.
 */
const createParticipantConnectionStatusEvent = (attributes = {}) => ({
    type: AnalyticsEvents.TYPE_OPERATIONAL,
    source: 'peer.conn.status',
    action: 'duration',
    attributes
});
/**
 * Creates an event related to remote track streaming status changes.
 *
 * @param attributes the attributes to attach to the event.
 */
const createTrackStreamingStatusEvent = (attributes = {}) => ({
    type: AnalyticsEvents.TYPE_OPERATIONAL,
    source: 'track.streaming.status',
    action: 'duration',
    attributes
});
/**
 * Creates an event for a Jingle-related event.
 * @param action the action of the event
 * @param attributes attributes to add to the event.
 */
const createJingleEvent = (action, attributes = {}) => ({
    type: AnalyticsEvents.TYPE_OPERATIONAL,
    action,
    source: 'jingle',
    attributes
});
/**
 * Creates an event which indicates that a local track was not able to read
 * data from its source (a camera or a microphone).
 *
 * @param mediaType the media type of the local track ('audio' or
 * 'video').
 */
const createNoDataFromSourceEvent = (mediaType, value) => ({
    attributes: {
        'media_type': mediaType,
        value
    },
    action: 'track.no.data.from.source',
    type: AnalyticsEvents.TYPE_OPERATIONAL
});
/**
 * Creates an event for a p2p-related event.
 * @param action the action of the event
 * @param attributes attributes to add to the event.
 */
const createP2PEvent = (action, attributes = {}) => ({
    type: AnalyticsEvents.TYPE_OPERATIONAL,
    action,
    source: 'p2p',
    attributes
});
/**
 * Indicates that we received a remote command to mute.
 */
const createRemotelyMutedEvent = (mediaType) => ({
    type: AnalyticsEvents.TYPE_OPERATIONAL,
    action: 'remotely.muted',
    mediaType
});
/**
 * Creates an event which contains RTP statistics such as RTT and packet loss.
 *
 * All average RTP stats are currently reported under 1 event name, but with
 * different properties that allows to distinguish between a P2P call, a
 * call relayed through TURN or the JVB, and multiparty vs 1:1.
 *
 * The structure of the event is:
 *
 * {
 *      p2p: true,
 *      conferenceSize: 2,
 *      localCandidateType: "relay",
 *      remoteCandidateType: "relay",
 *      transportType: "udp",
 *
 *      // Average RTT of 200ms
 *      "rtt.avg": 200,
 *      "rtt.samples": "[100, 200, 300]",
 *
 *      // Average packet loss of 10%
 *      "packet.loss.avg": 10,
 *      "packet.loss.samples": '[5, 10, 15]'
 *
 *      // Difference in milliseconds in the end-to-end RTT between p2p and jvb.
 *      // The e2e RTT through jvb is 15ms shorter:
 *      "rtt.diff": 15,
 *
 *      // End-to-end RTT through JVB is ms.
 *      "end2end.rtt.avg" = 100
 * }
 *
 * Note that the value of the "samples" properties are (JSON encoded) strings,
 * and not JSON arrays, as events' attributes can not be nested. The samples are
 * currently included for debug purposes only and can be removed anytime soon
 * from the structure.
 *
 * Also note that not all of values are present in each event, as values are
 * obtained and calculated as part of different process/event pipe. For example
 * {@link ConnectionAvgStats} instances are doing the reports for each
 * {@link TraceablePeerConnection} and work independently from the main stats
 * pipe.
 */
const createRtpStatsEvent = (attributes) => ({
    type: AnalyticsEvents.TYPE_OPERATIONAL,
    action: 'rtp.stats',
    attributes
});
/**
 * Creates an event which contains the round trip time (RTT) to a set of
 * regions.
 *
 * @param attributes
 */
const createRttByRegionEvent = (attributes) => ({
    type: AnalyticsEvents.TYPE_OPERATIONAL,
    action: 'rtt.by.region',
    attributes
});
/**
 * Creates an event which contains the local and remote ICE candidate types
 * for the transport that is currently selected.
 *
 * @param attributes
 */
const createTransportStatsEvent = (attributes) => ({
    type: AnalyticsEvents.TYPE_OPERATIONAL,
    action: 'transport.stats',
    attributes
});
/**
 * Creates an event which contains information about the audio output problem (the user id of the affected participant,
 * the local audio levels and the remote audio levels that triggered the event).
 *
 * @param userID - The user id of the affected participant.
 * @param localAudioLevels - The local audio levels.
 * @param remoteAudioLevels - The audio levels received from the participant.
 */
const createAudioOutputProblemEvent = (userID, localAudioLevels, remoteAudioLevels) => ({
    type: AnalyticsEvents.TYPE_OPERATIONAL,
    action: 'audio.output.problem',
    attributes: {
        userID,
        localAudioLevels,
        remoteAudioLevels
    }
});
/**
 * Creates an event which contains an information related to the bridge channel close event.
 *
 * @param code - A code from {@link https://developer.mozilla.org/en-US/docs/Web/API/CloseEvent}
 * @param reason - A string which describes the reason for closing the bridge channel.
 */
const createBridgeChannelClosedEvent = (code, reason) => ({
    type: AnalyticsEvents.TYPE_OPERATIONAL,
    action: 'bridge-channel.error',
    attributes: {
        code,
        reason
    }
});
/**
 * Creates an event which indicates the Time To First Media (TTFM).
 * It is measured in milliseconds relative to the beginning of the document's
 * lifetime (i.e. the origin used by window.performance.now()), and it excludes
 * the following:
 * 1. The delay due to getUserMedia()
 * 2. The period between the MUC being joined and the reception of the Jingle
 * session-initiate from jicofo. This is because jicofo will not start a Jingle
 * session until there are at least 2 participants in the room.
 *
 * @param attributes the attributes to add to the event. Currently used fields:
 *      mediaType: the media type of the local track ('audio' or 'video').
 *      muted: whether the track has ever been muted (?)
 *      value: the TTMF in milliseconds.
 */
const createTtfmEvent = (attributes) => createConnectionStageReachedEvent('ttfm', attributes);
//# sourceMappingURL=AnalyticsEvents.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/statistics/Events.js":
/*!**********************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/service/statistics/Events.js ***!
  \**********************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   AUDIO_LEVEL: () => (/* binding */ AUDIO_LEVEL),
/* harmony export */   BEFORE_DISPOSED: () => (/* binding */ BEFORE_DISPOSED),
/* harmony export */   BYTE_SENT_STATS: () => (/* binding */ BYTE_SENT_STATS),
/* harmony export */   CONNECTION_STATS: () => (/* binding */ CONNECTION_STATS),
/* harmony export */   Events: () => (/* binding */ Events),
/* harmony export */   LONG_TASKS_STATS: () => (/* binding */ LONG_TASKS_STATS)
/* harmony export */ });
var Events;
(function (Events) {
    /**
     * Notifies about audio level in RTP statistics by SSRC.
     *
     * @param ssrc - The synchronization source identifier (SSRC) of the
     * endpoint/participant whose audio level is being reported.
     * @param {number} audioLevel - The audio level of <tt>ssrc</tt> according to
     * RTP statistics.
     * @param {boolean} isLocal - <tt>true</tt> if <tt>ssrc</tt> identifies the
     * local endpoint/participant; otherwise, <tt>false</tt>.
     */
    Events["AUDIO_LEVEL"] = "statistics.audioLevel";
    /**
     * An event fired just before the statistics module gets disposes and it's
     * the last chance to submit some logs that will end up in stats services like
     * CallStats (if enabled).
     */
    Events["BEFORE_DISPOSED"] = "statistics.before_disposed";
    /**
     * An event carrying all statistics by ssrc.
     */
    Events["BYTE_SENT_STATS"] = "statistics.byte_sent_stats";
    /**
     * An event carrying connection statistics.
     *
     * @param {object} connectionStats - The connection statistics carried by the
     * event such as <tt>bandwidth</tt>, <tt>bitrate</tt>, <tt>packetLoss</tt>,
     * <tt>resolution</tt>, and <tt>transport</tt>.
     */
    Events["CONNECTION_STATS"] = "statistics.connectionstats";
    /**
     * An event carrying performance stats.
     */
    Events["LONG_TASKS_STATS"] = "statistics.long_tasks_stats";
})(Events || (Events = {}));
;
// exported for backward compatibility
const AUDIO_LEVEL = Events.AUDIO_LEVEL;
const BEFORE_DISPOSED = Events.BEFORE_DISPOSED;
const BYTE_SENT_STATS = Events.BYTE_SENT_STATS;
const CONNECTION_STATS = Events.CONNECTION_STATS;
const LONG_TASKS_STATS = Events.LONG_TASKS_STATS;
//# sourceMappingURL=Events.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/statistics/constants.js":
/*!*************************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/service/statistics/constants.js ***!
  \*************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   LOCAL_JID: () => (/* binding */ LOCAL_JID)
/* harmony export */ });
const LOCAL_JID = 'local';
//# sourceMappingURL=constants.js.map

/***/ }),

/***/ "./node_modules/@shren/lib-jitsi-meet/dist/esm/service/xmpp/XMPPEvents.js":
/*!********************************************************************************!*\
  !*** ./node_modules/@shren/lib-jitsi-meet/dist/esm/service/xmpp/XMPPEvents.js ***!
  \********************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   XMPPEvents: () => (/* binding */ XMPPEvents)
/* harmony export */ });
var XMPPEvents;
(function (XMPPEvents) {
    /**
     * Indicates error while adding ice candidate.
     */
    XMPPEvents["ADD_ICE_CANDIDATE_FAILED"] = "xmpp.add_ice_candidate_failed";
    // Designates an event indicating that the focus has asked us to mute our
    // audio.
    XMPPEvents["AUDIO_MUTED_BY_FOCUS"] = "xmpp.audio_muted_by_focus";
    // Designates an event indicating that the focus has asked us to disable our
    // camera.
    XMPPEvents["VIDEO_MUTED_BY_FOCUS"] = "xmpp.video_muted_by_focus";
    XMPPEvents["AUTHENTICATION_REQUIRED"] = "xmpp.authentication_required";
    XMPPEvents["BRIDGE_DOWN"] = "xmpp.bridge_down";
    /**
     * Triggered when 'session-accept' is received from the responder.
     */
    XMPPEvents["CALL_ACCEPTED"] = "xmpp.callaccepted.jingle";
    // Designates an event indicating that an offer (e.g. Jingle
    // session-initiate) was received.
    XMPPEvents["CALL_INCOMING"] = "xmpp.callincoming.jingle";
    // Triggered when Jicofo kills our media session, this can happen while
    // we're still in the MUC, when it decides to terminate the media session.
    // For example when the session is idle for too long, because we're the only
    // person in the conference room.
    XMPPEvents["CALL_ENDED"] = "xmpp.callended.jingle";
    XMPPEvents["CHAT_ERROR_RECEIVED"] = "xmpp.chat_error_received";
    XMPPEvents["SETTINGS_ERROR_RECEIVED"] = "xmpp.settings_error_received";
    // The conference properties (as advertised by jicofo) have changed
    XMPPEvents["CONFERENCE_PROPERTIES_CHANGED"] = "xmpp.conference_properties_changed";
    /**
     * This event is triggered when the ICE connects for the first time.
     */
    XMPPEvents["CONNECTION_ESTABLISHED"] = "xmpp.connection.connected";
    // Designates an event indicating that the connection to the XMPP server
    // failed.
    XMPPEvents["CONNECTION_FAILED"] = "xmpp.connection.failed";
    // Designates an event indicating that the media (ICE) connection was
    // interrupted. This should go to the RTC module.
    XMPPEvents["CONNECTION_INTERRUPTED"] = "xmpp.connection.interrupted";
    // Designates an event indicating that the media (ICE) connection was
    // restored. This should go to the RTC module.
    XMPPEvents["CONNECTION_RESTORED"] = "xmpp.connection.restored";
    // Designates an event indicating that the media (ICE) connection failed.
    // This should go to the RTC module.
    XMPPEvents["CONNECTION_ICE_FAILED"] = "xmpp.connection.ice.failed";
    // Designates an event indicating that the call has been migrated to a different
    // bridge and that the client needs to be restarted for a successful transition.
    XMPPEvents["CONNECTION_RESTARTED"] = "xmpp.connection.restart";
    /**
     * Designates an event indicating connection status changes.
     */
    XMPPEvents["CONNECTION_STATUS_CHANGED"] = "xmpp.connection.status.changed";
    // Designates an event indicating that the display name of a participant
    // has changed.
    XMPPEvents["DISPLAY_NAME_CHANGED"] = "xmpp.display_name_changed";
    /**
     * Event for incoming presence error which is for required display name.
     */
    XMPPEvents["DISPLAY_NAME_REQUIRED"] = "xmpp.display_name_required";
    /**
     * Chat room instance have been added to Strophe.emuc plugin.
     */
    XMPPEvents["EMUC_ROOM_ADDED"] = "xmpp.emuc_room_added";
    /**
     * Chat room instance have been removed from Strophe.emuc plugin.
     */
    XMPPEvents["EMUC_ROOM_REMOVED"] = "xmpp.emuc_room_removed";
    XMPPEvents["ETHERPAD"] = "xmpp.etherpad";
    XMPPEvents["FOCUS_DISCONNECTED"] = "xmpp.focus_disconnected";
    XMPPEvents["FOCUS_LEFT"] = "xmpp.focus_left";
    XMPPEvents["GRACEFUL_SHUTDOWN"] = "xmpp.graceful_shutdown";
    /**
     * Event fired when 'transport-replace' Jingle message has been received,
     * before the new offer is set on the PeerConnection.
     */
    XMPPEvents["ICE_RESTARTING"] = "rtc.ice_restarting";
    /**
     * Event fired after the 'transport-replace' message has been processed
     * and the new offer has been set successfully.
     */
    XMPPEvents["ICE_RESTART_SUCCESS"] = "rtc.ice_restart_success";
    /**
     * Designates an event indicating that we were kicked from the XMPP MUC.
     * @param {boolean} isSelfPresence - whether it is for local participant
     * or another participant.
     * @param {string} actorJid - the jid of the participant who was initiator
     * of the kick.
     * @param {?string} participantJid - when it is not a kick for local participant,
     * this is the jid of the participant which was kicked.
     */
    XMPPEvents["KICKED"] = "xmpp.kicked";
    // Designates an event indicating that our role in the XMPP MUC has changed.
    XMPPEvents["LOCAL_ROLE_CHANGED"] = "xmpp.localrole_changed";
    /**
     * Event fired when the unique meeting id is set.
     */
    XMPPEvents["MEETING_ID_SET"] = "xmpp.meeting_id_set";
    // Designates an event indicating that an XMPP message in the MUC was
    // received.
    XMPPEvents["MESSAGE_RECEIVED"] = "xmpp.message_received";
    // Designates an event indicating that an invite XMPP message in the MUC was
    // received.
    XMPPEvents["INVITE_MESSAGE_RECEIVED"] = "xmpp.invite_message_received";
    // Designates an event indicating that a private XMPP message in the MUC was
    // received.
    XMPPEvents["PRIVATE_MESSAGE_RECEIVED"] = "xmpp.private_message_received";
    // Designates an event indicating that a bot participant type had changed
    XMPPEvents["MUC_MEMBER_BOT_TYPE_CHANGED"] = "xmpp.muc_member_bot_type_changed";
    // Designates an event indicating that the XMPP MUC was destroyed.
    XMPPEvents["MUC_DESTROYED"] = "xmpp.muc_destroyed";
    // Designates an event indicating that we are currently in process of joining the XMPP MUC.
    XMPPEvents["MUC_JOIN_IN_PROGRESS"] = "xmpp.muc_join_in_progress";
    // Designates an event indicating that we have joined the XMPP MUC.
    XMPPEvents["MUC_JOINED"] = "xmpp.muc_joined";
    // Designates an event indicating that a participant joined the XMPP MUC.
    XMPPEvents["MUC_MEMBER_JOINED"] = "xmpp.muc_member_joined";
    // Designates an event indicating that a participant left the XMPP MUC.
    XMPPEvents["MUC_MEMBER_LEFT"] = "xmpp.muc_member_left";
    // Designates an event indicating that a participant joined the lobby XMPP MUC.
    XMPPEvents["MUC_LOBBY_MEMBER_JOINED"] = "xmpp.muc_lobby_member_joined";
    // Designates an event indicating that a participant in the lobby XMPP MUC has been updated
    XMPPEvents["MUC_LOBBY_MEMBER_UPDATED"] = "xmpp.muc_lobby_member_updated";
    // Designates an event indicating that a participant left the XMPP MUC.
    XMPPEvents["MUC_LOBBY_MEMBER_LEFT"] = "xmpp.muc_lobby_member_left";
    // Designates an event indicating that a participant was denied access to a conference from the lobby XMPP MUC.
    XMPPEvents["MUC_DENIED_ACCESS"] = "xmpp.muc_denied access";
    // Designates an event indicating that local participant left the muc
    XMPPEvents["MUC_LEFT"] = "xmpp.muc_left";
    // Designates an event indicating that the MUC role of a participant has
    // changed.
    XMPPEvents["MUC_ROLE_CHANGED"] = "xmpp.muc_role_changed";
    // Designates an event indicating that the MUC has been locked or unlocked.
    XMPPEvents["MUC_LOCK_CHANGED"] = "xmpp.muc_lock_changed";
    // Designates an event indicating that the MUC members only config has changed.
    XMPPEvents["MUC_MEMBERS_ONLY_CHANGED"] = "xmpp.muc_members_only_changed";
    // Designates an event indicating that a participant in the XMPP MUC has
    // advertised that they have audio muted (or unmuted).
    XMPPEvents["PARTICIPANT_AUDIO_MUTED"] = "xmpp.audio_muted";
    // Designates an event indicating that a participant in the XMPP MUC has
    // advertised that they have video muted (or unmuted).
    XMPPEvents["PARTICIPANT_VIDEO_MUTED"] = "xmpp.video_muted";
    // Designates an event indicating that the video type (e.g. 'camera' or
    // 'screen') for a participant has changed.
    // Note = currently this event fires every time we receive presence from
    // someone (regardless of whether or not the "video type" changed).
    XMPPEvents["PARTICIPANT_VIDEO_TYPE_CHANGED"] = "xmpp.video_type";
    /**
     * Indicates that the features of the participant has been changed.
     */
    XMPPEvents["PARTICIPANT_FEATURES_CHANGED"] = "xmpp.participant_features_changed";
    XMPPEvents["PASSWORD_REQUIRED"] = "xmpp.password_required";
    /**
     * Indicates that phone number changed.
     */
    XMPPEvents["PHONE_NUMBER_CHANGED"] = "conference.phoneNumberChanged";
    XMPPEvents["PRESENCE_RECEIVED"] = "xmpp.presence_received";
    XMPPEvents["PRESENCE_STATUS"] = "xmpp.presence_status";
    XMPPEvents["PROMPT_FOR_LOGIN"] = "xmpp.prompt_for_login";
    // xmpp is connected and obtained user media
    XMPPEvents["READY_TO_JOIN"] = "xmpp.ready_to_join";
    /**
     * Indicates that recording state changed.
     */
    XMPPEvents["RECORDER_STATE_CHANGED"] = "xmpp.recorderStateChanged";
    /**
     * The conference was redirected to a visitor node.
     */
    XMPPEvents["REDIRECTED"] = "xmpp.redirected";
    // Designates an event indicating that we received statistics from a
    // participant in the MUC.
    XMPPEvents["REMOTE_STATS"] = "xmpp.remote_stats";
    /**
     * Indicates that the offer / answer renegotiation has failed.
     */
    XMPPEvents["RENEGOTIATION_FAILED"] = "xmpp.renegotiation_failed";
    XMPPEvents["RESERVATION_ERROR"] = "xmpp.room_reservation_error";
    XMPPEvents["ROOM_CONNECT_ERROR"] = "xmpp.room_connect_error";
    XMPPEvents["ROOM_CONNECT_NOT_ALLOWED_ERROR"] = "xmpp.room_connect_error.not_allowed";
    XMPPEvents["ROOM_JOIN_ERROR"] = "xmpp.room_join_error";
    XMPPEvents["ROOM_CONNECT_MEMBERS_ONLY_ERROR"] = "xmpp.room_connect_error.members_only";
    /**
     * Indicates that max users limit has been reached.
     */
    XMPPEvents["ROOM_MAX_USERS_ERROR"] = "xmpp.room_max_users_error";
    // Designates an event indicating that we sent an XMPP message to the MUC.
    XMPPEvents["SENDING_CHAT_MESSAGE"] = "xmpp.sending_chat_message";
    // Designates an event indicating that we sent a private XMPP message to
    // a specific user of the muc.
    XMPPEvents["SENDING_PRIVATE_CHAT_MESSAGE"] = "xmpp.sending_private_chat_message";
    /**
     * Event fired after receiving the confirmation about session accept.
     */
    XMPPEvents["SESSION_ACCEPT"] = "xmpp.session_accept";
    /**
     * Event fired if we receive an error after sending the session accept.
     */
    XMPPEvents["SESSION_ACCEPT_ERROR"] = "xmpp.session_accept_error";
    /**
     * Event fired when we do not get our 'session-accept' acknowledged by
     * Jicofo. It most likely means that there is serious problem with our
     * connection or XMPP server and we should reload the conference.
     *
     * We have seen that to happen in BOSH requests race condition when the BOSH
     * request table containing the 'session-accept' was discarded by Prosody.
     * Jicofo does send the RESULT immediately without any condition, so missing
     * packets means that most likely it has never seen our IQ.
     */
    XMPPEvents["SESSION_ACCEPT_TIMEOUT"] = "xmpp.session_accept_timeout";
    /**
     * Event fired after successful sending of jingle source-add.
     */
    XMPPEvents["SOURCE_ADD"] = "xmpp.source_add";
    /**
     * Event fired after receiving an error sending of jingle source-add.
     */
    XMPPEvents["SOURCE_ADD_ERROR"] = "xmpp.source_add_error";
    /**
     * Event fired after successful sending of jingle source-remove.
     */
    XMPPEvents["SOURCE_REMOVE"] = "xmpp.source_remove";
    /**
     * Event fired after receiving an error sending of jingle source-remove.
     */
    XMPPEvents["SOURCE_REMOVE_ERROR"] = "xmpp.source_remove_error";
    /**
     * Event fired when speaker stats update message is received.
     */
    XMPPEvents["SPEAKER_STATS_RECEIVED"] = "xmpp.speaker_stats_received";
    /**
     * Event fired when conference creation timestamp is received.
     */
    XMPPEvents["CONFERENCE_TIMESTAMP_RECEIVED"] = "xmpp.conference_timestamp_received";
    /**
     * Event fired when we receive a message for AV moderation approved for the local participant.
     */
    XMPPEvents["AV_MODERATION_APPROVED"] = "xmpp.av_moderation.approved";
    /**
    * Event fired when we receive a message for AV moderation rejected for the local participant.
    */
    XMPPEvents["AV_MODERATION_REJECTED"] = "xmpp.av_moderation.rejected";
    /**
     * Event fired when we receive a message for AV moderation.
     */
    XMPPEvents["AV_MODERATION_RECEIVED"] = "xmpp.av_moderation.received";
    /**
     * Event fired when the moderation enable/disable changes.
     */
    XMPPEvents["AV_MODERATION_CHANGED"] = "xmpp.av_moderation.changed";
    /**
     * Event fired when we receive message that a new jid was approved.
     */
    XMPPEvents["AV_MODERATION_PARTICIPANT_APPROVED"] = "xmpp.av_moderation.participant.approved";
    /**
     * Event fired when we receive message that a new jid was approved.
     */
    XMPPEvents["AV_MODERATION_PARTICIPANT_REJECTED"] = "xmpp.av_moderation.participant.rejected";
    /**
     * Event fired when a participant is requested to join a given (breakout) room.
     */
    XMPPEvents["BREAKOUT_ROOMS_MOVE_TO_ROOM"] = "xmpp.breakout-rooms.move-to-room";
    /**
     * Event fired when we receive a message for breakout rooms.
     */
    XMPPEvents["BREAKOUT_ROOMS_EVENT"] = "xmpp.breakout-rooms.event";
    /**
     * Event fired when the breakout rooms data was updated.
     */
    XMPPEvents["BREAKOUT_ROOMS_UPDATED"] = "xmpp.breakout-rooms.updated";
    /**
     * Event fired when we receive a message related to room metadata.
     */
    XMPPEvents["ROOM_METADATA_EVENT"] = "xmpp.room-metadata.event";
    /**
     * Event fired when we receive a message related to room metadata.
     */
    XMPPEvents["ROOM_METADATA_UPDATED"] = "xmpp.room-metadata.updated";
    // Designates an event indicating that we should join the conference with
    // audio and/or video muted.
    XMPPEvents["START_MUTED_FROM_FOCUS"] = "xmpp.start_muted_from_focus";
    // Designates an event indicating that the subject of the XMPP MUC has
    // changed.
    XMPPEvents["SUBJECT_CHANGED"] = "xmpp.subject_changed";
    // FIXME: how does it belong to XMPP ? - it's detected by the PeerConnection
    // suspending detected
    XMPPEvents["SUSPEND_DETECTED"] = "xmpp.suspend_detected";
    /**
     * Notifies for transcription status changes. The event provides the
     * following parameters to its listeners:
     *
     * @param {String} status - The new status.
     */
    XMPPEvents["TRANSCRIPTION_STATUS_CHANGED"] = "xmpp.transcription_status_changed";
    /**
     * Event fired when 'transport-info' with new ICE candidates is received.
     */
    XMPPEvents["TRANSPORT_INFO"] = "xmpp.transportinfo.jingle";
    /**
     * Indicates that video SIP GW state changed.
     *
     * @param {VideoSIPGWStatusConstants} status - Any of the following statuses:
     * STATUS_BUSY, STATUS_AVAILABLE or STATUS_UNDEFINED.
     */
    XMPPEvents["VIDEO_SIP_GW_AVAILABILITY_CHANGED"] = "xmpp.videoSIPGWAvailabilityChanged";
    /**
     * Indicates that video SIP GW Session state changed.
     * The statuses are any of the following statuses:
     * STATE_ON, STATE_OFF, STATE_PENDING, STATE_RETRYING, STATE_FAILED.
     * {@see VideoSIPGWStateConstants}
     *
     * @param {options} event - {address, oldState, newState, displayName}.
     */
    XMPPEvents["VIDEO_SIP_GW_SESSION_STATE_CHANGED"] = "xmpp.videoSIPGWSessionStateChanged";
    // Designates an event indicating that the local ICE connection state has
    // changed.
    XMPPEvents["ICE_CONNECTION_STATE_CHANGED"] = "xmpp.ice_connection_state_changed";
    /**
     * Event which is emitted when the body in an XMPP message in the MUC
     * contains JSON
     * TODO: this event contains a typo (xmmp vs xmpp) but it's unlikely this can be changed now
     */
    XMPPEvents["JSON_MESSAGE_RECEIVED"] = "xmmp.json_message_received";
})(XMPPEvents || (XMPPEvents = {}));
;
//# sourceMappingURL=XMPPEvents.js.map

/***/ }),

/***/ "./node_modules/@testrtc/watchrtc-sdk/lib/index.js":
/*!*********************************************************!*\
  !*** ./node_modules/@testrtc/watchrtc-sdk/lib/index.js ***!
  \*********************************************************/
/***/ ((module) => {

!function(e,a){ true?module.exports=a():0}(self,(function(){return(()=>{var e={607:(e,a,n)=>{"use strict";a.ap=a.Tk=a.Vk=a.b1=a.zP=a.$j=a.dL=a.aM=a.vP=a.xt=a.Zt=a.UN=a.IO=a.zl=a.v6=a.S1=void 0,n(699);var r=n(231);a.S1=function(e,a){(0,r.initSDK)(e||{},[""],a)},a.v6=function(e){(0,r.setConfig)(e)},a.zl=function(e){},a.IO=function(e,a){(0,r.setUserRating)(e,a)},a.UN=function(e){(0,r.addKeys)(e)},a.Zt=function(){(0,r.disableDataCollection)()},a.xt=function(){(0,r.enableDataCollection)()},a.vP=function(e){(0,r.addEvent)(e)},a.aM=function(e,a){(0,r.mapStream)(e,a)},a.dL=function(e,a){(0,r.mapTrack)(e,a)},a.$j=function(){(0,r.connect)()},a.zP=function(){(0,r.disconnect)()},a.b1=function(e){(0,r.registerOnStatsListener)(e)},a.Vk=function(e){(0,r.persistentEnd)(e)},a.Tk=function(e,a){(0,r.persistentStart)(e,a)},a.ap=function(e){(0,r.registerStateListener)(e)},a.default={init:a.S1,addTags:a.zl,setUserRating:a.IO,addKeys:a.UN,setConfig:a.v6,disableDataCollection:a.Zt,enableDataCollection:a.xt,addEvent:a.vP,mapStream:a.aM,mapTrack:a.dL,connect:a.$j,disconnect:a.zP,addStatsListener:a.b1,persistentEnd:a.Vk,persistentStart:a.Tk,addStateListener:a.ap}},231:function(e,a,n){"use strict";var r=this&&this.__assign||function(){return r=Object.assign||function(e){for(var a,n=1,r=arguments.length;n<r;n++)for(var o in a=arguments[n])Object.prototype.hasOwnProperty.call(a,o)&&(e[o]=a[o]);return e},r.apply(this,arguments)},o=this&&this.__awaiter||function(e,a,n,r){return new(n||(n=Promise))((function(o,d){function i(e){try{g(r.next(e))}catch(e){d(e)}}function t(e){try{g(r.throw(e))}catch(e){d(e)}}function g(e){var a;e.done?o(e.value):(a=e.value,a instanceof n?a:new n((function(e){e(a)}))).then(i,t)}g((r=r.apply(e,a||[])).next())}))},d=this&&this.__generator||function(e,a){var n,r,o,d,i={label:0,sent:function(){if(1&o[0])throw o[1];return o[1]},trys:[],ops:[]};return d={next:t(0),throw:t(1),return:t(2)},"function"==typeof Symbol&&(d[Symbol.iterator]=function(){return this}),d;function t(d){return function(t){return function(d){if(n)throw new TypeError("Generator is already executing.");for(;i;)try{if(n=1,r&&(o=2&d[0]?r.return:d[0]?r.throw||((o=r.return)&&o.call(r),0):r.next)&&!(o=o.call(r,d[1])).done)return o;switch(r=0,o&&(d=[2&d[0],o.value]),d[0]){case 0:case 1:o=d;break;case 4:return i.label++,{value:d[1],done:!1};case 5:i.label++,r=d[1],d=[0];continue;case 7:d=i.ops.pop(),i.trys.pop();continue;default:if(!((o=(o=i.trys).length>0&&o[o.length-1])||6!==d[0]&&2!==d[0])){i=0;continue}if(3===d[0]&&(!o||d[1]>o[0]&&d[1]<o[3])){i.label=d[1];break}if(6===d[0]&&i.label<o[1]){i.label=o[1],o=d;break}if(o&&i.label<o[2]){i.label=o[2],i.ops.push(d);break}o[2]&&i.ops.pop(),i.trys.pop();continue}d=a.call(e,i)}catch(e){d=[6,e],r=0}finally{n=o=0}if(5&d[0])throw d[1];return{value:d[0]?d[1]:void 0,done:!0}}([d,t])}}},i=this&&this.__spreadArray||function(e,a,n){if(n||2===arguments.length)for(var r,o=0,d=a.length;o<d;o++)!r&&o in a||(r||(r=Array.prototype.slice.call(a,0,o)),r[o]=a[o]);return e.concat(r||Array.prototype.slice.call(a))};Object.defineProperty(a,"__esModule",{value:!0}),a.persistentStart=a.persistentEnd=a.registerStateListener=a.registerOnStatsListener=a.disconnect=a.connect=a.mapTrack=a.mapStream=a.addEvent=a.enableDataCollection=a.disableDataCollection=a.addKeys=a.setUserRating=a.setConfig=a.initSDK=void 0;var t,g,m,c,l,s,p=n(85),v=n(911),f=n(593),u=n(412),x=!!window.mozRTCPeerConnection,h=(!x&&window.RTCPeerConnection&&window.navigator.webkitGetUserMedia,{}),b=0,y={},w={rtcRoomId:void 0,rtcPeerId:void 0,projectId:void 0},k=null,q=null,S=null,z=0,C=!1,_=!1,I=!1,P=!1,T=null,j=f.debugLog.bind(null,(function(){return null==k?void 0:k.debug})),O={},R=function(e){var a,n=e.forceRecreate,o=void 0!==n&&n,d=e.reconnecting,g=void 0!==d&&d,c=e.pcId,s=void 0===c?"PC_unknown":c;if(j("info","maybeOpenWebsocketConnection called: [".concat(s,"]"),{forceRecreate:o,reconnecting:g,isManualDisconnect:P,tryingToConnectSocket:C,watchrtcConfig:k,openChannels:JSON.stringify(h)}),P=!1,(null===(a=null==S?void 0:S.connection)||void 0===a?void 0:a.readyState)===WebSocket.OPEN){if(!(0,f.isRoomIdOrPeerIdChanged)(w,k)||!o)return void j("info","maybeOpenWebsocketConnection. WS connection already opened [".concat(s,"]"));j("info","maybeOpenWebsocketConnection. Closing WS connection. [".concat(s,"]")),null==S||S.close()}var p=(0,f.countOfValidConnections)(h);if(!I&&p<1&&!C)j("info","maybeOpenWebsocketConnection. WS connection not opened - previous connect call not finished or missing peer connection [".concat(s,"]"),{openChannels:JSON.stringify(h),connectionCount:p,tryingToConnectSocket:C,isManualConnect:I});else{var v=(0,f.validateConfig)(k),x=Object.keys(h)[p-1];if(!v)return C=!1,void j("info","maybeOpenWebsocketConnection. WS connection not opened - invalid config [".concat(s,"]"),{watchrtcConfig:k});k.keys&&Object.keys(k.keys||{}).forEach((function(e){"string"==typeof k.keys[e]&&(k.keys[e]=[k.keys[e]])}));var b=!!k.rtcToken,q=(0,f.getConnectionData)("ws",b?k.rtcToken:k.rtcApiKey,k.proxyUrl);S||j("error","maybeOpenWebsocketConnection. WS socket wasn't initialized [".concat(s,"]")),C=!0,z=Date.now(),j("info","maybeOpenWebsocketConnection. Opening websocket connection [".concat(s,"]")),D();var O=Date.now();null==S||S.connect({url:"".concat(q.url,"?").concat(b?"token":"apiKey","=").concat(q.key,"&timestamp=").concat(Date.now()),onData:function(e){for(var a,n=0,o=Object.entries(e);n<o.length;n++){var d=o[n],c=d[0],l=d[1];y[c]=l}if(w.projectId=e.projectId,C=!1,k.allowBrowserLogCollection=Boolean(e.collectConsoleLogEnabled),k.allowBrowserLogCollection?!(null===(a=null==k?void 0:k.console)||void 0===a?void 0:a.override)&&e.collectConsoleLogLevel&&(0,f.setConsoleLevel)(e.collectConsoleLogLevel,t):((0,f.restoreOriginalConsoleMethods)(),(null==S?void 0:S.buffer)&&(S.buffer=S.buffer.filter((function(e){return"log"!==e[0]})))),console.info.apply(console,i(i([],(0,f.logPrefix)("info"),!1),["Connection established. watchRTCConnectionId: ".concat(e.connectionId," sdkVersion:").concat(u.default," [").concat(s,"]")],!1)),t({data:["watchrtc",x,r(r(r({},k),e),{sdkVersion:u.default})]}),g&&t({data:["reconnect",null,null]}),m&&t({data:["hardware",null,m]}),t({data:["sessionId",null,window.watchRTCSessionId]}),e.interval!==k.collectionInterval){var p=k.collectionInterval;k.collectionInterval=e.interval,A(),D(),console.info.apply(console,i(i([],(0,f.logPrefix)("error"),!1),["Collection interval missmatch - connection state reset"],!1)),t({data:["collectionIntervalChange",null,{oldInterval:p}]})}},onError:function(e,a){"auth"===a&&(_=!0),C=!1,z=0},onOpen:function(){T&&T({connectionStatus:"connected"}),_=!1,l&&(clearInterval(l),l=void 0);var e=Date.now()-O;j("info","maybeOpenWebsocketConnection. Connection opened. Opening time - ".concat(e," ms [").concat(s,"]"))},onClose:function(e){T&&T({connectionStatus:"disconnected"});var a=e.code,n=e.reason,r=e.wasClean;j("info","close event",{authFailed:_,code:a,reason:n,wasClean:r}),_?l&&clearInterval(l):l||P||(R({reconnecting:!0,pcId:s}),l=setInterval((function(){R({reconnecting:!0,pcId:s})}),3e4))}})}},D=function(){window.clearInterval(g),g=window.setInterval((function(){return o(this,void 0,void 0,(function(){var e,a,n,o,t,m,c;return d(this,(function(d){switch(d.label){case 0:return I||0!==(0,f.countOfValidConnections)(h)?[3,1]:(j("info","getStatsInterval. No valid connections at this time"),z&&z+2e4<Date.now()&&(window.clearInterval(g),null==S||S.close(),console.info.apply(console,i(i([],(0,f.logPrefix)("info"),!1),["Last connection closed. watchRTCConnectionId: ".concat(null==y?void 0:y.connectionId," sdkVersion: ").concat(u.default)],!1))),[3,6]);case 1:z=Date.now(),e={connections:{},streams:{}},a=0,n=Object.values(h),d.label=2;case 2:return a<n.length?(o=n[a],j("info","getStatsInterval. ".concat(o.id," signalingState: ").concat(o.pc.signalingState)),"closed"===o.pc.signalingState?[3,4]:[4,E(o)]):[3,5];case 3:t=d.sent(),m=t.peer,c=t.streams,e.connections=r(r({},e.connections),m),e.streams=r(r({},e.streams),c),d.label=4;case 4:return a++,[3,2];case 5:s&&s(e),d.label=6;case 6:return[2]}}))}))}),k.collectionInterval)},E=function(e){return new Promise((function(a,n){if(e){var r=e.id,o=e.pc,d=e.prev;o.getStats(null).then((function(n){(null==k?void 0:k.logGetStats)&&j("info","getStats res",{res:n});var o={};x?n.forEach((function(e){o["".concat(e.type,"_").concat(e.id)]=e})):o=(0,f.map2obj)(n);var i=JSON.parse(JSON.stringify(o));o=(0,f.applyPatchForRTT)(d,o);var g=(0,f.deltaCompression)(d,o);(null==k?void 0:k.logGetStats)&&j("info","getStats(null) [".concat(r,"]"),{data:g}),null!==(null==g?void 0:g.timestamp)&&(null==g?void 0:g.timestamp)!==-1/0&&t({data:["getstats",r,g]}),e.prev=i,a((0,f.exposeApplicationStatsForPC)(r,d,o,O))}))}}))};a.initSDK=function(e,a,n){var o,d;if(!window.watchRTCInitialized){-1!==RTCPeerConnection.toString().indexOf("[native code]")||console.warn.apply(console,i(i([],(0,f.logPrefix)("info"),!1),["init. RTCPeerConnection object has been already overridden"],!1)),window.watchRTCInitialized=!0,window.watchRTCSessionId=(0,f.generateID)(),setTimeout((function(){var e=Date.now();(0,f.getHardwareInfo)().then((function(a){var n=Date.now()-e;n<=5e4?j("info","getHardware",{hardwareInfo:m=a}):j("info","getHardware failure: getHardwareTime: ".concat(n),{hardwareInfo:m})})).catch((function(e){console.error("Error. Get hardware info: ".concat(e.message))}))}),0);var g=new URLSearchParams(location.search);if(g.has("watchrtc")&&"debug"===g.get("watchrtc")&&(e.debug=!0),S=(null==n?void 0:n.socketService)||new p.default({debug:null==e?void 0:e.debug}),q=(null==n?void 0:n.httpService)||new v.default({debug:null==e?void 0:e.debug}),e.collectionInterval=null!==(o=e.collectionInterval)&&void 0!==o?o:8e3,k=e,w.rtcRoomId=k.rtcRoomId,w.rtcPeerId=k.rtcPeerId,t=S.trace,k.wsUrl&&console.warn.apply(console,i(i([],(0,f.logPrefix)("info"),!1),['"wsUrl" config property is deprecated. Use "proxyUrl" instead of it'],!1)),k.proxyUrl&&console.info.apply(console,i(i([],(0,f.logPrefix)("info"),!1),['"proxyUrl" is used'],!1)),a.forEach((function(e){if(window[e+"RTCPeerConnection"]){var a=window[e+"RTCPeerConnection"],n=function(e,n){(null==e?void 0:e.watchrtc)&&(k=r(r({},k),e.watchrtc)),j("info","new RTCPeerConnection called.",{config:e,constraints:n});var o=new a(e,n),d="PC_"+b++;return o.__rtcStatsId=d,h[d]={id:d,pc:o,validConnection:!1},e||(e={nullConfig:!0}),((e=JSON.parse(JSON.stringify(e)))&&e.iceServers||[]).forEach((function(e){delete e.credential})),(null==e?void 0:e.watchrtc)&&delete e.watchrtc,e.browserType=x?"moz":"webkit",t({data:["create",d,e]}),n&&t({data:["constraints",d,n]}),o.addEventListener("icecandidate",(function(e){t({data:["onicecandidate",d,e.candidate]})})),o.addEventListener("icecandidateerror",(function(e){t({data:["onicecandidateerror",d,e]})})),o.addEventListener("addstream",(function(e){t({data:["onaddstream",d,e.stream.id+" "+e.stream.getTracks().map((function(e){return e.kind+":"+e.id}))]})})),o.addEventListener("track",(function(e){t({data:["ontrack",d,e.track.kind+":"+e.track.id+" state:"+e.track.readyState+" muted:"+e.track.muted+" "+e.streams.map((function(e){return"stream:"+e.id}))]}),e.track.onended=function(){t({data:["ontrack",d,e.track.kind+":"+e.track.id+" state:"+e.track.readyState+" "+e.streams.map((function(e){return"stream:"+e.id}))]})},e.track.onmute=function(){t({data:["ontrack",d,e.track.kind+":"+e.track.id+" state:"+e.track.readyState+" muted:"+e.track.muted+" "+e.streams.map((function(e){return"stream:"+e.id}))]})},e.track.onunmute=function(){t({data:["ontrack",d,e.track.kind+":"+e.track.id+" state:"+e.track.readyState+" muted:"+e.track.muted+" "+e.streams.map((function(e){return"stream:"+e.id}))]})}})),o.addEventListener("removestream",(function(e){t({data:["onremovestream",d,e.stream.id+" "+e.stream.getTracks().map((function(e){return e.kind+":"+e.id}))]})})),o.addEventListener("signalingstatechange",(function(){h[d]&&!h[d].validConnection?(h[d].validConnection=!0,setTimeout((function(){R({forceRecreate:!0,pcId:d})}),5e3)):j("info","signalingstatechage. WS connection opening not triggered - peer connection not in channels or was already opened [".concat(d,"]"),{openChannels:JSON.stringify(h)}),t({data:["onsignalingstatechange",d,o.signalingState]})})),o.addEventListener("iceconnectionstatechange",(function(){t({data:["oniceconnectionstatechange",d,o.iceConnectionState]})})),o.addEventListener("icegatheringstatechange",(function(){t({data:["onicegatheringstatechange",d,o.iceGatheringState]})})),o.addEventListener("connectionstatechange",(function(){t({data:["onconnectionstatechange",d,o.connectionState]})})),o.addEventListener("negotiationneeded",(function(){t({data:["onnegotiationneeded",d,void 0]})})),o.addEventListener("datachannel",(function(e){t({data:["ondatachannel",d,[e.channel.id,e.channel.label]]})})),o};if("HTMLMediaElement"in window&&"setSinkId"in HTMLMediaElement.prototype){var o=HTMLMediaElement.prototype.setSinkId;HTMLMediaElement.prototype.setSinkId=function(){var e=arguments[0];return navigator.mediaDevices.enumerateDevices().then((function(a){var n=a.find((function(a){return a.deviceId===e}));n&&n.deviceId!==c&&t({data:["audioOutputChange",null,n.label]}),c=e})).catch((function(e){j("error",e.message,{error:e})})),o.apply(this,arguments)}}if("RTCRtpTransceiver"in window&&"setCodecPreferences"in window.RTCRtpTransceiver.prototype){var d=window.RTCRtpTransceiver,i=d.prototype.setCodecPreferences;d.prototype.setCodecPreferences=function(){return t({data:["setCodecPreferences",this.__pcId,arguments]}),i.apply(this,arguments)}}if("RTCRtpSender"in window&&"setParameters"in window.RTCRtpSender.prototype){var g=(m=window.RTCRtpSender).prototype.setParameters;m.prototype.setParameters=function(){return t({data:["setParameters",this.__pcId,arguments]}),g.apply(this,arguments)}}if("RTCRtpSender"in window&&"replaceTrack"in window.RTCRtpSender.prototype){var m,l=(m=window.RTCRtpSender).prototype.replaceTrack;m.prototype.replaceTrack=function(){var e=arguments[0];return t(e?{data:["replaceTrack",this.__pcId,e.kind+":"+e.id+" state:"+e.readyState+" muted:"+e.muted+" label:"+e.label]}:{data:["replaceTrack",this.__pcId,null]}),l.apply(this,arguments)}}["addTransceiver"].forEach((function(e){var n=a.prototype[e];n&&(a.prototype[e]=function(){var a=this,o="";arguments[1]&&arguments[1].streams&&(o=arguments[1].streams.map((function(e){return"stream:"+e.id})).join(";"));var d="string"==typeof arguments[0]?arguments[0]:arguments[0].kind+":"+arguments[0].id+" "+arguments[0].label,i=arguments[1]?r(r({},arguments[1]),{streams:o}):null;t({data:[e,this.__rtcStatsId,[d,i]]});var g=n.apply(this,arguments);g.sender.__pcId=this.__rtcStatsId;var m=arguments[0];return"object"==typeof m&&(t({data:["onlocaltrack",this.__rtcStatsId,m.kind+":"+m.id+" state:"+m.readyState+" muted:"+m.muted+" label:"+m.label]}),m.onended=function(){t({data:["onlocaltrack",a.__rtcStatsId,m.kind+":"+m.id+" state:"+m.readyState+" label:"+m.label]})},m.onmute=function(){t({data:["onlocaltrack",a.__rtcStatsId,m.kind+":"+m.id+" state:"+m.readyState+" muted:"+m.muted+" label:"+m.label]})},m.onunmute=function(){t({data:["onlocaltrack",a.__rtcStatsId,m.kind+":"+m.id+" state:"+m.readyState+" muted:"+m.muted+" label:"+m.label]})}),g})})),["createDataChannel","restartIce"].forEach((function(e){var n=a.prototype[e];n&&(a.prototype[e]=function(){return t({data:[e,this.__rtcStatsId,arguments]}),n.apply(this,arguments)})})),["close"].forEach((function(e){var n=a.prototype[e];n&&(a.prototype[e]=function(){return t({data:[e,this.__rtcStatsId,arguments]}),delete h[this.__rtcStatsId],P=!0,j("info","on RTCPeerConnection(".concat(this.__rtcStatsId,") close")),n.apply(this,arguments)})})),["addStream","removeStream"].forEach((function(e){var n=a.prototype[e];n&&(a.prototype[e]=function(){var a=this,r=arguments[0],o=r.getTracks().map((function(e){return e.kind+":"+e.id})).join(",");return t({data:[e,this.__rtcStatsId,r.id+" "+o]}),"addStream"===e&&r.getTracks().map((function(e){t({data:["onlocaltrack",a.__rtcStatsId,e.kind+":"+e.id+" state:"+e.readyState+" muted:"+e.muted+" label:"+e.label+" "+r.id]}),e.onended=function(){t({data:["onlocaltrack",a.__rtcStatsId,e.kind+":"+e.id+" state:"+e.readyState+" label:"+e.label+" "+r.id]})},e.onmute=function(){t({data:["onlocaltrack",a.__rtcStatsId,e.kind+":"+e.id+" state:"+e.readyState+" muted:"+e.muted+" label:"+e.label+" "+r.id]})},e.onunmute=function(){t({data:["onlocaltrack",a.__rtcStatsId,e.kind+":"+e.id+" state:"+e.readyState+" muted:"+e.muted+" label:"+e.label+" "+r.id]})}})),n.apply(this,arguments)})})),["addTrack"].forEach((function(e){var n=a.prototype[e];n&&(a.prototype[e]=function(){var a=this,r=arguments[0],o=[].slice.call(arguments,1);t({data:[e,this.__rtcStatsId,r.kind+":"+r.id+" "+r.label+" "+(o.map((function(e){return"stream:"+e.id})).join(";")||"-")]}),t({data:["onlocaltrack",this.__rtcStatsId,r.kind+":"+r.id+" state:"+r.readyState+" muted:"+r.muted+" label:"+r.label+" "+o.map((function(e){return"stream:"+e.id}))]}),r.onended=function(){t({data:["onlocaltrack",a.__rtcStatsId,r.kind+":"+r.id+" state:"+r.readyState+" label:"+r.label+" "+o.map((function(e){return"stream:"+e.id}))]})},r.onmute=function(){t({data:["onlocaltrack",a.__rtcStatsId,r.kind+":"+r.id+" state:"+r.readyState+" muted:"+r.muted+" label:"+r.label+" "+o.map((function(e){return"stream:"+e.id}))]})},r.onunmute=function(){t({data:["onlocaltrack",a.__rtcStatsId,r.kind+":"+r.id+" state:"+r.readyState+" muted:"+r.muted+" label:"+r.label+" "+o.map((function(e){return"stream:"+e.id}))]})};var d=n.apply(this,arguments);d.__pcId=this.__rtcStatsId;var i=this.getTransceivers();return i&&i.forEach((function(e){e.__pcId=a.__rtcStatsId})),d})})),["removeTrack"].forEach((function(e){var n=a.prototype[e];n&&(a.prototype[e]=function(){var a=arguments[0].track;return t({data:[e,this.__rtcStatsId,a?a.kind+":"+a.id+" "+a.label:"null"]}),n.apply(this,arguments)})})),["createOffer","createAnswer"].forEach((function(e){var n=a.prototype[e];n&&(a.prototype[e]=function(){var a,r=this.__rtcStatsId,o=arguments;return 1===arguments.length&&"object"==typeof arguments[0]?a=arguments[0]:3===arguments.length&&"object"==typeof arguments[2]&&(a=arguments[2]),t({data:[e,this.__rtcStatsId,a]}),n.apply(this,a?[a]:void 0).then((function(a){if(t({data:[e+"OnSuccess",r,a]}),!(o.length>0&&"function"==typeof o[0]))return a;o[0].apply(null,[a])}),(function(a){if(t({data:[e+"OnFailure",r,a.toString()]}),!(o.length>1&&"function"==typeof o[1]))throw a;o[1].apply(null,[a])}))})})),["setLocalDescription","setRemoteDescription","addIceCandidate"].forEach((function(e){var n=a.prototype[e];n&&(a.prototype[e]=function(){var a=this.__rtcStatsId,r=arguments,o=this,d="setLocalDescription"===e&&(!r[0]||r[0]&&!r[0].sdp);return t({data:[e,this.__rtcStatsId,d?{parameterless:!0}:r[0]]}),n.apply(this,[r[0]]).then((function(){t({data:[e+"OnSuccess",a,d?null==o?void 0:o.localDescription:void 0]}),r.length>=2&&"function"==typeof r[1]&&r[1].apply(null,[])}),(function(n){if(t({data:[e+"OnFailure",a,n.toString()]}),!(r.length>=3&&"function"==typeof r[2]))throw n;r[2].apply(null,[n])}))})})),a.generateCertificate&&Object.defineProperty(n,"generateCertificate",{get:function(){return arguments.length?a.generateCertificate.apply(null,arguments):a.generateCertificate}}),window[e+"RTCPeerConnection"]=n,window[e+"RTCPeerConnection"].prototype=a.prototype}})),a.forEach((function(e){var a=e+(e.length?"GetUserMedia":"getUserMedia");if(navigator[a]){var n=navigator[a].bind(navigator);navigator[a]=function(){t({data:["getUserMedia",null,arguments[0]]});var e=arguments[1],a=arguments[2];n(arguments[0],(function(a){t({data:["getUserMediaOnSuccess",null,(0,f.dumpStream)(a)]}),e&&e(a)}),(function(e){var n=["getUserMediaOnFailure",null,e.name];t({data:n}),L(n),a&&a(e)}))}.bind(navigator)}})),navigator.mediaDevices&&navigator.mediaDevices.getUserMedia){var l=navigator.mediaDevices.getUserMedia.bind(navigator.mediaDevices);navigator.mediaDevices.getUserMedia=function(){return t({data:["navigator.mediaDevices.getUserMedia",null,arguments[0]]}),l.apply(navigator.mediaDevices,arguments).then((function(e){return t({data:["navigator.mediaDevices.getUserMediaOnSuccess",null,(0,f.dumpStream)(e)]}),e}),(function(e){var a=["navigator.mediaDevices.getUserMediaOnFailure",null,e.name];return t({data:a}),L(a),Promise.reject(e)}))}.bind(navigator.mediaDevices)}if(navigator.mediaDevices&&navigator.mediaDevices.getDisplayMedia){var s=navigator.mediaDevices.getDisplayMedia.bind(navigator.mediaDevices);navigator.mediaDevices.getDisplayMedia=function(){return t({data:["navigator.mediaDevices.getDisplayMedia",null,arguments[0]]}),s.apply(navigator.mediaDevices,arguments).then((function(e){return t({data:["navigator.mediaDevices.getDisplayMediaOnSuccess",null,(0,f.dumpStream)(e)]}),e}),(function(e){var a=["navigator.mediaDevices.getDisplayMediaOnFailure",null,e.name];return t({data:a}),L(a),Promise.reject(e)}))}.bind(navigator.mediaDevices)}(null===(d=e.console)||void 0===d?void 0:d.level)&&(0,f.setConsoleLevel)(e.console.level,t)}},a.setConfig=function(e){var a;window.watchRTCInitialized?(!(!1===(null==k?void 0:k.allowBrowserLogCollection))&&!0===(null===(a=null==e?void 0:e.console)||void 0===a?void 0:a.override)&&e.console.level&&(0,f.setConsoleLevel)(e.console.level,t),"collectionInterval"in e&&delete e.collectionInterval,k=r(r({},k),e),w.rtcRoomId=k.rtcRoomId,w.rtcPeerId=k.rtcPeerId,j("info","setConfig",{newWatchrtcConfig:e,watchrtcConfig:k}),R({})):console.info.apply(console,i(i([],(0,f.logPrefix)("error"),!1),["SDK is not initialized. Use 'init' function first."],!1))},a.setUserRating=function(e,a){var n;if(!window.watchRTCInitialized)return console.info.apply(console,i(i([],(0,f.logPrefix)("error"),!1),["SDK is not initialized. Use 'init' function first."],!1)),Promise.resolve({error:"SDK is not initialized. Use 'init' function first."});if(!(0,f.validateRating)(e))return Promise.resolve({error:"Rating is invalid"});var r=(null===(n=null==S?void 0:S.connection)||void 0===n?void 0:n.readyState)===WebSocket.OPEN,o=["userRating",null,{rating:e,ratingComment:a}];return new Promise((function(e,a){r?t({data:o,options:{promiseFuncs:{resolve:e,reject:a}}}):M.apply(void 0,o).then((function(){return e({})})).catch((function(a){return e({error:a})}))}))},a.addKeys=function(e){var a;if(window.watchRTCInitialized){Object.keys(e||{}).forEach((function(a){"string"==typeof e[a]&&(e[a]=[e[a]])}));var n=["keys",null,e],r=(null===(a=null==S?void 0:S.connection)||void 0===a?void 0:a.readyState)===WebSocket.OPEN,o=null==S?void 0:S.wasConnected;return new Promise((function(e,a){var d={promiseFuncs:{resolve:e,reject:a}};r?t({data:n,options:d}):o?M.apply(void 0,n).then((function(){return e({})})).catch((function(a){return e({error:a})})):t({data:n,options:d})}))}console.info.apply(console,i(i([],(0,f.logPrefix)("error"),!1),["SDK is not initialized. Use 'init' function first."],!1))},a.disableDataCollection=function(){window.watchRTCInitialized?null==S||S.disableDataCollection():console.info.apply(console,i(i([],(0,f.logPrefix)("error"),!1),["SDK is not initialized. Use 'init' function first."],!1))},a.enableDataCollection=function(){window.watchRTCInitialized?null==S||S.enableDataCollection():console.info.apply(console,i(i([],(0,f.logPrefix)("error"),!1),["SDK is not initialized. Use 'init' function first."],!1))},a.addEvent=function(e){if(window.watchRTCInitialized){if((0,f.validateEvent)(e)){var a=["event",null,e];return new Promise((function(e,n){t({data:a,options:{promiseFuncs:{resolve:e,reject:n}}})}))}}else console.info.apply(console,i(i([],(0,f.logPrefix)("error"),!1),["addEvent error. SDK is not initialized. Use 'init' function first."],!1))},a.mapStream=function(e,a){if(window.watchRTCInitialized){if(e&&a){var n=["mapStream",null,{id:e,name:a}];console.info.apply(console,i(i([],(0,f.logPrefix)("info"),!1),["mapStream method is deprecated. Please use mapTrack instead."],!1)),t({data:n})}}else console.info.apply(console,i(i([],(0,f.logPrefix)("error"),!1),["mapStream error. SDK is not initialized. Use 'init' function first."],!1))},a.mapTrack=function(e,a){window.watchRTCInitialized?!e||!a||(O[e]=a,t({data:["mapTrack",null,{id:e,name:a}]})):console.info.apply(console,i(i([],(0,f.logPrefix)("error"),!1),["mapTrack error. SDK is not initialized. Use 'init' function first."],!1))},a.connect=function(){window.watchRTCInitialized?(I=!0,j("info","manual connect"),R({})):console.info.apply(console,i(i([],(0,f.logPrefix)("error"),!1),["connect error. SDK is not initialized. Use 'init' function first."],!1))},a.disconnect=function(){window.watchRTCInitialized?(I=!1,P=!0,null==S||S.close(),j("info","manual disconnect")):console.info.apply(console,i(i([],(0,f.logPrefix)("error"),!1),["disconnect error. SDK is not initialized. Use 'init' function first."],!1))},a.registerOnStatsListener=function(e){s=e},a.registerStateListener=function(e){T=e};var M=function(){for(var e,a=[],n=0;n<arguments.length;n++)a[n]=arguments[n];if(!w.rtcRoomId||!w.rtcPeerId){var r="Cannot do http without room and peer ids";return console.log.apply(console,i(i([],(0,f.logPrefix)("info"),!1),[r],!1)),Promise.reject(r)}if(!w.projectId&&!k.rtcApiKey)return r="Missing apiKey to enable trace before connection establishment",console.log.apply(console,i(i([],(0,f.logPrefix)("info"),!1),[r],!1)),Promise.reject(r);var o=(0,f.getConnectionData)("http",k.rtcApiKey,k.proxyUrl);return q?q.trace.apply(q,i(["".concat(o.url,"/trace"),null!==(e=w.projectId)&&void 0!==e?e:o.key,w.rtcRoomId,w.rtcPeerId],a,!1)):Promise.reject("Invalid configuration of http service")},L=function(e){var a=null==k?void 0:k.rtcApiKey,n=null==k?void 0:k.rtcRoomId,r=null==k?void 0:k.rtcPeerId;if(a&&n&&r){var o=(0,f.getConnectionData)("http",null==k?void 0:k.rtcApiKey,k.proxyUrl);e=e||(null==S?void 0:S.buffer)||[],null==q||q.trace("".concat(o.url,"/error"),o.key,n,r,e)}else console.log.apply(console,i(i([],(0,f.logPrefix)("error"),!1),["Cannot report an error. Please provide apiKey, rtcRoomId and rtcPeerId "],!1))};a.persistentEnd=function(e){window.watchRTCInitialized?(clearInterval(g),I=!1,P=!0,null==S||S.close(e),j("info","persistentEnd. sessionId: ".concat(window.watchRTCSessionId))):console.info.apply(console,i(i([],(0,f.logPrefix)("error"),!1),["persistentEnd error. SDK is not initialized. Use 'init' function first."],!1))};var A=function(){for(var e,a=0,n=Object.values(h);a<n.length;a++)n[a].prev=null;(null===(e=null==S?void 0:S.buffer)||void 0===e?void 0:e.length)&&(S.buffer=[])};a.persistentStart=function(e,a){window.watchRTCInitialized?(k=r(r({},k),{rtcRoomId:e,rtcPeerId:a}),w.rtcRoomId=e,w.rtcPeerId=a,A(),R({}),j("info","persistentStart. sessionId: ".concat(window.watchRTCSessionId),{watchrtcConfig:k})):console.info.apply(console,i(i([],(0,f.logPrefix)("error"),!1),["persistentStart error. SDK is not initialized. Use 'init' function first."],!1))}},527:(e,a)=>{"use strict";Object.defineProperty(a,"__esModule",{value:!0}),a.getStreamsFromStats=a.getTransportFromStats=void 0,a.getTransportFromStats=function(e,a){if(!a)return null;var n=Object.keys(a),r=n.filter((function(e){return"candidate-pair"===a[e].type&&a[e].nominated}));if(r.length>0){var o=a[r[0]],d=o.localCandidateId,i=o.remoteCandidateId,t=n.find((function(e){return"local-candidate"===a[e].type&&a[e].id===d})),g=n.find((function(e){return"remote-candidate"===a[e].type&&a[e].id===i}));if(t&&g){var m=a[t],c=a[g],l={};return l[e]={connection:"relay"===m.candidateType?"relay":"direct",transport:"relay"===m.candidateType?m.relayProtocol:"udp",address:"".concat(c.address,":").concat(c.port)},l}}return null},a.getStreamsFromStats=function(e,a,n,r){var o={},d=Object.keys(n);return d.filter((function(e){return"inbound-rtp"===n[e].type||"outbound-rtp"===n[e].type})).forEach((function(i){var t=n[i],g=a&&i in a?a[i]:null,m="inbound-rtp"===t.type?"inbound":"outbound",c=t.kind,l=t.remoteId in n?n[t.remoteId]:null,s=g&&g.remoteId in a?a[g.remoteId]:null,p=g?(t.timestamp-g.timestamp)/1e3:null,v={direction:m,kind:c,peerId:e};if("video"===c&&(v.frameWidth=t.frameWidth,v.frameHeight=t.frameHeight,v.framerate=t.framesPerSecond),"inbound-rtp"===t.type)v.jitter=t.jitter,v.mappedName=t.trackIdentifier in r?r[t.trackIdentifier]:null,v.bytesReceived=g?t.bytesReceived-g.bytesReceived:null,v.packetsReceived=g?t.packetsReceived-g.packetsReceived:null,v.packetsLost=g?t.packetsLost-g.packetsLost:null,v.packetsLoss=v.packetsLost+v.packetsReceived>0?100*v.packetsLost/(v.packetsLost+v.packetsReceived):null,v.bitrate=p?8*v.bytesReceived/p:null,v.roundTripTime=l&&"roundTripTime"in l?l.roundTripTime:null;else{v.bytesSent=g?t.bytesSent-g.bytesSent:null,v.packetsSent=g?t.packetsSent-g.packetsSent:null,v.bitrate=p?8*v.bytesSent/p:null,v.roundTripTime=l&&"roundTripTime"in l?l.roundTripTime:null,v.jitter=l&&"jitter"in l?l.jitter:null,v.packetsLost=l&&s?l.packetsLost-s.packetsLost:null,v.packetsLoss=l&&"fractionLost"in l?l.fractionLost:null;var f=d.find((function(e){return n[e].id===t.mediaSourceId}));if(f){var u=n[f].trackIdentifier;v.mappedName=u in r?r[u]:null}}o[n[i].id]=v})),o}},699:(e,a)=>{"use strict";Object.defineProperty(a,"__esModule",{value:!0})},593:function(e,a,n){"use strict";var r=this&&this.__assign||function(){return r=Object.assign||function(e){for(var a,n=1,r=arguments.length;n<r;n++)for(var o in a=arguments[n])Object.prototype.hasOwnProperty.call(a,o)&&(e[o]=a[o]);return e},r.apply(this,arguments)},o=this&&this.__awaiter||function(e,a,n,r){return new(n||(n=Promise))((function(o,d){function i(e){try{g(r.next(e))}catch(e){d(e)}}function t(e){try{g(r.throw(e))}catch(e){d(e)}}function g(e){var a;e.done?o(e.value):(a=e.value,a instanceof n?a:new n((function(e){e(a)}))).then(i,t)}g((r=r.apply(e,a||[])).next())}))},d=this&&this.__generator||function(e,a){var n,r,o,d,i={label:0,sent:function(){if(1&o[0])throw o[1];return o[1]},trys:[],ops:[]};return d={next:t(0),throw:t(1),return:t(2)},"function"==typeof Symbol&&(d[Symbol.iterator]=function(){return this}),d;function t(d){return function(t){return function(d){if(n)throw new TypeError("Generator is already executing.");for(;i;)try{if(n=1,r&&(o=2&d[0]?r.return:d[0]?r.throw||((o=r.return)&&o.call(r),0):r.next)&&!(o=o.call(r,d[1])).done)return o;switch(r=0,o&&(d=[2&d[0],o.value]),d[0]){case 0:case 1:o=d;break;case 4:return i.label++,{value:d[1],done:!1};case 5:i.label++,r=d[1],d=[0];continue;case 7:d=i.ops.pop(),i.trys.pop();continue;default:if(!((o=(o=i.trys).length>0&&o[o.length-1])||6!==d[0]&&2!==d[0])){i=0;continue}if(3===d[0]&&(!o||d[1]>o[0]&&d[1]<o[3])){i.label=d[1];break}if(6===d[0]&&i.label<o[1]){i.label=o[1],o=d;break}if(o&&i.label<o[2]){i.label=o[2],i.ops.push(d);break}o[2]&&i.ops.pop(),i.trys.pop();continue}d=a.call(e,i)}catch(e){d=[6,e],r=0}finally{n=o=0}if(5&d[0])throw d[1];return{value:d[0]?d[1]:void 0,done:!0}}([d,t])}}},i=this&&this.__spreadArray||function(e,a,n){if(n||2===arguments.length)for(var r,o=0,d=a.length;o<d;o++)!r&&o in a||(r||(r=Array.prototype.slice.call(a,0,o)),r[o]=a[o]);return e.concat(r||Array.prototype.slice.call(a))};Object.defineProperty(a,"__esModule",{value:!0}),a.generateID=a.applyPatchForRTT=a.exposeApplicationStatsForPC=a.restoreOriginalConsoleMethods=a.setConsoleLevel=a.getHardwareInfo=a.validateEvent=a.validateRating=a.isRoomIdOrPeerIdChanged=a.countOfValidConnections=a.validateConfig=a.getConnectionData=a.dumpStream=a.map2obj=a.mangleChromeStats=a.deltaCompression=a.debugLog=a.logPrefix=void 0;var t=n(240),g=n(527);a.logPrefix=function(e){return void 0===e&&(e="info"),"error"===e?["%cwatchRTC %cERROR","background: ".concat("gold","; color: black; padding: 2px 0.5em; border-radius: 0.5em;"),"background: ".concat("red","; color: white; padding: 2px 0.5em; border-radius: 0.5em;")]:["%cwatchRTC","background: ".concat("gold","; color: black; padding: 2px 0.5em; border-radius: 0.5em;")]},a.debugLog=function(e,n,r,o){if(e()){var d=i(i([],(0,a.logPrefix)(n),!0),[r],!1);o&&d.push(o),console.log.apply(console,d)}},a.deltaCompression=function(e,a){e=e||{},a=a||{},a=JSON.parse(JSON.stringify(a)),Object.keys(a).forEach((function(n){var r=a[n];delete r.id,e[n]&&Object.keys(r).forEach((function(o){r.timestamp&&"string"==typeof r.timestamp&&(r.timestamp=new Date(r.timestamp).getTime()),(r[o]===e[n][o]||Array.isArray(r[o])&&JSON.stringify(r[o])===JSON.stringify(e[n][o]))&&delete a[n][o],(0===Object.keys(r).length||1===Object.keys(r).length&&r.timestamp)&&delete a[n]}))}));var n=-1/0;return Object.keys(a).forEach((function(e){var r=a[e];r.timestamp>n&&(n=r.timestamp)})),Object.keys(a).forEach((function(e){var r=a[e];r.timestamp===n&&(r.timestamp=0)})),a.timestamp=n,a},a.mangleChromeStats=function(e,a){var n={};return a.result().forEach((function(e){var a={id:e.id,timestamp:e.timestamp.getTime(),type:e.type};e.names().forEach((function(n){a[n]=e.stat(n)})),n[a.id]=a})),n},a.map2obj=function(e){if(!e.entries)return e;var a={};return e.forEach((function(e,n){a[n]=e})),a},a.dumpStream=function(e){return{id:e.id,tracks:e.getTracks().map((function(e){return{id:e.id,kind:e.kind,label:e.label,enabled:e.enabled,muted:e.muted,readyState:e.readyState}}))}},a.getConnectionData=function(e,a,n){var r="".concat("ws"==e?"ws":"http","://localhost:9101"),o="".concat("ws"==e?"wss":"https","://watchrtc-staging1.testrtc.com"),d="".concat("ws"==e?"wss":"https","://watchrtc-staging2.testrtc.com"),i="".concat("ws"==e?"wss":"https","://watchrtc.testrtc.com"),t="".concat("ws"==e?"wss":"https","://watchrtc-app1.testrtc.com");n&&"http"===e&&(n=n.includes("wss://")?n.replace("wss://","https://"):n.replace("ws://","http://"));var g=a.split(":");return-1!==a.indexOf("local")?{url:n||r,key:g[1]}:-1!==a.indexOf("staging1")?{url:n||o,key:g[1]}:-1!==a.indexOf("staging")?{url:n||d,key:g[1]}:-1!==a.indexOf("production1")?{url:n||t,key:g[1]}:-1!==a.indexOf("production")?{url:n||i,key:g[1]}:{url:n||i,key:g[0]}},a.validateConfig=function(e){return!(null==e?void 0:e.rtcApiKey)&&(null==e?void 0:e.debug)?(console.info.apply(console,i(i([],(0,a.logPrefix)("error"),!1),["config.rtcApiKey or config.rtcToken need to be provided."],!1)),!1):!(!(null==e?void 0:e.rtcRoomId)||!(null==e?void 0:e.rtcPeerId))||((null==e?void 0:e.debug)&&console.info.apply(console,i(i([],(0,a.logPrefix)("info"),!1),["config.rtcRoomId or config.rtcPeerId is empty."],!1)),!1)},a.countOfValidConnections=function(e){return Object.keys(e).filter((function(a){return e[a].validConnection})).length},a.isRoomIdOrPeerIdChanged=function(e,n){var r=!1;return n.rtcRoomId&&e.rtcRoomId&&e.rtcRoomId!==n.rtcRoomId&&(r=!0),n.rtcPeerId&&e.rtcPeerId&&e.rtcPeerId!==n.rtcPeerId&&(r=!0),r&&n.debug&&console.log.apply(console,i(i([],(0,a.logPrefix)("info"),!1),["maybeOpenWebsocketConnection. rtcRoomId or rtcPeerId has been changed",{old:{rtcRoomId:e.rtcRoomId,rtcPeerId:e.rtcPeerId},new:{rtcRoomId:n.rtcRoomId,rtcPeerId:n.rtcPeerId}}],!1)),r},a.validateRating=function(e){return e?!("number"!=typeof e||e<1||e>5)||(console.info.apply(console,i(i([],(0,a.logPrefix)("error"),!1),["rating parameter should be number from 1 to 5"],!1)),!1):(console.info.apply(console,i(i([],(0,a.logPrefix)("error"),!1),["rating parameter is required"],!1)),!1)},a.validateEvent=function(e){return e?"global"!==e.type&&"local"!==e.type&&"log"!==e.type?(console.info.apply(console,i(i([],(0,a.logPrefix)("error"),!1),['event.type should be either "global" or "local" or "log"'],!1)),!1):!e.parameters||"object"==typeof e.parameters||(console.info.apply(console,i(i([],(0,a.logPrefix)("error"),!1),['event.parameters should be JSON object"'],!1)),!1):(console.info.apply(console,i(i([],(0,a.logPrefix)("error"),!1),["event parameter is required"],!1)),!1)},a.getHardwareInfo=function(){return o(void 0,void 0,void 0,(function(){function e(e){return(Math.round(100*e)/100).toFixed(2)}var a,i,g,m;return d(this,(function(c){switch(c.label){case 0:return a=function(e){return o(void 0,void 0,void 0,(function(){return d(this,(function(a){switch(a.label){case 0:return[4,new Promise((function(a){try{var r=n(804)("./".concat(e));return r.shift(),a(r)}catch(n){console.error("Error. getHardwareInfo. loadBenchmarks",{err:n.stack,fileName:e}),a([])}}))];case 1:return[2,a.sent()]}}))}))},[4,t.getGPUTier({override:{loadBenchmarks:a}})];case 1:return i=c.sent(),g=r(r({},i),{cores_count:window.navigator.hardwareConcurrency}),(m=window.performance.memory)&&(g.jsHeapSizeLimit=e(m.jsHeapSizeLimit/1048576),g.totalJSHeapSize=e(m.totalJSHeapSize/1048576),g.usedJSHeapSize=e(m.usedJSHeapSize/1048576)),[2,g]}}))}))};var m={originalMethodPrefix:"_original_",methodsToPatch:["log","debug","info","warn","error"],level:""},c=function(e,a){var n=console[e];n&&(console[m.originalMethodPrefix+e]=n,console[e]=function(){for(var r=[],o=0;o<arguments.length;o++)r[o]=arguments[o];if(m.level&&r.length&&a){var d=m.methodsToPatch.indexOf(e),i=m.methodsToPatch.indexOf(m.level),t=d>=0&&d>=i;if(t){var g=l(r);a({data:["log",null,{type:e,text:g}]})}}n.apply(console,r)})};a.setConsoleLevel=function(e,a){if(e&&m.methodsToPatch.includes(e)&&e!==m.level){var n=m.methodsToPatch.indexOf(e),r=m.methodsToPatch.indexOf(m.level);if(r<0)for(var o=0,d=m.methodsToPatch.slice(n);o<d.length;o++){var i=d[o];c(i,a)}else if(n<r)for(var t=0,g=m.methodsToPatch.slice(n,r);t<g.length;t++)i=g[t],c(i,a);m.level=e}},a.restoreOriginalConsoleMethods=function(){if("console"in window)for(var e=0,a=m.methodsToPatch;e<a.length;e++){var n=a[e],r=console[m.originalMethodPrefix+n];r&&(console[n]=r.bind(console),delete console[m.originalMethodPrefix+n])}},a.exposeApplicationStatsForPC=function(e,a,n,r){return{peer:(0,g.getTransportFromStats)(e,n),streams:(0,g.getStreamsFromStats)(e,a,n,r)}};var l=function(e){try{return e.map((function(e){return"string"==typeof e?e:JSON.stringify(e,s())})).join(" ")}catch(e){return""}},s=function(){var e=new WeakSet;return function(a,n){if("object"==typeof n&&null!==n){if(e.has(n))return;e.add(n)}return n}};a.applyPatchForRTT=function(e,a){e=e||{},a=a||{};var n=!0;return 0===Object.keys(e).length&&(n=!1),Object.keys(a).filter((function(e){return"remote-outbound-rtp"===a[e].type||"remote-inbound-rtp"===a[e].type})).forEach((function(r){if("roundTripTime"in a[r]){var o="roundTripTimeMeasurements"in a[r]&&Boolean(e[r])&&"roundTripTimeMeasurements"in e[r];n&&o&&a[r].roundTripTimeMeasurements===e[r].roundTripTimeMeasurements&&(a[r].roundTripTime=NaN)}else a[r].roundTripTime=NaN})),a},a.generateID=function(){return Math.random().toString(36).substring(2,15)+Math.random().toString(36).substring(2,15)}},412:(e,a)=>{"use strict";Object.defineProperty(a,"__esModule",{value:!0}),a.default="1.36.3"},911:function(e,a,n){"use strict";var r=this&&this.__spreadArray||function(e,a,n){if(n||2===arguments.length)for(var r,o=0,d=a.length;o<d;o++)!r&&o in a||(r||(r=Array.prototype.slice.call(a,0,o)),r[o]=a[o]);return e.concat(r||Array.prototype.slice.call(a))};Object.defineProperty(a,"__esModule",{value:!0});var o=n(593),d=function(){function e(a){this.debug=!1,e._instance?console.info.apply(console,r(r([],(0,o.logPrefix)("info"),!1),["WatchRTCSocket instance already created"],!1)):(e._instance=this,this.debug=!!a.debug)}return e.prototype.trace=function(e,a,n,d){for(var i=[],t=4;t<arguments.length;t++)i[t-4]=arguments[t];var g=Array.prototype.slice.call(i);g.push(Date.now()),g[1]instanceof RTCPeerConnection&&(g[1]=g[1].__rtcStatsId);var m=fetch(e,{method:"POST",mode:"cors",cache:"no-cache",credentials:"same-origin",headers:{"Content-Type":"application/json"},body:JSON.stringify({data:i,projectId:a,rtcRoomId:n,rtcPeerId:d})});return m.then((function(){return{}})).catch((function(e){return console.log.apply(console,r(r([],(0,o.logPrefix)("error"),!1),[e.message,{err:e.stack}],!1)),{error:e}}))},e}();a.default=d},85:function(e,a,n){"use strict";var r=this&&this.__spreadArray||function(e,a,n){if(n||2===arguments.length)for(var r,o=0,d=a.length;o<d;o++)!r&&o in a||(r||(r=Array.prototype.slice.call(a,0,o)),r[o]=a[o]);return e.concat(r||Array.prototype.slice.call(a))};Object.defineProperty(a,"__esModule",{value:!0});var o=n(593),d=n(354),i=function(){function e(a){this.connection=null,this.wasConnected=!1,this.buffer=[],this.sendInterval=1,this.onClose=function(){},this.debug=!1,this.dataCollection=!0,this.sendPromises=[],this.trace=function(a){var n,i=a.data,t=a.options,g=Array.prototype.slice.call(i);if(g.push(Date.now()),g[1]instanceof RTCPeerConnection&&(g[1]=g[1].__rtcStatsId),e._instance.dataCollection){if(!e._instance.connection)return e._instance.buffer.length>1e3?void((null==t?void 0:t.promiseFuncs)&&t.promiseFuncs.resolve({error:"Message buffer size exceeded"})):(e._instance.buffer.push(g),void((null==t?void 0:t.promiseFuncs)&&e._instance.sendPromises.push(t.promiseFuncs)));if(e._instance.connection.readyState===WebSocket.OPEN&&(e._instance.buffer.push(g),(null==t?void 0:t.promiseFuncs)&&e._instance.sendPromises.push(t.promiseFuncs),e._instance.buffer.length>=e._instance.sendInterval)){var m=JSON.stringify(e._instance.buffer),c=d.compressToEncodedURIComponent(m);if(e._instance.debug){var l=null!==(n=console._original_log)&&void 0!==n?n:console.log;l.apply(void 0,r(r([],(0,o.logPrefix)("info"),!1),["lines: ".concat(m.length)],!1)),l.apply(void 0,r(r([],(0,o.logPrefix)("info"),!1),["compressedMessage: ".concat(c.length)],!1))}e._instance.buffer=[],e._instance.connection.send(c),e._instance.sendPromises.forEach((function(e){return(0,e.resolve)({})})),e._instance.sendPromises=[]}}else(null==t?void 0:t.promiseFuncs)&&t.promiseFuncs.resolve({error:"Data collection disabled"})},e._instance?console.info.apply(console,r(r([],(0,o.logPrefix)("info"),!1),["WatchRTCSocket instance already created"],!1)):(e._instance=this,this.debug=!!a.debug)}return e.prototype.connect=function(a){var n=a.url,d=a.onData,i=a.onError,t=a.onOpen,g=a.onClose;e._instance.connection&&e._instance.connection.close();var m=e._instance;e._instance.connection=new WebSocket(n,"2.0"),e._instance.connection.onopen=t||null,e._instance.connection.onclose=g||null,e._instance.connection.onmessage=function(a){var n;try{var t=JSON.parse(a.data);t.error?(null===(n=null==m?void 0:m.connection)||void 0===n||n.close(),m.connection=null,console.info.apply(console,r(r([],(0,o.logPrefix)("error"),!1),["\n"+t.error],!1)),i(t.error,"auth")):(t.sendInterval&&(e._instance.sendInterval=t.sendInterval),d(t),e._instance.wasConnected=!0)}catch(e){console.info.apply(console,r(r([],(0,o.logPrefix)("error"),!1),[{err:e.stack}],!1)),i(e.message)}},e._instance.connection.onerror=function(e){console.info.apply(console,r(r([],(0,o.logPrefix)("error"),!1),["\n",e],!1)),i(e,"connection")}},e.prototype.close=function(a){var n,r;if(a&&(null===(r=null===(n=e._instance)||void 0===n?void 0:n.connection)||void 0===r?void 0:r.readyState)===WebSocket.OPEN){var o=JSON.stringify(["nailUpCallEnd",null,null]),i=d.compressToEncodedURIComponent(o);e._instance.connection.send(i)}e._instance.buffer=[],e._instance.sendPromises.forEach((function(e){return(0,e.resolve)({error:"Connection was close"})})),e._instance.sendPromises=[],e._instance.connection&&(e._instance.connection.close(),e._instance.onClose(),e._instance.connection=null)},e.prototype.disableDataCollection=function(){e._instance.debug&&console.log.apply(console,r(r([],(0,o.logPrefix)("info"),!1),["Data collection disabled."],!1)),e._instance.dataCollection=!1},e.prototype.enableDataCollection=function(){e._instance.debug&&console.log.apply(console,r(r([],(0,o.logPrefix)("info"),!1),["Data collection enabled."],!1)),e._instance.dataCollection=!0},e.prototype.toggleDebug=function(a){e._instance.debug=a},e}();a.default=i},240:function(e,a){!function(e){"use strict";var a=function(e,n){return(a=Object.setPrototypeOf||{__proto__:[]}instanceof Array&&function(e,a){e.__proto__=a}||function(e,a){for(var n in a)Object.prototype.hasOwnProperty.call(a,n)&&(e[n]=a[n])})(e,n)};function n(e,a,n,r){return new(n||(n=Promise))((function(o,d){function i(e){try{g(r.next(e))}catch(e){d(e)}}function t(e){try{g(r.throw(e))}catch(e){d(e)}}function g(e){var a;e.done?o(e.value):(a=e.value,a instanceof n?a:new n((function(e){e(a)}))).then(i,t)}g((r=r.apply(e,a||[])).next())}))}function r(e,a){var n,r,o,d,i={label:0,sent:function(){if(1&o[0])throw o[1];return o[1]},trys:[],ops:[]};return d={next:t(0),throw:t(1),return:t(2)},"function"==typeof Symbol&&(d[Symbol.iterator]=function(){return this}),d;function t(d){return function(t){return function(d){if(n)throw new TypeError("Generator is already executing.");for(;i;)try{if(n=1,r&&(o=2&d[0]?r.return:d[0]?r.throw||((o=r.return)&&o.call(r),0):r.next)&&!(o=o.call(r,d[1])).done)return o;switch(r=0,o&&(d=[2&d[0],o.value]),d[0]){case 0:case 1:o=d;break;case 4:return i.label++,{value:d[1],done:!1};case 5:i.label++,r=d[1],d=[0];continue;case 7:d=i.ops.pop(),i.trys.pop();continue;default:if(!((o=(o=i.trys).length>0&&o[o.length-1])||6!==d[0]&&2!==d[0])){i=0;continue}if(3===d[0]&&(!o||d[1]>o[0]&&d[1]<o[3])){i.label=d[1];break}if(6===d[0]&&i.label<o[1]){i.label=o[1],o=d;break}if(o&&i.label<o[2]){i.label=o[2],i.ops.push(d);break}o[2]&&i.ops.pop(),i.trys.pop();continue}d=a.call(e,i)}catch(e){d=[6,e],r=0}finally{n=o=0}if(5&d[0])throw d[1];return{value:d[0]?d[1]:void 0,done:!0}}([d,t])}}}var o=["geforce 320m","geforce 8600","geforce 8600m gt","geforce 8800 gs","geforce 8800 gt","geforce 9400","geforce 9400m g","geforce 9400m","geforce 9600m gt","geforce 9600m","geforce fx go5200","geforce gt 120","geforce gt 130","geforce gt 330m","geforce gtx 285","google swiftshader","intel g41","intel g45","intel gma 4500mhd","intel gma x3100","intel hd 3000","intel q45","legacy","mali-2","mali-3","mali-4","quadro fx 1500","quadro fx 4","quadro fx 5","radeon hd 2400","radeon hd 2600","radeon hd 4670","radeon hd 4850","radeon hd 4870","radeon hd 5670","radeon hd 5750","radeon hd 6290","radeon hd 6300","radeon hd 6310","radeon hd 6320","radeon hd 6490m","radeon hd 6630m","radeon hd 6750m","radeon hd 6770m","radeon hd 6970m","sgx 543","sgx543"];function d(e){return e.toLowerCase().replace(/^angle ?\((.+)\)*$/,"$1").replace(/\s(\d{1,2}gb|direct3d.+$)|\(r\)| \([^)]+\)$/g,"")}var i="undefined"==typeof window,t=function(){if(!i){var e=window.navigator,a=e.userAgent,n=e.platform,r=e.maxTouchPoints,o=/(iphone|ipod|ipad)/i.test(a),d="iPad"===n||"MacIntel"===n&&r>0&&!window.MSStream;return{isIpad:d,isMobile:/android/i.test(a)||o||d,isSafari12:/Version\/12.+Safari/.test(a)}}}();function g(e,a,n){if(!n)return[a];var r,o=function(e){var a=e.createShader(35633),n=e.createShader(35632),r=e.createProgram();if(n&&a&&r){e.shaderSource(a,"\n    precision highp float;\n    attribute vec3 aPosition;\n    varying float vvv;\n    void main() {\n      vvv = 0.31622776601683794;\n      gl_Position = vec4(aPosition, 1.0);\n    }\n  "),e.shaderSource(n,"\n    precision highp float;\n    varying float vvv;\n    void main() {\n      vec4 enc = vec4(1.0, 255.0, 65025.0, 16581375.0) * vvv;\n      enc = fract(enc);\n      enc -= enc.yzww * vec4(1.0 / 255.0, 1.0 / 255.0, 1.0 / 255.0, 0.0);\n      gl_FragColor = enc;\n    }\n  "),e.compileShader(a),e.compileShader(n),e.attachShader(r,a),e.attachShader(r,n),e.linkProgram(r),e.detachShader(r,a),e.detachShader(r,n),e.deleteShader(a),e.deleteShader(n),e.useProgram(r);var o=e.createBuffer();e.bindBuffer(34962,o),e.bufferData(34962,new Float32Array([-1,-1,0,3,-1,0,-1,3,0]),35044);var d=e.getAttribLocation(r,"aPosition");e.vertexAttribPointer(d,3,5126,!1,0,0),e.enableVertexAttribArray(d),e.clearColor(1,1,1,1),e.clear(16384),e.viewport(0,0,1,1),e.drawArrays(4,0,3);var i=new Uint8Array(4);return e.readPixels(0,0,1,1,6408,5121,i),e.deleteProgram(r),e.deleteBuffer(o),i.join("")}}(e),d="801621810",i="8016218135",g="80162181161",m=(null==t?void 0:t.isIpad)?[["a7",g,12],["a8",i,15],["a8x",i,15],["a9",i,15],["a9x",i,15],["a10",i,15],["a10x",i,15],["a12",d,15],["a12x",d,15],["a12z",d,15],["a14",d,15],["m1",d,15]]:[["a7",g,12],["a8",i,12],["a9",i,15],["a10",i,15],["a11",d,15],["a12",d,15],["a13",d,15],["a14",d,15]];return"80162181255"===o?r=m.filter((function(e){return e[2]>=14})):(r=m.filter((function(e){return e[1]===o}))).length||(r=m),r.map((function(e){var a=e[0];return"apple ".concat(a," gpu")}))}var m=[],c=[];function l(e,a){if(e===a)return 0;var n=e;e.length>a.length&&(e=a,a=n);for(var r=e.length,o=a.length;r>0&&e.charCodeAt(~-r)===a.charCodeAt(~-o);)r--,o--;for(var d,i=0;i<r&&e.charCodeAt(i)===a.charCodeAt(i);)i++;if(o-=i,0==(r-=i))return o;for(var t,g,l=0,s=0,p=0;s<r;)c[s]=e.charCodeAt(i+s),m[s]=++s;for(;p<o;)for(d=a.charCodeAt(i+p),t=p++,l=p,s=0;s<r;s++)g=d===c[s]?t:t+1,t=m[s],l=m[s]=t>l?g>l?l+1:g:g>t?t+1:g;return l}function s(e){return null!=e}var p=function(e){function n(a){var n=this.constructor,r=e.call(this,a)||this;return Object.setPrototypeOf(r,n.prototype),r}return function(e,n){if("function"!=typeof n&&null!==n)throw new TypeError("Class extends value "+String(n)+" is not a constructor or null");function r(){this.constructor=e}a(e,n),e.prototype=null===n?Object.create(n):(r.prototype=n.prototype,new r)}(n,e),n}(Error);e.getGPUTier=function(e){var a=void 0===e?{}:e,m=a.mobileTiers,c=void 0===m?[0,15,30,60]:m,v=a.desktopTiers,f=void 0===v?[0,15,30,60]:v,u=a.override,x=void 0===u?{}:u,h=a.glContext,b=a.failIfMajorPerformanceCaveat,y=void 0!==b&&b,w=a.benchmarksURL,k=void 0===w?"https://unpkg.com/detect-gpu@".concat("4.0.8","/dist/benchmarks"):w;return n(void 0,void 0,void 0,(function(){var e,a,m,v,u,b,w,q,S,z,C,_,I,P,T,j,O,R,D,E,M,L,A,U,N,F;return r(this,(function(J){switch(J.label){case 0:if(e={},i)return[2,{tier:0,type:"SSR"}];if(a=x.isIpad,m=void 0===a?!!(null==t?void 0:t.isIpad):a,v=x.isMobile,u=void 0===v?!!(null==t?void 0:t.isMobile):v,b=x.screenSize,w=void 0===b?window.screen:b,q=x.loadBenchmarks,S=void 0===q?function(e){return n(void 0,void 0,void 0,(function(){var a;return r(this,(function(n){switch(n.label){case 0:return[4,fetch("".concat(k,"/").concat(e)).then((function(e){return e.json()}))];case 1:if(a=n.sent(),parseInt(a.shift().split(".")[0],10)<4)throw new p("Detect GPU benchmark data is out of date. Please update to version 4x");return[2,a]}}))}))}:q,z=x.renderer,C=function(e){for(var a=0,n=u?["adreno","apple","mali-t","mali","nvidia","powervr"]:["intel","apple","amd","radeon","nvidia","geforce"];a<n.length;a++){var r=n[a];if(e.includes(r))return r}},_=function(a){return n(void 0,void 0,void 0,(function(){var n,o,d,i,t,g,c,s,v,f,x,h,b,y,k,q,z,_,I,P,T,j,O,R,D,E;return r(this,(function(r){switch(r.label){case 0:if(!(n=C(a)))return[2];o="".concat(u?"m":"d","-").concat(n).concat(m?"-ipad":"",".json"),d=e[o]=null!==(E=e[o])&&void 0!==E?E:S(o),r.label=1;case 1:return r.trys.push([1,3,,4]),[4,d];case 2:return i=r.sent(),[3,4];case 3:if((t=r.sent())instanceof p)throw t;return[2];case 4:if(g=function(e){var a,n=(e=e.replace(/\([^)]+\)/,"")).match(/\d+/)||e.match(/(\W|^)([A-Za-z]{1,3})(\W|$)/g);return null!==(a=null==n?void 0:n.join("").replace(/\W|amd/g,""))&&void 0!==a?a:""}(a),(c=i.filter((function(e){return e[1]===g}))).length||(c=i.filter((function(e){return e[0].includes(a)}))),0===(s=c.length))return[2];for(v=s>1?c.map((function(e){return[e,l(a,e[0])]})).sort((function(e,a){return e[1]-a[1]}))[0][0]:c[0],f=v[0],x=v[3],h=Number.MAX_VALUE,y=window.devicePixelRatio,k=w.width*y*w.height*y,q=0,z=x;q<z.length;q++)_=z[q],I=_[0],P=_[1],T=I*P,(j=Math.abs(k-T))<h&&(h=j,b=_);return b?(R=(O=b)[2],D=O[3],[2,[h,R,f,D]]):[2]}}))}))},I=function(e,a,n,r,o){return{device:o,fps:r,gpu:n,isMobile:u,tier:e,type:a}},T="",z)z=d(z),P=[z];else{if(!(j=h||function(e,a){void 0===a&&(a=!1);var n={alpha:!1,antialias:!1,depth:!1,failIfMajorPerformanceCaveat:a,powerPreference:"high-performance",stencil:!1};e&&delete n.powerPreference;var r=window.document.createElement("canvas"),o=r.getContext("webgl",n)||r.getContext("experimental-webgl",n);return null!=o?o:void 0}(null==t?void 0:t.isSafari12,y)))return[2,I(0,"WEBGL_UNSUPPORTED")];if((O=j.getExtension("WEBGL_debug_renderer_info"))&&(z=j.getParameter(O.UNMASKED_RENDERER_WEBGL)),!z)return[2,I(1,"FALLBACK")];T=z,z=d(z),P=function(e,a,n){return"apple gpu"===a?g(e,a,n):[a]}(j,z,u)}return[4,Promise.all(P.map(_))];case 1:if(!(R=J.sent().filter(s).sort((function(e,a){var n=e[0],r=void 0===n?Number.MAX_VALUE:n,o=e[1],d=a[0],i=void 0===d?Number.MAX_VALUE:d,t=a[1];return r===i?o-t:r-i}))).length)return[2,(D=o.find((function(e){return z.includes(e)})))?I(0,"BLOCKLISTED",D):I(1,"FALLBACK","".concat(z," (").concat(T,")"))];if(E=R[0],M=E[1],L=E[2],A=E[3],-1===M)return[2,I(0,"BLOCKLISTED",L,M,A)];for(U=u?c:f,N=0,F=0;F<U.length;F++)M>=U[F]&&(N=F);return[2,I(N,"BENCHMARK",L,M,A)]}}))}))},Object.defineProperty(e,"__esModule",{value:!0})}(a)},622:e=>{"use strict";e.exports=JSON.parse('["4.0.8",["qualcomm adreno 540","540",0,[[1919,1279,19]]],["qualcomm adreno 540 gpu","540",0,[[1919,1279,24]]],["qualcomm adreno 618 gpu","618",0,[[1920,1080,20]]],["qualcomm adreno 630 gpu","630",0,[[1920,1080,21]]],["qualcomm adreno 680 gpu","680",0,[[2880,1920,25]]],["qualcomm adreno 685 gpu","685",0,[[1920,1080,28]]],["qualcomm adreno 690 gpu","690",0,[[1920,1280,28]]],["qualcomm adreno 8cx gen 3","8",0,[[1920,1080,22]]]]')},183:e=>{"use strict";e.exports=JSON.parse('["4.0.8",["amd ???","",0,[[1920,1080,144]]],["amd [amd/ati] fiji [radeon r9 fury / nano series]","9",0,[[1920,1200,162]]],["amd 15dd","15",0,[[3840,2160,14]]],["amd 66af:f1","66",0,[[3840,2160,181]]],["amd 67df:c4","67",0,[[2560,1600,59]]],["amd 67e8:00","67",0,[[1920,1080,59]]],["amd 67ef:c5","67",0,[[1920,1080,52]]],["amd 67ef:cf","67",0,[[1920,1080,74]]],["amd 67ef:e7","67",0,[[1920,1080,60]]],["amd 67ff:08","67",0,[[1920,1200,31]]],["amd 694c:c0","694",0,[[1919,1080,28],[3840,2160,12]]],["amd 694e:c0","694",0,[[3840,2160,27]]],["amd 6980:00","6980",0,[[1920,1200,59]]],["amd 699f:c1","699",0,[[1920,1080,48]]],["amd 7310:00","7310",0,[[3840,2160,55]]],["amd 731f:c1","731",0,[[1920,1080,60]]],["amd 7340:c5","7340",0,[[2560,1600,44]]],["amd advanced micro devices [amd] nee ati device","nee",0,[[1920,1200,157]]],["amd asus amd radeon r9-990x","9",0,[[1920,1080,60]]],["amd asus eah5450","5450",0,[[1600,900,12],[1680,1050,11],[1920,1200,12]]],["amd asus eah5670","5670",0,[[1920,1080,28]]],["amd asus eah6450","6450",0,[[1920,1080,12]]],["amd asus hd7750","7750",0,[[1920,1080,105]]],["amd asus hd7770","7770",0,[[1680,1050,60]]],["amd asus hd7850","7850",0,[[1920,1080,60]]],["amd asus hd7970","7970",0,[[3840,2160,50]]],["amd asus hd8760","8760",0,[[1680,1050,59]]],["amd asus r5 230","5",0,[[1920,1080,12]]],["amd asus r7 240","7",0,[[1600,900,28],[1920,1080,31]]],["amd asus r7 250","7",0,[[1920,1080,59]]],["amd asus r7 250x","7",0,[[1920,1080,60]]],["amd asus r7 265","7",0,[[1920,1080,60]]],["amd asus r7 360","7",0,[[1920,1080,78]]],["amd asus r7 370","7",0,[[1600,900,60],[1920,1080,143]]],["amd asus r9 270","9",0,[[1600,900,60]]],["amd asus r9 280x","9",0,[[1920,1080,146]]],["amd asus r9 295x2","9",0,[[2560,1440,93]]],["amd asus r9 380","9",0,[[1920,1080,60]]],["amd asus r9 390","9",0,[[1920,1080,235]]],["amd asus radeon r7 250","7",0,[[800,638,60]]],["amd asus radeon r7 260x","7",0,[[2560,1080,65]]],["amd asus radeon r9 270x","9",0,[[1024,768,85],[1920,1080,60]]],["amd asus radeon r9 280","9",0,[[1920,1080,60]]],["amd asus radeon rx 460","460",0,[[1360,768,104]]],["amd asus radeon rx 470","470",0,[[1920,1080,60]]],["amd asus radeon rx 480","480",0,[[1920,1080,124]]],["amd asus radeon rx 550","550",0,[[1440,900,60],[1920,1080,49]]],["amd asus radeon rx 5500 xt","5500",0,[[1920,1080,325]]],["amd asus radeon rx 560","560",0,[[1360,768,60],[1920,1080,85]]],["amd asus radeon rx 570","570",0,[[1600,900,202],[1920,1080,60]]],["amd asus radeon rx 5700","5700",0,[[1920,1080,327]]],["amd asus radeon rx 5700 xt","5700",0,[[1920,1080,224],[2560,1440,60]]],["amd asus radeon rx 580","580",0,[[1920,1080,177],[2560,1080,60]]],["amd asus radeon rx vega","rx",0,[[2560,1440,117]]],["amd asus rx 6600xt macos","6600",0,[[3840,2160,60]]],["amd ati mobility radeon hd 5870","5870",0,[[1920,1200,19]]],["amd baffin amd radeon rx 560","560",0,[[1920,1080,60]]],["amd barco mxrt 5600","5600",0,[[2800,2100,30]]],["amd carrizo 9874","9874",0,[[1920,1200,11]]],["amd cezanne","",0,[[1920,1080,162]]],["amd device","",0,[[1920,1080,188]]],["amd ellesmere radeon rx 570","570",0,[[1920,1080,60]]],["amd embedded radeon e9171","9171",0,[[3840,2160,26]]],["amd embedded radeon e9173","9173",0,[[3840,2160,16]]],["amd firepro 2270","2270",0,[[1245,768,19],[1920,1200,9]]],["amd firepro 3800 graphics adapter","3800",0,[[1920,1080,18]]],["amd firepro d300","300",0,[[1920,1080,60],[2560,1440,60],[3440,1440,60],[3840,2160,30]]],["amd firepro d500","500",0,[[1600,900,60],[2560,1440,59],[2560,1600,87],[3840,2160,57]]],["amd firepro d700","700",0,[[2048,1152,59],[2560,1440,59]]],["amd firepro m2000","2000",0,[[1600,900,28],[1920,1080,24]]],["amd firepro m4000","4000",0,[[1920,1080,57]]],["amd firepro m4000 mobility pro","4000",0,[[1920,1080,57]]],["amd firepro m4100","4100",0,[[1920,1080,58]]],["amd firepro m4100 firegl v","4100",0,[[1920,1080,24]]],["amd firepro m4150","4150",0,[[1600,900,51]]],["amd firepro m4170","4170",0,[[1920,1080,43]]],["amd firepro m5100","5100",0,[[1920,1080,60]]],["amd firepro m5100 firegl v","5100",0,[[1920,1080,29]]],["amd firepro m5950","5950",0,[[1920,1080,42]]],["amd firepro m6000 mobility pro","6000",0,[[1600,900,33],[1920,1080,60]]],["amd firepro m6100","6100",0,[[1920,1080,60]]],["amd firepro m6100 firegl v","6100",0,[[1920,1080,60]]],["amd firepro m7820","7820",0,[[1680,1050,44]]],["amd firepro r5000","5000",0,[[1920,1080,60]]],["amd firepro s10000","10000",0,[[2560,1440,58]]],["amd firepro s7150","7150",0,[[1440,900,70]]],["amd firepro s9000","9000",0,[[1920,1080,60]]],["amd firepro s9050","9050",0,[[1920,1080,101]]],["amd firepro v graphics adapter","v",0,[[1680,1050,53],[1920,1080,54]]],["amd firepro v3800","3800",0,[[1280,992,28],[1680,1050,25]]],["amd firepro v3900","3900",0,[[1920,1080,28],[2560,1440,26]]],["amd firepro v4800","4800",0,[[1440,900,37],[1920,1080,50]]],["amd firepro v4800 graphics adapter","4800",0,[[1920,1080,46]]],["amd firepro v4900","4900",0,[[1600,900,76],[1920,1080,53]]],["amd firepro v4900 graphics adapter","4900",0,[[1920,1200,40]]],["amd firepro v5800","5800",0,[[1366,768,60],[1920,1200,62]]],["amd firepro v5800 graphics adapter","5800",0,[[1360,768,83],[1280,1024,58]]],["amd firepro v5900","5900",0,[[1920,1080,53],[1920,1200,58],[3440,1440,34]]],["amd firepro v5900 graphics adapter","5900",0,[[1600,1200,54],[1920,1080,65]]],["amd firepro v7800 graphics adapter","7800",0,[[1680,1050,60],[1920,1080,60]]],["amd firepro v7900","7900",0,[[1920,1080,135],[1920,1200,60],[2560,1080,124]]],["amd firepro v7900 graphics adapter","7900",0,[[1920,1080,58]]],["amd firepro v8800","8800",0,[[2560,1440,58]]],["amd firepro w2100","2100",0,[[1920,1080,33]]],["amd firepro w4100","4100",0,[[1920,1080,55]]],["amd firepro w4100 graphics adapter","4100",0,[[1600,1200,70],[1920,1080,56]]],["amd firepro w4150m firegl v","4150",0,[[1920,1080,45]]],["amd firepro w4170m","4170",0,[[1366,768,11]]],["amd firepro w4190m","4190",0,[[1920,1080,42]]],["amd firepro w4300","4300",0,[[1280,1024,116]]],["amd firepro w5000","5000",0,[[1920,1080,60],[2560,1600,75]]],["amd firepro w5000 graphics adapter","5000",0,[[1280,1024,60],[1920,1080,117]]],["amd firepro w5100","5100",0,[[1920,1080,60],[1920,1200,59]]],["amd firepro w5100 graphics adapter","5100",0,[[1920,1080,89],[3840,2160,29]]],["amd firepro w5130m","5130",0,[[1920,1080,60]]],["amd firepro w5170m","5170",0,[[1920,1080,84],[2560,1440,51]]],["amd firepro w600","600",0,[[3840,2160,25]]],["amd firepro w6150m","6150",0,[[1920,1080,45]]],["amd firepro w7000","7000",0,[[1920,1080,60],[1920,1200,136]]],["amd firepro w7000 graphics adapter","7000",0,[[1920,1080,60]]],["amd firepro w7100","7100",0,[[1920,1080,60],[1920,1200,141]]],["amd firepro w7100 graphics adapter","7100",0,[[1200,900,60]]],["amd firepro w7170m","7170",0,[[1920,1080,60]]],["amd firepro w8000","8000",0,[[1920,1200,110],[2560,1440,60]]],["amd firepro w8100","8100",0,[[1920,1080,60],[1920,1200,60]]],["amd firepro w8100 graphic adapter","8100",0,[[1280,1024,113]]],["amd firepro w9100","9100",0,[[1920,1080,60],[1920,1200,188],[2560,1600,59]]],["amd gigabyte radeon rx 580","580",0,[[1920,1080,60]]],["amd gigabyte vega 64 macos","64",0,[[1920,1080,60]]],["amd hd7950 martin rev.","7950",0,[[2560,1440,101]]],["amd hd7950 martin ver.","7950",0,[[2560,1440,104]]],["amd kamen rider black rx","rx",0,[[1920,1080,60]]],["amd kaveri","",0,[[1920,1080,9]]],["amd madison [mobility radeon hd 5650 / 6530m/6550m]","5650",0,[[1366,768,43]]],["amd matrox c680 pcie x16","680",0,[[2560,1440,49]]],["amd matrox c900 pcie x16","900",0,[[5760,3240,9]]],["amd metal","",0,[[1920,1080,120]]],["amd mobility radeon hd 4250","4250",0,[[963,722,26]]],["amd mobility radeon hd 5000","5000",0,[[1366,768,47]]],["amd mobility radeon hd 5400","5400",0,[[1366,768,24]]],["amd mobility radeon hd 5430","5430",0,[[1600,900,15],[1920,1080,60]]],["amd mobility radeon hd 5470","5470",0,[[1366,768,24]]],["amd mobility radeon hd 5570","5570",0,[[1920,1080,27]]],["amd mobility radeon hd 5730 / 6570m","5730",0,[[1366,768,58]]],["amd mobility radeon hd 5850","5850",0,[[1600,900,55]]],["amd mobility radeon hd 5870","5870",0,[[1600,900,64],[1920,1200,53]]],["amd msi / amd rx 560","560",0,[[1920,1080,60]]],["amd msi / amd rx 560 4g","560",0,[[1920,1080,60]]],["amd msi baffin rx650","650",0,[[1920,1080,399]]],["amd msi rx560","560",0,[[1920,1080,343]]],["amd msi rx650","650",0,[[1920,1080,60]]],["amd mxgpu","",0,[[1920,1012,67],[1920,1080,106]]],["amd navi 10 5700 xt","10",0,[[3840,2160,60]]],["amd opal xt/gl","xt",0,[[1366,768,60]]],["amd park [mobility radeon hd 5430","5430",0,[[1280,720,11]]],["amd picasso","",0,[[1920,1080,48]]],["amd pitcairn pro radeon hd 7850","7850",0,[[1920,1080,60]]],["amd powercolor radeon r9 280","9",0,[[1920,1080,60]]],["amd r9 270x devil","9",0,[[1920,1080,60]]],["amd r9 280x dual-x","9",0,[[1920,1080,60]]],["amd r9 380","9",0,[[2560,1440,119]]],["amd r9 xxx","9",0,[[1920,1080,60]]],["amd radeon","",0,[[1920,1080,299],[3440,1440,60]]],["amd radeon 500","500",0,[[1920,1080,73]]],["amd radeon 520","520",0,[[1920,1080,35],[2560,1440,29]]],["amd radeon 530","530",0,[[1366,768,60],[1920,1080,30]]],["amd radeon 535","535",0,[[1920,1080,35]]],["amd radeon 535dx","535",0,[[1366,768,31],[1920,1080,37]]],["amd radeon 540","540",0,[[1920,1080,38]]],["amd radeon 540 / rx 540x/550/550x","540",0,[[2560,1440,88]]],["amd radeon 540x","540",0,[[1920,1080,59]]],["amd radeon 550","550",0,[[1920,1080,115]]],["amd radeon 550x","550",0,[[1920,1080,28]]],["amd radeon 610","610",0,[[1920,1080,29]]],["amd radeon 620","620",0,[[1920,1080,18]]],["amd radeon 625","625",0,[[1366,768,55],[1920,1080,47]]],["amd radeon 630","630",0,[[1920,1080,29]]],["amd radeon 6600m and 6700m","6600",0,[[1366,768,36],[1440,900,60]]],["amd radeon 6800","6800",0,[[3440,1440,100]]],["amd radeon 7500m/7600m","7500",0,[[1366,768,37]]],["amd radeon 7950 x2","7950",0,[[2560,1440,174]]],["amd radeon d700","700",0,[[2560,1440,120]]],["amd radeon e6460","6460",0,[[1600,1200,13]]],["amd radeon e6760","6760",0,[[1200,900,54],[1920,1080,42]]],["amd radeon e8860","8860",0,[[1920,1200,27],[2560,1374,88]]],["amd radeon e8870","8870",0,[[1920,1080,81]]],["amd radeon e8870mxm","8870",0,[[1920,1080,60]]],["amd radeon e9260","9260",0,[[1680,1050,60],[3840,2160,38]]],["amd radeon e9550","9550",0,[[1680,1050,60],[3840,2160,58]]],["amd radeon embedded e9560","9560",0,[[1920,1200,60]]],["amd radeon fury","",0,[[1920,1080,60]]],["amd radeon fury x","x",0,[[1920,1080,60],[2560,1440,144]]],["amd radeon hd - firepro d300","300",0,[[1920,1080,60]]],["amd radeon hd - firepro d300 opengl engine","300",0,[[1920,1080,60],[2560,1440,59]]],["amd radeon hd - firepro d500 opengl engine","500",0,[[1920,1080,60],[2560,1440,59]]],["amd radeon hd - firepro d700 opengl engine","700",0,[[3840,2160,52]]],["amd radeon hd 2600 xt","2600",1,[[2560,1600,-1]]],["amd radeon hd 5000","5000",0,[[1920,1080,8]]],["amd radeon hd 5400","5400",0,[[1920,1080,12]]],["amd radeon hd 5450","5450",0,[[1920,1080,13]]],["amd radeon hd 5470","5470",0,[[1280,1024,16]]],["amd radeon hd 5500","5500",0,[[1920,1080,27]]],["amd radeon hd 5570","5570",0,[[1920,1080,60],[2048,1152,31]]],["amd radeon hd 5600","5600",0,[[1920,1080,56]]],["amd radeon hd 5650","5650",0,[[1366,768,53]]],["amd radeon hd 5670","5670",1,[[1920,1080,-1],[2560,1440,-1]]],["amd radeon hd 5670 opengl engine","5670",1,[[2560,1440,-1]]],["amd radeon hd 5700","5700",0,[[1920,1080,59]]],["amd radeon hd 5730","5730",0,[[1366,768,46],[1680,1050,40]]],["amd radeon hd 5750","5750",1,[[1920,1080,-1],[1920,1200,-1],[2560,1440,-1]]],["amd radeon hd 5750 opengl engine","5750",1,[[2560,1440,-1]]],["amd radeon hd 5770","5770",0,[[1776,1000,43],[1920,1080,59]]],["amd radeon hd 5800","5800",0,[[1366,768,60],[1920,1200,102]]],["amd radeon hd 5850","5850",0,[[1920,1080,60]]],["amd radeon hd 5870","5870",0,[[1280,960,75],[1920,1080,60],[2048,1280,60]]],["amd radeon hd 5870m","5870",0,[[2560,1080,31]]],["amd radeon hd 5970","5970",0,[[1360,768,60],[1920,1080,60]]],["amd radeon hd 6230","6230",0,[[1366,768,13]]],["amd radeon hd 6250","6250",0,[[1280,800,8],[1366,768,8]]],["amd radeon hd 6290","6290",1,[[1366,768,-1]]],["amd radeon hd 6300m","6300",1,[[1366,768,-1]]],["amd radeon hd 6310","6310",1,[[1366,768,-1]]],["amd radeon hd 6320","6320",1,[[1366,768,-1]]],["amd radeon hd 6350","6350",0,[[1280,1024,18],[1920,1080,14]]],["amd radeon hd 6370d","6370",0,[[1920,1080,14]]],["amd radeon hd 6370m","6370",0,[[1366,768,25]]],["amd radeon hd 6380g","6380",0,[[1366,768,19]]],["amd radeon hd 6400","6400",0,[[1920,1080,13]]],["amd radeon hd 6400m","6400",0,[[1366,768,28]]],["amd radeon hd 6400m/7400m","6400",0,[[1366,768,28]]],["amd radeon hd 6410d","6410",0,[[1920,1080,11]]],["amd radeon hd 6450","6450",0,[[1920,1080,14]]],["amd radeon hd 6450 / r5 230","6450",0,[[1440,900,12]]],["amd radeon hd 6450 230","6450",0,[[1920,1080,15]]],["amd radeon hd 6470m","6470",0,[[1366,768,27],[1600,900,21]]],["amd radeon hd 6470m/7400m","6470",0,[[1366,768,44]]],["amd radeon hd 6480g","6480",0,[[1280,768,19],[1366,768,27],[1600,900,18]]],["amd radeon hd 6490m","6490",1,[[1366,768,-1],[1440,900,-1],[1680,1050,-1]]],["amd radeon hd 6500","6500",0,[[1920,1080,25]]],["amd radeon hd 6500m/5600","6500",0,[[1920,1080,27]]],["amd radeon hd 6510","6510",0,[[1600,900,32]]],["amd radeon hd 6520g","6520",0,[[1366,768,21],[1600,900,20]]],["amd radeon hd 6530d","6530",0,[[1366,768,31],[1440,900,36],[1920,1080,24]]],["amd radeon hd 6540","6540",0,[[1600,1200,13]]],["amd radeon hd 6550d","6550",0,[[1920,1080,28]]],["amd radeon hd 6570","6570",0,[[1920,1080,52],[2560,1440,17]]],["amd radeon hd 6620g","6620",0,[[1360,768,43],[1366,768,28]]],["amd radeon hd 6630m","6630",1,[[1366,768,-1],[1600,900,-1],[1920,1080,-1]]],["amd radeon hd 6630m/6650m/6750m/7670m/7690m","6630",1,[[1366,768,-1],[1920,1080,-1]]],["amd radeon hd 6650m","6650",0,[[1366,768,51],[1600,900,31]]],["amd radeon hd 6670","6670",0,[[1920,1080,55]]],["amd radeon hd 6700","6700",0,[[1920,1080,56]]],["amd radeon hd 6700 green","6700",0,[[1360,768,89]]],["amd radeon hd 6700m/7700m/7900m","6700",0,[[1366,768,59]]],["amd radeon hd 6730m/6770m","6730",0,[[1366,768,58],[1920,1080,46]]],["amd radeon hd 6730m/6770m/7690m xt","6730",0,[[1920,1080,48]]],["amd radeon hd 6750","6750",0,[[1440,900,72],[1920,1080,60]]],["amd radeon hd 6750m","6750",1,[[1440,900,-1],[1920,1080,-1],[1920,1200,-1]]],["amd radeon hd 6770","6770",0,[[1920,1080,60]]],["amd radeon hd 6770m","6770",1,[[1440,900,-1],[2560,1440,-1]]],["amd radeon hd 6770m opengl engine","6770",1,[[2560,1440,-1]]],["amd radeon hd 6790","6790",0,[[1920,1080,59]]],["amd radeon hd 6800","6800",0,[[1280,1024,89],[1920,1080,60]]],["amd radeon hd 6800m","6800",0,[[1600,900,18],[1920,1080,40]]],["amd radeon hd 6850","6850",0,[[1920,1080,59],[2560,1600,54]]],["amd radeon hd 6870","6870",0,[[1920,1080,60],[2560,1440,59]]],["amd radeon hd 6900","6900",0,[[1920,1080,60]]],["amd radeon hd 6900m","6900",0,[[1920,1080,60]]],["amd radeon hd 6950","6950",0,[[1680,1050,60],[1920,1080,41]]],["amd radeon hd 6970","6970",0,[[1920,1080,60]]],["amd radeon hd 6970m","6970",1,[[2560,1440,-1]]],["amd radeon hd 6970m opengl engine","6970",1,[[2560,1440,-1]]],["amd radeon hd 6990","6990",0,[[1920,1080,60]]],["amd radeon hd 7000","7000",0,[[1920,1080,24]]],["amd radeon hd 7290","7290",0,[[1366,768,9]]],["amd radeon hd 7310","7310",0,[[1366,768,14]]],["amd radeon hd 7340","7340",0,[[1366,768,17],[1920,1080,10]]],["amd radeon hd 7340g","7340",0,[[1366,768,15]]],["amd radeon hd 7340m","7340",0,[[1366,768,15]]],["amd radeon hd 7350","7350",0,[[1920,1080,13]]],["amd radeon hd 7400","7400",0,[[1920,1080,18]]],["amd radeon hd 7400g","7400",0,[[963,768,31]]],["amd radeon hd 7400m","7400",0,[[1366,768,44]]],["amd radeon hd 7420g","7420",0,[[1366,768,28],[1600,900,26]]],["amd radeon hd 7450","7450",0,[[1920,1080,15]]],["amd radeon hd 7450a","7450",0,[[1920,1080,15]]],["amd radeon hd 7450m","7450",0,[[1366,768,30]]],["amd radeon hd 7470","7470",0,[[1680,1050,22],[1920,1080,144]]],["amd radeon hd 7470m","7470",0,[[1366,768,31],[1600,900,23]]],["amd radeon hd 7480d","7480",0,[[1280,1024,25],[1920,1080,24],[1920,1200,18]]],["amd radeon hd 7500","7500",0,[[1366,696,49],[1366,768,49]]],["amd radeon hd 7500g","7500",0,[[1366,768,26]]],["amd radeon hd 7500m/7600m","7500",0,[[1366,768,46]]],["amd radeon hd 7520g","7520",0,[[1366,768,33]]],["amd radeon hd 7520g + hd 7400m dual","7520",0,[[1366,768,34]]],["amd radeon hd 7520g + hd 7600m dual","7520",0,[[1366,768,31],[1600,900,41]]],["amd radeon hd 7540d","7540",0,[[1024,768,55],[1280,1024,44],[1920,1080,22]]],["amd radeon hd 7540d + hd 6670 dual","7540",0,[[1280,1024,36]]],["amd radeon hd 7550m/7650m","7550",0,[[1366,768,57]]],["amd radeon hd 7560d","7560",0,[[1920,1080,34]]],["amd radeon hd 7560d + hd 6570 dual","7560",0,[[1680,1050,44]]],["amd radeon hd 7560d + hd 6670 dual","7560",0,[[800,638,60]]],["amd radeon hd 7570","7570",0,[[1024,768,72],[1920,1080,52]]],["amd radeon hd 7570m","7570",0,[[1366,768,35]]],["amd radeon hd 7570m/hd 7670m","7570",0,[[1366,768,50],[1600,900,29]]],["amd radeon hd 7600","7600",0,[[1920,1080,60]]],["amd radeon hd 7600a","7600",0,[[1920,1080,28]]],["amd radeon hd 7600g","7600",0,[[1366,768,29]]],["amd radeon hd 7600g + 7500m/7600m dual","7600",0,[[1366,768,19]]],["amd radeon hd 7600g + hd 8670m dual","7600",0,[[1366,768,29]]],["amd radeon hd 7600g + hd dual","7600",0,[[1366,768,20]]],["amd radeon hd 7600m","7600",0,[[1366,768,56]]],["amd radeon hd 7600m/7700m","7600",0,[[1366,768,31]]],["amd radeon hd 7610m","7610",0,[[1366,768,43]]],["amd radeon hd 7620g","7620",0,[[1366,768,22],[1920,1080,19]]],["amd radeon hd 7640g","7640",0,[[1366,768,38]]],["amd radeon hd 7640g + 7470m dual","7640",0,[[1366,768,32]]],["amd radeon hd 7640g + 7600m dual","7640",0,[[1366,768,23]]],["amd radeon hd 7640g + 7670m dual","7640",0,[[1600,900,15]]],["amd radeon hd 7640g + 8500m dual","7640",0,[[1366,768,35]]],["amd radeon hd 7640g + hd 7400m dual","7640",0,[[1366,768,37]]],["amd radeon hd 7640g + hd 7500 dual","7640",0,[[1366,768,35]]],["amd radeon hd 7640g + hd 7670m dual","7640",0,[[1366,768,34]]],["amd radeon hd 7640g + hd 8500m dual","7640",0,[[1366,768,40]]],["amd radeon hd 7640g + hd 8570m dual","7640",0,[[1366,768,31]]],["amd radeon hd 7650a","7650",0,[[1680,1050,43],[1920,1080,15]]],["amd radeon hd 7650m","7650",0,[[1366,768,41],[1600,900,45]]],["amd radeon hd 7660d","7660",0,[[1680,1050,40],[1920,1008,60],[1920,1080,38]]],["amd radeon hd 7660d + hd 6570 dual","7660",0,[[1200,900,32]]],["amd radeon hd 7660d + hd 6670 dual","7660",0,[[1360,768,57],[1920,1080,53]]],["amd radeon hd 7660g","7660",0,[[1366,768,44],[1600,900,41],[1920,1080,34],[1920,1200,27]]],["amd radeon hd 7660g + 7600m dual","7660",0,[[1366,768,53],[1600,900,45]]],["amd radeon hd 7660g + 7670m dual","7660",0,[[1366,768,52]]],["amd radeon hd 7660g + 8670m dual","7660",0,[[1600,900,46]]],["amd radeon hd 7660g + hd 7600m dual","7660",0,[[1366,768,50]]],["amd radeon hd 7660g + hd 7670m dual","7660",0,[[1366,768,35]]],["amd radeon hd 7660g + hd 8600m dual","7660",0,[[1600,900,29]]],["amd radeon hd 7670","7670",0,[[1920,1080,39]]],["amd radeon hd 7670m","7670",0,[[1366,768,49],[1920,1080,36]]],["amd radeon hd 7700","7700",0,[[1400,1050,45],[1920,1080,60]]],["amd radeon hd 7700m","7700",0,[[1920,1080,54]]],["amd radeon hd 7730m","7730",0,[[1920,1080,57]]],["amd radeon hd 7750","7750",0,[[1280,1024,60],[1600,900,60],[1400,1050,98],[1920,1080,60],[3840,2160,23]]],["amd radeon hd 7750 / r7 250e","7750",0,[[2560,1080,69]]],["amd radeon hd 7750m","7750",0,[[1680,1050,57]]],["amd radeon hd 7770","7770",0,[[1920,1080,60]]],["amd radeon hd 7770 / r7 250x","7770",0,[[1680,1050,78]]],["amd radeon hd 7770 ghz","7770",0,[[1920,1080,78]]],["amd radeon hd 7790","7790",0,[[1920,1080,16]]],["amd radeon hd 7790 / r7 360 / r9 260/360","7790",0,[[1280,1024,131]]],["amd radeon hd 7800","7800",0,[[1920,1080,60]]],["amd radeon hd 7800m","7800",0,[[1920,1080,57]]],["amd radeon hd 7850","7850",0,[[1920,1080,60]]],["amd radeon hd 7850 / r7 265 / r9 270 1024sp","7850",0,[[1280,1024,87]]],["amd radeon hd 7870","7870",0,[[1920,1080,120],[2560,1440,60],[2560,1600,114],[3840,2160,30]]],["amd radeon hd 7870 ghz","7870",0,[[1920,1080,75]]],["amd radeon hd 7870 xt","7870",0,[[1920,1080,57],[3840,2160,53]]],["amd radeon hd 7870m","7870",0,[[1920,1080,22],[2732,1536,40]]],["amd radeon hd 7900","7900",0,[[2560,1600,59]]],["amd radeon hd 7950","7950",0,[[1920,1080,50]]],["amd radeon hd 7950 / r9 280","7950",0,[[1920,1080,59]]],["amd radeon hd 7950 oem / r9 280","7950",0,[[1920,1080,60]]],["amd radeon hd 7970","7970",0,[[1920,1080,60]]],["amd radeon hd 7970 / r9 280x","7970",0,[[1920,1080,193]]],["amd radeon hd 7970m","7970",0,[[1366,768,60],[1920,1080,60]]],["amd radeon hd 7970x/8970 280x","7970",0,[[1920,1080,60]]],["amd radeon hd 7990","7990",0,[[1920,1080,60],[5120,2880,63]]],["amd radeon hd 7xxx","7",0,[[1920,1080,60]]],["amd radeon hd 8180","8180",0,[[1366,768,10]]],["amd radeon hd 8200 / r3","8200",0,[[1366,768,21],[1600,900,13],[1680,1050,13]]],["amd radeon hd 8210","8210",0,[[1366,768,18]]],["amd radeon hd 8240","8240",0,[[1600,900,17]]],["amd radeon hd 8240 / r3","8240",0,[[1366,768,14]]],["amd radeon hd 8250","8250",0,[[1366,768,14],[1920,1200,10]]],["amd radeon hd 8280","8280",0,[[1600,900,60]]],["amd radeon hd 8280 / r3","8280",0,[[1366,768,22]]],["amd radeon hd 8280e","8280",0,[[2880,1620,6]]],["amd radeon hd 8330","8330",0,[[1366,768,24]]],["amd radeon hd 8350","8350",0,[[1920,1080,57]]],["amd radeon hd 8350g","8350",0,[[1366,768,18]]],["amd radeon hd 8370d","8370",0,[[1366,768,60],[1280,1024,26],[1920,1080,22]]],["amd radeon hd 8400","8400",0,[[1366,768,30],[1920,1080,16]]],["amd radeon hd 8400 / r3","8400",0,[[1360,768,19],[1366,768,22],[1920,1080,12]]],["amd radeon hd 8400e","8400",0,[[1680,1050,17],[1920,1080,16],[1920,1200,14]]],["amd radeon hd 8410g","8410",0,[[1366,768,32]]],["amd radeon hd 8450g","8450",0,[[1366,768,23]]],["amd radeon hd 8450g + hd 8750m dual","8450",0,[[1366,768,21]]],["amd radeon hd 8470","8470",0,[[1920,1080,17]]],["amd radeon hd 8470 + 7660d dual","8470",0,[[1920,1080,60]]],["amd radeon hd 8470d","8470",0,[[1280,1024,44],[1920,1080,21]]],["amd radeon hd 8470d + hd 6450 dual","8470",0,[[1600,900,37]]],["amd radeon hd 8490","8490",0,[[1920,1080,18],[1920,1200,20]]],["amd radeon hd 8500m","8500",0,[[1366,768,41],[1920,1080,19]]],["amd radeon hd 8500m/8700m","8500",0,[[1920,1080,30]]],["amd radeon hd 8510g","8510",0,[[1366,768,29],[1920,1080,17]]],["amd radeon hd 8550","8550",0,[[1920,1080,25]]],["amd radeon hd 8550g","8550",0,[[1366,768,34],[1600,900,41],[1920,1080,34]]],["amd radeon hd 8550g + 8500m dual","8550",0,[[1366,768,42]]],["amd radeon hd 8550g + 8600 dual","8550",0,[[1920,1080,27]]],["amd radeon hd 8550g + hd 8570m dual","8550",0,[[1366,768,32]]],["amd radeon hd 8550g + hd 8600 dual","8550",0,[[1366,768,60]]],["amd radeon hd 8550g + hd 8750m dual","8550",0,[[1366,768,37]]],["amd radeon hd 8550g + r5 m230 dual","8550",0,[[1366,768,29]]],["amd radeon hd 8570","8570",0,[[1280,1024,60],[1680,1050,54],[1920,1080,50]]],["amd radeon hd 8570 / r5 430 / r7 240 / radeon 520","8570",0,[[1920,1080,25]]],["amd radeon hd 8570d","8570",0,[[1920,1080,16]]],["amd radeon hd 8570d + r7 240 dual","8570",0,[[1920,1080,45]]],["amd radeon hd 8570m","8570",0,[[1366,768,40]]],["amd radeon hd 8600","8600",0,[[1366,768,41]]],["amd radeon hd 8600m","8600",0,[[1366,768,42],[1920,1080,14]]],["amd radeon hd 8610g","8610",0,[[1366,768,31],[1920,1080,16]]],["amd radeon hd 8610g + 8600m dual","8610",0,[[1366,768,22]]],["amd radeon hd 8610g + hd 8600m dual","8610",0,[[1366,768,41]]],["amd radeon hd 8610g + hd 8670m dual","8610",0,[[1366,768,33]]],["amd radeon hd 8650g","8650",0,[[1360,768,44],[1366,768,44]]],["amd radeon hd 8650g + 8500m dual","8650",0,[[1366,768,35]]],["amd radeon hd 8650g + 8600 dual","8650",0,[[1920,1080,38]]],["amd radeon hd 8650g + 8600m dual","8650",0,[[1366,768,21]]],["amd radeon hd 8650g + 8670m dual","8650",0,[[1366,768,66]]],["amd radeon hd 8650g + 8750m dual","8650",0,[[1920,1080,28]]],["amd radeon hd 8650g + hd 7600m dual","8650",0,[[1366,768,36]]],["amd radeon hd 8650g + hd 8500m dual","8650",0,[[1366,768,23]]],["amd radeon hd 8650g + hd 8570m dual","8650",0,[[1366,768,36]]],["amd radeon hd 8650g + hd 8600m dual","8650",0,[[1366,768,46],[1600,900,29]]],["amd radeon hd 8650g + hd 8750m dual","8650",0,[[1366,768,36]]],["amd radeon hd 8650g + r5 m200 dual","8650",0,[[1366,768,35]]],["amd radeon hd 8670 / r7 250","8670",0,[[1024,768,1]]],["amd radeon hd 8670a/8670m/8690m","8670",0,[[1366,768,47]]],["amd radeon hd 8670a/8670m/8750m","8670",0,[[1366,768,60]]],["amd radeon hd 8670d","8670",0,[[1024,768,45],[1280,1024,69],[1920,1080,38]]],["amd radeon hd 8670d + 7700 dual","8670",0,[[1680,1050,58]]],["amd radeon hd 8670d + hd 6670 dual","8670",0,[[1680,1050,33]]],["amd radeon hd 8670d + r5 200 dual","8670",0,[[2560,1080,14]]],["amd radeon hd 8670d + r7 200 dual","8670",0,[[1920,1080,37]]],["amd radeon hd 8670m","8670",0,[[1366,768,41]]],["amd radeon hd 8690a","8690",0,[[1920,1080,31]]],["amd radeon hd 8690m","8690",0,[[1600,900,35]]],["amd radeon hd 8700m","8700",0,[[1366,768,60]]],["amd radeon hd 8730m","8730",0,[[1366,768,59]]],["amd radeon hd 8750m","8750",0,[[1366,768,60]]],["amd radeon hd 8770","8770",0,[[1920,1080,111]]],["amd radeon hd 8790m","8790",0,[[1600,900,78],[1920,1080,60]]],["amd radeon hd 8800m","8800",0,[[1920,1080,60],[2880,1800,45]]],["amd radeon hd 8830m","8830",0,[[1920,1080,82]]],["amd radeon hd 8850m","8850",0,[[1366,768,45]]],["amd radeon hd 8870m","8870",0,[[1280,1024,60],[1600,900,60]]],["amd radeon hd 8950","8950",0,[[1920,1080,60],[1920,1200,59]]],["amd radeon hd 8970","8970",0,[[2560,1600,60]]],["amd radeon hd 8970m","8970",0,[[1920,1080,146],[1920,1200,60]]],["amd radeon hd 8xxx","8",0,[[1920,1080,120],[2560,1440,58]]],["amd radeon hd5450","5450",0,[[1280,720,24]]],["amd radeon hd6870","6870",0,[[1920,1080,60]]],["amd radeon hd7970m","7970",0,[[2560,1440,116]]],["amd radeon hd8530m","8530",0,[[1366,768,40]]],["amd radeon hd8730","8730",0,[[1680,1050,42]]],["amd radeon hd8970m","8970",0,[[1920,1080,74]]],["amd radeon hybrid","",0,[[1366,768,27]]],["amd radeon infoshock rx 460","460",0,[[1360,768,102]]],["amd radeon instinct mi25","25",0,[[1920,1200,26]]],["amd radeon instinct mi25 mxgpu","25",0,[[1920,1080,20],[1920,1200,32]]],["amd radeon m535dx","535",0,[[1366,768,58]]],["amd radeon navi14","14",0,[[3840,2160,60]]],["amd radeon polaris","",0,[[3840,2160,60],[5120,2880,44]]],["amd radeon polaris 10","10",0,[[1920,1200,60]]],["amd radeon pro","pro",0,[[1920,1080,114]]],["amd radeon pro 270x","270",0,[[2560,1440,74]]],["amd radeon pro 450","450",0,[[1920,1080,30],[2880,1800,43],[3360,2100,36],[5120,2880,30]]],["amd radeon pro 450 opengl engine","450",0,[[1920,1200,60]]],["amd radeon pro 455","455",0,[[2879,1800,54],[2880,1800,48],[3360,2100,37]]],["amd radeon pro 455 opengl engine","455",0,[[3360,2100,36]]],["amd radeon pro 460","460",0,[[2880,1800,50],[3360,2100,42]]],["amd radeon pro 460 opengl engine","460",0,[[5760,3240,15]]],["amd radeon pro 470","470",0,[[6016,3384,49]]],["amd radeon pro 480","480",0,[[1920,1080,60]]],["amd radeon pro 5300","5300",0,[[5120,2880,60]]],["amd radeon pro 5300m","5300",0,[[1920,1080,214],[3584,2240,130]]],["amd radeon pro 5500 xt","5500",0,[[5120,2880,51]]],["amd radeon pro 5500m","5500",0,[[3072,1920,60],[3584,2240,139]]],["amd radeon pro 555","555",0,[[2879,1800,54],[2880,1800,36],[3360,2100,40]]],["amd radeon pro 555x","555",0,[[2880,1800,42],[3360,2100,39]]],["amd radeon pro 560","560",0,[[2879,1800,56],[2880,1800,56],[3360,2100,42]]],["amd radeon pro 5600m","5600",0,[[3072,1920,60],[3584,2240,60]]],["amd radeon pro 560x","560",0,[[2879,1800,59],[2880,1800,71],[3360,2100,43]]],["amd radeon pro 570","570",0,[[5120,2880,48]]],["amd radeon pro 570 opengl engine","570",0,[[5120,2880,46]]],["amd radeon pro 5700","5700",0,[[5120,2880,60]]],["amd radeon pro 5700 xt","5700",0,[[5120,2880,60]]],["amd radeon pro 570x","570",0,[[5120,2880,50]]],["amd radeon pro 575","575",0,[[4096,2304,60],[5120,2880,50]]],["amd radeon pro 575 opengl engine","575",0,[[5120,2880,48]]],["amd radeon pro 575x","575",0,[[5120,2880,56]]],["amd radeon pro 580","580",0,[[5120,2880,54]]],["amd radeon pro 580 opengl engine","580",0,[[5120,2880,50]]],["amd radeon pro 580x","580",0,[[5120,2880,52]]],["amd radeon pro duo","pro",0,[[1920,1080,234],[1800,1350,59],[3840,2160,82],[4096,2160,60]]],["amd radeon pro rx 560","560",0,[[2560,1080,60]]],["amd radeon pro ssg","pro",0,[[3440,1440,125]]],["amd radeon pro v340","340",0,[[1920,1080,112]]],["amd radeon pro v520 mxgpu","520",0,[[1920,1080,271]]],["amd radeon pro v7350x2","7350",0,[[1920,1080,60]]],["amd radeon pro vega 16","16",0,[[2879,1800,60],[3360,2100,60]]],["amd radeon pro vega 20","20",0,[[2880,1800,120],[3360,2100,121],[3840,2160,30]]],["amd radeon pro vega 48","48",0,[[5120,2880,86]]],["amd radeon pro vega 56","56",0,[[1920,1080,60],[5120,2880,60]]],["amd radeon pro vega 56 opengl engine","56",0,[[5120,2880,60]]],["amd radeon pro vega 64","64",0,[[5120,2880,60]]],["amd radeon pro vega 64 opengl engine","64",0,[[5120,2880,60]]],["amd radeon pro vega 64x","64",0,[[2560,1440,206],[4096,2304,60],[5120,2880,60]]],["amd radeon pro vega ii","proii",0,[[3840,1600,60],[5120,2880,60]]],["amd radeon pro vega ii duo","proii",0,[[2560,1440,239],[5120,2880,60]]],["amd radeon pro w5500","5500",0,[[1920,1080,195],[3840,2160,59],[7680,3240,56]]],["amd radeon pro w5500m","5500",0,[[1920,1080,60]]],["amd radeon pro w5500x","5500",0,[[1920,1200,60]]],["amd radeon pro w5700","5700",0,[[1680,1050,253],[5120,1440,120],[3840,2160,60]]],["amd radeon pro w5700x","5700",0,[[3840,2160,60]]],["amd radeon pro w6600","6600",0,[[1920,1200,60],[3840,2160,166]]],["amd radeon pro w6600m","6600",0,[[1920,1080,60]]],["amd radeon pro w6800","6800",0,[[1920,1080,60],[3840,2160,237]]],["amd radeon pro w6800x","6800",0,[[6016,3384,60]]],["amd radeon pro w6800x duo","6800",0,[[3840,1600,60],[5120,2880,45]]],["amd radeon pro w6900x","6900",0,[[3840,2160,60]]],["amd radeon pro wx","pro",0,[[2560,1080,69]]],["amd radeon pro wx 2100","2100",0,[[1280,1024,145],[1920,1080,60]]],["amd radeon pro wx 3100","3100",0,[[1919,1080,58],[1920,1080,123],[2560,1440,82]]],["amd radeon pro wx 3200","3200",0,[[2560,1440,92]]],["amd radeon pro wx 4100","4100",0,[[1920,1080,60],[1920,1200,60],[3840,2160,30],[5120,2880,18]]],["amd radeon pro wx 4130","4130",0,[[1920,1080,60],[3840,2160,30]]],["amd radeon pro wx 4150","4150",0,[[1920,1080,56],[3840,2160,37],[4096,2160,34]]],["amd radeon pro wx 5100","5100",0,[[1920,1080,60],[2560,1440,91],[3840,2160,55]]],["amd radeon pro wx 5100 opengl engine","5100",0,[[2560,1440,60]]],["amd radeon pro wx 7100","7100",0,[[1920,1080,122],[2560,1080,58],[3840,2160,60],[5120,2880,60]]],["amd radeon pro wx 7100 mobile","7100",0,[[2560,1440,60]]],["amd radeon pro wx 7100 opengl engine","7100",0,[[3840,2160,60]]],["amd radeon pro wx 8200","8200",0,[[3440,1440,124]]],["amd radeon pro wx 9100","9100",0,[[1920,1080,60],[4096,2160,101]]],["amd radeon pro wx 9100 opengl engine","9100",0,[[1920,1080,60]]],["amd radeon pro wx vega m gl","prom",0,[[3840,2160,14]]],["amd radeon pro wx3200","3200",0,[[1920,1080,55]]],["amd radeon pro wx9100","9100",0,[[2560,1440,60]]],["amd radeon r2","2",0,[[1366,768,13],[1600,900,14]]],["amd radeon r2e","2",0,[[1366,768,16],[1920,1080,45],[3840,2160,4]]],["amd radeon r3","3",0,[[1366,768,17],[1920,1080,15]]],["amd radeon r4","4",0,[[1366,768,19],[1920,1080,13]]],["amd radeon r4e","4",0,[[3840,2160,6]]],["amd radeon r5","5",0,[[1024,768,38],[1360,768,25],[1366,768,21],[1280,1024,33],[1920,1080,14],[3200,1800,7]]],["amd radeon r5 220","5",0,[[1366,768,19],[1920,1080,12]]],["amd radeon r5 230","5",0,[[1920,1080,21]]],["amd radeon r5 235","5",0,[[1920,1080,17]]],["amd radeon r5 240","5",0,[[1280,1024,34],[1920,1080,24]]],["amd radeon r5 340","5",0,[[1920,1080,27]]],["amd radeon r5 340x","5",0,[[1920,1080,31]]],["amd radeon r5 430","5",0,[[1280,1024,31],[1680,1050,54],[1920,1080,54]]],["amd radeon r5 435","5",0,[[1920,1080,30]]],["amd radeon r5 m200","5",0,[[1600,900,45],[1920,1080,20]]],["amd radeon r5 m200 / hd 8500m","5",0,[[1366,768,31],[1920,1080,24]]],["amd radeon r5 m230","5",0,[[1366,768,37]]],["amd radeon r5 m240","5",0,[[1366,768,42],[1920,1080,23]]],["amd radeon r5 m255","5",0,[[1366,768,59],[1600,900,33]]],["amd radeon r5 m315","5",0,[[1366,768,45]]],["amd radeon r5 m320","5",0,[[1920,1080,19]]],["amd radeon r5 m330","5",0,[[1366,768,27],[1920,1080,26]]],["amd radeon r5 m335","5",0,[[1366,768,55],[1920,1080,19]]],["amd radeon r5 m420","5",0,[[1366,768,49]]],["amd radeon r5 m430","5",0,[[1366,768,36],[1920,1080,20]]],["amd radeon r5 m435","5",0,[[1920,1080,41],[2560,1440,67]]],["amd radeon r5 m445","5",0,[[1920,1080,32]]],["amd radeon r5e","5",0,[[1600,768,14],[1920,1080,16]]],["amd radeon r6","6",0,[[1366,768,30],[1280,1024,23],[1920,1080,12]]],["amd radeon r6 m255dx","6",0,[[1366,768,25]]],["amd radeon r6 m340dx","6",0,[[1366,768,31],[1920,1080,15]]],["amd radeon r6e","6",0,[[3840,2160,5]]],["amd radeon r7","7",0,[[1366,768,35],[1280,1024,31],[1680,1050,39],[1920,1080,12],[1920,1200,16],[2560,1080,15],[2560,1440,21],[3840,2160,8]]],["amd radeon r7 200","7",0,[[1280,1024,45],[1920,1080,120]]],["amd radeon r7 200 series","7",0,[[1920,1080,43]]],["amd radeon r7 240","7",0,[[1920,1080,29]]],["amd radeon r7 240 + hd 8570d dual","7",0,[[1920,1080,43]]],["amd radeon r7 250","7",0,[[1920,1080,49]]],["amd radeon r7 250e","7",0,[[1920,1080,60]]],["amd radeon r7 250x","7",0,[[1920,1080,60]]],["amd radeon r7 260x","7",0,[[1920,1080,56]]],["amd radeon r7 260x/360","7",0,[[1920,1200,102]]],["amd radeon r7 350","7",0,[[1024,768,60],[1280,1024,79],[1920,1080,59]]],["amd radeon r7 350x","7",0,[[1920,1080,50]]],["amd radeon r7 360","7",0,[[1920,1048,60],[1920,1080,102]]],["amd radeon r7 360 / r9 360","7",0,[[1920,1080,60]]],["amd radeon r7 370","7",0,[[1600,900,60],[1920,1080,75]]],["amd radeon r7 370 / r9 270","7",0,[[1920,1080,74]]],["amd radeon r7 370 / r9 270x/370","7",0,[[1600,900,115],[1920,1080,60]]],["amd radeon r7 370 / r9 270x/370x","7",0,[[1920,1080,115]]],["amd radeon r7 370 series","7",0,[[1920,1080,212],[3840,2160,60]]],["amd radeon r7 430","7",0,[[1920,1080,55],[3840,2160,10]]],["amd radeon r7 450","7",0,[[1920,1080,60]]],["amd radeon r7 a360","7",0,[[1920,1080,28]]],["amd radeon r7 graphics + hd 7700 dual","7",0,[[1600,1200,72]]],["amd radeon r7 graphics + r5 340 dual","7",0,[[1920,1080,47]]],["amd radeon r7 graphics + r7 200 dual","7",0,[[1920,1080,45],[1920,1200,47]]],["amd radeon r7 graphics + r7 350 dual","7",0,[[1919,1080,60]]],["amd radeon r7 m260","7",0,[[1600,900,44],[1920,1080,13]]],["amd radeon r7 m260dx","7",0,[[1366,768,46],[1920,1080,18]]],["amd radeon r7 m260x","7",0,[[1920,1080,29]]],["amd radeon r7 m265","7",0,[[1366,768,48],[1920,1080,27]]],["amd radeon r7 m270","7",0,[[1920,1080,31],[3840,2160,10]]],["amd radeon r7 m340","7",0,[[1366,768,60],[1920,1080,32]]],["amd radeon r7 m350","7",0,[[3840,2160,12]]],["amd radeon r7 m360","7",0,[[1366,768,40],[1920,1080,22]]],["amd radeon r7 m370","7",0,[[1920,1080,24]]],["amd radeon r7 m440","7",0,[[1920,1080,39]]],["amd radeon r7 m445","7",0,[[1920,1080,36]]],["amd radeon r7 m460","7",0,[[1919,1080,24],[1920,1080,29]]],["amd radeon r7 m520","7",0,[[1919,1080,17]]],["amd radeon r7 series / hd 9000","7",0,[[1920,1080,71],[2560,1080,59]]],["amd radeon r7e","7",0,[[1024,768,41]]],["amd radeon r8 m350dx","8",0,[[1366,768,30]]],["amd radeon r8 m365dx","8",0,[[1920,1080,28]]],["amd radeon r8 m435dx","8",0,[[1920,1080,22]]],["amd radeon r8 m445dx","8",0,[[1366,768,38],[1920,1080,27]]],["amd radeon r8 m535dx","8",0,[[1366,768,55]]],["amd radeon r9","9",0,[[1920,1080,60]]],["amd radeon r9 200","9",0,[[1920,1080,60]]],["amd radeon r9 200 / hd 7900","9",0,[[1920,1080,250]]],["amd radeon r9 255","9",0,[[1600,900,52],[1920,1080,51]]],["amd radeon r9 260","9",0,[[1920,1080,16]]],["amd radeon r9 270","9",0,[[1280,1024,60],[1920,1080,60]]],["amd radeon r9 270 1024sp","9",0,[[1920,1080,135]]],["amd radeon r9 270x","9",0,[[1920,1080,30]]],["amd radeon r9 280","9",0,[[1920,1080,75],[1920,1200,428],[2560,1440,60]]],["amd radeon r9 280,","9",0,[[5120,2880,39]]],["amd radeon r9 280x","9",0,[[1920,1080,137]]],["amd radeon r9 285","9",0,[[1920,1080,60],[1920,1200,129]]],["amd radeon r9 290","9",0,[[1920,1080,60]]],["amd radeon r9 290x","9",0,[[1920,1080,60],[2560,1440,60],[3840,2160,118]]],["amd radeon r9 300","9",0,[[1920,1080,59]]],["amd radeon r9 350","9",0,[[1920,1200,63]]],["amd radeon r9 360","9",0,[[1600,900,83],[1920,1080,60],[2560,1440,59]]],["amd radeon r9 370","9",0,[[1680,1050,205],[1920,1080,60],[3840,2160,49]]],["amd radeon r9 370x","9",0,[[1920,1080,60]]],["amd radeon r9 380","9",0,[[1920,1080,41],[2560,1440,75]]],["amd radeon r9 380x","9",0,[[2560,1600,60]]],["amd radeon r9 390","9",0,[[1920,1080,60],[2560,1440,60]]],["amd radeon r9 390x","9",0,[[2560,1440,60],[3840,2160,60]]],["amd radeon r9 a375","9",0,[[1920,1080,28]]],["amd radeon r9 fury","9",0,[[1920,1080,75],[3840,2160,133]]],["amd radeon r9 fury / nano","9",0,[[1920,1200,155]]],["amd radeon r9 m200x","9",0,[[1366,768,104],[1920,1080,60]]],["amd radeon r9 m265x","9",0,[[1920,1080,33]]],["amd radeon r9 m270x","9",0,[[1600,900,60],[1920,1080,68]]],["amd radeon r9 m275","9",0,[[1920,1080,29]]],["amd radeon r9 m275x","9",0,[[1920,1080,20]]],["amd radeon r9 m280x","9",0,[[1920,1080,60],[2560,1440,25]]],["amd radeon r9 m290","9",0,[[5120,2880,33]]],["amd radeon r9 m290x","9",0,[[1920,1080,60],[3840,2160,61],[5120,2880,33]]],["amd radeon r9 m295x","9",0,[[3840,2160,33],[5120,2880,36]]],["amd radeon r9 m295x mac","9",0,[[5120,2880,42]]],["amd radeon r9 m295x mac edition / r9 380x","9",0,[[1920,1080,128]]],["amd radeon r9 m360","9",0,[[1920,1080,60],[3840,2160,26]]],["amd radeon r9 m370x","9",0,[[2560,1440,30],[2880,1800,27]]],["amd radeon r9 m370x opengl engine","9",0,[[5120,2880,14]]],["amd radeon r9 m375","9",0,[[1920,1080,29]]],["amd radeon r9 m375x","9",0,[[1920,1080,60],[3840,2160,22]]],["amd radeon r9 m380","9",0,[[1920,1080,50],[3840,2160,8],[5120,2880,9]]],["amd radeon r9 m380 opengl engine","9",0,[[5120,2880,15]]],["amd radeon r9 m385","9",0,[[1920,1080,58]]],["amd radeon r9 m385x","9",0,[[1920,1080,60]]],["amd radeon r9 m390","9",0,[[5119,2879,29],[5120,2880,21],[5760,3240,32]]],["amd radeon r9 m390 opengl engine","9",0,[[5120,2880,27]]],["amd radeon r9 m390x","9",0,[[1920,1080,140]]],["amd radeon r9 m395","9",0,[[2560,1440,59],[5120,2880,19]]],["amd radeon r9 m395 opengl engine","9",0,[[5120,2880,38]]],["amd radeon r9 m395x","9",0,[[3840,2160,58],[5120,2880,36]]],["amd radeon r9 m395x opengl engine","9",0,[[5120,2880,35]]],["amd radeon r9 m470","9",0,[[3840,2160,29]]],["amd radeon r9 m470x","9",0,[[1920,1080,60]]],["amd radeon r9-290x","9",0,[[1920,1080,60]]],["amd radeon renoir graphics d1","1",0,[[1366,768,60]]],["amd radeon rro 580x","580",0,[[5120,2880,59]]],["amd radeon rx 460","460",0,[[1920,1080,55],[2560,1080,60],[3840,2160,31]]],["amd radeon rx 460 / pro 450/455/460/555/555x/560/560x","460",0,[[3440,1440,93]]],["amd radeon rx 460 / pro 450/455/460/560","460",0,[[1920,1080,72]]],["amd radeon rx 470","470",0,[[1280,1024,73],[1920,1080,58],[1920,1200,147],[3840,2160,51]]],["amd radeon rx 470 opengl engine","470",0,[[2560,1440,60]]],["amd radeon rx 475m","475",0,[[1920,1080,60]]],["amd radeon rx 480","480",0,[[1400,1050,267],[1920,1080,60],[2560,1080,71]]],["amd radeon rx 480 opengl engine","480",0,[[1920,1080,60]]],["amd radeon rx 5300m","5300",0,[[1920,1080,60],[3840,2160,60]]],["amd radeon rx 540","540",0,[[1919,1080,52],[1920,1080,36]]],["amd radeon rx 550","550",0,[[1280,1024,135],[1920,1080,60],[1920,1200,60],[6016,3384,15]]],["amd radeon rx 550 640sp / rx 560","550",0,[[1920,1080,60]]],["amd radeon rx 5500","5500",0,[[1920,1080,139]]],["amd radeon rx 5500 / pro 5500m","5500",0,[[1920,1080,60],[2560,1440,227]]],["amd radeon rx 5500 xt","5500",0,[[1920,1080,239]]],["amd radeon rx 5500m","5500",0,[[1920,1048,144],[1920,1080,144],[3840,2160,60]]],["amd radeon rx 550x","550",0,[[1920,1080,52]]],["amd radeon rx 560","560",0,[[1920,1080,60],[1920,1200,42],[2560,1440,60]]],["amd radeon rx 560 [baffin]","560",0,[[1920,1080,60]]],["amd radeon rx 5600 oem/5600 xt / 5700 xt","5600",0,[[1920,1080,360],[2560,1440,164]]],["amd radeon rx 5600 xt","5600",0,[[1920,1080,75]]],["amd radeon rx 5600m","5600",0,[[1920,1080,144]]],["amd radeon rx 560d","560",0,[[2560,1080,60]]],["amd radeon rx 560x","560",0,[[1920,1080,115],[3840,2160,35]]],["amd radeon rx 570","570",0,[[1920,1080,60],[3072,1728,60]]],["amd radeon rx 570 opengl engine","570",0,[[1920,1080,226]]],["amd radeon rx 5700","5700",0,[[1920,1080,144]]],["amd radeon rx 5700 / 5700 xt","5700",0,[[3840,2160,201]]],["amd radeon rx 5700 xt","5700",0,[[1920,1080,464],[3840,2160,60],[6016,3384,34]]],["amd radeon rx 5700 xt 50th anniversary","5700",0,[[2560,1440,144],[3840,1600,60],[3840,2160,222],[5120,2880,60]]],["amd radeon rx 5700xt","5700",0,[[1920,1080,369]]],["amd radeon rx 580","580",0,[[1920,1080,60],[1920,1200,97],[2560,1440,60],[3840,2160,60]]],["amd radeon rx 580 2048sp","580",0,[[1920,1080,60]]],["amd radeon rx 580 opengl engine","580",0,[[1920,1080,145]]],["amd radeon rx 580 special","580",0,[[2560,1440,60]]],["amd radeon rx 580x","580",0,[[1920,1200,60],[3840,2160,79]]],["amd radeon rx 590","590",0,[[1920,1080,75],[2560,1440,164],[3584,2240,60]]],["amd radeon rx 640","640",0,[[1920,1080,39]]],["amd radeon rx 6500 xt","6500",0,[[1920,1080,60]]],["amd radeon rx 6600","6600",0,[[1920,1080,433],[3840,2160,57]]],["amd radeon rx 6600 xt","6600",0,[[1920,1080,60]]],["amd radeon rx 6600 xt/6600m","6600",0,[[2560,1440,60]]],["amd radeon rx 6600m","6600",0,[[1920,1080,139]]],["amd radeon rx 6700 xt","6700",0,[[1920,1080,451]]],["amd radeon rx 6700 xt / 6800m","6700",0,[[2560,1440,144]]],["amd radeon rx 6700m","6700",0,[[1920,1080,240]]],["amd radeon rx 6800","6800",0,[[2560,1440,564],[3840,2160,60]]],["amd radeon rx 6800 xt","6800",0,[[2560,1440,446],[3440,1440,144],[3840,2160,60]]],["amd radeon rx 6800 xt / 6900 xt","6800",0,[[2560,1440,239]]],["amd radeon rx 6800 xt 16gb","6800",0,[[6400,2666,60]]],["amd radeon rx 6800m","6800",0,[[1920,1080,300]]],["amd radeon rx 6900 xt","6900",0,[[3840,2160,60]]],["amd radeon rx rx 560","560",0,[[1920,1080,60]]],["amd radeon rx vega","rx",0,[[1920,1080,39]]],["amd radeon rx vega 10","10",0,[[1920,1080,38]]],["amd radeon rx vega 11","11",0,[[1920,1080,35]]],["amd radeon rx vega 56","56",0,[[1920,1080,144],[3440,1440,60],[3840,2160,60]]],["amd radeon rx vega 56 8gb","56",0,[[2560,1600,60]]],["amd radeon rx vega 56 opengl engine","56",0,[[2560,1440,60]]],["amd radeon rx vega 64","64",0,[[2560,1440,518]]],["amd radeon rx vega 64 8gb","64",0,[[2560,1440,60]]],["amd radeon rx vega 64 opengl engine","64",0,[[3840,2160,119]]],["amd radeon rx vega 64.1","64",0,[[6016,3384,60]]],["amd radeon rx vega 8","8",0,[[1920,1080,53]]],["amd radeon rx vega m gh","rxm",0,[[1920,1080,60],[2560,1440,60],[3840,2160,51]]],["amd radeon rx vega m gl","rxm",0,[[2560,1440,567],[3840,2160,59]]],["amd radeon rx vega11","11",0,[[2496,1664,30]]],["amd radeon rx460","460",0,[[1920,1080,60]]],["amd radeon rx480","480",0,[[1920,1080,102],[2560,1080,71]]],["amd radeon rx540","540",0,[[2400,1800,37]]],["amd radeon rx550","550",0,[[1920,1080,60]]],["amd radeon rx560","560",0,[[1920,1080,93]]],["amd radeon rx5600","5600",0,[[3840,2160,129]]],["amd radeon rx570","570",0,[[5120,2880,59]]],["amd radeon rx5700","5700",0,[[1920,1080,60]]],["amd radeon rx580","580",0,[[1920,1080,60]]],["amd radeon rx590 gme","590",0,[[1920,1080,112]]],["amd radeon rx6600xt","6600",0,[[3840,2160,60]]],["amd radeon sky 500","500",0,[[4096,2160,34]]],["amd radeon vega","",0,[[5120,2880,32]]],["amd radeon vega 10","10",0,[[1920,1080,44]]],["amd radeon vega 10 mobile","10",0,[[1920,1080,30]]],["amd radeon vega 11","11",0,[[1280,1024,60],[1920,1080,60],[3840,2160,17]]],["amd radeon vega 2","2",0,[[1366,768,30]]],["amd radeon vega 3","3",0,[[1440,900,44],[1920,1080,29],[3840,2160,8]]],["amd radeon vega 3 mobile","3",0,[[1920,1080,30]]],["amd radeon vega 56","56",0,[[2560,1440,144]]],["amd radeon vega 6","6",0,[[1366,768,61],[1920,1080,23]]],["amd radeon vega 64","64",0,[[6016,3384,35]]],["amd radeon vega 64 lc","64",0,[[2560,1080,60]]],["amd radeon vega 8","8",0,[[1920,1080,35],[2560,1440,24],[4096,2160,15]]],["amd radeon vega 8 mobile","8",0,[[1920,1080,36]]],["amd radeon vega 9","9",0,[[2496,1663,32],[2496,1664,39]]],["amd radeon vega fe","fe",0,[[1920,1080,120],[2560,1440,60]]],["amd radeon vega frontier","",0,[[1920,1080,120],[3840,2160,60]]],["amd radeon vega frontier edition opengl engine","",0,[[3440,1440,60]]],["amd radeon vega series / radeon vega mobile","",0,[[1920,1080,67]]],["amd radeon vii","vii",0,[[1920,1080,468],[2560,1440,60],[3840,2160,60]]],["amd radeont 540x","540",0,[[1920,1080,74],[3840,2160,22]]],["amd radeont rx 5300","5300",0,[[1920,1080,60]]],["amd radeont rx 5500m","5500",0,[[1920,1080,303]]],["amd radeont rx 560x","560",0,[[1920,1080,60]]],["amd renoir","",0,[[1920,1080,60]]],["amd rx 480","480",0,[[1680,1050,119]]],["amd rx 560","560",0,[[5120,2880,37]]],["amd rx 5700xt","5700",0,[[3840,2160,60]]],["amd rx 580","580",0,[[1920,1200,60],[5120,2880,60]]],["amd rx 590","590",0,[[5120,2880,60]]],["amd rx vega 64","64",0,[[1920,1080,60]]],["amd rx xxx","xxx",0,[[1920,1080,60],[2560,1440,144]]],["amd saphire radeon rx 580","580",0,[[1920,1080,57]]],["amd sapphire hd 5770","5770",0,[[1440,900,60]]],["amd sapphire nitro+ rx 6800","6800",0,[[1920,1080,75]]],["amd sapphire radeon hd6870","6870",0,[[1680,1050,60]]],["amd sapphire radeon rx 560","560",0,[[1280,1024,60]]],["amd sapphire radeon rx vega 64 8gb","64",0,[[2560,1440,144]]],["amd tonga pro gl [firepro w7100]","7100",0,[[1920,1200,127]]],["amd video controller","",0,[[1919,1079,60],[1920,1080,291]]],["intel radeong 0.4 on amd bonaire","0",0,[[1920,1200,92]]],["intel radeong 0.4 on amd cape verde","0",0,[[1920,1200,73]]],["intel radeong 0.4 on amd polaris10","0",0,[[3840,2160,108]]],["intel radeong 0.4 on amd tonga","0",0,[[1920,1080,124]]],["radeong 0.4 on amd polaris10","0",0,[[3840,2160,109]]],["radeong 0.4 on amd tahiti","0",0,[[1920,1080,223]]]]')},732:e=>{"use strict";e.exports=JSON.parse('["4.0.8",["apple a14","14",0,[[2704,1756,120]]],["apple m1","1",0,[[2880,1800,60]]],["apple m1 max","1",0,[[3456,2234,120]]],["apple m1 pro","1",0,[[3024,1964,120]]],["apple paravirtual device","",0,[[1024,768,30]]]]')},405:e=>{"use strict";e.exports=JSON.parse('["4.0.8",["intel geforce gtx 960","960",0,[[1920,1080,26]]],["nvidia asus geforce gt 430","430",0,[[1366,768,35]]],["nvidia asus geforce gt 440","440",0,[[1920,1080,28]]],["nvidia asus geforce gt 520","520",0,[[1680,1050,12]]],["nvidia asus geforce gt 610","610",0,[[1920,1200,15]]],["nvidia asus geforce gt 630","630",0,[[1680,1050,41]]],["nvidia asus geforce gt 640","640",0,[[2560,1440,34]]],["nvidia asus geforce gt 710","710",0,[[1920,1080,31]]],["nvidia asus geforce gt 730","730",0,[[2560,1080,28],[3840,2160,12]]],["nvidia asus geforce gts 450","450",0,[[1920,1080,54]]],["nvidia asus geforce gtx 1060","1060",0,[[3840,2160,38]]],["nvidia asus geforce gtx 1080","1080",0,[[2560,1440,120]]],["nvidia asus geforce gtx 460","460",0,[[1920,1080,60]]],["nvidia asus geforce gtx 480","480",0,[[1920,1080,59]]],["nvidia asus geforce gtx 550 ti","550",0,[[1920,1080,57]]],["nvidia asus geforce gtx 560","560",0,[[1920,1080,60]]],["nvidia asus geforce gtx 560 se","560",0,[[1920,1080,59]]],["nvidia asus geforce gtx 560 ti","560",0,[[1680,1050,58]]],["nvidia asus geforce gtx 570","570",0,[[1280,1024,74]]],["nvidia asus geforce gtx 570 hd","570",0,[[1920,1080,60]]],["nvidia asus geforce gtx 580","580",0,[[1920,1200,59]]],["nvidia asus geforce gtx 660","660",0,[[1920,1080,60]]],["nvidia asus geforce gtx 670","670",0,[[1920,1080,60]]],["nvidia asus geforce gtx 750 ti","750",0,[[1360,768,59],[1920,1080,118]]],["nvidia asus geforce gtx 760","760",0,[[1920,1080,60],[1920,1200,60]]],["nvidia asus geforce gtx 770","770",0,[[1920,1080,60]]],["nvidia asus geforce gtx 780","780",0,[[1920,1080,60]]],["nvidia asus geforce gtx 950","950",0,[[1920,1080,60]]],["nvidia asus geforce gtx 960","960",0,[[1920,1080,60],[2560,1600,117]]],["nvidia asus geforce gtx 970","970",0,[[2560,1600,60]]],["nvidia asus geforce gtx 980 ti","980",0,[[2560,1440,131]]],["nvidia colorful geforce gtx 960","960",0,[[2560,1440,60]]],["nvidia elitegroup geforce gtx 460","460",0,[[1920,1080,60]]],["nvidia evga geforce gt 545","545",0,[[1920,1080,37]]],["nvidia evga geforce gt 640","640",0,[[1366,768,60]]],["nvidia evga geforce gt 710","710",0,[[1680,1050,36],[1920,1080,29]]],["nvidia evga geforce gt 730","730",0,[[1600,900,59]]],["nvidia evga geforce gt 740","740",0,[[1280,1024,45]]],["nvidia evga geforce gtx 1050 ti","1050",0,[[2560,1440,60],[4096,2304,58]]],["nvidia evga geforce gtx 1070","1070",0,[[5120,2880,60]]],["nvidia evga geforce gtx 1080 ti","1080",0,[[1920,1200,60]]],["nvidia evga geforce gtx 560 ti","560",0,[[1680,1050,59]]],["nvidia evga geforce gtx 570","570",0,[[1920,1080,60]]],["nvidia evga geforce gtx 580","580",0,[[2560,1440,60]]],["nvidia evga geforce gtx 650","650",0,[[1920,1200,87],[2560,1600,43]]],["nvidia evga geforce gtx 650 ti","650",0,[[1680,1050,116],[2560,1440,55]]],["nvidia evga geforce gtx 650 ti boost","650",0,[[1920,1080,56]]],["nvidia evga geforce gtx 660 ti","660",0,[[1920,1200,60]]],["nvidia evga geforce gtx 680","680",0,[[1600,1200,60]]],["nvidia evga geforce gtx 750 ti","750",0,[[1920,1080,60]]],["nvidia evga geforce gtx 760","760",0,[[1920,1080,119],[1920,1200,60]]],["nvidia evga geforce gtx 780","780",0,[[1920,1080,60]]],["nvidia evga geforce gtx 960","960",0,[[1920,1080,60],[2560,1440,115]]],["nvidia evga geforce gtx 970","970",0,[[1920,1080,120]]],["nvidia evga geforce gtx 980","980",0,[[3440,1440,60]]],["nvidia evga geforce gtx 980 ti","980",0,[[1920,1080,60]]],["nvidia gainward geforce gt 630","630",0,[[1920,1080,28]]],["nvidia gainward geforce gts 450","450",0,[[1920,1080,55]]],["nvidia gainward geforce gtx 460","460",0,[[1920,1080,58]]],["nvidia gainward geforce gtx 550 ti","550",0,[[1280,1024,67]]],["nvidia gainward geforce gtx 560 ti","560",0,[[1920,1080,60]]],["nvidia gainward geforce gtx 570","570",0,[[1920,1080,60]]],["nvidia gainward geforce gtx 750 ti","750",0,[[1920,1080,60]]],["nvidia geforce 210","210",0,[[1920,1080,8]]],["nvidia geforce 410m","410",0,[[1366,768,25],[1600,900,19]]],["nvidia geforce 510","510",0,[[1280,960,20]]],["nvidia geforce 605","605",0,[[1768,992,17],[1920,1080,15]]],["nvidia geforce 610m","610",0,[[1366,768,26]]],["nvidia geforce 610m/710m/810m/820m / gt 620m/625m/630m/720m","610",0,[[1366,768,51]]],["nvidia geforce 615","615",0,[[1920,1080,21]]],["nvidia geforce 705m","705",0,[[1920,1080,18]]],["nvidia geforce 710a","710",0,[[1920,1080,32]]],["nvidia geforce 710m","710",0,[[1366,768,55]]],["nvidia geforce 730a","730",0,[[1920,1080,37]]],["nvidia geforce 800m","800",0,[[1920,1080,18]]],["nvidia geforce 810m","810",0,[[1366,768,44],[1920,1080,31]]],["nvidia geforce 820a","820",0,[[1920,1080,28]]],["nvidia geforce 820m","820",0,[[1366,768,57],[1920,1080,23]]],["nvidia geforce 830a","830",0,[[1920,1080,53]]],["nvidia geforce 830m","830",0,[[1366,768,60]]],["nvidia geforce 8400 gs","8400",0,[[1680,1050,4]]],["nvidia geforce 8400 gs rev. 3","8400",0,[[1920,1080,4]]],["nvidia geforce 840a","840",0,[[1920,1080,56]]],["nvidia geforce 840m","840",0,[[1920,1080,56]]],["nvidia geforce 845m","845",0,[[1920,1080,59]]],["nvidia geforce 8600 gt","8600",1,[[1920,1200,-1]]],["nvidia geforce 8600 gts","8600",1,[[1920,1080,-1]]],["nvidia geforce 910m","910",0,[[1366,768,58],[1600,900,45]]],["nvidia geforce 920m","920",0,[[1366,768,60]]],["nvidia geforce 920mx","920",0,[[1366,768,60],[1920,1080,60]]],["nvidia geforce 9300 / nforce 730i","9300",0,[[1920,1080,6]]],["nvidia geforce 930a","930",0,[[1920,1080,55]]],["nvidia geforce 930m","930",0,[[1366,768,60]]],["nvidia geforce 930mx","930",0,[[1366,768,89],[1920,1080,59]]],["nvidia geforce 9400 gt","9400",1,[[1366,768,-1]]],["nvidia geforce 940a","940",0,[[1920,1080,58]]],["nvidia geforce 940m","940",0,[[1920,1080,54]]],["nvidia geforce 940mx","940",0,[[1920,1080,60]]],["nvidia geforce 945m","945",0,[[1920,1080,59]]],["nvidia geforce 9600 gt","9600",0,[[1920,1200,2]]],["nvidia geforce 9600m gt","9600",1,[[1440,900,-1]]],["nvidia geforce 9800 gt","9800",0,[[1920,1200,52]]],["nvidia geforce 9800 gtx / 9800 gtx+","9800",0,[[1280,1024,59]]],["nvidia geforce gpu","gpu",0,[[3000,2000,36]]],["nvidia geforce gt 1010","1010",0,[[1920,1080,135]]],["nvidia geforce gt 1030","1030",0,[[1920,1080,60]]],["nvidia geforce gt 1030 opengl engine","1030",0,[[6720,3780,15]]],["nvidia geforce gt 120","120",1,[[1920,1080,-1]]],["nvidia geforce gt 240","240",0,[[1366,768,32]]],["nvidia geforce gt 320m","320",0,[[1366,768,26]]],["nvidia geforce gt 415m","415",0,[[1366,768,19]]],["nvidia geforce gt 420","420",0,[[1024,768,33],[1920,1080,20]]],["nvidia geforce gt 420m","420",0,[[1366,768,28]]],["nvidia geforce gt 425m","425",0,[[1366,768,55],[1600,900,28]]],["nvidia geforce gt 430","430",0,[[1600,1200,16],[1920,1080,28]]],["nvidia geforce gt 435m","435",0,[[1366,768,53],[1920,1080,22]]],["nvidia geforce gt 440","440",0,[[1280,1024,51],[1680,1050,38],[1920,1080,45]]],["nvidia geforce gt 445m","445",0,[[1600,900,53]]],["nvidia geforce gt 520","520",0,[[1440,900,19],[1920,1080,17]]],["nvidia geforce gt 520m","520",0,[[1366,768,29]]],["nvidia geforce gt 520mx","520",0,[[1366,768,35]]],["nvidia geforce gt 525m","525",0,[[1366,768,28],[1600,900,22]]],["nvidia geforce gt 530","530",0,[[1920,1080,26]]],["nvidia geforce gt 540m","540",0,[[1366,768,38]]],["nvidia geforce gt 545","545",0,[[1920,1080,54]]],["nvidia geforce gt 550m","550",0,[[1600,900,44],[1920,1080,29]]],["nvidia geforce gt 555m","555",0,[[1920,1080,42]]],["nvidia geforce gt 555m/635m","555",0,[[1920,1080,36]]],["nvidia geforce gt 610","610",0,[[1280,1024,22],[1920,1080,15]]],["nvidia geforce gt 620","620",0,[[1920,1080,19]]],["nvidia geforce gt 620 oem","620",0,[[1920,1080,20],[1920,1200,20]]],["nvidia geforce gt 620m","620",0,[[1366,768,55],[1920,1080,30]]],["nvidia geforce gt 620m/630m/635m/640m le","620",0,[[1368,768,38]]],["nvidia geforce gt 625","625",0,[[1920,1080,18]]],["nvidia geforce gt 625m","625",0,[[1366,768,38]]],["nvidia geforce gt 630","630",0,[[1680,1050,36],[1920,1080,36],[1920,1200,30]]],["nvidia geforce gt 630 oem","630",0,[[1600,900,33]]],["nvidia geforce gt 630 opengl engine","630",0,[[1920,1080,33]]],["nvidia geforce gt 630 rev. 2","630",0,[[1920,1080,26]]],["nvidia geforce gt 630m","630",0,[[1366,768,57]]],["nvidia geforce gt 635","635",0,[[1920,1080,27]]],["nvidia geforce gt 635m","635",0,[[1366,768,47]]],["nvidia geforce gt 640","640",0,[[1920,1080,47]]],["nvidia geforce gt 640 oem","640",0,[[1920,1080,46],[2560,1440,35]]],["nvidia geforce gt 640 opengl engine","640",0,[[1280,1024,43]]],["nvidia geforce gt 640 rev. 2","640",0,[[1280,1024,60],[1920,1080,55]]],["nvidia geforce gt 640m","640",0,[[1366,768,82],[1600,900,59],[1920,1080,34]]],["nvidia geforce gt 640m le","640",0,[[1920,1080,49]]],["nvidia geforce gt 640m mac","640",0,[[1366,768,56],[1920,1080,20]]],["nvidia geforce gt 640m opengl engine","640",0,[[1920,1080,45]]],["nvidia geforce gt 645m","645",0,[[1366,768,60]]],["nvidia geforce gt 650m","650",0,[[1360,768,59],[1920,1080,58],[2560,1440,59]]],["nvidia geforce gt 650m mac","650",0,[[1440,900,56],[1920,1080,15],[2560,1440,19],[2880,1800,31]]],["nvidia geforce gt 650m opengl engine","650",0,[[1920,1080,56],[3840,2160,27]]],["nvidia geforce gt 705","705",0,[[1920,1080,11]]],["nvidia geforce gt 710","710",0,[[1920,1080,28]]],["nvidia geforce gt 710b","710",0,[[1920,1080,26]]],["nvidia geforce gt 710m","710",0,[[1366,768,46]]],["nvidia geforce gt 720","720",0,[[1920,1080,19],[2560,1440,16],[5120,2880,5]]],["nvidia geforce gt 720 opengl engine","720",0,[[2560,1600,20]]],["nvidia geforce gt 720m","720",0,[[1366,768,42]]],["nvidia geforce gt 730","730",0,[[1920,1080,54]]],["nvidia geforce gt 730a","730",0,[[1920,1080,23]]],["nvidia geforce gt 730m","730",0,[[1920,1080,43]]],["nvidia geforce gt 735m","735",0,[[1920,1080,39]]],["nvidia geforce gt 740","740",0,[[1920,1080,55],[3440,1440,23]]],["nvidia geforce gt 740 opengl engine","740",0,[[1920,1200,51]]],["nvidia geforce gt 740m","740",0,[[1366,768,60]]],["nvidia geforce gt 745m","745",0,[[1920,1080,55]]],["nvidia geforce gt 750m","750",0,[[1920,1080,57]]],["nvidia geforce gt 750m mac","750",0,[[1920,1080,58],[2880,1800,28]]],["nvidia geforce gt 755m","755",0,[[1920,1080,57]]],["nvidia geforce gt 755m mac","755",0,[[2560,1440,41]]],["nvidia geforce gt 755m opengl engine","755",0,[[2560,1440,51]]],["nvidia geforce gt 820m","820",0,[[1600,900,47]]],["nvidia geforce gts 250","250",0,[[1680,1050,53]]],["nvidia geforce gts 450","450",0,[[1360,768,60],[1680,1050,57],[1920,1080,55]]],["nvidia geforce gts 450 rev. 2","450",0,[[1920,1080,56]]],["nvidia geforce gtx 1050","1050",0,[[1920,1080,60]]],["nvidia geforce gtx 1050 3gb","1050",0,[[1280,1024,60]]],["nvidia geforce gtx 1050 mobile","1050",0,[[1920,1080,60]]],["nvidia geforce gtx 1050 opengl engine","1050",0,[[1920,1080,116]]],["nvidia geforce gtx 1050 ti","1050",0,[[1920,1080,60]]],["nvidia geforce gtx 1050 ti mobile","1050",0,[[1920,1080,298]]],["nvidia geforce gtx 1050 ti opengl engine","1050",0,[[1920,1080,60]]],["nvidia geforce gtx 1050 ti with max-q design","1050",0,[[1920,1080,268],[2560,1440,102],[3840,2160,60]]],["nvidia geforce gtx 1050 with max-q design","1050",0,[[1920,1080,60],[3840,2160,24]]],["nvidia geforce gtx 1060","1060",0,[[1920,1080,60],[3840,2160,59]]],["nvidia geforce gtx 1060 3gb","1060",0,[[1920,1080,60]]],["nvidia geforce gtx 1060 3gb opengl engine","1060",0,[[1920,1080,60]]],["nvidia geforce gtx 1060 5gb","1060",0,[[1920,1080,55]]],["nvidia geforce gtx 1060 6gb","1060",0,[[1920,1080,60]]],["nvidia geforce gtx 1060 6gb opengl engine","1060",0,[[1920,1080,75]]],["nvidia geforce gtx 1060 mobile","1060",0,[[1920,1080,422]]],["nvidia geforce gtx 1060 mobile 6gb","1060",0,[[1920,1080,120]]],["nvidia geforce gtx 1060 with max-q design","1060",0,[[1920,1080,60]]],["nvidia geforce gtx 1060se 3gb","1060",0,[[1920,1080,60]]],["nvidia geforce gtx 1070","1070",0,[[1920,1080,134]]],["nvidia geforce gtx 1070 a17","1070",0,[[1920,1080,60]]],["nvidia geforce gtx 1070 mobile","1070",0,[[1920,1080,467]]],["nvidia geforce gtx 1070 opengl engine","1070",0,[[1920,1080,143]]],["nvidia geforce gtx 1070 ti","1070",0,[[1920,1080,60],[6016,3384,59]]],["nvidia geforce gtx 1070 ti opengl engine","1070",0,[[1920,1080,75]]],["nvidia geforce gtx 1070 with max-q design","1070",0,[[1920,1080,448]]],["nvidia geforce gtx 1070 with maxq design","1070",0,[[1920,1080,60],[3840,2160,59]]],["nvidia geforce gtx 1080","1080",0,[[1920,1080,119],[2560,1440,326],[3840,2160,286]]],["nvidia geforce gtx 1080 mobile","1080",0,[[1920,1080,120]]],["nvidia geforce gtx 1080 opengl engine","1080",0,[[1920,1080,79]]],["nvidia geforce gtx 1080 ti","1080",0,[[1920,1080,120]]],["nvidia geforce gtx 1080 ti opengl engine","1080",0,[[1920,1080,127]]],["nvidia geforce gtx 1080 with max-q design","1080",0,[[1920,1080,144]]],["nvidia geforce gtx 1180","1180",0,[[3440,1440,60]]],["nvidia geforce gtx 1650","1650",0,[[1920,1080,380]]],["nvidia geforce gtx 1650 mobile / max-q","1650",0,[[1920,1080,292]]],["nvidia geforce gtx 1650 super","1650",0,[[1920,1080,433]]],["nvidia geforce gtx 1650 ti","1650",0,[[1920,1080,144],[3840,2400,59]]],["nvidia geforce gtx 1650 ti mobile","1650",0,[[1920,1080,144]]],["nvidia geforce gtx 1650 ti with max-q design","1650",0,[[1920,1080,60],[3839,2160,60]]],["nvidia geforce gtx 1650 with max-q design","1650",0,[[1920,1080,142],[3000,2000,60]]],["nvidia geforce gtx 1660","1660",0,[[1920,1080,144]]],["nvidia geforce gtx 1660 super","1660",0,[[1920,1080,60]]],["nvidia geforce gtx 1660 ti","1660",0,[[1920,1080,546],[3840,2160,60]]],["nvidia geforce gtx 1660 ti mobile","1660",0,[[1920,1080,451]]],["nvidia geforce gtx 1660 ti with max-q design","1660",0,[[1920,1080,144]]],["nvidia geforce gtx 280","280",0,[[1680,1050,56]]],["nvidia geforce gtx 295","295",0,[[1920,1080,56]]],["nvidia geforce gtx 460","460",0,[[1920,1080,60]]],["nvidia geforce gtx 460 oem","460",0,[[1360,768,60],[1920,1080,60]]],["nvidia geforce gtx 460 opengl engine","460",0,[[1920,1080,59]]],["nvidia geforce gtx 460 se","460",0,[[1920,1080,56],[1920,1200,57]]],["nvidia geforce gtx 460 v2","460",0,[[1920,1080,60],[1920,1200,60],[2560,1600,55]]],["nvidia geforce gtx 460m","460",0,[[1920,1080,46]]],["nvidia geforce gtx 465","465",0,[[1920,1080,134],[1920,1200,59]]],["nvidia geforce gtx 470","470",0,[[1680,1050,60],[1920,1080,59]]],["nvidia geforce gtx 470m","470",0,[[1920,1200,55]]],["nvidia geforce gtx 480","480",0,[[1440,900,191],[1920,1080,115],[1920,1200,60]]],["nvidia geforce gtx 480 opengl engine","480",0,[[1600,1200,60]]],["nvidia geforce gtx 550 ti","550",0,[[1280,1024,58],[1920,1080,58]]],["nvidia geforce gtx 550 ti opengl engine","550",0,[[1920,1080,55]]],["nvidia geforce gtx 555","555",0,[[1920,1080,54]]],["nvidia geforce gtx 560","560",0,[[1920,1080,60]]],["nvidia geforce gtx 560 se","560",0,[[1680,1050,52],[1920,1080,111]]],["nvidia geforce gtx 560 ti","560",0,[[1920,1080,60]]],["nvidia geforce gtx 560 ti 448 cores","560",0,[[1920,1080,60],[2560,1440,60]]],["nvidia geforce gtx 560 ti oem","560",0,[[1920,1080,176]]],["nvidia geforce gtx 560 ti opengl engine","560",0,[[1920,1080,48]]],["nvidia geforce gtx 560m","560",0,[[1920,1080,55]]],["nvidia geforce gtx 570","570",0,[[1920,1080,60]]],["nvidia geforce gtx 570 opengl engine","570",0,[[1920,1080,60]]],["nvidia geforce gtx 570 rev. 2","570",0,[[1920,1080,60],[1920,1200,60]]],["nvidia geforce gtx 570m","570",0,[[1920,1080,125],[2560,1440,8]]],["nvidia geforce gtx 580","580",0,[[1920,1080,60]]],["nvidia geforce gtx 580 opengl engine","580",0,[[1680,1050,59]]],["nvidia geforce gtx 580m","580",0,[[1920,1080,60]]],["nvidia geforce gtx 590","590",0,[[1920,1080,59]]],["nvidia geforce gtx 645","645",0,[[1920,1080,57],[1920,1200,58]]],["nvidia geforce gtx 645 opengl engine","645",0,[[1920,1200,58]]],["nvidia geforce gtx 650","650",0,[[1920,1080,72]]],["nvidia geforce gtx 650 oem","650",0,[[1366,768,59]]],["nvidia geforce gtx 650 opengl engine","650",0,[[1920,1080,59]]],["nvidia geforce gtx 650 ti","650",0,[[1920,1080,60]]],["nvidia geforce gtx 650 ti boost","650",0,[[1280,1024,60],[1600,1200,187],[1920,1080,60]]],["nvidia geforce gtx 650 ti opengl engine","650",0,[[1920,1080,60]]],["nvidia geforce gtx 660","660",0,[[1920,1080,111]]],["nvidia geforce gtx 660 oem","660",0,[[1920,1080,59]]],["nvidia geforce gtx 660 ti","660",0,[[1920,1080,60]]],["nvidia geforce gtx 660 ti opengl engine","660",0,[[1280,1024,60]]],["nvidia geforce gtx 660m","660",0,[[1680,1050,36],[1920,1080,59]]],["nvidia geforce gtx 660m mac","660",0,[[2560,1440,2]]],["nvidia geforce gtx 660m opengl engine","660",0,[[2560,1440,36]]],["nvidia geforce gtx 670","670",0,[[1920,1080,100]]],["nvidia geforce gtx 670 opengl engine","670",0,[[1920,1080,60]]],["nvidia geforce gtx 670m","670",0,[[1920,1080,66]]],["nvidia geforce gtx 670mx","670",0,[[1920,1080,60]]],["nvidia geforce gtx 675m","675",0,[[1920,1080,60]]],["nvidia geforce gtx 675mx","675",0,[[1680,1050,60],[1920,1080,60],[2560,1440,55]]],["nvidia geforce gtx 675mx mac","675",0,[[2560,1440,36]]],["nvidia geforce gtx 675mx opengl engine","675",0,[[2560,1440,60]]],["nvidia geforce gtx 680","680",0,[[1920,1080,60]]],["nvidia geforce gtx 680 opengl engine","680",0,[[1920,1080,60]]],["nvidia geforce gtx 680m","680",0,[[1920,1080,39],[1920,1200,60]]],["nvidia geforce gtx 680m opengl engine","680",0,[[1920,1080,36]]],["nvidia geforce gtx 680mx","680",0,[[2560,1440,59]]],["nvidia geforce gtx 680mx opengl engine","680",0,[[2560,1440,59]]],["nvidia geforce gtx 690","690",0,[[1920,1080,60],[3840,2160,30]]],["nvidia geforce gtx 745","745",0,[[1920,1080,60],[2560,1600,29]]],["nvidia geforce gtx 750","750",0,[[1920,1080,60]]],["nvidia geforce gtx 750 opengl engine","750",0,[[1920,1200,58]]],["nvidia geforce gtx 750 ti","750",0,[[1920,1080,97]]],["nvidia geforce gtx 760","760",0,[[1920,1080,60],[1920,1200,116]]],["nvidia geforce gtx 760 oem","760",0,[[1920,1080,60]]],["nvidia geforce gtx 760 opengl engine","760",0,[[1920,1080,52]]],["nvidia geforce gtx 760 ti","760",0,[[1920,1080,60],[1920,1200,60]]],["nvidia geforce gtx 760 ti oem","760",0,[[1920,1200,60]]],["nvidia geforce gtx 760 ti opengl engine","760",0,[[1920,1080,60]]],["nvidia geforce gtx 760a","760",0,[[2560,1080,15]]],["nvidia geforce gtx 760m","760",0,[[1920,1080,60]]],["nvidia geforce gtx 765m","765",0,[[1920,1080,53],[2560,1440,57]]],["nvidia geforce gtx 765m by nick[d]vb","765",0,[[2560,1440,58]]],["nvidia geforce gtx 765m opengl engine","765",0,[[2560,1440,57]]],["nvidia geforce gtx 770","770",0,[[1920,1080,143],[2560,1440,203]]],["nvidia geforce gtx 770 opengl engine","770",0,[[1920,1080,60]]],["nvidia geforce gtx 770m","770",0,[[1920,1080,60],[2560,1440,59]]],["nvidia geforce gtx 770m by nick[d]vb","770",0,[[2560,1440,34]]],["nvidia geforce gtx 770m opengl engine","770",0,[[2560,1440,59]]],["nvidia geforce gtx 775m by idopt mac","775",0,[[2560,1440,56]]],["nvidia geforce gtx 775m mac","775",0,[[2560,1440,59]]],["nvidia geforce gtx 775m opengl engine","775",0,[[2560,1440,60]]],["nvidia geforce gtx 780","780",0,[[1920,1080,159]]],["nvidia geforce gtx 780 by st3phl3","780",0,[[3840,2160,30]]],["nvidia geforce gtx 780 mac","780",0,[[1680,1050,60],[1920,1080,60]]],["nvidia geforce gtx 780 rev. 2","780",0,[[1920,1080,144],[2560,1440,119],[3840,2160,58],[5120,2880,58]]],["nvidia geforce gtx 780 ti","780",0,[[1280,1024,120],[1920,1080,119]]],["nvidia geforce gtx 780 ti opengl engine","780",0,[[2560,1440,60]]],["nvidia geforce gtx 780m","780",0,[[1920,1080,60],[2560,1440,59]]],["nvidia geforce gtx 780m by nick[d]vb","780",0,[[1920,1080,59],[2560,1440,60]]],["nvidia geforce gtx 780m mac","780",0,[[2560,1440,60]]],["nvidia geforce gtx 780m opengl engine","780",0,[[2560,1440,60]]],["nvidia geforce gtx 850a","850",0,[[2560,1440,48]]],["nvidia geforce gtx 850m","850",0,[[1920,1080,60]]],["nvidia geforce gtx 860m","860",0,[[1920,1080,59]]],["nvidia geforce gtx 860m opengl engine","860",0,[[2560,1440,58]]],["nvidia geforce gtx 870m","870",0,[[1920,1080,60],[2560,1440,102]]],["nvidia geforce gtx 880m","880",0,[[1920,1080,60],[2560,1440,74]]],["nvidia geforce gtx 880m opengl engine","880",0,[[2560,1440,60]]],["nvidia geforce gtx 950","950",0,[[1920,1080,98]]],["nvidia geforce gtx 950 opengl engine","950",0,[[1920,1200,60]]],["nvidia geforce gtx 950a","950",0,[[1920,1080,60],[3840,2160,38]]],["nvidia geforce gtx 950m","950",0,[[1920,1080,114]]],["nvidia geforce gtx 960","960",0,[[1920,1080,60]]],["nvidia geforce gtx 960a","960",0,[[1920,1440,128]]],["nvidia geforce gtx 960m","960",0,[[1920,1080,119],[3840,2160,37]]],["nvidia geforce gtx 965m","965",0,[[1920,1080,195],[3000,2000,59],[3840,2160,41]]],["nvidia geforce gtx 965m opengl engine","965",0,[[2880,1620,55]]],["nvidia geforce gtx 970","970",0,[[1920,1080,143]]],["nvidia geforce gtx 970 opengl engine","970",0,[[2560,1600,60]]],["nvidia geforce gtx 970m","970",0,[[1920,1080,60]]],["nvidia geforce gtx 980","980",0,[[1920,1080,60],[3440,1440,294]]],["nvidia geforce gtx 980 ti","980",0,[[1920,1080,119],[2560,1440,456]]],["nvidia geforce gtx 980 ti opengl engine","980",0,[[1920,1080,60]]],["nvidia geforce gtx 980m","980",0,[[1920,1080,60],[3840,2160,104]]],["nvidia geforce gtx titan","gtx",0,[[1920,1080,119],[1920,1200,119],[2560,1440,60]]],["nvidia geforce gtx titan black","gtx",0,[[1680,1050,60],[1920,1080,60],[1920,1200,60],[2560,1440,60]]],["nvidia geforce gtx titan black opengl engine","gtx",0,[[3840,2160,60]]],["nvidia geforce gtx titan opengl engine","gtx",0,[[2560,1440,60]]],["nvidia geforce gtx titan x","gtxx",0,[[1920,1080,144],[2560,1440,120],[2560,1600,60]]],["nvidia geforce gtx titan xp","gtxxp",0,[[2560,1440,60],[3440,1440,60]]],["nvidia geforce gtx titan z","gtxz",0,[[1440,900,59],[1920,1080,39],[3840,2160,60]]],["nvidia geforce gtx780m by nikey22","780",0,[[2560,1440,60]]],["nvidia geforce gtx870m by nikey22","870",0,[[2560,1440,60]]],["nvidia geforce gtx880m","880",0,[[1920,1080,60]]],["nvidia geforce gtx880m by nikey22","880",0,[[2560,1440,59]]],["nvidia geforce gtx880m opengl engine","880",0,[[2560,1440,59]]],["nvidia geforce mx110","110",0,[[1366,768,61],[1920,1080,57]]],["nvidia geforce mx130","130",0,[[1920,1080,60]]],["nvidia geforce mx150","150",0,[[1920,1080,113]]],["nvidia geforce mx230","230",0,[[1920,1080,60]]],["nvidia geforce mx250","250",0,[[1920,1080,60]]],["nvidia geforce mx330","330",0,[[1920,1080,60],[3840,2160,51]]],["nvidia geforce mx350","350",0,[[1920,1080,60]]],["nvidia geforce mx450","450",0,[[1920,1080,60]]],["nvidia geforce pre-release graphics device","pre",0,[[2560,1440,60]]],["nvidia geforce pre-release tesla c2075 opengl engine","2075",0,[[1600,900,59]]],["nvidia geforce pre-release titan x opengl engine","prex",0,[[1920,1080,60]]],["nvidia geforce pre-release titan xp collectors edition opengl e","prexpe",0,[[1920,1080,59]]],["nvidia geforce pre-release titan xp opengl engine","prexp",0,[[2560,1440,60]]],["nvidia geforce rtx 2060","2060",0,[[1920,1080,512]]],["nvidia geforce rtx 2060 max-q","2060",0,[[2560,1440,301]]],["nvidia geforce rtx 2060 mobile","2060",0,[[1920,1080,518]]],["nvidia geforce rtx 2060 rev. a","2060",0,[[3840,2160,257]]],["nvidia geforce rtx 2060 super","2060",0,[[1920,1080,645],[2560,1440,143]]],["nvidia geforce rtx 2060 with max-q design","2060",0,[[1920,1080,292],[1920,1200,60]]],["nvidia geforce rtx 2070","2070",0,[[1920,1080,60],[3840,2160,60]]],["nvidia geforce rtx 2070 mobile","2070",0,[[1920,1080,477]]],["nvidia geforce rtx 2070 mobile / max-q","2070",0,[[1920,1080,526]]],["nvidia geforce rtx 2070 mobile / max-q refresh","2070",0,[[1920,1080,143]]],["nvidia geforce rtx 2070 rev. a","2070",0,[[2560,1440,144]]],["nvidia geforce rtx 2070 super","2070",0,[[1920,1080,510]]],["nvidia geforce rtx 2070 super with max-q design","2070",0,[[1920,1080,300]]],["nvidia geforce rtx 2070 with max-q design","2070",0,[[1920,1080,240]]],["nvidia geforce rtx 2080","2080",0,[[1920,1080,632],[2560,1440,165]]],["nvidia geforce rtx 2080 mobile","2080",0,[[1920,1080,144]]],["nvidia geforce rtx 2080 rev. a","2080",0,[[2560,1440,143]]],["nvidia geforce rtx 2080 super","2080",0,[[1920,1080,601]]],["nvidia geforce rtx 2080 super mobile / max-q","2080",0,[[3840,2160,59]]],["nvidia geforce rtx 2080 super with max-q design","2080",0,[[1920,1080,300]]],["nvidia geforce rtx 2080 ti","2080",0,[[1920,1080,83]]],["nvidia geforce rtx 2080 ti rev. a","2080",0,[[1920,1080,403]]],["nvidia geforce rtx 2080 with max-q design","2080",0,[[1920,1080,476]]],["nvidia geforce rtx 3050","3050",0,[[1920,1080,60]]],["nvidia geforce rtx 3050 laptop gpu","3050",0,[[1920,1080,144]]],["nvidia geforce rtx 3050 ti laptop gpu","3050",0,[[1920,1080,144]]],["nvidia geforce rtx 3060","3060",0,[[1920,1080,674]]],["nvidia geforce rtx 3060 laptop gpu","3060",0,[[1920,1080,300]]],["nvidia geforce rtx 3060 lite hash rate","3060",0,[[1920,1080,60]]],["nvidia geforce rtx 3060 mobile / max-q","3060",0,[[1920,1080,435]]],["nvidia geforce rtx 3060 ti","3060",0,[[1920,1080,779]]],["nvidia geforce rtx 3070","3070",0,[[1920,1080,723],[2560,1440,294]]],["nvidia geforce rtx 3070 laptop gpu","3070",0,[[1920,1080,357]]],["nvidia geforce rtx 3070 mobile / max-q","3070",0,[[2560,1440,386]]],["nvidia geforce rtx 3070 ti","3070",0,[[1920,1080,60]]],["nvidia geforce rtx 3080","3080",0,[[1920,1080,726],[2560,1440,60],[3840,2160,60]]],["nvidia geforce rtx 3080 laptop gpu","3080",0,[[1920,1080,294],[2560,1440,244]]],["nvidia geforce rtx 3080 mobile / max-q 8gb/16gb","3080",0,[[1920,1080,293]]],["nvidia geforce rtx 3080 ti","3080",0,[[1920,1080,239],[2560,1440,60]]],["nvidia geforce rtx 3090","3090",0,[[2560,1440,60],[3840,2160,474]]],["nvidia geforce rtx t10-16","10",0,[[2560,1600,3]]],["nvidia geforce rtx t10-8","10",0,[[2560,1600,3]]],["nvidia gigabyte geforce gt 440","440",0,[[1280,1024,34]]],["nvidia gigabyte geforce gt 610","610",0,[[1920,1080,17]]],["nvidia gigabyte geforce gt 630","630",0,[[1920,1080,34]]],["nvidia gigabyte geforce gt 730","730",0,[[1280,1024,38]]],["nvidia gigabyte geforce gts 450","450",0,[[1280,1024,37]]],["nvidia gigabyte geforce gtx 1050 ti","1050",0,[[1920,1080,30]]],["nvidia gigabyte geforce gtx 460","460",0,[[1680,1050,60]]],["nvidia gigabyte geforce gtx 550 ti","550",0,[[1920,1080,57]]],["nvidia gigabyte geforce gtx 560 ti","560",0,[[1920,1080,60]]],["nvidia gigabyte geforce gtx 570 hd","570",0,[[1920,1080,60]]],["nvidia gigabyte geforce gtx 580","580",0,[[1920,1200,60]]],["nvidia gigabyte geforce gtx 650","650",0,[[1680,1050,55]]],["nvidia gigabyte geforce gtx 650 ti","650",0,[[2560,1440,40]]],["nvidia gigabyte geforce gtx 660","660",0,[[1920,1080,31]]],["nvidia gigabyte geforce gtx 660 ti","660",0,[[5120,2880,29]]],["nvidia gigabyte geforce gtx 670","670",0,[[1920,1080,60]]],["nvidia gigabyte geforce gtx 750","750",0,[[1920,1080,59]]],["nvidia gigabyte geforce gtx 750 ti","750",0,[[1920,1080,60]]],["nvidia gigabyte geforce gtx 760","760",0,[[3440,1440,17]]],["nvidia gigabyte geforce gtx 770","770",0,[[2560,1440,59]]],["nvidia gigabyte geforce gtx 780 ti","780",0,[[1920,1080,240]]],["nvidia gigabyte geforce gtx 960","960",0,[[1920,1080,142],[1920,1200,120]]],["nvidia gigabyte geforce gtx 970","970",0,[[1920,1080,60]]],["nvidia gigabyte geforce gtx 980","980",0,[[2560,1440,60]]],["nvidia gigabyte geforce gtx 980 ti","980",0,[[1920,1080,60]]],["nvidia hp geforce gt 730","730",0,[[1920,1080,55]]],["nvidia inno3d geforce gtx660","3",0,[[2560,1440,107]]],["nvidia msi geforce gt 610","610",0,[[1920,1080,16]]],["nvidia msi geforce gt 630","630",0,[[1440,900,12]]],["nvidia msi geforce gt 635","635",0,[[1920,1080,30]]],["nvidia msi geforce gt 710","710",0,[[1920,1080,27]]],["nvidia msi geforce gt 730","730",0,[[1920,1080,53]]],["nvidia msi geforce gtx 1050 ti","1050",0,[[1920,1080,59]]],["nvidia msi geforce gtx 1060","1060",0,[[1920,1080,120]]],["nvidia msi geforce gtx 1070","1070",0,[[1920,1200,45]]],["nvidia msi geforce gtx 460","460",0,[[1920,1080,60]]],["nvidia msi geforce gtx 560 ti","560",0,[[1920,1080,60]]],["nvidia msi geforce gtx 570 hd","570",0,[[1920,1200,60]]],["nvidia msi geforce gtx 580","580",0,[[2560,1440,60]]],["nvidia msi geforce gtx 650","650",0,[[2560,1080,52]]],["nvidia msi geforce gtx 650 ti","650",0,[[1920,1080,60]]],["nvidia msi geforce gtx 660","660",0,[[1920,1080,60]]],["nvidia msi geforce gtx 660 ti","660",0,[[1680,1050,49]]],["nvidia msi geforce gtx 670","670",0,[[1920,1080,60]]],["nvidia msi geforce gtx 745","745",0,[[1920,1080,55]]],["nvidia msi geforce gtx 760","760",0,[[1280,1024,30],[1920,1080,58]]],["nvidia msi geforce gtx 780","780",0,[[1920,1080,60]]],["nvidia msi geforce gtx 950","950",0,[[1920,1080,59]]],["nvidia msi geforce gtx 960","960",0,[[1680,1050,120],[2560,1440,59]]],["nvidia msi geforce gtx 970","970",0,[[1680,1050,60]]],["nvidia msi geforce gtx 980","980",0,[[1920,1080,120],[3840,2160,60]]],["nvidia msi geforce gtx 980 ti","980",0,[[5120,2880,56]]],["nvidia null geforce 920a","920",0,[[1920,1080,25]]],["nvidia palit geforce gtx 650","650",0,[[1920,1080,49]]],["nvidia palit geforce gtx 650 ti","650",0,[[1920,1080,59]]],["nvidia palit geforce gtx 660","660",0,[[1920,1080,26]]],["nvidia pegatron geforce gt 420","420",0,[[1400,1050,25]]],["nvidia pny geforce gt 610","610",0,[[1280,1024,19]]],["nvidia pny geforce gtx 1060","1060",0,[[1920,1080,60]]],["nvidia pny geforce gtx 460","460",0,[[1360,768,59]]],["nvidia pny geforce gtx 550 ti","550",0,[[1920,1080,55]]],["nvidia pny geforce gtx 570 hd","570",0,[[1280,1024,72]]],["nvidia pny geforce gtx 580","580",0,[[1920,1200,59]]],["nvidia pny geforce gtx 680","680",0,[[2560,1080,120]]],["nvidia pny geforce gtx 750","750",0,[[1280,1024,60]]],["nvidia pny geforce gtx 970","970",0,[[2560,1440,60]]],["nvidia pny geforce gtx 980","980",0,[[1920,1080,120]]],["nvidia point of view geforce gtx 470","470",0,[[1920,1080,59]]],["nvidia point of view geforce gtx 660 ti","660",0,[[1680,1050,59]]],["nvidia sony geforce 410m","410",0,[[1366,768,24]]],["nvidia toshiba geforce gt 525m","525",0,[[1366,768,33]]],["nvidia zotac geforce gt 430","430",0,[[1600,900,32]]],["nvidia zotac geforce gt 610","610",0,[[1920,1080,15]]],["nvidia zotac geforce gt 630","630",0,[[1360,768,46]]],["nvidia zotac geforce gt 740","740",0,[[1280,1024,118]]],["nvidia zotac geforce gtx 460","460",0,[[1920,1080,59]]],["nvidia zotac geforce gtx 550 ti","550",0,[[1920,1080,42]]],["nvidia zotac geforce gtx 560","560",0,[[1920,1080,60]]],["nvidia zotac geforce gtx 560 ti","560",0,[[1920,1080,60]]],["nvidia zotac geforce gtx 580","580",0,[[1920,1080,48]]],["nvidia zotac geforce gtx 650","650",0,[[1920,1080,44]]],["nvidia zotac geforce gtx 650 ti","650",0,[[1920,1080,58]]],["nvidia zotac geforce gtx 660","660",0,[[1920,1080,60]]],["nvidia zotac geforce gtx 680","680",0,[[1920,1080,60]]],["nvidia zotac geforce gtx 750","750",0,[[1680,1050,114],[1920,1080,60]]],["nvidia zotac geforce gtx 760","760",0,[[1920,1080,101]]],["nvidia zotac geforce gtx 770","770",0,[[1920,1080,60]]],["nvidia zotac geforce gtx 780","780",0,[[1920,1080,60]]],["nvidia zotac geforce gtx 960","960",0,[[2048,1152,60]]]]')},178:e=>{"use strict";e.exports=JSON.parse('["4.0.8",["intel","",0,[[4096,2304,12]]],["intel 0x496e74656c2048442047726170686963000732034343","0",0,[[1920,1080,22]]],["intel broxton-p hd","p",0,[[1920,1080,73]]],["intel cherryview hd","hd",0,[[1920,1080,16]]],["intel coffee lake uhd","uhd",0,[[1920,1080,49]]],["intel cometlake uhd graphics 630","630",0,[[2560,1440,40]]],["intel corporation 2nd gen core processor family integrated graphics controller","2",0,[[1366,768,25]]],["intel corporation 2nd generation core processor family integrated graphics controller","2",0,[[1600,900,28]]],["intel corporation 3rd gen core processor graphics controller","3",0,[[1366,768,20]]],["intel corporation 8th gen core processor gaussian mixture model","8",0,[[1366,768,17]]],["intel corporation atom processor z36xxx/z37xxx series graphics & display","36",0,[[1280,799,18],[1366,768,18]]],["intel corporation atom/celeron/pentium processor n4200 series integrated graphics controller","4200",0,[[1280,1024,28]]],["intel corporation atom/celeron/pentium processor x5-e8000 integrated graphics controller","5",0,[[1366,768,34]]],["intel corporation atom/celeron/pentium processor x5-e8000 series pci configuration registers","5",0,[[1920,1080,14]]],["intel corporation broadwell-u integrated","u",0,[[1920,1080,38]]],["intel corporation celeron n3350 n4200/atom e3900 series integrated graphics controller","3350",0,[[1680,1050,33]]],["intel corporation coffeelake-h gt2 [uhd graphics 630]","2",0,[[1920,1080,76]]],["intel corporation cometlake-h gt2 [uhd graphics]","2",0,[[3072,1728,29]]],["intel corporation cometlake-s gt2 [uhd graphics 630]","2",0,[[1920,1080,52]]],["intel corporation cometlake-u gt2 [uhd graphics]","2",0,[[1920,1080,39]]],["intel corporation device","",0,[[1920,1080,31]]],["intel corporation geminilake [uhd graphics 600]","600",0,[[1920,1080,15]]],["intel corporation haswell-ult integrated graphics controller","ult",0,[[1366,768,35]]],["intel corporation hd","hd",0,[[1920,1080,24]]],["intel corporation hd graphics 500","500",0,[[1366,768,19]]],["intel corporation hd graphics 510","510",0,[[1368,768,48]]],["intel corporation hd graphics 515","515",0,[[1920,1080,29]]],["intel corporation hd graphics 520","520",0,[[1366,768,59]]],["intel corporation hd graphics 530","530",0,[[1920,1080,58]]],["intel corporation hd graphics 5300","5300",0,[[1920,1080,35]]],["intel corporation hd graphics 5500","5500",0,[[1920,1080,36]]],["intel corporation hd graphics 610","610",0,[[1920,1080,28]]],["intel corporation hd graphics 620","620",0,[[1920,1080,56],[3200,1800,17]]],["intel corporation hd graphics 630","630",0,[[1920,1080,58]]],["intel corporation iris graphics 540","540",0,[[1920,1080,54]]],["intel corporation iris graphics 6100","6100",0,[[2560,1600,20]]],["intel corporation iris plus graphics 650","650",0,[[1440,900,60]]],["intel corporation iris plus graphics 655","655",0,[[1920,1080,119]]],["intel corporation iris plus graphics g1","1",0,[[1920,1080,57]]],["intel corporation iris plus graphics g7","7",0,[[1920,1080,112]]],["intel corporation iris pro graphics 580","580",0,[[1920,1080,60]]],["intel corporation iris pro graphics 6200","6200",0,[[2560,1080,41]]],["intel corporation iris xe","xe",0,[[1920,1200,60]]],["intel corporation sky lake integrated","sky",0,[[2560,1440,52]]],["intel corporation skylake gt2 [hd graphics 520]","2",0,[[1920,1080,52],[2560,1440,31]]],["intel corporation skylake integrated","",0,[[1920,1080,51]]],["intel corporation tigerlake gt2 [iris xe graphics]","2",0,[[1920,1080,60]]],["intel corporation tigerlake-lp gt2 [iris xe graphics]","2",0,[[1920,1080,60]]],["intel corporation uhd","uhd",0,[[1920,1080,65]]],["intel corporation uhd graphics 605","605",0,[[1920,1080,21]]],["intel corporation uhd graphics 615","615",0,[[1920,1080,30]]],["intel corporation uhd graphics 620","620",0,[[1920,1080,55]]],["intel corporation uhd graphics 630","630",0,[[1920,1080,57]]],["intel corporation whiskeylake-u gt2 [uhd graphics 620]","2",0,[[1920,1080,57]]],["intel corporation xeon e3-1200 v2 gen core processor graphics controller","3",0,[[1920,1080,15]]],["intel corporation xeon e3-1200 v3 gen core processor integrated graphics controller","3",0,[[1360,768,42],[1440,900,34],[1280,1024,23],[1920,1080,22]]],["intel corporation, series chipset iris plus graphics 655","655",0,[[1920,1080,42]]],["intel geforce gtx 960","960",0,[[1920,1080,26]]],["intel gen12 desktop graphics controller","12",0,[[3840,2160,20]]],["intel graphics gfx-driver-user-feature_dg1_poweron-27723 dch releaseinternal","1",0,[[3840,2160,11]]],["intel hd","hd",0,[[1280,800,18],[1366,768,26],[1600,900,12],[1920,1080,13],[1920,1200,16],[1920,1280,18],[3000,2002,6],[4096,2160,4]]],["intel hd 4000","4000",0,[[1366,768,37]]],["intel hd 530","530",0,[[1920,1200,54]]],["intel hd graphics 3000","3000",0,[[1920,1080,21]]],["intel hd graphics 4000","4000",0,[[1280,800,41],[1366,768,33],[1440,900,31],[1680,1050,50],[1920,1080,27],[2560,1600,13],[2880,1800,12]]],["intel hd graphics 4000,,,,,,,","4000",0,[[1920,1080,19]]],["intel hd graphics 4400","4400",0,[[1366,768,28],[1280,1024,48],[1920,1080,18],[2160,1440,20]]],["intel hd graphics 4600","4600",0,[[1366,768,14],[1280,960,65],[1280,1024,60],[1600,900,33],[1680,1050,31],[1600,1200,47],[1920,1080,19],[1920,1200,22],[2880,1620,14]]],["intel hd graphics 500","500",0,[[1920,1080,15]]],["intel hd graphics 5000","5000",0,[[1366,768,45],[1440,900,42],[1920,1032,25],[1920,1080,27],[2160,1439,19],[2160,1440,23],[2560,1440,15]]],["intel hd graphics 505","505",0,[[1366,768,28],[1920,1080,16]]],["intel hd graphics 510","510",0,[[1366,768,29],[1440,900,46],[1680,1050,12],[1920,1080,27]]],["intel hd graphics 515","515",0,[[1920,1080,45],[2720,768,22],[1920,1280,41],[2160,1440,28],[2560,1600,16],[2736,1824,19],[3200,1800,12],[3840,2160,10]]],["intel hd graphics 520","520",0,[[1366,768,90],[1920,1080,30],[2736,1824,26],[3000,2000,21]]],["intel hd graphics 530","530",0,[[1366,768,21],[1280,1024,65],[1920,1080,47],[1920,1200,39],[3840,2160,6]]],["intel hd graphics 5300","5300",0,[[1920,1080,21],[2304,1440,19],[2560,1600,13]]],["intel hd graphics 5500","5500",0,[[1366,768,37],[1920,1080,21]]],["intel hd graphics 5600","5600",0,[[1920,1080,26],[1920,1200,40],[2880,1620,21]]],["intel hd graphics 6000","6000",0,[[1366,768,43],[1440,900,40],[1920,1080,21]]],["intel hd graphics 610","610",0,[[1366,768,33],[1600,900,42],[1920,1080,27],[3840,2160,8]]],["intel hd graphics 615","615",0,[[1600,900,13],[1920,1080,18],[1800,1200,29],[1920,1200,34],[2560,1440,25],[2560,1600,21],[2736,1824,21]]],["intel hd graphics 620","620",0,[[1920,1080,37],[2736,1824,27],[3200,1800,25],[3840,2160,13]]],["intel hd graphics 630","630",0,[[1366,768,69],[1920,1080,40],[2560,1440,27],[2560,1600,23],[3360,2100,56],[3840,2160,12]]],["intel hd graphics 630 gt2","630",0,[[1920,1080,39],[1720,1440,120]]],["intel hd graphics cfl crb","hdcfl",0,[[2560,1440,38]]],["intel hd graphics family","hd",0,[[1366,768,44]]],["intel hd graphics icl rvp","hdicl",0,[[1920,1080,58]]],["intel hd graphics icl rvp bigsur","hdicl",0,[[1920,1080,57]]],["intel hd graphics kbl crb","hdkbl",0,[[1920,1080,57],[3840,2160,13]]],["intel hd graphics p4600","4600",0,[[1280,1024,57],[1920,1080,18],[2560,1600,60]]],["intel hd graphics p530","530",0,[[2560,1440,36],[3840,2160,12]]],["intel hd graphics p630","630",0,[[1440,900,35],[1920,1200,50]]],["intel hd graphics, gen10","10",0,[[3840,2160,4]]],["intel hd5500 broadwell pg7","5500",0,[[1366,768,31]]],["intel hd5500 graphics pg7","5500",0,[[1366,768,56]]],["intel iris","",0,[[1366,768,57],[1600,900,34],[1920,1080,34],[2560,1600,17],[2880,1800,14]]],["intel iris graphics 5100","5100",0,[[1920,1080,35],[2560,1600,18]]],["intel iris graphics 540","540",0,[[1920,1080,20],[2736,1824,28],[2880,1800,23],[3200,1800,17],[3840,2160,17]]],["intel iris graphics 550","550",0,[[1920,1080,81],[2160,1440,45],[2560,1600,28],[2880,1800,26],[3840,2160,24]]],["intel iris graphics 6100","6100",0,[[1920,1080,26],[2560,1600,19],[3840,2160,10]]],["intel iris graphics 6200","6200",0,[[4096,2304,13]]],["intel iris graphics 640","640",0,[[2256,1504,24],[3840,2160,9]]],["intel iris graphics 650","650",0,[[2560,1440,24]]],["intel iris graphics p580","580",0,[[3840,2160,12]]],["intel iris plus","",0,[[1920,1080,60],[2256,1504,95],[2496,1664,93],[2736,1824,60],[2880,1800,60],[3000,2000,56]]],["intel iris plus graphics 640","640",0,[[1920,1080,87],[2256,1504,46],[2560,1600,44],[2735,1823,28],[2736,1824,28],[2880,1800,26],[3072,1728,25],[3200,1800,37],[3840,2160,16]]],["intel iris plus graphics 645","645",0,[[2560,1599,32],[2560,1600,56],[2880,1800,47]]],["intel iris plus graphics 650","650",0,[[1920,1080,60],[2560,1600,49],[2880,1800,27],[3840,2160,16]]],["intel iris plus graphics 655","655",0,[[1920,1080,58],[2560,1440,85],[2880,1800,32],[3840,2160,24]]],["intel iris pro","pro",0,[[1920,1080,56]]],["intel iris pro graphics 5200","5200",0,[[1920,1080,53],[2879,1800,24],[2880,1800,21]]],["intel iris pro graphics 580","580",0,[[1920,1080,58],[2560,1080,91],[2560,1440,58],[3840,1600,27]]],["intel iris pro graphics 6200","6200",0,[[1366,696,38],[1920,1080,58],[1920,1200,60],[3840,2160,19],[4096,2304,14]]],["intel iris pro graphics p580","580",0,[[1024,768,42],[1920,1080,103],[3840,2160,27]]],["intel iris pro graphics p6300","6300",0,[[1366,768,102],[1440,900,128],[1920,1080,30]]],["intel iris xe","xe",0,[[1920,1080,88]]],["intel iris xe graphics releaseinternal","xe",0,[[3840,2160,38]]],["intel iris xe max","xe",0,[[1920,1080,60],[3840,2160,56]]],["intel kabylake hd graphics ult gt2","2",0,[[3840,2160,11]]],["intel kabylake hd graphics ulx gt2","2",0,[[1920,1080,28],[3840,2160,6]]],["intel kbl unknown","kbl",0,[[1920,1080,54]]],["intel mesa dri intel bay trail","dribay",0,[[1366,768,14]]],["intel mesa dri intel haswell mobile","dri",0,[[1920,1080,27]]],["intel mesa dri intel hd","drihd",0,[[1920,1080,10]]],["intel mesa dri intel hd graphics 400","400",0,[[1366,768,30]]],["intel mesa dri intel hd graphics 505","505",0,[[1920,1080,27]]],["intel mesa dri intel hd graphics 520","520",0,[[1920,1080,45],[2560,1440,24]]],["intel mesa dri intel hd graphics 530","530",0,[[3840,2160,12]]],["intel mesa dri intel hd graphics 5500","5500",0,[[1366,768,40]]],["intel mesa dri intel hd graphics 620","620",0,[[1920,1080,53]]],["intel mesa dri intel hd graphics 630","630",0,[[1477,831,58]]],["intel mesa dri intel hd graphics p4000","4000",0,[[1920,1080,36]]],["intel mesa dri intel iris graphics 540","540",0,[[1280,720,40]]],["intel mesa dri intel ivybridge desktop","dri",0,[[2560,1080,16]]],["intel mesa dri intel ivybridge mobile","dri",0,[[1920,1080,25]]],["intel mesa dri intel kabylake gt2","2",0,[[1920,1080,36]]],["intel mesa dri intel sandybridge desktop","dri",0,[[1280,1024,12]]],["intel mesa dri intel sandybridge mobile","dri",0,[[1366,768,33]]],["intel mesa dri intel uhd graphics 620","620",0,[[2736,1824,22]]],["intel mesa dri intel uhd graphics 630","630",0,[[1920,1080,42]]],["intel mesa intel hd graphics 520","520",0,[[1920,1080,47]]],["intel mesa intel hd graphics 530","530",0,[[1920,1080,55]]],["intel phdgd ivy 4","4",0,[[1366,768,45]]],["intel radeon pro vega 16","16",0,[[3360,1890,20]]],["intel radeong 0.4 on amd bonaire","0",0,[[1920,1200,92]]],["intel radeong 0.4 on amd cape verde","0",0,[[1920,1200,73]]],["intel radeong 0.4 on amd polaris10","0",0,[[3840,2160,108]]],["intel radeong 0.4 on amd tonga","0",0,[[1920,1080,124]]],["intel skl unknown","skl",0,[[1920,1080,43]]],["intel skylake gt2 [hd graphics 520]","2",0,[[1920,1080,39]]],["intel uhd","uhd",0,[[1920,1080,58],[2560,1600,22],[3440,1440,14],[2736,1824,32],[3840,2160,31]]],["intel uhd 630","630",0,[[2560,1440,38]]],["intel uhd graphics 600","600",0,[[1366,768,27],[1920,1080,13],[1920,1200,13],[2560,1440,11],[3840,2160,5]]],["intel uhd graphics 600 universal","600",0,[[1919,1031,15]]],["intel uhd graphics 605","605",0,[[1366,768,29],[1920,1080,37]]],["intel uhd graphics 610","610",0,[[1366,768,58],[1920,1080,32],[1920,1200,37],[2560,1440,17],[3840,2160,11]]],["intel uhd graphics 615","615",0,[[1920,1080,34],[1920,1280,29],[3840,2160,9]]],["intel uhd graphics 617","617",0,[[1920,1080,43],[2560,1599,24],[2560,1600,26],[2880,1800,24]]],["intel uhd graphics 620","620",0,[[1920,1080,50],[2736,1824,33],[3200,1800,16]]],["intel uhd graphics 630","630",0,[[1440,900,112],[1920,1080,44],[1920,1200,65],[2560,1080,68],[2560,1440,26],[3440,1440,25],[3584,2240,137],[3840,2160,12],[6016,3384,8]]],["intel uhd graphics 730","730",0,[[1920,1080,53]]],["intel uhd graphics 750","750",0,[[1920,1080,56],[3840,2160,36]]],["intel uhd graphics 770","770",0,[[3440,1440,78],[5120,1440,31]]],["intel uhd graphics gfx-driver-user-comp_core-23599","23599",0,[[3840,2160,18]]],["intel uhd graphics p630","630",0,[[1920,1080,54],[3840,2160,21]]],["intel uhd graphics releaseinternal","uhd",0,[[3199,1800,22],[3000,2000,47]]],["intel uhd graphics, gen11 lp","11",0,[[3840,2160,10]]],["intel uhd graphics, gen12 lp releaseinternal","12",0,[[3839,2159,4]]],["intel uhd graphics, lkf","uhdlkf",0,[[1927,1439,14]]],["intel unknown","",0,[[1920,1080,37]]],["intel xe","xe",0,[[1920,1080,268],[2560,1440,137]]],["intel xeon e3-1200 v3 gen core processor integrated graphics controller","3",0,[[1600,900,49]]]]')},217:e=>{"use strict";e.exports=JSON.parse('["4.0.8",["nvidia %nvidia_dev.13d7.0580.1028%","13",0,[[1920,1018,60]]],["nvidia a100-pcie-40gb","100",0,[[1920,1080,449]]],["nvidia a40","40",0,[[1920,1080,504]]],["nvidia a40-8q","40",0,[[2560,1440,58]]],["nvidia ashley","",0,[[1920,1080,60]]],["nvidia asus geforce gt 430","430",0,[[1366,768,35]]],["nvidia asus geforce gt 440","440",0,[[1920,1080,28]]],["nvidia asus geforce gt 520","520",0,[[1680,1050,12]]],["nvidia asus geforce gt 610","610",0,[[1920,1200,15]]],["nvidia asus geforce gt 630","630",0,[[1680,1050,41]]],["nvidia asus geforce gt 640","640",0,[[2560,1440,34]]],["nvidia asus geforce gt 710","710",0,[[1920,1080,31]]],["nvidia asus geforce gt 730","730",0,[[2560,1080,28],[3840,2160,12]]],["nvidia asus geforce gts 450","450",0,[[1920,1080,54]]],["nvidia asus geforce gtx 1060","1060",0,[[3840,2160,38]]],["nvidia asus geforce gtx 1080","1080",0,[[2560,1440,120]]],["nvidia asus geforce gtx 460","460",0,[[1920,1080,60]]],["nvidia asus geforce gtx 480","480",0,[[1920,1080,59]]],["nvidia asus geforce gtx 550 ti","550",0,[[1920,1080,57]]],["nvidia asus geforce gtx 560","560",0,[[1920,1080,60]]],["nvidia asus geforce gtx 560 se","560",0,[[1920,1080,59]]],["nvidia asus geforce gtx 560 ti","560",0,[[1680,1050,58]]],["nvidia asus geforce gtx 570","570",0,[[1280,1024,74]]],["nvidia asus geforce gtx 570 hd","570",0,[[1920,1080,60]]],["nvidia asus geforce gtx 580","580",0,[[1920,1200,59]]],["nvidia asus geforce gtx 660","660",0,[[1920,1080,60]]],["nvidia asus geforce gtx 670","670",0,[[1920,1080,60]]],["nvidia asus geforce gtx 750 ti","750",0,[[1360,768,59],[1920,1080,118]]],["nvidia asus geforce gtx 760","760",0,[[1920,1080,60],[1920,1200,60]]],["nvidia asus geforce gtx 770","770",0,[[1920,1080,60]]],["nvidia asus geforce gtx 780","780",0,[[1920,1080,60]]],["nvidia asus geforce gtx 950","950",0,[[1920,1080,60]]],["nvidia asus geforce gtx 960","960",0,[[1920,1080,60],[2560,1600,117]]],["nvidia asus geforce gtx 970","970",0,[[2560,1600,60]]],["nvidia asus geforce gtx 980 ti","980",0,[[2560,1440,131]]],["nvidia chip model","",0,[[1920,1080,60]]],["nvidia colorful geforce gtx 960","960",0,[[2560,1440,60]]],["nvidia dell nvs 5200m","5200",0,[[1920,1080,27]]],["nvidia dell quadro 2000m","2000",0,[[1920,1080,29]]],["nvidia device","",0,[[1920,1080,746]]],["nvidia elitegroup geforce gtx 460","460",0,[[1920,1080,60]]],["nvidia evga geforce gt 545","545",0,[[1920,1080,37]]],["nvidia evga geforce gt 640","640",0,[[1366,768,60]]],["nvidia evga geforce gt 710","710",0,[[1680,1050,36],[1920,1080,29]]],["nvidia evga geforce gt 730","730",0,[[1600,900,59]]],["nvidia evga geforce gt 740","740",0,[[1280,1024,45]]],["nvidia evga geforce gtx 1050 ti","1050",0,[[2560,1440,60],[4096,2304,58]]],["nvidia evga geforce gtx 1070","1070",0,[[5120,2880,60]]],["nvidia evga geforce gtx 1080 ti","1080",0,[[1920,1200,60]]],["nvidia evga geforce gtx 560 ti","560",0,[[1680,1050,59]]],["nvidia evga geforce gtx 570","570",0,[[1920,1080,60]]],["nvidia evga geforce gtx 580","580",0,[[2560,1440,60]]],["nvidia evga geforce gtx 650","650",0,[[1920,1200,87],[2560,1600,43]]],["nvidia evga geforce gtx 650 ti","650",0,[[1680,1050,116],[2560,1440,55]]],["nvidia evga geforce gtx 650 ti boost","650",0,[[1920,1080,56]]],["nvidia evga geforce gtx 660 ti","660",0,[[1920,1200,60]]],["nvidia evga geforce gtx 680","680",0,[[1600,1200,60]]],["nvidia evga geforce gtx 750 ti","750",0,[[1920,1080,60]]],["nvidia evga geforce gtx 760","760",0,[[1920,1080,119],[1920,1200,60]]],["nvidia evga geforce gtx 780","780",0,[[1920,1080,60]]],["nvidia evga geforce gtx 960","960",0,[[1920,1080,60],[2560,1440,115]]],["nvidia evga geforce gtx 970","970",0,[[1920,1080,120]]],["nvidia evga geforce gtx 980","980",0,[[3440,1440,60]]],["nvidia evga geforce gtx 980 ti","980",0,[[1920,1080,60]]],["nvidia ga104gl [rtx a4000]","104",0,[[3840,2160,60]]],["nvidia gainward geforce gt 630","630",0,[[1920,1080,28]]],["nvidia gainward geforce gts 450","450",0,[[1920,1080,55]]],["nvidia gainward geforce gtx 460","460",0,[[1920,1080,58]]],["nvidia gainward geforce gtx 550 ti","550",0,[[1280,1024,67]]],["nvidia gainward geforce gtx 560 ti","560",0,[[1920,1080,60]]],["nvidia gainward geforce gtx 570","570",0,[[1920,1080,60]]],["nvidia gainward geforce gtx 750 ti","750",0,[[1920,1080,60]]],["nvidia geforce 210","210",0,[[1920,1080,8]]],["nvidia geforce 410m","410",0,[[1366,768,25],[1600,900,19]]],["nvidia geforce 510","510",0,[[1280,960,20]]],["nvidia geforce 605","605",0,[[1768,992,17],[1920,1080,15]]],["nvidia geforce 610m","610",0,[[1366,768,26]]],["nvidia geforce 610m/710m/810m/820m / gt 620m/625m/630m/720m","610",0,[[1366,768,51]]],["nvidia geforce 615","615",0,[[1920,1080,21]]],["nvidia geforce 705m","705",0,[[1920,1080,18]]],["nvidia geforce 710a","710",0,[[1920,1080,32]]],["nvidia geforce 710m","710",0,[[1366,768,55]]],["nvidia geforce 730a","730",0,[[1920,1080,37]]],["nvidia geforce 800m","800",0,[[1920,1080,18]]],["nvidia geforce 810m","810",0,[[1366,768,44],[1920,1080,31]]],["nvidia geforce 820a","820",0,[[1920,1080,28]]],["nvidia geforce 820m","820",0,[[1366,768,57],[1920,1080,23]]],["nvidia geforce 830a","830",0,[[1920,1080,53]]],["nvidia geforce 830m","830",0,[[1366,768,60]]],["nvidia geforce 8400 gs","8400",0,[[1680,1050,4]]],["nvidia geforce 8400 gs rev. 3","8400",0,[[1920,1080,4]]],["nvidia geforce 840a","840",0,[[1920,1080,56]]],["nvidia geforce 840m","840",0,[[1920,1080,56]]],["nvidia geforce 845m","845",0,[[1920,1080,59]]],["nvidia geforce 8600 gt","8600",1,[[1920,1200,-1]]],["nvidia geforce 8600 gts","8600",1,[[1920,1080,-1]]],["nvidia geforce 910m","910",0,[[1366,768,58],[1600,900,45]]],["nvidia geforce 920m","920",0,[[1366,768,60]]],["nvidia geforce 920mx","920",0,[[1366,768,60],[1920,1080,60]]],["nvidia geforce 9300 / nforce 730i","9300",0,[[1920,1080,6]]],["nvidia geforce 930a","930",0,[[1920,1080,55]]],["nvidia geforce 930m","930",0,[[1366,768,60]]],["nvidia geforce 930mx","930",0,[[1366,768,89],[1920,1080,59]]],["nvidia geforce 9400 gt","9400",1,[[1366,768,-1]]],["nvidia geforce 940a","940",0,[[1920,1080,58]]],["nvidia geforce 940m","940",0,[[1920,1080,54]]],["nvidia geforce 940mx","940",0,[[1920,1080,60]]],["nvidia geforce 945m","945",0,[[1920,1080,59]]],["nvidia geforce 9600 gt","9600",0,[[1920,1200,2]]],["nvidia geforce 9600m gt","9600",1,[[1440,900,-1]]],["nvidia geforce 9800 gt","9800",0,[[1920,1200,52]]],["nvidia geforce 9800 gtx / 9800 gtx+","9800",0,[[1280,1024,59]]],["nvidia geforce gpu","gpu",0,[[3000,2000,36]]],["nvidia geforce gt 1010","1010",0,[[1920,1080,135]]],["nvidia geforce gt 1030","1030",0,[[1920,1080,60]]],["nvidia geforce gt 1030 opengl engine","1030",0,[[6720,3780,15]]],["nvidia geforce gt 120","120",1,[[1920,1080,-1]]],["nvidia geforce gt 240","240",0,[[1366,768,32]]],["nvidia geforce gt 320m","320",0,[[1366,768,26]]],["nvidia geforce gt 415m","415",0,[[1366,768,19]]],["nvidia geforce gt 420","420",0,[[1024,768,33],[1920,1080,20]]],["nvidia geforce gt 420m","420",0,[[1366,768,28]]],["nvidia geforce gt 425m","425",0,[[1366,768,55],[1600,900,28]]],["nvidia geforce gt 430","430",0,[[1600,1200,16],[1920,1080,28]]],["nvidia geforce gt 435m","435",0,[[1366,768,53],[1920,1080,22]]],["nvidia geforce gt 440","440",0,[[1280,1024,51],[1680,1050,38],[1920,1080,45]]],["nvidia geforce gt 445m","445",0,[[1600,900,53]]],["nvidia geforce gt 520","520",0,[[1440,900,19],[1920,1080,17]]],["nvidia geforce gt 520m","520",0,[[1366,768,29]]],["nvidia geforce gt 520mx","520",0,[[1366,768,35]]],["nvidia geforce gt 525m","525",0,[[1366,768,28],[1600,900,22]]],["nvidia geforce gt 530","530",0,[[1920,1080,26]]],["nvidia geforce gt 540m","540",0,[[1366,768,38]]],["nvidia geforce gt 545","545",0,[[1920,1080,54]]],["nvidia geforce gt 550m","550",0,[[1600,900,44],[1920,1080,29]]],["nvidia geforce gt 555m","555",0,[[1920,1080,42]]],["nvidia geforce gt 555m/635m","555",0,[[1920,1080,36]]],["nvidia geforce gt 610","610",0,[[1280,1024,22],[1920,1080,15]]],["nvidia geforce gt 620","620",0,[[1920,1080,19]]],["nvidia geforce gt 620 oem","620",0,[[1920,1080,20],[1920,1200,20]]],["nvidia geforce gt 620m","620",0,[[1366,768,55],[1920,1080,30]]],["nvidia geforce gt 620m/630m/635m/640m le","620",0,[[1368,768,38]]],["nvidia geforce gt 625","625",0,[[1920,1080,18]]],["nvidia geforce gt 625m","625",0,[[1366,768,38]]],["nvidia geforce gt 630","630",0,[[1680,1050,36],[1920,1080,36],[1920,1200,30]]],["nvidia geforce gt 630 oem","630",0,[[1600,900,33]]],["nvidia geforce gt 630 opengl engine","630",0,[[1920,1080,33]]],["nvidia geforce gt 630 rev. 2","630",0,[[1920,1080,26]]],["nvidia geforce gt 630m","630",0,[[1366,768,57]]],["nvidia geforce gt 635","635",0,[[1920,1080,27]]],["nvidia geforce gt 635m","635",0,[[1366,768,47]]],["nvidia geforce gt 640","640",0,[[1920,1080,47]]],["nvidia geforce gt 640 oem","640",0,[[1920,1080,46],[2560,1440,35]]],["nvidia geforce gt 640 opengl engine","640",0,[[1280,1024,43]]],["nvidia geforce gt 640 rev. 2","640",0,[[1280,1024,60],[1920,1080,55]]],["nvidia geforce gt 640m","640",0,[[1366,768,82],[1600,900,59],[1920,1080,34]]],["nvidia geforce gt 640m le","640",0,[[1920,1080,49]]],["nvidia geforce gt 640m mac","640",0,[[1366,768,56],[1920,1080,20]]],["nvidia geforce gt 640m opengl engine","640",0,[[1920,1080,45]]],["nvidia geforce gt 645m","645",0,[[1366,768,60]]],["nvidia geforce gt 650m","650",0,[[1360,768,59],[1920,1080,58],[2560,1440,59]]],["nvidia geforce gt 650m mac","650",0,[[1440,900,56],[1920,1080,15],[2560,1440,19],[2880,1800,31]]],["nvidia geforce gt 650m opengl engine","650",0,[[1920,1080,56],[3840,2160,27]]],["nvidia geforce gt 705","705",0,[[1920,1080,11]]],["nvidia geforce gt 710","710",0,[[1920,1080,28]]],["nvidia geforce gt 710b","710",0,[[1920,1080,26]]],["nvidia geforce gt 710m","710",0,[[1366,768,46]]],["nvidia geforce gt 720","720",0,[[1920,1080,19],[2560,1440,16],[5120,2880,5]]],["nvidia geforce gt 720 opengl engine","720",0,[[2560,1600,20]]],["nvidia geforce gt 720m","720",0,[[1366,768,42]]],["nvidia geforce gt 730","730",0,[[1920,1080,54]]],["nvidia geforce gt 730a","730",0,[[1920,1080,23]]],["nvidia geforce gt 730m","730",0,[[1920,1080,43]]],["nvidia geforce gt 735m","735",0,[[1920,1080,39]]],["nvidia geforce gt 740","740",0,[[1920,1080,55],[3440,1440,23]]],["nvidia geforce gt 740 opengl engine","740",0,[[1920,1200,51]]],["nvidia geforce gt 740m","740",0,[[1366,768,60]]],["nvidia geforce gt 745m","745",0,[[1920,1080,55]]],["nvidia geforce gt 750m","750",0,[[1920,1080,57]]],["nvidia geforce gt 750m mac","750",0,[[1920,1080,58],[2880,1800,28]]],["nvidia geforce gt 755m","755",0,[[1920,1080,57]]],["nvidia geforce gt 755m mac","755",0,[[2560,1440,41]]],["nvidia geforce gt 755m opengl engine","755",0,[[2560,1440,51]]],["nvidia geforce gt 820m","820",0,[[1600,900,47]]],["nvidia geforce gts 250","250",0,[[1680,1050,53]]],["nvidia geforce gts 450","450",0,[[1360,768,60],[1680,1050,57],[1920,1080,55]]],["nvidia geforce gts 450 rev. 2","450",0,[[1920,1080,56]]],["nvidia geforce gtx 1050","1050",0,[[1920,1080,60]]],["nvidia geforce gtx 1050 3gb","1050",0,[[1280,1024,60]]],["nvidia geforce gtx 1050 mobile","1050",0,[[1920,1080,60]]],["nvidia geforce gtx 1050 opengl engine","1050",0,[[1920,1080,116]]],["nvidia geforce gtx 1050 ti","1050",0,[[1920,1080,60]]],["nvidia geforce gtx 1050 ti mobile","1050",0,[[1920,1080,298]]],["nvidia geforce gtx 1050 ti opengl engine","1050",0,[[1920,1080,60]]],["nvidia geforce gtx 1050 ti with max-q design","1050",0,[[1920,1080,268],[2560,1440,102],[3840,2160,60]]],["nvidia geforce gtx 1050 with max-q design","1050",0,[[1920,1080,60],[3840,2160,24]]],["nvidia geforce gtx 1060","1060",0,[[1920,1080,60],[3840,2160,59]]],["nvidia geforce gtx 1060 3gb","1060",0,[[1920,1080,60]]],["nvidia geforce gtx 1060 3gb opengl engine","1060",0,[[1920,1080,60]]],["nvidia geforce gtx 1060 5gb","1060",0,[[1920,1080,55]]],["nvidia geforce gtx 1060 6gb","1060",0,[[1920,1080,60]]],["nvidia geforce gtx 1060 6gb opengl engine","1060",0,[[1920,1080,75]]],["nvidia geforce gtx 1060 mobile","1060",0,[[1920,1080,422]]],["nvidia geforce gtx 1060 mobile 6gb","1060",0,[[1920,1080,120]]],["nvidia geforce gtx 1060 with max-q design","1060",0,[[1920,1080,60]]],["nvidia geforce gtx 1060se 3gb","1060",0,[[1920,1080,60]]],["nvidia geforce gtx 1070","1070",0,[[1920,1080,134]]],["nvidia geforce gtx 1070 a17","1070",0,[[1920,1080,60]]],["nvidia geforce gtx 1070 mobile","1070",0,[[1920,1080,467]]],["nvidia geforce gtx 1070 opengl engine","1070",0,[[1920,1080,143]]],["nvidia geforce gtx 1070 ti","1070",0,[[1920,1080,60],[6016,3384,59]]],["nvidia geforce gtx 1070 ti opengl engine","1070",0,[[1920,1080,75]]],["nvidia geforce gtx 1070 with max-q design","1070",0,[[1920,1080,448]]],["nvidia geforce gtx 1070 with maxq design","1070",0,[[1920,1080,60],[3840,2160,59]]],["nvidia geforce gtx 1080","1080",0,[[1920,1080,119],[2560,1440,326],[3840,2160,286]]],["nvidia geforce gtx 1080 mobile","1080",0,[[1920,1080,120]]],["nvidia geforce gtx 1080 opengl engine","1080",0,[[1920,1080,79]]],["nvidia geforce gtx 1080 ti","1080",0,[[1920,1080,120]]],["nvidia geforce gtx 1080 ti opengl engine","1080",0,[[1920,1080,127]]],["nvidia geforce gtx 1080 with max-q design","1080",0,[[1920,1080,144]]],["nvidia geforce gtx 1180","1180",0,[[3440,1440,60]]],["nvidia geforce gtx 1650","1650",0,[[1920,1080,380]]],["nvidia geforce gtx 1650 mobile / max-q","1650",0,[[1920,1080,292]]],["nvidia geforce gtx 1650 super","1650",0,[[1920,1080,433]]],["nvidia geforce gtx 1650 ti","1650",0,[[1920,1080,144],[3840,2400,59]]],["nvidia geforce gtx 1650 ti mobile","1650",0,[[1920,1080,144]]],["nvidia geforce gtx 1650 ti with max-q design","1650",0,[[1920,1080,60],[3839,2160,60]]],["nvidia geforce gtx 1650 with max-q design","1650",0,[[1920,1080,142],[3000,2000,60]]],["nvidia geforce gtx 1660","1660",0,[[1920,1080,144]]],["nvidia geforce gtx 1660 super","1660",0,[[1920,1080,60]]],["nvidia geforce gtx 1660 ti","1660",0,[[1920,1080,546],[3840,2160,60]]],["nvidia geforce gtx 1660 ti mobile","1660",0,[[1920,1080,451]]],["nvidia geforce gtx 1660 ti with max-q design","1660",0,[[1920,1080,144]]],["nvidia geforce gtx 280","280",0,[[1680,1050,56]]],["nvidia geforce gtx 295","295",0,[[1920,1080,56]]],["nvidia geforce gtx 460","460",0,[[1920,1080,60]]],["nvidia geforce gtx 460 oem","460",0,[[1360,768,60],[1920,1080,60]]],["nvidia geforce gtx 460 opengl engine","460",0,[[1920,1080,59]]],["nvidia geforce gtx 460 se","460",0,[[1920,1080,56],[1920,1200,57]]],["nvidia geforce gtx 460 v2","460",0,[[1920,1080,60],[1920,1200,60],[2560,1600,55]]],["nvidia geforce gtx 460m","460",0,[[1920,1080,46]]],["nvidia geforce gtx 465","465",0,[[1920,1080,134],[1920,1200,59]]],["nvidia geforce gtx 470","470",0,[[1680,1050,60],[1920,1080,59]]],["nvidia geforce gtx 470m","470",0,[[1920,1200,55]]],["nvidia geforce gtx 480","480",0,[[1440,900,191],[1920,1080,115],[1920,1200,60]]],["nvidia geforce gtx 480 opengl engine","480",0,[[1600,1200,60]]],["nvidia geforce gtx 550 ti","550",0,[[1280,1024,58],[1920,1080,58]]],["nvidia geforce gtx 550 ti opengl engine","550",0,[[1920,1080,55]]],["nvidia geforce gtx 555","555",0,[[1920,1080,54]]],["nvidia geforce gtx 560","560",0,[[1920,1080,60]]],["nvidia geforce gtx 560 se","560",0,[[1680,1050,52],[1920,1080,111]]],["nvidia geforce gtx 560 ti","560",0,[[1920,1080,60]]],["nvidia geforce gtx 560 ti 448 cores","560",0,[[1920,1080,60],[2560,1440,60]]],["nvidia geforce gtx 560 ti oem","560",0,[[1920,1080,176]]],["nvidia geforce gtx 560 ti opengl engine","560",0,[[1920,1080,48]]],["nvidia geforce gtx 560m","560",0,[[1920,1080,55]]],["nvidia geforce gtx 570","570",0,[[1920,1080,60]]],["nvidia geforce gtx 570 opengl engine","570",0,[[1920,1080,60]]],["nvidia geforce gtx 570 rev. 2","570",0,[[1920,1080,60],[1920,1200,60]]],["nvidia geforce gtx 570m","570",0,[[1920,1080,125],[2560,1440,8]]],["nvidia geforce gtx 580","580",0,[[1920,1080,60]]],["nvidia geforce gtx 580 opengl engine","580",0,[[1680,1050,59]]],["nvidia geforce gtx 580m","580",0,[[1920,1080,60]]],["nvidia geforce gtx 590","590",0,[[1920,1080,59]]],["nvidia geforce gtx 645","645",0,[[1920,1080,57],[1920,1200,58]]],["nvidia geforce gtx 645 opengl engine","645",0,[[1920,1200,58]]],["nvidia geforce gtx 650","650",0,[[1920,1080,72]]],["nvidia geforce gtx 650 oem","650",0,[[1366,768,59]]],["nvidia geforce gtx 650 opengl engine","650",0,[[1920,1080,59]]],["nvidia geforce gtx 650 ti","650",0,[[1920,1080,60]]],["nvidia geforce gtx 650 ti boost","650",0,[[1280,1024,60],[1600,1200,187],[1920,1080,60]]],["nvidia geforce gtx 650 ti opengl engine","650",0,[[1920,1080,60]]],["nvidia geforce gtx 660","660",0,[[1920,1080,111]]],["nvidia geforce gtx 660 oem","660",0,[[1920,1080,59]]],["nvidia geforce gtx 660 ti","660",0,[[1920,1080,60]]],["nvidia geforce gtx 660 ti opengl engine","660",0,[[1280,1024,60]]],["nvidia geforce gtx 660m","660",0,[[1680,1050,36],[1920,1080,59]]],["nvidia geforce gtx 660m mac","660",0,[[2560,1440,2]]],["nvidia geforce gtx 660m opengl engine","660",0,[[2560,1440,36]]],["nvidia geforce gtx 670","670",0,[[1920,1080,100]]],["nvidia geforce gtx 670 opengl engine","670",0,[[1920,1080,60]]],["nvidia geforce gtx 670m","670",0,[[1920,1080,66]]],["nvidia geforce gtx 670mx","670",0,[[1920,1080,60]]],["nvidia geforce gtx 675m","675",0,[[1920,1080,60]]],["nvidia geforce gtx 675mx","675",0,[[1680,1050,60],[1920,1080,60],[2560,1440,55]]],["nvidia geforce gtx 675mx mac","675",0,[[2560,1440,36]]],["nvidia geforce gtx 675mx opengl engine","675",0,[[2560,1440,60]]],["nvidia geforce gtx 680","680",0,[[1920,1080,60]]],["nvidia geforce gtx 680 opengl engine","680",0,[[1920,1080,60]]],["nvidia geforce gtx 680m","680",0,[[1920,1080,39],[1920,1200,60]]],["nvidia geforce gtx 680m opengl engine","680",0,[[1920,1080,36]]],["nvidia geforce gtx 680mx","680",0,[[2560,1440,59]]],["nvidia geforce gtx 680mx opengl engine","680",0,[[2560,1440,59]]],["nvidia geforce gtx 690","690",0,[[1920,1080,60],[3840,2160,30]]],["nvidia geforce gtx 745","745",0,[[1920,1080,60],[2560,1600,29]]],["nvidia geforce gtx 750","750",0,[[1920,1080,60]]],["nvidia geforce gtx 750 opengl engine","750",0,[[1920,1200,58]]],["nvidia geforce gtx 750 ti","750",0,[[1920,1080,97]]],["nvidia geforce gtx 760","760",0,[[1920,1080,60],[1920,1200,116]]],["nvidia geforce gtx 760 oem","760",0,[[1920,1080,60]]],["nvidia geforce gtx 760 opengl engine","760",0,[[1920,1080,52]]],["nvidia geforce gtx 760 ti","760",0,[[1920,1080,60],[1920,1200,60]]],["nvidia geforce gtx 760 ti oem","760",0,[[1920,1200,60]]],["nvidia geforce gtx 760 ti opengl engine","760",0,[[1920,1080,60]]],["nvidia geforce gtx 760a","760",0,[[2560,1080,15]]],["nvidia geforce gtx 760m","760",0,[[1920,1080,60]]],["nvidia geforce gtx 765m","765",0,[[1920,1080,53],[2560,1440,57]]],["nvidia geforce gtx 765m by nick[d]vb","765",0,[[2560,1440,58]]],["nvidia geforce gtx 765m opengl engine","765",0,[[2560,1440,57]]],["nvidia geforce gtx 770","770",0,[[1920,1080,143],[2560,1440,203]]],["nvidia geforce gtx 770 opengl engine","770",0,[[1920,1080,60]]],["nvidia geforce gtx 770m","770",0,[[1920,1080,60],[2560,1440,59]]],["nvidia geforce gtx 770m by nick[d]vb","770",0,[[2560,1440,34]]],["nvidia geforce gtx 770m opengl engine","770",0,[[2560,1440,59]]],["nvidia geforce gtx 775m by idopt mac","775",0,[[2560,1440,56]]],["nvidia geforce gtx 775m mac","775",0,[[2560,1440,59]]],["nvidia geforce gtx 775m opengl engine","775",0,[[2560,1440,60]]],["nvidia geforce gtx 780","780",0,[[1920,1080,159]]],["nvidia geforce gtx 780 by st3phl3","780",0,[[3840,2160,30]]],["nvidia geforce gtx 780 mac","780",0,[[1680,1050,60],[1920,1080,60]]],["nvidia geforce gtx 780 rev. 2","780",0,[[1920,1080,144],[2560,1440,119],[3840,2160,58],[5120,2880,58]]],["nvidia geforce gtx 780 ti","780",0,[[1280,1024,120],[1920,1080,119]]],["nvidia geforce gtx 780 ti opengl engine","780",0,[[2560,1440,60]]],["nvidia geforce gtx 780m","780",0,[[1920,1080,60],[2560,1440,59]]],["nvidia geforce gtx 780m by nick[d]vb","780",0,[[1920,1080,59],[2560,1440,60]]],["nvidia geforce gtx 780m mac","780",0,[[2560,1440,60]]],["nvidia geforce gtx 780m opengl engine","780",0,[[2560,1440,60]]],["nvidia geforce gtx 850a","850",0,[[2560,1440,48]]],["nvidia geforce gtx 850m","850",0,[[1920,1080,60]]],["nvidia geforce gtx 860m","860",0,[[1920,1080,59]]],["nvidia geforce gtx 860m opengl engine","860",0,[[2560,1440,58]]],["nvidia geforce gtx 870m","870",0,[[1920,1080,60],[2560,1440,102]]],["nvidia geforce gtx 880m","880",0,[[1920,1080,60],[2560,1440,74]]],["nvidia geforce gtx 880m opengl engine","880",0,[[2560,1440,60]]],["nvidia geforce gtx 950","950",0,[[1920,1080,98]]],["nvidia geforce gtx 950 opengl engine","950",0,[[1920,1200,60]]],["nvidia geforce gtx 950a","950",0,[[1920,1080,60],[3840,2160,38]]],["nvidia geforce gtx 950m","950",0,[[1920,1080,114]]],["nvidia geforce gtx 960","960",0,[[1920,1080,60]]],["nvidia geforce gtx 960a","960",0,[[1920,1440,128]]],["nvidia geforce gtx 960m","960",0,[[1920,1080,119],[3840,2160,37]]],["nvidia geforce gtx 965m","965",0,[[1920,1080,195],[3000,2000,59],[3840,2160,41]]],["nvidia geforce gtx 965m opengl engine","965",0,[[2880,1620,55]]],["nvidia geforce gtx 970","970",0,[[1920,1080,143]]],["nvidia geforce gtx 970 opengl engine","970",0,[[2560,1600,60]]],["nvidia geforce gtx 970m","970",0,[[1920,1080,60]]],["nvidia geforce gtx 980","980",0,[[1920,1080,60],[3440,1440,294]]],["nvidia geforce gtx 980 ti","980",0,[[1920,1080,119],[2560,1440,456]]],["nvidia geforce gtx 980 ti opengl engine","980",0,[[1920,1080,60]]],["nvidia geforce gtx 980m","980",0,[[1920,1080,60],[3840,2160,104]]],["nvidia geforce gtx titan","gtx",0,[[1920,1080,119],[1920,1200,119],[2560,1440,60]]],["nvidia geforce gtx titan black","gtx",0,[[1680,1050,60],[1920,1080,60],[1920,1200,60],[2560,1440,60]]],["nvidia geforce gtx titan black opengl engine","gtx",0,[[3840,2160,60]]],["nvidia geforce gtx titan opengl engine","gtx",0,[[2560,1440,60]]],["nvidia geforce gtx titan x","gtxx",0,[[1920,1080,144],[2560,1440,120],[2560,1600,60]]],["nvidia geforce gtx titan xp","gtxxp",0,[[2560,1440,60],[3440,1440,60]]],["nvidia geforce gtx titan z","gtxz",0,[[1440,900,59],[1920,1080,39],[3840,2160,60]]],["nvidia geforce gtx780m by nikey22","780",0,[[2560,1440,60]]],["nvidia geforce gtx870m by nikey22","870",0,[[2560,1440,60]]],["nvidia geforce gtx880m","880",0,[[1920,1080,60]]],["nvidia geforce gtx880m by nikey22","880",0,[[2560,1440,59]]],["nvidia geforce gtx880m opengl engine","880",0,[[2560,1440,59]]],["nvidia geforce mx110","110",0,[[1366,768,61],[1920,1080,57]]],["nvidia geforce mx130","130",0,[[1920,1080,60]]],["nvidia geforce mx150","150",0,[[1920,1080,113]]],["nvidia geforce mx230","230",0,[[1920,1080,60]]],["nvidia geforce mx250","250",0,[[1920,1080,60]]],["nvidia geforce mx330","330",0,[[1920,1080,60],[3840,2160,51]]],["nvidia geforce mx350","350",0,[[1920,1080,60]]],["nvidia geforce mx450","450",0,[[1920,1080,60]]],["nvidia geforce pre-release graphics device","pre",0,[[2560,1440,60]]],["nvidia geforce pre-release tesla c2075 opengl engine","2075",0,[[1600,900,59]]],["nvidia geforce pre-release titan x opengl engine","prex",0,[[1920,1080,60]]],["nvidia geforce pre-release titan xp collectors edition opengl e","prexpe",0,[[1920,1080,59]]],["nvidia geforce pre-release titan xp opengl engine","prexp",0,[[2560,1440,60]]],["nvidia geforce rtx 2060","2060",0,[[1920,1080,512]]],["nvidia geforce rtx 2060 max-q","2060",0,[[2560,1440,301]]],["nvidia geforce rtx 2060 mobile","2060",0,[[1920,1080,518]]],["nvidia geforce rtx 2060 rev. a","2060",0,[[3840,2160,257]]],["nvidia geforce rtx 2060 super","2060",0,[[1920,1080,645],[2560,1440,143]]],["nvidia geforce rtx 2060 with max-q design","2060",0,[[1920,1080,292],[1920,1200,60]]],["nvidia geforce rtx 2070","2070",0,[[1920,1080,60],[3840,2160,60]]],["nvidia geforce rtx 2070 mobile","2070",0,[[1920,1080,477]]],["nvidia geforce rtx 2070 mobile / max-q","2070",0,[[1920,1080,526]]],["nvidia geforce rtx 2070 mobile / max-q refresh","2070",0,[[1920,1080,143]]],["nvidia geforce rtx 2070 rev. a","2070",0,[[2560,1440,144]]],["nvidia geforce rtx 2070 super","2070",0,[[1920,1080,510]]],["nvidia geforce rtx 2070 super with max-q design","2070",0,[[1920,1080,300]]],["nvidia geforce rtx 2070 with max-q design","2070",0,[[1920,1080,240]]],["nvidia geforce rtx 2080","2080",0,[[1920,1080,632],[2560,1440,165]]],["nvidia geforce rtx 2080 mobile","2080",0,[[1920,1080,144]]],["nvidia geforce rtx 2080 rev. a","2080",0,[[2560,1440,143]]],["nvidia geforce rtx 2080 super","2080",0,[[1920,1080,601]]],["nvidia geforce rtx 2080 super mobile / max-q","2080",0,[[3840,2160,59]]],["nvidia geforce rtx 2080 super with max-q design","2080",0,[[1920,1080,300]]],["nvidia geforce rtx 2080 ti","2080",0,[[1920,1080,83]]],["nvidia geforce rtx 2080 ti rev. a","2080",0,[[1920,1080,403]]],["nvidia geforce rtx 2080 with max-q design","2080",0,[[1920,1080,476]]],["nvidia geforce rtx 3050","3050",0,[[1920,1080,60]]],["nvidia geforce rtx 3050 laptop gpu","3050",0,[[1920,1080,144]]],["nvidia geforce rtx 3050 ti laptop gpu","3050",0,[[1920,1080,144]]],["nvidia geforce rtx 3060","3060",0,[[1920,1080,674]]],["nvidia geforce rtx 3060 laptop gpu","3060",0,[[1920,1080,300]]],["nvidia geforce rtx 3060 lite hash rate","3060",0,[[1920,1080,60]]],["nvidia geforce rtx 3060 mobile / max-q","3060",0,[[1920,1080,435]]],["nvidia geforce rtx 3060 ti","3060",0,[[1920,1080,779]]],["nvidia geforce rtx 3070","3070",0,[[1920,1080,723],[2560,1440,294]]],["nvidia geforce rtx 3070 laptop gpu","3070",0,[[1920,1080,357]]],["nvidia geforce rtx 3070 mobile / max-q","3070",0,[[2560,1440,386]]],["nvidia geforce rtx 3070 ti","3070",0,[[1920,1080,60]]],["nvidia geforce rtx 3080","3080",0,[[1920,1080,726],[2560,1440,60],[3840,2160,60]]],["nvidia geforce rtx 3080 laptop gpu","3080",0,[[1920,1080,294],[2560,1440,244]]],["nvidia geforce rtx 3080 mobile / max-q 8gb/16gb","3080",0,[[1920,1080,293]]],["nvidia geforce rtx 3080 ti","3080",0,[[1920,1080,239],[2560,1440,60]]],["nvidia geforce rtx 3090","3090",0,[[2560,1440,60],[3840,2160,474]]],["nvidia geforce rtx t10-16","10",0,[[2560,1600,3]]],["nvidia geforce rtx t10-8","10",0,[[2560,1600,3]]],["nvidia gf100 board - 10220000","100",0,[[1920,1200,60]]],["nvidia gf117","117",0,[[1920,1080,32]]],["nvidia gigabyte geforce gt 440","440",0,[[1280,1024,34]]],["nvidia gigabyte geforce gt 610","610",0,[[1920,1080,17]]],["nvidia gigabyte geforce gt 630","630",0,[[1920,1080,34]]],["nvidia gigabyte geforce gt 730","730",0,[[1280,1024,38]]],["nvidia gigabyte geforce gts 450","450",0,[[1280,1024,37]]],["nvidia gigabyte geforce gtx 1050 ti","1050",0,[[1920,1080,30]]],["nvidia gigabyte geforce gtx 460","460",0,[[1680,1050,60]]],["nvidia gigabyte geforce gtx 550 ti","550",0,[[1920,1080,57]]],["nvidia gigabyte geforce gtx 560 ti","560",0,[[1920,1080,60]]],["nvidia gigabyte geforce gtx 570 hd","570",0,[[1920,1080,60]]],["nvidia gigabyte geforce gtx 580","580",0,[[1920,1200,60]]],["nvidia gigabyte geforce gtx 650","650",0,[[1680,1050,55]]],["nvidia gigabyte geforce gtx 650 ti","650",0,[[2560,1440,40]]],["nvidia gigabyte geforce gtx 660","660",0,[[1920,1080,31]]],["nvidia gigabyte geforce gtx 660 ti","660",0,[[5120,2880,29]]],["nvidia gigabyte geforce gtx 670","670",0,[[1920,1080,60]]],["nvidia gigabyte geforce gtx 750","750",0,[[1920,1080,59]]],["nvidia gigabyte geforce gtx 750 ti","750",0,[[1920,1080,60]]],["nvidia gigabyte geforce gtx 760","760",0,[[3440,1440,17]]],["nvidia gigabyte geforce gtx 770","770",0,[[2560,1440,59]]],["nvidia gigabyte geforce gtx 780 ti","780",0,[[1920,1080,240]]],["nvidia gigabyte geforce gtx 960","960",0,[[1920,1080,142],[1920,1200,120]]],["nvidia gigabyte geforce gtx 970","970",0,[[1920,1080,60]]],["nvidia gigabyte geforce gtx 980","980",0,[[2560,1440,60]]],["nvidia gigabyte geforce gtx 980 ti","980",0,[[1920,1080,60]]],["nvidia gk104 board - 2051b502","104",0,[[2560,1440,60]]],["nvidia gk104 board - 20530501","104",0,[[2560,1440,60]]],["nvidia gk104gl [grid k2]","104",0,[[2560,1343,21]]],["nvidia gk104gl [grid k520]","104",0,[[1024,768,120]]],["nvidia gp102 [titan x]","102",0,[[3440,1440,462]]],["nvidia gp102 [titan xp]","102",0,[[1920,1080,126]]],["nvidia gp104","104",0,[[1920,1080,60]]],["nvidia gp104gl","104",0,[[2560,1343,36]]],["nvidia gp108","108",0,[[1920,1080,60]]],["nvidia graphics device","",0,[[1920,1080,60],[1920,1200,60],[3840,2160,60]]],["nvidia grid gtx p40-6","40",0,[[1440,900,153]]],["nvidia grid k1","1",0,[[1245,768,6],[1920,1080,35]]],["nvidia grid k140q vgpu","140",0,[[1920,1080,30]]],["nvidia grid k160q","160",0,[[1920,1080,34]]],["nvidia grid k180q","180",0,[[1920,1080,28]]],["nvidia grid k2","2",0,[[1245,768,6],[1920,1080,59]]],["nvidia grid k220q","220",0,[[1920,1200,34]]],["nvidia grid k240q","240",0,[[1920,1080,64]]],["nvidia grid k260q","260",0,[[2560,1440,31]]],["nvidia grid k280q","280",0,[[1920,1080,64]]],["nvidia grid k520","520",0,[[1280,720,60]]],["nvidia grid m10-1b","10",0,[[1024,768,49]]],["nvidia grid m10-2q","10",0,[[2560,1440,15]]],["nvidia grid m6-0b","6",0,[[1680,1050,33]]],["nvidia grid m60-1b","60",0,[[1680,1050,46],[1920,1080,46]]],["nvidia grid m60-1q","60",0,[[1536,864,60]]],["nvidia grid m60-2q","60",0,[[1920,1080,57]]],["nvidia grid m60-4q","60",0,[[1920,1080,59]]],["nvidia grid m60-8q","60",0,[[1920,1080,60]]],["nvidia grid p100-4q","100",0,[[2560,1440,16]]],["nvidia grid p4-4q","4",0,[[1892,932,247]]],["nvidia grid p40-4q","40",0,[[2741,1495,60]]],["nvidia grid p40-8q","40",0,[[1920,1080,60]]],["nvidia grid rtx6000-2q","6000",0,[[1024,768,60]]],["nvidia grid rtx6000p-6","6000",0,[[1280,1024,161]]],["nvidia grid t4-16q","4",0,[[1920,1080,61]]],["nvidia grid t4-1b","4",0,[[1920,1080,46]]],["nvidia grid t4-1q","4",0,[[1280,1024,48]]],["nvidia grid t4-2b4","4",0,[[1536,864,47]]],["nvidia grid t4-2q","4",0,[[1920,1080,65]]],["nvidia grid t4-8q","4",0,[[2560,1080,60]]],["nvidia grid v100-1q","100",0,[[1646,1154,59]]],["nvidia grid v100-2b","100",0,[[1440,900,45]]],["nvidia grid v100dx-16q","100",0,[[1280,1024,60]]],["nvidia grid v100dx-1q","100",0,[[1280,1024,60]]],["nvidia gtx 1060 hl","1060",0,[[3840,2160,60]]],["nvidia gtx 865m by imacgfx","865",0,[[2560,1440,60]]],["nvidia gtx 980m sli","980",0,[[1366,768,29]]],["nvidia gv-n660oc-2gd","660",0,[[1920,1200,60]]],["nvidia gv100","100",0,[[3840,2160,60]]],["nvidia gv100 [titan v]","100",0,[[2560,1440,60]]],["nvidia gv102","102",0,[[2560,1600,525]]],["nvidia hp geforce gt 730","730",0,[[1920,1080,55]]],["nvidia hp quadro 2000","2000",0,[[2560,1080,38]]],["nvidia hp quadro 4000","4000",0,[[2560,1080,52]]],["nvidia hp quadro 600","600",0,[[1360,768,41]]],["nvidia hp quadro k4000","4000",0,[[1920,1200,26]]],["nvidia hp quadro k620","620",0,[[1600,1200,94]]],["nvidia inno3d geforce gtx660","3",0,[[2560,1440,107]]],["nvidia microsoft virtual render driver","",0,[[1920,1080,59]]],["nvidia msi geforce gt 610","610",0,[[1920,1080,16]]],["nvidia msi geforce gt 630","630",0,[[1440,900,12]]],["nvidia msi geforce gt 635","635",0,[[1920,1080,30]]],["nvidia msi geforce gt 710","710",0,[[1920,1080,27]]],["nvidia msi geforce gt 730","730",0,[[1920,1080,53]]],["nvidia msi geforce gtx 1050 ti","1050",0,[[1920,1080,59]]],["nvidia msi geforce gtx 1060","1060",0,[[1920,1080,120]]],["nvidia msi geforce gtx 1070","1070",0,[[1920,1200,45]]],["nvidia msi geforce gtx 460","460",0,[[1920,1080,60]]],["nvidia msi geforce gtx 560 ti","560",0,[[1920,1080,60]]],["nvidia msi geforce gtx 570 hd","570",0,[[1920,1200,60]]],["nvidia msi geforce gtx 580","580",0,[[2560,1440,60]]],["nvidia msi geforce gtx 650","650",0,[[2560,1080,52]]],["nvidia msi geforce gtx 650 ti","650",0,[[1920,1080,60]]],["nvidia msi geforce gtx 660","660",0,[[1920,1080,60]]],["nvidia msi geforce gtx 660 ti","660",0,[[1680,1050,49]]],["nvidia msi geforce gtx 670","670",0,[[1920,1080,60]]],["nvidia msi geforce gtx 745","745",0,[[1920,1080,55]]],["nvidia msi geforce gtx 760","760",0,[[1280,1024,30],[1920,1080,58]]],["nvidia msi geforce gtx 780","780",0,[[1920,1080,60]]],["nvidia msi geforce gtx 950","950",0,[[1920,1080,59]]],["nvidia msi geforce gtx 960","960",0,[[1680,1050,120],[2560,1440,59]]],["nvidia msi geforce gtx 970","970",0,[[1680,1050,60]]],["nvidia msi geforce gtx 980","980",0,[[1920,1080,120],[3840,2160,60]]],["nvidia msi geforce gtx 980 ti","980",0,[[5120,2880,56]]],["nvidia n15e-gt","15",0,[[3840,2160,30]]],["nvidia null geforce 920a","920",0,[[1920,1080,25]]],["nvidia null graphics device","",0,[[1920,1080,24]]],["nvidia nvs 310","310",0,[[1280,1024,24],[1920,1080,15]]],["nvidia nvs 3100m","3100",0,[[1920,1080,10]]],["nvidia nvs 315","315",0,[[1280,1024,25],[1920,1080,15]]],["nvidia nvs 4200m","4200",0,[[1920,1080,11]]],["nvidia nvs 510","510",0,[[1920,1200,27],[2560,1080,24],[3440,1440,16]]],["nvidia nvs 5200m","5200",0,[[1366,768,55],[1600,900,33],[1920,1080,57]]],["nvidia nvs 5400m","5400",0,[[1600,900,46],[1920,1200,27]]],["nvidia p102-100","102",0,[[1600,1200,35]]],["nvidia p106-090","106",0,[[1920,1371,16]]],["nvidia p106-100","106",0,[[1920,1080,60],[3840,2160,30]]],["nvidia p106-100 custom","106",0,[[1680,1050,60]]],["nvidia palit geforce gtx 650","650",0,[[1920,1080,49]]],["nvidia palit geforce gtx 650 ti","650",0,[[1920,1080,59]]],["nvidia palit geforce gtx 660","660",0,[[1920,1080,26]]],["nvidia palit gtx 680 jetstream","680",0,[[1920,1080,60]]],["nvidia pegatron geforce gt 420","420",0,[[1400,1050,25]]],["nvidia pny geforce gt 610","610",0,[[1280,1024,19]]],["nvidia pny geforce gtx 1060","1060",0,[[1920,1080,60]]],["nvidia pny geforce gtx 460","460",0,[[1360,768,59]]],["nvidia pny geforce gtx 550 ti","550",0,[[1920,1080,55]]],["nvidia pny geforce gtx 570 hd","570",0,[[1280,1024,72]]],["nvidia pny geforce gtx 580","580",0,[[1920,1200,59]]],["nvidia pny geforce gtx 680","680",0,[[2560,1080,120]]],["nvidia pny geforce gtx 750","750",0,[[1280,1024,60]]],["nvidia pny geforce gtx 970","970",0,[[2560,1440,60]]],["nvidia pny geforce gtx 980","980",0,[[1920,1080,120]]],["nvidia point of view geforce gtx 470","470",0,[[1920,1080,59]]],["nvidia point of view geforce gtx 660 ti","660",0,[[1680,1050,59]]],["nvidia quadro 1000m","1000",0,[[1920,1080,28]]],["nvidia quadro 1000m,","1000",0,[[1920,1080,27]]],["nvidia quadro 2000","2000",0,[[1920,1080,51],[2560,1440,28]]],["nvidia quadro 2000d","2000",0,[[1280,1024,56]]],["nvidia quadro 2000m","2000",0,[[1920,1080,31]]],["nvidia quadro 3000m","3000",0,[[1920,1080,53],[2560,1440,6]]],["nvidia quadro 3000m opengl engine","3000",0,[[1920,1080,49]]],["nvidia quadro 4000","4000",0,[[1920,1080,56],[1920,1200,58]]],["nvidia quadro 4000m","4000",0,[[1920,1080,51]]],["nvidia quadro 410","410",0,[[1920,1080,23]]],["nvidia quadro 5000","5000",0,[[1920,1080,60],[2560,1080,55],[2560,1440,51]]],["nvidia quadro 5000 opengl engine","5000",0,[[1920,1200,59]]],["nvidia quadro 5000m","5000",0,[[1600,900,110]]],["nvidia quadro 600","600",0,[[1680,1050,28],[1920,1080,28],[1920,1200,26]]],["nvidia quadro 6000","6000",0,[[1920,1080,60],[1920,1200,60]]],["nvidia quadro 7000","7000",0,[[1920,1200,60]]],["nvidia quadro fx 1800m","1800",0,[[1600,900,15]]],["nvidia quadro fx 2800m","2800",0,[[1920,1200,36]]],["nvidia quadro fx grid k1","1",0,[[1920,1080,31]]],["nvidia quadro gp100","100",0,[[1920,1200,366]]],["nvidia quadro gv100","100",0,[[3840,2160,60],[4096,2160,60]]],["nvidia quadro k1000m","1000",0,[[1920,1080,28]]],["nvidia quadro k1000m by nick[d]vb","1000",0,[[1920,1080,36]]],["nvidia quadro k1100m","1100",0,[[1920,1080,56]]],["nvidia quadro k1100m by nick[d]vb","1100",0,[[1920,1080,66]]],["nvidia quadro k1100m opengl engine","1100",0,[[1920,1080,54]]],["nvidia quadro k1200","1200",0,[[1920,1080,60],[2560,1440,57],[3840,2160,28]]],["nvidia quadro k1200 opengl engine","1200",0,[[3840,2160,34]]],["nvidia quadro k2000","2000",0,[[1920,1080,55]]],["nvidia quadro k2000 opengl engine","2000",0,[[2560,1440,44]]],["nvidia quadro k2000d","2000",0,[[1280,1024,57],[1680,1050,57],[1920,1080,59]]],["nvidia quadro k2000m","2000",0,[[1920,1080,36]]],["nvidia quadro k2000m by nick[d]vb","2000",0,[[2560,1440,38]]],["nvidia quadro k2000m opengl engine","2000",0,[[1920,1080,43]]],["nvidia quadro k2100m","2100",0,[[1920,1080,58]]],["nvidia quadro k2100m by nick[d]vb","2100",0,[[2560,1440,54]]],["nvidia quadro k2100m opengl engine","2100",0,[[1920,1080,59]]],["nvidia quadro k2200","2200",0,[[1920,1080,60],[1920,1200,126],[5120,2880,25]]],["nvidia quadro k2200m","2200",0,[[1920,1080,60]]],["nvidia quadro k3000m","3000",0,[[1920,1080,59]]],["nvidia quadro k3000m by st3phl3","3000",0,[[2560,1440,50]]],["nvidia quadro k3100m","3100",0,[[1920,1080,60]]],["nvidia quadro k3100m by nikey22","3100",0,[[2560,1440,59]]],["nvidia quadro k3100m opengl engine","3100",0,[[2560,1440,58]]],["nvidia quadro k4000","4000",0,[[1920,1080,60],[1920,1200,59]]],["nvidia quadro k4000 opengl engine","4000",0,[[1920,1080,59]]],["nvidia quadro k4000m","4000",0,[[1920,1080,80]]],["nvidia quadro k4100m","4100",0,[[1920,1080,32]]],["nvidia quadro k4100m by nikey22","4100",0,[[2560,1440,60]]],["nvidia quadro k420","420",0,[[1366,768,57],[2560,1440,19],[3840,2160,10]]],["nvidia quadro k4200","4200",0,[[1920,1080,60],[2560,1440,59],[3840,2160,57]]],["nvidia quadro k5000","5000",0,[[1920,1080,60],[2560,1440,60]]],["nvidia quadro k5000 opengl engine","5000",0,[[2560,1600,59]]],["nvidia quadro k5000m","5000",0,[[1920,1080,60],[2560,1440,60]]],["nvidia quadro k5000m opengl engine","5000",0,[[2560,1440,60]]],["nvidia quadro k5100m","5100",0,[[1920,1080,60],[2560,1080,171]]],["nvidia quadro k5100m by nikey22","5100",0,[[2560,1440,60]]],["nvidia quadro k510m","510",0,[[1920,1080,33]]],["nvidia quadro k5200","5200",0,[[1920,1080,60],[1920,1200,60]]],["nvidia quadro k5200 opengl engine","5200",0,[[1920,1200,41]]],["nvidia quadro k600","600",0,[[1920,1080,28]]],["nvidia quadro k600 opengl engine","600",0,[[1920,1200,31]]],["nvidia quadro k6000","6000",0,[[1920,1080,60],[1920,1200,60],[2560,1440,60]]],["nvidia quadro k6000 opengl engine","6000",0,[[1920,1080,59]]],["nvidia quadro k610m","610",0,[[1920,1080,36]]],["nvidia quadro k610m by nick[d]vb","610",0,[[1920,1080,34]]],["nvidia quadro k620","620",0,[[1920,1080,87],[1920,1200,69],[2560,1440,44]]],["nvidia quadro k620 opengl engine","620",0,[[1920,1080,59]]],["nvidia quadro k620m","620",0,[[1920,1080,49],[2880,1620,15]]],["nvidia quadro m1000m","1000",0,[[1920,1080,60]]],["nvidia quadro m1200","1200",0,[[1920,1080,60],[3840,2160,43]]],["nvidia quadro m2000","2000",0,[[1920,1080,73],[2560,1440,59]]],["nvidia quadro m2000m","2000",0,[[1920,1080,60]]],["nvidia quadro m2000m special","2000",0,[[1920,1080,60]]],["nvidia quadro m2200","2200",0,[[1920,1080,60]]],["nvidia quadro m2200 mobile","2200",0,[[3840,2160,13]]],["nvidia quadro m3000m","3000",0,[[1920,1080,60]]],["nvidia quadro m4000","4000",0,[[1920,1080,120],[1920,1200,60],[2560,1440,60]]],["nvidia quadro m4000 opengl engine","4000",0,[[1920,1080,60]]],["nvidia quadro m4000m","4000",0,[[1920,1080,60],[3840,2160,69]]],["nvidia quadro m5000","5000",0,[[1920,1080,60],[1920,1200,60],[2560,1440,59]]],["nvidia quadro m5000m","5000",0,[[1920,1080,212],[3840,2160,60]]],["nvidia quadro m500m","500",0,[[1920,1080,58],[2880,1620,29]]],["nvidia quadro m520","520",0,[[1920,1080,59],[3840,2160,27]]],["nvidia quadro m5500","5500",0,[[3440,1440,60]]],["nvidia quadro m6000","6000",0,[[1920,1080,408],[2560,1440,60]]],["nvidia quadro m6000 24gb","6000",0,[[1680,1050,60],[1920,1200,60]]],["nvidia quadro m600m","600",0,[[1920,1080,59]]],["nvidia quadro m620","620",0,[[1920,1080,60]]],["nvidia quadro nvs 4200m","4200",0,[[1600,900,26],[1920,1080,19]]],["nvidia quadro p1000","1000",0,[[1920,1080,60],[1920,1200,60]]],["nvidia quadro p1000 mobile","1000",0,[[1920,1080,60]]],["nvidia quadro p2000","2000",0,[[1680,1050,60],[1920,1080,242],[2560,1440,60]]],["nvidia quadro p2000 mobile","2000",0,[[1920,1080,60]]],["nvidia quadro p2000 opengl engine","2000",0,[[1920,1080,59]]],["nvidia quadro p2000 with max-q design","2000",0,[[1920,1080,60],[3840,2160,67]]],["nvidia quadro p2200","2200",0,[[1920,1080,60],[3840,2160,340]]],["nvidia quadro p3000","3000",0,[[1920,1080,60]]],["nvidia quadro p3200","3200",0,[[1920,1080,60],[3840,2160,60]]],["nvidia quadro p3200 mobile","3200",0,[[3840,2160,60]]],["nvidia quadro p3200 with max-q design","3200",0,[[2560,1440,60]]],["nvidia quadro p400","400",0,[[1680,1050,46],[1920,1080,57],[1920,1200,54]]],["nvidia quadro p4000","4000",0,[[1920,1080,60],[3840,2160,167]]],["nvidia quadro p4200","4200",0,[[1920,1080,60],[3840,2160,60]]],["nvidia quadro p4200 with max-q design","4200",0,[[3839,2159,53]]],["nvidia quadro p500","500",0,[[1920,1080,60]]],["nvidia quadro p5000","5000",0,[[1920,1080,60]]],["nvidia quadro p5000 opengl engine","5000",0,[[3840,2160,58]]],["nvidia quadro p520","520",0,[[1920,1080,60]]],["nvidia quadro p5200","5200",0,[[3840,2160,100]]],["nvidia quadro p600","600",0,[[1920,1080,60]]],["nvidia quadro p6000","6000",0,[[1920,1080,60],[2560,1440,60],[2560,1600,411]]],["nvidia quadro p620","620",0,[[1920,1080,65]]],["nvidia quadro rtx 3000","3000",0,[[1920,1080,60]]],["nvidia quadro rtx 3000 mobile / max-q","3000",0,[[3840,2160,60]]],["nvidia quadro rtx 3000 with max-q design","3000",0,[[3240,2160,60]]],["nvidia quadro rtx 4000","4000",0,[[1920,1080,60]]],["nvidia quadro rtx 4000 mobile / max-q","4000",0,[[1920,1080,60]]],["nvidia quadro rtx 4000 with max-q design","4000",0,[[1920,1080,60],[3840,2160,60]]],["nvidia quadro rtx 5000","5000",0,[[1920,1080,443],[2560,1440,60]]],["nvidia quadro rtx 5000 mobile / max-q","5000",0,[[3840,2160,60]]],["nvidia quadro rtx 5000 with max-q design","5000",0,[[1920,1080,60],[3840,2160,60]]],["nvidia quadro rtx 6000","6000",0,[[1920,1080,438],[2560,1440,60]]],["nvidia quadro rtx 8000","8000",0,[[1920,1080,60],[1920,1200,60]]],["nvidia quadro t1000","1000",0,[[1920,1080,60],[2560,1440,41]]],["nvidia quadro t1000 mobile","1000",0,[[1920,1080,277]]],["nvidia quadro t1000 with max-q design","1000",0,[[1920,1080,60]]],["nvidia quadro t2000","2000",0,[[1920,1080,60]]],["nvidia quadro t2000 mobile / max-q","2000",0,[[1920,1080,302]]],["nvidia quadro t2000 with max-q design","2000",0,[[1920,1080,60],[1920,1200,60],[2560,1440,60]]],["nvidia rtx a1000 laptop gpu","1000",0,[[1920,1080,60]]],["nvidia rtx a2000","2000",0,[[3840,2160,60]]],["nvidia rtx a2000 laptop gpu","2000",0,[[2400,1600,120],[3840,2160,60]]],["nvidia rtx a3000 laptop gpu","3000",0,[[1920,1080,60],[3840,2160,60]]],["nvidia rtx a4000","4000",0,[[1920,1080,60],[3840,2160,60]]],["nvidia rtx a4000 laptop gpu","4000",0,[[1920,1080,60]]],["nvidia rtx a5000","5000",0,[[3840,2160,60]]],["nvidia rtx a5000 laptop gpu","5000",0,[[3840,2160,60]]],["nvidia rtx a6000","6000",0,[[1920,1200,60]]],["nvidia sony geforce 410m","410",0,[[1366,768,24]]],["nvidia t1000","1000",0,[[1920,1080,43],[3840,2160,60]]],["nvidia t1200 laptop gpu","1200",0,[[1920,1080,60]]],["nvidia t400","400",0,[[3840,2160,35]]],["nvidia t500","500",0,[[1920,1080,60],[3839,2159,52]]],["nvidia t600","600",0,[[1920,1080,60]]],["nvidia tesla c2050 / c2070","2050",0,[[1920,1080,105]]],["nvidia tesla c2070","2070",0,[[1920,1200,60]]],["nvidia tesla c2075","2075",0,[[1920,1080,60]]],["nvidia tesla k10","10",0,[[1920,1080,60]]],["nvidia tesla k10.g1.8gb","10",0,[[1440,900,59]]],["nvidia tesla k20m","20",0,[[1240,821,118]]],["nvidia tesla k20xm","20",0,[[3840,2400,17]]],["nvidia tesla k80","80",0,[[1664,896,66],[3840,2160,30]]],["nvidia tesla m10","10",0,[[1440,900,60],[1280,1024,60]]],["nvidia tesla m40","40",0,[[1600,1024,190]]],["nvidia tesla m6","6",0,[[1920,1080,59]]],["nvidia tesla m60","60",0,[[1366,768,60],[1920,962,61],[3840,2160,27]]],["nvidia tesla p100 pcie 16gb","100",0,[[1920,1080,60]]],["nvidia tesla p100-pcie-16gb","100",0,[[1920,1080,103]]],["nvidia tesla p4","4",0,[[1680,1050,60]]],["nvidia tesla p40","40",0,[[1546,877,62],[1920,1200,60]]],["nvidia tesla t4","4",0,[[1440,900,33],[1920,1080,60]]],["nvidia tesla v100-pcie-16gb","100",0,[[1920,997,57]]],["nvidia tesla v100-pcie-32gb","100",0,[[1920,1080,57]]],["nvidia tesla v100-sxm2-16gb","100",0,[[1920,1080,60]]],["nvidia tesla v100-sxm2-32gb","100",0,[[1920,1080,1],[2560,1440,60]]],["nvidia titan rtx","rtx",0,[[2560,1440,60],[3840,2160,680]]],["nvidia titan v","v",0,[[2560,1440,622],[3840,2160,60]]],["nvidia titan x","x",0,[[2560,1080,60],[3840,1600,75],[3840,2160,339]]],["nvidia titan xp","xp",0,[[1920,1200,60],[2560,1440,60],[3440,1440,105]]],["nvidia titan xp collectors","xp",0,[[1920,1080,60],[2560,1440,893],[5120,2880,60]]],["nvidia toshiba geforce gt 525m","525",0,[[1366,768,33]]],["nvidia tu102 [titan rtx]","102",0,[[3840,2160,60]]],["nvidia tu107","107",0,[[1920,1080,312]]],["nvidia tu117m","117",0,[[1920,1080,337]]],["nvidia unknown","",0,[[1920,1080,60]]],["nvidia zotac geforce gt 430","430",0,[[1600,900,32]]],["nvidia zotac geforce gt 610","610",0,[[1920,1080,15]]],["nvidia zotac geforce gt 630","630",0,[[1360,768,46]]],["nvidia zotac geforce gt 740","740",0,[[1280,1024,118]]],["nvidia zotac geforce gtx 460","460",0,[[1920,1080,59]]],["nvidia zotac geforce gtx 550 ti","550",0,[[1920,1080,42]]],["nvidia zotac geforce gtx 560","560",0,[[1920,1080,60]]],["nvidia zotac geforce gtx 560 ti","560",0,[[1920,1080,60]]],["nvidia zotac geforce gtx 580","580",0,[[1920,1080,48]]],["nvidia zotac geforce gtx 650","650",0,[[1920,1080,44]]],["nvidia zotac geforce gtx 650 ti","650",0,[[1920,1080,58]]],["nvidia zotac geforce gtx 660","660",0,[[1920,1080,60]]],["nvidia zotac geforce gtx 680","680",0,[[1920,1080,60]]],["nvidia zotac geforce gtx 750","750",0,[[1680,1050,114],[1920,1080,60]]],["nvidia zotac geforce gtx 760","760",0,[[1920,1080,101]]],["nvidia zotac geforce gtx 770","770",0,[[1920,1080,60]]],["nvidia zotac geforce gtx 780","780",0,[[1920,1080,60]]],["nvidia zotac geforce gtx 960","960",0,[[2048,1152,60]]]]')},145:e=>{"use strict";e.exports=JSON.parse('["4.0.8",["amd [amd/ati] fiji [radeon r9 fury / nano series]","9",0,[[1920,1200,162]]],["amd asus amd radeon r9-990x","9",0,[[1920,1080,60]]],["amd asus radeon r7 250","7",0,[[800,638,60]]],["amd asus radeon r7 260x","7",0,[[2560,1080,65]]],["amd asus radeon r9 270x","9",0,[[1024,768,85],[1920,1080,60]]],["amd asus radeon r9 280","9",0,[[1920,1080,60]]],["amd asus radeon rx 460","460",0,[[1360,768,104]]],["amd asus radeon rx 470","470",0,[[1920,1080,60]]],["amd asus radeon rx 480","480",0,[[1920,1080,124]]],["amd asus radeon rx 550","550",0,[[1440,900,60],[1920,1080,49]]],["amd asus radeon rx 5500 xt","5500",0,[[1920,1080,325]]],["amd asus radeon rx 560","560",0,[[1360,768,60],[1920,1080,85]]],["amd asus radeon rx 570","570",0,[[1600,900,202],[1920,1080,60]]],["amd asus radeon rx 5700","5700",0,[[1920,1080,327]]],["amd asus radeon rx 5700 xt","5700",0,[[1920,1080,224],[2560,1440,60]]],["amd asus radeon rx 580","580",0,[[1920,1080,177],[2560,1080,60]]],["amd asus radeon rx vega","rx",0,[[2560,1440,117]]],["amd ati mobility radeon hd 5870","5870",0,[[1920,1200,19]]],["amd baffin amd radeon rx 560","560",0,[[1920,1080,60]]],["amd ellesmere radeon rx 570","570",0,[[1920,1080,60]]],["amd embedded radeon e9171","9171",0,[[3840,2160,26]]],["amd embedded radeon e9173","9173",0,[[3840,2160,16]]],["amd gigabyte radeon rx 580","580",0,[[1920,1080,60]]],["amd madison [mobility radeon hd 5650 / 6530m/6550m]","5650",0,[[1366,768,43]]],["amd mobility radeon hd 4250","4250",0,[[963,722,26]]],["amd mobility radeon hd 5000","5000",0,[[1366,768,47]]],["amd mobility radeon hd 5400","5400",0,[[1366,768,24]]],["amd mobility radeon hd 5430","5430",0,[[1600,900,15],[1920,1080,60]]],["amd mobility radeon hd 5470","5470",0,[[1366,768,24]]],["amd mobility radeon hd 5570","5570",0,[[1920,1080,27]]],["amd mobility radeon hd 5730 / 6570m","5730",0,[[1366,768,58]]],["amd mobility radeon hd 5850","5850",0,[[1600,900,55]]],["amd mobility radeon hd 5870","5870",0,[[1600,900,64],[1920,1200,53]]],["amd park [mobility radeon hd 5430","5430",0,[[1280,720,11]]],["amd pitcairn pro radeon hd 7850","7850",0,[[1920,1080,60]]],["amd powercolor radeon r9 280","9",0,[[1920,1080,60]]],["amd radeon","",0,[[1920,1080,299],[3440,1440,60]]],["amd radeon 500","500",0,[[1920,1080,73]]],["amd radeon 520","520",0,[[1920,1080,35],[2560,1440,29]]],["amd radeon 530","530",0,[[1366,768,60],[1920,1080,30]]],["amd radeon 535","535",0,[[1920,1080,35]]],["amd radeon 535dx","535",0,[[1366,768,31],[1920,1080,37]]],["amd radeon 540","540",0,[[1920,1080,38]]],["amd radeon 540 / rx 540x/550/550x","540",0,[[2560,1440,88]]],["amd radeon 540x","540",0,[[1920,1080,59]]],["amd radeon 550","550",0,[[1920,1080,115]]],["amd radeon 550x","550",0,[[1920,1080,28]]],["amd radeon 610","610",0,[[1920,1080,29]]],["amd radeon 620","620",0,[[1920,1080,18]]],["amd radeon 625","625",0,[[1366,768,55],[1920,1080,47]]],["amd radeon 630","630",0,[[1920,1080,29]]],["amd radeon 6600m and 6700m","6600",0,[[1366,768,36],[1440,900,60]]],["amd radeon 6800","6800",0,[[3440,1440,100]]],["amd radeon 7500m/7600m","7500",0,[[1366,768,37]]],["amd radeon 7950 x2","7950",0,[[2560,1440,174]]],["amd radeon d700","700",0,[[2560,1440,120]]],["amd radeon e6460","6460",0,[[1600,1200,13]]],["amd radeon e6760","6760",0,[[1200,900,54],[1920,1080,42]]],["amd radeon e8860","8860",0,[[1920,1200,27],[2560,1374,88]]],["amd radeon e8870","8870",0,[[1920,1080,81]]],["amd radeon e8870mxm","8870",0,[[1920,1080,60]]],["amd radeon e9260","9260",0,[[1680,1050,60],[3840,2160,38]]],["amd radeon e9550","9550",0,[[1680,1050,60],[3840,2160,58]]],["amd radeon embedded e9560","9560",0,[[1920,1200,60]]],["amd radeon fury","",0,[[1920,1080,60]]],["amd radeon fury x","x",0,[[1920,1080,60],[2560,1440,144]]],["amd radeon hd - firepro d300","300",0,[[1920,1080,60]]],["amd radeon hd - firepro d300 opengl engine","300",0,[[1920,1080,60],[2560,1440,59]]],["amd radeon hd - firepro d500 opengl engine","500",0,[[1920,1080,60],[2560,1440,59]]],["amd radeon hd - firepro d700 opengl engine","700",0,[[3840,2160,52]]],["amd radeon hd 2600 xt","2600",1,[[2560,1600,-1]]],["amd radeon hd 5000","5000",0,[[1920,1080,8]]],["amd radeon hd 5400","5400",0,[[1920,1080,12]]],["amd radeon hd 5450","5450",0,[[1920,1080,13]]],["amd radeon hd 5470","5470",0,[[1280,1024,16]]],["amd radeon hd 5500","5500",0,[[1920,1080,27]]],["amd radeon hd 5570","5570",0,[[1920,1080,60],[2048,1152,31]]],["amd radeon hd 5600","5600",0,[[1920,1080,56]]],["amd radeon hd 5650","5650",0,[[1366,768,53]]],["amd radeon hd 5670","5670",1,[[1920,1080,-1],[2560,1440,-1]]],["amd radeon hd 5670 opengl engine","5670",1,[[2560,1440,-1]]],["amd radeon hd 5700","5700",0,[[1920,1080,59]]],["amd radeon hd 5730","5730",0,[[1366,768,46],[1680,1050,40]]],["amd radeon hd 5750","5750",1,[[1920,1080,-1],[1920,1200,-1],[2560,1440,-1]]],["amd radeon hd 5750 opengl engine","5750",1,[[2560,1440,-1]]],["amd radeon hd 5770","5770",0,[[1776,1000,43],[1920,1080,59]]],["amd radeon hd 5800","5800",0,[[1366,768,60],[1920,1200,102]]],["amd radeon hd 5850","5850",0,[[1920,1080,60]]],["amd radeon hd 5870","5870",0,[[1280,960,75],[1920,1080,60],[2048,1280,60]]],["amd radeon hd 5870m","5870",0,[[2560,1080,31]]],["amd radeon hd 5970","5970",0,[[1360,768,60],[1920,1080,60]]],["amd radeon hd 6230","6230",0,[[1366,768,13]]],["amd radeon hd 6250","6250",0,[[1280,800,8],[1366,768,8]]],["amd radeon hd 6290","6290",1,[[1366,768,-1]]],["amd radeon hd 6300m","6300",1,[[1366,768,-1]]],["amd radeon hd 6310","6310",1,[[1366,768,-1]]],["amd radeon hd 6320","6320",1,[[1366,768,-1]]],["amd radeon hd 6350","6350",0,[[1280,1024,18],[1920,1080,14]]],["amd radeon hd 6370d","6370",0,[[1920,1080,14]]],["amd radeon hd 6370m","6370",0,[[1366,768,25]]],["amd radeon hd 6380g","6380",0,[[1366,768,19]]],["amd radeon hd 6400","6400",0,[[1920,1080,13]]],["amd radeon hd 6400m","6400",0,[[1366,768,28]]],["amd radeon hd 6400m/7400m","6400",0,[[1366,768,28]]],["amd radeon hd 6410d","6410",0,[[1920,1080,11]]],["amd radeon hd 6450","6450",0,[[1920,1080,14]]],["amd radeon hd 6450 / r5 230","6450",0,[[1440,900,12]]],["amd radeon hd 6450 230","6450",0,[[1920,1080,15]]],["amd radeon hd 6470m","6470",0,[[1366,768,27],[1600,900,21]]],["amd radeon hd 6470m/7400m","6470",0,[[1366,768,44]]],["amd radeon hd 6480g","6480",0,[[1280,768,19],[1366,768,27],[1600,900,18]]],["amd radeon hd 6490m","6490",1,[[1366,768,-1],[1440,900,-1],[1680,1050,-1]]],["amd radeon hd 6500","6500",0,[[1920,1080,25]]],["amd radeon hd 6500m/5600","6500",0,[[1920,1080,27]]],["amd radeon hd 6510","6510",0,[[1600,900,32]]],["amd radeon hd 6520g","6520",0,[[1366,768,21],[1600,900,20]]],["amd radeon hd 6530d","6530",0,[[1366,768,31],[1440,900,36],[1920,1080,24]]],["amd radeon hd 6540","6540",0,[[1600,1200,13]]],["amd radeon hd 6550d","6550",0,[[1920,1080,28]]],["amd radeon hd 6570","6570",0,[[1920,1080,52],[2560,1440,17]]],["amd radeon hd 6620g","6620",0,[[1360,768,43],[1366,768,28]]],["amd radeon hd 6630m","6630",1,[[1366,768,-1],[1600,900,-1],[1920,1080,-1]]],["amd radeon hd 6630m/6650m/6750m/7670m/7690m","6630",1,[[1366,768,-1],[1920,1080,-1]]],["amd radeon hd 6650m","6650",0,[[1366,768,51],[1600,900,31]]],["amd radeon hd 6670","6670",0,[[1920,1080,55]]],["amd radeon hd 6700","6700",0,[[1920,1080,56]]],["amd radeon hd 6700 green","6700",0,[[1360,768,89]]],["amd radeon hd 6700m/7700m/7900m","6700",0,[[1366,768,59]]],["amd radeon hd 6730m/6770m","6730",0,[[1366,768,58],[1920,1080,46]]],["amd radeon hd 6730m/6770m/7690m xt","6730",0,[[1920,1080,48]]],["amd radeon hd 6750","6750",0,[[1440,900,72],[1920,1080,60]]],["amd radeon hd 6750m","6750",1,[[1440,900,-1],[1920,1080,-1],[1920,1200,-1]]],["amd radeon hd 6770","6770",0,[[1920,1080,60]]],["amd radeon hd 6770m","6770",1,[[1440,900,-1],[2560,1440,-1]]],["amd radeon hd 6770m opengl engine","6770",1,[[2560,1440,-1]]],["amd radeon hd 6790","6790",0,[[1920,1080,59]]],["amd radeon hd 6800","6800",0,[[1280,1024,89],[1920,1080,60]]],["amd radeon hd 6800m","6800",0,[[1600,900,18],[1920,1080,40]]],["amd radeon hd 6850","6850",0,[[1920,1080,59],[2560,1600,54]]],["amd radeon hd 6870","6870",0,[[1920,1080,60],[2560,1440,59]]],["amd radeon hd 6900","6900",0,[[1920,1080,60]]],["amd radeon hd 6900m","6900",0,[[1920,1080,60]]],["amd radeon hd 6950","6950",0,[[1680,1050,60],[1920,1080,41]]],["amd radeon hd 6970","6970",0,[[1920,1080,60]]],["amd radeon hd 6970m","6970",1,[[2560,1440,-1]]],["amd radeon hd 6970m opengl engine","6970",1,[[2560,1440,-1]]],["amd radeon hd 6990","6990",0,[[1920,1080,60]]],["amd radeon hd 7000","7000",0,[[1920,1080,24]]],["amd radeon hd 7290","7290",0,[[1366,768,9]]],["amd radeon hd 7310","7310",0,[[1366,768,14]]],["amd radeon hd 7340","7340",0,[[1366,768,17],[1920,1080,10]]],["amd radeon hd 7340g","7340",0,[[1366,768,15]]],["amd radeon hd 7340m","7340",0,[[1366,768,15]]],["amd radeon hd 7350","7350",0,[[1920,1080,13]]],["amd radeon hd 7400","7400",0,[[1920,1080,18]]],["amd radeon hd 7400g","7400",0,[[963,768,31]]],["amd radeon hd 7400m","7400",0,[[1366,768,44]]],["amd radeon hd 7420g","7420",0,[[1366,768,28],[1600,900,26]]],["amd radeon hd 7450","7450",0,[[1920,1080,15]]],["amd radeon hd 7450a","7450",0,[[1920,1080,15]]],["amd radeon hd 7450m","7450",0,[[1366,768,30]]],["amd radeon hd 7470","7470",0,[[1680,1050,22],[1920,1080,144]]],["amd radeon hd 7470m","7470",0,[[1366,768,31],[1600,900,23]]],["amd radeon hd 7480d","7480",0,[[1280,1024,25],[1920,1080,24],[1920,1200,18]]],["amd radeon hd 7500","7500",0,[[1366,696,49],[1366,768,49]]],["amd radeon hd 7500g","7500",0,[[1366,768,26]]],["amd radeon hd 7500m/7600m","7500",0,[[1366,768,46]]],["amd radeon hd 7520g","7520",0,[[1366,768,33]]],["amd radeon hd 7520g + hd 7400m dual","7520",0,[[1366,768,34]]],["amd radeon hd 7520g + hd 7600m dual","7520",0,[[1366,768,31],[1600,900,41]]],["amd radeon hd 7540d","7540",0,[[1024,768,55],[1280,1024,44],[1920,1080,22]]],["amd radeon hd 7540d + hd 6670 dual","7540",0,[[1280,1024,36]]],["amd radeon hd 7550m/7650m","7550",0,[[1366,768,57]]],["amd radeon hd 7560d","7560",0,[[1920,1080,34]]],["amd radeon hd 7560d + hd 6570 dual","7560",0,[[1680,1050,44]]],["amd radeon hd 7560d + hd 6670 dual","7560",0,[[800,638,60]]],["amd radeon hd 7570","7570",0,[[1024,768,72],[1920,1080,52]]],["amd radeon hd 7570m","7570",0,[[1366,768,35]]],["amd radeon hd 7570m/hd 7670m","7570",0,[[1366,768,50],[1600,900,29]]],["amd radeon hd 7600","7600",0,[[1920,1080,60]]],["amd radeon hd 7600a","7600",0,[[1920,1080,28]]],["amd radeon hd 7600g","7600",0,[[1366,768,29]]],["amd radeon hd 7600g + 7500m/7600m dual","7600",0,[[1366,768,19]]],["amd radeon hd 7600g + hd 8670m dual","7600",0,[[1366,768,29]]],["amd radeon hd 7600g + hd dual","7600",0,[[1366,768,20]]],["amd radeon hd 7600m","7600",0,[[1366,768,56]]],["amd radeon hd 7600m/7700m","7600",0,[[1366,768,31]]],["amd radeon hd 7610m","7610",0,[[1366,768,43]]],["amd radeon hd 7620g","7620",0,[[1366,768,22],[1920,1080,19]]],["amd radeon hd 7640g","7640",0,[[1366,768,38]]],["amd radeon hd 7640g + 7470m dual","7640",0,[[1366,768,32]]],["amd radeon hd 7640g + 7600m dual","7640",0,[[1366,768,23]]],["amd radeon hd 7640g + 7670m dual","7640",0,[[1600,900,15]]],["amd radeon hd 7640g + 8500m dual","7640",0,[[1366,768,35]]],["amd radeon hd 7640g + hd 7400m dual","7640",0,[[1366,768,37]]],["amd radeon hd 7640g + hd 7500 dual","7640",0,[[1366,768,35]]],["amd radeon hd 7640g + hd 7670m dual","7640",0,[[1366,768,34]]],["amd radeon hd 7640g + hd 8500m dual","7640",0,[[1366,768,40]]],["amd radeon hd 7640g + hd 8570m dual","7640",0,[[1366,768,31]]],["amd radeon hd 7650a","7650",0,[[1680,1050,43],[1920,1080,15]]],["amd radeon hd 7650m","7650",0,[[1366,768,41],[1600,900,45]]],["amd radeon hd 7660d","7660",0,[[1680,1050,40],[1920,1008,60],[1920,1080,38]]],["amd radeon hd 7660d + hd 6570 dual","7660",0,[[1200,900,32]]],["amd radeon hd 7660d + hd 6670 dual","7660",0,[[1360,768,57],[1920,1080,53]]],["amd radeon hd 7660g","7660",0,[[1366,768,44],[1600,900,41],[1920,1080,34],[1920,1200,27]]],["amd radeon hd 7660g + 7600m dual","7660",0,[[1366,768,53],[1600,900,45]]],["amd radeon hd 7660g + 7670m dual","7660",0,[[1366,768,52]]],["amd radeon hd 7660g + 8670m dual","7660",0,[[1600,900,46]]],["amd radeon hd 7660g + hd 7600m dual","7660",0,[[1366,768,50]]],["amd radeon hd 7660g + hd 7670m dual","7660",0,[[1366,768,35]]],["amd radeon hd 7660g + hd 8600m dual","7660",0,[[1600,900,29]]],["amd radeon hd 7670","7670",0,[[1920,1080,39]]],["amd radeon hd 7670m","7670",0,[[1366,768,49],[1920,1080,36]]],["amd radeon hd 7700","7700",0,[[1400,1050,45],[1920,1080,60]]],["amd radeon hd 7700m","7700",0,[[1920,1080,54]]],["amd radeon hd 7730m","7730",0,[[1920,1080,57]]],["amd radeon hd 7750","7750",0,[[1280,1024,60],[1600,900,60],[1400,1050,98],[1920,1080,60],[3840,2160,23]]],["amd radeon hd 7750 / r7 250e","7750",0,[[2560,1080,69]]],["amd radeon hd 7750m","7750",0,[[1680,1050,57]]],["amd radeon hd 7770","7770",0,[[1920,1080,60]]],["amd radeon hd 7770 / r7 250x","7770",0,[[1680,1050,78]]],["amd radeon hd 7770 ghz","7770",0,[[1920,1080,78]]],["amd radeon hd 7790","7790",0,[[1920,1080,16]]],["amd radeon hd 7790 / r7 360 / r9 260/360","7790",0,[[1280,1024,131]]],["amd radeon hd 7800","7800",0,[[1920,1080,60]]],["amd radeon hd 7800m","7800",0,[[1920,1080,57]]],["amd radeon hd 7850","7850",0,[[1920,1080,60]]],["amd radeon hd 7850 / r7 265 / r9 270 1024sp","7850",0,[[1280,1024,87]]],["amd radeon hd 7870","7870",0,[[1920,1080,120],[2560,1440,60],[2560,1600,114],[3840,2160,30]]],["amd radeon hd 7870 ghz","7870",0,[[1920,1080,75]]],["amd radeon hd 7870 xt","7870",0,[[1920,1080,57],[3840,2160,53]]],["amd radeon hd 7870m","7870",0,[[1920,1080,22],[2732,1536,40]]],["amd radeon hd 7900","7900",0,[[2560,1600,59]]],["amd radeon hd 7950","7950",0,[[1920,1080,50]]],["amd radeon hd 7950 / r9 280","7950",0,[[1920,1080,59]]],["amd radeon hd 7950 oem / r9 280","7950",0,[[1920,1080,60]]],["amd radeon hd 7970","7970",0,[[1920,1080,60]]],["amd radeon hd 7970 / r9 280x","7970",0,[[1920,1080,193]]],["amd radeon hd 7970m","7970",0,[[1366,768,60],[1920,1080,60]]],["amd radeon hd 7970x/8970 280x","7970",0,[[1920,1080,60]]],["amd radeon hd 7990","7990",0,[[1920,1080,60],[5120,2880,63]]],["amd radeon hd 7xxx","7",0,[[1920,1080,60]]],["amd radeon hd 8180","8180",0,[[1366,768,10]]],["amd radeon hd 8200 / r3","8200",0,[[1366,768,21],[1600,900,13],[1680,1050,13]]],["amd radeon hd 8210","8210",0,[[1366,768,18]]],["amd radeon hd 8240","8240",0,[[1600,900,17]]],["amd radeon hd 8240 / r3","8240",0,[[1366,768,14]]],["amd radeon hd 8250","8250",0,[[1366,768,14],[1920,1200,10]]],["amd radeon hd 8280","8280",0,[[1600,900,60]]],["amd radeon hd 8280 / r3","8280",0,[[1366,768,22]]],["amd radeon hd 8280e","8280",0,[[2880,1620,6]]],["amd radeon hd 8330","8330",0,[[1366,768,24]]],["amd radeon hd 8350","8350",0,[[1920,1080,57]]],["amd radeon hd 8350g","8350",0,[[1366,768,18]]],["amd radeon hd 8370d","8370",0,[[1366,768,60],[1280,1024,26],[1920,1080,22]]],["amd radeon hd 8400","8400",0,[[1366,768,30],[1920,1080,16]]],["amd radeon hd 8400 / r3","8400",0,[[1360,768,19],[1366,768,22],[1920,1080,12]]],["amd radeon hd 8400e","8400",0,[[1680,1050,17],[1920,1080,16],[1920,1200,14]]],["amd radeon hd 8410g","8410",0,[[1366,768,32]]],["amd radeon hd 8450g","8450",0,[[1366,768,23]]],["amd radeon hd 8450g + hd 8750m dual","8450",0,[[1366,768,21]]],["amd radeon hd 8470","8470",0,[[1920,1080,17]]],["amd radeon hd 8470 + 7660d dual","8470",0,[[1920,1080,60]]],["amd radeon hd 8470d","8470",0,[[1280,1024,44],[1920,1080,21]]],["amd radeon hd 8470d + hd 6450 dual","8470",0,[[1600,900,37]]],["amd radeon hd 8490","8490",0,[[1920,1080,18],[1920,1200,20]]],["amd radeon hd 8500m","8500",0,[[1366,768,41],[1920,1080,19]]],["amd radeon hd 8500m/8700m","8500",0,[[1920,1080,30]]],["amd radeon hd 8510g","8510",0,[[1366,768,29],[1920,1080,17]]],["amd radeon hd 8550","8550",0,[[1920,1080,25]]],["amd radeon hd 8550g","8550",0,[[1366,768,34],[1600,900,41],[1920,1080,34]]],["amd radeon hd 8550g + 8500m dual","8550",0,[[1366,768,42]]],["amd radeon hd 8550g + 8600 dual","8550",0,[[1920,1080,27]]],["amd radeon hd 8550g + hd 8570m dual","8550",0,[[1366,768,32]]],["amd radeon hd 8550g + hd 8600 dual","8550",0,[[1366,768,60]]],["amd radeon hd 8550g + hd 8750m dual","8550",0,[[1366,768,37]]],["amd radeon hd 8550g + r5 m230 dual","8550",0,[[1366,768,29]]],["amd radeon hd 8570","8570",0,[[1280,1024,60],[1680,1050,54],[1920,1080,50]]],["amd radeon hd 8570 / r5 430 / r7 240 / radeon 520","8570",0,[[1920,1080,25]]],["amd radeon hd 8570d","8570",0,[[1920,1080,16]]],["amd radeon hd 8570d + r7 240 dual","8570",0,[[1920,1080,45]]],["amd radeon hd 8570m","8570",0,[[1366,768,40]]],["amd radeon hd 8600","8600",0,[[1366,768,41]]],["amd radeon hd 8600m","8600",0,[[1366,768,42],[1920,1080,14]]],["amd radeon hd 8610g","8610",0,[[1366,768,31],[1920,1080,16]]],["amd radeon hd 8610g + 8600m dual","8610",0,[[1366,768,22]]],["amd radeon hd 8610g + hd 8600m dual","8610",0,[[1366,768,41]]],["amd radeon hd 8610g + hd 8670m dual","8610",0,[[1366,768,33]]],["amd radeon hd 8650g","8650",0,[[1360,768,44],[1366,768,44]]],["amd radeon hd 8650g + 8500m dual","8650",0,[[1366,768,35]]],["amd radeon hd 8650g + 8600 dual","8650",0,[[1920,1080,38]]],["amd radeon hd 8650g + 8600m dual","8650",0,[[1366,768,21]]],["amd radeon hd 8650g + 8670m dual","8650",0,[[1366,768,66]]],["amd radeon hd 8650g + 8750m dual","8650",0,[[1920,1080,28]]],["amd radeon hd 8650g + hd 7600m dual","8650",0,[[1366,768,36]]],["amd radeon hd 8650g + hd 8500m dual","8650",0,[[1366,768,23]]],["amd radeon hd 8650g + hd 8570m dual","8650",0,[[1366,768,36]]],["amd radeon hd 8650g + hd 8600m dual","8650",0,[[1366,768,46],[1600,900,29]]],["amd radeon hd 8650g + hd 8750m dual","8650",0,[[1366,768,36]]],["amd radeon hd 8650g + r5 m200 dual","8650",0,[[1366,768,35]]],["amd radeon hd 8670 / r7 250","8670",0,[[1024,768,1]]],["amd radeon hd 8670a/8670m/8690m","8670",0,[[1366,768,47]]],["amd radeon hd 8670a/8670m/8750m","8670",0,[[1366,768,60]]],["amd radeon hd 8670d","8670",0,[[1024,768,45],[1280,1024,69],[1920,1080,38]]],["amd radeon hd 8670d + 7700 dual","8670",0,[[1680,1050,58]]],["amd radeon hd 8670d + hd 6670 dual","8670",0,[[1680,1050,33]]],["amd radeon hd 8670d + r5 200 dual","8670",0,[[2560,1080,14]]],["amd radeon hd 8670d + r7 200 dual","8670",0,[[1920,1080,37]]],["amd radeon hd 8670m","8670",0,[[1366,768,41]]],["amd radeon hd 8690a","8690",0,[[1920,1080,31]]],["amd radeon hd 8690m","8690",0,[[1600,900,35]]],["amd radeon hd 8700m","8700",0,[[1366,768,60]]],["amd radeon hd 8730m","8730",0,[[1366,768,59]]],["amd radeon hd 8750m","8750",0,[[1366,768,60]]],["amd radeon hd 8770","8770",0,[[1920,1080,111]]],["amd radeon hd 8790m","8790",0,[[1600,900,78],[1920,1080,60]]],["amd radeon hd 8800m","8800",0,[[1920,1080,60],[2880,1800,45]]],["amd radeon hd 8830m","8830",0,[[1920,1080,82]]],["amd radeon hd 8850m","8850",0,[[1366,768,45]]],["amd radeon hd 8870m","8870",0,[[1280,1024,60],[1600,900,60]]],["amd radeon hd 8950","8950",0,[[1920,1080,60],[1920,1200,59]]],["amd radeon hd 8970","8970",0,[[2560,1600,60]]],["amd radeon hd 8970m","8970",0,[[1920,1080,146],[1920,1200,60]]],["amd radeon hd 8xxx","8",0,[[1920,1080,120],[2560,1440,58]]],["amd radeon hd5450","5450",0,[[1280,720,24]]],["amd radeon hd6870","6870",0,[[1920,1080,60]]],["amd radeon hd7970m","7970",0,[[2560,1440,116]]],["amd radeon hd8530m","8530",0,[[1366,768,40]]],["amd radeon hd8730","8730",0,[[1680,1050,42]]],["amd radeon hd8970m","8970",0,[[1920,1080,74]]],["amd radeon hybrid","",0,[[1366,768,27]]],["amd radeon infoshock rx 460","460",0,[[1360,768,102]]],["amd radeon instinct mi25","25",0,[[1920,1200,26]]],["amd radeon instinct mi25 mxgpu","25",0,[[1920,1080,20],[1920,1200,32]]],["amd radeon m535dx","535",0,[[1366,768,58]]],["amd radeon navi14","14",0,[[3840,2160,60]]],["amd radeon polaris","",0,[[3840,2160,60],[5120,2880,44]]],["amd radeon polaris 10","10",0,[[1920,1200,60]]],["amd radeon pro","pro",0,[[1920,1080,114]]],["amd radeon pro 270x","270",0,[[2560,1440,74]]],["amd radeon pro 450","450",0,[[1920,1080,30],[2880,1800,43],[3360,2100,36],[5120,2880,30]]],["amd radeon pro 450 opengl engine","450",0,[[1920,1200,60]]],["amd radeon pro 455","455",0,[[2879,1800,54],[2880,1800,48],[3360,2100,37]]],["amd radeon pro 455 opengl engine","455",0,[[3360,2100,36]]],["amd radeon pro 460","460",0,[[2880,1800,50],[3360,2100,42]]],["amd radeon pro 460 opengl engine","460",0,[[5760,3240,15]]],["amd radeon pro 470","470",0,[[6016,3384,49]]],["amd radeon pro 480","480",0,[[1920,1080,60]]],["amd radeon pro 5300","5300",0,[[5120,2880,60]]],["amd radeon pro 5300m","5300",0,[[1920,1080,214],[3584,2240,130]]],["amd radeon pro 5500 xt","5500",0,[[5120,2880,51]]],["amd radeon pro 5500m","5500",0,[[3072,1920,60],[3584,2240,139]]],["amd radeon pro 555","555",0,[[2879,1800,54],[2880,1800,36],[3360,2100,40]]],["amd radeon pro 555x","555",0,[[2880,1800,42],[3360,2100,39]]],["amd radeon pro 560","560",0,[[2879,1800,56],[2880,1800,56],[3360,2100,42]]],["amd radeon pro 5600m","5600",0,[[3072,1920,60],[3584,2240,60]]],["amd radeon pro 560x","560",0,[[2879,1800,59],[2880,1800,71],[3360,2100,43]]],["amd radeon pro 570","570",0,[[5120,2880,48]]],["amd radeon pro 570 opengl engine","570",0,[[5120,2880,46]]],["amd radeon pro 5700","5700",0,[[5120,2880,60]]],["amd radeon pro 5700 xt","5700",0,[[5120,2880,60]]],["amd radeon pro 570x","570",0,[[5120,2880,50]]],["amd radeon pro 575","575",0,[[4096,2304,60],[5120,2880,50]]],["amd radeon pro 575 opengl engine","575",0,[[5120,2880,48]]],["amd radeon pro 575x","575",0,[[5120,2880,56]]],["amd radeon pro 580","580",0,[[5120,2880,54]]],["amd radeon pro 580 opengl engine","580",0,[[5120,2880,50]]],["amd radeon pro 580x","580",0,[[5120,2880,52]]],["amd radeon pro duo","pro",0,[[1920,1080,234],[1800,1350,59],[3840,2160,82],[4096,2160,60]]],["amd radeon pro rx 560","560",0,[[2560,1080,60]]],["amd radeon pro ssg","pro",0,[[3440,1440,125]]],["amd radeon pro v340","340",0,[[1920,1080,112]]],["amd radeon pro v520 mxgpu","520",0,[[1920,1080,271]]],["amd radeon pro v7350x2","7350",0,[[1920,1080,60]]],["amd radeon pro vega 16","16",0,[[2879,1800,60],[3360,2100,60]]],["amd radeon pro vega 20","20",0,[[2880,1800,120],[3360,2100,121],[3840,2160,30]]],["amd radeon pro vega 48","48",0,[[5120,2880,86]]],["amd radeon pro vega 56","56",0,[[1920,1080,60],[5120,2880,60]]],["amd radeon pro vega 56 opengl engine","56",0,[[5120,2880,60]]],["amd radeon pro vega 64","64",0,[[5120,2880,60]]],["amd radeon pro vega 64 opengl engine","64",0,[[5120,2880,60]]],["amd radeon pro vega 64x","64",0,[[2560,1440,206],[4096,2304,60],[5120,2880,60]]],["amd radeon pro vega ii","proii",0,[[3840,1600,60],[5120,2880,60]]],["amd radeon pro vega ii duo","proii",0,[[2560,1440,239],[5120,2880,60]]],["amd radeon pro w5500","5500",0,[[1920,1080,195],[3840,2160,59],[7680,3240,56]]],["amd radeon pro w5500m","5500",0,[[1920,1080,60]]],["amd radeon pro w5500x","5500",0,[[1920,1200,60]]],["amd radeon pro w5700","5700",0,[[1680,1050,253],[5120,1440,120],[3840,2160,60]]],["amd radeon pro w5700x","5700",0,[[3840,2160,60]]],["amd radeon pro w6600","6600",0,[[1920,1200,60],[3840,2160,166]]],["amd radeon pro w6600m","6600",0,[[1920,1080,60]]],["amd radeon pro w6800","6800",0,[[1920,1080,60],[3840,2160,237]]],["amd radeon pro w6800x","6800",0,[[6016,3384,60]]],["amd radeon pro w6800x duo","6800",0,[[3840,1600,60],[5120,2880,45]]],["amd radeon pro w6900x","6900",0,[[3840,2160,60]]],["amd radeon pro wx","pro",0,[[2560,1080,69]]],["amd radeon pro wx 2100","2100",0,[[1280,1024,145],[1920,1080,60]]],["amd radeon pro wx 3100","3100",0,[[1919,1080,58],[1920,1080,123],[2560,1440,82]]],["amd radeon pro wx 3200","3200",0,[[2560,1440,92]]],["amd radeon pro wx 4100","4100",0,[[1920,1080,60],[1920,1200,60],[3840,2160,30],[5120,2880,18]]],["amd radeon pro wx 4130","4130",0,[[1920,1080,60],[3840,2160,30]]],["amd radeon pro wx 4150","4150",0,[[1920,1080,56],[3840,2160,37],[4096,2160,34]]],["amd radeon pro wx 5100","5100",0,[[1920,1080,60],[2560,1440,91],[3840,2160,55]]],["amd radeon pro wx 5100 opengl engine","5100",0,[[2560,1440,60]]],["amd radeon pro wx 7100","7100",0,[[1920,1080,122],[2560,1080,58],[3840,2160,60],[5120,2880,60]]],["amd radeon pro wx 7100 mobile","7100",0,[[2560,1440,60]]],["amd radeon pro wx 7100 opengl engine","7100",0,[[3840,2160,60]]],["amd radeon pro wx 8200","8200",0,[[3440,1440,124]]],["amd radeon pro wx 9100","9100",0,[[1920,1080,60],[4096,2160,101]]],["amd radeon pro wx 9100 opengl engine","9100",0,[[1920,1080,60]]],["amd radeon pro wx vega m gl","prom",0,[[3840,2160,14]]],["amd radeon pro wx3200","3200",0,[[1920,1080,55]]],["amd radeon pro wx9100","9100",0,[[2560,1440,60]]],["amd radeon r2","2",0,[[1366,768,13],[1600,900,14]]],["amd radeon r2e","2",0,[[1366,768,16],[1920,1080,45],[3840,2160,4]]],["amd radeon r3","3",0,[[1366,768,17],[1920,1080,15]]],["amd radeon r4","4",0,[[1366,768,19],[1920,1080,13]]],["amd radeon r4e","4",0,[[3840,2160,6]]],["amd radeon r5","5",0,[[1024,768,38],[1360,768,25],[1366,768,21],[1280,1024,33],[1920,1080,14],[3200,1800,7]]],["amd radeon r5 220","5",0,[[1366,768,19],[1920,1080,12]]],["amd radeon r5 230","5",0,[[1920,1080,21]]],["amd radeon r5 235","5",0,[[1920,1080,17]]],["amd radeon r5 240","5",0,[[1280,1024,34],[1920,1080,24]]],["amd radeon r5 340","5",0,[[1920,1080,27]]],["amd radeon r5 340x","5",0,[[1920,1080,31]]],["amd radeon r5 430","5",0,[[1280,1024,31],[1680,1050,54],[1920,1080,54]]],["amd radeon r5 435","5",0,[[1920,1080,30]]],["amd radeon r5 m200","5",0,[[1600,900,45],[1920,1080,20]]],["amd radeon r5 m200 / hd 8500m","5",0,[[1366,768,31],[1920,1080,24]]],["amd radeon r5 m230","5",0,[[1366,768,37]]],["amd radeon r5 m240","5",0,[[1366,768,42],[1920,1080,23]]],["amd radeon r5 m255","5",0,[[1366,768,59],[1600,900,33]]],["amd radeon r5 m315","5",0,[[1366,768,45]]],["amd radeon r5 m320","5",0,[[1920,1080,19]]],["amd radeon r5 m330","5",0,[[1366,768,27],[1920,1080,26]]],["amd radeon r5 m335","5",0,[[1366,768,55],[1920,1080,19]]],["amd radeon r5 m420","5",0,[[1366,768,49]]],["amd radeon r5 m430","5",0,[[1366,768,36],[1920,1080,20]]],["amd radeon r5 m435","5",0,[[1920,1080,41],[2560,1440,67]]],["amd radeon r5 m445","5",0,[[1920,1080,32]]],["amd radeon r5e","5",0,[[1600,768,14],[1920,1080,16]]],["amd radeon r6","6",0,[[1366,768,30],[1280,1024,23],[1920,1080,12]]],["amd radeon r6 m255dx","6",0,[[1366,768,25]]],["amd radeon r6 m340dx","6",0,[[1366,768,31],[1920,1080,15]]],["amd radeon r6e","6",0,[[3840,2160,5]]],["amd radeon r7","7",0,[[1366,768,35],[1280,1024,31],[1680,1050,39],[1920,1080,12],[1920,1200,16],[2560,1080,15],[2560,1440,21],[3840,2160,8]]],["amd radeon r7 200","7",0,[[1280,1024,45],[1920,1080,120]]],["amd radeon r7 200 series","7",0,[[1920,1080,43]]],["amd radeon r7 240","7",0,[[1920,1080,29]]],["amd radeon r7 240 + hd 8570d dual","7",0,[[1920,1080,43]]],["amd radeon r7 250","7",0,[[1920,1080,49]]],["amd radeon r7 250e","7",0,[[1920,1080,60]]],["amd radeon r7 250x","7",0,[[1920,1080,60]]],["amd radeon r7 260x","7",0,[[1920,1080,56]]],["amd radeon r7 260x/360","7",0,[[1920,1200,102]]],["amd radeon r7 350","7",0,[[1024,768,60],[1280,1024,79],[1920,1080,59]]],["amd radeon r7 350x","7",0,[[1920,1080,50]]],["amd radeon r7 360","7",0,[[1920,1048,60],[1920,1080,102]]],["amd radeon r7 360 / r9 360","7",0,[[1920,1080,60]]],["amd radeon r7 370","7",0,[[1600,900,60],[1920,1080,75]]],["amd radeon r7 370 / r9 270","7",0,[[1920,1080,74]]],["amd radeon r7 370 / r9 270x/370","7",0,[[1600,900,115],[1920,1080,60]]],["amd radeon r7 370 / r9 270x/370x","7",0,[[1920,1080,115]]],["amd radeon r7 370 series","7",0,[[1920,1080,212],[3840,2160,60]]],["amd radeon r7 430","7",0,[[1920,1080,55],[3840,2160,10]]],["amd radeon r7 450","7",0,[[1920,1080,60]]],["amd radeon r7 a360","7",0,[[1920,1080,28]]],["amd radeon r7 graphics + hd 7700 dual","7",0,[[1600,1200,72]]],["amd radeon r7 graphics + r5 340 dual","7",0,[[1920,1080,47]]],["amd radeon r7 graphics + r7 200 dual","7",0,[[1920,1080,45],[1920,1200,47]]],["amd radeon r7 graphics + r7 350 dual","7",0,[[1919,1080,60]]],["amd radeon r7 m260","7",0,[[1600,900,44],[1920,1080,13]]],["amd radeon r7 m260dx","7",0,[[1366,768,46],[1920,1080,18]]],["amd radeon r7 m260x","7",0,[[1920,1080,29]]],["amd radeon r7 m265","7",0,[[1366,768,48],[1920,1080,27]]],["amd radeon r7 m270","7",0,[[1920,1080,31],[3840,2160,10]]],["amd radeon r7 m340","7",0,[[1366,768,60],[1920,1080,32]]],["amd radeon r7 m350","7",0,[[3840,2160,12]]],["amd radeon r7 m360","7",0,[[1366,768,40],[1920,1080,22]]],["amd radeon r7 m370","7",0,[[1920,1080,24]]],["amd radeon r7 m440","7",0,[[1920,1080,39]]],["amd radeon r7 m445","7",0,[[1920,1080,36]]],["amd radeon r7 m460","7",0,[[1919,1080,24],[1920,1080,29]]],["amd radeon r7 m520","7",0,[[1919,1080,17]]],["amd radeon r7 series / hd 9000","7",0,[[1920,1080,71],[2560,1080,59]]],["amd radeon r7e","7",0,[[1024,768,41]]],["amd radeon r8 m350dx","8",0,[[1366,768,30]]],["amd radeon r8 m365dx","8",0,[[1920,1080,28]]],["amd radeon r8 m435dx","8",0,[[1920,1080,22]]],["amd radeon r8 m445dx","8",0,[[1366,768,38],[1920,1080,27]]],["amd radeon r8 m535dx","8",0,[[1366,768,55]]],["amd radeon r9","9",0,[[1920,1080,60]]],["amd radeon r9 200","9",0,[[1920,1080,60]]],["amd radeon r9 200 / hd 7900","9",0,[[1920,1080,250]]],["amd radeon r9 255","9",0,[[1600,900,52],[1920,1080,51]]],["amd radeon r9 260","9",0,[[1920,1080,16]]],["amd radeon r9 270","9",0,[[1280,1024,60],[1920,1080,60]]],["amd radeon r9 270 1024sp","9",0,[[1920,1080,135]]],["amd radeon r9 270x","9",0,[[1920,1080,30]]],["amd radeon r9 280","9",0,[[1920,1080,75],[1920,1200,428],[2560,1440,60]]],["amd radeon r9 280,","9",0,[[5120,2880,39]]],["amd radeon r9 280x","9",0,[[1920,1080,137]]],["amd radeon r9 285","9",0,[[1920,1080,60],[1920,1200,129]]],["amd radeon r9 290","9",0,[[1920,1080,60]]],["amd radeon r9 290x","9",0,[[1920,1080,60],[2560,1440,60],[3840,2160,118]]],["amd radeon r9 300","9",0,[[1920,1080,59]]],["amd radeon r9 350","9",0,[[1920,1200,63]]],["amd radeon r9 360","9",0,[[1600,900,83],[1920,1080,60],[2560,1440,59]]],["amd radeon r9 370","9",0,[[1680,1050,205],[1920,1080,60],[3840,2160,49]]],["amd radeon r9 370x","9",0,[[1920,1080,60]]],["amd radeon r9 380","9",0,[[1920,1080,41],[2560,1440,75]]],["amd radeon r9 380x","9",0,[[2560,1600,60]]],["amd radeon r9 390","9",0,[[1920,1080,60],[2560,1440,60]]],["amd radeon r9 390x","9",0,[[2560,1440,60],[3840,2160,60]]],["amd radeon r9 a375","9",0,[[1920,1080,28]]],["amd radeon r9 fury","9",0,[[1920,1080,75],[3840,2160,133]]],["amd radeon r9 fury / nano","9",0,[[1920,1200,155]]],["amd radeon r9 m200x","9",0,[[1366,768,104],[1920,1080,60]]],["amd radeon r9 m265x","9",0,[[1920,1080,33]]],["amd radeon r9 m270x","9",0,[[1600,900,60],[1920,1080,68]]],["amd radeon r9 m275","9",0,[[1920,1080,29]]],["amd radeon r9 m275x","9",0,[[1920,1080,20]]],["amd radeon r9 m280x","9",0,[[1920,1080,60],[2560,1440,25]]],["amd radeon r9 m290","9",0,[[5120,2880,33]]],["amd radeon r9 m290x","9",0,[[1920,1080,60],[3840,2160,61],[5120,2880,33]]],["amd radeon r9 m295x","9",0,[[3840,2160,33],[5120,2880,36]]],["amd radeon r9 m295x mac","9",0,[[5120,2880,42]]],["amd radeon r9 m295x mac edition / r9 380x","9",0,[[1920,1080,128]]],["amd radeon r9 m360","9",0,[[1920,1080,60],[3840,2160,26]]],["amd radeon r9 m370x","9",0,[[2560,1440,30],[2880,1800,27]]],["amd radeon r9 m370x opengl engine","9",0,[[5120,2880,14]]],["amd radeon r9 m375","9",0,[[1920,1080,29]]],["amd radeon r9 m375x","9",0,[[1920,1080,60],[3840,2160,22]]],["amd radeon r9 m380","9",0,[[1920,1080,50],[3840,2160,8],[5120,2880,9]]],["amd radeon r9 m380 opengl engine","9",0,[[5120,2880,15]]],["amd radeon r9 m385","9",0,[[1920,1080,58]]],["amd radeon r9 m385x","9",0,[[1920,1080,60]]],["amd radeon r9 m390","9",0,[[5119,2879,29],[5120,2880,21],[5760,3240,32]]],["amd radeon r9 m390 opengl engine","9",0,[[5120,2880,27]]],["amd radeon r9 m390x","9",0,[[1920,1080,140]]],["amd radeon r9 m395","9",0,[[2560,1440,59],[5120,2880,19]]],["amd radeon r9 m395 opengl engine","9",0,[[5120,2880,38]]],["amd radeon r9 m395x","9",0,[[3840,2160,58],[5120,2880,36]]],["amd radeon r9 m395x opengl engine","9",0,[[5120,2880,35]]],["amd radeon r9 m470","9",0,[[3840,2160,29]]],["amd radeon r9 m470x","9",0,[[1920,1080,60]]],["amd radeon r9-290x","9",0,[[1920,1080,60]]],["amd radeon renoir graphics d1","1",0,[[1366,768,60]]],["amd radeon rro 580x","580",0,[[5120,2880,59]]],["amd radeon rx 460","460",0,[[1920,1080,55],[2560,1080,60],[3840,2160,31]]],["amd radeon rx 460 / pro 450/455/460/555/555x/560/560x","460",0,[[3440,1440,93]]],["amd radeon rx 460 / pro 450/455/460/560","460",0,[[1920,1080,72]]],["amd radeon rx 470","470",0,[[1280,1024,73],[1920,1080,58],[1920,1200,147],[3840,2160,51]]],["amd radeon rx 470 opengl engine","470",0,[[2560,1440,60]]],["amd radeon rx 475m","475",0,[[1920,1080,60]]],["amd radeon rx 480","480",0,[[1400,1050,267],[1920,1080,60],[2560,1080,71]]],["amd radeon rx 480 opengl engine","480",0,[[1920,1080,60]]],["amd radeon rx 5300m","5300",0,[[1920,1080,60],[3840,2160,60]]],["amd radeon rx 540","540",0,[[1919,1080,52],[1920,1080,36]]],["amd radeon rx 550","550",0,[[1280,1024,135],[1920,1080,60],[1920,1200,60],[6016,3384,15]]],["amd radeon rx 550 640sp / rx 560","550",0,[[1920,1080,60]]],["amd radeon rx 5500","5500",0,[[1920,1080,139]]],["amd radeon rx 5500 / pro 5500m","5500",0,[[1920,1080,60],[2560,1440,227]]],["amd radeon rx 5500 xt","5500",0,[[1920,1080,239]]],["amd radeon rx 5500m","5500",0,[[1920,1048,144],[1920,1080,144],[3840,2160,60]]],["amd radeon rx 550x","550",0,[[1920,1080,52]]],["amd radeon rx 560","560",0,[[1920,1080,60],[1920,1200,42],[2560,1440,60]]],["amd radeon rx 560 [baffin]","560",0,[[1920,1080,60]]],["amd radeon rx 5600 oem/5600 xt / 5700 xt","5600",0,[[1920,1080,360],[2560,1440,164]]],["amd radeon rx 5600 xt","5600",0,[[1920,1080,75]]],["amd radeon rx 5600m","5600",0,[[1920,1080,144]]],["amd radeon rx 560d","560",0,[[2560,1080,60]]],["amd radeon rx 560x","560",0,[[1920,1080,115],[3840,2160,35]]],["amd radeon rx 570","570",0,[[1920,1080,60],[3072,1728,60]]],["amd radeon rx 570 opengl engine","570",0,[[1920,1080,226]]],["amd radeon rx 5700","5700",0,[[1920,1080,144]]],["amd radeon rx 5700 / 5700 xt","5700",0,[[3840,2160,201]]],["amd radeon rx 5700 xt","5700",0,[[1920,1080,464],[3840,2160,60],[6016,3384,34]]],["amd radeon rx 5700 xt 50th anniversary","5700",0,[[2560,1440,144],[3840,1600,60],[3840,2160,222],[5120,2880,60]]],["amd radeon rx 5700xt","5700",0,[[1920,1080,369]]],["amd radeon rx 580","580",0,[[1920,1080,60],[1920,1200,97],[2560,1440,60],[3840,2160,60]]],["amd radeon rx 580 2048sp","580",0,[[1920,1080,60]]],["amd radeon rx 580 opengl engine","580",0,[[1920,1080,145]]],["amd radeon rx 580 special","580",0,[[2560,1440,60]]],["amd radeon rx 580x","580",0,[[1920,1200,60],[3840,2160,79]]],["amd radeon rx 590","590",0,[[1920,1080,75],[2560,1440,164],[3584,2240,60]]],["amd radeon rx 640","640",0,[[1920,1080,39]]],["amd radeon rx 6500 xt","6500",0,[[1920,1080,60]]],["amd radeon rx 6600","6600",0,[[1920,1080,433],[3840,2160,57]]],["amd radeon rx 6600 xt","6600",0,[[1920,1080,60]]],["amd radeon rx 6600 xt/6600m","6600",0,[[2560,1440,60]]],["amd radeon rx 6600m","6600",0,[[1920,1080,139]]],["amd radeon rx 6700 xt","6700",0,[[1920,1080,451]]],["amd radeon rx 6700 xt / 6800m","6700",0,[[2560,1440,144]]],["amd radeon rx 6700m","6700",0,[[1920,1080,240]]],["amd radeon rx 6800","6800",0,[[2560,1440,564],[3840,2160,60]]],["amd radeon rx 6800 xt","6800",0,[[2560,1440,446],[3440,1440,144],[3840,2160,60]]],["amd radeon rx 6800 xt / 6900 xt","6800",0,[[2560,1440,239]]],["amd radeon rx 6800 xt 16gb","6800",0,[[6400,2666,60]]],["amd radeon rx 6800m","6800",0,[[1920,1080,300]]],["amd radeon rx 6900 xt","6900",0,[[3840,2160,60]]],["amd radeon rx rx 560","560",0,[[1920,1080,60]]],["amd radeon rx vega","rx",0,[[1920,1080,39]]],["amd radeon rx vega 10","10",0,[[1920,1080,38]]],["amd radeon rx vega 11","11",0,[[1920,1080,35]]],["amd radeon rx vega 56","56",0,[[1920,1080,144],[3440,1440,60],[3840,2160,60]]],["amd radeon rx vega 56 8gb","56",0,[[2560,1600,60]]],["amd radeon rx vega 56 opengl engine","56",0,[[2560,1440,60]]],["amd radeon rx vega 64","64",0,[[2560,1440,518]]],["amd radeon rx vega 64 8gb","64",0,[[2560,1440,60]]],["amd radeon rx vega 64 opengl engine","64",0,[[3840,2160,119]]],["amd radeon rx vega 64.1","64",0,[[6016,3384,60]]],["amd radeon rx vega 8","8",0,[[1920,1080,53]]],["amd radeon rx vega m gh","rxm",0,[[1920,1080,60],[2560,1440,60],[3840,2160,51]]],["amd radeon rx vega m gl","rxm",0,[[2560,1440,567],[3840,2160,59]]],["amd radeon rx vega11","11",0,[[2496,1664,30]]],["amd radeon rx460","460",0,[[1920,1080,60]]],["amd radeon rx480","480",0,[[1920,1080,102],[2560,1080,71]]],["amd radeon rx540","540",0,[[2400,1800,37]]],["amd radeon rx550","550",0,[[1920,1080,60]]],["amd radeon rx560","560",0,[[1920,1080,93]]],["amd radeon rx5600","5600",0,[[3840,2160,129]]],["amd radeon rx570","570",0,[[5120,2880,59]]],["amd radeon rx5700","5700",0,[[1920,1080,60]]],["amd radeon rx580","580",0,[[1920,1080,60]]],["amd radeon rx590 gme","590",0,[[1920,1080,112]]],["amd radeon rx6600xt","6600",0,[[3840,2160,60]]],["amd radeon sky 500","500",0,[[4096,2160,34]]],["amd radeon vega","",0,[[5120,2880,32]]],["amd radeon vega 10","10",0,[[1920,1080,44]]],["amd radeon vega 10 mobile","10",0,[[1920,1080,30]]],["amd radeon vega 11","11",0,[[1280,1024,60],[1920,1080,60],[3840,2160,17]]],["amd radeon vega 2","2",0,[[1366,768,30]]],["amd radeon vega 3","3",0,[[1440,900,44],[1920,1080,29],[3840,2160,8]]],["amd radeon vega 3 mobile","3",0,[[1920,1080,30]]],["amd radeon vega 56","56",0,[[2560,1440,144]]],["amd radeon vega 6","6",0,[[1366,768,61],[1920,1080,23]]],["amd radeon vega 64","64",0,[[6016,3384,35]]],["amd radeon vega 64 lc","64",0,[[2560,1080,60]]],["amd radeon vega 8","8",0,[[1920,1080,35],[2560,1440,24],[4096,2160,15]]],["amd radeon vega 8 mobile","8",0,[[1920,1080,36]]],["amd radeon vega 9","9",0,[[2496,1663,32],[2496,1664,39]]],["amd radeon vega fe","fe",0,[[1920,1080,120],[2560,1440,60]]],["amd radeon vega frontier","",0,[[1920,1080,120],[3840,2160,60]]],["amd radeon vega frontier edition opengl engine","",0,[[3440,1440,60]]],["amd radeon vega series / radeon vega mobile","",0,[[1920,1080,67]]],["amd radeon vii","vii",0,[[1920,1080,468],[2560,1440,60],[3840,2160,60]]],["amd radeont 540x","540",0,[[1920,1080,74],[3840,2160,22]]],["amd radeont rx 5300","5300",0,[[1920,1080,60]]],["amd radeont rx 5500m","5500",0,[[1920,1080,303]]],["amd radeont rx 560x","560",0,[[1920,1080,60]]],["amd saphire radeon rx 580","580",0,[[1920,1080,57]]],["amd sapphire radeon hd6870","6870",0,[[1680,1050,60]]],["amd sapphire radeon rx 560","560",0,[[1280,1024,60]]],["amd sapphire radeon rx vega 64 8gb","64",0,[[2560,1440,144]]],["intel radeon pro vega 16","16",0,[[3360,1890,20]]],["intel radeong 0.4 on amd bonaire","0",0,[[1920,1200,92]]],["intel radeong 0.4 on amd cape verde","0",0,[[1920,1200,73]]],["intel radeong 0.4 on amd polaris10","0",0,[[3840,2160,108]]],["intel radeong 0.4 on amd tonga","0",0,[[1920,1080,124]]],["radeon 500","500",0,[[1920,1080,58]]],["radeon 550","550",0,[[1920,1080,60]]],["radeon 550x","550",0,[[1920,1080,68]]],["radeon hd 7700","7700",0,[[1920,1080,60],[1920,1200,90]]],["radeon hd 7800","7800",0,[[1920,1080,60]]],["radeon hd 7900","7900",0,[[1920,1080,60],[1920,1200,60],[2560,1440,60]]],["radeon hd 8500","8500",0,[[1920,1080,42]]],["radeon hd 8790m","8790",0,[[1600,900,60]]],["radeon hd8800","8800",0,[[1920,1080,60]]],["radeon pro wx 5100 graphics (polaris10 / drm 3.27.0 / 4.19.4-1.el7.elrepo.x86_64, llvm 6.0","5100",0,[[1920,1080,60]]],["radeon pro wx3100","3100",0,[[2560,1440,1],[3840,2160,43]]],["radeon r5 340","5",0,[[1536,864,41]]],["radeon r5 m330","5",0,[[1366,768,38]]],["radeon r7 200","7",0,[[1280,1024,60],[2560,1440,52]]],["radeon r7 300","7",0,[[1920,1080,60]]],["radeon r7 m340","7",0,[[1920,1080,32]]],["radeon r7 m360","7",0,[[1920,1080,32]]],["radeon r9 200","9",0,[[1920,1080,60],[1920,1200,60],[2560,1440,1]]],["radeon r9 380","9",0,[[2560,1440,1]]],["radeon r9 390","9",0,[[1920,1080,60],[2560,1440,60]]],["radeon r9 fury","9",0,[[1920,1080,51],[1920,1920,60]]],["radeon rx","rx",0,[[1920,1200,60]]],["radeon rx 460","460",0,[[1920,1080,60],[1920,1200,60]]],["radeon rx 470","470",0,[[1280,768,60],[1680,1050,422],[1920,1080,60],[2560,1440,60]]],["radeon rx 480","480",0,[[1920,1080,60],[1920,1200,185],[2560,1440,1]]],["radeon rx 550","550",0,[[1600,900,60],[1680,1050,60],[1920,1080,1],[1920,1200,60],[2560,1080,60],[3840,2160,30]]],["radeon rx 5500 xt","5500",0,[[1920,1080,60],[1920,1200,60],[2560,1440,60],[3840,2160,19]]],["radeon rx 560","560",0,[[1600,900,60],[1920,1080,29],[1920,1200,47],[2688,1512,60],[3440,1440,60],[3840,2160,58]]],["radeon rx 5600 xt","5600",0,[[1920,1080,60]]],["radeon rx 570","570",0,[[1440,900,60],[1280,1024,60],[1920,1080,51],[1920,1200,60],[2560,1080,60],[2560,1440,37],[3440,1440,60]]],["radeon rx 5700 xt","5700",0,[[1707,960,60],[1920,1080,60],[2560,1440,55],[3840,2160,60]]],["radeon rx 580","580",0,[[1477,831,72],[1440,900,60],[1680,1050,60],[1920,1080,4],[1920,1200,60],[2560,1080,52],[2560,1440,60],[2560,1600,60],[3840,2160,1]]],["radeon rx 580 2048sp","580",0,[[1440,900,75]]],["radeon rx 590","590",0,[[1920,1080,60],[2560,1440,60],[3840,2160,30]]],["radeon rx vega","rx",0,[[1920,1080,60],[1920,1200,60],[2194,1234,60],[2560,1080,60],[2560,1440,60],[3440,1440,75],[3840,2160,60]]],["radeon rx vega 8","8",0,[[3840,2160,23]]],["radeon rx550","550",0,[[1680,1050,60],[1920,1080,60],[3440,1440,58]]],["radeon vega 8","8",0,[[1680,1050,60]]],["radeon vega frontier","",0,[[2560,1440,144]]],["radeon vii","vii",0,[[2560,1440,60],[3440,1440,60],[3840,2160,1]]],["radeong 0.4 on amd polaris10","0",0,[[3840,2160,109]]],["radeong 0.4 on amd tahiti","0",0,[[1920,1080,223]]],["ryzen embedded r1305g with radeon vega gfx","1305",0,[[3840,2160,14]]],["ryzen embedded v1605b with radeon vega gfx","1605",0,[[3840,2160,28]]]]')},921:e=>{"use strict";e.exports=JSON.parse('["4.0.8",["adreno 506","506",0,[[1512,720,18,"motorola moto g(7) play"]]],["adreno 530","530",0,[[2560,1140,27,"samsung galaxy s7 (sm-930x)"],[2392,1440,28,"google pixel xl"]]],["adreno 615","615",0,[[2088,1080,20,"google pixel 3a"]]],["adreno 618","618",0,[[2210,1080,34,"xiaomi mi 9t"]]],["adreno 620","620",0,[[2340,1080,42,"google pixel 5"]]],["adreno 630","630",0,[[2280,1080,58,"oneplus a6003"]]],["adreno 640","640",0,[[2280,1080,60,"google pixel 4"]]],["qualcomm adreno 205","205",0,[[1280,720,11,"coolpad 8675-w00 (adreno 205)"]]],["qualcomm adreno 304","304",0,[[480,320,16,"zte z353vl cymbal t"],[480,480,6,"lg watch sport"],[758,480,8,"kyocera kyf33 torque x01 s-max"],[782,480,8,"vodafone vfd 510"],[791,480,8,"acer t012"],[792,480,6,"lg k4 2017 (m151, m160, m150 phoenix 3, m153 fortune, m154 risio 2, l58vl rebel 2)"],[800,480,7,"chainway c4050-q4"],[854,480,6,"zte q302c"],[897,540,6,"kyocera c6742 hydro view"],[960,540,6,"cat s40"],[1024,552,6,"tcl 9007 pixi 3 (7)"],[1184,720,4,"micromax q4251 canvas juice a1"],[1187,720,4,"lg phoenix 2 (k37x)"],[1193,720,4,"lg x power (k210, k450)"],[1196,720,4,"obi sj2.5"],[1217,720,4,"fibo la0920"],[1224,720,4,"umax visionbook p70 lte"],[1280,720,4,"k-touch beeline fast +"],[1280,736,4,"alcatel 9022x one touch pixi 3 8.0"],[1280,752,4,"lenovo tab 10 (x103f)"]]],["qualcomm adreno 305","305",0,[[432,320,18,"sonim xp6700"],[480,320,16,"lg t480s wine smart 3g"],[400,400,0,"huawei watch"],[734,480,7,"lg l fino (d290, d295)"],[737,480,7,"acer liquid z220"],[790,480,8,"htc desire 510 (adreno 305)"],[791,480,7,"sony xperia m (c19xx, c20xx)"],[800,480,5,"cherry mobile q510"],[854,480,6,"alcatel a564c one touch pop icon"],[886,540,7,"lg g2 mini (d610, d618, d620)"],[896,540,7,"htc desire 610"],[897,540,5,"motorola xt830c moto e"],[960,540,4,"huawei c8817l"],[1024,528,5,"aurora au701"],[1024,552,4,"asus zenfone go 6.9 (l001 zb690kg)"],[982,600,4,"huawei mediapad 7 youth 2"],[1024,600,7,"samsung galaxy tab 3 7.0 (sm-t215, sm-t217)"],[1024,720,4,"ereneben eben a2"],[1024,722,5,"prestigio pmt5287 multipad ranger 8.0 4g"],[1280,648,5,"tomtom bridge"],[1184,720,5,"htc desire 650 (d650)"],[1188,720,4,"lg aka (h778, h788, f520x)"],[1196,720,3,"zte z787"],[1200,720,4,"lg g vista (d631, vs880, gx2 f430)"],[1216,720,4,"vodafone smart 4 max"],[1217,720,4,"kyocera e6790 duraforce xd"],[1220,720,4,"huawei ascend mate 2 mt2-l03"],[1196,768,4,"infocus m2"],[1280,720,3,"zuum p47"],[1280,732,4,"lg g pad 7.0 (uk410, v410, vk410)"],[1280,736,4,"zte amazing p6"],[1280,737,4,"asus memo pad hd 7 (k00s me175kg)"],[1280,739,4,"lg g pad 8.0 (v480, v49x, p490, t01)"],[1280,740,4,"qualcomm msm8926 (adreno 305, development board)"],[1280,752,4,"asus padfone e (t008 a68m)"],[1216,800,3,"huawei mediapad t1 8.0 (adreno 305)"],[1280,800,3,"samsung tn10gedlte"],[1920,1080,2,"zte s2002 star 1"],[1920,1128,2,"lenovo b8080"]]],["qualcomm adreno 306","306",0,[[734,480,9,"lg f60 (d390, d392)"],[790,480,8,"htc desire 510 (adreno 306)"],[791,480,5,"lg l21g destiny"],[800,480,8,"covia fleaz cp-l42a pop"],[854,480,8,"freetel ft151a priori2 lte"],[897,540,7,"kyocera c6740 hydro wave"],[960,540,5,"blu studio mini lte 2"],[1024,552,6,"tcl 9006w"],[1024,600,5,"samsung sm-t116ir (adreno 306)"],[1024,720,5,"ereneben eben k8s"],[1024,768,5,"samsung sm-p350 galaxy tab a plus"],[1184,720,4,"lg x screen (k500, f650)"],[1188,720,4,"lg band play (f570s)"],[1196,720,4,"fly a5042"],[1199,720,4,"lg stylus 2 (f720, k520, k540, ls775 g stylo 2, l82vl)"],[1200,720,4,"lg g4 stylus (h63x, ms631, f560, ls770 g stylo)"],[1208,720,4,"vizio xr6m10 tablet remote"],[1217,720,4,"lenovo pb1-750x phab"],[1224,720,4,"c spire ft7"],[1280,720,3,"bgh joy smart axs ii"],[1280,736,4,"vodafone smart tab 4g"],[1280,752,4,"huawei mediapad t1 10 (t1-a21)"],[1216,800,4,"huawei mediapad t1 8.0 pro, lte (adreno 306)"],[1280,800,4,"samsung galaxy tab e 8.0 (adreno 306, sm-t377p)"],[1794,1080,2,"bluebird sf550"],[1815,1080,2,"vizio xr6"],[1920,1080,2,"longcheer cc01"]]],["qualcomm adreno 308","308",0,[[800,480,13,"samsung galaxy folder 2 (sm-g160x)"],[854,480,12,"coolpad 3632"],[960,540,10,"samsung sm-j250g"],[1184,720,5,"infocus 00ww"],[1187,720,6,"lg m200"],[1193,720,6,"lg k20 plus (mp260, k20 v vs501)"],[1195,720,6,"lg x charge (x power 2, m322, l63bl fiesta)"],[1199,720,6,"lg stylo 3 (l83bl)"],[1280,720,6,"hisense f23"],[1280,736,6,"lenovo tb-8504"],[1280,752,6,"lenovo tb-x304"],[1344,720,6,"wiko view"],[1223,800,6,"huawei mediapad t3 8.0 (kob-xxx)"],[1368,720,6,"casper via g1"],[1280,800,6,"samsung galaxy tab a2 s (sm-t380, sm-t385)"]]],["qualcomm adreno 320","320",0,[[1196,720,11,"pantech im-a850 vega r3"],[1196,768,10,"google nexus 4 (lg e960)"],[1280,720,8,"blackberry z30"],[1280,752,8,"asus memo pad 10 (k01e me103k)"],[1280,768,10,"lg optimus g (e97x, ls970, e987, f180, kddi lgl21)"],[1920,1008,5,"technicolor px36"],[1794,1080,5,"sony xperia z (c66xx, so-02e, l36x)"],[1848,1080,5,"pantech im-a860 vega n6"],[1920,1080,5,"zte nubia z5 (nx501, nx50x)"],[1920,1104,5,"google nexus 7 (2nd gen, razor)"],[1920,1114,4,"lg g pad 8.3 (vk810 4g)"],[1920,1128,5,"sony xperia tablet z (sgp3xx, so-03e)"]]],["qualcomm adreno 330","330",0,[[800,480,18,"samsung sm-w2014"],[1184,720,27,"sony so-04g xperia a4"],[1196,720,21,"sony xperia j1 compact (d5788)"],[1202,720,21,"lg g flex (d95x, ls995, lgl23, f340)"],[1280,720,20,"amazon fire phone (sd4930ur)"],[1280,768,21,"samsung sm-w2015 galaxy golden 2"],[1280,960,14,"lg f300 optimus vu 3"],[1600,1152,15,"hp pro slate 12"],[1440,1308,10,"blackberry passport"],[1776,1080,11,"google nexus 5"],[1788,1080,11,"lg g3 a f410"],[1794,1080,10,"fujitsu f-01f arrows nx luge (docomo)"],[1803,1080,11,"lg g pro 2 (d838, f350)"],[1836,1080,11,"sony xperia z ultra (c68xx, xl39h, sol24, sgp412)"],[1920,1080,9,"qualcomm quanta is7"],[1920,1104,12,"ntt docomo sh-06f sharp aquos pad"],[1920,1128,12,"sony xperia z2 tablet (sgp5xx, so-05f, sot21)"],[1920,1129,10,"lg g pad ii (v935, v940 prada 3.0, v930 g pad x 10.1, uk932)"],[1920,1200,9,"amazon kindle fire hdx 7 (3rd gen, kfthwa, kfthwi)"],[2048,1440,8,"hp red"],[2392,1440,8,"fujitsu f-02g arrows nx (docomo)"],[2400,1440,6,"iuni u3"],[2560,1440,7,"vivo x520l xplay 3s"],[2560,1504,7,"ntt docomo f-03g (fujitsu arrows tab)"],[2560,1600,5,"samsung sm-t525 galaxy tab pro 10.1"]]],["qualcomm adreno 405","405",0,[[1184,720,13,"lyf ls-5015 water 8"],[1196,720,10,"alcatel 6044 one touch pop up"],[1200,720,12,"oppo a53"],[1280,720,8,"hisense c1"],[1280,736,10,"asus zenpad 8 (adreno 405, p024 z380kl)"],[1776,1080,7,"lyf ls-5505"],[1794,1080,6,"medion life x5020"],[1798,1080,7,"lg h740 g vista 2"],[1800,1080,6,"oppo r7s plus"],[1803,1080,6,"oppo r7 plus (adreno 405)"],[1812,1080,6,"ramos mos1"],[1824,1080,6,"vargo ivargo v210101"],[1836,1080,6,"lenovo pb1-770m everypad3"],[1920,1080,2,"smartisan yq607 jianguo"],[1920,1104,5,"lg vk815 g pad x8.3, p815l g pad ii 8.3"],[1920,1111,6,"lg g pad x 8.0 (v52x)"],[1794,1200,5,"qisda f80"],[1920,1128,5,"huawei mediapad t2 10.0 pro (fdr-xxx)"],[1830,1200,6,"huawei mediapad x3 (ple-xxx)"],[1836,1200,6,"huawei mediapad t2 8.0 pro (jdn-xxx)"]]],["qualcomm adreno 418","418",0,[[1280,768,28,"samsung sm-g9198"],[1776,1080,17,"sharp sh-m03 aquos mini"],[1794,1080,15,"softbank 502sh (sharp aquos xx2)"],[1920,1080,11,"smartisan t2 (sm801)"],[2368,1440,10,"fujitsu f-02h arrows nx (docomo)"],[2392,1440,10,"lg k600"],[2413,1440,10,"motorola moto x style, pure (xt1570, xt1572, xt1575)"],[2560,1440,9,"qiku q terra (8692-a00)"],[2560,1504,9,"ntt docomo f-04h arrows tab"]]],["qualcomm adreno 420","420",0,[[1280,720,32,"odg r7-w"],[1920,1080,20,"samsung galaxy s5 (adreno 420, sm-g901)"],[2392,1440,13,"lg g3 (adreno 420, f460)"],[2560,1352,7,"qualcomm apq8084 (adreno 420, development board)"],[2413,1440,12,"motorola moto x pro"],[2560,1440,8,"qualcomm liquid (adreno 420, windows, development board)"],[2560,1532,12,"samsung galaxy note edge (adreno 420, sm-n915x, scl24, sc-01g)"],[2560,1600,11,"amazon kindle fire hdx 8.9 (4th gen, kfsawa, kfsawi)"]]],["qualcomm adreno 430","430",0,[[1184,720,53,"sony xperia z5 compact (e58xx, so-02h)"],[1280,720,18,"zebra technologies mtp8994"],[1776,1080,29,"sony xperia z5 (e66xx, so-01h, sov32, 501so)"],[1794,1080,19,"vertu signature touch (2015)"],[1920,1080,9,"nokia rm-1106"],[1920,1104,21,"ntt docomo sh-05g sharp aquos pad"],[2392,1440,11,"sony e6508 vzw xperia z4v"],[2413,1440,17,"sirin labs solarin"],[2560,1440,7,"microsoft rm-1105"],[2560,1504,16,"sony xperia z4 tablet (sgp7xx, so-05g, sot31)"]]],["qualcomm adreno 505","505",0,[[728,480,29,"zebra technologies tc25"],[1184,720,15,"ivvi i3-01"],[1196,720,15,"huawei honor 6c (dig-xxx)"],[1199,720,14,"lg stylus 2 plus (ms550, k550)"],[1280,720,14,"xiaomi land"],[1344,720,14,"wiko view prime"],[1368,720,13,"micromax hs3"],[1776,1080,7,"hisense a2"],[1787,1080,7,"lg qua phone px (lgv33)"],[1794,1080,7,"pantech im-100 vega"],[1798,1080,8,"lg stylo 3 plus (tp450, mp450, m470)"],[1802,1080,7,"lg k11 (k530, k535)"],[1812,1080,7,"sugar f11"],[1920,1080,6,"lg x venture (h700, m710)"],[1920,1111,6,"lg g pad x ii 8.0 plus (v530)"],[2004,1080,7,"lg q6 (m700, x600)"],[1920,1128,7,"vodafone vfd 1400"],[1920,1132,7,"huawei mediapad t3 lite 10 (bah-xxx)"],[1839,1200,7,"huawei mediapad m3 lite 8.0 (cpn-xxx)"]]],["qualcomm adreno 506","506",0,[[1184,720,20,"fujitsu f-04j docomo"],[1280,720,20,"samsung galaxy j7 2017 (adreno 506, sm-j727x)"],[1320,720,18,"xiaomi redmi 5"],[1356,720,18,"vivo v7 plus (1716)"],[1620,1080,11,"blackberry bbb100-x (keyone, mercury)"],[1776,1080,10,"condor plume h1"],[1788,1080,10,"huawei nova (caz-xxx)"],[1794,1080,10,"nuans neo reloaded"],[1920,1080,9,"blackberry bbd100"],[1920,1104,9,"nec lavietab pc-ts508fam"],[1980,1080,10,"xiaomi redmi 5 plus"],[1920,1128,9,"zte k92 primetime"],[1920,1132,9,"vestel v tab 1090 lte"],[1920,1200,9,"i.safe is910.1"]]],["qualcomm adreno 508","508",0,[[1776,1080,15,"sonim xp8812"],[1798,1080,15,"sharp fs8010"],[1920,1080,14,"htc u11 life"],[2009,1080,14,"vestel venus z20"]]],["qualcomm adreno 509","509",0,[[2159,1080,15,"asus zenfone 5"]]],["qualcomm adreno 510","510",0,[[1184,720,31,"zebra technologies tc51"],[1208,800,27,"askey turbonet tn800a1 turbotab e1"],[1366,720,29,"sony xperia touch (g1109)"],[1776,1080,13,"agm x2"],[1794,1080,14,"qualcomm msm8952 (adreno 510, development board)"],[1920,1080,14,"coolpad r116 cool1"],[2048,1440,11,"asus zenpad 3 8.0 (p008 z581kl)"],[2160,1440,10,"jide remix pro"],[2048,1536,11,"asus zenpad z10 (p00i zt500kl)"],[2368,1440,10,"vodafone vfd 900"],[2392,1440,10,"sharp aquos z3 (fs8009)"],[2413,1440,9,"infocus m820"],[2560,1440,9,"vivo pd1522a"],[2560,1504,9,"lenovo yoga tab3 plus (yt-x703)"]]],["qualcomm adreno 512","512",0,[[782,480,59,"honeywell cn80"],[1798,1080,23,"sharp fs8016"],[1920,1080,22,"vivo td1608"],[2016,1080,22,"oppo r11s"],[2034,1080,22,"vivo x20a"],[2151,1080,20,"xiaomi redmi note 7"]]],["qualcomm adreno 530","530",0,[[1600,900,56,"keecker keecker"],[1776,1080,43,"softbank 506sh (sharp aquos phone xx3)"],[1794,1080,49,"google pixel"],[1920,1024,47,"contextmedia p-wal-107-elc-03"],[1920,1080,26,"nokia 6071w"],[2048,1536,35,"samsung galaxy tab s3 (sm-t82x)"],[2368,1440,27,"motorola xt1650 (1.8 ghz)"],[2392,1440,21,"lg q8 (h970, x800l)"],[2416,1440,31,"alcatel 6076s"],[2560,1439,17,"hp elite x3"],[2560,1440,4,"hp falcon"],[2672,1440,30,"lg g6 (g600, us997, ls993, vs988, h87x)"],[2880,1440,26,"baofeng ke-01"],[3840,2076,15,"via vt6093"]]],["qualcomm adreno 540","540",0,[[1184,720,61,"sony xperia xz1 compact (g8441)"],[1776,1080,57,"sony xperia xz1 (g834x, sov36, so-01k, 701so)"],[1794,1080,57,"google pixel 2 (walleye)"],[1920,1080,56,"zte nx595j nubia"],[1980,1080,56,"xiaomi mi mix 2"],[2034,1080,55,"oneplus 5t (a5010)"],[2276,1312,43,"essential ph-1"],[2368,1440,39,"sharp aquos r (sh-03j, shv39, 605sh)"],[2392,1440,41,"qualcomm adreno 540 (development board)"],[2416,1440,40,"razer phone"],[2560,1440,36,"htc u11 (u-3x, 2pzc100, 2pzc5, htv33, 601ht)"],[2678,1440,35,"samsung galaxy s8 active (sm-g892)"],[2768,1440,33,"samsung galaxy s8+ (adreno 540, sm-g955x, sc-03j, scv35)"],[2960,1440,33,"samsung galaxy note 8 (adreno 540, sm-n950, sc-01k, scv37)"]]],["qualcomm adreno 615","615",0,[[2560,1492,18,"samsung galaxy tab s5e sm-t720"]]],["qualcomm adreno 616","616",0,[[2047,1080,30,"meizu x8"]]],["qualcomm adreno 618","618",0,[[2183,1080,38,"samsung galaxy a71 (sm-a715f)"],[2274,1080,37,"samsung galaxy a80 sm-a805f"]]],["qualcomm adreno 630","630",0,[[2792,1440,49,"samsung galaxy s9+ (adreno 630, sm-g965)"]]],["qualcomm adreno 640","640",0,[[2020,1080,60,"samsung galaxy s10e (adreno 640, sm-g970x)"],[2064,1080,60,"samsung galaxy note 10 (adreno 640, sm-n970x)"],[2181,1080,60,"samsung galaxy s10 lite"],[2198,1080,60,"samsung galaxy a90 5g"],[2210,1080,79,"xiaomi redmi k20 pro premium edition"],[2048,1410,59,"samsung galaxy fold 5g (adreno 640, sm-f900x)"],[2723,1440,55,"samsung galaxy s10 (adreno 640, sm-g973x)"],[2730,1440,56,"samsung galaxy s10+ (adreno 640, sm-g975x)"],[2759,1440,56,"samsung galaxy note 10+ (adreno 640, sm-n975x)"],[2901,1440,55,"samsung galaxy s10 5g (adreno 640, sm-g977x)"]]],["qualcomm adreno 650","650",0,[[2274,1080,90,"asus zenfone 7"],[3101,1387,50,"samsung galaxy s20 ultra 5g (sm-g988u1)"]]]]')},535:e=>{"use strict";e.exports=JSON.parse('["4.0.8",["apple a10 gpu","10",0,[[2048,1536,41,"apple ipad (6th gen)"],[2160,1620,36,"apple ipad (10.2-inch) (7th generation)"]]],["apple a10x gpu","10",0,[[2048,1536,59,"apple ipad pro (10.5-inch)"],[2224,1668,69,"apple ipad pro (10.5-inch)"],[2732,2048,46,"apple ipad pro (12.9-inch, 2nd gen)"]]],["apple a12 gpu","12",0,[[2048,1536,60,"apple ipad mini (2019)"]]],["apple a12x gpu","12",0,[[2224,1668,116,"apple ipad pro (11-inch)"],[2388,1668,115,"apple ipad pro (11-inch)"],[2732,2048,60,"apple ipad pro (12.9-inch) (3rd generation)"]]],["apple a12z gpu","12",0,[[2388,1668,115,"apple ipad pro (11-inch) (2nd generation)"],[2732,2048,60,"apple ipad pro (12.9 inch) (4th generation)"]]],["apple a13 gpu","13",0,[[2160,1620,59,"apple ipad 9th gen"]]],["apple a14 gpu","14",0,[[2388,1668,52,"apple ipad air 4th gen (wi-fi only)"]]],["apple a15 gpu","15",0,[[2388,1668,60,"apple ipad mini (6th gen)"]]],["apple a7 gpu","7",0,[[2048,1536,10,"apple ipad mini 3"]]],["apple a8 gpu","8",0,[[2048,1536,16,"apple ipad mini 4"]]],["apple a8x gpu","8",0,[[2048,1536,30,"apple ipad air 2"]]],["apple a9 gpu","9",0,[[2048,1536,29,"apple ipad 9.7 (5th gen)"]]],["apple a9x gpu","9",0,[[2048,1536,40,"apple ipad pro 9.7"],[2732,2048,35,"apple ipad pro"]]],["apple m1 gpu","1",0,[[2732,2048,60,"apple ipad pro (12.9-inch) (5th generation)"]]]]')},438:e=>{"use strict";e.exports=JSON.parse('["4.0.8",["apple a10 gpu","10",0,[[1334,750,104,"apple iphone 7"],[1920,1080,60,"apple iphone 7 plus"],[2001,1125,59,"apple iphone x"]]],["apple a11 gpu","11",0,[[1334,750,64,"apple iphone 8"],[1920,1080,78,"apple iphone 8 plus"]]],["apple a12 gpu","12",0,[[1792,828,60,"apple iphone xr"],[2436,1125,57,"apple iphone xs"],[2208,1242,60,"apple iphone xs max"]]],["apple a13 gpu","13",0,[[1334,750,60,"apple iphone se (2nd gen)"],[1792,828,61,"apple iphone 11"],[2436,1125,60,"apple iphone 11 pro"],[2688,1242,61,"apple iphone 11 pro max"]]],["apple a14 gpu","14",0,[[2338,1080,60,"apple iphone 12 mini"],[2436,1125,60,"apple iphone 12"],[2778,1284,60,"apple iphone 12 pro max"]]],["apple a15 gpu","15",0,[[2338,1080,60,"apple iphone 13 mini"],[2436,1125,60,"apple iphone 13 pro"],[2688,1242,60,"apple iphone 13 pro max"]]],["apple a7 gpu","7",0,[[1136,640,32,"apple iphone 5s"]]],["apple a8 gpu","8",0,[[1136,640,40,"apple ipod touch 6"],[1334,750,36,"apple iphone 6"],[1920,1080,21,"apple iphone 6 plus"]]],["apple a9 gpu","9",0,[[1136,640,90,"apple iphone se"],[1334,750,72,"apple iphone 6s"],[1920,1080,42,"apple iphone 6s plus"]]]]')},283:e=>{"use strict";e.exports=JSON.parse('["4.0.8",["intel intel hd graphics for atom x5","5",0,[[1024,600,35,"amazon aeokn"],[1024,720,13,"arbor venus 8"],[1217,720,23,"gole gole1"],[1280,736,27,"medion p850x"],[1360,704,15,"chuwi hibox hero mini pc"],[1280,752,21,"tetratab casebook 3"],[1280,759,28,"lenovo yoga a12 (yb-q501f)"],[1366,720,19,"nextbook nx16a11264 ares 11 (x5-z8300)"],[1920,996,20,"teclast x16 pro"],[1920,1008,12,"teclast tbook 16 pro"],[1920,1016,13,"teclast x16 plus"],[1920,1104,13,"medion p851x"],[1920,1116,13,"teclast x80 pro (x5-z8350)"],[1920,1128,8,"cube technology i12-y"],[1920,1133,9,"cube technology i1-tfp (x5-z8350)"],[1920,1134,11,"microtech e-tab pro lte"],[1920,1136,14,"cube technology iwork 10 ultimate (i15-t)"],[1920,1214,10,"chuwi cw-hi10 plus (x5-z8350)"],[2048,1440,8,"teclast x98 plus"],[2160,1368,10,"chuwi hi12 (x5-z8350)"],[2048,1452,10,"teclast x98 plus ii"],[2048,1536,14,"xiaomi mi pad 2"],[2560,1356,7,"baofeng a1"],[2560,1504,6,"chuwi hibook pro (z8350)"],[2560,1518,11,"lenovo yt3-x90 yoga tablet 3 pro (x5-z8550)"]]],["intel intel hd graphics for baytrail","hdfor",0,[[1024,552,13,"multilaser intel 7qc"],[1024,696,17,"thundersoft dual os tablet"],[1024,720,15,"airis onepad 785i"],[1184,720,18,"trimble tdc500"],[1280,736,12,"acer a1-840"],[1280,752,9,"imuz mupad win 10.1 ii"],[1366,720,13,"nextbook nxa116qc164"],[1366,724,10,"cube technology i10 remix"],[1440,1008,12,"teclast x89 kindow"],[1920,1008,8,"minix neo z64"],[1920,1014,9,"cube technology i7 cx remix"],[1920,1032,11,"hp slate 17"],[1920,1104,5,"jltd d630"],[1920,1128,6,"intel(r) e1008"],[1920,1133,9,"pipo w3f"],[2048,1440,6,"kruger & matz eagle 975 (km0975)"],[2048,1448,6,"jide e-tab 3g"],[2048,1464,6,"reeder a10ix air"],[2560,1344,7,"lenovo yoga tablet 2 pro-1380"],[2560,1504,5,"teclast x10hd 3g"]]],["intel mesa dri intel bay trail","dribay",0,[[1366,768,15,"google chromebook pixel (2015, n2830)"]]],["intel mesa dri intel hd","drihd",0,[[688,412,39,"hp chromebook x360 11 g1 ee"],[960,568,36,"google chromebook pixel (2015, n3450)"],[1024,561,28,"aaeon up-cht01 up board"],[1024,736,33,"google chromebook reef (n3350)"]]],["intel mesa dri intel hd graphics 400","400",0,[[688,412,41,"asus c202sa chromebook"],[768,431,45,"hp chromebook 11 g5"],[960,568,25,"acer chromebook r11 (n3050)"],[1366,768,19,"samsung chromebook 3"],[1536,832,25,"google chromebook r11 (n3160)"],[1920,1080,17,"acer chromebook 14"]]],["intel mesa dri intel hd graphics 510","510",0,[[690,378,53,"hp chromebook chell"],[688,412,60,"acer chromebook 14 for work"]]],["intel mesa dri intel hd graphics 515","515",0,[[1033,617,56,"samsung chromebook pro (m7-6y75, caroline)"],[1536,1088,32,"google chromebook pixel (2015, m3-6y30)"],[1920,980,32,"asus c302 chromebook flip"],[2400,1504,22,"samsung chromebook pro (caroline)"],[3200,1640,12,"google chromebook pixel (2015, 4405y)"]]],["intel mesa dri intel hd graphics 520","520",0,[[700,412,60,"acer chromebook 14 for work (i3-6100u)"]]],["intel mesa dri intel hd graphics 5500","5500",0,[[1080,575,59,"google chromebook pixel (2015, i3-5005u)"],[1920,1000,30,"google chromebook pixel (2015, i5-5300u)"],[2560,1700,14,"google chromebook pixel (2015, i5-5200u)"]]],["intel mesa dri intel hd graphics 615","615",0,[[1034,618,55,"google soraka (4415y)"],[1200,720,34,"google poppy (4410y, kabylake)"],[2400,1504,21,"google chromebook eve (i5-7y54)"]]],["intel mesa dri intel kabylake gt2","2",0,[[960,568,38,"google chromebook pixel (2015, m3-7y30)"]]]]')},327:e=>{"use strict";e.exports=JSON.parse('["4.0.8",["arm mali-t604 mp4","604",0,[[2560,1504,4,"google nexus 10"]]],["arm mali-t622","622",0,[[1024,564,12,"telechips tcc896x (quad core, development board)"],[1280,720,7,"leadcore l1860 (mali-t622, development board)"]]],["arm mali-t624","624",0,[[1794,1080,7,"huawei grace"],[1812,1080,6,"huawei abc-ul00"],[1830,1080,10,"huawei p8 max (dav-70x)"],[1920,1080,4,"sony amai vp9"],[1920,1104,9,"huawei dtab compact d-02h (docomo)"],[1920,1128,8,"huawei dtab d-01h (docomo)"],[1824,1200,9,"huawei mediapad m2 (m2-80xx)"],[1830,1200,9,"huawei mediapad x2 (gem-701l, gem-702l, gem-703l)"]]],["arm mali-t624 mp2","624",0,[[1280,720,5,"samsung sm-g910f (mali-t624)"]]],["arm mali-t624 mp4","624",0,[[1794,1080,9,"huawei z100"]]],["arm mali-t628","628",0,[[1024,600,30,"thinkware inavi davinci"],[2560,1536,8,"meizu mx4 pro"]]],["arm mali-t628 mp2","628",0,[[1280,720,8,"leadcore l1860 (development board)"]]],["arm mali-t628 mp6","628",0,[[800,480,35,"gen2wave rp1600"],[1280,672,14,"hardkernel odroid-xu3 (development board)"],[1280,720,26,"samsung galaxy alpha (mali-t628, sm-g850)"],[1920,1080,11,"samsung galaxy note iii (mali-t628, sm-n900, sm-n9000q)"],[2560,1600,3,"samsung sm-t520 galaxy tab 10.1"]]],["arm mali-t720","720",0,[[432,240,16,"unihertz jelly pro"],[782,480,8,"mobiistar lai zoro"],[784,480,8,"lg k3 (k100)"],[791,480,6,"i-mobile i-style 812 4g"],[800,480,4,"lava iris 550"],[854,480,3,"verykool sl5009 jet"],[897,540,5,"bluboo xfire"],[960,540,3,"siswoo a5 chocolate"],[1024,552,4,"bb-mobile tq763i techno 7.0 lte"],[1024,714,9,"bluedot bnt-791 (2g)"],[1024,720,3,"zte e8qp"],[1280,624,10,"panasonic p55 novo 4g"],[1280,648,4,"tcl 9025"],[1280,656,7,"acer a1-734 iconia talk s"],[1184,720,4,"lenovo xt1700, xt1706, k10a40"],[1187,720,7,"lg k8 (k350)"],[1189,720,5,"ark impulse p2"],[1193,720,7,"lg x power (k220, f750)"],[1196,720,2,"dtac phone m2"],[1198,720,5,"dtac phone t3"],[1205,720,7,"firefly aurii passion"],[1206,720,4,"archos 50 power"],[1208,720,3,"advan i7 plus"],[1217,720,7,"energy sistem energy phone max 2+"],[1238,720,9,"vnpt technology vivas lotus s3 lte"],[1280,720,2,"archos bush spira c2 5"],[1280,736,2,"digma cs1062ml citi 1903 4g"],[1280,737,3,"waywalkers t805g"],[1280,740,3,"casper via l8"],[1280,746,3,"philips tle821l e line 4g"],[1280,752,3,"4good light at200"],[1280,755,7,"leotec letab1020 supernova qi32"],[1356,720,8,"xiaolajiao la-v11"],[1360,720,7,"tecno in5"],[1368,720,7,"tinno p100"],[1280,800,4,"samsung galaxy tab e 8.0 (sm-t375x, sm-t377x)"],[1920,936,4,"panasonic eluga note"],[1920,996,4,"cube technology u83 iplay10"],[1776,1080,4,"fly fs522 cirrus 14"],[1787,1080,5,"lg x cam (k580, f690)"],[1920,1008,6,"alcatel one touch xess (p17aa)"],[1794,1080,3,"ramos mos 1 max"],[1800,1080,4,"archos sense 55 s"],[1815,1080,4,"archos diamond plus"],[1920,1032,5,"virgin media tellytablet"],[1920,1080,2,"infocus m640"],[1920,1104,4,"vestel v tab 7030"],[1920,1116,4,"jty q101"],[1920,1128,2,"archos 80 oxygen"],[2009,1080,4,"tcl 5099"],[1920,1136,4,"asus zenpad 10 (p028 z301m)"]]],["arm mali-t760","760",0,[[854,480,14,"aux t6200l"],[897,540,13,"sony xperia e4g (e20xx)"],[960,540,12,"gionee v381"],[960,568,24,"asus c100pa chromebook flip"],[1024,552,12,"archos 70 helium"],[1024,720,10,"wiz t-8168"],[1188,720,9,"lg h520 magna, h522 prime plus"],[1196,720,9,"acer s57 liquid jade z"],[1280,720,8,"dunetek vitamin a"],[1280,736,8,"archos 80b helium"],[1280,752,8,"frael m10g 4g"],[1280,768,8,"meizu m1"],[1794,1080,6,"sugar 2 ss136 l8560"],[1920,1032,9,"qbic bxp-300 box pc"],[1920,1080,4,"byxpress mphone xone"],[1920,1104,6,"cube technology t7"],[1920,1128,5,"nec lavietab pc-te510bal"],[2048,1440,3,"teclast p98 4g"],[2560,1440,10,"samsung galaxy note 4 (mali-t760, sm-n910x, sm-n916)"]]],["arm mali-t760 mp6","760",0,[[1920,1080,17,"samsung galaxy a8 (mali-t760, sm-a800x, scv32)"],[2048,1536,12,"samsung galaxy tab s 2 8.0 (sm-t710, sm-t715)"],[2560,1532,10,"samsung galaxy note edge (mali-t760, sm-n915x)"],[2560,1600,10,"samsung galaxy tab s 10.5 (mali-t760, sm-t805s)"]]],["arm mali-t760 mp8","760",0,[[1280,768,42,"samsung sm-w2016"],[1920,1080,25,"meizu niux"],[2160,1200,17,"idealens k2"],[2560,1440,12,"le xiang deepoon m2 vr"],[2560,1504,15,"bungbungame kalos 2"]]],["arm mali-t764","764",0,[[1024,600,19,"gpd q9"],[1280,720,15,"gpd xd"],[1280,752,13,"kruger & matz 1064.1g eagle"],[1280,800,13,"pipo p7"],[1920,1008,6,"rockchip mk809 4k tv stick"],[1920,1010,8,"pipo p7 hd"],[1920,1020,5,"rockchip mk903v mini tv"],[1920,1032,7,"acooo oneboard pro+"],[1872,1080,7,"contextmedia wallboard 32 tablet (p-wal-106-yit-01)"],[1920,1080,7,"rockchip cs4k tv box"],[1920,1128,7,"archos 101 oxygen"],[2048,1437,5,"haier pad 971"],[2048,1440,5,"hisense f5281 vidaa pad"],[2560,1504,4,"teclast p90hd"]]],["arm mali-t820","820",0,[[1344,720,5,"lenovo k320t"],[1776,1080,6,"leagoo t5c"],[1920,1008,7,"probox2 ava tv box"],[1920,1080,4,"skyworth coocaa 5s32 n2"]]],["arm mali-t830","830",0,[[1280,720,9,"samsung galaxy on7 (mali-t830, sm-g600x)"],[1280,800,9,"samsung sm-t536 (mali-t830)"],[1776,1080,9,"huawei p10 lite (was-xxx)"],[1794,1080,9,"huawei honor 6x (bln-xxx)"],[1920,1080,5,"samsung galaxy on7 prime 2018 (sm-g611)"],[2033,1080,8,"huawei p smart (fig-xxx)"],[2040,1080,9,"huawei maimang 6 (rne-xxx)"],[1920,1200,5,"samsung galaxy tab a 10.1 (sm-t580, sm-t585)"]]],["arm mali-t860","860",0,[[1184,720,8,"tcl a626"],[1196,720,8,"green orange go t2"],[1280,720,14,"htc one a9s"],[1920,1024,17,"hardkernel odroid-n1 (development board)"],[1920,1032,16,"contextmedia p-wal-108-elc-02"],[1920,1080,7,"htc u play (u-2u)"],[1920,1116,15,"imuz revolution a8"],[1920,1128,15,"rockchip rk3399 (development board)"],[2400,1440,10,"samsung chromebook plus (kevin)"]]],["arm mali-t860 mp2","860",0,[[598,480,25,"cipherlab 9700a"],[1184,720,11,"vernee m5"],[1193,720,11,"lg x power 2 (u+, x500, m-x320, m320)"],[1196,720,11,"lava z25"],[1199,720,11,"lg stylus 3 (m400)"],[1212,720,11,"meeg 306"],[1280,720,10,"oppo r66"],[1336,720,13,"asus pegasus 4s (x018d zb570tl)"],[1344,720,13,"allview x4 soul infinity n"],[1776,1080,7,"benq f55"],[1794,1080,6,"alcatel 7070"],[1798,1080,7,"energy sistem energy phone pro 3"],[1806,1080,8,"tecno phantom 6"],[1807,1080,7,"covia fleaz cp-j55a g07"],[1810,1080,8,"archos 55 diamond 2 plus"],[1920,1080,4,"advan vandroid i55c"],[2004,1080,7,"asus zenfone max plus m1 (x018d zb570tl)"],[1920,1128,7,"verizon qtaxia1"]]],["arm mali-t880","880",0,[[1184,720,22,"doogee mix"],[1280,720,20,"lenovo k8"],[1344,720,18,"casper via f2"],[1776,1080,11,"alcatel 6060 (mali-t880)"],[1794,1080,20,"huawei mate 8 (nxt-xxx)"],[1824,1080,11,"meiigoo m1"],[1920,1080,10,"letv leeco lex650"],[2016,1080,9,"vernee mix 2"],[2064,1080,10,"umi s2 pro"],[2392,1440,12,"huawei honor v8 (knt-al20)"],[2434,1440,11,"huawei honor note 8 premium edition (edi-al10)"],[2560,1440,24,"meizu pro 6 plus"],[2560,1480,10,"huawei dtab compact d-01j (docomo)"],[2560,1600,10,"huawei mediapad m3 (btv-xxx)"]]],["arm mali-t880 mp12","880",0,[[1920,1080,44,"samsung galaxy s7 (sm-g930f)"],[2560,1440,27,"samsung galaxy note 7 (mali-t880, sm-n930)"]]],["arm mali-t880 mp2","880",0,[[1184,720,19,"sony pikachu"],[1376,720,17,"umi s2"],[1776,1080,10,"coolpad a9s-9"],[1800,1080,11,"infinix x603"],[1920,1080,9,"innjoo pro2"]]],["arm mali-t880 mp4","880",0,[[1280,672,18,"mediatek x20 (development board)"],[1794,1080,13,"infocus tsp"],[1800,1080,16,"infinix x602 zero 4 plus"],[1806,1080,16,"tecno phantom a9"],[1810,1080,8,"mobiistar prime x pro"],[1815,1080,16,"tecno phantom 6 plus"],[1920,1080,7,"elephone r9"],[2048,1440,12,"brown tab 1"],[2392,1440,12,"vernee apollo"],[2416,1440,11,"freetel ftj162b kiwami2"],[2560,1440,10,"ivvi i5"]]],["mali-t830","830",0,[[1480,720,10,"samsung gm-j600fn"]]]]')},538:e=>{"use strict";e.exports=JSON.parse('["4.0.8",["arm mali-g31","31",0,[[1920,1080,7,"mecool km9 pro"]]],["arm mali-g51","51",0,[[1920,636,10,"telechips tcc803x_lcn"],[1920,1080,5,"skyworth 8n10 g1a"]]],["arm mali-g52 mc1","52",0,[[1280,736,25,"amazon fire hd 8 (kfonwi, 2020)"]]],["arm mali-g52 mc2","52",0,[[2110,1080,23,"xiaomi redmi 10x 4g"],[2264,1080,20,"xiaomi redmi 9 m2004j19c"],[2400,1080,20,"huawei y9a frl-l22"]]],["arm mali-g57 mc3","57",0,[[2158,1080,48,"realme rmx2173"]]],["arm mali-g71","71",0,[[1280,720,14,"samsung sm-j337"],[1812,1080,53,"huawei mate 9 (mha-xxx)"],[1920,1080,12,"sony amai vp9 (mali-g71)"],[2009,1080,11,"tcl 6062"],[2016,1080,11,"gionee s11"],[2038,1080,10,"ulefone power 3"],[2076,1080,15,"samsung galaxy a8 2018 (sm-a530x)"],[2094,1080,15,"samsung sm-a730x"],[2160,1080,9,"oukitel k6"],[2368,1440,35,"huawei honor v9 (duk-xxx)"],[2560,1440,32,"huawei mate 9 pro (lon-xxx)"],[2678,1440,41,"samsung galaxy s8 (mali-g71, sm-g950x)"],[2960,1440,39,"samsung galaxy s8+ (mali-g71, sm-g955x)"]]],["arm mali-g72","72",0,[[2041,1080,55,"huawei mate 10 pro (bla-xxx)"],[2160,1080,56,"huawei honor view 10 (v10, bkl-xxx)"],[2560,1440,43,"huawei mate 10 (alp-xxx)"],[2768,1440,47,"samsung galaxy s9 (mali-g72, sm-g960)"],[2792,1440,47,"samsung galaxy s9+ (mali-g72, sm-g965)"]]],["arm mali-g76","76",0,[[2020,1080,60,"samsung galaxy s10e (mali-g76, sm-g970x)"],[2029,1080,31,"samsung galaxy s10 plus sm-g975n"],[2064,1080,60,"samsung galaxy note 10 5g (mali-g76, sm-n971x)"],[2159,1080,47,"samsung galaxy a51 5g"],[2232,1080,59,"huawei honor 20 pro yal-l41"],[2328,1128,60,"huawei mate 30 pro (lio-lx9, lio-xl00"],[2723,1440,57,"samsung galaxy s10 (mali-g76, sm-g973x)"],[2730,1440,56,"samsung galaxy s10+ (mali-g76, sm-g975x)"],[2733,1440,56,"samsung galaxy s10 5g (mali-g76, sm-g977x)"],[2759,1440,57,"samsung galaxy note 10+ (mali-g76, sm-n975x)"]]],["arm mali-g77","77",0,[[2178,1080,60,"samsung galaxy s20 5g (sm-g981b)"],[2200,1080,67,"samsung galaxy s20 ultra 5g (sm-g988b)"],[2304,1080,55,"oppo pdcm00"]]],["arm mali-g77 mc9","77",0,[[2293,1080,59,"oppo pdsm00"]]],["arm mali-g78","78",0,[[2646,1288,90,"huawei mate 40 pro 5g"]]],["arm mali-t604 mp4","604",0,[[2560,1504,4,"google nexus 10"]]],["arm mali-t622","622",0,[[1024,564,12,"telechips tcc896x (quad core, development board)"],[1280,720,7,"leadcore l1860 (mali-t622, development board)"]]],["arm mali-t624","624",0,[[1794,1080,7,"huawei grace"],[1812,1080,6,"huawei abc-ul00"],[1830,1080,10,"huawei p8 max (dav-70x)"],[1920,1080,4,"sony amai vp9"],[1920,1104,9,"huawei dtab compact d-02h (docomo)"],[1920,1128,8,"huawei dtab d-01h (docomo)"],[1824,1200,9,"huawei mediapad m2 (m2-80xx)"],[1830,1200,9,"huawei mediapad x2 (gem-701l, gem-702l, gem-703l)"]]],["arm mali-t624 mp2","624",0,[[1280,720,5,"samsung sm-g910f (mali-t624)"]]],["arm mali-t624 mp4","624",0,[[1794,1080,9,"huawei z100"]]],["arm mali-t628","628",0,[[1024,600,30,"thinkware inavi davinci"],[2560,1536,8,"meizu mx4 pro"]]],["arm mali-t628 mp2","628",0,[[1280,720,8,"leadcore l1860 (development board)"]]],["arm mali-t628 mp6","628",0,[[800,480,35,"gen2wave rp1600"],[1280,672,14,"hardkernel odroid-xu3 (development board)"],[1280,720,26,"samsung galaxy alpha (mali-t628, sm-g850)"],[1920,1080,11,"samsung galaxy note iii (mali-t628, sm-n900, sm-n9000q)"],[2560,1600,3,"samsung sm-t520 galaxy tab 10.1"]]],["arm mali-t720","720",0,[[432,240,16,"unihertz jelly pro"],[782,480,8,"mobiistar lai zoro"],[784,480,8,"lg k3 (k100)"],[791,480,6,"i-mobile i-style 812 4g"],[800,480,4,"lava iris 550"],[854,480,3,"verykool sl5009 jet"],[897,540,5,"bluboo xfire"],[960,540,3,"siswoo a5 chocolate"],[1024,552,4,"bb-mobile tq763i techno 7.0 lte"],[1024,714,9,"bluedot bnt-791 (2g)"],[1024,720,3,"zte e8qp"],[1280,624,10,"panasonic p55 novo 4g"],[1280,648,4,"tcl 9025"],[1280,656,7,"acer a1-734 iconia talk s"],[1184,720,4,"lenovo xt1700, xt1706, k10a40"],[1187,720,7,"lg k8 (k350)"],[1189,720,5,"ark impulse p2"],[1193,720,7,"lg x power (k220, f750)"],[1196,720,2,"dtac phone m2"],[1198,720,5,"dtac phone t3"],[1205,720,7,"firefly aurii passion"],[1206,720,4,"archos 50 power"],[1208,720,3,"advan i7 plus"],[1217,720,7,"energy sistem energy phone max 2+"],[1238,720,9,"vnpt technology vivas lotus s3 lte"],[1280,720,2,"archos bush spira c2 5"],[1280,736,2,"digma cs1062ml citi 1903 4g"],[1280,737,3,"waywalkers t805g"],[1280,740,3,"casper via l8"],[1280,746,3,"philips tle821l e line 4g"],[1280,752,3,"4good light at200"],[1280,755,7,"leotec letab1020 supernova qi32"],[1356,720,8,"xiaolajiao la-v11"],[1360,720,7,"tecno in5"],[1368,720,7,"tinno p100"],[1280,800,4,"samsung galaxy tab e 8.0 (sm-t375x, sm-t377x)"],[1920,936,4,"panasonic eluga note"],[1920,996,4,"cube technology u83 iplay10"],[1776,1080,4,"fly fs522 cirrus 14"],[1787,1080,5,"lg x cam (k580, f690)"],[1920,1008,6,"alcatel one touch xess (p17aa)"],[1794,1080,3,"ramos mos 1 max"],[1800,1080,4,"archos sense 55 s"],[1815,1080,4,"archos diamond plus"],[1920,1032,5,"virgin media tellytablet"],[1920,1080,2,"infocus m640"],[1920,1104,4,"vestel v tab 7030"],[1920,1116,4,"jty q101"],[1920,1128,2,"archos 80 oxygen"],[2009,1080,4,"tcl 5099"],[1920,1136,4,"asus zenpad 10 (p028 z301m)"]]],["arm mali-t760","760",0,[[854,480,14,"aux t6200l"],[897,540,13,"sony xperia e4g (e20xx)"],[960,540,12,"gionee v381"],[960,568,24,"asus c100pa chromebook flip"],[1024,552,12,"archos 70 helium"],[1024,720,10,"wiz t-8168"],[1188,720,9,"lg h520 magna, h522 prime plus"],[1196,720,9,"acer s57 liquid jade z"],[1280,720,8,"dunetek vitamin a"],[1280,736,8,"archos 80b helium"],[1280,752,8,"frael m10g 4g"],[1280,768,8,"meizu m1"],[1794,1080,6,"sugar 2 ss136 l8560"],[1920,1032,9,"qbic bxp-300 box pc"],[1920,1080,4,"byxpress mphone xone"],[1920,1104,6,"cube technology t7"],[1920,1128,5,"nec lavietab pc-te510bal"],[2048,1440,3,"teclast p98 4g"],[2560,1440,10,"samsung galaxy note 4 (mali-t760, sm-n910x, sm-n916)"]]],["arm mali-t760 mp6","760",0,[[1920,1080,17,"samsung galaxy a8 (mali-t760, sm-a800x, scv32)"],[2048,1536,12,"samsung galaxy tab s 2 8.0 (sm-t710, sm-t715)"],[2560,1532,10,"samsung galaxy note edge (mali-t760, sm-n915x)"],[2560,1600,10,"samsung galaxy tab s 10.5 (mali-t760, sm-t805s)"]]],["arm mali-t760 mp8","760",0,[[1280,768,42,"samsung sm-w2016"],[1920,1080,25,"meizu niux"],[2160,1200,17,"idealens k2"],[2560,1440,12,"le xiang deepoon m2 vr"],[2560,1504,15,"bungbungame kalos 2"]]],["arm mali-t764","764",0,[[1024,600,19,"gpd q9"],[1280,720,15,"gpd xd"],[1280,752,13,"kruger & matz 1064.1g eagle"],[1280,800,13,"pipo p7"],[1920,1008,6,"rockchip mk809 4k tv stick"],[1920,1010,8,"pipo p7 hd"],[1920,1020,5,"rockchip mk903v mini tv"],[1920,1032,7,"acooo oneboard pro+"],[1872,1080,7,"contextmedia wallboard 32 tablet (p-wal-106-yit-01)"],[1920,1080,7,"rockchip cs4k tv box"],[1920,1128,7,"archos 101 oxygen"],[2048,1437,5,"haier pad 971"],[2048,1440,5,"hisense f5281 vidaa pad"],[2560,1504,4,"teclast p90hd"]]],["arm mali-t820","820",0,[[1344,720,5,"lenovo k320t"],[1776,1080,6,"leagoo t5c"],[1920,1008,7,"probox2 ava tv box"],[1920,1080,4,"skyworth coocaa 5s32 n2"]]],["arm mali-t830","830",0,[[1280,720,9,"samsung galaxy on7 (mali-t830, sm-g600x)"],[1280,800,9,"samsung sm-t536 (mali-t830)"],[1776,1080,9,"huawei p10 lite (was-xxx)"],[1794,1080,9,"huawei honor 6x (bln-xxx)"],[1920,1080,5,"samsung galaxy on7 prime 2018 (sm-g611)"],[2033,1080,8,"huawei p smart (fig-xxx)"],[2040,1080,9,"huawei maimang 6 (rne-xxx)"],[1920,1200,5,"samsung galaxy tab a 10.1 (sm-t580, sm-t585)"]]],["arm mali-t860","860",0,[[1184,720,8,"tcl a626"],[1196,720,8,"green orange go t2"],[1280,720,14,"htc one a9s"],[1920,1024,17,"hardkernel odroid-n1 (development board)"],[1920,1032,16,"contextmedia p-wal-108-elc-02"],[1920,1080,7,"htc u play (u-2u)"],[1920,1116,15,"imuz revolution a8"],[1920,1128,15,"rockchip rk3399 (development board)"],[2400,1440,10,"samsung chromebook plus (kevin)"]]],["arm mali-t860 mp2","860",0,[[598,480,25,"cipherlab 9700a"],[1184,720,11,"vernee m5"],[1193,720,11,"lg x power 2 (u+, x500, m-x320, m320)"],[1196,720,11,"lava z25"],[1199,720,11,"lg stylus 3 (m400)"],[1212,720,11,"meeg 306"],[1280,720,10,"oppo r66"],[1336,720,13,"asus pegasus 4s (x018d zb570tl)"],[1344,720,13,"allview x4 soul infinity n"],[1776,1080,7,"benq f55"],[1794,1080,6,"alcatel 7070"],[1798,1080,7,"energy sistem energy phone pro 3"],[1806,1080,8,"tecno phantom 6"],[1807,1080,7,"covia fleaz cp-j55a g07"],[1810,1080,8,"archos 55 diamond 2 plus"],[1920,1080,4,"advan vandroid i55c"],[2004,1080,7,"asus zenfone max plus m1 (x018d zb570tl)"],[1920,1128,7,"verizon qtaxia1"]]],["arm mali-t880","880",0,[[1184,720,22,"doogee mix"],[1280,720,20,"lenovo k8"],[1344,720,18,"casper via f2"],[1776,1080,11,"alcatel 6060 (mali-t880)"],[1794,1080,20,"huawei mate 8 (nxt-xxx)"],[1824,1080,11,"meiigoo m1"],[1920,1080,10,"letv leeco lex650"],[2016,1080,9,"vernee mix 2"],[2064,1080,10,"umi s2 pro"],[2392,1440,12,"huawei honor v8 (knt-al20)"],[2434,1440,11,"huawei honor note 8 premium edition (edi-al10)"],[2560,1440,24,"meizu pro 6 plus"],[2560,1480,10,"huawei dtab compact d-01j (docomo)"],[2560,1600,10,"huawei mediapad m3 (btv-xxx)"]]],["arm mali-t880 mp12","880",0,[[1920,1080,44,"samsung galaxy s7 (sm-g930f)"],[2560,1440,27,"samsung galaxy note 7 (mali-t880, sm-n930)"]]],["arm mali-t880 mp2","880",0,[[1184,720,19,"sony pikachu"],[1376,720,17,"umi s2"],[1776,1080,10,"coolpad a9s-9"],[1800,1080,11,"infinix x603"],[1920,1080,9,"innjoo pro2"]]],["arm mali-t880 mp4","880",0,[[1280,672,18,"mediatek x20 (development board)"],[1794,1080,13,"infocus tsp"],[1800,1080,16,"infinix x602 zero 4 plus"],[1806,1080,16,"tecno phantom a9"],[1810,1080,8,"mobiistar prime x pro"],[1815,1080,16,"tecno phantom 6 plus"],[1920,1080,7,"elephone r9"],[2048,1440,12,"brown tab 1"],[2392,1440,12,"vernee apollo"],[2416,1440,11,"freetel ftj162b kiwami2"],[2560,1440,10,"ivvi i5"]]],["mali-g71","71",0,[[2220,1080,54,"samsung s8+ sm-g955f"]]],["mali-g72","72",0,[[2220,1080,56,"samsung s9+ sm-g965f"]]],["mali-t830","830",0,[[1480,720,10,"samsung gm-j600fn"]]]]')},884:e=>{"use strict";e.exports=JSON.parse('["4.0.8",["nvidia tegra","",0,[[2048,1440,23,"google nexus 9"]]],["nvidia tegra k1","1",0,[[1920,1008,32,"nvidia jetson tk1 (pm375, development board)"],[1920,1032,12,"lenovo k1 hd (2014)"],[1920,1080,28,"nvidia tegra gk20a (ardbeg, development board)"],[1920,1104,29,"google project tango"],[2048,1536,21,"xiaomi mi pad"],[3840,2088,8,"lenovo thinkvision 28"]]],["nvidia tegra x1","1",0,[[1920,1080,60,"nvidia shield android tv"],[2560,1688,33,"google pixel c"]]]]')},214:e=>{"use strict";e.exports=JSON.parse('["4.0.8",["powervr rogue g6110","6110",0,[[1024,600,11,"dasaita mtcd px5 head unit"],[1280,752,8,"visual land prestige prime 10se"],[1366,720,7,"ditecma m1092r"],[1920,1008,6,"vensmile t051 tv box"],[1920,1016,5,"geekbuying geekbox tv box"],[1920,1032,4,"hannspree hsg1351"],[1920,1080,5,"10moons tv box (rogue g6110)"],[1920,1128,5,"teclast p10"]]],["powervr rogue g6200","6200",0,[[1280,720,15,"infocus m530"],[1280,736,12,"amazon kindle fire hd 8 (5th gen, kfmewi)"],[1280,752,12,"amazon kindle fire hd 10 (5th gen, kftbwi)"],[1280,800,9,"amazon kindle fire hd 7 (4th gen, kfaswi)"],[1794,1080,5,"ubik uno"],[1920,1080,6,"cherry mobile x220 cosmos one plus"],[1920,1152,8,"meizu mx4 (m460, m460a, m461)"],[2392,1440,6,"hasee hl9916004"],[2560,1440,6,"condor allure a100 pgn-607"]]],["powervr rogue g6230","6230",0,[[1920,1008,8,"rikomagic mk80 tv box (tronsmart draco aw80, fantasy a80)"],[1920,1016,7,"cubietech cubieboard 4 (cc-a80, hansen-a80, development board)"],[2048,1440,5,"teclast p98air"],[2048,1464,7,"actions gs900a (development board)"]]],["powervr rogue g6400","6400",0,[[1794,1080,8,"lg f490 liger (g6400)"],[1920,1032,8,"renesas lager"]]],["powervr rogue g6430","6430",0,[[1024,552,26,"asus fonepad 7 (k01f fe171mg)"],[1280,720,27,"asus zenfone 2 (z008 ze550ml)"],[1280,736,20,"asus fonepad 7 (k019 fe375cg)"],[1280,752,27,"asus zenpad 10 (p01t z300cl)"],[1788,1080,8,"lg f490 liger (g6430)"],[1920,1080,15,"asus zenfone zoom (intel z3560, z00xsb zx551ml)"],[1920,1104,11,"asus memo pad 8 ast21 (intel z3580, k015 me581cl)"],[2048,1440,11,"asus zenpad s 8.0 (p01m z580c)"],[2560,1504,9,"dell venue 10 7040"]]],["powervr rogue ge8100","8100",0,[[906,480,8,"tinno k600"],[1184,720,5,"mediatek mt6739 (development board, rogue ge8100)"],[1339,720,5,"vodafone vfd 720"],[1344,720,6,"gionee f205"]]],["powervr rogue ge8300","8300",0,[[1280,752,9,"acer b3-a40 iconia one 10"],[1208,800,8,"verizon qtaki1"],[1920,1128,5,"acer b3-a40 fhd iconia one 10"]]],["powervr rogue gx6250","6250",0,[[688,412,16,"lenovo n23 yoga / flex 11 chromebook"],[1280,672,25,"renesas salvator-x-r8a7796"],[1280,736,25,"mediatek mt8173 (development board)"],[1920,980,10,"google chromebook pixel (2015, rogue gx6250)"],[1920,1016,14,"peloton ruby"],[1920,1020,8,"acer chromebook r13"],[1920,1032,13,"renesas salvator-x-m3"],[1920,1080,12,"xiaomi mibox 3 pro tv box"],[1920,1128,10,"amazon kindle fire hd 10 (2017, kfsuwi)"],[2048,1536,7,"alps jdtab j01"],[2560,1504,7,"onda f109"]]],["powervr rogue gx6650","6650",0,[[1280,672,52,"renesas salvator-x"],[1920,1032,24,"renesas salvator-x (octa core)"]]],["powervr rogue han","han",0,[[1794,1080,6,"ireadygo w3d"],[1920,1080,6,"changhong x6"],[2392,1440,5,"alcatel one touch d820"],[2560,1440,4,"alcatel 6071y phantom"]]],["powervr rogue hood","",0,[[1280,736,16,"dell venue 7 3740"],[1920,1080,12,"lenovo p90"],[1920,1104,9,"dell venue 8 3840"]]],["powervr rogue lando","",0,[[1920,1080,13,"spreadtrum sp9861e (development board, rogue lando)"]]],["powervr rogue marlowe","",0,[[1920,1080,39,"meitu v6 mp1605"],[2560,1440,25,"meizu pro 7 plus"]]]]')},804:(e,a,n)=>{var r={"./d-adreno.json":622,"./d-amd.json":183,"./d-apple.json":732,"./d-geforce.json":405,"./d-intel.json":178,"./d-nvidia.json":217,"./d-radeon.json":145,"./m-adreno.json":921,"./m-apple-ipad.json":535,"./m-apple.json":438,"./m-intel.json":283,"./m-mali-t.json":327,"./m-mali.json":538,"./m-nvidia.json":884,"./m-powervr.json":214};function o(e){var a=d(e);return n(a)}function d(e){if(!n.o(r,e)){var a=new Error("Cannot find module '"+e+"'");throw a.code="MODULE_NOT_FOUND",a}return r[e]}o.keys=function(){return Object.keys(r)},o.resolve=d,e.exports=o,o.id=804},354:(e,a,n)=>{var r,o=function(){function e(e,a){if(!o[e]){o[e]={};for(var n=0;n<e.length;n++)o[e][e.charAt(n)]=n}return o[e][a]}var a=String.fromCharCode,n="ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/=",r="ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+-$",o={},d={compressToBase64:function(e){if(null==e)return"";var a=d._compress(e,6,(function(e){return n.charAt(e)}));switch(a.length%4){default:case 0:return a;case 1:return a+"===";case 2:return a+"==";case 3:return a+"="}},decompressFromBase64:function(a){return null==a?"":""==a?null:d._decompress(a.length,32,(function(r){return e(n,a.charAt(r))}))},compressToUTF16:function(e){return null==e?"":d._compress(e,15,(function(e){return a(e+32)}))+" "},decompressFromUTF16:function(e){return null==e?"":""==e?null:d._decompress(e.length,16384,(function(a){return e.charCodeAt(a)-32}))},compressToUint8Array:function(e){for(var a=d.compress(e),n=new Uint8Array(2*a.length),r=0,o=a.length;o>r;r++){var i=a.charCodeAt(r);n[2*r]=i>>>8,n[2*r+1]=i%256}return n},decompressFromUint8Array:function(e){if(null==e)return d.decompress(e);for(var n=new Array(e.length/2),r=0,o=n.length;o>r;r++)n[r]=256*e[2*r]+e[2*r+1];var i=[];return n.forEach((function(e){i.push(a(e))})),d.decompress(i.join(""))},compressToEncodedURIComponent:function(e){return null==e?"":d._compress(e,6,(function(e){return r.charAt(e)}))},decompressFromEncodedURIComponent:function(a){return null==a?"":""==a?null:(a=a.replace(/ /g,"+"),d._decompress(a.length,32,(function(n){return e(r,a.charAt(n))})))},compress:function(e){return d._compress(e,16,(function(e){return a(e)}))},_compress:function(e,a,n){if(null==e)return"";var r,o,d,i={},t={},g="",m="",c="",l=2,s=3,p=2,v=[],f=0,u=0;for(d=0;d<e.length;d+=1)if(g=e.charAt(d),Object.prototype.hasOwnProperty.call(i,g)||(i[g]=s++,t[g]=!0),m=c+g,Object.prototype.hasOwnProperty.call(i,m))c=m;else{if(Object.prototype.hasOwnProperty.call(t,c)){if(c.charCodeAt(0)<256){for(r=0;p>r;r++)f<<=1,u==a-1?(u=0,v.push(n(f)),f=0):u++;for(o=c.charCodeAt(0),r=0;8>r;r++)f=f<<1|1&o,u==a-1?(u=0,v.push(n(f)),f=0):u++,o>>=1}else{for(o=1,r=0;p>r;r++)f=f<<1|o,u==a-1?(u=0,v.push(n(f)),f=0):u++,o=0;for(o=c.charCodeAt(0),r=0;16>r;r++)f=f<<1|1&o,u==a-1?(u=0,v.push(n(f)),f=0):u++,o>>=1}0==--l&&(l=Math.pow(2,p),p++),delete t[c]}else for(o=i[c],r=0;p>r;r++)f=f<<1|1&o,u==a-1?(u=0,v.push(n(f)),f=0):u++,o>>=1;0==--l&&(l=Math.pow(2,p),p++),i[m]=s++,c=String(g)}if(""!==c){if(Object.prototype.hasOwnProperty.call(t,c)){if(c.charCodeAt(0)<256){for(r=0;p>r;r++)f<<=1,u==a-1?(u=0,v.push(n(f)),f=0):u++;for(o=c.charCodeAt(0),r=0;8>r;r++)f=f<<1|1&o,u==a-1?(u=0,v.push(n(f)),f=0):u++,o>>=1}else{for(o=1,r=0;p>r;r++)f=f<<1|o,u==a-1?(u=0,v.push(n(f)),f=0):u++,o=0;for(o=c.charCodeAt(0),r=0;16>r;r++)f=f<<1|1&o,u==a-1?(u=0,v.push(n(f)),f=0):u++,o>>=1}0==--l&&(l=Math.pow(2,p),p++),delete t[c]}else for(o=i[c],r=0;p>r;r++)f=f<<1|1&o,u==a-1?(u=0,v.push(n(f)),f=0):u++,o>>=1;0==--l&&(l=Math.pow(2,p),p++)}for(o=2,r=0;p>r;r++)f=f<<1|1&o,u==a-1?(u=0,v.push(n(f)),f=0):u++,o>>=1;for(;;){if(f<<=1,u==a-1){v.push(n(f));break}u++}return v.join("")},decompress:function(e){return null==e?"":""==e?null:d._decompress(e.length,32768,(function(a){return e.charCodeAt(a)}))},_decompress:function(e,n,r){var o,d,i,t,g,m,c,l=[],s=4,p=4,v=3,f="",u=[],x={val:r(0),position:n,index:1};for(o=0;3>o;o+=1)l[o]=o;for(i=0,g=Math.pow(2,2),m=1;m!=g;)t=x.val&x.position,x.position>>=1,0==x.position&&(x.position=n,x.val=r(x.index++)),i|=(t>0?1:0)*m,m<<=1;switch(i){case 0:for(i=0,g=Math.pow(2,8),m=1;m!=g;)t=x.val&x.position,x.position>>=1,0==x.position&&(x.position=n,x.val=r(x.index++)),i|=(t>0?1:0)*m,m<<=1;c=a(i);break;case 1:for(i=0,g=Math.pow(2,16),m=1;m!=g;)t=x.val&x.position,x.position>>=1,0==x.position&&(x.position=n,x.val=r(x.index++)),i|=(t>0?1:0)*m,m<<=1;c=a(i);break;case 2:return""}for(l[3]=c,d=c,u.push(c);;){if(x.index>e)return"";for(i=0,g=Math.pow(2,v),m=1;m!=g;)t=x.val&x.position,x.position>>=1,0==x.position&&(x.position=n,x.val=r(x.index++)),i|=(t>0?1:0)*m,m<<=1;switch(c=i){case 0:for(i=0,g=Math.pow(2,8),m=1;m!=g;)t=x.val&x.position,x.position>>=1,0==x.position&&(x.position=n,x.val=r(x.index++)),i|=(t>0?1:0)*m,m<<=1;l[p++]=a(i),c=p-1,s--;break;case 1:for(i=0,g=Math.pow(2,16),m=1;m!=g;)t=x.val&x.position,x.position>>=1,0==x.position&&(x.position=n,x.val=r(x.index++)),i|=(t>0?1:0)*m,m<<=1;l[p++]=a(i),c=p-1,s--;break;case 2:return u.join("")}if(0==s&&(s=Math.pow(2,v),v++),l[c])f=l[c];else{if(c!==p)return null;f=d+d.charAt(0)}u.push(f),l[p++]=d+f.charAt(0),d=f,0==--s&&(s=Math.pow(2,v),v++)}}};return d}();void 0===(r=function(){return o}.call(a,n,a,e))||(e.exports=r)}},a={};function n(r){if(a[r])return a[r].exports;var o=a[r]={exports:{}};return e[r].call(o.exports,o,o.exports,n),o.exports}return n.o=(e,a)=>Object.prototype.hasOwnProperty.call(e,a),n(607)})().default}));
//# sourceMappingURL=index.js.map

/***/ }),

/***/ "./node_modules/@xmldom/xmldom/lib/conventions.js":
/*!********************************************************!*\
  !*** ./node_modules/@xmldom/xmldom/lib/conventions.js ***!
  \********************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";


/**
 * "Shallow freezes" an object to render it immutable.
 * Uses `Object.freeze` if available,
 * otherwise the immutability is only in the type.
 *
 * Is used to create "enum like" objects.
 *
 * @template T
 * @param {T} object the object to freeze
 * @param {Pick<ObjectConstructor, 'freeze'> = Object} oc `Object` by default,
 * 				allows to inject custom object constructor for tests
 * @returns {Readonly<T>}
 *
 * @see https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Object/freeze
 */
function freeze(object, oc) {
	if (oc === undefined) {
		oc = Object
	}
	return oc && typeof oc.freeze === 'function' ? oc.freeze(object) : object
}

/**
 * Since we can not rely on `Object.assign` we provide a simplified version
 * that is sufficient for our needs.
 *
 * @param {Object} target
 * @param {Object | null | undefined} source
 *
 * @returns {Object} target
 * @throws TypeError if target is not an object
 *
 * @see https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Object/assign
 * @see https://tc39.es/ecma262/multipage/fundamental-objects.html#sec-object.assign
 */
function assign(target, source) {
	if (target === null || typeof target !== 'object') {
		throw new TypeError('target is not an object')
	}
	for (var key in source) {
		if (Object.prototype.hasOwnProperty.call(source, key)) {
			target[key] = source[key]
		}
	}
	return target
}

/**
 * All mime types that are allowed as input to `DOMParser.parseFromString`
 *
 * @see https://developer.mozilla.org/en-US/docs/Web/API/DOMParser/parseFromString#Argument02 MDN
 * @see https://html.spec.whatwg.org/multipage/dynamic-markup-insertion.html#domparsersupportedtype WHATWG HTML Spec
 * @see DOMParser.prototype.parseFromString
 */
var MIME_TYPE = freeze({
	/**
	 * `text/html`, the only mime type that triggers treating an XML document as HTML.
	 *
	 * @see DOMParser.SupportedType.isHTML
	 * @see https://www.iana.org/assignments/media-types/text/html IANA MimeType registration
	 * @see https://en.wikipedia.org/wiki/HTML Wikipedia
	 * @see https://developer.mozilla.org/en-US/docs/Web/API/DOMParser/parseFromString MDN
	 * @see https://html.spec.whatwg.org/multipage/dynamic-markup-insertion.html#dom-domparser-parsefromstring WHATWG HTML Spec
	 */
	HTML: 'text/html',

	/**
	 * Helper method to check a mime type if it indicates an HTML document
	 *
	 * @param {string} [value]
	 * @returns {boolean}
	 *
	 * @see https://www.iana.org/assignments/media-types/text/html IANA MimeType registration
	 * @see https://en.wikipedia.org/wiki/HTML Wikipedia
	 * @see https://developer.mozilla.org/en-US/docs/Web/API/DOMParser/parseFromString MDN
	 * @see https://html.spec.whatwg.org/multipage/dynamic-markup-insertion.html#dom-domparser-parsefromstring 	 */
	isHTML: function (value) {
		return value === MIME_TYPE.HTML
	},

	/**
	 * `application/xml`, the standard mime type for XML documents.
	 *
	 * @see https://www.iana.org/assignments/media-types/application/xml IANA MimeType registration
	 * @see https://tools.ietf.org/html/rfc7303#section-9.1 RFC 7303
	 * @see https://en.wikipedia.org/wiki/XML_and_MIME Wikipedia
	 */
	XML_APPLICATION: 'application/xml',

	/**
	 * `text/html`, an alias for `application/xml`.
	 *
	 * @see https://tools.ietf.org/html/rfc7303#section-9.2 RFC 7303
	 * @see https://www.iana.org/assignments/media-types/text/xml IANA MimeType registration
	 * @see https://en.wikipedia.org/wiki/XML_and_MIME Wikipedia
	 */
	XML_TEXT: 'text/xml',

	/**
	 * `application/xhtml+xml`, indicates an XML document that has the default HTML namespace,
	 * but is parsed as an XML document.
	 *
	 * @see https://www.iana.org/assignments/media-types/application/xhtml+xml IANA MimeType registration
	 * @see https://dom.spec.whatwg.org/#dom-domimplementation-createdocument WHATWG DOM Spec
	 * @see https://en.wikipedia.org/wiki/XHTML Wikipedia
	 */
	XML_XHTML_APPLICATION: 'application/xhtml+xml',

	/**
	 * `image/svg+xml`,
	 *
	 * @see https://www.iana.org/assignments/media-types/image/svg+xml IANA MimeType registration
	 * @see https://www.w3.org/TR/SVG11/ W3C SVG 1.1
	 * @see https://en.wikipedia.org/wiki/Scalable_Vector_Graphics Wikipedia
	 */
	XML_SVG_IMAGE: 'image/svg+xml',
})

/**
 * Namespaces that are used in this code base.
 *
 * @see http://www.w3.org/TR/REC-xml-names
 */
var NAMESPACE = freeze({
	/**
	 * The XHTML namespace.
	 *
	 * @see http://www.w3.org/1999/xhtml
	 */
	HTML: 'http://www.w3.org/1999/xhtml',

	/**
	 * Checks if `uri` equals `NAMESPACE.HTML`.
	 *
	 * @param {string} [uri]
	 *
	 * @see NAMESPACE.HTML
	 */
	isHTML: function (uri) {
		return uri === NAMESPACE.HTML
	},

	/**
	 * The SVG namespace.
	 *
	 * @see http://www.w3.org/2000/svg
	 */
	SVG: 'http://www.w3.org/2000/svg',

	/**
	 * The `xml:` namespace.
	 *
	 * @see http://www.w3.org/XML/1998/namespace
	 */
	XML: 'http://www.w3.org/XML/1998/namespace',

	/**
	 * The `xmlns:` namespace
	 *
	 * @see https://www.w3.org/2000/xmlns/
	 */
	XMLNS: 'http://www.w3.org/2000/xmlns/',
})

exports.assign = assign;
exports.freeze = freeze;
exports.MIME_TYPE = MIME_TYPE;
exports.NAMESPACE = NAMESPACE;


/***/ }),

/***/ "./node_modules/@xmldom/xmldom/lib/dom-parser.js":
/*!*******************************************************!*\
  !*** ./node_modules/@xmldom/xmldom/lib/dom-parser.js ***!
  \*******************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

var conventions = __webpack_require__(/*! ./conventions */ "./node_modules/@xmldom/xmldom/lib/conventions.js");
var dom = __webpack_require__(/*! ./dom */ "./node_modules/@xmldom/xmldom/lib/dom.js")
var entities = __webpack_require__(/*! ./entities */ "./node_modules/@xmldom/xmldom/lib/entities.js");
var sax = __webpack_require__(/*! ./sax */ "./node_modules/@xmldom/xmldom/lib/sax.js");

var DOMImplementation = dom.DOMImplementation;

var NAMESPACE = conventions.NAMESPACE;

var ParseError = sax.ParseError;
var XMLReader = sax.XMLReader;

/**
 * Normalizes line ending according to https://www.w3.org/TR/xml11/#sec-line-ends:
 *
 * > XML parsed entities are often stored in computer files which,
 * > for editing convenience, are organized into lines.
 * > These lines are typically separated by some combination
 * > of the characters CARRIAGE RETURN (#xD) and LINE FEED (#xA).
 * >
 * > To simplify the tasks of applications, the XML processor must behave
 * > as if it normalized all line breaks in external parsed entities (including the document entity)
 * > on input, before parsing, by translating all of the following to a single #xA character:
 * >
 * > 1. the two-character sequence #xD #xA
 * > 2. the two-character sequence #xD #x85
 * > 3. the single character #x85
 * > 4. the single character #x2028
 * > 5. any #xD character that is not immediately followed by #xA or #x85.
 *
 * @param {string} input
 * @returns {string}
 */
function normalizeLineEndings(input) {
	return input
		.replace(/\r[\n\u0085]/g, '\n')
		.replace(/[\r\u0085\u2028]/g, '\n')
}

/**
 * @typedef Locator
 * @property {number} [columnNumber]
 * @property {number} [lineNumber]
 */

/**
 * @typedef DOMParserOptions
 * @property {DOMHandler} [domBuilder]
 * @property {Function} [errorHandler]
 * @property {(string) => string} [normalizeLineEndings] used to replace line endings before parsing
 * 						defaults to `normalizeLineEndings`
 * @property {Locator} [locator]
 * @property {Record<string, string>} [xmlns]
 *
 * @see normalizeLineEndings
 */

/**
 * The DOMParser interface provides the ability to parse XML or HTML source code
 * from a string into a DOM `Document`.
 *
 * _xmldom is different from the spec in that it allows an `options` parameter,
 * to override the default behavior._
 *
 * @param {DOMParserOptions} [options]
 * @constructor
 *
 * @see https://developer.mozilla.org/en-US/docs/Web/API/DOMParser
 * @see https://html.spec.whatwg.org/multipage/dynamic-markup-insertion.html#dom-parsing-and-serialization
 */
function DOMParser(options){
	this.options = options ||{locator:{}};
}

DOMParser.prototype.parseFromString = function(source,mimeType){
	var options = this.options;
	var sax =  new XMLReader();
	var domBuilder = options.domBuilder || new DOMHandler();//contentHandler and LexicalHandler
	var errorHandler = options.errorHandler;
	var locator = options.locator;
	var defaultNSMap = options.xmlns||{};
	var isHTML = /\/x?html?$/.test(mimeType);//mimeType.toLowerCase().indexOf('html') > -1;
  	var entityMap = isHTML ? entities.HTML_ENTITIES : entities.XML_ENTITIES;
	if(locator){
		domBuilder.setDocumentLocator(locator)
	}

	sax.errorHandler = buildErrorHandler(errorHandler,domBuilder,locator);
	sax.domBuilder = options.domBuilder || domBuilder;
	if(isHTML){
		defaultNSMap[''] = NAMESPACE.HTML;
	}
	defaultNSMap.xml = defaultNSMap.xml || NAMESPACE.XML;
	var normalize = options.normalizeLineEndings || normalizeLineEndings;
	if (source && typeof source === 'string') {
		sax.parse(
			normalize(source),
			defaultNSMap,
			entityMap
		)
	} else {
		sax.errorHandler.error('invalid doc source')
	}
	return domBuilder.doc;
}
function buildErrorHandler(errorImpl,domBuilder,locator){
	if(!errorImpl){
		if(domBuilder instanceof DOMHandler){
			return domBuilder;
		}
		errorImpl = domBuilder ;
	}
	var errorHandler = {}
	var isCallback = errorImpl instanceof Function;
	locator = locator||{}
	function build(key){
		var fn = errorImpl[key];
		if(!fn && isCallback){
			fn = errorImpl.length == 2?function(msg){errorImpl(key,msg)}:errorImpl;
		}
		errorHandler[key] = fn && function(msg){
			fn('[xmldom '+key+']\t'+msg+_locator(locator));
		}||function(){};
	}
	build('warning');
	build('error');
	build('fatalError');
	return errorHandler;
}

//console.log('#\n\n\n\n\n\n\n####')
/**
 * +ContentHandler+ErrorHandler
 * +LexicalHandler+EntityResolver2
 * -DeclHandler-DTDHandler
 *
 * DefaultHandler:EntityResolver, DTDHandler, ContentHandler, ErrorHandler
 * DefaultHandler2:DefaultHandler,LexicalHandler, DeclHandler, EntityResolver2
 * @link http://www.saxproject.org/apidoc/org/xml/sax/helpers/DefaultHandler.html
 */
function DOMHandler() {
    this.cdata = false;
}
function position(locator,node){
	node.lineNumber = locator.lineNumber;
	node.columnNumber = locator.columnNumber;
}
/**
 * @see org.xml.sax.ContentHandler#startDocument
 * @link http://www.saxproject.org/apidoc/org/xml/sax/ContentHandler.html
 */
DOMHandler.prototype = {
	startDocument : function() {
    	this.doc = new DOMImplementation().createDocument(null, null, null);
    	if (this.locator) {
        	this.doc.documentURI = this.locator.systemId;
    	}
	},
	startElement:function(namespaceURI, localName, qName, attrs) {
		var doc = this.doc;
	    var el = doc.createElementNS(namespaceURI, qName||localName);
	    var len = attrs.length;
	    appendElement(this, el);
	    this.currentElement = el;

		this.locator && position(this.locator,el)
	    for (var i = 0 ; i < len; i++) {
	        var namespaceURI = attrs.getURI(i);
	        var value = attrs.getValue(i);
	        var qName = attrs.getQName(i);
			var attr = doc.createAttributeNS(namespaceURI, qName);
			this.locator &&position(attrs.getLocator(i),attr);
			attr.value = attr.nodeValue = value;
			el.setAttributeNode(attr)
	    }
	},
	endElement:function(namespaceURI, localName, qName) {
		var current = this.currentElement
		var tagName = current.tagName;
		this.currentElement = current.parentNode;
	},
	startPrefixMapping:function(prefix, uri) {
	},
	endPrefixMapping:function(prefix) {
	},
	processingInstruction:function(target, data) {
	    var ins = this.doc.createProcessingInstruction(target, data);
	    this.locator && position(this.locator,ins)
	    appendElement(this, ins);
	},
	ignorableWhitespace:function(ch, start, length) {
	},
	characters:function(chars, start, length) {
		chars = _toString.apply(this,arguments)
		//console.log(chars)
		if(chars){
			if (this.cdata) {
				var charNode = this.doc.createCDATASection(chars);
			} else {
				var charNode = this.doc.createTextNode(chars);
			}
			if(this.currentElement){
				this.currentElement.appendChild(charNode);
			}else if(/^\s*$/.test(chars)){
				this.doc.appendChild(charNode);
				//process xml
			}
			this.locator && position(this.locator,charNode)
		}
	},
	skippedEntity:function(name) {
	},
	endDocument:function() {
		this.doc.normalize();
	},
	setDocumentLocator:function (locator) {
	    if(this.locator = locator){// && !('lineNumber' in locator)){
	    	locator.lineNumber = 0;
	    }
	},
	//LexicalHandler
	comment:function(chars, start, length) {
		chars = _toString.apply(this,arguments)
	    var comm = this.doc.createComment(chars);
	    this.locator && position(this.locator,comm)
	    appendElement(this, comm);
	},

	startCDATA:function() {
	    //used in characters() methods
	    this.cdata = true;
	},
	endCDATA:function() {
	    this.cdata = false;
	},

	startDTD:function(name, publicId, systemId) {
		var impl = this.doc.implementation;
	    if (impl && impl.createDocumentType) {
	        var dt = impl.createDocumentType(name, publicId, systemId);
	        this.locator && position(this.locator,dt)
	        appendElement(this, dt);
					this.doc.doctype = dt;
	    }
	},
	/**
	 * @see org.xml.sax.ErrorHandler
	 * @link http://www.saxproject.org/apidoc/org/xml/sax/ErrorHandler.html
	 */
	warning:function(error) {
		console.warn('[xmldom warning]\t'+error,_locator(this.locator));
	},
	error:function(error) {
		console.error('[xmldom error]\t'+error,_locator(this.locator));
	},
	fatalError:function(error) {
		throw new ParseError(error, this.locator);
	}
}
function _locator(l){
	if(l){
		return '\n@'+(l.systemId ||'')+'#[line:'+l.lineNumber+',col:'+l.columnNumber+']'
	}
}
function _toString(chars,start,length){
	if(typeof chars == 'string'){
		return chars.substr(start,length)
	}else{//java sax connect width xmldom on rhino(what about: "? && !(chars instanceof String)")
		if(chars.length >= start+length || start){
			return new java.lang.String(chars,start,length)+'';
		}
		return chars;
	}
}

/*
 * @link http://www.saxproject.org/apidoc/org/xml/sax/ext/LexicalHandler.html
 * used method of org.xml.sax.ext.LexicalHandler:
 *  #comment(chars, start, length)
 *  #startCDATA()
 *  #endCDATA()
 *  #startDTD(name, publicId, systemId)
 *
 *
 * IGNORED method of org.xml.sax.ext.LexicalHandler:
 *  #endDTD()
 *  #startEntity(name)
 *  #endEntity(name)
 *
 *
 * @link http://www.saxproject.org/apidoc/org/xml/sax/ext/DeclHandler.html
 * IGNORED method of org.xml.sax.ext.DeclHandler
 * 	#attributeDecl(eName, aName, type, mode, value)
 *  #elementDecl(name, model)
 *  #externalEntityDecl(name, publicId, systemId)
 *  #internalEntityDecl(name, value)
 * @link http://www.saxproject.org/apidoc/org/xml/sax/ext/EntityResolver2.html
 * IGNORED method of org.xml.sax.EntityResolver2
 *  #resolveEntity(String name,String publicId,String baseURI,String systemId)
 *  #resolveEntity(publicId, systemId)
 *  #getExternalSubset(name, baseURI)
 * @link http://www.saxproject.org/apidoc/org/xml/sax/DTDHandler.html
 * IGNORED method of org.xml.sax.DTDHandler
 *  #notationDecl(name, publicId, systemId) {};
 *  #unparsedEntityDecl(name, publicId, systemId, notationName) {};
 */
"endDTD,startEntity,endEntity,attributeDecl,elementDecl,externalEntityDecl,internalEntityDecl,resolveEntity,getExternalSubset,notationDecl,unparsedEntityDecl".replace(/\w+/g,function(key){
	DOMHandler.prototype[key] = function(){return null}
})

/* Private static helpers treated below as private instance methods, so don't need to add these to the public API; we might use a Relator to also get rid of non-standard public properties */
function appendElement (hander,node) {
    if (!hander.currentElement) {
        hander.doc.appendChild(node);
    } else {
        hander.currentElement.appendChild(node);
    }
}//appendChild and setAttributeNS are preformance key

exports.__DOMHandler = DOMHandler;
exports.normalizeLineEndings = normalizeLineEndings;
exports.DOMParser = DOMParser;


/***/ }),

/***/ "./node_modules/@xmldom/xmldom/lib/dom.js":
/*!************************************************!*\
  !*** ./node_modules/@xmldom/xmldom/lib/dom.js ***!
  \************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

var conventions = __webpack_require__(/*! ./conventions */ "./node_modules/@xmldom/xmldom/lib/conventions.js");

var NAMESPACE = conventions.NAMESPACE;

/**
 * A prerequisite for `[].filter`, to drop elements that are empty
 * @param {string} input
 * @returns {boolean}
 */
function notEmptyString (input) {
	return input !== ''
}
/**
 * @see https://infra.spec.whatwg.org/#split-on-ascii-whitespace
 * @see https://infra.spec.whatwg.org/#ascii-whitespace
 *
 * @param {string} input
 * @returns {string[]} (can be empty)
 */
function splitOnASCIIWhitespace(input) {
	// U+0009 TAB, U+000A LF, U+000C FF, U+000D CR, U+0020 SPACE
	return input ? input.split(/[\t\n\f\r ]+/).filter(notEmptyString) : []
}

/**
 * Adds element as a key to current if it is not already present.
 *
 * @param {Record<string, boolean | undefined>} current
 * @param {string} element
 * @returns {Record<string, boolean | undefined>}
 */
function orderedSetReducer (current, element) {
	if (!current.hasOwnProperty(element)) {
		current[element] = true;
	}
	return current;
}

/**
 * @see https://infra.spec.whatwg.org/#ordered-set
 * @param {string} input
 * @returns {string[]}
 */
function toOrderedSet(input) {
	if (!input) return [];
	var list = splitOnASCIIWhitespace(input);
	return Object.keys(list.reduce(orderedSetReducer, {}))
}

/**
 * Uses `list.indexOf` to implement something like `Array.prototype.includes`,
 * which we can not rely on being available.
 *
 * @param {any[]} list
 * @returns {function(any): boolean}
 */
function arrayIncludes (list) {
	return function(element) {
		return list && list.indexOf(element) !== -1;
	}
}

function copy(src,dest){
	for(var p in src){
		dest[p] = src[p];
	}
}

/**
^\w+\.prototype\.([_\w]+)\s*=\s*((?:.*\{\s*?[\r\n][\s\S]*?^})|\S.*?(?=[;\r\n]));?
^\w+\.prototype\.([_\w]+)\s*=\s*(\S.*?(?=[;\r\n]));?
 */
function _extends(Class,Super){
	var pt = Class.prototype;
	if(!(pt instanceof Super)){
		function t(){};
		t.prototype = Super.prototype;
		t = new t();
		copy(pt,t);
		Class.prototype = pt = t;
	}
	if(pt.constructor != Class){
		if(typeof Class != 'function'){
			console.error("unknown Class:"+Class)
		}
		pt.constructor = Class
	}
}

// Node Types
var NodeType = {}
var ELEMENT_NODE                = NodeType.ELEMENT_NODE                = 1;
var ATTRIBUTE_NODE              = NodeType.ATTRIBUTE_NODE              = 2;
var TEXT_NODE                   = NodeType.TEXT_NODE                   = 3;
var CDATA_SECTION_NODE          = NodeType.CDATA_SECTION_NODE          = 4;
var ENTITY_REFERENCE_NODE       = NodeType.ENTITY_REFERENCE_NODE       = 5;
var ENTITY_NODE                 = NodeType.ENTITY_NODE                 = 6;
var PROCESSING_INSTRUCTION_NODE = NodeType.PROCESSING_INSTRUCTION_NODE = 7;
var COMMENT_NODE                = NodeType.COMMENT_NODE                = 8;
var DOCUMENT_NODE               = NodeType.DOCUMENT_NODE               = 9;
var DOCUMENT_TYPE_NODE          = NodeType.DOCUMENT_TYPE_NODE          = 10;
var DOCUMENT_FRAGMENT_NODE      = NodeType.DOCUMENT_FRAGMENT_NODE      = 11;
var NOTATION_NODE               = NodeType.NOTATION_NODE               = 12;

// ExceptionCode
var ExceptionCode = {}
var ExceptionMessage = {};
var INDEX_SIZE_ERR              = ExceptionCode.INDEX_SIZE_ERR              = ((ExceptionMessage[1]="Index size error"),1);
var DOMSTRING_SIZE_ERR          = ExceptionCode.DOMSTRING_SIZE_ERR          = ((ExceptionMessage[2]="DOMString size error"),2);
var HIERARCHY_REQUEST_ERR       = ExceptionCode.HIERARCHY_REQUEST_ERR       = ((ExceptionMessage[3]="Hierarchy request error"),3);
var WRONG_DOCUMENT_ERR          = ExceptionCode.WRONG_DOCUMENT_ERR          = ((ExceptionMessage[4]="Wrong document"),4);
var INVALID_CHARACTER_ERR       = ExceptionCode.INVALID_CHARACTER_ERR       = ((ExceptionMessage[5]="Invalid character"),5);
var NO_DATA_ALLOWED_ERR         = ExceptionCode.NO_DATA_ALLOWED_ERR         = ((ExceptionMessage[6]="No data allowed"),6);
var NO_MODIFICATION_ALLOWED_ERR = ExceptionCode.NO_MODIFICATION_ALLOWED_ERR = ((ExceptionMessage[7]="No modification allowed"),7);
var NOT_FOUND_ERR               = ExceptionCode.NOT_FOUND_ERR               = ((ExceptionMessage[8]="Not found"),8);
var NOT_SUPPORTED_ERR           = ExceptionCode.NOT_SUPPORTED_ERR           = ((ExceptionMessage[9]="Not supported"),9);
var INUSE_ATTRIBUTE_ERR         = ExceptionCode.INUSE_ATTRIBUTE_ERR         = ((ExceptionMessage[10]="Attribute in use"),10);
//level2
var INVALID_STATE_ERR        	= ExceptionCode.INVALID_STATE_ERR        	= ((ExceptionMessage[11]="Invalid state"),11);
var SYNTAX_ERR               	= ExceptionCode.SYNTAX_ERR               	= ((ExceptionMessage[12]="Syntax error"),12);
var INVALID_MODIFICATION_ERR 	= ExceptionCode.INVALID_MODIFICATION_ERR 	= ((ExceptionMessage[13]="Invalid modification"),13);
var NAMESPACE_ERR            	= ExceptionCode.NAMESPACE_ERR           	= ((ExceptionMessage[14]="Invalid namespace"),14);
var INVALID_ACCESS_ERR       	= ExceptionCode.INVALID_ACCESS_ERR      	= ((ExceptionMessage[15]="Invalid access"),15);

/**
 * DOM Level 2
 * Object DOMException
 * @see http://www.w3.org/TR/2000/REC-DOM-Level-2-Core-20001113/ecma-script-binding.html
 * @see http://www.w3.org/TR/REC-DOM-Level-1/ecma-script-language-binding.html
 */
function DOMException(code, message) {
	if(message instanceof Error){
		var error = message;
	}else{
		error = this;
		Error.call(this, ExceptionMessage[code]);
		this.message = ExceptionMessage[code];
		if(Error.captureStackTrace) Error.captureStackTrace(this, DOMException);
	}
	error.code = code;
	if(message) this.message = this.message + ": " + message;
	return error;
};
DOMException.prototype = Error.prototype;
copy(ExceptionCode,DOMException)

/**
 * @see http://www.w3.org/TR/2000/REC-DOM-Level-2-Core-20001113/core.html#ID-536297177
 * The NodeList interface provides the abstraction of an ordered collection of nodes, without defining or constraining how this collection is implemented. NodeList objects in the DOM are live.
 * The items in the NodeList are accessible via an integral index, starting from 0.
 */
function NodeList() {
};
NodeList.prototype = {
	/**
	 * The number of nodes in the list. The range of valid child node indices is 0 to length-1 inclusive.
	 * @standard level1
	 */
	length:0, 
	/**
	 * Returns the indexth item in the collection. If index is greater than or equal to the number of nodes in the list, this returns null.
	 * @standard level1
	 * @param index  unsigned long 
	 *   Index into the collection.
	 * @return Node
	 * 	The node at the indexth position in the NodeList, or null if that is not a valid index. 
	 */
	item: function(index) {
		return this[index] || null;
	},
	toString:function(isHTML,nodeFilter){
		for(var buf = [], i = 0;i<this.length;i++){
			serializeToString(this[i],buf,isHTML,nodeFilter);
		}
		return buf.join('');
	}
};

function LiveNodeList(node,refresh){
	this._node = node;
	this._refresh = refresh
	_updateLiveList(this);
}
function _updateLiveList(list){
	var inc = list._node._inc || list._node.ownerDocument._inc;
	if(list._inc != inc){
		var ls = list._refresh(list._node);
		//console.log(ls.length)
		__set__(list,'length',ls.length);
		copy(ls,list);
		list._inc = inc;
	}
}
LiveNodeList.prototype.item = function(i){
	_updateLiveList(this);
	return this[i];
}

_extends(LiveNodeList,NodeList);

/**
 * Objects implementing the NamedNodeMap interface are used
 * to represent collections of nodes that can be accessed by name.
 * Note that NamedNodeMap does not inherit from NodeList;
 * NamedNodeMaps are not maintained in any particular order.
 * Objects contained in an object implementing NamedNodeMap may also be accessed by an ordinal index,
 * but this is simply to allow convenient enumeration of the contents of a NamedNodeMap,
 * and does not imply that the DOM specifies an order to these Nodes.
 * NamedNodeMap objects in the DOM are live.
 * used for attributes or DocumentType entities 
 */
function NamedNodeMap() {
};

function _findNodeIndex(list,node){
	var i = list.length;
	while(i--){
		if(list[i] === node){return i}
	}
}

function _addNamedNode(el,list,newAttr,oldAttr){
	if(oldAttr){
		list[_findNodeIndex(list,oldAttr)] = newAttr;
	}else{
		list[list.length++] = newAttr;
	}
	if(el){
		newAttr.ownerElement = el;
		var doc = el.ownerDocument;
		if(doc){
			oldAttr && _onRemoveAttribute(doc,el,oldAttr);
			_onAddAttribute(doc,el,newAttr);
		}
	}
}
function _removeNamedNode(el,list,attr){
	//console.log('remove attr:'+attr)
	var i = _findNodeIndex(list,attr);
	if(i>=0){
		var lastIndex = list.length-1
		while(i<lastIndex){
			list[i] = list[++i]
		}
		list.length = lastIndex;
		if(el){
			var doc = el.ownerDocument;
			if(doc){
				_onRemoveAttribute(doc,el,attr);
				attr.ownerElement = null;
			}
		}
	}else{
		throw DOMException(NOT_FOUND_ERR,new Error(el.tagName+'@'+attr))
	}
}
NamedNodeMap.prototype = {
	length:0,
	item:NodeList.prototype.item,
	getNamedItem: function(key) {
//		if(key.indexOf(':')>0 || key == 'xmlns'){
//			return null;
//		}
		//console.log()
		var i = this.length;
		while(i--){
			var attr = this[i];
			//console.log(attr.nodeName,key)
			if(attr.nodeName == key){
				return attr;
			}
		}
	},
	setNamedItem: function(attr) {
		var el = attr.ownerElement;
		if(el && el!=this._ownerElement){
			throw new DOMException(INUSE_ATTRIBUTE_ERR);
		}
		var oldAttr = this.getNamedItem(attr.nodeName);
		_addNamedNode(this._ownerElement,this,attr,oldAttr);
		return oldAttr;
	},
	/* returns Node */
	setNamedItemNS: function(attr) {// raises: WRONG_DOCUMENT_ERR,NO_MODIFICATION_ALLOWED_ERR,INUSE_ATTRIBUTE_ERR
		var el = attr.ownerElement, oldAttr;
		if(el && el!=this._ownerElement){
			throw new DOMException(INUSE_ATTRIBUTE_ERR);
		}
		oldAttr = this.getNamedItemNS(attr.namespaceURI,attr.localName);
		_addNamedNode(this._ownerElement,this,attr,oldAttr);
		return oldAttr;
	},

	/* returns Node */
	removeNamedItem: function(key) {
		var attr = this.getNamedItem(key);
		_removeNamedNode(this._ownerElement,this,attr);
		return attr;
		
		
	},// raises: NOT_FOUND_ERR,NO_MODIFICATION_ALLOWED_ERR
	
	//for level2
	removeNamedItemNS:function(namespaceURI,localName){
		var attr = this.getNamedItemNS(namespaceURI,localName);
		_removeNamedNode(this._ownerElement,this,attr);
		return attr;
	},
	getNamedItemNS: function(namespaceURI, localName) {
		var i = this.length;
		while(i--){
			var node = this[i];
			if(node.localName == localName && node.namespaceURI == namespaceURI){
				return node;
			}
		}
		return null;
	}
};

/**
 * The DOMImplementation interface represents an object providing methods
 * which are not dependent on any particular document.
 * Such an object is returned by the `Document.implementation` property.
 *
 * __The individual methods describe the differences compared to the specs.__
 *
 * @constructor
 *
 * @see https://developer.mozilla.org/en-US/docs/Web/API/DOMImplementation MDN
 * @see https://www.w3.org/TR/REC-DOM-Level-1/level-one-core.html#ID-102161490 DOM Level 1 Core (Initial)
 * @see https://www.w3.org/TR/DOM-Level-2-Core/core.html#ID-102161490 DOM Level 2 Core
 * @see https://www.w3.org/TR/DOM-Level-3-Core/core.html#ID-102161490 DOM Level 3 Core
 * @see https://dom.spec.whatwg.org/#domimplementation DOM Living Standard
 */
function DOMImplementation() {
}

DOMImplementation.prototype = {
	/**
	 * The DOMImplementation.hasFeature() method returns a Boolean flag indicating if a given feature is supported.
	 * The different implementations fairly diverged in what kind of features were reported.
	 * The latest version of the spec settled to force this method to always return true, where the functionality was accurate and in use.
	 *
	 * @deprecated It is deprecated and modern browsers return true in all cases.
	 *
	 * @param {string} feature
	 * @param {string} [version]
	 * @returns {boolean} always true
	 *
	 * @see https://developer.mozilla.org/en-US/docs/Web/API/DOMImplementation/hasFeature MDN
	 * @see https://www.w3.org/TR/REC-DOM-Level-1/level-one-core.html#ID-5CED94D7 DOM Level 1 Core
	 * @see https://dom.spec.whatwg.org/#dom-domimplementation-hasfeature DOM Living Standard
	 */
	hasFeature: function(feature, version) {
			return true;
	},
	/**
	 * Creates an XML Document object of the specified type with its document element.
	 *
	 * __It behaves slightly different from the description in the living standard__:
	 * - There is no interface/class `XMLDocument`, it returns a `Document` instance.
	 * - `contentType`, `encoding`, `mode`, `origin`, `url` fields are currently not declared.
	 * - this implementation is not validating names or qualified names
	 *   (when parsing XML strings, the SAX parser takes care of that)
	 *
	 * @param {string|null} namespaceURI
	 * @param {string} qualifiedName
	 * @param {DocumentType=null} doctype
	 * @returns {Document}
	 *
	 * @see https://developer.mozilla.org/en-US/docs/Web/API/DOMImplementation/createDocument MDN
	 * @see https://www.w3.org/TR/DOM-Level-2-Core/core.html#Level-2-Core-DOM-createDocument DOM Level 2 Core (initial)
	 * @see https://dom.spec.whatwg.org/#dom-domimplementation-createdocument  DOM Level 2 Core
	 *
	 * @see https://dom.spec.whatwg.org/#validate-and-extract DOM: Validate and extract
	 * @see https://www.w3.org/TR/xml/#NT-NameStartChar XML Spec: Names
	 * @see https://www.w3.org/TR/xml-names/#ns-qualnames XML Namespaces: Qualified names
	 */
	createDocument: function(namespaceURI,  qualifiedName, doctype){
		var doc = new Document();
		doc.implementation = this;
		doc.childNodes = new NodeList();
		doc.doctype = doctype || null;
		if (doctype){
			doc.appendChild(doctype);
		}
		if (qualifiedName){
			var root = doc.createElementNS(namespaceURI, qualifiedName);
			doc.appendChild(root);
		}
		return doc;
	},
	/**
	 * Returns a doctype, with the given `qualifiedName`, `publicId`, and `systemId`.
	 *
	 * __This behavior is slightly different from the in the specs__:
	 * - this implementation is not validating names or qualified names
	 *   (when parsing XML strings, the SAX parser takes care of that)
	 *
	 * @param {string} qualifiedName
	 * @param {string} [publicId]
	 * @param {string} [systemId]
	 * @returns {DocumentType} which can either be used with `DOMImplementation.createDocument` upon document creation
	 * 				  or can be put into the document via methods like `Node.insertBefore()` or `Node.replaceChild()`
	 *
	 * @see https://developer.mozilla.org/en-US/docs/Web/API/DOMImplementation/createDocumentType MDN
	 * @see https://www.w3.org/TR/DOM-Level-2-Core/core.html#Level-2-Core-DOM-createDocType DOM Level 2 Core
	 * @see https://dom.spec.whatwg.org/#dom-domimplementation-createdocumenttype DOM Living Standard
	 *
	 * @see https://dom.spec.whatwg.org/#validate-and-extract DOM: Validate and extract
	 * @see https://www.w3.org/TR/xml/#NT-NameStartChar XML Spec: Names
	 * @see https://www.w3.org/TR/xml-names/#ns-qualnames XML Namespaces: Qualified names
	 */
	createDocumentType: function(qualifiedName, publicId, systemId){
		var node = new DocumentType();
		node.name = qualifiedName;
		node.nodeName = qualifiedName;
		node.publicId = publicId || '';
		node.systemId = systemId || '';

		return node;
	}
};


/**
 * @see http://www.w3.org/TR/2000/REC-DOM-Level-2-Core-20001113/core.html#ID-1950641247
 */

function Node() {
};

Node.prototype = {
	firstChild : null,
	lastChild : null,
	previousSibling : null,
	nextSibling : null,
	attributes : null,
	parentNode : null,
	childNodes : null,
	ownerDocument : null,
	nodeValue : null,
	namespaceURI : null,
	prefix : null,
	localName : null,
	// Modified in DOM Level 2:
	insertBefore:function(newChild, refChild){//raises 
		return _insertBefore(this,newChild,refChild);
	},
	replaceChild:function(newChild, oldChild){//raises 
		this.insertBefore(newChild,oldChild);
		if(oldChild){
			this.removeChild(oldChild);
		}
	},
	removeChild:function(oldChild){
		return _removeChild(this,oldChild);
	},
	appendChild:function(newChild){
		return this.insertBefore(newChild,null);
	},
	hasChildNodes:function(){
		return this.firstChild != null;
	},
	cloneNode:function(deep){
		return cloneNode(this.ownerDocument||this,this,deep);
	},
	// Modified in DOM Level 2:
	normalize:function(){
		var child = this.firstChild;
		while(child){
			var next = child.nextSibling;
			if(next && next.nodeType == TEXT_NODE && child.nodeType == TEXT_NODE){
				this.removeChild(next);
				child.appendData(next.data);
			}else{
				child.normalize();
				child = next;
			}
		}
	},
  	// Introduced in DOM Level 2:
	isSupported:function(feature, version){
		return this.ownerDocument.implementation.hasFeature(feature,version);
	},
    // Introduced in DOM Level 2:
    hasAttributes:function(){
    	return this.attributes.length>0;
    },
	/**
	 * Look up the prefix associated to the given namespace URI, starting from this node.
	 * **The default namespace declarations are ignored by this method.**
	 * See Namespace Prefix Lookup for details on the algorithm used by this method.
	 *
	 * _Note: The implementation seems to be incomplete when compared to the algorithm described in the specs._
	 *
	 * @param {string | null} namespaceURI
	 * @returns {string | null}
	 * @see https://www.w3.org/TR/DOM-Level-3-Core/core.html#Node3-lookupNamespacePrefix
	 * @see https://www.w3.org/TR/DOM-Level-3-Core/namespaces-algorithms.html#lookupNamespacePrefixAlgo
	 * @see https://dom.spec.whatwg.org/#dom-node-lookupprefix
	 * @see https://github.com/xmldom/xmldom/issues/322
	 */
    lookupPrefix:function(namespaceURI){
    	var el = this;
    	while(el){
    		var map = el._nsMap;
    		//console.dir(map)
    		if(map){
    			for(var n in map){
    				if(map[n] == namespaceURI){
    					return n;
    				}
    			}
    		}
    		el = el.nodeType == ATTRIBUTE_NODE?el.ownerDocument : el.parentNode;
    	}
    	return null;
    },
    // Introduced in DOM Level 3:
    lookupNamespaceURI:function(prefix){
    	var el = this;
    	while(el){
    		var map = el._nsMap;
    		//console.dir(map)
    		if(map){
    			if(prefix in map){
    				return map[prefix] ;
    			}
    		}
    		el = el.nodeType == ATTRIBUTE_NODE?el.ownerDocument : el.parentNode;
    	}
    	return null;
    },
    // Introduced in DOM Level 3:
    isDefaultNamespace:function(namespaceURI){
    	var prefix = this.lookupPrefix(namespaceURI);
    	return prefix == null;
    }
};


function _xmlEncoder(c){
	return c == '<' && '&lt;' ||
         c == '>' && '&gt;' ||
         c == '&' && '&amp;' ||
         c == '"' && '&quot;' ||
         '&#'+c.charCodeAt()+';'
}


copy(NodeType,Node);
copy(NodeType,Node.prototype);

/**
 * @param callback return true for continue,false for break
 * @return boolean true: break visit;
 */
function _visitNode(node,callback){
	if(callback(node)){
		return true;
	}
	if(node = node.firstChild){
		do{
			if(_visitNode(node,callback)){return true}
        }while(node=node.nextSibling)
    }
}



function Document(){
}

function _onAddAttribute(doc,el,newAttr){
	doc && doc._inc++;
	var ns = newAttr.namespaceURI ;
	if(ns === NAMESPACE.XMLNS){
		//update namespace
		el._nsMap[newAttr.prefix?newAttr.localName:''] = newAttr.value
	}
}

function _onRemoveAttribute(doc,el,newAttr,remove){
	doc && doc._inc++;
	var ns = newAttr.namespaceURI ;
	if(ns === NAMESPACE.XMLNS){
		//update namespace
		delete el._nsMap[newAttr.prefix?newAttr.localName:'']
	}
}

/**
 * Updates `el.childNodes`, updating the indexed items and it's `length`.
 * Passing `newChild` means it will be appended.
 * Otherwise it's assumed that an item has been removed,
 * and `el.firstNode` and it's `.nextSibling` are used
 * to walk the current list of child nodes.
 *
 * @param {Document} doc
 * @param {Node} el
 * @param {Node} [newChild]
 * @private
 */
function _onUpdateChild (doc, el, newChild) {
	if(doc && doc._inc){
		doc._inc++;
		//update childNodes
		var cs = el.childNodes;
		if (newChild) {
			cs[cs.length++] = newChild;
		} else {
			var child = el.firstChild;
			var i = 0;
			while (child) {
				cs[i++] = child;
				child = child.nextSibling;
			}
			cs.length = i;
			delete cs[cs.length];
		}
	}
}

/**
 * Removes the connections between `parentNode` and `child`
 * and any existing `child.previousSibling` or `child.nextSibling`.
 *
 * @see https://github.com/xmldom/xmldom/issues/135
 * @see https://github.com/xmldom/xmldom/issues/145
 *
 * @param {Node} parentNode
 * @param {Node} child
 * @returns {Node} the child that was removed.
 * @private
 */
function _removeChild (parentNode, child) {
	var previous = child.previousSibling;
	var next = child.nextSibling;
	if (previous) {
		previous.nextSibling = next;
	} else {
		parentNode.firstChild = next;
	}
	if (next) {
		next.previousSibling = previous;
	} else {
		parentNode.lastChild = previous;
	}
	child.parentNode = null;
	child.previousSibling = null;
	child.nextSibling = null;
	_onUpdateChild(parentNode.ownerDocument, parentNode);
	return child;
}
/**
 * preformance key(refChild == null)
 */
function _insertBefore(parentNode,newChild,nextChild){
	var cp = newChild.parentNode;
	if(cp){
		cp.removeChild(newChild);//remove and update
	}
	if(newChild.nodeType === DOCUMENT_FRAGMENT_NODE){
		var newFirst = newChild.firstChild;
		if (newFirst == null) {
			return newChild;
		}
		var newLast = newChild.lastChild;
	}else{
		newFirst = newLast = newChild;
	}
	var pre = nextChild ? nextChild.previousSibling : parentNode.lastChild;

	newFirst.previousSibling = pre;
	newLast.nextSibling = nextChild;
	
	
	if(pre){
		pre.nextSibling = newFirst;
	}else{
		parentNode.firstChild = newFirst;
	}
	if(nextChild == null){
		parentNode.lastChild = newLast;
	}else{
		nextChild.previousSibling = newLast;
	}
	do{
		newFirst.parentNode = parentNode;
	}while(newFirst !== newLast && (newFirst= newFirst.nextSibling))
	_onUpdateChild(parentNode.ownerDocument||parentNode,parentNode);
	//console.log(parentNode.lastChild.nextSibling == null)
	if (newChild.nodeType == DOCUMENT_FRAGMENT_NODE) {
		newChild.firstChild = newChild.lastChild = null;
	}
	return newChild;
}

/**
 * Appends `newChild` to `parentNode`.
 * If `newChild` is already connected to a `parentNode` it is first removed from it.
 *
 * @see https://github.com/xmldom/xmldom/issues/135
 * @see https://github.com/xmldom/xmldom/issues/145
 * @param {Node} parentNode
 * @param {Node} newChild
 * @returns {Node}
 * @private
 */
function _appendSingleChild (parentNode, newChild) {
	if (newChild.parentNode) {
		newChild.parentNode.removeChild(newChild);
	}
	newChild.parentNode = parentNode;
	newChild.previousSibling = parentNode.lastChild;
	newChild.nextSibling = null;
	if (newChild.previousSibling) {
		newChild.previousSibling.nextSibling = newChild;
	} else {
		parentNode.firstChild = newChild;
	}
	parentNode.lastChild = newChild;
	_onUpdateChild(parentNode.ownerDocument, parentNode, newChild);
	return newChild;
}

Document.prototype = {
	//implementation : null,
	nodeName :  '#document',
	nodeType :  DOCUMENT_NODE,
	/**
	 * The DocumentType node of the document.
	 *
	 * @readonly
	 * @type DocumentType
	 */
	doctype :  null,
	documentElement :  null,
	_inc : 1,

	insertBefore :  function(newChild, refChild){//raises
		if(newChild.nodeType == DOCUMENT_FRAGMENT_NODE){
			var child = newChild.firstChild;
			while(child){
				var next = child.nextSibling;
				this.insertBefore(child,refChild);
				child = next;
			}
			return newChild;
		}
		if(this.documentElement == null && newChild.nodeType == ELEMENT_NODE){
			this.documentElement = newChild;
		}

		return _insertBefore(this,newChild,refChild),(newChild.ownerDocument = this),newChild;
	},
	removeChild :  function(oldChild){
		if(this.documentElement == oldChild){
			this.documentElement = null;
		}
		return _removeChild(this,oldChild);
	},
	// Introduced in DOM Level 2:
	importNode : function(importedNode,deep){
		return importNode(this,importedNode,deep);
	},
	// Introduced in DOM Level 2:
	getElementById :	function(id){
		var rtv = null;
		_visitNode(this.documentElement,function(node){
			if(node.nodeType == ELEMENT_NODE){
				if(node.getAttribute('id') == id){
					rtv = node;
					return true;
				}
			}
		})
		return rtv;
	},

	/**
	 * The `getElementsByClassName` method of `Document` interface returns an array-like object
	 * of all child elements which have **all** of the given class name(s).
	 *
	 * Returns an empty list if `classeNames` is an empty string or only contains HTML white space characters.
	 *
	 *
	 * Warning: This is a live LiveNodeList.
	 * Changes in the DOM will reflect in the array as the changes occur.
	 * If an element selected by this array no longer qualifies for the selector,
	 * it will automatically be removed. Be aware of this for iteration purposes.
	 *
	 * @param {string} classNames is a string representing the class name(s) to match; multiple class names are separated by (ASCII-)whitespace
	 *
	 * @see https://developer.mozilla.org/en-US/docs/Web/API/Document/getElementsByClassName
	 * @see https://dom.spec.whatwg.org/#concept-getelementsbyclassname
	 */
	getElementsByClassName: function(classNames) {
		var classNamesSet = toOrderedSet(classNames)
		return new LiveNodeList(this, function(base) {
			var ls = [];
			if (classNamesSet.length > 0) {
				_visitNode(base.documentElement, function(node) {
					if(node !== base && node.nodeType === ELEMENT_NODE) {
						var nodeClassNames = node.getAttribute('class')
						// can be null if the attribute does not exist
						if (nodeClassNames) {
							// before splitting and iterating just compare them for the most common case
							var matches = classNames === nodeClassNames;
							if (!matches) {
								var nodeClassNamesSet = toOrderedSet(nodeClassNames)
								matches = classNamesSet.every(arrayIncludes(nodeClassNamesSet))
							}
							if(matches) {
								ls.push(node);
							}
						}
					}
				});
			}
			return ls;
		});
	},

	//document factory method:
	createElement :	function(tagName){
		var node = new Element();
		node.ownerDocument = this;
		node.nodeName = tagName;
		node.tagName = tagName;
		node.localName = tagName;
		node.childNodes = new NodeList();
		var attrs	= node.attributes = new NamedNodeMap();
		attrs._ownerElement = node;
		return node;
	},
	createDocumentFragment :	function(){
		var node = new DocumentFragment();
		node.ownerDocument = this;
		node.childNodes = new NodeList();
		return node;
	},
	createTextNode :	function(data){
		var node = new Text();
		node.ownerDocument = this;
		node.appendData(data)
		return node;
	},
	createComment :	function(data){
		var node = new Comment();
		node.ownerDocument = this;
		node.appendData(data)
		return node;
	},
	createCDATASection :	function(data){
		var node = new CDATASection();
		node.ownerDocument = this;
		node.appendData(data)
		return node;
	},
	createProcessingInstruction :	function(target,data){
		var node = new ProcessingInstruction();
		node.ownerDocument = this;
		node.tagName = node.target = target;
		node.nodeValue= node.data = data;
		return node;
	},
	createAttribute :	function(name){
		var node = new Attr();
		node.ownerDocument	= this;
		node.name = name;
		node.nodeName	= name;
		node.localName = name;
		node.specified = true;
		return node;
	},
	createEntityReference :	function(name){
		var node = new EntityReference();
		node.ownerDocument	= this;
		node.nodeName	= name;
		return node;
	},
	// Introduced in DOM Level 2:
	createElementNS :	function(namespaceURI,qualifiedName){
		var node = new Element();
		var pl = qualifiedName.split(':');
		var attrs	= node.attributes = new NamedNodeMap();
		node.childNodes = new NodeList();
		node.ownerDocument = this;
		node.nodeName = qualifiedName;
		node.tagName = qualifiedName;
		node.namespaceURI = namespaceURI;
		if(pl.length == 2){
			node.prefix = pl[0];
			node.localName = pl[1];
		}else{
			//el.prefix = null;
			node.localName = qualifiedName;
		}
		attrs._ownerElement = node;
		return node;
	},
	// Introduced in DOM Level 2:
	createAttributeNS :	function(namespaceURI,qualifiedName){
		var node = new Attr();
		var pl = qualifiedName.split(':');
		node.ownerDocument = this;
		node.nodeName = qualifiedName;
		node.name = qualifiedName;
		node.namespaceURI = namespaceURI;
		node.specified = true;
		if(pl.length == 2){
			node.prefix = pl[0];
			node.localName = pl[1];
		}else{
			//el.prefix = null;
			node.localName = qualifiedName;
		}
		return node;
	}
};
_extends(Document,Node);


function Element() {
	this._nsMap = {};
};
Element.prototype = {
	nodeType : ELEMENT_NODE,
	hasAttribute : function(name){
		return this.getAttributeNode(name)!=null;
	},
	getAttribute : function(name){
		var attr = this.getAttributeNode(name);
		return attr && attr.value || '';
	},
	getAttributeNode : function(name){
		return this.attributes.getNamedItem(name);
	},
	setAttribute : function(name, value){
		var attr = this.ownerDocument.createAttribute(name);
		attr.value = attr.nodeValue = "" + value;
		this.setAttributeNode(attr)
	},
	removeAttribute : function(name){
		var attr = this.getAttributeNode(name)
		attr && this.removeAttributeNode(attr);
	},
	
	//four real opeartion method
	appendChild:function(newChild){
		if(newChild.nodeType === DOCUMENT_FRAGMENT_NODE){
			return this.insertBefore(newChild,null);
		}else{
			return _appendSingleChild(this,newChild);
		}
	},
	setAttributeNode : function(newAttr){
		return this.attributes.setNamedItem(newAttr);
	},
	setAttributeNodeNS : function(newAttr){
		return this.attributes.setNamedItemNS(newAttr);
	},
	removeAttributeNode : function(oldAttr){
		//console.log(this == oldAttr.ownerElement)
		return this.attributes.removeNamedItem(oldAttr.nodeName);
	},
	//get real attribute name,and remove it by removeAttributeNode
	removeAttributeNS : function(namespaceURI, localName){
		var old = this.getAttributeNodeNS(namespaceURI, localName);
		old && this.removeAttributeNode(old);
	},
	
	hasAttributeNS : function(namespaceURI, localName){
		return this.getAttributeNodeNS(namespaceURI, localName)!=null;
	},
	getAttributeNS : function(namespaceURI, localName){
		var attr = this.getAttributeNodeNS(namespaceURI, localName);
		return attr && attr.value || '';
	},
	setAttributeNS : function(namespaceURI, qualifiedName, value){
		var attr = this.ownerDocument.createAttributeNS(namespaceURI, qualifiedName);
		attr.value = attr.nodeValue = "" + value;
		this.setAttributeNode(attr)
	},
	getAttributeNodeNS : function(namespaceURI, localName){
		return this.attributes.getNamedItemNS(namespaceURI, localName);
	},
	
	getElementsByTagName : function(tagName){
		return new LiveNodeList(this,function(base){
			var ls = [];
			_visitNode(base,function(node){
				if(node !== base && node.nodeType == ELEMENT_NODE && (tagName === '*' || node.tagName == tagName)){
					ls.push(node);
				}
			});
			return ls;
		});
	},
	getElementsByTagNameNS : function(namespaceURI, localName){
		return new LiveNodeList(this,function(base){
			var ls = [];
			_visitNode(base,function(node){
				if(node !== base && node.nodeType === ELEMENT_NODE && (namespaceURI === '*' || node.namespaceURI === namespaceURI) && (localName === '*' || node.localName == localName)){
					ls.push(node);
				}
			});
			return ls;
			
		});
	}
};
Document.prototype.getElementsByTagName = Element.prototype.getElementsByTagName;
Document.prototype.getElementsByTagNameNS = Element.prototype.getElementsByTagNameNS;


_extends(Element,Node);
function Attr() {
};
Attr.prototype.nodeType = ATTRIBUTE_NODE;
_extends(Attr,Node);


function CharacterData() {
};
CharacterData.prototype = {
	data : '',
	substringData : function(offset, count) {
		return this.data.substring(offset, offset+count);
	},
	appendData: function(text) {
		text = this.data+text;
		this.nodeValue = this.data = text;
		this.length = text.length;
	},
	insertData: function(offset,text) {
		this.replaceData(offset,0,text);
	
	},
	appendChild:function(newChild){
		throw new Error(ExceptionMessage[HIERARCHY_REQUEST_ERR])
	},
	deleteData: function(offset, count) {
		this.replaceData(offset,count,"");
	},
	replaceData: function(offset, count, text) {
		var start = this.data.substring(0,offset);
		var end = this.data.substring(offset+count);
		text = start + text + end;
		this.nodeValue = this.data = text;
		this.length = text.length;
	}
}
_extends(CharacterData,Node);
function Text() {
};
Text.prototype = {
	nodeName : "#text",
	nodeType : TEXT_NODE,
	splitText : function(offset) {
		var text = this.data;
		var newText = text.substring(offset);
		text = text.substring(0, offset);
		this.data = this.nodeValue = text;
		this.length = text.length;
		var newNode = this.ownerDocument.createTextNode(newText);
		if(this.parentNode){
			this.parentNode.insertBefore(newNode, this.nextSibling);
		}
		return newNode;
	}
}
_extends(Text,CharacterData);
function Comment() {
};
Comment.prototype = {
	nodeName : "#comment",
	nodeType : COMMENT_NODE
}
_extends(Comment,CharacterData);

function CDATASection() {
};
CDATASection.prototype = {
	nodeName : "#cdata-section",
	nodeType : CDATA_SECTION_NODE
}
_extends(CDATASection,CharacterData);


function DocumentType() {
};
DocumentType.prototype.nodeType = DOCUMENT_TYPE_NODE;
_extends(DocumentType,Node);

function Notation() {
};
Notation.prototype.nodeType = NOTATION_NODE;
_extends(Notation,Node);

function Entity() {
};
Entity.prototype.nodeType = ENTITY_NODE;
_extends(Entity,Node);

function EntityReference() {
};
EntityReference.prototype.nodeType = ENTITY_REFERENCE_NODE;
_extends(EntityReference,Node);

function DocumentFragment() {
};
DocumentFragment.prototype.nodeName =	"#document-fragment";
DocumentFragment.prototype.nodeType =	DOCUMENT_FRAGMENT_NODE;
_extends(DocumentFragment,Node);


function ProcessingInstruction() {
}
ProcessingInstruction.prototype.nodeType = PROCESSING_INSTRUCTION_NODE;
_extends(ProcessingInstruction,Node);
function XMLSerializer(){}
XMLSerializer.prototype.serializeToString = function(node,isHtml,nodeFilter){
	return nodeSerializeToString.call(node,isHtml,nodeFilter);
}
Node.prototype.toString = nodeSerializeToString;
function nodeSerializeToString(isHtml,nodeFilter){
	var buf = [];
	var refNode = this.nodeType == 9 && this.documentElement || this;
	var prefix = refNode.prefix;
	var uri = refNode.namespaceURI;
	
	if(uri && prefix == null){
		//console.log(prefix)
		var prefix = refNode.lookupPrefix(uri);
		if(prefix == null){
			//isHTML = true;
			var visibleNamespaces=[
			{namespace:uri,prefix:null}
			//{namespace:uri,prefix:''}
			]
		}
	}
	serializeToString(this,buf,isHtml,nodeFilter,visibleNamespaces);
	//console.log('###',this.nodeType,uri,prefix,buf.join(''))
	return buf.join('');
}

function needNamespaceDefine(node, isHTML, visibleNamespaces) {
	var prefix = node.prefix || '';
	var uri = node.namespaceURI;
	// According to [Namespaces in XML 1.0](https://www.w3.org/TR/REC-xml-names/#ns-using) ,
	// and more specifically https://www.w3.org/TR/REC-xml-names/#nsc-NoPrefixUndecl :
	// > In a namespace declaration for a prefix [...], the attribute value MUST NOT be empty.
	// in a similar manner [Namespaces in XML 1.1](https://www.w3.org/TR/xml-names11/#ns-using)
	// and more specifically https://www.w3.org/TR/xml-names11/#nsc-NSDeclared :
	// > [...] Furthermore, the attribute value [...] must not be an empty string.
	// so serializing empty namespace value like xmlns:ds="" would produce an invalid XML document.
	if (!uri) {
		return false;
	}
	if (prefix === "xml" && uri === NAMESPACE.XML || uri === NAMESPACE.XMLNS) {
		return false;
	}
	
	var i = visibleNamespaces.length 
	while (i--) {
		var ns = visibleNamespaces[i];
		// get namespace prefix
		if (ns.prefix === prefix) {
			return ns.namespace !== uri;
		}
	}
	return true;
}
/**
 * Well-formed constraint: No < in Attribute Values
 * > The replacement text of any entity referred to directly or indirectly
 * > in an attribute value must not contain a <.
 * @see https://www.w3.org/TR/xml11/#CleanAttrVals
 * @see https://www.w3.org/TR/xml11/#NT-AttValue
 *
 * Literal whitespace other than space that appear in attribute values
 * are serialized as their entity references, so they will be preserved.
 * (In contrast to whitespace literals in the input which are normalized to spaces)
 * @see https://www.w3.org/TR/xml11/#AVNormalize
 * @see https://w3c.github.io/DOM-Parsing/#serializing-an-element-s-attributes
 */
function addSerializedAttribute(buf, qualifiedName, value) {
	buf.push(' ', qualifiedName, '="', value.replace(/[<>&"\t\n\r]/g, _xmlEncoder), '"')
}

function serializeToString(node,buf,isHTML,nodeFilter,visibleNamespaces){
	if (!visibleNamespaces) {
		visibleNamespaces = [];
	}

	if(nodeFilter){
		node = nodeFilter(node);
		if(node){
			if(typeof node == 'string'){
				buf.push(node);
				return;
			}
		}else{
			return;
		}
		//buf.sort.apply(attrs, attributeSorter);
	}

	switch(node.nodeType){
	case ELEMENT_NODE:
		var attrs = node.attributes;
		var len = attrs.length;
		var child = node.firstChild;
		var nodeName = node.tagName;
		
		isHTML = NAMESPACE.isHTML(node.namespaceURI) || isHTML

		var prefixedNodeName = nodeName
		if (!isHTML && !node.prefix && node.namespaceURI) {
			var defaultNS
			// lookup current default ns from `xmlns` attribute
			for (var ai = 0; ai < attrs.length; ai++) {
				if (attrs.item(ai).name === 'xmlns') {
					defaultNS = attrs.item(ai).value
					break
				}
			}
			if (!defaultNS) {
				// lookup current default ns in visibleNamespaces
				for (var nsi = visibleNamespaces.length - 1; nsi >= 0; nsi--) {
					var namespace = visibleNamespaces[nsi]
					if (namespace.prefix === '' && namespace.namespace === node.namespaceURI) {
						defaultNS = namespace.namespace
						break
					}
				}
			}
			if (defaultNS !== node.namespaceURI) {
				for (var nsi = visibleNamespaces.length - 1; nsi >= 0; nsi--) {
					var namespace = visibleNamespaces[nsi]
					if (namespace.namespace === node.namespaceURI) {
						if (namespace.prefix) {
							prefixedNodeName = namespace.prefix + ':' + nodeName
						}
						break
					}
				}
			}
		}

		buf.push('<', prefixedNodeName);

		for(var i=0;i<len;i++){
			// add namespaces for attributes
			var attr = attrs.item(i);
			if (attr.prefix == 'xmlns') {
				visibleNamespaces.push({ prefix: attr.localName, namespace: attr.value });
			}else if(attr.nodeName == 'xmlns'){
				visibleNamespaces.push({ prefix: '', namespace: attr.value });
			}
		}

		for(var i=0;i<len;i++){
			var attr = attrs.item(i);
			if (needNamespaceDefine(attr,isHTML, visibleNamespaces)) {
				var prefix = attr.prefix||'';
				var uri = attr.namespaceURI;
				addSerializedAttribute(buf, prefix ? 'xmlns:' + prefix : "xmlns", uri);
				visibleNamespaces.push({ prefix: prefix, namespace:uri });
			}
			serializeToString(attr,buf,isHTML,nodeFilter,visibleNamespaces);
		}

		// add namespace for current node		
		if (nodeName === prefixedNodeName && needNamespaceDefine(node, isHTML, visibleNamespaces)) {
			var prefix = node.prefix||'';
			var uri = node.namespaceURI;
			addSerializedAttribute(buf, prefix ? 'xmlns:' + prefix : "xmlns", uri);
			visibleNamespaces.push({ prefix: prefix, namespace:uri });
		}
		
		if(child || isHTML && !/^(?:meta|link|img|br|hr|input)$/i.test(nodeName)){
			buf.push('>');
			//if is cdata child node
			if(isHTML && /^script$/i.test(nodeName)){
				while(child){
					if(child.data){
						buf.push(child.data);
					}else{
						serializeToString(child, buf, isHTML, nodeFilter, visibleNamespaces.slice());
					}
					child = child.nextSibling;
				}
			}else
			{
				while(child){
					serializeToString(child, buf, isHTML, nodeFilter, visibleNamespaces.slice());
					child = child.nextSibling;
				}
			}
			buf.push('</',prefixedNodeName,'>');
		}else{
			buf.push('/>');
		}
		// remove added visible namespaces
		//visibleNamespaces.length = startVisibleNamespaces;
		return;
	case DOCUMENT_NODE:
	case DOCUMENT_FRAGMENT_NODE:
		var child = node.firstChild;
		while(child){
			serializeToString(child, buf, isHTML, nodeFilter, visibleNamespaces.slice());
			child = child.nextSibling;
		}
		return;
	case ATTRIBUTE_NODE:
		return addSerializedAttribute(buf, node.name, node.value);
	case TEXT_NODE:
		/**
		 * The ampersand character (&) and the left angle bracket (<) must not appear in their literal form,
		 * except when used as markup delimiters, or within a comment, a processing instruction, or a CDATA section.
		 * If they are needed elsewhere, they must be escaped using either numeric character references or the strings
		 * `&amp;` and `&lt;` respectively.
		 * The right angle bracket (>) may be represented using the string " &gt; ", and must, for compatibility,
		 * be escaped using either `&gt;` or a character reference when it appears in the string `]]>` in content,
		 * when that string is not marking the end of a CDATA section.
		 *
		 * In the content of elements, character data is any string of characters
		 * which does not contain the start-delimiter of any markup
		 * and does not include the CDATA-section-close delimiter, `]]>`.
		 *
		 * @see https://www.w3.org/TR/xml/#NT-CharData
		 * @see https://w3c.github.io/DOM-Parsing/#xml-serializing-a-text-node
		 */
		return buf.push(node.data
			.replace(/[<&>]/g,_xmlEncoder)
		);
	case CDATA_SECTION_NODE:
		return buf.push( '<![CDATA[',node.data,']]>');
	case COMMENT_NODE:
		return buf.push( "<!--",node.data,"-->");
	case DOCUMENT_TYPE_NODE:
		var pubid = node.publicId;
		var sysid = node.systemId;
		buf.push('<!DOCTYPE ',node.name);
		if(pubid){
			buf.push(' PUBLIC ', pubid);
			if (sysid && sysid!='.') {
				buf.push(' ', sysid);
			}
			buf.push('>');
		}else if(sysid && sysid!='.'){
			buf.push(' SYSTEM ', sysid, '>');
		}else{
			var sub = node.internalSubset;
			if(sub){
				buf.push(" [",sub,"]");
			}
			buf.push(">");
		}
		return;
	case PROCESSING_INSTRUCTION_NODE:
		return buf.push( "<?",node.target," ",node.data,"?>");
	case ENTITY_REFERENCE_NODE:
		return buf.push( '&',node.nodeName,';');
	//case ENTITY_NODE:
	//case NOTATION_NODE:
	default:
		buf.push('??',node.nodeName);
	}
}
function importNode(doc,node,deep){
	var node2;
	switch (node.nodeType) {
	case ELEMENT_NODE:
		node2 = node.cloneNode(false);
		node2.ownerDocument = doc;
		//var attrs = node2.attributes;
		//var len = attrs.length;
		//for(var i=0;i<len;i++){
			//node2.setAttributeNodeNS(importNode(doc,attrs.item(i),deep));
		//}
	case DOCUMENT_FRAGMENT_NODE:
		break;
	case ATTRIBUTE_NODE:
		deep = true;
		break;
	//case ENTITY_REFERENCE_NODE:
	//case PROCESSING_INSTRUCTION_NODE:
	////case TEXT_NODE:
	//case CDATA_SECTION_NODE:
	//case COMMENT_NODE:
	//	deep = false;
	//	break;
	//case DOCUMENT_NODE:
	//case DOCUMENT_TYPE_NODE:
	//cannot be imported.
	//case ENTITY_NODE:
	//case NOTATION_NODE
	//can not hit in level3
	//default:throw e;
	}
	if(!node2){
		node2 = node.cloneNode(false);//false
	}
	node2.ownerDocument = doc;
	node2.parentNode = null;
	if(deep){
		var child = node.firstChild;
		while(child){
			node2.appendChild(importNode(doc,child,deep));
			child = child.nextSibling;
		}
	}
	return node2;
}
//
//var _relationMap = {firstChild:1,lastChild:1,previousSibling:1,nextSibling:1,
//					attributes:1,childNodes:1,parentNode:1,documentElement:1,doctype,};
function cloneNode(doc,node,deep){
	var node2 = new node.constructor();
	for(var n in node){
		var v = node[n];
		if(typeof v != 'object' ){
			if(v != node2[n]){
				node2[n] = v;
			}
		}
	}
	if(node.childNodes){
		node2.childNodes = new NodeList();
	}
	node2.ownerDocument = doc;
	switch (node2.nodeType) {
	case ELEMENT_NODE:
		var attrs	= node.attributes;
		var attrs2	= node2.attributes = new NamedNodeMap();
		var len = attrs.length
		attrs2._ownerElement = node2;
		for(var i=0;i<len;i++){
			node2.setAttributeNode(cloneNode(doc,attrs.item(i),true));
		}
		break;;
	case ATTRIBUTE_NODE:
		deep = true;
	}
	if(deep){
		var child = node.firstChild;
		while(child){
			node2.appendChild(cloneNode(doc,child,deep));
			child = child.nextSibling;
		}
	}
	return node2;
}

function __set__(object,key,value){
	object[key] = value
}
//do dynamic
try{
	if(Object.defineProperty){
		Object.defineProperty(LiveNodeList.prototype,'length',{
			get:function(){
				_updateLiveList(this);
				return this.$$length;
			}
		});

		Object.defineProperty(Node.prototype,'textContent',{
			get:function(){
				return getTextContent(this);
			},

			set:function(data){
				switch(this.nodeType){
				case ELEMENT_NODE:
				case DOCUMENT_FRAGMENT_NODE:
					while(this.firstChild){
						this.removeChild(this.firstChild);
					}
					if(data || String(data)){
						this.appendChild(this.ownerDocument.createTextNode(data));
					}
					break;

				default:
					this.data = data;
					this.value = data;
					this.nodeValue = data;
				}
			}
		})
		
		function getTextContent(node){
			switch(node.nodeType){
			case ELEMENT_NODE:
			case DOCUMENT_FRAGMENT_NODE:
				var buf = [];
				node = node.firstChild;
				while(node){
					if(node.nodeType!==7 && node.nodeType !==8){
						buf.push(getTextContent(node));
					}
					node = node.nextSibling;
				}
				return buf.join('');
			default:
				return node.nodeValue;
			}
		}

		__set__ = function(object,key,value){
			//console.log(value)
			object['$$'+key] = value
		}
	}
}catch(e){//ie8
}

//if(typeof require == 'function'){
	exports.DocumentType = DocumentType;
	exports.DOMException = DOMException;
	exports.DOMImplementation = DOMImplementation;
	exports.Element = Element;
	exports.Node = Node;
	exports.NodeList = NodeList;
	exports.XMLSerializer = XMLSerializer;
//}


/***/ }),

/***/ "./node_modules/@xmldom/xmldom/lib/entities.js":
/*!*****************************************************!*\
  !*** ./node_modules/@xmldom/xmldom/lib/entities.js ***!
  \*****************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

var freeze = (__webpack_require__(/*! ./conventions */ "./node_modules/@xmldom/xmldom/lib/conventions.js").freeze);

/**
 * The entities that are predefined in every XML document.
 *
 * @see https://www.w3.org/TR/2006/REC-xml11-20060816/#sec-predefined-ent W3C XML 1.1
 * @see https://www.w3.org/TR/2008/REC-xml-20081126/#sec-predefined-ent W3C XML 1.0
 * @see https://en.wikipedia.org/wiki/List_of_XML_and_HTML_character_entity_references#Predefined_entities_in_XML Wikipedia
 */
exports.XML_ENTITIES = freeze({amp:'&', apos:"'", gt:'>', lt:'<', quot:'"'})

/**
 * A map of currently 241 entities that are detected in an HTML document.
 * They contain all entries from `XML_ENTITIES`.
 *
 * @see XML_ENTITIES
 * @see DOMParser.parseFromString
 * @see DOMImplementation.prototype.createHTMLDocument
 * @see https://html.spec.whatwg.org/#named-character-references WHATWG HTML(5) Spec
 * @see https://www.w3.org/TR/xml-entity-names/ W3C XML Entity Names
 * @see https://www.w3.org/TR/html4/sgml/entities.html W3C HTML4/SGML
 * @see https://en.wikipedia.org/wiki/List_of_XML_and_HTML_character_entity_references#Character_entity_references_in_HTML Wikipedia (HTML)
 * @see https://en.wikipedia.org/wiki/List_of_XML_and_HTML_character_entity_references#Entities_representing_special_characters_in_XHTML Wikpedia (XHTML)
 */
exports.HTML_ENTITIES = freeze({
       lt: '<',
       gt: '>',
       amp: '&',
       quot: '"',
       apos: "'",
       Agrave: "",
       Aacute: "",
       Acirc: "",
       Atilde: "",
       Auml: "",
       Aring: "",
       AElig: "",
       Ccedil: "",
       Egrave: "",
       Eacute: "",
       Ecirc: "",
       Euml: "",
       Igrave: "",
       Iacute: "",
       Icirc: "",
       Iuml: "",
       ETH: "",
       Ntilde: "",
       Ograve: "",
       Oacute: "",
       Ocirc: "",
       Otilde: "",
       Ouml: "",
       Oslash: "",
       Ugrave: "",
       Uacute: "",
       Ucirc: "",
       Uuml: "",
       Yacute: "",
       THORN: "",
       szlig: "",
       agrave: "",
       aacute: "",
       acirc: "",
       atilde: "",
       auml: "",
       aring: "",
       aelig: "",
       ccedil: "",
       egrave: "",
       eacute: "",
       ecirc: "",
       euml: "",
       igrave: "",
       iacute: "",
       icirc: "",
       iuml: "",
       eth: "",
       ntilde: "",
       ograve: "",
       oacute: "",
       ocirc: "",
       otilde: "",
       ouml: "",
       oslash: "",
       ugrave: "",
       uacute: "",
       ucirc: "",
       uuml: "",
       yacute: "",
       thorn: "",
       yuml: "",
       nbsp: "\u00a0",
       iexcl: "",
       cent: "",
       pound: "",
       curren: "",
       yen: "",
       brvbar: "",
       sect: "",
       uml: "",
       copy: "",
       ordf: "",
       laquo: "",
       not: "",
       shy: "",
       reg: "",
       macr: "",
       deg: "",
       plusmn: "",
       sup2: "",
       sup3: "",
       acute: "",
       micro: "",
       para: "",
       middot: "",
       cedil: "",
       sup1: "",
       ordm: "",
       raquo: "",
       frac14: "",
       frac12: "",
       frac34: "",
       iquest: "",
       times: "",
       divide: "",
       forall: "",
       part: "",
       exist: "",
       empty: "",
       nabla: "",
       isin: "",
       notin: "",
       ni: "",
       prod: "",
       sum: "",
       minus: "",
       lowast: "",
       radic: "",
       prop: "",
       infin: "",
       ang: "",
       and: "",
       or: "",
       cap: "",
       cup: "",
       'int': "",
       there4: "",
       sim: "",
       cong: "",
       asymp: "",
       ne: "",
       equiv: "",
       le: "",
       ge: "",
       sub: "",
       sup: "",
       nsub: "",
       sube: "",
       supe: "",
       oplus: "",
       otimes: "",
       perp: "",
       sdot: "",
       Alpha: "",
       Beta: "",
       Gamma: "",
       Delta: "",
       Epsilon: "",
       Zeta: "",
       Eta: "",
       Theta: "",
       Iota: "",
       Kappa: "",
       Lambda: "",
       Mu: "",
       Nu: "",
       Xi: "",
       Omicron: "",
       Pi: "",
       Rho: "",
       Sigma: "",
       Tau: "",
       Upsilon: "",
       Phi: "",
       Chi: "",
       Psi: "",
       Omega: "",
       alpha: "",
       beta: "",
       gamma: "",
       delta: "",
       epsilon: "",
       zeta: "",
       eta: "",
       theta: "",
       iota: "",
       kappa: "",
       lambda: "",
       mu: "",
       nu: "",
       xi: "",
       omicron: "",
       pi: "",
       rho: "",
       sigmaf: "",
       sigma: "",
       tau: "",
       upsilon: "",
       phi: "",
       chi: "",
       psi: "",
       omega: "",
       thetasym: "",
       upsih: "",
       piv: "",
       OElig: "",
       oelig: "",
       Scaron: "",
       scaron: "",
       Yuml: "",
       fnof: "",
       circ: "",
       tilde: "",
       ensp: "",
       emsp: "",
       thinsp: "",
       zwnj: "",
       zwj: "",
       lrm: "",
       rlm: "",
       ndash: "",
       mdash: "",
       lsquo: "",
       rsquo: "",
       sbquo: "",
       ldquo: "",
       rdquo: "",
       bdquo: "",
       dagger: "",
       Dagger: "",
       bull: "",
       hellip: "",
       permil: "",
       prime: "",
       Prime: "",
       lsaquo: "",
       rsaquo: "",
       oline: "",
       euro: "",
       trade: "",
       larr: "",
       uarr: "",
       rarr: "",
       darr: "",
       harr: "",
       crarr: "",
       lceil: "",
       rceil: "",
       lfloor: "",
       rfloor: "",
       loz: "",
       spades: "",
       clubs: "",
       hearts: "",
       diams: ""
});

/**
 * @deprecated use `HTML_ENTITIES` instead
 * @see HTML_ENTITIES
 */
exports.entityMap = exports.HTML_ENTITIES


/***/ }),

/***/ "./node_modules/@xmldom/xmldom/lib/index.js":
/*!**************************************************!*\
  !*** ./node_modules/@xmldom/xmldom/lib/index.js ***!
  \**************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

var dom = __webpack_require__(/*! ./dom */ "./node_modules/@xmldom/xmldom/lib/dom.js")
exports.DOMImplementation = dom.DOMImplementation
exports.XMLSerializer = dom.XMLSerializer
exports.DOMParser = __webpack_require__(/*! ./dom-parser */ "./node_modules/@xmldom/xmldom/lib/dom-parser.js").DOMParser


/***/ }),

/***/ "./node_modules/@xmldom/xmldom/lib/sax.js":
/*!************************************************!*\
  !*** ./node_modules/@xmldom/xmldom/lib/sax.js ***!
  \************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

var NAMESPACE = (__webpack_require__(/*! ./conventions */ "./node_modules/@xmldom/xmldom/lib/conventions.js").NAMESPACE);

//[4]   	NameStartChar	   ::=   	":" | [A-Z] | "_" | [a-z] | [#xC0-#xD6] | [#xD8-#xF6] | [#xF8-#x2FF] | [#x370-#x37D] | [#x37F-#x1FFF] | [#x200C-#x200D] | [#x2070-#x218F] | [#x2C00-#x2FEF] | [#x3001-#xD7FF] | [#xF900-#xFDCF] | [#xFDF0-#xFFFD] | [#x10000-#xEFFFF]
//[4a]   	NameChar	   ::=   	NameStartChar | "-" | "." | [0-9] | #xB7 | [#x0300-#x036F] | [#x203F-#x2040]
//[5]   	Name	   ::=   	NameStartChar (NameChar)*
var nameStartChar = /[A-Z_a-z\xC0-\xD6\xD8-\xF6\u00F8-\u02FF\u0370-\u037D\u037F-\u1FFF\u200C-\u200D\u2070-\u218F\u2C00-\u2FEF\u3001-\uD7FF\uF900-\uFDCF\uFDF0-\uFFFD]///\u10000-\uEFFFF
var nameChar = new RegExp("[\\-\\.0-9"+nameStartChar.source.slice(1,-1)+"\\u00B7\\u0300-\\u036F\\u203F-\\u2040]");
var tagNamePattern = new RegExp('^'+nameStartChar.source+nameChar.source+'*(?:\:'+nameStartChar.source+nameChar.source+'*)?$');
//var tagNamePattern = /^[a-zA-Z_][\w\-\.]*(?:\:[a-zA-Z_][\w\-\.]*)?$/
//var handlers = 'resolveEntity,getExternalSubset,characters,endDocument,endElement,endPrefixMapping,ignorableWhitespace,processingInstruction,setDocumentLocator,skippedEntity,startDocument,startElement,startPrefixMapping,notationDecl,unparsedEntityDecl,error,fatalError,warning,attributeDecl,elementDecl,externalEntityDecl,internalEntityDecl,comment,endCDATA,endDTD,endEntity,startCDATA,startDTD,startEntity'.split(',')

//S_TAG,	S_ATTR,	S_EQ,	S_ATTR_NOQUOT_VALUE
//S_ATTR_SPACE,	S_ATTR_END,	S_TAG_SPACE, S_TAG_CLOSE
var S_TAG = 0;//tag name offerring
var S_ATTR = 1;//attr name offerring
var S_ATTR_SPACE=2;//attr name end and space offer
var S_EQ = 3;//=space?
var S_ATTR_NOQUOT_VALUE = 4;//attr value(no quot value only)
var S_ATTR_END = 5;//attr value end and no space(quot end)
var S_TAG_SPACE = 6;//(attr value end || tag end ) && (space offer)
var S_TAG_CLOSE = 7;//closed el<el />

/**
 * Creates an error that will not be caught by XMLReader aka the SAX parser.
 *
 * @param {string} message
 * @param {any?} locator Optional, can provide details about the location in the source
 * @constructor
 */
function ParseError(message, locator) {
	this.message = message
	this.locator = locator
	if(Error.captureStackTrace) Error.captureStackTrace(this, ParseError);
}
ParseError.prototype = new Error();
ParseError.prototype.name = ParseError.name

function XMLReader(){

}

XMLReader.prototype = {
	parse:function(source,defaultNSMap,entityMap){
		var domBuilder = this.domBuilder;
		domBuilder.startDocument();
		_copy(defaultNSMap ,defaultNSMap = {})
		parse(source,defaultNSMap,entityMap,
				domBuilder,this.errorHandler);
		domBuilder.endDocument();
	}
}
function parse(source,defaultNSMapCopy,entityMap,domBuilder,errorHandler){
	function fixedFromCharCode(code) {
		// String.prototype.fromCharCode does not supports
		// > 2 bytes unicode chars directly
		if (code > 0xffff) {
			code -= 0x10000;
			var surrogate1 = 0xd800 + (code >> 10)
				, surrogate2 = 0xdc00 + (code & 0x3ff);

			return String.fromCharCode(surrogate1, surrogate2);
		} else {
			return String.fromCharCode(code);
		}
	}
	function entityReplacer(a){
		var k = a.slice(1,-1);
		if (Object.hasOwnProperty.call(entityMap, k)) {
			return entityMap[k];
		}else if(k.charAt(0) === '#'){
			return fixedFromCharCode(parseInt(k.substr(1).replace('x','0x')))
		}else{
			errorHandler.error('entity not found:'+a);
			return a;
		}
	}
	function appendText(end){//has some bugs
		if(end>start){
			var xt = source.substring(start,end).replace(/&#?\w+;/g,entityReplacer);
			locator&&position(start);
			domBuilder.characters(xt,0,end-start);
			start = end
		}
	}
	function position(p,m){
		while(p>=lineEnd && (m = linePattern.exec(source))){
			lineStart = m.index;
			lineEnd = lineStart + m[0].length;
			locator.lineNumber++;
			//console.log('line++:',locator,startPos,endPos)
		}
		locator.columnNumber = p-lineStart+1;
	}
	var lineStart = 0;
	var lineEnd = 0;
	var linePattern = /.*(?:\r\n?|\n)|.*$/g
	var locator = domBuilder.locator;

	var parseStack = [{currentNSMap:defaultNSMapCopy}]
	var closeMap = {};
	var start = 0;
	while(true){
		try{
			var tagStart = source.indexOf('<',start);
			if(tagStart<0){
				if(!source.substr(start).match(/^\s*$/)){
					var doc = domBuilder.doc;
	    			var text = doc.createTextNode(source.substr(start));
	    			doc.appendChild(text);
	    			domBuilder.currentElement = text;
				}
				return;
			}
			if(tagStart>start){
				appendText(tagStart);
			}
			switch(source.charAt(tagStart+1)){
			case '/':
				var end = source.indexOf('>',tagStart+3);
				var tagName = source.substring(tagStart + 2, end).replace(/[ \t\n\r]+$/g, '');
				var config = parseStack.pop();
				if(end<0){

	        		tagName = source.substring(tagStart+2).replace(/[\s<].*/,'');
	        		errorHandler.error("end tag name: "+tagName+' is not complete:'+config.tagName);
	        		end = tagStart+1+tagName.length;
	        	}else if(tagName.match(/\s</)){
	        		tagName = tagName.replace(/[\s<].*/,'');
	        		errorHandler.error("end tag name: "+tagName+' maybe not complete');
	        		end = tagStart+1+tagName.length;
				}
				var localNSMap = config.localNSMap;
				var endMatch = config.tagName == tagName;
				var endIgnoreCaseMach = endMatch || config.tagName&&config.tagName.toLowerCase() == tagName.toLowerCase()
		        if(endIgnoreCaseMach){
		        	domBuilder.endElement(config.uri,config.localName,tagName);
					if(localNSMap){
						for(var prefix in localNSMap){
							domBuilder.endPrefixMapping(prefix) ;
						}
					}
					if(!endMatch){
		            	errorHandler.fatalError("end tag name: "+tagName+' is not match the current start tagName:'+config.tagName ); // No known test case
					}
		        }else{
		        	parseStack.push(config)
		        }

				end++;
				break;
				// end elment
			case '?':// <?...?>
				locator&&position(tagStart);
				end = parseInstruction(source,tagStart,domBuilder);
				break;
			case '!':// <!doctype,<![CDATA,<!--
				locator&&position(tagStart);
				end = parseDCC(source,tagStart,domBuilder,errorHandler);
				break;
			default:
				locator&&position(tagStart);
				var el = new ElementAttributes();
				var currentNSMap = parseStack[parseStack.length-1].currentNSMap;
				//elStartEnd
				var end = parseElementStartPart(source,tagStart,el,currentNSMap,entityReplacer,errorHandler);
				var len = el.length;


				if(!el.closed && fixSelfClosed(source,end,el.tagName,closeMap)){
					el.closed = true;
					if(!entityMap.nbsp){
						errorHandler.warning('unclosed xml attribute');
					}
				}
				if(locator && len){
					var locator2 = copyLocator(locator,{});
					//try{//attribute position fixed
					for(var i = 0;i<len;i++){
						var a = el[i];
						position(a.offset);
						a.locator = copyLocator(locator,{});
					}
					domBuilder.locator = locator2
					if(appendElement(el,domBuilder,currentNSMap)){
						parseStack.push(el)
					}
					domBuilder.locator = locator;
				}else{
					if(appendElement(el,domBuilder,currentNSMap)){
						parseStack.push(el)
					}
				}

				if (NAMESPACE.isHTML(el.uri) && !el.closed) {
					end = parseHtmlSpecialContent(source,end,el.tagName,entityReplacer,domBuilder)
				} else {
					end++;
				}
			}
		}catch(e){
			if (e instanceof ParseError) {
				throw e;
			}
			errorHandler.error('element parse error: '+e)
			end = -1;
		}
		if(end>start){
			start = end;
		}else{
			//TODO: sax
			appendText(Math.max(tagStart,start)+1);
		}
	}
}
function copyLocator(f,t){
	t.lineNumber = f.lineNumber;
	t.columnNumber = f.columnNumber;
	return t;
}

/**
 * @see #appendElement(source,elStartEnd,el,selfClosed,entityReplacer,domBuilder,parseStack);
 * @return end of the elementStartPart(end of elementEndPart for selfClosed el)
 */
function parseElementStartPart(source,start,el,currentNSMap,entityReplacer,errorHandler){

	/**
	 * @param {string} qname
	 * @param {string} value
	 * @param {number} startIndex
	 */
	function addAttribute(qname, value, startIndex) {
		if (el.attributeNames.hasOwnProperty(qname)) {
			errorHandler.fatalError('Attribute ' + qname + ' redefined')
		}
		el.addValue(
			qname,
			// @see https://www.w3.org/TR/xml/#AVNormalize
			// since the xmldom sax parser does not "interpret" DTD the following is not implemented:
			// - recursive replacement of (DTD) entity references
			// - trimming and collapsing multiple spaces into a single one for attributes that are not of type CDATA
			value.replace(/[\t\n\r]/g, ' ').replace(/&#?\w+;/g, entityReplacer),
			startIndex
		)
	}
	var attrName;
	var value;
	var p = ++start;
	var s = S_TAG;//status
	while(true){
		var c = source.charAt(p);
		switch(c){
		case '=':
			if(s === S_ATTR){//attrName
				attrName = source.slice(start,p);
				s = S_EQ;
			}else if(s === S_ATTR_SPACE){
				s = S_EQ;
			}else{
				//fatalError: equal must after attrName or space after attrName
				throw new Error('attribute equal must after attrName'); // No known test case
			}
			break;
		case '\'':
		case '"':
			if(s === S_EQ || s === S_ATTR //|| s == S_ATTR_SPACE
				){//equal
				if(s === S_ATTR){
					errorHandler.warning('attribute value must after "="')
					attrName = source.slice(start,p)
				}
				start = p+1;
				p = source.indexOf(c,start)
				if(p>0){
					value = source.slice(start, p);
					addAttribute(attrName, value, start-1);
					s = S_ATTR_END;
				}else{
					//fatalError: no end quot match
					throw new Error('attribute value no end \''+c+'\' match');
				}
			}else if(s == S_ATTR_NOQUOT_VALUE){
				value = source.slice(start, p);
				addAttribute(attrName, value, start);
				errorHandler.warning('attribute "'+attrName+'" missed start quot('+c+')!!');
				start = p+1;
				s = S_ATTR_END
			}else{
				//fatalError: no equal before
				throw new Error('attribute value must after "="'); // No known test case
			}
			break;
		case '/':
			switch(s){
			case S_TAG:
				el.setTagName(source.slice(start,p));
			case S_ATTR_END:
			case S_TAG_SPACE:
			case S_TAG_CLOSE:
				s =S_TAG_CLOSE;
				el.closed = true;
			case S_ATTR_NOQUOT_VALUE:
			case S_ATTR:
			case S_ATTR_SPACE:
				break;
			//case S_EQ:
			default:
				throw new Error("attribute invalid close char('/')") // No known test case
			}
			break;
		case ''://end document
			errorHandler.error('unexpected end of input');
			if(s == S_TAG){
				el.setTagName(source.slice(start,p));
			}
			return p;
		case '>':
			switch(s){
			case S_TAG:
				el.setTagName(source.slice(start,p));
			case S_ATTR_END:
			case S_TAG_SPACE:
			case S_TAG_CLOSE:
				break;//normal
			case S_ATTR_NOQUOT_VALUE://Compatible state
			case S_ATTR:
				value = source.slice(start,p);
				if(value.slice(-1) === '/'){
					el.closed  = true;
					value = value.slice(0,-1)
				}
			case S_ATTR_SPACE:
				if(s === S_ATTR_SPACE){
					value = attrName;
				}
				if(s == S_ATTR_NOQUOT_VALUE){
					errorHandler.warning('attribute "'+value+'" missed quot(")!');
					addAttribute(attrName, value, start)
				}else{
					if(!NAMESPACE.isHTML(currentNSMap['']) || !value.match(/^(?:disabled|checked|selected)$/i)){
						errorHandler.warning('attribute "'+value+'" missed value!! "'+value+'" instead!!')
					}
					addAttribute(value, value, start)
				}
				break;
			case S_EQ:
				throw new Error('attribute value missed!!');
			}
//			console.log(tagName,tagNamePattern,tagNamePattern.test(tagName))
			return p;
		/*xml space '\x20' | #x9 | #xD | #xA; */
		case '\u0080':
			c = ' ';
		default:
			if(c<= ' '){//space
				switch(s){
				case S_TAG:
					el.setTagName(source.slice(start,p));//tagName
					s = S_TAG_SPACE;
					break;
				case S_ATTR:
					attrName = source.slice(start,p)
					s = S_ATTR_SPACE;
					break;
				case S_ATTR_NOQUOT_VALUE:
					var value = source.slice(start, p);
					errorHandler.warning('attribute "'+value+'" missed quot(")!!');
					addAttribute(attrName, value, start)
				case S_ATTR_END:
					s = S_TAG_SPACE;
					break;
				//case S_TAG_SPACE:
				//case S_EQ:
				//case S_ATTR_SPACE:
				//	void();break;
				//case S_TAG_CLOSE:
					//ignore warning
				}
			}else{//not space
//S_TAG,	S_ATTR,	S_EQ,	S_ATTR_NOQUOT_VALUE
//S_ATTR_SPACE,	S_ATTR_END,	S_TAG_SPACE, S_TAG_CLOSE
				switch(s){
				//case S_TAG:void();break;
				//case S_ATTR:void();break;
				//case S_ATTR_NOQUOT_VALUE:void();break;
				case S_ATTR_SPACE:
					var tagName =  el.tagName;
					if (!NAMESPACE.isHTML(currentNSMap['']) || !attrName.match(/^(?:disabled|checked|selected)$/i)) {
						errorHandler.warning('attribute "'+attrName+'" missed value!! "'+attrName+'" instead2!!')
					}
					addAttribute(attrName, attrName, start);
					start = p;
					s = S_ATTR;
					break;
				case S_ATTR_END:
					errorHandler.warning('attribute space is required"'+attrName+'"!!')
				case S_TAG_SPACE:
					s = S_ATTR;
					start = p;
					break;
				case S_EQ:
					s = S_ATTR_NOQUOT_VALUE;
					start = p;
					break;
				case S_TAG_CLOSE:
					throw new Error("elements closed character '/' and '>' must be connected to");
				}
			}
		}//end outer switch
		//console.log('p++',p)
		p++;
	}
}
/**
 * @return true if has new namespace define
 */
function appendElement(el,domBuilder,currentNSMap){
	var tagName = el.tagName;
	var localNSMap = null;
	//var currentNSMap = parseStack[parseStack.length-1].currentNSMap;
	var i = el.length;
	while(i--){
		var a = el[i];
		var qName = a.qName;
		var value = a.value;
		var nsp = qName.indexOf(':');
		if(nsp>0){
			var prefix = a.prefix = qName.slice(0,nsp);
			var localName = qName.slice(nsp+1);
			var nsPrefix = prefix === 'xmlns' && localName
		}else{
			localName = qName;
			prefix = null
			nsPrefix = qName === 'xmlns' && ''
		}
		//can not set prefix,because prefix !== ''
		a.localName = localName ;
		//prefix == null for no ns prefix attribute
		if(nsPrefix !== false){//hack!!
			if(localNSMap == null){
				localNSMap = {}
				//console.log(currentNSMap,0)
				_copy(currentNSMap,currentNSMap={})
				//console.log(currentNSMap,1)
			}
			currentNSMap[nsPrefix] = localNSMap[nsPrefix] = value;
			a.uri = NAMESPACE.XMLNS
			domBuilder.startPrefixMapping(nsPrefix, value)
		}
	}
	var i = el.length;
	while(i--){
		a = el[i];
		var prefix = a.prefix;
		if(prefix){//no prefix attribute has no namespace
			if(prefix === 'xml'){
				a.uri = NAMESPACE.XML;
			}if(prefix !== 'xmlns'){
				a.uri = currentNSMap[prefix || '']

				//{console.log('###'+a.qName,domBuilder.locator.systemId+'',currentNSMap,a.uri)}
			}
		}
	}
	var nsp = tagName.indexOf(':');
	if(nsp>0){
		prefix = el.prefix = tagName.slice(0,nsp);
		localName = el.localName = tagName.slice(nsp+1);
	}else{
		prefix = null;//important!!
		localName = el.localName = tagName;
	}
	//no prefix element has default namespace
	var ns = el.uri = currentNSMap[prefix || ''];
	domBuilder.startElement(ns,localName,tagName,el);
	//endPrefixMapping and startPrefixMapping have not any help for dom builder
	//localNSMap = null
	if(el.closed){
		domBuilder.endElement(ns,localName,tagName);
		if(localNSMap){
			for(prefix in localNSMap){
				domBuilder.endPrefixMapping(prefix)
			}
		}
	}else{
		el.currentNSMap = currentNSMap;
		el.localNSMap = localNSMap;
		//parseStack.push(el);
		return true;
	}
}
function parseHtmlSpecialContent(source,elStartEnd,tagName,entityReplacer,domBuilder){
	if(/^(?:script|textarea)$/i.test(tagName)){
		var elEndStart =  source.indexOf('</'+tagName+'>',elStartEnd);
		var text = source.substring(elStartEnd+1,elEndStart);
		if(/[&<]/.test(text)){
			if(/^script$/i.test(tagName)){
				//if(!/\]\]>/.test(text)){
					//lexHandler.startCDATA();
					domBuilder.characters(text,0,text.length);
					//lexHandler.endCDATA();
					return elEndStart;
				//}
			}//}else{//text area
				text = text.replace(/&#?\w+;/g,entityReplacer);
				domBuilder.characters(text,0,text.length);
				return elEndStart;
			//}

		}
	}
	return elStartEnd+1;
}
function fixSelfClosed(source,elStartEnd,tagName,closeMap){
	//if(tagName in closeMap){
	var pos = closeMap[tagName];
	if(pos == null){
		//console.log(tagName)
		pos =  source.lastIndexOf('</'+tagName+'>')
		if(pos<elStartEnd){//
			pos = source.lastIndexOf('</'+tagName)
		}
		closeMap[tagName] =pos
	}
	return pos<elStartEnd;
	//}
}
function _copy(source,target){
	for(var n in source){target[n] = source[n]}
}
function parseDCC(source,start,domBuilder,errorHandler){//sure start with '<!'
	var next= source.charAt(start+2)
	switch(next){
	case '-':
		if(source.charAt(start + 3) === '-'){
			var end = source.indexOf('-->',start+4);
			//append comment source.substring(4,end)//<!--
			if(end>start){
				domBuilder.comment(source,start+4,end-start-4);
				return end+3;
			}else{
				errorHandler.error("Unclosed comment");
				return -1;
			}
		}else{
			//error
			return -1;
		}
	default:
		if(source.substr(start+3,6) == 'CDATA['){
			var end = source.indexOf(']]>',start+9);
			domBuilder.startCDATA();
			domBuilder.characters(source,start+9,end-start-9);
			domBuilder.endCDATA()
			return end+3;
		}
		//<!DOCTYPE
		//startDTD(java.lang.String name, java.lang.String publicId, java.lang.String systemId)
		var matchs = split(source,start);
		var len = matchs.length;
		if(len>1 && /!doctype/i.test(matchs[0][0])){
			var name = matchs[1][0];
			var pubid = false;
			var sysid = false;
			if(len>3){
				if(/^public$/i.test(matchs[2][0])){
					pubid = matchs[3][0];
					sysid = len>4 && matchs[4][0];
				}else if(/^system$/i.test(matchs[2][0])){
					sysid = matchs[3][0];
				}
			}
			var lastMatch = matchs[len-1]
			domBuilder.startDTD(name, pubid, sysid);
			domBuilder.endDTD();

			return lastMatch.index+lastMatch[0].length
		}
	}
	return -1;
}



function parseInstruction(source,start,domBuilder){
	var end = source.indexOf('?>',start);
	if(end){
		var match = source.substring(start,end).match(/^<\?(\S*)\s*([\s\S]*?)\s*$/);
		if(match){
			var len = match[0].length;
			domBuilder.processingInstruction(match[1], match[2]) ;
			return end+2;
		}else{//error
			return -1;
		}
	}
	return -1;
}

function ElementAttributes(){
	this.attributeNames = {}
}
ElementAttributes.prototype = {
	setTagName:function(tagName){
		if(!tagNamePattern.test(tagName)){
			throw new Error('invalid tagName:'+tagName)
		}
		this.tagName = tagName
	},
	addValue:function(qName, value, offset) {
		if(!tagNamePattern.test(qName)){
			throw new Error('invalid attribute:'+qName)
		}
		this.attributeNames[qName] = this.length;
		this[this.length++] = {qName:qName,value:value,offset:offset}
	},
	length:0,
	getLocalName:function(i){return this[i].localName},
	getLocator:function(i){return this[i].locator},
	getQName:function(i){return this[i].qName},
	getURI:function(i){return this[i].uri},
	getValue:function(i){return this[i].value}
//	,getIndex:function(uri, localName)){
//		if(localName){
//
//		}else{
//			var qName = uri
//		}
//	},
//	getValue:function(){return this.getValue(this.getIndex.apply(this,arguments))},
//	getType:function(uri,localName){}
//	getType:function(i){},
}



function split(source,start){
	var match;
	var buf = [];
	var reg = /'[^']+'|"[^"]+"|[^\s<>\/=]+=?|(\/?\s*>|<)/g;
	reg.lastIndex = start;
	reg.exec(source);//skip <
	while(match = reg.exec(source)){
		buf.push(match);
		if(match[1])return buf;
	}
}

exports.XMLReader = XMLReader;
exports.ParseError = ParseError;


/***/ }),

/***/ "./node_modules/async-es/asyncify.js":
/*!*******************************************!*\
  !*** ./node_modules/async-es/asyncify.js ***!
  \*******************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (/* binding */ asyncify)
/* harmony export */ });
/* harmony import */ var _internal_initialParams_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./internal/initialParams.js */ "./node_modules/async-es/internal/initialParams.js");
/* harmony import */ var _internal_setImmediate_js__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./internal/setImmediate.js */ "./node_modules/async-es/internal/setImmediate.js");
/* harmony import */ var _internal_wrapAsync_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./internal/wrapAsync.js */ "./node_modules/async-es/internal/wrapAsync.js");




/**
 * Take a sync function and make it async, passing its return value to a
 * callback. This is useful for plugging sync functions into a waterfall,
 * series, or other async functions. Any arguments passed to the generated
 * function will be passed to the wrapped function (except for the final
 * callback argument). Errors thrown will be passed to the callback.
 *
 * If the function passed to `asyncify` returns a Promise, that promises's
 * resolved/rejected state will be used to call the callback, rather than simply
 * the synchronous return value.
 *
 * This also means you can asyncify ES2017 `async` functions.
 *
 * @name asyncify
 * @static
 * @memberOf module:Utils
 * @method
 * @alias wrapSync
 * @category Util
 * @param {Function} func - The synchronous function, or Promise-returning
 * function to convert to an {@link AsyncFunction}.
 * @returns {AsyncFunction} An asynchronous wrapper of the `func`. To be
 * invoked with `(args..., callback)`.
 * @example
 *
 * // passing a regular synchronous function
 * async.waterfall([
 *     async.apply(fs.readFile, filename, "utf8"),
 *     async.asyncify(JSON.parse),
 *     function (data, next) {
 *         // data is the result of parsing the text.
 *         // If there was a parsing error, it would have been caught.
 *     }
 * ], callback);
 *
 * // passing a function returning a promise
 * async.waterfall([
 *     async.apply(fs.readFile, filename, "utf8"),
 *     async.asyncify(function (contents) {
 *         return db.model.create(contents);
 *     }),
 *     function (model, next) {
 *         // `model` is the instantiated model object.
 *         // If there was an error, this function would be skipped.
 *     }
 * ], callback);
 *
 * // es2017 example, though `asyncify` is not needed if your JS environment
 * // supports async functions out of the box
 * var q = async.queue(async.asyncify(async function(file) {
 *     var intermediateStep = await processFile(file);
 *     return await somePromise(intermediateStep)
 * }));
 *
 * q.push(files);
 */
function asyncify(func) {
    if ((0,_internal_wrapAsync_js__WEBPACK_IMPORTED_MODULE_0__.isAsync)(func)) {
        return function (...args/*, callback*/) {
            const callback = args.pop()
            const promise = func.apply(this, args)
            return handlePromise(promise, callback)
        }
    }

    return (0,_internal_initialParams_js__WEBPACK_IMPORTED_MODULE_1__["default"])(function (args, callback) {
        var result;
        try {
            result = func.apply(this, args);
        } catch (e) {
            return callback(e);
        }
        // if result is Promise object
        if (result && typeof result.then === 'function') {
            return handlePromise(result, callback)
        } else {
            callback(null, result);
        }
    });
}

function handlePromise(promise, callback) {
    return promise.then(value => {
        invokeCallback(callback, null, value);
    }, err => {
        invokeCallback(callback, err && err.message ? err : new Error(err));
    });
}

function invokeCallback(callback, error, value) {
    try {
        callback(error, value);
    } catch (err) {
        (0,_internal_setImmediate_js__WEBPACK_IMPORTED_MODULE_2__["default"])(e => { throw e }, err);
    }
}


/***/ }),

/***/ "./node_modules/async-es/internal/DoublyLinkedList.js":
/*!************************************************************!*\
  !*** ./node_modules/async-es/internal/DoublyLinkedList.js ***!
  \************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (/* binding */ DLL)
/* harmony export */ });
// Simple doubly linked list (https://en.wikipedia.org/wiki/Doubly_linked_list) implementation
// used for queues. This implementation assumes that the node provided by the user can be modified
// to adjust the next and last properties. We implement only the minimal functionality
// for queue support.
class DLL {
    constructor() {
        this.head = this.tail = null;
        this.length = 0;
    }

    removeLink(node) {
        if (node.prev) node.prev.next = node.next;
        else this.head = node.next
        if (node.next) node.next.prev = node.prev;
        else this.tail = node.prev;

        node.prev = node.next = null;
        this.length -= 1;
        return node;
    }

    empty () {
        while(this.head) this.shift();
        return this;
    }

    insertAfter(node, newNode) {
        newNode.prev = node;
        newNode.next = node.next;
        if (node.next) node.next.prev = newNode;
        else this.tail = newNode;
        node.next = newNode;
        this.length += 1;
    }

    insertBefore(node, newNode) {
        newNode.prev = node.prev;
        newNode.next = node;
        if (node.prev) node.prev.next = newNode;
        else this.head = newNode;
        node.prev = newNode;
        this.length += 1;
    }

    unshift(node) {
        if (this.head) this.insertBefore(this.head, node);
        else setInitial(this, node);
    }

    push(node) {
        if (this.tail) this.insertAfter(this.tail, node);
        else setInitial(this, node);
    }

    shift() {
        return this.head && this.removeLink(this.head);
    }

    pop() {
        return this.tail && this.removeLink(this.tail);
    }

    toArray() {
        return [...this]
    }

    *[Symbol.iterator] () {
        var cur = this.head
        while (cur) {
            yield cur.data
            cur = cur.next
        }
    }

    remove (testFn) {
        var curr = this.head;
        while(curr) {
            var {next} = curr;
            if (testFn(curr)) {
                this.removeLink(curr);
            }
            curr = next;
        }
        return this;
    }
}

function setInitial(dll, node) {
    dll.length = 1;
    dll.head = dll.tail = node;
}



/***/ }),

/***/ "./node_modules/async-es/internal/initialParams.js":
/*!*********************************************************!*\
  !*** ./node_modules/async-es/internal/initialParams.js ***!
  \*********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (/* export default binding */ __WEBPACK_DEFAULT_EXPORT__)
/* harmony export */ });
/* harmony default export */ function __WEBPACK_DEFAULT_EXPORT__(fn) {
    return function (...args/*, callback*/) {
        var callback = args.pop();
        return fn.call(this, args, callback);
    };
}


/***/ }),

/***/ "./node_modules/async-es/internal/onlyOnce.js":
/*!****************************************************!*\
  !*** ./node_modules/async-es/internal/onlyOnce.js ***!
  \****************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (/* binding */ onlyOnce)
/* harmony export */ });
function onlyOnce(fn) {
    return function (...args) {
        if (fn === null) throw new Error("Callback was already called.");
        var callFn = fn;
        fn = null;
        callFn.apply(this, args);
    };
}


/***/ }),

/***/ "./node_modules/async-es/internal/queue.js":
/*!*************************************************!*\
  !*** ./node_modules/async-es/internal/queue.js ***!
  \*************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (/* binding */ queue)
/* harmony export */ });
/* harmony import */ var _onlyOnce_js__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./onlyOnce.js */ "./node_modules/async-es/internal/onlyOnce.js");
/* harmony import */ var _setImmediate_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./setImmediate.js */ "./node_modules/async-es/internal/setImmediate.js");
/* harmony import */ var _DoublyLinkedList_js__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./DoublyLinkedList.js */ "./node_modules/async-es/internal/DoublyLinkedList.js");
/* harmony import */ var _wrapAsync_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./wrapAsync.js */ "./node_modules/async-es/internal/wrapAsync.js");





function queue(worker, concurrency, payload) {
    if (concurrency == null) {
        concurrency = 1;
    }
    else if(concurrency === 0) {
        throw new RangeError('Concurrency must not be zero');
    }

    var _worker = (0,_wrapAsync_js__WEBPACK_IMPORTED_MODULE_0__["default"])(worker);
    var numRunning = 0;
    var workersList = [];
    const events = {
        error: [],
        drain: [],
        saturated: [],
        unsaturated: [],
        empty: []
    }

    function on (event, handler) {
        events[event].push(handler)
    }

    function once (event, handler) {
        const handleAndRemove = (...args) => {
            off(event, handleAndRemove)
            handler(...args)
        }
        events[event].push(handleAndRemove)
    }

    function off (event, handler) {
        if (!event) return Object.keys(events).forEach(ev => events[ev] = [])
        if (!handler) return events[event] = []
        events[event] = events[event].filter(ev => ev !== handler)
    }

    function trigger (event, ...args) {
        events[event].forEach(handler => handler(...args))
    }

    var processingScheduled = false;
    function _insert(data, insertAtFront, rejectOnError, callback) {
        if (callback != null && typeof callback !== 'function') {
            throw new Error('task callback must be a function');
        }
        q.started = true;

        var res, rej;
        function promiseCallback (err, ...args) {
            // we don't care about the error, let the global error handler
            // deal with it
            if (err) return rejectOnError ? rej(err) : res()
            if (args.length <= 1) return res(args[0])
            res(args)
        }

        var item = q._createTaskItem(
            data,
            rejectOnError ? promiseCallback :
                (callback || promiseCallback)
        );

        if (insertAtFront) {
            q._tasks.unshift(item);
        } else {
            q._tasks.push(item);
        }

        if (!processingScheduled) {
            processingScheduled = true;
            (0,_setImmediate_js__WEBPACK_IMPORTED_MODULE_1__["default"])(() => {
                processingScheduled = false;
                q.process();
            });
        }

        if (rejectOnError || !callback) {
            return new Promise((resolve, reject) => {
                res = resolve
                rej = reject
            })
        }
    }

    function _createCB(tasks) {
        return function (err, ...args) {
            numRunning -= 1;

            for (var i = 0, l = tasks.length; i < l; i++) {
                var task = tasks[i];

                var index = workersList.indexOf(task);
                if (index === 0) {
                    workersList.shift();
                } else if (index > 0) {
                    workersList.splice(index, 1);
                }

                task.callback(err, ...args);

                if (err != null) {
                    trigger('error', err, task.data);
                }
            }

            if (numRunning <= (q.concurrency - q.buffer) ) {
                trigger('unsaturated')
            }

            if (q.idle()) {
                trigger('drain')
            }
            q.process();
        };
    }

    function _maybeDrain(data) {
        if (data.length === 0 && q.idle()) {
            // call drain immediately if there are no tasks
            (0,_setImmediate_js__WEBPACK_IMPORTED_MODULE_1__["default"])(() => trigger('drain'));
            return true
        }
        return false
    }

    const eventMethod = (name) => (handler) => {
        if (!handler) {
            return new Promise((resolve, reject) => {
                once(name, (err, data) => {
                    if (err) return reject(err)
                    resolve(data)
                })
            })
        }
        off(name)
        on(name, handler)

    }

    var isProcessing = false;
    var q = {
        _tasks: new _DoublyLinkedList_js__WEBPACK_IMPORTED_MODULE_2__["default"](),
        _createTaskItem (data, callback) {
            return {
                data,
                callback
            };
        },
        *[Symbol.iterator] () {
            yield* q._tasks[Symbol.iterator]()
        },
        concurrency,
        payload,
        buffer: concurrency / 4,
        started: false,
        paused: false,
        push (data, callback) {
            if (Array.isArray(data)) {
                if (_maybeDrain(data)) return
                return data.map(datum => _insert(datum, false, false, callback))
            }
            return _insert(data, false, false, callback);
        },
        pushAsync (data, callback) {
            if (Array.isArray(data)) {
                if (_maybeDrain(data)) return
                return data.map(datum => _insert(datum, false, true, callback))
            }
            return _insert(data, false, true, callback);
        },
        kill () {
            off()
            q._tasks.empty();
        },
        unshift (data, callback) {
            if (Array.isArray(data)) {
                if (_maybeDrain(data)) return
                return data.map(datum => _insert(datum, true, false, callback))
            }
            return _insert(data, true, false, callback);
        },
        unshiftAsync (data, callback) {
            if (Array.isArray(data)) {
                if (_maybeDrain(data)) return
                return data.map(datum => _insert(datum, true, true, callback))
            }
            return _insert(data, true, true, callback);
        },
        remove (testFn) {
            q._tasks.remove(testFn);
        },
        process () {
            // Avoid trying to start too many processing operations. This can occur
            // when callbacks resolve synchronously (#1267).
            if (isProcessing) {
                return;
            }
            isProcessing = true;
            while(!q.paused && numRunning < q.concurrency && q._tasks.length){
                var tasks = [], data = [];
                var l = q._tasks.length;
                if (q.payload) l = Math.min(l, q.payload);
                for (var i = 0; i < l; i++) {
                    var node = q._tasks.shift();
                    tasks.push(node);
                    workersList.push(node);
                    data.push(node.data);
                }

                numRunning += 1;

                if (q._tasks.length === 0) {
                    trigger('empty');
                }

                if (numRunning === q.concurrency) {
                    trigger('saturated');
                }

                var cb = (0,_onlyOnce_js__WEBPACK_IMPORTED_MODULE_3__["default"])(_createCB(tasks));
                _worker(data, cb);
            }
            isProcessing = false;
        },
        length () {
            return q._tasks.length;
        },
        running () {
            return numRunning;
        },
        workersList () {
            return workersList;
        },
        idle() {
            return q._tasks.length + numRunning === 0;
        },
        pause () {
            q.paused = true;
        },
        resume () {
            if (q.paused === false) { return; }
            q.paused = false;
            (0,_setImmediate_js__WEBPACK_IMPORTED_MODULE_1__["default"])(q.process);
        }
    };
    // define these as fixed properties, so people get useful errors when updating
    Object.defineProperties(q, {
        saturated: {
            writable: false,
            value: eventMethod('saturated')
        },
        unsaturated: {
            writable: false,
            value: eventMethod('unsaturated')
        },
        empty: {
            writable: false,
            value: eventMethod('empty')
        },
        drain: {
            writable: false,
            value: eventMethod('drain')
        },
        error: {
            writable: false,
            value: eventMethod('error')
        },
    })
    return q;
}


/***/ }),

/***/ "./node_modules/async-es/internal/setImmediate.js":
/*!********************************************************!*\
  !*** ./node_modules/async-es/internal/setImmediate.js ***!
  \********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (__WEBPACK_DEFAULT_EXPORT__),
/* harmony export */   fallback: () => (/* binding */ fallback),
/* harmony export */   hasNextTick: () => (/* binding */ hasNextTick),
/* harmony export */   hasQueueMicrotask: () => (/* binding */ hasQueueMicrotask),
/* harmony export */   hasSetImmediate: () => (/* binding */ hasSetImmediate),
/* harmony export */   wrap: () => (/* binding */ wrap)
/* harmony export */ });
/* istanbul ignore file */

var hasQueueMicrotask = typeof queueMicrotask === 'function' && queueMicrotask;
var hasSetImmediate = typeof setImmediate === 'function' && setImmediate;
var hasNextTick = typeof process === 'object' && typeof process.nextTick === 'function';

function fallback(fn) {
    setTimeout(fn, 0);
}

function wrap(defer) {
    return (fn, ...args) => defer(() => fn(...args));
}

var _defer;

if (hasQueueMicrotask) {
    _defer = queueMicrotask;
} else if (hasSetImmediate) {
    _defer = setImmediate;
} else if (hasNextTick) {
    _defer = process.nextTick;
} else {
    _defer = fallback;
}

/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (wrap(_defer));


/***/ }),

/***/ "./node_modules/async-es/internal/wrapAsync.js":
/*!*****************************************************!*\
  !*** ./node_modules/async-es/internal/wrapAsync.js ***!
  \*****************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (__WEBPACK_DEFAULT_EXPORT__),
/* harmony export */   isAsync: () => (/* binding */ isAsync),
/* harmony export */   isAsyncGenerator: () => (/* binding */ isAsyncGenerator),
/* harmony export */   isAsyncIterable: () => (/* binding */ isAsyncIterable)
/* harmony export */ });
/* harmony import */ var _asyncify_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../asyncify.js */ "./node_modules/async-es/asyncify.js");


function isAsync(fn) {
    return fn[Symbol.toStringTag] === 'AsyncFunction';
}

function isAsyncGenerator(fn) {
    return fn[Symbol.toStringTag] === 'AsyncGenerator';
}

function isAsyncIterable(obj) {
    return typeof obj[Symbol.asyncIterator] === 'function';
}

function wrapAsync(asyncFn) {
    if (typeof asyncFn !== 'function') throw new Error('expected a function')
    return isAsync(asyncFn) ? (0,_asyncify_js__WEBPACK_IMPORTED_MODULE_0__["default"])(asyncFn) : asyncFn;
}

/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (wrapAsync);




/***/ }),

/***/ "./node_modules/async-es/queue.js":
/*!****************************************!*\
  !*** ./node_modules/async-es/queue.js ***!
  \****************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (/* export default binding */ __WEBPACK_DEFAULT_EXPORT__)
/* harmony export */ });
/* harmony import */ var _internal_queue_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./internal/queue.js */ "./node_modules/async-es/internal/queue.js");
/* harmony import */ var _internal_wrapAsync_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./internal/wrapAsync.js */ "./node_modules/async-es/internal/wrapAsync.js");



/**
 * A queue of tasks for the worker function to complete.
 * @typedef {Iterable} QueueObject
 * @memberOf module:ControlFlow
 * @property {Function} length - a function returning the number of items
 * waiting to be processed. Invoke with `queue.length()`.
 * @property {boolean} started - a boolean indicating whether or not any
 * items have been pushed and processed by the queue.
 * @property {Function} running - a function returning the number of items
 * currently being processed. Invoke with `queue.running()`.
 * @property {Function} workersList - a function returning the array of items
 * currently being processed. Invoke with `queue.workersList()`.
 * @property {Function} idle - a function returning false if there are items
 * waiting or being processed, or true if not. Invoke with `queue.idle()`.
 * @property {number} concurrency - an integer for determining how many `worker`
 * functions should be run in parallel. This property can be changed after a
 * `queue` is created to alter the concurrency on-the-fly.
 * @property {number} payload - an integer that specifies how many items are
 * passed to the worker function at a time. only applies if this is a
 * [cargo]{@link module:ControlFlow.cargo} object
 * @property {AsyncFunction} push - add a new task to the `queue`. Calls `callback`
 * once the `worker` has finished processing the task. Instead of a single task,
 * a `tasks` array can be submitted. The respective callback is used for every
 * task in the list. Invoke with `queue.push(task, [callback])`,
 * @property {AsyncFunction} unshift - add a new task to the front of the `queue`.
 * Invoke with `queue.unshift(task, [callback])`.
 * @property {AsyncFunction} pushAsync - the same as `q.push`, except this returns
 * a promise that rejects if an error occurs.
 * @property {AsyncFunction} unshiftAsync - the same as `q.unshift`, except this returns
 * a promise that rejects if an error occurs.
 * @property {Function} remove - remove items from the queue that match a test
 * function.  The test function will be passed an object with a `data` property,
 * and a `priority` property, if this is a
 * [priorityQueue]{@link module:ControlFlow.priorityQueue} object.
 * Invoked with `queue.remove(testFn)`, where `testFn` is of the form
 * `function ({data, priority}) {}` and returns a Boolean.
 * @property {Function} saturated - a function that sets a callback that is
 * called when the number of running workers hits the `concurrency` limit, and
 * further tasks will be queued.  If the callback is omitted, `q.saturated()`
 * returns a promise for the next occurrence.
 * @property {Function} unsaturated - a function that sets a callback that is
 * called when the number of running workers is less than the `concurrency` &
 * `buffer` limits, and further tasks will not be queued. If the callback is
 * omitted, `q.unsaturated()` returns a promise for the next occurrence.
 * @property {number} buffer - A minimum threshold buffer in order to say that
 * the `queue` is `unsaturated`.
 * @property {Function} empty - a function that sets a callback that is called
 * when the last item from the `queue` is given to a `worker`. If the callback
 * is omitted, `q.empty()` returns a promise for the next occurrence.
 * @property {Function} drain - a function that sets a callback that is called
 * when the last item from the `queue` has returned from the `worker`. If the
 * callback is omitted, `q.drain()` returns a promise for the next occurrence.
 * @property {Function} error - a function that sets a callback that is called
 * when a task errors. Has the signature `function(error, task)`. If the
 * callback is omitted, `error()` returns a promise that rejects on the next
 * error.
 * @property {boolean} paused - a boolean for determining whether the queue is
 * in a paused state.
 * @property {Function} pause - a function that pauses the processing of tasks
 * until `resume()` is called. Invoke with `queue.pause()`.
 * @property {Function} resume - a function that resumes the processing of
 * queued tasks when the queue is paused. Invoke with `queue.resume()`.
 * @property {Function} kill - a function that removes the `drain` callback and
 * empties remaining tasks from the queue forcing it to go idle. No more tasks
 * should be pushed to the queue after calling this function. Invoke with `queue.kill()`.
 *
 * @example
 * const q = async.queue(worker, 2)
 * q.push(item1)
 * q.push(item2)
 * q.push(item3)
 * // queues are iterable, spread into an array to inspect
 * const items = [...q] // [item1, item2, item3]
 * // or use for of
 * for (let item of q) {
 *     console.log(item)
 * }
 *
 * q.drain(() => {
 *     console.log('all done')
 * })
 * // or
 * await q.drain()
 */

/**
 * Creates a `queue` object with the specified `concurrency`. Tasks added to the
 * `queue` are processed in parallel (up to the `concurrency` limit). If all
 * `worker`s are in progress, the task is queued until one becomes available.
 * Once a `worker` completes a `task`, that `task`'s callback is called.
 *
 * @name queue
 * @static
 * @memberOf module:ControlFlow
 * @method
 * @category Control Flow
 * @param {AsyncFunction} worker - An async function for processing a queued task.
 * If you want to handle errors from an individual task, pass a callback to
 * `q.push()`. Invoked with (task, callback).
 * @param {number} [concurrency=1] - An `integer` for determining how many
 * `worker` functions should be run in parallel.  If omitted, the concurrency
 * defaults to `1`.  If the concurrency is `0`, an error is thrown.
 * @returns {module:ControlFlow.QueueObject} A queue object to manage the tasks. Callbacks can be
 * attached as certain properties to listen for specific events during the
 * lifecycle of the queue.
 * @example
 *
 * // create a queue object with concurrency 2
 * var q = async.queue(function(task, callback) {
 *     console.log('hello ' + task.name);
 *     callback();
 * }, 2);
 *
 * // assign a callback
 * q.drain(function() {
 *     console.log('all items have been processed');
 * });
 * // or await the end
 * await q.drain()
 *
 * // assign an error callback
 * q.error(function(err, task) {
 *     console.error('task experienced an error');
 * });
 *
 * // add some items to the queue
 * q.push({name: 'foo'}, function(err) {
 *     console.log('finished processing foo');
 * });
 * // callback is optional
 * q.push({name: 'bar'});
 *
 * // add some items to the queue (batch-wise)
 * q.push([{name: 'baz'},{name: 'bay'},{name: 'bax'}], function(err) {
 *     console.log('finished processing item');
 * });
 *
 * // add some items to the front of the queue
 * q.unshift({name: 'bar'}, function (err) {
 *     console.log('finished processing bar');
 * });
 */
/* harmony default export */ function __WEBPACK_DEFAULT_EXPORT__(worker, concurrency) {
    var _worker = (0,_internal_wrapAsync_js__WEBPACK_IMPORTED_MODULE_0__["default"])(worker);
    return (0,_internal_queue_js__WEBPACK_IMPORTED_MODULE_1__["default"])((items, cb) => {
        _worker(items[0], cb);
    }, concurrency, 1);
}


/***/ }),

/***/ "./node_modules/base64-js/index.js":
/*!*****************************************!*\
  !*** ./node_modules/base64-js/index.js ***!
  \*****************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";


exports.byteLength = byteLength
exports.toByteArray = toByteArray
exports.fromByteArray = fromByteArray

var lookup = []
var revLookup = []
var Arr = typeof Uint8Array !== 'undefined' ? Uint8Array : Array

var code = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/'
for (var i = 0, len = code.length; i < len; ++i) {
  lookup[i] = code[i]
  revLookup[code.charCodeAt(i)] = i
}

// Support decoding URL-safe base64 strings, as Node.js does.
// See: https://en.wikipedia.org/wiki/Base64#URL_applications
revLookup['-'.charCodeAt(0)] = 62
revLookup['_'.charCodeAt(0)] = 63

function getLens (b64) {
  var len = b64.length

  if (len % 4 > 0) {
    throw new Error('Invalid string. Length must be a multiple of 4')
  }

  // Trim off extra bytes after placeholder bytes are found
  // See: https://github.com/beatgammit/base64-js/issues/42
  var validLen = b64.indexOf('=')
  if (validLen === -1) validLen = len

  var placeHoldersLen = validLen === len
    ? 0
    : 4 - (validLen % 4)

  return [validLen, placeHoldersLen]
}

// base64 is 4/3 + up to two characters of the original data
function byteLength (b64) {
  var lens = getLens(b64)
  var validLen = lens[0]
  var placeHoldersLen = lens[1]
  return ((validLen + placeHoldersLen) * 3 / 4) - placeHoldersLen
}

function _byteLength (b64, validLen, placeHoldersLen) {
  return ((validLen + placeHoldersLen) * 3 / 4) - placeHoldersLen
}

function toByteArray (b64) {
  var tmp
  var lens = getLens(b64)
  var validLen = lens[0]
  var placeHoldersLen = lens[1]

  var arr = new Arr(_byteLength(b64, validLen, placeHoldersLen))

  var curByte = 0

  // if there are placeholders, only get up to the last complete 4 chars
  var len = placeHoldersLen > 0
    ? validLen - 4
    : validLen

  var i
  for (i = 0; i < len; i += 4) {
    tmp =
      (revLookup[b64.charCodeAt(i)] << 18) |
      (revLookup[b64.charCodeAt(i + 1)] << 12) |
      (revLookup[b64.charCodeAt(i + 2)] << 6) |
      revLookup[b64.charCodeAt(i + 3)]
    arr[curByte++] = (tmp >> 16) & 0xFF
    arr[curByte++] = (tmp >> 8) & 0xFF
    arr[curByte++] = tmp & 0xFF
  }

  if (placeHoldersLen === 2) {
    tmp =
      (revLookup[b64.charCodeAt(i)] << 2) |
      (revLookup[b64.charCodeAt(i + 1)] >> 4)
    arr[curByte++] = tmp & 0xFF
  }

  if (placeHoldersLen === 1) {
    tmp =
      (revLookup[b64.charCodeAt(i)] << 10) |
      (revLookup[b64.charCodeAt(i + 1)] << 4) |
      (revLookup[b64.charCodeAt(i + 2)] >> 2)
    arr[curByte++] = (tmp >> 8) & 0xFF
    arr[curByte++] = tmp & 0xFF
  }

  return arr
}

function tripletToBase64 (num) {
  return lookup[num >> 18 & 0x3F] +
    lookup[num >> 12 & 0x3F] +
    lookup[num >> 6 & 0x3F] +
    lookup[num & 0x3F]
}

function encodeChunk (uint8, start, end) {
  var tmp
  var output = []
  for (var i = start; i < end; i += 3) {
    tmp =
      ((uint8[i] << 16) & 0xFF0000) +
      ((uint8[i + 1] << 8) & 0xFF00) +
      (uint8[i + 2] & 0xFF)
    output.push(tripletToBase64(tmp))
  }
  return output.join('')
}

function fromByteArray (uint8) {
  var tmp
  var len = uint8.length
  var extraBytes = len % 3 // if we have 1 byte left, pad 2 bytes
  var parts = []
  var maxChunkLength = 16383 // must be multiple of 3

  // go through the array every three bytes, we'll deal with trailing stuff later
  for (var i = 0, len2 = len - extraBytes; i < len2; i += maxChunkLength) {
    parts.push(encodeChunk(
      uint8, i, (i + maxChunkLength) > len2 ? len2 : (i + maxChunkLength)
    ))
  }

  // pad the end with zeros, but make sure to not forget the extra bytes
  if (extraBytes === 1) {
    tmp = uint8[len - 1]
    parts.push(
      lookup[tmp >> 2] +
      lookup[(tmp << 4) & 0x3F] +
      '=='
    )
  } else if (extraBytes === 2) {
    tmp = (uint8[len - 2] << 8) + uint8[len - 1]
    parts.push(
      lookup[tmp >> 10] +
      lookup[(tmp >> 4) & 0x3F] +
      lookup[(tmp << 2) & 0x3F] +
      '='
    )
  }

  return parts.join('')
}


/***/ }),

/***/ "./node_modules/bowser/es5.js":
/*!************************************!*\
  !*** ./node_modules/bowser/es5.js ***!
  \************************************/
/***/ (function(module) {

!function(e,t){ true?module.exports=t():0}(this,(function(){return function(e){var t={};function r(i){if(t[i])return t[i].exports;var n=t[i]={i:i,l:!1,exports:{}};return e[i].call(n.exports,n,n.exports,r),n.l=!0,n.exports}return r.m=e,r.c=t,r.d=function(e,t,i){r.o(e,t)||Object.defineProperty(e,t,{enumerable:!0,get:i})},r.r=function(e){"undefined"!=typeof Symbol&&Symbol.toStringTag&&Object.defineProperty(e,Symbol.toStringTag,{value:"Module"}),Object.defineProperty(e,"__esModule",{value:!0})},r.t=function(e,t){if(1&t&&(e=r(e)),8&t)return e;if(4&t&&"object"==typeof e&&e&&e.__esModule)return e;var i=Object.create(null);if(r.r(i),Object.defineProperty(i,"default",{enumerable:!0,value:e}),2&t&&"string"!=typeof e)for(var n in e)r.d(i,n,function(t){return e[t]}.bind(null,n));return i},r.n=function(e){var t=e&&e.__esModule?function(){return e.default}:function(){return e};return r.d(t,"a",t),t},r.o=function(e,t){return Object.prototype.hasOwnProperty.call(e,t)},r.p="",r(r.s=90)}({17:function(e,t,r){"use strict";t.__esModule=!0,t.default=void 0;var i=r(18),n=function(){function e(){}return e.getFirstMatch=function(e,t){var r=t.match(e);return r&&r.length>0&&r[1]||""},e.getSecondMatch=function(e,t){var r=t.match(e);return r&&r.length>1&&r[2]||""},e.matchAndReturnConst=function(e,t,r){if(e.test(t))return r},e.getWindowsVersionName=function(e){switch(e){case"NT":return"NT";case"XP":return"XP";case"NT 5.0":return"2000";case"NT 5.1":return"XP";case"NT 5.2":return"2003";case"NT 6.0":return"Vista";case"NT 6.1":return"7";case"NT 6.2":return"8";case"NT 6.3":return"8.1";case"NT 10.0":return"10";default:return}},e.getMacOSVersionName=function(e){var t=e.split(".").splice(0,2).map((function(e){return parseInt(e,10)||0}));if(t.push(0),10===t[0])switch(t[1]){case 5:return"Leopard";case 6:return"Snow Leopard";case 7:return"Lion";case 8:return"Mountain Lion";case 9:return"Mavericks";case 10:return"Yosemite";case 11:return"El Capitan";case 12:return"Sierra";case 13:return"High Sierra";case 14:return"Mojave";case 15:return"Catalina";default:return}},e.getAndroidVersionName=function(e){var t=e.split(".").splice(0,2).map((function(e){return parseInt(e,10)||0}));if(t.push(0),!(1===t[0]&&t[1]<5))return 1===t[0]&&t[1]<6?"Cupcake":1===t[0]&&t[1]>=6?"Donut":2===t[0]&&t[1]<2?"Eclair":2===t[0]&&2===t[1]?"Froyo":2===t[0]&&t[1]>2?"Gingerbread":3===t[0]?"Honeycomb":4===t[0]&&t[1]<1?"Ice Cream Sandwich":4===t[0]&&t[1]<4?"Jelly Bean":4===t[0]&&t[1]>=4?"KitKat":5===t[0]?"Lollipop":6===t[0]?"Marshmallow":7===t[0]?"Nougat":8===t[0]?"Oreo":9===t[0]?"Pie":void 0},e.getVersionPrecision=function(e){return e.split(".").length},e.compareVersions=function(t,r,i){void 0===i&&(i=!1);var n=e.getVersionPrecision(t),s=e.getVersionPrecision(r),o=Math.max(n,s),a=0,u=e.map([t,r],(function(t){var r=o-e.getVersionPrecision(t),i=t+new Array(r+1).join(".0");return e.map(i.split("."),(function(e){return new Array(20-e.length).join("0")+e})).reverse()}));for(i&&(a=o-Math.min(n,s)),o-=1;o>=a;){if(u[0][o]>u[1][o])return 1;if(u[0][o]===u[1][o]){if(o===a)return 0;o-=1}else if(u[0][o]<u[1][o])return-1}},e.map=function(e,t){var r,i=[];if(Array.prototype.map)return Array.prototype.map.call(e,t);for(r=0;r<e.length;r+=1)i.push(t(e[r]));return i},e.getBrowserAlias=function(e){return i.BROWSER_ALIASES_MAP[e]},e.getBrowserTypeByAlias=function(e){return i.BROWSER_MAP[e]||""},e}();t.default=n,e.exports=t.default},18:function(e,t,r){"use strict";t.__esModule=!0,t.ENGINE_MAP=t.OS_MAP=t.PLATFORMS_MAP=t.BROWSER_MAP=t.BROWSER_ALIASES_MAP=void 0;t.BROWSER_ALIASES_MAP={"Amazon Silk":"amazon_silk","Android Browser":"android",Bada:"bada",BlackBerry:"blackberry",Chrome:"chrome",Chromium:"chromium",Epiphany:"epiphany",Firefox:"firefox",Focus:"focus",Generic:"generic","Google Search":"google_search",Googlebot:"googlebot","Internet Explorer":"ie","K-Meleon":"k_meleon",Maxthon:"maxthon","Microsoft Edge":"edge","MZ Browser":"mz","NAVER Whale Browser":"naver",Opera:"opera","Opera Coast":"opera_coast",PhantomJS:"phantomjs",Puffin:"puffin",QupZilla:"qupzilla",QQ:"qq",QQLite:"qqlite",Safari:"safari",Sailfish:"sailfish","Samsung Internet for Android":"samsung_internet",SeaMonkey:"seamonkey",Sleipnir:"sleipnir",Swing:"swing",Tizen:"tizen","UC Browser":"uc",Vivaldi:"vivaldi","WebOS Browser":"webos",WeChat:"wechat","Yandex Browser":"yandex",Roku:"roku"};t.BROWSER_MAP={amazon_silk:"Amazon Silk",android:"Android Browser",bada:"Bada",blackberry:"BlackBerry",chrome:"Chrome",chromium:"Chromium",epiphany:"Epiphany",firefox:"Firefox",focus:"Focus",generic:"Generic",googlebot:"Googlebot",google_search:"Google Search",ie:"Internet Explorer",k_meleon:"K-Meleon",maxthon:"Maxthon",edge:"Microsoft Edge",mz:"MZ Browser",naver:"NAVER Whale Browser",opera:"Opera",opera_coast:"Opera Coast",phantomjs:"PhantomJS",puffin:"Puffin",qupzilla:"QupZilla",qq:"QQ Browser",qqlite:"QQ Browser Lite",safari:"Safari",sailfish:"Sailfish",samsung_internet:"Samsung Internet for Android",seamonkey:"SeaMonkey",sleipnir:"Sleipnir",swing:"Swing",tizen:"Tizen",uc:"UC Browser",vivaldi:"Vivaldi",webos:"WebOS Browser",wechat:"WeChat",yandex:"Yandex Browser"};t.PLATFORMS_MAP={tablet:"tablet",mobile:"mobile",desktop:"desktop",tv:"tv"};t.OS_MAP={WindowsPhone:"Windows Phone",Windows:"Windows",MacOS:"macOS",iOS:"iOS",Android:"Android",WebOS:"WebOS",BlackBerry:"BlackBerry",Bada:"Bada",Tizen:"Tizen",Linux:"Linux",ChromeOS:"Chrome OS",PlayStation4:"PlayStation 4",Roku:"Roku"};t.ENGINE_MAP={EdgeHTML:"EdgeHTML",Blink:"Blink",Trident:"Trident",Presto:"Presto",Gecko:"Gecko",WebKit:"WebKit"}},90:function(e,t,r){"use strict";t.__esModule=!0,t.default=void 0;var i,n=(i=r(91))&&i.__esModule?i:{default:i},s=r(18);function o(e,t){for(var r=0;r<t.length;r++){var i=t[r];i.enumerable=i.enumerable||!1,i.configurable=!0,"value"in i&&(i.writable=!0),Object.defineProperty(e,i.key,i)}}var a=function(){function e(){}var t,r,i;return e.getParser=function(e,t){if(void 0===t&&(t=!1),"string"!=typeof e)throw new Error("UserAgent should be a string");return new n.default(e,t)},e.parse=function(e){return new n.default(e).getResult()},t=e,i=[{key:"BROWSER_MAP",get:function(){return s.BROWSER_MAP}},{key:"ENGINE_MAP",get:function(){return s.ENGINE_MAP}},{key:"OS_MAP",get:function(){return s.OS_MAP}},{key:"PLATFORMS_MAP",get:function(){return s.PLATFORMS_MAP}}],(r=null)&&o(t.prototype,r),i&&o(t,i),e}();t.default=a,e.exports=t.default},91:function(e,t,r){"use strict";t.__esModule=!0,t.default=void 0;var i=u(r(92)),n=u(r(93)),s=u(r(94)),o=u(r(95)),a=u(r(17));function u(e){return e&&e.__esModule?e:{default:e}}var d=function(){function e(e,t){if(void 0===t&&(t=!1),null==e||""===e)throw new Error("UserAgent parameter can't be empty");this._ua=e,this.parsedResult={},!0!==t&&this.parse()}var t=e.prototype;return t.getUA=function(){return this._ua},t.test=function(e){return e.test(this._ua)},t.parseBrowser=function(){var e=this;this.parsedResult.browser={};var t=i.default.find((function(t){if("function"==typeof t.test)return t.test(e);if(t.test instanceof Array)return t.test.some((function(t){return e.test(t)}));throw new Error("Browser's test function is not valid")}));return t&&(this.parsedResult.browser=t.describe(this.getUA())),this.parsedResult.browser},t.getBrowser=function(){return this.parsedResult.browser?this.parsedResult.browser:this.parseBrowser()},t.getBrowserName=function(e){return e?String(this.getBrowser().name).toLowerCase()||"":this.getBrowser().name||""},t.getBrowserVersion=function(){return this.getBrowser().version},t.getOS=function(){return this.parsedResult.os?this.parsedResult.os:this.parseOS()},t.parseOS=function(){var e=this;this.parsedResult.os={};var t=n.default.find((function(t){if("function"==typeof t.test)return t.test(e);if(t.test instanceof Array)return t.test.some((function(t){return e.test(t)}));throw new Error("Browser's test function is not valid")}));return t&&(this.parsedResult.os=t.describe(this.getUA())),this.parsedResult.os},t.getOSName=function(e){var t=this.getOS().name;return e?String(t).toLowerCase()||"":t||""},t.getOSVersion=function(){return this.getOS().version},t.getPlatform=function(){return this.parsedResult.platform?this.parsedResult.platform:this.parsePlatform()},t.getPlatformType=function(e){void 0===e&&(e=!1);var t=this.getPlatform().type;return e?String(t).toLowerCase()||"":t||""},t.parsePlatform=function(){var e=this;this.parsedResult.platform={};var t=s.default.find((function(t){if("function"==typeof t.test)return t.test(e);if(t.test instanceof Array)return t.test.some((function(t){return e.test(t)}));throw new Error("Browser's test function is not valid")}));return t&&(this.parsedResult.platform=t.describe(this.getUA())),this.parsedResult.platform},t.getEngine=function(){return this.parsedResult.engine?this.parsedResult.engine:this.parseEngine()},t.getEngineName=function(e){return e?String(this.getEngine().name).toLowerCase()||"":this.getEngine().name||""},t.parseEngine=function(){var e=this;this.parsedResult.engine={};var t=o.default.find((function(t){if("function"==typeof t.test)return t.test(e);if(t.test instanceof Array)return t.test.some((function(t){return e.test(t)}));throw new Error("Browser's test function is not valid")}));return t&&(this.parsedResult.engine=t.describe(this.getUA())),this.parsedResult.engine},t.parse=function(){return this.parseBrowser(),this.parseOS(),this.parsePlatform(),this.parseEngine(),this},t.getResult=function(){return Object.assign({},this.parsedResult)},t.satisfies=function(e){var t=this,r={},i=0,n={},s=0;if(Object.keys(e).forEach((function(t){var o=e[t];"string"==typeof o?(n[t]=o,s+=1):"object"==typeof o&&(r[t]=o,i+=1)})),i>0){var o=Object.keys(r),a=o.find((function(e){return t.isOS(e)}));if(a){var u=this.satisfies(r[a]);if(void 0!==u)return u}var d=o.find((function(e){return t.isPlatform(e)}));if(d){var c=this.satisfies(r[d]);if(void 0!==c)return c}}if(s>0){var f=Object.keys(n).find((function(e){return t.isBrowser(e,!0)}));if(void 0!==f)return this.compareVersion(n[f])}},t.isBrowser=function(e,t){void 0===t&&(t=!1);var r=this.getBrowserName().toLowerCase(),i=e.toLowerCase(),n=a.default.getBrowserTypeByAlias(i);return t&&n&&(i=n.toLowerCase()),i===r},t.compareVersion=function(e){var t=[0],r=e,i=!1,n=this.getBrowserVersion();if("string"==typeof n)return">"===e[0]||"<"===e[0]?(r=e.substr(1),"="===e[1]?(i=!0,r=e.substr(2)):t=[],">"===e[0]?t.push(1):t.push(-1)):"="===e[0]?r=e.substr(1):"~"===e[0]&&(i=!0,r=e.substr(1)),t.indexOf(a.default.compareVersions(n,r,i))>-1},t.isOS=function(e){return this.getOSName(!0)===String(e).toLowerCase()},t.isPlatform=function(e){return this.getPlatformType(!0)===String(e).toLowerCase()},t.isEngine=function(e){return this.getEngineName(!0)===String(e).toLowerCase()},t.is=function(e){return this.isBrowser(e)||this.isOS(e)||this.isPlatform(e)},t.some=function(e){var t=this;return void 0===e&&(e=[]),e.some((function(e){return t.is(e)}))},e}();t.default=d,e.exports=t.default},92:function(e,t,r){"use strict";t.__esModule=!0,t.default=void 0;var i,n=(i=r(17))&&i.__esModule?i:{default:i};var s=/version\/(\d+(\.?_?\d+)+)/i,o=[{test:[/googlebot/i],describe:function(e){var t={name:"Googlebot"},r=n.default.getFirstMatch(/googlebot\/(\d+(\.\d+))/i,e)||n.default.getFirstMatch(s,e);return r&&(t.version=r),t}},{test:[/opera/i],describe:function(e){var t={name:"Opera"},r=n.default.getFirstMatch(s,e)||n.default.getFirstMatch(/(?:opera)[\s/](\d+(\.?_?\d+)+)/i,e);return r&&(t.version=r),t}},{test:[/opr\/|opios/i],describe:function(e){var t={name:"Opera"},r=n.default.getFirstMatch(/(?:opr|opios)[\s/](\S+)/i,e)||n.default.getFirstMatch(s,e);return r&&(t.version=r),t}},{test:[/SamsungBrowser/i],describe:function(e){var t={name:"Samsung Internet for Android"},r=n.default.getFirstMatch(s,e)||n.default.getFirstMatch(/(?:SamsungBrowser)[\s/](\d+(\.?_?\d+)+)/i,e);return r&&(t.version=r),t}},{test:[/Whale/i],describe:function(e){var t={name:"NAVER Whale Browser"},r=n.default.getFirstMatch(s,e)||n.default.getFirstMatch(/(?:whale)[\s/](\d+(?:\.\d+)+)/i,e);return r&&(t.version=r),t}},{test:[/MZBrowser/i],describe:function(e){var t={name:"MZ Browser"},r=n.default.getFirstMatch(/(?:MZBrowser)[\s/](\d+(?:\.\d+)+)/i,e)||n.default.getFirstMatch(s,e);return r&&(t.version=r),t}},{test:[/focus/i],describe:function(e){var t={name:"Focus"},r=n.default.getFirstMatch(/(?:focus)[\s/](\d+(?:\.\d+)+)/i,e)||n.default.getFirstMatch(s,e);return r&&(t.version=r),t}},{test:[/swing/i],describe:function(e){var t={name:"Swing"},r=n.default.getFirstMatch(/(?:swing)[\s/](\d+(?:\.\d+)+)/i,e)||n.default.getFirstMatch(s,e);return r&&(t.version=r),t}},{test:[/coast/i],describe:function(e){var t={name:"Opera Coast"},r=n.default.getFirstMatch(s,e)||n.default.getFirstMatch(/(?:coast)[\s/](\d+(\.?_?\d+)+)/i,e);return r&&(t.version=r),t}},{test:[/yabrowser/i],describe:function(e){var t={name:"Yandex Browser"},r=n.default.getFirstMatch(/(?:yabrowser)[\s/](\d+(\.?_?\d+)+)/i,e)||n.default.getFirstMatch(s,e);return r&&(t.version=r),t}},{test:[/ucbrowser/i],describe:function(e){var t={name:"UC Browser"},r=n.default.getFirstMatch(s,e)||n.default.getFirstMatch(/(?:ucbrowser)[\s/](\d+(\.?_?\d+)+)/i,e);return r&&(t.version=r),t}},{test:[/Maxthon|mxios/i],describe:function(e){var t={name:"Maxthon"},r=n.default.getFirstMatch(s,e)||n.default.getFirstMatch(/(?:Maxthon|mxios)[\s/](\d+(\.?_?\d+)+)/i,e);return r&&(t.version=r),t}},{test:[/epiphany/i],describe:function(e){var t={name:"Epiphany"},r=n.default.getFirstMatch(s,e)||n.default.getFirstMatch(/(?:epiphany)[\s/](\d+(\.?_?\d+)+)/i,e);return r&&(t.version=r),t}},{test:[/puffin/i],describe:function(e){var t={name:"Puffin"},r=n.default.getFirstMatch(s,e)||n.default.getFirstMatch(/(?:puffin)[\s/](\d+(\.?_?\d+)+)/i,e);return r&&(t.version=r),t}},{test:[/sleipnir/i],describe:function(e){var t={name:"Sleipnir"},r=n.default.getFirstMatch(s,e)||n.default.getFirstMatch(/(?:sleipnir)[\s/](\d+(\.?_?\d+)+)/i,e);return r&&(t.version=r),t}},{test:[/k-meleon/i],describe:function(e){var t={name:"K-Meleon"},r=n.default.getFirstMatch(s,e)||n.default.getFirstMatch(/(?:k-meleon)[\s/](\d+(\.?_?\d+)+)/i,e);return r&&(t.version=r),t}},{test:[/micromessenger/i],describe:function(e){var t={name:"WeChat"},r=n.default.getFirstMatch(/(?:micromessenger)[\s/](\d+(\.?_?\d+)+)/i,e)||n.default.getFirstMatch(s,e);return r&&(t.version=r),t}},{test:[/qqbrowser/i],describe:function(e){var t={name:/qqbrowserlite/i.test(e)?"QQ Browser Lite":"QQ Browser"},r=n.default.getFirstMatch(/(?:qqbrowserlite|qqbrowser)[/](\d+(\.?_?\d+)+)/i,e)||n.default.getFirstMatch(s,e);return r&&(t.version=r),t}},{test:[/msie|trident/i],describe:function(e){var t={name:"Internet Explorer"},r=n.default.getFirstMatch(/(?:msie |rv:)(\d+(\.?_?\d+)+)/i,e);return r&&(t.version=r),t}},{test:[/\sedg\//i],describe:function(e){var t={name:"Microsoft Edge"},r=n.default.getFirstMatch(/\sedg\/(\d+(\.?_?\d+)+)/i,e);return r&&(t.version=r),t}},{test:[/edg([ea]|ios)/i],describe:function(e){var t={name:"Microsoft Edge"},r=n.default.getSecondMatch(/edg([ea]|ios)\/(\d+(\.?_?\d+)+)/i,e);return r&&(t.version=r),t}},{test:[/vivaldi/i],describe:function(e){var t={name:"Vivaldi"},r=n.default.getFirstMatch(/vivaldi\/(\d+(\.?_?\d+)+)/i,e);return r&&(t.version=r),t}},{test:[/seamonkey/i],describe:function(e){var t={name:"SeaMonkey"},r=n.default.getFirstMatch(/seamonkey\/(\d+(\.?_?\d+)+)/i,e);return r&&(t.version=r),t}},{test:[/sailfish/i],describe:function(e){var t={name:"Sailfish"},r=n.default.getFirstMatch(/sailfish\s?browser\/(\d+(\.\d+)?)/i,e);return r&&(t.version=r),t}},{test:[/silk/i],describe:function(e){var t={name:"Amazon Silk"},r=n.default.getFirstMatch(/silk\/(\d+(\.?_?\d+)+)/i,e);return r&&(t.version=r),t}},{test:[/phantom/i],describe:function(e){var t={name:"PhantomJS"},r=n.default.getFirstMatch(/phantomjs\/(\d+(\.?_?\d+)+)/i,e);return r&&(t.version=r),t}},{test:[/slimerjs/i],describe:function(e){var t={name:"SlimerJS"},r=n.default.getFirstMatch(/slimerjs\/(\d+(\.?_?\d+)+)/i,e);return r&&(t.version=r),t}},{test:[/blackberry|\bbb\d+/i,/rim\stablet/i],describe:function(e){var t={name:"BlackBerry"},r=n.default.getFirstMatch(s,e)||n.default.getFirstMatch(/blackberry[\d]+\/(\d+(\.?_?\d+)+)/i,e);return r&&(t.version=r),t}},{test:[/(web|hpw)[o0]s/i],describe:function(e){var t={name:"WebOS Browser"},r=n.default.getFirstMatch(s,e)||n.default.getFirstMatch(/w(?:eb)?[o0]sbrowser\/(\d+(\.?_?\d+)+)/i,e);return r&&(t.version=r),t}},{test:[/bada/i],describe:function(e){var t={name:"Bada"},r=n.default.getFirstMatch(/dolfin\/(\d+(\.?_?\d+)+)/i,e);return r&&(t.version=r),t}},{test:[/tizen/i],describe:function(e){var t={name:"Tizen"},r=n.default.getFirstMatch(/(?:tizen\s?)?browser\/(\d+(\.?_?\d+)+)/i,e)||n.default.getFirstMatch(s,e);return r&&(t.version=r),t}},{test:[/qupzilla/i],describe:function(e){var t={name:"QupZilla"},r=n.default.getFirstMatch(/(?:qupzilla)[\s/](\d+(\.?_?\d+)+)/i,e)||n.default.getFirstMatch(s,e);return r&&(t.version=r),t}},{test:[/firefox|iceweasel|fxios/i],describe:function(e){var t={name:"Firefox"},r=n.default.getFirstMatch(/(?:firefox|iceweasel|fxios)[\s/](\d+(\.?_?\d+)+)/i,e);return r&&(t.version=r),t}},{test:[/chromium/i],describe:function(e){var t={name:"Chromium"},r=n.default.getFirstMatch(/(?:chromium)[\s/](\d+(\.?_?\d+)+)/i,e)||n.default.getFirstMatch(s,e);return r&&(t.version=r),t}},{test:[/chrome|crios|crmo/i],describe:function(e){var t={name:"Chrome"},r=n.default.getFirstMatch(/(?:chrome|crios|crmo)\/(\d+(\.?_?\d+)+)/i,e);return r&&(t.version=r),t}},{test:[/GSA/i],describe:function(e){var t={name:"Google Search"},r=n.default.getFirstMatch(/(?:GSA)\/(\d+(\.?_?\d+)+)/i,e);return r&&(t.version=r),t}},{test:function(e){var t=!e.test(/like android/i),r=e.test(/android/i);return t&&r},describe:function(e){var t={name:"Android Browser"},r=n.default.getFirstMatch(s,e);return r&&(t.version=r),t}},{test:[/playstation 4/i],describe:function(e){var t={name:"PlayStation 4"},r=n.default.getFirstMatch(s,e);return r&&(t.version=r),t}},{test:[/safari|applewebkit/i],describe:function(e){var t={name:"Safari"},r=n.default.getFirstMatch(s,e);return r&&(t.version=r),t}},{test:[/.*/i],describe:function(e){var t=-1!==e.search("\\(")?/^(.*)\/(.*)[ \t]\((.*)/:/^(.*)\/(.*) /;return{name:n.default.getFirstMatch(t,e),version:n.default.getSecondMatch(t,e)}}}];t.default=o,e.exports=t.default},93:function(e,t,r){"use strict";t.__esModule=!0,t.default=void 0;var i,n=(i=r(17))&&i.__esModule?i:{default:i},s=r(18);var o=[{test:[/Roku\/DVP/],describe:function(e){var t=n.default.getFirstMatch(/Roku\/DVP-(\d+\.\d+)/i,e);return{name:s.OS_MAP.Roku,version:t}}},{test:[/windows phone/i],describe:function(e){var t=n.default.getFirstMatch(/windows phone (?:os)?\s?(\d+(\.\d+)*)/i,e);return{name:s.OS_MAP.WindowsPhone,version:t}}},{test:[/windows/i],describe:function(e){var t=n.default.getFirstMatch(/Windows ((NT|XP)( \d\d?.\d)?)/i,e),r=n.default.getWindowsVersionName(t);return{name:s.OS_MAP.Windows,version:t,versionName:r}}},{test:[/macintosh/i],describe:function(e){var t=n.default.getFirstMatch(/mac os x (\d+(\.?_?\d+)+)/i,e).replace(/[_\s]/g,"."),r=n.default.getMacOSVersionName(t),i={name:s.OS_MAP.MacOS,version:t};return r&&(i.versionName=r),i}},{test:[/(ipod|iphone|ipad)/i],describe:function(e){var t=n.default.getFirstMatch(/os (\d+([_\s]\d+)*) like mac os x/i,e).replace(/[_\s]/g,".");return{name:s.OS_MAP.iOS,version:t}}},{test:function(e){var t=!e.test(/like android/i),r=e.test(/android/i);return t&&r},describe:function(e){var t=n.default.getFirstMatch(/android[\s/-](\d+(\.\d+)*)/i,e),r=n.default.getAndroidVersionName(t),i={name:s.OS_MAP.Android,version:t};return r&&(i.versionName=r),i}},{test:[/(web|hpw)[o0]s/i],describe:function(e){var t=n.default.getFirstMatch(/(?:web|hpw)[o0]s\/(\d+(\.\d+)*)/i,e),r={name:s.OS_MAP.WebOS};return t&&t.length&&(r.version=t),r}},{test:[/blackberry|\bbb\d+/i,/rim\stablet/i],describe:function(e){var t=n.default.getFirstMatch(/rim\stablet\sos\s(\d+(\.\d+)*)/i,e)||n.default.getFirstMatch(/blackberry\d+\/(\d+([_\s]\d+)*)/i,e)||n.default.getFirstMatch(/\bbb(\d+)/i,e);return{name:s.OS_MAP.BlackBerry,version:t}}},{test:[/bada/i],describe:function(e){var t=n.default.getFirstMatch(/bada\/(\d+(\.\d+)*)/i,e);return{name:s.OS_MAP.Bada,version:t}}},{test:[/tizen/i],describe:function(e){var t=n.default.getFirstMatch(/tizen[/\s](\d+(\.\d+)*)/i,e);return{name:s.OS_MAP.Tizen,version:t}}},{test:[/linux/i],describe:function(){return{name:s.OS_MAP.Linux}}},{test:[/CrOS/],describe:function(){return{name:s.OS_MAP.ChromeOS}}},{test:[/PlayStation 4/],describe:function(e){var t=n.default.getFirstMatch(/PlayStation 4[/\s](\d+(\.\d+)*)/i,e);return{name:s.OS_MAP.PlayStation4,version:t}}}];t.default=o,e.exports=t.default},94:function(e,t,r){"use strict";t.__esModule=!0,t.default=void 0;var i,n=(i=r(17))&&i.__esModule?i:{default:i},s=r(18);var o=[{test:[/googlebot/i],describe:function(){return{type:"bot",vendor:"Google"}}},{test:[/huawei/i],describe:function(e){var t=n.default.getFirstMatch(/(can-l01)/i,e)&&"Nova",r={type:s.PLATFORMS_MAP.mobile,vendor:"Huawei"};return t&&(r.model=t),r}},{test:[/nexus\s*(?:7|8|9|10).*/i],describe:function(){return{type:s.PLATFORMS_MAP.tablet,vendor:"Nexus"}}},{test:[/ipad/i],describe:function(){return{type:s.PLATFORMS_MAP.tablet,vendor:"Apple",model:"iPad"}}},{test:[/kftt build/i],describe:function(){return{type:s.PLATFORMS_MAP.tablet,vendor:"Amazon",model:"Kindle Fire HD 7"}}},{test:[/silk/i],describe:function(){return{type:s.PLATFORMS_MAP.tablet,vendor:"Amazon"}}},{test:[/tablet(?! pc)/i],describe:function(){return{type:s.PLATFORMS_MAP.tablet}}},{test:function(e){var t=e.test(/ipod|iphone/i),r=e.test(/like (ipod|iphone)/i);return t&&!r},describe:function(e){var t=n.default.getFirstMatch(/(ipod|iphone)/i,e);return{type:s.PLATFORMS_MAP.mobile,vendor:"Apple",model:t}}},{test:[/nexus\s*[0-6].*/i,/galaxy nexus/i],describe:function(){return{type:s.PLATFORMS_MAP.mobile,vendor:"Nexus"}}},{test:[/[^-]mobi/i],describe:function(){return{type:s.PLATFORMS_MAP.mobile}}},{test:function(e){return"blackberry"===e.getBrowserName(!0)},describe:function(){return{type:s.PLATFORMS_MAP.mobile,vendor:"BlackBerry"}}},{test:function(e){return"bada"===e.getBrowserName(!0)},describe:function(){return{type:s.PLATFORMS_MAP.mobile}}},{test:function(e){return"windows phone"===e.getBrowserName()},describe:function(){return{type:s.PLATFORMS_MAP.mobile,vendor:"Microsoft"}}},{test:function(e){var t=Number(String(e.getOSVersion()).split(".")[0]);return"android"===e.getOSName(!0)&&t>=3},describe:function(){return{type:s.PLATFORMS_MAP.tablet}}},{test:function(e){return"android"===e.getOSName(!0)},describe:function(){return{type:s.PLATFORMS_MAP.mobile}}},{test:function(e){return"macos"===e.getOSName(!0)},describe:function(){return{type:s.PLATFORMS_MAP.desktop,vendor:"Apple"}}},{test:function(e){return"windows"===e.getOSName(!0)},describe:function(){return{type:s.PLATFORMS_MAP.desktop}}},{test:function(e){return"linux"===e.getOSName(!0)},describe:function(){return{type:s.PLATFORMS_MAP.desktop}}},{test:function(e){return"playstation 4"===e.getOSName(!0)},describe:function(){return{type:s.PLATFORMS_MAP.tv}}},{test:function(e){return"roku"===e.getOSName(!0)},describe:function(){return{type:s.PLATFORMS_MAP.tv}}}];t.default=o,e.exports=t.default},95:function(e,t,r){"use strict";t.__esModule=!0,t.default=void 0;var i,n=(i=r(17))&&i.__esModule?i:{default:i},s=r(18);var o=[{test:function(e){return"microsoft edge"===e.getBrowserName(!0)},describe:function(e){if(/\sedg\//i.test(e))return{name:s.ENGINE_MAP.Blink};var t=n.default.getFirstMatch(/edge\/(\d+(\.?_?\d+)+)/i,e);return{name:s.ENGINE_MAP.EdgeHTML,version:t}}},{test:[/trident/i],describe:function(e){var t={name:s.ENGINE_MAP.Trident},r=n.default.getFirstMatch(/trident\/(\d+(\.?_?\d+)+)/i,e);return r&&(t.version=r),t}},{test:function(e){return e.test(/presto/i)},describe:function(e){var t={name:s.ENGINE_MAP.Presto},r=n.default.getFirstMatch(/presto\/(\d+(\.?_?\d+)+)/i,e);return r&&(t.version=r),t}},{test:function(e){var t=e.test(/gecko/i),r=e.test(/like gecko/i);return t&&!r},describe:function(e){var t={name:s.ENGINE_MAP.Gecko},r=n.default.getFirstMatch(/gecko\/(\d+(\.?_?\d+)+)/i,e);return r&&(t.version=r),t}},{test:[/(apple)?webkit\/537\.36/i],describe:function(){return{name:s.ENGINE_MAP.Blink}}},{test:[/(apple)?webkit/i],describe:function(e){var t={name:s.ENGINE_MAP.WebKit},r=n.default.getFirstMatch(/webkit\/(\d+(\.?_?\d+)+)/i,e);return r&&(t.version=r),t}}];t.default=o,e.exports=t.default}})}));

/***/ }),

/***/ "./node_modules/current-executing-script/dist/currentExecutingScript.js":
/*!******************************************************************************!*\
  !*** ./node_modules/current-executing-script/dist/currentExecutingScript.js ***!
  \******************************************************************************/
/***/ (function(module, exports) {

var __WEBPACK_AMD_DEFINE_FACTORY__, __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;/*!
 * currentExecutingScript
 * Get the currently executing script, regardless of its source/trigger/synchronicity. Similar to HTML5's `document.currentScript` but arguably much more useful!
 * Copyright (c) 2015 James M. Greene
 * Licensed MIT
 * https://github.com/JamesMGreene/currentExecutingScript
 * v0.1.3
 */
(function(root, factory) {
  if (true) {
    // AMD. Register as an anonymous module.
    !(__WEBPACK_AMD_DEFINE_ARRAY__ = [], __WEBPACK_AMD_DEFINE_FACTORY__ = (factory),
		__WEBPACK_AMD_DEFINE_RESULT__ = (typeof __WEBPACK_AMD_DEFINE_FACTORY__ === 'function' ?
		(__WEBPACK_AMD_DEFINE_FACTORY__.apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__)) : __WEBPACK_AMD_DEFINE_FACTORY__),
		__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));
  } else {}
}(
  // Current context/scope
  this || window,

  // Factory function to return the export
  function() {

var scriptReadyRegex = /^(interactive|loaded|complete)$/;

// This page's URL (minus query string and fragment identifer hash, if any)
var fullPageUrl = !!window.location ? window.location.href : null;
var pageUrl = fullPageUrl ? fullPageUrl.replace(/#.*$/, "").replace(/\?.*$/, "") || null : null;

// Live NodeList collection
var scripts = document.getElementsByTagName("script");

// Check if the browser supports the `readyState` property on `script` elements
var supportsScriptReadyState = "readyState" in (scripts[0] || document.createElement("script"));

// Lousy browser detection for [not] Opera
var isNotOpera = !window.opera || window.opera.toString() !== "[object Opera]";

// Detect if `document.currentScript` is supported
var hasNativeCurrentScriptAccessor = "currentScript" in document;

var originalStackDepthConfig;
// Detect if the V8 Error Stack Trace API is supported
if ("stackTraceLimit" in Error && Error.stackTraceLimit !== Infinity) {
  originalStackDepthConfig = Error.stackTraceLimit;
  Error.stackTraceLimit = Infinity;
}


// In some browsers (e.g. Chrome), you can get the current stack from an Error
// object instance without needing to throw it. Avoiding an unnecessary
// use of `throw` saves time and performance.
var hasStackBeforeThrowing = false,
    hasStackAfterThrowing = false;
(function() {
  try {
    var err = new Error();
    hasStackBeforeThrowing = typeof err.stack === "string" && !!err.stack;
    throw err;
  }
  catch (thrownErr) {
    hasStackAfterThrowing = typeof thrownErr.stack === "string" && !!thrownErr.stack;
  }
})();


// Normalize whitespace within a string
function normalizeWhitespace(str) {
  return str ? str.replace(/^\s+$|\s+$/g, "").replace(/\s\s+/g, " ") : "";
}

// Get script object based on the `src` URL
function getScriptFromUrl(url, eligibleScripts) {
  var i,
      script = null;

  eligibleScripts = eligibleScripts || scripts;

  if (typeof url === "string" && url) {
    for (i = eligibleScripts.length; i--; ) {
      if (eligibleScripts[i].src === url) {
        // NOTE: Could check if the same script URL is used by more than one `script` element
        // here... but let's not. That would yield less useful results in "loose" detection. ;)
        script = eligibleScripts[i];
        break;
      }
    }
  }
  return script;
}

// Get script object based on the caller function's source code body (text)
function getInlineScriptFromCallerSource(callerFnSource, eligibleScripts) {
  var i, inlineScriptText,
      script = null,
      callerSourceText = normalizeWhitespace(callerFnSource);

  eligibleScripts = eligibleScripts || scripts;

  if (callerFnSource && callerSourceText) {
    for (i = eligibleScripts.length; i--; ) {
      // Only look at inline scripts
      if (!eligibleScripts[i].hasAttribute("src")) {
        inlineScriptText = normalizeWhitespace(eligibleScripts[i].text);
        if (inlineScriptText.indexOf(callerSourceText) !== -1) {
          // If more than one match is found, don't return any
          if (script) {
            script = null;
            break;
          }
          script = eligibleScripts[i];
        }
      }
    }
  }

  return script;
}

// If there is only a single inline script on the page, return it; otherwise `null`
function getSoleInlineScript(eligibleScripts) {
  var i, len,
      script = null;
  eligibleScripts = eligibleScripts || scripts;
  for (i = 0, len = eligibleScripts.length; i < len; i++) {
    if (!eligibleScripts[i].hasAttribute("src")) {
      if (script) {
        script = null;
        break;
      }
      script = eligibleScripts[i];
    }
  }
  return script;
}

// Get the currently executing script URL from an Error stack trace
function getScriptUrlFromStack(stack, skipStackDepth) {
  var matches, remainingStack,
      url = null,
      ignoreMessage = typeof skipStackDepth === "number";
  skipStackDepth = ignoreMessage ? Math.round(skipStackDepth) : 0;
  if (typeof stack === "string" && stack) {
    if (ignoreMessage) {
      matches = stack.match(/(data:text\/javascript(?:;[^,]+)?,.+?|(?:|blob:)(?:http[s]?|file):\/\/[\/]?.+?\/[^:\)]*?)(?::\d+)(?::\d+)?/);
    }
    else {
      matches = stack.match(/^(?:|[^:@]*@|.+\)@(?=data:text\/javascript|blob|http[s]?|file)|.+?\s+(?: at |@)(?:[^:\(]+ )*[\(]?)(data:text\/javascript(?:;[^,]+)?,.+?|(?:|blob:)(?:http[s]?|file):\/\/[\/]?.+?\/[^:\)]*?)(?::\d+)(?::\d+)?/);

      if (!(matches && matches[1])) {
        matches = stack.match(/\)@(data:text\/javascript(?:;[^,]+)?,.+?|(?:|blob:)(?:http[s]?|file):\/\/[\/]?.+?\/[^:\)]*?)(?::\d+)(?::\d+)?/);
      }
    }

    if (matches && matches[1]) {
      if (skipStackDepth > 0) {
        remainingStack = stack.slice(stack.indexOf(matches[0]) + matches[0].length);
        url = getScriptUrlFromStack(remainingStack, (skipStackDepth - 1));
      }
      else {
        url = matches[1];
      }
    }

    // TODO: Handle more edge cases!
    // Fixes #1
    // See https://github.com/JamesMGreene/currentExecutingScript/issues/1

    // ???

  }
  return url;
}


// Get the farthest currently executing (i.e. yes, EXECUTING) `script` DOM
// element for the caller function, regardless of whether it is that `script`
// DOM element is currently being evaluated for the first time. The farthest
// currently executing `script` DOM element would typically be considered the
// originator of the current execution stack.
function _farthestExecutingScript() {
  /*jshint noarg:false */

  // TODO: Implement!
  // Fixes #3
  // See https://github.com/JamesMGreene/currentExecutingScript/issues/3
  return null;

/*
  // Yes, this IS possible, i.e. if a script removes other scripts (or itself)
  if (scripts.length === 0) {
    return null;
  }

  // Guaranteed accurate in IE 6-10.
  // Not accurate/supported in any other browsers.
  if (isNotOpera && supportsScriptReadyState) {
    for (var i = scripts.length; i--; ) {
      if (scripts[i].readyState === "interactive") {
        return scripts[i];
      }
    }
  }

  var stack,
      e = new Error();
  if (hasStackBeforeThrowing) {
    stack = e.stack;
  }
  if (!stack && hasStackAfterThrowing) {
    try {
      throw e;
    }
    catch (err) {
      // NOTE: Cannot use `err.sourceURL` or `err.fileName` as they will always be THIS script
      stack = err.stack;
    }
  }
  if (stack) {
    var url = getScriptUrlFromStack(stack, skipStackDepth);
    var script = getScriptFromUrl(url, scripts );
    if (!script && pageUrl && url === pageUrl) {
      // Try to find the correct inline script by searching through
      // inline scripts' text content for the caller function's source
      // code to be present. If the caller function's source code is
      // not available, see if there is only one inline script element
      // in the DOM and return that (even though it may be wrong)

      // TODO: Implement!
      // Fixes #4 in part
      // See https://github.com/JamesMGreene/currentExecutingScript/issues/4

      var callerFn = _farthestExecutingScript.caller || null,
          callerFnStack = [],
          callerFnSource = null;

      while (callerFn) {
        callerFnStack.push(callerFn);
        callerFn = callerFn.caller || null;
      }
      callerFn = callerFnStack.slice(-1)[0];
      callerFnSource = callerFn ? ("" + callerFn) : null;


      if (callerFnSource) {
        script = getInlineScriptFromCallerSource(callerFnSource);
      }
      else {
        // NOTE: This is a loose assumption that could be inaccurate!
        //
        // Inaccuracies:
        //  - If the inline script that initiated the call was also removed from the DOM.
        //  - If the call was initiated by an element's inline event handler,
        //    e.g. `<a onclick="(function() { alert(currentExecutingScript()); }()">click</a>`
        script = getSoleInlineScript();
      }
    }
    return script;
  }

  // NOTE: This is a loose assumption that could be inaccurate!
  //
  // Inaccuracies:
  //  - If a script is created dynamically and appended to some position
  //    other than the very end of the document.
  //  - If multiple scripts are created dynamically and all appended to the
  //    same position within the document (and do not have their `async` attributes
  //    set to `false`, at least in browsers that support async script evaluation.
  //    other than the very end of the document.
  //  - If any scripts are added with the `async` attribute set to `true` in a browser
  //    that supports it.
  //  - May get confused by `script` elements within `svg` elements
  return scripts[scripts.length - 1] || null;
*/
}


// Get the originating currently executing (i.e. yes, EXECUTING) `script` DOM
// element or attribute node (e.g. `onclick`) for the caller function,
// regardless of whether it is that `script` DOM element is currently being
// evaluated for the first time. The originating currently executing `script`
// DOM element [or attribute node] is the originator of the current execution stack.
function _originatingExecutingScript() {
  // TODO: Implement!
  // Fixes #2
  // See https://github.com/JamesMGreene/currentExecutingScript/issues/2
  return null;
}

// Get the nearest currently executing (i.e. yes, EXECUTING) `script` DOM
// element for the caller function, regardless of whether it is that `script`
// DOM element is currently being evaluated for the first time.
function _nearestExecutingScript() {
  /*jshint noarg:false */

  // Yes, this IS possible, i.e. if a script removes other scripts (or itself)
  if (scripts.length === 0) {
    return null;
  }

  var i, e, stack, url, script,
      eligibleScripts = [],
      skipStackDepth = _nearestExecutingScript.skipStackDepth || 1,

      // TODO: Implement!
      // Fixes #4 in part
      // See https://github.com/JamesMGreene/currentExecutingScript/issues/4
      callerFnSource = null;  //("" + (_nearestExecutingScript.caller || "")) || null;

  // This part will only help in IE 6-10.
  for (i = 0; i < scripts.length; i++) {
    if (isNotOpera && supportsScriptReadyState) {
      if (scriptReadyRegex.test(scripts[i].readyState)) {
        eligibleScripts.push(scripts[i]);
      }
    }
    else {
      eligibleScripts.push(scripts[i]);
    }
  }

  e = new Error();
  if (hasStackBeforeThrowing) {
    stack = e.stack;
  }
  if (!stack && hasStackAfterThrowing) {
    try {
      throw e;
    }
    catch (err) {
      // NOTE: Cannot use `err.sourceURL` or `err.fileName` as they will always be THIS script
      stack = err.stack;
    }
  }

  if (stack) {
    url = getScriptUrlFromStack(stack, skipStackDepth);
    script = getScriptFromUrl(url, eligibleScripts);

    if (!script && pageUrl && url === pageUrl) {
      // Try to find the correct inline script by searching through
      // inline scripts' text content for the caller function's source
      // code to be present.
      if (callerFnSource) {
        script = getInlineScriptFromCallerSource(callerFnSource, eligibleScripts);
      }
      // If the caller function's source code is not available, see if
      // there is only one inline script element in the DOM and return
      // that (even though it may be wrong)...
      else {
        // NOTE: This is a loose assumption that could be inaccurate!
        //
        // Inaccuracies:
        //  - If the inline script that initiated the call was also removed from the DOM.
        //  - If the call was initiated by an element's inline event handler,
        //    e.g. `<a onclick="(function() { alert(currentExecutingScript()); }()">click</a>`
        script = getSoleInlineScript(eligibleScripts);
      }
    }
  }

  //
  // Welcome to the Island of Inaccurate Assumptions!
  // NOTE: ALL of the following are loose assumptions that could be inaccurate!
  //

  if (!script) {
    // Inaccuracies:
    //  - If the inline script that initiated the call was also removed from the DOM.
    //  - If the call was initiated by an element's inline event handler,
    //    e.g. `<a onclick="(function() { alert(currentExecutingScript()); }()">click</a>`
    if (eligibleScripts.length === 1) {
      script = eligibleScripts[0];
    }
  }

  if (!script) {
    // Inaccuracies:
    //  - If script currently being synchronously evaluated by the parser is the
    //    originator of this call stack but NOT the source script of the caller/invocation
    //    e.g.
    //    ```html
    //    <script id="a">
    //    function getCurrentScriptCallerFn() {
    //      return currentExecutingScript.near();
    //    }
    //    </script>
    //    <script id="b">
    //    // Should get `script[id="a"]` but will get `script[id="b"]` instead
    //    getCurrentScriptCallerFn();
    //    </script>
    if (hasNativeCurrentScriptAccessor) {
      script = document.currentScript;
    }
  }

  if (!script) {
    // Inaccuracies:
    //  - If script currently being synchronously evaluated by the parser is the
    //    originator of this call stack but NOT the source script of the caller/invocation
    //    e.g.
    //    ```html
    //    <script id="a">
    //    function getCurrentScriptCallerFn() {
    //      return currentExecutingScript.near();
    //    }
    //    </script>
    //    <script id="b">
    //    // Should get `script[id="a"]` but will get `script[id="b"]` instead
    //    getCurrentScriptCallerFn();
    //    </script>
    if (isNotOpera && supportsScriptReadyState) {
      for (i = eligibleScripts.length; i--; ) {
        if (eligibleScripts[i].readyState === "interactive") {
          script = eligibleScripts[i];
          break;
        }
      }
    }
  }

  if (!script) {
    // Inaccuracies:
    //  - If a script is created dynamically and appended to some position
    //    other than the very end of the document.
    //  - If multiple scripts are created dynamically and all appended to the
    //    same position within the document (and do not have their `async` attributes
    //    set to `false`, at least in browsers that support async script evaluation.
    //    other than the very end of the document.
    //  - If any scripts are added with the `async` attribute set to `true` in a browser
    //    that supports it.
    //  - May get confused by `script` elements within `svg` elements
    //  - If script currently being synchronously evaluated by the parser is the
    //    originator of this call stack but NOT the source script of the caller/invocation
    //    e.g.
    //    ```html
    //    <script id="a">
    //    function getCurrentScriptCallerFn() {
    //      return currentExecutingScript.near();
    //    }
    //    </script>
    //    <script id="b">
    //    // Should get `script[id="a"]` but will get `script[id="b"]` instead
    //    getCurrentScriptCallerFn();
    //    </script>
    //    ```
    script = eligibleScripts[eligibleScripts.length - 1] || null;
  }

  return script;
}

// Default stack depth to skip over when analyzing call stack frames
_nearestExecutingScript.skipStackDepth = 1;



    //
    // Export the API
    //
    var currentExecutingScript    = _nearestExecutingScript;      // default
    currentExecutingScript.near   = _nearestExecutingScript;
    currentExecutingScript.far    = _farthestExecutingScript;
    currentExecutingScript.origin = _originatingExecutingScript;


    // Just return a value to define the module export.
    // This example returns an object, but the module
    // can return a function as the exported value.
    return currentExecutingScript;
  })
);


/***/ }),

/***/ "./src/ServerOptions.ts":
/*!******************************!*\
  !*** ./src/ServerOptions.ts ***!
  \******************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (__WEBPACK_DEFAULT_EXPORT__)
/* harmony export */ });

const serverOptions = {
  hosts: {
    domain: "meet.jit.si",
    focus: "focus.meet.jit.si",
    muc: "conference.meet.jit.si"
  },
  bosh: "https://meet.jit.si/http-bind"
};
/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (serverOptions);


/***/ }),

/***/ "./src/index.ts":
/*!**********************!*\
  !*** ./src/index.ts ***!
  \**********************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   author: () => (/* binding */ author),
/* harmony export */   "default": () => (__WEBPACK_DEFAULT_EXPORT__),
/* harmony export */   description: () => (/* binding */ description),
/* harmony export */   jspatcher: () => (/* binding */ jspatcher),
/* harmony export */   keywords: () => (/* binding */ keywords),
/* harmony export */   license: () => (/* binding */ license),
/* harmony export */   name: () => (/* binding */ name),
/* harmony export */   version: () => (/* binding */ version)
/* harmony export */ });
/* harmony import */ var _package_info__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./package-info */ "./src/package-info.ts");

var __defProp = Object.defineProperty;
var __getOwnPropSymbols = Object.getOwnPropertySymbols;
var __hasOwnProp = Object.prototype.hasOwnProperty;
var __propIsEnum = Object.prototype.propertyIsEnumerable;
var __defNormalProp = (obj, key, value) => key in obj ? __defProp(obj, key, { enumerable: true, configurable: true, writable: true, value }) : obj[key] = value;
var __spreadValues = (a, b) => {
  for (var prop in b || (b = {}))
    if (__hasOwnProp.call(b, prop))
      __defNormalProp(a, prop, b[prop]);
  if (__getOwnPropSymbols)
    for (var prop of __getOwnPropSymbols(b)) {
      if (__propIsEnum.call(b, prop))
        __defNormalProp(a, prop, b[prop]);
    }
  return a;
};

const name = _package_info__WEBPACK_IMPORTED_MODULE_0__["default"].name.split("/").pop().replace(/^package-/, "");
const { author, license, keywords, version, description, jspatcher } = _package_info__WEBPACK_IMPORTED_MODULE_0__["default"];
/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (__spreadValues({ name, author, license, keywords, version, description }, jspatcher));


/***/ }),

/***/ "./src/objects/base.ts":
/*!*****************************!*\
  !*** ./src/objects/base.ts ***!
  \*****************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (/* binding */ JitsiObject)
/* harmony export */ });
/* harmony import */ var _index__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../index */ "./src/index.ts");
/* harmony import */ var _sdk__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../sdk */ "./src/sdk.ts");



class JitsiObject extends _sdk__WEBPACK_IMPORTED_MODULE_1__.DefaultObject {
}
JitsiObject.package = _index__WEBPACK_IMPORTED_MODULE_0__.name;
JitsiObject.author = _index__WEBPACK_IMPORTED_MODULE_0__.author;
JitsiObject.version = _index__WEBPACK_IMPORTED_MODULE_0__.version;
JitsiObject.description = _index__WEBPACK_IMPORTED_MODULE_0__.description;


/***/ }),

/***/ "./src/objects/meeting.ts":
/*!********************************!*\
  !*** ./src/objects/meeting.ts ***!
  \********************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (/* binding */ Meeting)
/* harmony export */ });
/* harmony import */ var _shren_lib_jitsi_meet__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @shren/lib-jitsi-meet */ "./node_modules/@shren/lib-jitsi-meet/dist/esm/JitsiMeetJS.js");
/* harmony import */ var _base__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./base */ "./src/objects/base.ts");
/* harmony import */ var _sdk__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../sdk */ "./src/sdk.ts");
/* harmony import */ var _ServerOptions__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../ServerOptions */ "./src/ServerOptions.ts");





_shren_lib_jitsi_meet__WEBPACK_IMPORTED_MODULE_0__["default"].setLogLevel(_shren_lib_jitsi_meet__WEBPACK_IMPORTED_MODULE_0__["default"].logLevels.ERROR);
class Meeting extends _base__WEBPACK_IMPORTED_MODULE_1__["default"] {
  constructor() {
    super(...arguments);
    this._ = {
      audioInStreamNode: this.audioCtx.createMediaStreamDestination(),
      audioOutGainNode: this.audioCtx.createGain(),
      connection: null,
      room: null,
      streamMap: {},
      audioMap: {},
      localTrack: null
    };
    this.handleRemoteTrackAdded = (track) => {
      if (track.isLocal())
        return;
      if (track.getType() !== "audio")
        return;
      const participant = track.getParticipantId();
      const stream = track.getOriginalStream();
      const audio = new Audio();
      audio.muted = true;
      audio.srcObject = stream;
      const streamSourceNode = this.audioCtx.createMediaStreamSource(audio.srcObject);
      audio.play();
      if (!this._.streamMap[participant])
        this._.streamMap[participant] = /* @__PURE__ */ new Set([streamSourceNode]);
      else
        this._.streamMap[participant].add(streamSourceNode);
      if (!this._.audioMap[participant])
        this._.audioMap[participant] = /* @__PURE__ */ new Set([audio]);
      else
        this._.audioMap[participant].add(audio);
      streamSourceNode.connect(this._.audioOutGainNode);
      track.addEventListener(_shren_lib_jitsi_meet__WEBPACK_IMPORTED_MODULE_0__["default"].events.track.LOCAL_TRACK_STOPPED, () => {
        var _a, _b;
        (_a = this._.streamMap[participant]) == null ? void 0 : _a.delete(streamSourceNode);
        (_b = this._.audioMap[participant]) == null ? void 0 : _b.delete(audio);
        streamSourceNode.disconnect();
        audio.pause();
      });
    };
    this.handleRemoteTrackRemoved = (track) => {
      var _a, _b;
      const participant = track.getParticipantId();
      if (!participant)
        return;
      const stream = track.getOriginalStream();
      const streamSourceNode = [...this._.streamMap[participant]].find((node) => node.mediaStream === stream);
      const audio = [...this._.audioMap[participant]].find((audio2) => audio2.srcObject === stream);
      if (streamSourceNode)
        (_a = this._.streamMap[participant]) == null ? void 0 : _a.delete(streamSourceNode);
      if (audio)
        (_b = this._.audioMap[participant]) == null ? void 0 : _b.delete(audio);
      streamSourceNode == null ? void 0 : streamSourceNode.disconnect();
      audio == null ? void 0 : audio.pause();
    };
    this.handleUserLeft = (id) => {
      [...this._.streamMap[id]].forEach((node) => node.disconnect());
      [...this._.audioMap[id]].forEach((audio) => audio.pause());
      this._.streamMap[id].clear();
      this._.audioMap[id].clear();
    };
    this.handleConferenceJoined = (room) => {
      const [track] = _shren_lib_jitsi_meet__WEBPACK_IMPORTED_MODULE_0__["default"].util.RTC.createLocalTracks([{
        mediaType: "audio",
        stream: this._.audioInStreamNode.stream,
        track: this._.audioInStreamNode.stream.getAudioTracks()[0]
      }]);
      this._.localTrack = track;
      room.addTrack(track);
      track.unmute();
    };
    this.handleMessageReceived = (id, message, timestamp) => {
      var _a;
      const username = (_a = this._.room.getParticipantById(id)) == null ? void 0 : _a.getDisplayName();
      this.outlet(0, { username, message, timestamp });
    };
    this.handleConnectionSuccess = () => {
      const confOptions = {};
      const room = this._.connection.initJitsiConference(this.args[0], confOptions);
      this._.room = room;
      this.outlet(1, room);
      room.on(_shren_lib_jitsi_meet__WEBPACK_IMPORTED_MODULE_0__["default"].events.conference.TRACK_ADDED, this.handleRemoteTrackAdded);
      room.on(_shren_lib_jitsi_meet__WEBPACK_IMPORTED_MODULE_0__["default"].events.conference.TRACK_REMOVED, this.handleRemoteTrackRemoved);
      room.on(_shren_lib_jitsi_meet__WEBPACK_IMPORTED_MODULE_0__["default"].events.conference.CONFERENCE_JOINED, () => this.handleConferenceJoined(room));
      room.on(_shren_lib_jitsi_meet__WEBPACK_IMPORTED_MODULE_0__["default"].events.conference.MESSAGE_RECEIVED, this.handleMessageReceived);
      room.on(_shren_lib_jitsi_meet__WEBPACK_IMPORTED_MODULE_0__["default"].events.conference.USER_LEFT, this.handleUserLeft);
      room.setDisplayName(this.getProp("username"));
      room.join(null);
    };
    this.handleConnectionFailed = () => {
      this.error("Connection Failed.");
      this.handleConnectionDisconnect();
    };
    this.handleConnectionDisconnect = async () => {
      var _a, _b, _c, _d;
      (_a = this._.connection) == null ? void 0 : _a.removeEventListener(_shren_lib_jitsi_meet__WEBPACK_IMPORTED_MODULE_0__["default"].events.connection.CONNECTION_ESTABLISHED, this.handleConnectionSuccess);
      (_b = this._.connection) == null ? void 0 : _b.removeEventListener(_shren_lib_jitsi_meet__WEBPACK_IMPORTED_MODULE_0__["default"].events.connection.CONNECTION_FAILED, this.handleConnectionFailed);
      (_c = this._.connection) == null ? void 0 : _c.removeEventListener(_shren_lib_jitsi_meet__WEBPACK_IMPORTED_MODULE_0__["default"].events.connection.CONNECTION_DISCONNECTED, this.handleConnectionDisconnect);
      for (const id in this._.streamMap) {
        [...this._.streamMap[id]].forEach((node) => node.disconnect());
        this._.streamMap[id].clear();
      }
      for (const id in this._.audioMap) {
        [...this._.audioMap[id]].forEach((audio) => audio.pause());
        this._.audioMap[id].clear();
      }
      this._.connection = void 0;
      this._.room = void 0;
      await ((_d = this._.localTrack) == null ? void 0 : _d.dispose());
    };
    this.connect = () => {
      const connection = new _shren_lib_jitsi_meet__WEBPACK_IMPORTED_MODULE_0__["default"].JitsiConnection(null, null, _ServerOptions__WEBPACK_IMPORTED_MODULE_3__["default"]);
      this._.connection = connection;
      connection.addEventListener(_shren_lib_jitsi_meet__WEBPACK_IMPORTED_MODULE_0__["default"].events.connection.CONNECTION_ESTABLISHED, this.handleConnectionSuccess);
      connection.addEventListener(_shren_lib_jitsi_meet__WEBPACK_IMPORTED_MODULE_0__["default"].events.connection.CONNECTION_FAILED, this.handleConnectionFailed);
      connection.addEventListener(_shren_lib_jitsi_meet__WEBPACK_IMPORTED_MODULE_0__["default"].events.connection.CONNECTION_DISCONNECTED, this.handleConnectionDisconnect);
      connection.connect({});
    };
  }
  subscribe() {
    super.subscribe();
    this.on("preInit", () => {
      this.inlets = 1;
      this.outlets = 1;
      this.inletAudioConnections = [{ node: this._.audioInStreamNode, index: 0 }];
      this.outletAudioConnections = [{ node: this._.audioOutGainNode, index: 0 }];
    });
    this.on("postInit", () => {
      _shren_lib_jitsi_meet__WEBPACK_IMPORTED_MODULE_0__["default"].init({
        disableAudioLevels: true,
        audioQuality: {
          stereo: false,
          opusMaxAverageBitrate: ~~+this.getProp("opusMaxAverageBitrate"),
          enableOpusDtx: false
        }
      });
      this.connect();
    });
    this.on("argsUpdated", async ({ args }) => {
      var _a, _b;
      await this.handleConnectionDisconnect();
      await ((_a = this._.room) == null ? void 0 : _a.leave());
      await ((_b = this._.connection) == null ? void 0 : _b.disconnect());
      this.connect();
    });
    this.on("propsUpdated", ({ props: { username } }) => {
      var _a;
      if (username)
        (_a = this._.room) == null ? void 0 : _a.setDisplayName(username);
    });
    this.on("destroy", async () => {
      var _a, _b;
      await this.handleConnectionDisconnect();
      await ((_a = this._.room) == null ? void 0 : _a.leave());
      await ((_b = this._.connection) == null ? void 0 : _b.disconnect());
    });
    this.on("inlet", async ({ data, inlet }) => {
      if (inlet === 0) {
        if ((0,_sdk__WEBPACK_IMPORTED_MODULE_2__.isBang)(data)) {
          if (!this._.connection)
            this.connect();
        } else if (typeof data === "string") {
          if (this._.room) {
            this._.room.sendMessage(data);
          }
        } else if (typeof data === "object") {
          if (this._.room) {
            const id = this._.room.getParticipants().find((p) => p.getDisplayName() === data.username).getId();
            if (id)
              this._.room.sendMessage(data.message, id);
          }
        }
      }
    });
  }
}
Meeting.description = "Send/Receive Audio or Text Message to a Jitsi Meeting";
Meeting.inlets = [{
  isHot: true,
  type: "signal",
  description: "Audio to send, text string to broadcast, { username: string; message: string } to send private message"
}];
Meeting.outlets = [{
  type: "signal",
  description: "Audio and text received, text message under format { username: string; message: string }"
}, {
  type: "object",
  description: "The JitsiConference instance"
}];
Meeting.args = [{
  type: "string",
  optional: true,
  description: "Jitsi Meeting Name",
  default: `jspatcher${new Date().toISOString().slice(0, 10).replace("-", "")}`
}];
Meeting.props = {
  opusMaxAverageBitrate: {
    type: "number",
    description: "Jitsi audio quality, Value to fit the 6000 to 510000 range",
    default: 48e3
  },
  username: {
    type: "string",
    description: "Jitsi display username in the room",
    default: `JSPatcher User ${Math.random().toFixed(3).slice(2)}`
  }
};


/***/ }),

/***/ "./src/package-info.ts":
/*!*****************************!*\
  !*** ./src/package-info.ts ***!
  \*****************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
var _package_json__WEBPACK_IMPORTED_MODULE_0___namespace_cache;
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (__WEBPACK_DEFAULT_EXPORT__)
/* harmony export */ });
/* harmony import */ var _package_json__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../package.json */ "./package.json");


/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (/*#__PURE__*/ (_package_json__WEBPACK_IMPORTED_MODULE_0___namespace_cache || (_package_json__WEBPACK_IMPORTED_MODULE_0___namespace_cache = __webpack_require__.t(_package_json__WEBPACK_IMPORTED_MODULE_0__, 2))));


/***/ }),

/***/ "./src/sdk.ts":
/*!********************!*\
  !*** ./src/sdk.ts ***!
  \********************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   Bang: () => (/* binding */ Bang),
/* harmony export */   BaseObject: () => (/* binding */ BaseObject),
/* harmony export */   BaseUI: () => (/* binding */ BaseUI),
/* harmony export */   Box: () => (/* binding */ Box),
/* harmony export */   DefaultObject: () => (/* binding */ DefaultObject),
/* harmony export */   DefaultUI: () => (/* binding */ DefaultUI),
/* harmony export */   Line: () => (/* binding */ Line),
/* harmony export */   Patcher: () => (/* binding */ Patcher),
/* harmony export */   React: () => (/* binding */ React),
/* harmony export */   Utils: () => (/* binding */ Utils),
/* harmony export */   generateDefaultObject: () => (/* binding */ generateDefaultObject),
/* harmony export */   generateRemoteObject: () => (/* binding */ generateRemoteObject),
/* harmony export */   generateRemotedObject: () => (/* binding */ generateRemotedObject),
/* harmony export */   isBang: () => (/* binding */ isBang)
/* harmony export */ });

const sdk = globalThis.jspatcherEnv.sdk;
const {
  React,
  Patcher,
  Box,
  Line,
  BaseObject,
  BaseUI,
  DefaultObject,
  DefaultUI,
  generateRemotedObject,
  generateDefaultObject,
  generateRemoteObject,
  Bang,
  isBang,
  Utils
} = sdk;


/***/ }),

/***/ "./node_modules/events/events.js":
/*!***************************************!*\
  !*** ./node_modules/events/events.js ***!
  \***************************************/
/***/ ((module) => {

"use strict";
// Copyright Joyent, Inc. and other Node contributors.
//
// Permission is hereby granted, free of charge, to any person obtaining a
// copy of this software and associated documentation files (the
// "Software"), to deal in the Software without restriction, including
// without limitation the rights to use, copy, modify, merge, publish,
// distribute, sublicense, and/or sell copies of the Software, and to permit
// persons to whom the Software is furnished to do so, subject to the
// following conditions:
//
// The above copyright notice and this permission notice shall be included
// in all copies or substantial portions of the Software.
//
// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS
// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN
// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,
// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR
// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE
// USE OR OTHER DEALINGS IN THE SOFTWARE.



var R = typeof Reflect === 'object' ? Reflect : null
var ReflectApply = R && typeof R.apply === 'function'
  ? R.apply
  : function ReflectApply(target, receiver, args) {
    return Function.prototype.apply.call(target, receiver, args);
  }

var ReflectOwnKeys
if (R && typeof R.ownKeys === 'function') {
  ReflectOwnKeys = R.ownKeys
} else if (Object.getOwnPropertySymbols) {
  ReflectOwnKeys = function ReflectOwnKeys(target) {
    return Object.getOwnPropertyNames(target)
      .concat(Object.getOwnPropertySymbols(target));
  };
} else {
  ReflectOwnKeys = function ReflectOwnKeys(target) {
    return Object.getOwnPropertyNames(target);
  };
}

function ProcessEmitWarning(warning) {
  if (console && console.warn) console.warn(warning);
}

var NumberIsNaN = Number.isNaN || function NumberIsNaN(value) {
  return value !== value;
}

function EventEmitter() {
  EventEmitter.init.call(this);
}
module.exports = EventEmitter;
module.exports.once = once;

// Backwards-compat with node 0.10.x
EventEmitter.EventEmitter = EventEmitter;

EventEmitter.prototype._events = undefined;
EventEmitter.prototype._eventsCount = 0;
EventEmitter.prototype._maxListeners = undefined;

// By default EventEmitters will print a warning if more than 10 listeners are
// added to it. This is a useful default which helps finding memory leaks.
var defaultMaxListeners = 10;

function checkListener(listener) {
  if (typeof listener !== 'function') {
    throw new TypeError('The "listener" argument must be of type Function. Received type ' + typeof listener);
  }
}

Object.defineProperty(EventEmitter, 'defaultMaxListeners', {
  enumerable: true,
  get: function() {
    return defaultMaxListeners;
  },
  set: function(arg) {
    if (typeof arg !== 'number' || arg < 0 || NumberIsNaN(arg)) {
      throw new RangeError('The value of "defaultMaxListeners" is out of range. It must be a non-negative number. Received ' + arg + '.');
    }
    defaultMaxListeners = arg;
  }
});

EventEmitter.init = function() {

  if (this._events === undefined ||
      this._events === Object.getPrototypeOf(this)._events) {
    this._events = Object.create(null);
    this._eventsCount = 0;
  }

  this._maxListeners = this._maxListeners || undefined;
};

// Obviously not all Emitters should be limited to 10. This function allows
// that to be increased. Set to zero for unlimited.
EventEmitter.prototype.setMaxListeners = function setMaxListeners(n) {
  if (typeof n !== 'number' || n < 0 || NumberIsNaN(n)) {
    throw new RangeError('The value of "n" is out of range. It must be a non-negative number. Received ' + n + '.');
  }
  this._maxListeners = n;
  return this;
};

function _getMaxListeners(that) {
  if (that._maxListeners === undefined)
    return EventEmitter.defaultMaxListeners;
  return that._maxListeners;
}

EventEmitter.prototype.getMaxListeners = function getMaxListeners() {
  return _getMaxListeners(this);
};

EventEmitter.prototype.emit = function emit(type) {
  var args = [];
  for (var i = 1; i < arguments.length; i++) args.push(arguments[i]);
  var doError = (type === 'error');

  var events = this._events;
  if (events !== undefined)
    doError = (doError && events.error === undefined);
  else if (!doError)
    return false;

  // If there is no 'error' event listener then throw.
  if (doError) {
    var er;
    if (args.length > 0)
      er = args[0];
    if (er instanceof Error) {
      // Note: The comments on the `throw` lines are intentional, they show
      // up in Node's output if this results in an unhandled exception.
      throw er; // Unhandled 'error' event
    }
    // At least give some kind of context to the user
    var err = new Error('Unhandled error.' + (er ? ' (' + er.message + ')' : ''));
    err.context = er;
    throw err; // Unhandled 'error' event
  }

  var handler = events[type];

  if (handler === undefined)
    return false;

  if (typeof handler === 'function') {
    ReflectApply(handler, this, args);
  } else {
    var len = handler.length;
    var listeners = arrayClone(handler, len);
    for (var i = 0; i < len; ++i)
      ReflectApply(listeners[i], this, args);
  }

  return true;
};

function _addListener(target, type, listener, prepend) {
  var m;
  var events;
  var existing;

  checkListener(listener);

  events = target._events;
  if (events === undefined) {
    events = target._events = Object.create(null);
    target._eventsCount = 0;
  } else {
    // To avoid recursion in the case that type === "newListener"! Before
    // adding it to the listeners, first emit "newListener".
    if (events.newListener !== undefined) {
      target.emit('newListener', type,
                  listener.listener ? listener.listener : listener);

      // Re-assign `events` because a newListener handler could have caused the
      // this._events to be assigned to a new object
      events = target._events;
    }
    existing = events[type];
  }

  if (existing === undefined) {
    // Optimize the case of one listener. Don't need the extra array object.
    existing = events[type] = listener;
    ++target._eventsCount;
  } else {
    if (typeof existing === 'function') {
      // Adding the second element, need to change to array.
      existing = events[type] =
        prepend ? [listener, existing] : [existing, listener];
      // If we've already got an array, just append.
    } else if (prepend) {
      existing.unshift(listener);
    } else {
      existing.push(listener);
    }

    // Check for listener leak
    m = _getMaxListeners(target);
    if (m > 0 && existing.length > m && !existing.warned) {
      existing.warned = true;
      // No error code for this since it is a Warning
      // eslint-disable-next-line no-restricted-syntax
      var w = new Error('Possible EventEmitter memory leak detected. ' +
                          existing.length + ' ' + String(type) + ' listeners ' +
                          'added. Use emitter.setMaxListeners() to ' +
                          'increase limit');
      w.name = 'MaxListenersExceededWarning';
      w.emitter = target;
      w.type = type;
      w.count = existing.length;
      ProcessEmitWarning(w);
    }
  }

  return target;
}

EventEmitter.prototype.addListener = function addListener(type, listener) {
  return _addListener(this, type, listener, false);
};

EventEmitter.prototype.on = EventEmitter.prototype.addListener;

EventEmitter.prototype.prependListener =
    function prependListener(type, listener) {
      return _addListener(this, type, listener, true);
    };

function onceWrapper() {
  if (!this.fired) {
    this.target.removeListener(this.type, this.wrapFn);
    this.fired = true;
    if (arguments.length === 0)
      return this.listener.call(this.target);
    return this.listener.apply(this.target, arguments);
  }
}

function _onceWrap(target, type, listener) {
  var state = { fired: false, wrapFn: undefined, target: target, type: type, listener: listener };
  var wrapped = onceWrapper.bind(state);
  wrapped.listener = listener;
  state.wrapFn = wrapped;
  return wrapped;
}

EventEmitter.prototype.once = function once(type, listener) {
  checkListener(listener);
  this.on(type, _onceWrap(this, type, listener));
  return this;
};

EventEmitter.prototype.prependOnceListener =
    function prependOnceListener(type, listener) {
      checkListener(listener);
      this.prependListener(type, _onceWrap(this, type, listener));
      return this;
    };

// Emits a 'removeListener' event if and only if the listener was removed.
EventEmitter.prototype.removeListener =
    function removeListener(type, listener) {
      var list, events, position, i, originalListener;

      checkListener(listener);

      events = this._events;
      if (events === undefined)
        return this;

      list = events[type];
      if (list === undefined)
        return this;

      if (list === listener || list.listener === listener) {
        if (--this._eventsCount === 0)
          this._events = Object.create(null);
        else {
          delete events[type];
          if (events.removeListener)
            this.emit('removeListener', type, list.listener || listener);
        }
      } else if (typeof list !== 'function') {
        position = -1;

        for (i = list.length - 1; i >= 0; i--) {
          if (list[i] === listener || list[i].listener === listener) {
            originalListener = list[i].listener;
            position = i;
            break;
          }
        }

        if (position < 0)
          return this;

        if (position === 0)
          list.shift();
        else {
          spliceOne(list, position);
        }

        if (list.length === 1)
          events[type] = list[0];

        if (events.removeListener !== undefined)
          this.emit('removeListener', type, originalListener || listener);
      }

      return this;
    };

EventEmitter.prototype.off = EventEmitter.prototype.removeListener;

EventEmitter.prototype.removeAllListeners =
    function removeAllListeners(type) {
      var listeners, events, i;

      events = this._events;
      if (events === undefined)
        return this;

      // not listening for removeListener, no need to emit
      if (events.removeListener === undefined) {
        if (arguments.length === 0) {
          this._events = Object.create(null);
          this._eventsCount = 0;
        } else if (events[type] !== undefined) {
          if (--this._eventsCount === 0)
            this._events = Object.create(null);
          else
            delete events[type];
        }
        return this;
      }

      // emit removeListener for all listeners on all events
      if (arguments.length === 0) {
        var keys = Object.keys(events);
        var key;
        for (i = 0; i < keys.length; ++i) {
          key = keys[i];
          if (key === 'removeListener') continue;
          this.removeAllListeners(key);
        }
        this.removeAllListeners('removeListener');
        this._events = Object.create(null);
        this._eventsCount = 0;
        return this;
      }

      listeners = events[type];

      if (typeof listeners === 'function') {
        this.removeListener(type, listeners);
      } else if (listeners !== undefined) {
        // LIFO order
        for (i = listeners.length - 1; i >= 0; i--) {
          this.removeListener(type, listeners[i]);
        }
      }

      return this;
    };

function _listeners(target, type, unwrap) {
  var events = target._events;

  if (events === undefined)
    return [];

  var evlistener = events[type];
  if (evlistener === undefined)
    return [];

  if (typeof evlistener === 'function')
    return unwrap ? [evlistener.listener || evlistener] : [evlistener];

  return unwrap ?
    unwrapListeners(evlistener) : arrayClone(evlistener, evlistener.length);
}

EventEmitter.prototype.listeners = function listeners(type) {
  return _listeners(this, type, true);
};

EventEmitter.prototype.rawListeners = function rawListeners(type) {
  return _listeners(this, type, false);
};

EventEmitter.listenerCount = function(emitter, type) {
  if (typeof emitter.listenerCount === 'function') {
    return emitter.listenerCount(type);
  } else {
    return listenerCount.call(emitter, type);
  }
};

EventEmitter.prototype.listenerCount = listenerCount;
function listenerCount(type) {
  var events = this._events;

  if (events !== undefined) {
    var evlistener = events[type];

    if (typeof evlistener === 'function') {
      return 1;
    } else if (evlistener !== undefined) {
      return evlistener.length;
    }
  }

  return 0;
}

EventEmitter.prototype.eventNames = function eventNames() {
  return this._eventsCount > 0 ? ReflectOwnKeys(this._events) : [];
};

function arrayClone(arr, n) {
  var copy = new Array(n);
  for (var i = 0; i < n; ++i)
    copy[i] = arr[i];
  return copy;
}

function spliceOne(list, index) {
  for (; index + 1 < list.length; index++)
    list[index] = list[index + 1];
  list.pop();
}

function unwrapListeners(arr) {
  var ret = new Array(arr.length);
  for (var i = 0; i < ret.length; ++i) {
    ret[i] = arr[i].listener || arr[i];
  }
  return ret;
}

function once(emitter, name) {
  return new Promise(function (resolve, reject) {
    function errorListener(err) {
      emitter.removeListener(name, resolver);
      reject(err);
    }

    function resolver() {
      if (typeof emitter.removeListener === 'function') {
        emitter.removeListener('error', errorListener);
      }
      resolve([].slice.call(arguments));
    };

    eventTargetAgnosticAddListener(emitter, name, resolver, { once: true });
    if (name !== 'error') {
      addErrorHandlerIfEventEmitter(emitter, errorListener, { once: true });
    }
  });
}

function addErrorHandlerIfEventEmitter(emitter, handler, flags) {
  if (typeof emitter.on === 'function') {
    eventTargetAgnosticAddListener(emitter, 'error', handler, flags);
  }
}

function eventTargetAgnosticAddListener(emitter, name, listener, flags) {
  if (typeof emitter.on === 'function') {
    if (flags.once) {
      emitter.once(name, listener);
    } else {
      emitter.on(name, listener);
    }
  } else if (typeof emitter.addEventListener === 'function') {
    // EventTarget does not have `error` event semantics like Node
    // EventEmitters, we do not listen for `error` events here.
    emitter.addEventListener(name, function wrapListener(arg) {
      // IE does not have builtin `{ once: true }` support so we
      // have to do it manually.
      if (flags.once) {
        emitter.removeEventListener(name, wrapListener);
      }
      listener(arg);
    });
  } else {
    throw new TypeError('The "emitter" argument must be of type EventEmitter. Received type ' + typeof emitter);
  }
}


/***/ }),

/***/ "./node_modules/jquery/dist/jquery.js":
/*!********************************************!*\
  !*** ./node_modules/jquery/dist/jquery.js ***!
  \********************************************/
/***/ (function(module, exports) {

var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;/*!
 * jQuery JavaScript Library v3.6.1
 * https://jquery.com/
 *
 * Includes Sizzle.js
 * https://sizzlejs.com/
 *
 * Copyright OpenJS Foundation and other contributors
 * Released under the MIT license
 * https://jquery.org/license
 *
 * Date: 2022-08-26T17:52Z
 */
( function( global, factory ) {

	"use strict";

	if (  true && typeof module.exports === "object" ) {

		// For CommonJS and CommonJS-like environments where a proper `window`
		// is present, execute the factory and get jQuery.
		// For environments that do not have a `window` with a `document`
		// (such as Node.js), expose a factory as module.exports.
		// This accentuates the need for the creation of a real `window`.
		// e.g. var jQuery = require("jquery")(window);
		// See ticket trac-14549 for more info.
		module.exports = global.document ?
			factory( global, true ) :
			function( w ) {
				if ( !w.document ) {
					throw new Error( "jQuery requires a window with a document" );
				}
				return factory( w );
			};
	} else {
		factory( global );
	}

// Pass this if window is not defined yet
} )( typeof window !== "undefined" ? window : this, function( window, noGlobal ) {

// Edge <= 12 - 13+, Firefox <=18 - 45+, IE 10 - 11, Safari 5.1 - 9+, iOS 6 - 9.1
// throw exceptions when non-strict code (e.g., ASP.NET 4.5) accesses strict mode
// arguments.callee.caller (trac-13335). But as of jQuery 3.0 (2016), strict mode should be common
// enough that all such attempts are guarded in a try block.
"use strict";

var arr = [];

var getProto = Object.getPrototypeOf;

var slice = arr.slice;

var flat = arr.flat ? function( array ) {
	return arr.flat.call( array );
} : function( array ) {
	return arr.concat.apply( [], array );
};


var push = arr.push;

var indexOf = arr.indexOf;

var class2type = {};

var toString = class2type.toString;

var hasOwn = class2type.hasOwnProperty;

var fnToString = hasOwn.toString;

var ObjectFunctionString = fnToString.call( Object );

var support = {};

var isFunction = function isFunction( obj ) {

		// Support: Chrome <=57, Firefox <=52
		// In some browsers, typeof returns "function" for HTML <object> elements
		// (i.e., `typeof document.createElement( "object" ) === "function"`).
		// We don't want to classify *any* DOM node as a function.
		// Support: QtWeb <=3.8.5, WebKit <=534.34, wkhtmltopdf tool <=0.12.5
		// Plus for old WebKit, typeof returns "function" for HTML collections
		// (e.g., `typeof document.getElementsByTagName("div") === "function"`). (gh-4756)
		return typeof obj === "function" && typeof obj.nodeType !== "number" &&
			typeof obj.item !== "function";
	};


var isWindow = function isWindow( obj ) {
		return obj != null && obj === obj.window;
	};


var document = window.document;



	var preservedScriptAttributes = {
		type: true,
		src: true,
		nonce: true,
		noModule: true
	};

	function DOMEval( code, node, doc ) {
		doc = doc || document;

		var i, val,
			script = doc.createElement( "script" );

		script.text = code;
		if ( node ) {
			for ( i in preservedScriptAttributes ) {

				// Support: Firefox 64+, Edge 18+
				// Some browsers don't support the "nonce" property on scripts.
				// On the other hand, just using `getAttribute` is not enough as
				// the `nonce` attribute is reset to an empty string whenever it
				// becomes browsing-context connected.
				// See https://github.com/whatwg/html/issues/2369
				// See https://html.spec.whatwg.org/#nonce-attributes
				// The `node.getAttribute` check was added for the sake of
				// `jQuery.globalEval` so that it can fake a nonce-containing node
				// via an object.
				val = node[ i ] || node.getAttribute && node.getAttribute( i );
				if ( val ) {
					script.setAttribute( i, val );
				}
			}
		}
		doc.head.appendChild( script ).parentNode.removeChild( script );
	}


function toType( obj ) {
	if ( obj == null ) {
		return obj + "";
	}

	// Support: Android <=2.3 only (functionish RegExp)
	return typeof obj === "object" || typeof obj === "function" ?
		class2type[ toString.call( obj ) ] || "object" :
		typeof obj;
}
/* global Symbol */
// Defining this global in .eslintrc.json would create a danger of using the global
// unguarded in another place, it seems safer to define global only for this module



var
	version = "3.6.1",

	// Define a local copy of jQuery
	jQuery = function( selector, context ) {

		// The jQuery object is actually just the init constructor 'enhanced'
		// Need init if jQuery is called (just allow error to be thrown if not included)
		return new jQuery.fn.init( selector, context );
	};

jQuery.fn = jQuery.prototype = {

	// The current version of jQuery being used
	jquery: version,

	constructor: jQuery,

	// The default length of a jQuery object is 0
	length: 0,

	toArray: function() {
		return slice.call( this );
	},

	// Get the Nth element in the matched element set OR
	// Get the whole matched element set as a clean array
	get: function( num ) {

		// Return all the elements in a clean array
		if ( num == null ) {
			return slice.call( this );
		}

		// Return just the one element from the set
		return num < 0 ? this[ num + this.length ] : this[ num ];
	},

	// Take an array of elements and push it onto the stack
	// (returning the new matched element set)
	pushStack: function( elems ) {

		// Build a new jQuery matched element set
		var ret = jQuery.merge( this.constructor(), elems );

		// Add the old object onto the stack (as a reference)
		ret.prevObject = this;

		// Return the newly-formed element set
		return ret;
	},

	// Execute a callback for every element in the matched set.
	each: function( callback ) {
		return jQuery.each( this, callback );
	},

	map: function( callback ) {
		return this.pushStack( jQuery.map( this, function( elem, i ) {
			return callback.call( elem, i, elem );
		} ) );
	},

	slice: function() {
		return this.pushStack( slice.apply( this, arguments ) );
	},

	first: function() {
		return this.eq( 0 );
	},

	last: function() {
		return this.eq( -1 );
	},

	even: function() {
		return this.pushStack( jQuery.grep( this, function( _elem, i ) {
			return ( i + 1 ) % 2;
		} ) );
	},

	odd: function() {
		return this.pushStack( jQuery.grep( this, function( _elem, i ) {
			return i % 2;
		} ) );
	},

	eq: function( i ) {
		var len = this.length,
			j = +i + ( i < 0 ? len : 0 );
		return this.pushStack( j >= 0 && j < len ? [ this[ j ] ] : [] );
	},

	end: function() {
		return this.prevObject || this.constructor();
	},

	// For internal use only.
	// Behaves like an Array's method, not like a jQuery method.
	push: push,
	sort: arr.sort,
	splice: arr.splice
};

jQuery.extend = jQuery.fn.extend = function() {
	var options, name, src, copy, copyIsArray, clone,
		target = arguments[ 0 ] || {},
		i = 1,
		length = arguments.length,
		deep = false;

	// Handle a deep copy situation
	if ( typeof target === "boolean" ) {
		deep = target;

		// Skip the boolean and the target
		target = arguments[ i ] || {};
		i++;
	}

	// Handle case when target is a string or something (possible in deep copy)
	if ( typeof target !== "object" && !isFunction( target ) ) {
		target = {};
	}

	// Extend jQuery itself if only one argument is passed
	if ( i === length ) {
		target = this;
		i--;
	}

	for ( ; i < length; i++ ) {

		// Only deal with non-null/undefined values
		if ( ( options = arguments[ i ] ) != null ) {

			// Extend the base object
			for ( name in options ) {
				copy = options[ name ];

				// Prevent Object.prototype pollution
				// Prevent never-ending loop
				if ( name === "__proto__" || target === copy ) {
					continue;
				}

				// Recurse if we're merging plain objects or arrays
				if ( deep && copy && ( jQuery.isPlainObject( copy ) ||
					( copyIsArray = Array.isArray( copy ) ) ) ) {
					src = target[ name ];

					// Ensure proper type for the source value
					if ( copyIsArray && !Array.isArray( src ) ) {
						clone = [];
					} else if ( !copyIsArray && !jQuery.isPlainObject( src ) ) {
						clone = {};
					} else {
						clone = src;
					}
					copyIsArray = false;

					// Never move original objects, clone them
					target[ name ] = jQuery.extend( deep, clone, copy );

				// Don't bring in undefined values
				} else if ( copy !== undefined ) {
					target[ name ] = copy;
				}
			}
		}
	}

	// Return the modified object
	return target;
};

jQuery.extend( {

	// Unique for each copy of jQuery on the page
	expando: "jQuery" + ( version + Math.random() ).replace( /\D/g, "" ),

	// Assume jQuery is ready without the ready module
	isReady: true,

	error: function( msg ) {
		throw new Error( msg );
	},

	noop: function() {},

	isPlainObject: function( obj ) {
		var proto, Ctor;

		// Detect obvious negatives
		// Use toString instead of jQuery.type to catch host objects
		if ( !obj || toString.call( obj ) !== "[object Object]" ) {
			return false;
		}

		proto = getProto( obj );

		// Objects with no prototype (e.g., `Object.create( null )`) are plain
		if ( !proto ) {
			return true;
		}

		// Objects with prototype are plain iff they were constructed by a global Object function
		Ctor = hasOwn.call( proto, "constructor" ) && proto.constructor;
		return typeof Ctor === "function" && fnToString.call( Ctor ) === ObjectFunctionString;
	},

	isEmptyObject: function( obj ) {
		var name;

		for ( name in obj ) {
			return false;
		}
		return true;
	},

	// Evaluates a script in a provided context; falls back to the global one
	// if not specified.
	globalEval: function( code, options, doc ) {
		DOMEval( code, { nonce: options && options.nonce }, doc );
	},

	each: function( obj, callback ) {
		var length, i = 0;

		if ( isArrayLike( obj ) ) {
			length = obj.length;
			for ( ; i < length; i++ ) {
				if ( callback.call( obj[ i ], i, obj[ i ] ) === false ) {
					break;
				}
			}
		} else {
			for ( i in obj ) {
				if ( callback.call( obj[ i ], i, obj[ i ] ) === false ) {
					break;
				}
			}
		}

		return obj;
	},

	// results is for internal usage only
	makeArray: function( arr, results ) {
		var ret = results || [];

		if ( arr != null ) {
			if ( isArrayLike( Object( arr ) ) ) {
				jQuery.merge( ret,
					typeof arr === "string" ?
						[ arr ] : arr
				);
			} else {
				push.call( ret, arr );
			}
		}

		return ret;
	},

	inArray: function( elem, arr, i ) {
		return arr == null ? -1 : indexOf.call( arr, elem, i );
	},

	// Support: Android <=4.0 only, PhantomJS 1 only
	// push.apply(_, arraylike) throws on ancient WebKit
	merge: function( first, second ) {
		var len = +second.length,
			j = 0,
			i = first.length;

		for ( ; j < len; j++ ) {
			first[ i++ ] = second[ j ];
		}

		first.length = i;

		return first;
	},

	grep: function( elems, callback, invert ) {
		var callbackInverse,
			matches = [],
			i = 0,
			length = elems.length,
			callbackExpect = !invert;

		// Go through the array, only saving the items
		// that pass the validator function
		for ( ; i < length; i++ ) {
			callbackInverse = !callback( elems[ i ], i );
			if ( callbackInverse !== callbackExpect ) {
				matches.push( elems[ i ] );
			}
		}

		return matches;
	},

	// arg is for internal usage only
	map: function( elems, callback, arg ) {
		var length, value,
			i = 0,
			ret = [];

		// Go through the array, translating each of the items to their new values
		if ( isArrayLike( elems ) ) {
			length = elems.length;
			for ( ; i < length; i++ ) {
				value = callback( elems[ i ], i, arg );

				if ( value != null ) {
					ret.push( value );
				}
			}

		// Go through every key on the object,
		} else {
			for ( i in elems ) {
				value = callback( elems[ i ], i, arg );

				if ( value != null ) {
					ret.push( value );
				}
			}
		}

		// Flatten any nested arrays
		return flat( ret );
	},

	// A global GUID counter for objects
	guid: 1,

	// jQuery.support is not used in Core but other projects attach their
	// properties to it so it needs to exist.
	support: support
} );

if ( typeof Symbol === "function" ) {
	jQuery.fn[ Symbol.iterator ] = arr[ Symbol.iterator ];
}

// Populate the class2type map
jQuery.each( "Boolean Number String Function Array Date RegExp Object Error Symbol".split( " " ),
	function( _i, name ) {
		class2type[ "[object " + name + "]" ] = name.toLowerCase();
	} );

function isArrayLike( obj ) {

	// Support: real iOS 8.2 only (not reproducible in simulator)
	// `in` check used to prevent JIT error (gh-2145)
	// hasOwn isn't used here due to false negatives
	// regarding Nodelist length in IE
	var length = !!obj && "length" in obj && obj.length,
		type = toType( obj );

	if ( isFunction( obj ) || isWindow( obj ) ) {
		return false;
	}

	return type === "array" || length === 0 ||
		typeof length === "number" && length > 0 && ( length - 1 ) in obj;
}
var Sizzle =
/*!
 * Sizzle CSS Selector Engine v2.3.6
 * https://sizzlejs.com/
 *
 * Copyright JS Foundation and other contributors
 * Released under the MIT license
 * https://js.foundation/
 *
 * Date: 2021-02-16
 */
( function( window ) {
var i,
	support,
	Expr,
	getText,
	isXML,
	tokenize,
	compile,
	select,
	outermostContext,
	sortInput,
	hasDuplicate,

	// Local document vars
	setDocument,
	document,
	docElem,
	documentIsHTML,
	rbuggyQSA,
	rbuggyMatches,
	matches,
	contains,

	// Instance-specific data
	expando = "sizzle" + 1 * new Date(),
	preferredDoc = window.document,
	dirruns = 0,
	done = 0,
	classCache = createCache(),
	tokenCache = createCache(),
	compilerCache = createCache(),
	nonnativeSelectorCache = createCache(),
	sortOrder = function( a, b ) {
		if ( a === b ) {
			hasDuplicate = true;
		}
		return 0;
	},

	// Instance methods
	hasOwn = ( {} ).hasOwnProperty,
	arr = [],
	pop = arr.pop,
	pushNative = arr.push,
	push = arr.push,
	slice = arr.slice,

	// Use a stripped-down indexOf as it's faster than native
	// https://jsperf.com/thor-indexof-vs-for/5
	indexOf = function( list, elem ) {
		var i = 0,
			len = list.length;
		for ( ; i < len; i++ ) {
			if ( list[ i ] === elem ) {
				return i;
			}
		}
		return -1;
	},

	booleans = "checked|selected|async|autofocus|autoplay|controls|defer|disabled|hidden|" +
		"ismap|loop|multiple|open|readonly|required|scoped",

	// Regular expressions

	// http://www.w3.org/TR/css3-selectors/#whitespace
	whitespace = "[\\x20\\t\\r\\n\\f]",

	// https://www.w3.org/TR/css-syntax-3/#ident-token-diagram
	identifier = "(?:\\\\[\\da-fA-F]{1,6}" + whitespace +
		"?|\\\\[^\\r\\n\\f]|[\\w-]|[^\0-\\x7f])+",

	// Attribute selectors: http://www.w3.org/TR/selectors/#attribute-selectors
	attributes = "\\[" + whitespace + "*(" + identifier + ")(?:" + whitespace +

		// Operator (capture 2)
		"*([*^$|!~]?=)" + whitespace +

		// "Attribute values must be CSS identifiers [capture 5]
		// or strings [capture 3 or capture 4]"
		"*(?:'((?:\\\\.|[^\\\\'])*)'|\"((?:\\\\.|[^\\\\\"])*)\"|(" + identifier + "))|)" +
		whitespace + "*\\]",

	pseudos = ":(" + identifier + ")(?:\\((" +

		// To reduce the number of selectors needing tokenize in the preFilter, prefer arguments:
		// 1. quoted (capture 3; capture 4 or capture 5)
		"('((?:\\\\.|[^\\\\'])*)'|\"((?:\\\\.|[^\\\\\"])*)\")|" +

		// 2. simple (capture 6)
		"((?:\\\\.|[^\\\\()[\\]]|" + attributes + ")*)|" +

		// 3. anything else (capture 2)
		".*" +
		")\\)|)",

	// Leading and non-escaped trailing whitespace, capturing some non-whitespace characters preceding the latter
	rwhitespace = new RegExp( whitespace + "+", "g" ),
	rtrim = new RegExp( "^" + whitespace + "+|((?:^|[^\\\\])(?:\\\\.)*)" +
		whitespace + "+$", "g" ),

	rcomma = new RegExp( "^" + whitespace + "*," + whitespace + "*" ),
	rcombinators = new RegExp( "^" + whitespace + "*([>+~]|" + whitespace + ")" + whitespace +
		"*" ),
	rdescend = new RegExp( whitespace + "|>" ),

	rpseudo = new RegExp( pseudos ),
	ridentifier = new RegExp( "^" + identifier + "$" ),

	matchExpr = {
		"ID": new RegExp( "^#(" + identifier + ")" ),
		"CLASS": new RegExp( "^\\.(" + identifier + ")" ),
		"TAG": new RegExp( "^(" + identifier + "|[*])" ),
		"ATTR": new RegExp( "^" + attributes ),
		"PSEUDO": new RegExp( "^" + pseudos ),
		"CHILD": new RegExp( "^:(only|first|last|nth|nth-last)-(child|of-type)(?:\\(" +
			whitespace + "*(even|odd|(([+-]|)(\\d*)n|)" + whitespace + "*(?:([+-]|)" +
			whitespace + "*(\\d+)|))" + whitespace + "*\\)|)", "i" ),
		"bool": new RegExp( "^(?:" + booleans + ")$", "i" ),

		// For use in libraries implementing .is()
		// We use this for POS matching in `select`
		"needsContext": new RegExp( "^" + whitespace +
			"*[>+~]|:(even|odd|eq|gt|lt|nth|first|last)(?:\\(" + whitespace +
			"*((?:-\\d)?\\d*)" + whitespace + "*\\)|)(?=[^-]|$)", "i" )
	},

	rhtml = /HTML$/i,
	rinputs = /^(?:input|select|textarea|button)$/i,
	rheader = /^h\d$/i,

	rnative = /^[^{]+\{\s*\[native \w/,

	// Easily-parseable/retrievable ID or TAG or CLASS selectors
	rquickExpr = /^(?:#([\w-]+)|(\w+)|\.([\w-]+))$/,

	rsibling = /[+~]/,

	// CSS escapes
	// http://www.w3.org/TR/CSS21/syndata.html#escaped-characters
	runescape = new RegExp( "\\\\[\\da-fA-F]{1,6}" + whitespace + "?|\\\\([^\\r\\n\\f])", "g" ),
	funescape = function( escape, nonHex ) {
		var high = "0x" + escape.slice( 1 ) - 0x10000;

		return nonHex ?

			// Strip the backslash prefix from a non-hex escape sequence
			nonHex :

			// Replace a hexadecimal escape sequence with the encoded Unicode code point
			// Support: IE <=11+
			// For values outside the Basic Multilingual Plane (BMP), manually construct a
			// surrogate pair
			high < 0 ?
				String.fromCharCode( high + 0x10000 ) :
				String.fromCharCode( high >> 10 | 0xD800, high & 0x3FF | 0xDC00 );
	},

	// CSS string/identifier serialization
	// https://drafts.csswg.org/cssom/#common-serializing-idioms
	rcssescape = /([\0-\x1f\x7f]|^-?\d)|^-$|[^\0-\x1f\x7f-\uFFFF\w-]/g,
	fcssescape = function( ch, asCodePoint ) {
		if ( asCodePoint ) {

			// U+0000 NULL becomes U+FFFD REPLACEMENT CHARACTER
			if ( ch === "\0" ) {
				return "\uFFFD";
			}

			// Control characters and (dependent upon position) numbers get escaped as code points
			return ch.slice( 0, -1 ) + "\\" +
				ch.charCodeAt( ch.length - 1 ).toString( 16 ) + " ";
		}

		// Other potentially-special ASCII characters get backslash-escaped
		return "\\" + ch;
	},

	// Used for iframes
	// See setDocument()
	// Removing the function wrapper causes a "Permission Denied"
	// error in IE
	unloadHandler = function() {
		setDocument();
	},

	inDisabledFieldset = addCombinator(
		function( elem ) {
			return elem.disabled === true && elem.nodeName.toLowerCase() === "fieldset";
		},
		{ dir: "parentNode", next: "legend" }
	);

// Optimize for push.apply( _, NodeList )
try {
	push.apply(
		( arr = slice.call( preferredDoc.childNodes ) ),
		preferredDoc.childNodes
	);

	// Support: Android<4.0
	// Detect silently failing push.apply
	// eslint-disable-next-line no-unused-expressions
	arr[ preferredDoc.childNodes.length ].nodeType;
} catch ( e ) {
	push = { apply: arr.length ?

		// Leverage slice if possible
		function( target, els ) {
			pushNative.apply( target, slice.call( els ) );
		} :

		// Support: IE<9
		// Otherwise append directly
		function( target, els ) {
			var j = target.length,
				i = 0;

			// Can't trust NodeList.length
			while ( ( target[ j++ ] = els[ i++ ] ) ) {}
			target.length = j - 1;
		}
	};
}

function Sizzle( selector, context, results, seed ) {
	var m, i, elem, nid, match, groups, newSelector,
		newContext = context && context.ownerDocument,

		// nodeType defaults to 9, since context defaults to document
		nodeType = context ? context.nodeType : 9;

	results = results || [];

	// Return early from calls with invalid selector or context
	if ( typeof selector !== "string" || !selector ||
		nodeType !== 1 && nodeType !== 9 && nodeType !== 11 ) {

		return results;
	}

	// Try to shortcut find operations (as opposed to filters) in HTML documents
	if ( !seed ) {
		setDocument( context );
		context = context || document;

		if ( documentIsHTML ) {

			// If the selector is sufficiently simple, try using a "get*By*" DOM method
			// (excepting DocumentFragment context, where the methods don't exist)
			if ( nodeType !== 11 && ( match = rquickExpr.exec( selector ) ) ) {

				// ID selector
				if ( ( m = match[ 1 ] ) ) {

					// Document context
					if ( nodeType === 9 ) {
						if ( ( elem = context.getElementById( m ) ) ) {

							// Support: IE, Opera, Webkit
							// TODO: identify versions
							// getElementById can match elements by name instead of ID
							if ( elem.id === m ) {
								results.push( elem );
								return results;
							}
						} else {
							return results;
						}

					// Element context
					} else {

						// Support: IE, Opera, Webkit
						// TODO: identify versions
						// getElementById can match elements by name instead of ID
						if ( newContext && ( elem = newContext.getElementById( m ) ) &&
							contains( context, elem ) &&
							elem.id === m ) {

							results.push( elem );
							return results;
						}
					}

				// Type selector
				} else if ( match[ 2 ] ) {
					push.apply( results, context.getElementsByTagName( selector ) );
					return results;

				// Class selector
				} else if ( ( m = match[ 3 ] ) && support.getElementsByClassName &&
					context.getElementsByClassName ) {

					push.apply( results, context.getElementsByClassName( m ) );
					return results;
				}
			}

			// Take advantage of querySelectorAll
			if ( support.qsa &&
				!nonnativeSelectorCache[ selector + " " ] &&
				( !rbuggyQSA || !rbuggyQSA.test( selector ) ) &&

				// Support: IE 8 only
				// Exclude object elements
				( nodeType !== 1 || context.nodeName.toLowerCase() !== "object" ) ) {

				newSelector = selector;
				newContext = context;

				// qSA considers elements outside a scoping root when evaluating child or
				// descendant combinators, which is not what we want.
				// In such cases, we work around the behavior by prefixing every selector in the
				// list with an ID selector referencing the scope context.
				// The technique has to be used as well when a leading combinator is used
				// as such selectors are not recognized by querySelectorAll.
				// Thanks to Andrew Dupont for this technique.
				if ( nodeType === 1 &&
					( rdescend.test( selector ) || rcombinators.test( selector ) ) ) {

					// Expand context for sibling selectors
					newContext = rsibling.test( selector ) && testContext( context.parentNode ) ||
						context;

					// We can use :scope instead of the ID hack if the browser
					// supports it & if we're not changing the context.
					if ( newContext !== context || !support.scope ) {

						// Capture the context ID, setting it first if necessary
						if ( ( nid = context.getAttribute( "id" ) ) ) {
							nid = nid.replace( rcssescape, fcssescape );
						} else {
							context.setAttribute( "id", ( nid = expando ) );
						}
					}

					// Prefix every selector in the list
					groups = tokenize( selector );
					i = groups.length;
					while ( i-- ) {
						groups[ i ] = ( nid ? "#" + nid : ":scope" ) + " " +
							toSelector( groups[ i ] );
					}
					newSelector = groups.join( "," );
				}

				try {
					push.apply( results,
						newContext.querySelectorAll( newSelector )
					);
					return results;
				} catch ( qsaError ) {
					nonnativeSelectorCache( selector, true );
				} finally {
					if ( nid === expando ) {
						context.removeAttribute( "id" );
					}
				}
			}
		}
	}

	// All others
	return select( selector.replace( rtrim, "$1" ), context, results, seed );
}

/**
 * Create key-value caches of limited size
 * @returns {function(string, object)} Returns the Object data after storing it on itself with
 *	property name the (space-suffixed) string and (if the cache is larger than Expr.cacheLength)
 *	deleting the oldest entry
 */
function createCache() {
	var keys = [];

	function cache( key, value ) {

		// Use (key + " ") to avoid collision with native prototype properties (see Issue #157)
		if ( keys.push( key + " " ) > Expr.cacheLength ) {

			// Only keep the most recent entries
			delete cache[ keys.shift() ];
		}
		return ( cache[ key + " " ] = value );
	}
	return cache;
}

/**
 * Mark a function for special use by Sizzle
 * @param {Function} fn The function to mark
 */
function markFunction( fn ) {
	fn[ expando ] = true;
	return fn;
}

/**
 * Support testing using an element
 * @param {Function} fn Passed the created element and returns a boolean result
 */
function assert( fn ) {
	var el = document.createElement( "fieldset" );

	try {
		return !!fn( el );
	} catch ( e ) {
		return false;
	} finally {

		// Remove from its parent by default
		if ( el.parentNode ) {
			el.parentNode.removeChild( el );
		}

		// release memory in IE
		el = null;
	}
}

/**
 * Adds the same handler for all of the specified attrs
 * @param {String} attrs Pipe-separated list of attributes
 * @param {Function} handler The method that will be applied
 */
function addHandle( attrs, handler ) {
	var arr = attrs.split( "|" ),
		i = arr.length;

	while ( i-- ) {
		Expr.attrHandle[ arr[ i ] ] = handler;
	}
}

/**
 * Checks document order of two siblings
 * @param {Element} a
 * @param {Element} b
 * @returns {Number} Returns less than 0 if a precedes b, greater than 0 if a follows b
 */
function siblingCheck( a, b ) {
	var cur = b && a,
		diff = cur && a.nodeType === 1 && b.nodeType === 1 &&
			a.sourceIndex - b.sourceIndex;

	// Use IE sourceIndex if available on both nodes
	if ( diff ) {
		return diff;
	}

	// Check if b follows a
	if ( cur ) {
		while ( ( cur = cur.nextSibling ) ) {
			if ( cur === b ) {
				return -1;
			}
		}
	}

	return a ? 1 : -1;
}

/**
 * Returns a function to use in pseudos for input types
 * @param {String} type
 */
function createInputPseudo( type ) {
	return function( elem ) {
		var name = elem.nodeName.toLowerCase();
		return name === "input" && elem.type === type;
	};
}

/**
 * Returns a function to use in pseudos for buttons
 * @param {String} type
 */
function createButtonPseudo( type ) {
	return function( elem ) {
		var name = elem.nodeName.toLowerCase();
		return ( name === "input" || name === "button" ) && elem.type === type;
	};
}

/**
 * Returns a function to use in pseudos for :enabled/:disabled
 * @param {Boolean} disabled true for :disabled; false for :enabled
 */
function createDisabledPseudo( disabled ) {

	// Known :disabled false positives: fieldset[disabled] > legend:nth-of-type(n+2) :can-disable
	return function( elem ) {

		// Only certain elements can match :enabled or :disabled
		// https://html.spec.whatwg.org/multipage/scripting.html#selector-enabled
		// https://html.spec.whatwg.org/multipage/scripting.html#selector-disabled
		if ( "form" in elem ) {

			// Check for inherited disabledness on relevant non-disabled elements:
			// * listed form-associated elements in a disabled fieldset
			//   https://html.spec.whatwg.org/multipage/forms.html#category-listed
			//   https://html.spec.whatwg.org/multipage/forms.html#concept-fe-disabled
			// * option elements in a disabled optgroup
			//   https://html.spec.whatwg.org/multipage/forms.html#concept-option-disabled
			// All such elements have a "form" property.
			if ( elem.parentNode && elem.disabled === false ) {

				// Option elements defer to a parent optgroup if present
				if ( "label" in elem ) {
					if ( "label" in elem.parentNode ) {
						return elem.parentNode.disabled === disabled;
					} else {
						return elem.disabled === disabled;
					}
				}

				// Support: IE 6 - 11
				// Use the isDisabled shortcut property to check for disabled fieldset ancestors
				return elem.isDisabled === disabled ||

					// Where there is no isDisabled, check manually
					/* jshint -W018 */
					elem.isDisabled !== !disabled &&
					inDisabledFieldset( elem ) === disabled;
			}

			return elem.disabled === disabled;

		// Try to winnow out elements that can't be disabled before trusting the disabled property.
		// Some victims get caught in our net (label, legend, menu, track), but it shouldn't
		// even exist on them, let alone have a boolean value.
		} else if ( "label" in elem ) {
			return elem.disabled === disabled;
		}

		// Remaining elements are neither :enabled nor :disabled
		return false;
	};
}

/**
 * Returns a function to use in pseudos for positionals
 * @param {Function} fn
 */
function createPositionalPseudo( fn ) {
	return markFunction( function( argument ) {
		argument = +argument;
		return markFunction( function( seed, matches ) {
			var j,
				matchIndexes = fn( [], seed.length, argument ),
				i = matchIndexes.length;

			// Match elements found at the specified indexes
			while ( i-- ) {
				if ( seed[ ( j = matchIndexes[ i ] ) ] ) {
					seed[ j ] = !( matches[ j ] = seed[ j ] );
				}
			}
		} );
	} );
}

/**
 * Checks a node for validity as a Sizzle context
 * @param {Element|Object=} context
 * @returns {Element|Object|Boolean} The input node if acceptable, otherwise a falsy value
 */
function testContext( context ) {
	return context && typeof context.getElementsByTagName !== "undefined" && context;
}

// Expose support vars for convenience
support = Sizzle.support = {};

/**
 * Detects XML nodes
 * @param {Element|Object} elem An element or a document
 * @returns {Boolean} True iff elem is a non-HTML XML node
 */
isXML = Sizzle.isXML = function( elem ) {
	var namespace = elem && elem.namespaceURI,
		docElem = elem && ( elem.ownerDocument || elem ).documentElement;

	// Support: IE <=8
	// Assume HTML when documentElement doesn't yet exist, such as inside loading iframes
	// https://bugs.jquery.com/ticket/4833
	return !rhtml.test( namespace || docElem && docElem.nodeName || "HTML" );
};

/**
 * Sets document-related variables once based on the current document
 * @param {Element|Object} [doc] An element or document object to use to set the document
 * @returns {Object} Returns the current document
 */
setDocument = Sizzle.setDocument = function( node ) {
	var hasCompare, subWindow,
		doc = node ? node.ownerDocument || node : preferredDoc;

	// Return early if doc is invalid or already selected
	// Support: IE 11+, Edge 17 - 18+
	// IE/Edge sometimes throw a "Permission denied" error when strict-comparing
	// two documents; shallow comparisons work.
	// eslint-disable-next-line eqeqeq
	if ( doc == document || doc.nodeType !== 9 || !doc.documentElement ) {
		return document;
	}

	// Update global variables
	document = doc;
	docElem = document.documentElement;
	documentIsHTML = !isXML( document );

	// Support: IE 9 - 11+, Edge 12 - 18+
	// Accessing iframe documents after unload throws "permission denied" errors (jQuery #13936)
	// Support: IE 11+, Edge 17 - 18+
	// IE/Edge sometimes throw a "Permission denied" error when strict-comparing
	// two documents; shallow comparisons work.
	// eslint-disable-next-line eqeqeq
	if ( preferredDoc != document &&
		( subWindow = document.defaultView ) && subWindow.top !== subWindow ) {

		// Support: IE 11, Edge
		if ( subWindow.addEventListener ) {
			subWindow.addEventListener( "unload", unloadHandler, false );

		// Support: IE 9 - 10 only
		} else if ( subWindow.attachEvent ) {
			subWindow.attachEvent( "onunload", unloadHandler );
		}
	}

	// Support: IE 8 - 11+, Edge 12 - 18+, Chrome <=16 - 25 only, Firefox <=3.6 - 31 only,
	// Safari 4 - 5 only, Opera <=11.6 - 12.x only
	// IE/Edge & older browsers don't support the :scope pseudo-class.
	// Support: Safari 6.0 only
	// Safari 6.0 supports :scope but it's an alias of :root there.
	support.scope = assert( function( el ) {
		docElem.appendChild( el ).appendChild( document.createElement( "div" ) );
		return typeof el.querySelectorAll !== "undefined" &&
			!el.querySelectorAll( ":scope fieldset div" ).length;
	} );

	/* Attributes
	---------------------------------------------------------------------- */

	// Support: IE<8
	// Verify that getAttribute really returns attributes and not properties
	// (excepting IE8 booleans)
	support.attributes = assert( function( el ) {
		el.className = "i";
		return !el.getAttribute( "className" );
	} );

	/* getElement(s)By*
	---------------------------------------------------------------------- */

	// Check if getElementsByTagName("*") returns only elements
	support.getElementsByTagName = assert( function( el ) {
		el.appendChild( document.createComment( "" ) );
		return !el.getElementsByTagName( "*" ).length;
	} );

	// Support: IE<9
	support.getElementsByClassName = rnative.test( document.getElementsByClassName );

	// Support: IE<10
	// Check if getElementById returns elements by name
	// The broken getElementById methods don't pick up programmatically-set names,
	// so use a roundabout getElementsByName test
	support.getById = assert( function( el ) {
		docElem.appendChild( el ).id = expando;
		return !document.getElementsByName || !document.getElementsByName( expando ).length;
	} );

	// ID filter and find
	if ( support.getById ) {
		Expr.filter[ "ID" ] = function( id ) {
			var attrId = id.replace( runescape, funescape );
			return function( elem ) {
				return elem.getAttribute( "id" ) === attrId;
			};
		};
		Expr.find[ "ID" ] = function( id, context ) {
			if ( typeof context.getElementById !== "undefined" && documentIsHTML ) {
				var elem = context.getElementById( id );
				return elem ? [ elem ] : [];
			}
		};
	} else {
		Expr.filter[ "ID" ] =  function( id ) {
			var attrId = id.replace( runescape, funescape );
			return function( elem ) {
				var node = typeof elem.getAttributeNode !== "undefined" &&
					elem.getAttributeNode( "id" );
				return node && node.value === attrId;
			};
		};

		// Support: IE 6 - 7 only
		// getElementById is not reliable as a find shortcut
		Expr.find[ "ID" ] = function( id, context ) {
			if ( typeof context.getElementById !== "undefined" && documentIsHTML ) {
				var node, i, elems,
					elem = context.getElementById( id );

				if ( elem ) {

					// Verify the id attribute
					node = elem.getAttributeNode( "id" );
					if ( node && node.value === id ) {
						return [ elem ];
					}

					// Fall back on getElementsByName
					elems = context.getElementsByName( id );
					i = 0;
					while ( ( elem = elems[ i++ ] ) ) {
						node = elem.getAttributeNode( "id" );
						if ( node && node.value === id ) {
							return [ elem ];
						}
					}
				}

				return [];
			}
		};
	}

	// Tag
	Expr.find[ "TAG" ] = support.getElementsByTagName ?
		function( tag, context ) {
			if ( typeof context.getElementsByTagName !== "undefined" ) {
				return context.getElementsByTagName( tag );

			// DocumentFragment nodes don't have gEBTN
			} else if ( support.qsa ) {
				return context.querySelectorAll( tag );
			}
		} :

		function( tag, context ) {
			var elem,
				tmp = [],
				i = 0,

				// By happy coincidence, a (broken) gEBTN appears on DocumentFragment nodes too
				results = context.getElementsByTagName( tag );

			// Filter out possible comments
			if ( tag === "*" ) {
				while ( ( elem = results[ i++ ] ) ) {
					if ( elem.nodeType === 1 ) {
						tmp.push( elem );
					}
				}

				return tmp;
			}
			return results;
		};

	// Class
	Expr.find[ "CLASS" ] = support.getElementsByClassName && function( className, context ) {
		if ( typeof context.getElementsByClassName !== "undefined" && documentIsHTML ) {
			return context.getElementsByClassName( className );
		}
	};

	/* QSA/matchesSelector
	---------------------------------------------------------------------- */

	// QSA and matchesSelector support

	// matchesSelector(:active) reports false when true (IE9/Opera 11.5)
	rbuggyMatches = [];

	// qSa(:focus) reports false when true (Chrome 21)
	// We allow this because of a bug in IE8/9 that throws an error
	// whenever `document.activeElement` is accessed on an iframe
	// So, we allow :focus to pass through QSA all the time to avoid the IE error
	// See https://bugs.jquery.com/ticket/13378
	rbuggyQSA = [];

	if ( ( support.qsa = rnative.test( document.querySelectorAll ) ) ) {

		// Build QSA regex
		// Regex strategy adopted from Diego Perini
		assert( function( el ) {

			var input;

			// Select is set to empty string on purpose
			// This is to test IE's treatment of not explicitly
			// setting a boolean content attribute,
			// since its presence should be enough
			// https://bugs.jquery.com/ticket/12359
			docElem.appendChild( el ).innerHTML = "<a id='" + expando + "'></a>" +
				"<select id='" + expando + "-\r\\' msallowcapture=''>" +
				"<option selected=''></option></select>";

			// Support: IE8, Opera 11-12.16
			// Nothing should be selected when empty strings follow ^= or $= or *=
			// The test attribute must be unknown in Opera but "safe" for WinRT
			// https://msdn.microsoft.com/en-us/library/ie/hh465388.aspx#attribute_section
			if ( el.querySelectorAll( "[msallowcapture^='']" ).length ) {
				rbuggyQSA.push( "[*^$]=" + whitespace + "*(?:''|\"\")" );
			}

			// Support: IE8
			// Boolean attributes and "value" are not treated correctly
			if ( !el.querySelectorAll( "[selected]" ).length ) {
				rbuggyQSA.push( "\\[" + whitespace + "*(?:value|" + booleans + ")" );
			}

			// Support: Chrome<29, Android<4.4, Safari<7.0+, iOS<7.0+, PhantomJS<1.9.8+
			if ( !el.querySelectorAll( "[id~=" + expando + "-]" ).length ) {
				rbuggyQSA.push( "~=" );
			}

			// Support: IE 11+, Edge 15 - 18+
			// IE 11/Edge don't find elements on a `[name='']` query in some cases.
			// Adding a temporary attribute to the document before the selection works
			// around the issue.
			// Interestingly, IE 10 & older don't seem to have the issue.
			input = document.createElement( "input" );
			input.setAttribute( "name", "" );
			el.appendChild( input );
			if ( !el.querySelectorAll( "[name='']" ).length ) {
				rbuggyQSA.push( "\\[" + whitespace + "*name" + whitespace + "*=" +
					whitespace + "*(?:''|\"\")" );
			}

			// Webkit/Opera - :checked should return selected option elements
			// http://www.w3.org/TR/2011/REC-css3-selectors-20110929/#checked
			// IE8 throws error here and will not see later tests
			if ( !el.querySelectorAll( ":checked" ).length ) {
				rbuggyQSA.push( ":checked" );
			}

			// Support: Safari 8+, iOS 8+
			// https://bugs.webkit.org/show_bug.cgi?id=136851
			// In-page `selector#id sibling-combinator selector` fails
			if ( !el.querySelectorAll( "a#" + expando + "+*" ).length ) {
				rbuggyQSA.push( ".#.+[+~]" );
			}

			// Support: Firefox <=3.6 - 5 only
			// Old Firefox doesn't throw on a badly-escaped identifier.
			el.querySelectorAll( "\\\f" );
			rbuggyQSA.push( "[\\r\\n\\f]" );
		} );

		assert( function( el ) {
			el.innerHTML = "<a href='' disabled='disabled'></a>" +
				"<select disabled='disabled'><option/></select>";

			// Support: Windows 8 Native Apps
			// The type and name attributes are restricted during .innerHTML assignment
			var input = document.createElement( "input" );
			input.setAttribute( "type", "hidden" );
			el.appendChild( input ).setAttribute( "name", "D" );

			// Support: IE8
			// Enforce case-sensitivity of name attribute
			if ( el.querySelectorAll( "[name=d]" ).length ) {
				rbuggyQSA.push( "name" + whitespace + "*[*^$|!~]?=" );
			}

			// FF 3.5 - :enabled/:disabled and hidden elements (hidden elements are still enabled)
			// IE8 throws error here and will not see later tests
			if ( el.querySelectorAll( ":enabled" ).length !== 2 ) {
				rbuggyQSA.push( ":enabled", ":disabled" );
			}

			// Support: IE9-11+
			// IE's :disabled selector does not pick up the children of disabled fieldsets
			docElem.appendChild( el ).disabled = true;
			if ( el.querySelectorAll( ":disabled" ).length !== 2 ) {
				rbuggyQSA.push( ":enabled", ":disabled" );
			}

			// Support: Opera 10 - 11 only
			// Opera 10-11 does not throw on post-comma invalid pseudos
			el.querySelectorAll( "*,:x" );
			rbuggyQSA.push( ",.*:" );
		} );
	}

	if ( ( support.matchesSelector = rnative.test( ( matches = docElem.matches ||
		docElem.webkitMatchesSelector ||
		docElem.mozMatchesSelector ||
		docElem.oMatchesSelector ||
		docElem.msMatchesSelector ) ) ) ) {

		assert( function( el ) {

			// Check to see if it's possible to do matchesSelector
			// on a disconnected node (IE 9)
			support.disconnectedMatch = matches.call( el, "*" );

			// This should fail with an exception
			// Gecko does not error, returns false instead
			matches.call( el, "[s!='']:x" );
			rbuggyMatches.push( "!=", pseudos );
		} );
	}

	rbuggyQSA = rbuggyQSA.length && new RegExp( rbuggyQSA.join( "|" ) );
	rbuggyMatches = rbuggyMatches.length && new RegExp( rbuggyMatches.join( "|" ) );

	/* Contains
	---------------------------------------------------------------------- */
	hasCompare = rnative.test( docElem.compareDocumentPosition );

	// Element contains another
	// Purposefully self-exclusive
	// As in, an element does not contain itself
	contains = hasCompare || rnative.test( docElem.contains ) ?
		function( a, b ) {
			var adown = a.nodeType === 9 ? a.documentElement : a,
				bup = b && b.parentNode;
			return a === bup || !!( bup && bup.nodeType === 1 && (
				adown.contains ?
					adown.contains( bup ) :
					a.compareDocumentPosition && a.compareDocumentPosition( bup ) & 16
			) );
		} :
		function( a, b ) {
			if ( b ) {
				while ( ( b = b.parentNode ) ) {
					if ( b === a ) {
						return true;
					}
				}
			}
			return false;
		};

	/* Sorting
	---------------------------------------------------------------------- */

	// Document order sorting
	sortOrder = hasCompare ?
	function( a, b ) {

		// Flag for duplicate removal
		if ( a === b ) {
			hasDuplicate = true;
			return 0;
		}

		// Sort on method existence if only one input has compareDocumentPosition
		var compare = !a.compareDocumentPosition - !b.compareDocumentPosition;
		if ( compare ) {
			return compare;
		}

		// Calculate position if both inputs belong to the same document
		// Support: IE 11+, Edge 17 - 18+
		// IE/Edge sometimes throw a "Permission denied" error when strict-comparing
		// two documents; shallow comparisons work.
		// eslint-disable-next-line eqeqeq
		compare = ( a.ownerDocument || a ) == ( b.ownerDocument || b ) ?
			a.compareDocumentPosition( b ) :

			// Otherwise we know they are disconnected
			1;

		// Disconnected nodes
		if ( compare & 1 ||
			( !support.sortDetached && b.compareDocumentPosition( a ) === compare ) ) {

			// Choose the first element that is related to our preferred document
			// Support: IE 11+, Edge 17 - 18+
			// IE/Edge sometimes throw a "Permission denied" error when strict-comparing
			// two documents; shallow comparisons work.
			// eslint-disable-next-line eqeqeq
			if ( a == document || a.ownerDocument == preferredDoc &&
				contains( preferredDoc, a ) ) {
				return -1;
			}

			// Support: IE 11+, Edge 17 - 18+
			// IE/Edge sometimes throw a "Permission denied" error when strict-comparing
			// two documents; shallow comparisons work.
			// eslint-disable-next-line eqeqeq
			if ( b == document || b.ownerDocument == preferredDoc &&
				contains( preferredDoc, b ) ) {
				return 1;
			}

			// Maintain original order
			return sortInput ?
				( indexOf( sortInput, a ) - indexOf( sortInput, b ) ) :
				0;
		}

		return compare & 4 ? -1 : 1;
	} :
	function( a, b ) {

		// Exit early if the nodes are identical
		if ( a === b ) {
			hasDuplicate = true;
			return 0;
		}

		var cur,
			i = 0,
			aup = a.parentNode,
			bup = b.parentNode,
			ap = [ a ],
			bp = [ b ];

		// Parentless nodes are either documents or disconnected
		if ( !aup || !bup ) {

			// Support: IE 11+, Edge 17 - 18+
			// IE/Edge sometimes throw a "Permission denied" error when strict-comparing
			// two documents; shallow comparisons work.
			/* eslint-disable eqeqeq */
			return a == document ? -1 :
				b == document ? 1 :
				/* eslint-enable eqeqeq */
				aup ? -1 :
				bup ? 1 :
				sortInput ?
				( indexOf( sortInput, a ) - indexOf( sortInput, b ) ) :
				0;

		// If the nodes are siblings, we can do a quick check
		} else if ( aup === bup ) {
			return siblingCheck( a, b );
		}

		// Otherwise we need full lists of their ancestors for comparison
		cur = a;
		while ( ( cur = cur.parentNode ) ) {
			ap.unshift( cur );
		}
		cur = b;
		while ( ( cur = cur.parentNode ) ) {
			bp.unshift( cur );
		}

		// Walk down the tree looking for a discrepancy
		while ( ap[ i ] === bp[ i ] ) {
			i++;
		}

		return i ?

			// Do a sibling check if the nodes have a common ancestor
			siblingCheck( ap[ i ], bp[ i ] ) :

			// Otherwise nodes in our document sort first
			// Support: IE 11+, Edge 17 - 18+
			// IE/Edge sometimes throw a "Permission denied" error when strict-comparing
			// two documents; shallow comparisons work.
			/* eslint-disable eqeqeq */
			ap[ i ] == preferredDoc ? -1 :
			bp[ i ] == preferredDoc ? 1 :
			/* eslint-enable eqeqeq */
			0;
	};

	return document;
};

Sizzle.matches = function( expr, elements ) {
	return Sizzle( expr, null, null, elements );
};

Sizzle.matchesSelector = function( elem, expr ) {
	setDocument( elem );

	if ( support.matchesSelector && documentIsHTML &&
		!nonnativeSelectorCache[ expr + " " ] &&
		( !rbuggyMatches || !rbuggyMatches.test( expr ) ) &&
		( !rbuggyQSA     || !rbuggyQSA.test( expr ) ) ) {

		try {
			var ret = matches.call( elem, expr );

			// IE 9's matchesSelector returns false on disconnected nodes
			if ( ret || support.disconnectedMatch ||

				// As well, disconnected nodes are said to be in a document
				// fragment in IE 9
				elem.document && elem.document.nodeType !== 11 ) {
				return ret;
			}
		} catch ( e ) {
			nonnativeSelectorCache( expr, true );
		}
	}

	return Sizzle( expr, document, null, [ elem ] ).length > 0;
};

Sizzle.contains = function( context, elem ) {

	// Set document vars if needed
	// Support: IE 11+, Edge 17 - 18+
	// IE/Edge sometimes throw a "Permission denied" error when strict-comparing
	// two documents; shallow comparisons work.
	// eslint-disable-next-line eqeqeq
	if ( ( context.ownerDocument || context ) != document ) {
		setDocument( context );
	}
	return contains( context, elem );
};

Sizzle.attr = function( elem, name ) {

	// Set document vars if needed
	// Support: IE 11+, Edge 17 - 18+
	// IE/Edge sometimes throw a "Permission denied" error when strict-comparing
	// two documents; shallow comparisons work.
	// eslint-disable-next-line eqeqeq
	if ( ( elem.ownerDocument || elem ) != document ) {
		setDocument( elem );
	}

	var fn = Expr.attrHandle[ name.toLowerCase() ],

		// Don't get fooled by Object.prototype properties (jQuery #13807)
		val = fn && hasOwn.call( Expr.attrHandle, name.toLowerCase() ) ?
			fn( elem, name, !documentIsHTML ) :
			undefined;

	return val !== undefined ?
		val :
		support.attributes || !documentIsHTML ?
			elem.getAttribute( name ) :
			( val = elem.getAttributeNode( name ) ) && val.specified ?
				val.value :
				null;
};

Sizzle.escape = function( sel ) {
	return ( sel + "" ).replace( rcssescape, fcssescape );
};

Sizzle.error = function( msg ) {
	throw new Error( "Syntax error, unrecognized expression: " + msg );
};

/**
 * Document sorting and removing duplicates
 * @param {ArrayLike} results
 */
Sizzle.uniqueSort = function( results ) {
	var elem,
		duplicates = [],
		j = 0,
		i = 0;

	// Unless we *know* we can detect duplicates, assume their presence
	hasDuplicate = !support.detectDuplicates;
	sortInput = !support.sortStable && results.slice( 0 );
	results.sort( sortOrder );

	if ( hasDuplicate ) {
		while ( ( elem = results[ i++ ] ) ) {
			if ( elem === results[ i ] ) {
				j = duplicates.push( i );
			}
		}
		while ( j-- ) {
			results.splice( duplicates[ j ], 1 );
		}
	}

	// Clear input after sorting to release objects
	// See https://github.com/jquery/sizzle/pull/225
	sortInput = null;

	return results;
};

/**
 * Utility function for retrieving the text value of an array of DOM nodes
 * @param {Array|Element} elem
 */
getText = Sizzle.getText = function( elem ) {
	var node,
		ret = "",
		i = 0,
		nodeType = elem.nodeType;

	if ( !nodeType ) {

		// If no nodeType, this is expected to be an array
		while ( ( node = elem[ i++ ] ) ) {

			// Do not traverse comment nodes
			ret += getText( node );
		}
	} else if ( nodeType === 1 || nodeType === 9 || nodeType === 11 ) {

		// Use textContent for elements
		// innerText usage removed for consistency of new lines (jQuery #11153)
		if ( typeof elem.textContent === "string" ) {
			return elem.textContent;
		} else {

			// Traverse its children
			for ( elem = elem.firstChild; elem; elem = elem.nextSibling ) {
				ret += getText( elem );
			}
		}
	} else if ( nodeType === 3 || nodeType === 4 ) {
		return elem.nodeValue;
	}

	// Do not include comment or processing instruction nodes

	return ret;
};

Expr = Sizzle.selectors = {

	// Can be adjusted by the user
	cacheLength: 50,

	createPseudo: markFunction,

	match: matchExpr,

	attrHandle: {},

	find: {},

	relative: {
		">": { dir: "parentNode", first: true },
		" ": { dir: "parentNode" },
		"+": { dir: "previousSibling", first: true },
		"~": { dir: "previousSibling" }
	},

	preFilter: {
		"ATTR": function( match ) {
			match[ 1 ] = match[ 1 ].replace( runescape, funescape );

			// Move the given value to match[3] whether quoted or unquoted
			match[ 3 ] = ( match[ 3 ] || match[ 4 ] ||
				match[ 5 ] || "" ).replace( runescape, funescape );

			if ( match[ 2 ] === "~=" ) {
				match[ 3 ] = " " + match[ 3 ] + " ";
			}

			return match.slice( 0, 4 );
		},

		"CHILD": function( match ) {

			/* matches from matchExpr["CHILD"]
				1 type (only|nth|...)
				2 what (child|of-type)
				3 argument (even|odd|\d*|\d*n([+-]\d+)?|...)
				4 xn-component of xn+y argument ([+-]?\d*n|)
				5 sign of xn-component
				6 x of xn-component
				7 sign of y-component
				8 y of y-component
			*/
			match[ 1 ] = match[ 1 ].toLowerCase();

			if ( match[ 1 ].slice( 0, 3 ) === "nth" ) {

				// nth-* requires argument
				if ( !match[ 3 ] ) {
					Sizzle.error( match[ 0 ] );
				}

				// numeric x and y parameters for Expr.filter.CHILD
				// remember that false/true cast respectively to 0/1
				match[ 4 ] = +( match[ 4 ] ?
					match[ 5 ] + ( match[ 6 ] || 1 ) :
					2 * ( match[ 3 ] === "even" || match[ 3 ] === "odd" ) );
				match[ 5 ] = +( ( match[ 7 ] + match[ 8 ] ) || match[ 3 ] === "odd" );

				// other types prohibit arguments
			} else if ( match[ 3 ] ) {
				Sizzle.error( match[ 0 ] );
			}

			return match;
		},

		"PSEUDO": function( match ) {
			var excess,
				unquoted = !match[ 6 ] && match[ 2 ];

			if ( matchExpr[ "CHILD" ].test( match[ 0 ] ) ) {
				return null;
			}

			// Accept quoted arguments as-is
			if ( match[ 3 ] ) {
				match[ 2 ] = match[ 4 ] || match[ 5 ] || "";

			// Strip excess characters from unquoted arguments
			} else if ( unquoted && rpseudo.test( unquoted ) &&

				// Get excess from tokenize (recursively)
				( excess = tokenize( unquoted, true ) ) &&

				// advance to the next closing parenthesis
				( excess = unquoted.indexOf( ")", unquoted.length - excess ) - unquoted.length ) ) {

				// excess is a negative index
				match[ 0 ] = match[ 0 ].slice( 0, excess );
				match[ 2 ] = unquoted.slice( 0, excess );
			}

			// Return only captures needed by the pseudo filter method (type and argument)
			return match.slice( 0, 3 );
		}
	},

	filter: {

		"TAG": function( nodeNameSelector ) {
			var nodeName = nodeNameSelector.replace( runescape, funescape ).toLowerCase();
			return nodeNameSelector === "*" ?
				function() {
					return true;
				} :
				function( elem ) {
					return elem.nodeName && elem.nodeName.toLowerCase() === nodeName;
				};
		},

		"CLASS": function( className ) {
			var pattern = classCache[ className + " " ];

			return pattern ||
				( pattern = new RegExp( "(^|" + whitespace +
					")" + className + "(" + whitespace + "|$)" ) ) && classCache(
						className, function( elem ) {
							return pattern.test(
								typeof elem.className === "string" && elem.className ||
								typeof elem.getAttribute !== "undefined" &&
									elem.getAttribute( "class" ) ||
								""
							);
				} );
		},

		"ATTR": function( name, operator, check ) {
			return function( elem ) {
				var result = Sizzle.attr( elem, name );

				if ( result == null ) {
					return operator === "!=";
				}
				if ( !operator ) {
					return true;
				}

				result += "";

				/* eslint-disable max-len */

				return operator === "=" ? result === check :
					operator === "!=" ? result !== check :
					operator === "^=" ? check && result.indexOf( check ) === 0 :
					operator === "*=" ? check && result.indexOf( check ) > -1 :
					operator === "$=" ? check && result.slice( -check.length ) === check :
					operator === "~=" ? ( " " + result.replace( rwhitespace, " " ) + " " ).indexOf( check ) > -1 :
					operator === "|=" ? result === check || result.slice( 0, check.length + 1 ) === check + "-" :
					false;
				/* eslint-enable max-len */

			};
		},

		"CHILD": function( type, what, _argument, first, last ) {
			var simple = type.slice( 0, 3 ) !== "nth",
				forward = type.slice( -4 ) !== "last",
				ofType = what === "of-type";

			return first === 1 && last === 0 ?

				// Shortcut for :nth-*(n)
				function( elem ) {
					return !!elem.parentNode;
				} :

				function( elem, _context, xml ) {
					var cache, uniqueCache, outerCache, node, nodeIndex, start,
						dir = simple !== forward ? "nextSibling" : "previousSibling",
						parent = elem.parentNode,
						name = ofType && elem.nodeName.toLowerCase(),
						useCache = !xml && !ofType,
						diff = false;

					if ( parent ) {

						// :(first|last|only)-(child|of-type)
						if ( simple ) {
							while ( dir ) {
								node = elem;
								while ( ( node = node[ dir ] ) ) {
									if ( ofType ?
										node.nodeName.toLowerCase() === name :
										node.nodeType === 1 ) {

										return false;
									}
								}

								// Reverse direction for :only-* (if we haven't yet done so)
								start = dir = type === "only" && !start && "nextSibling";
							}
							return true;
						}

						start = [ forward ? parent.firstChild : parent.lastChild ];

						// non-xml :nth-child(...) stores cache data on `parent`
						if ( forward && useCache ) {

							// Seek `elem` from a previously-cached index

							// ...in a gzip-friendly way
							node = parent;
							outerCache = node[ expando ] || ( node[ expando ] = {} );

							// Support: IE <9 only
							// Defend against cloned attroperties (jQuery gh-1709)
							uniqueCache = outerCache[ node.uniqueID ] ||
								( outerCache[ node.uniqueID ] = {} );

							cache = uniqueCache[ type ] || [];
							nodeIndex = cache[ 0 ] === dirruns && cache[ 1 ];
							diff = nodeIndex && cache[ 2 ];
							node = nodeIndex && parent.childNodes[ nodeIndex ];

							while ( ( node = ++nodeIndex && node && node[ dir ] ||

								// Fallback to seeking `elem` from the start
								( diff = nodeIndex = 0 ) || start.pop() ) ) {

								// When found, cache indexes on `parent` and break
								if ( node.nodeType === 1 && ++diff && node === elem ) {
									uniqueCache[ type ] = [ dirruns, nodeIndex, diff ];
									break;
								}
							}

						} else {

							// Use previously-cached element index if available
							if ( useCache ) {

								// ...in a gzip-friendly way
								node = elem;
								outerCache = node[ expando ] || ( node[ expando ] = {} );

								// Support: IE <9 only
								// Defend against cloned attroperties (jQuery gh-1709)
								uniqueCache = outerCache[ node.uniqueID ] ||
									( outerCache[ node.uniqueID ] = {} );

								cache = uniqueCache[ type ] || [];
								nodeIndex = cache[ 0 ] === dirruns && cache[ 1 ];
								diff = nodeIndex;
							}

							// xml :nth-child(...)
							// or :nth-last-child(...) or :nth(-last)?-of-type(...)
							if ( diff === false ) {

								// Use the same loop as above to seek `elem` from the start
								while ( ( node = ++nodeIndex && node && node[ dir ] ||
									( diff = nodeIndex = 0 ) || start.pop() ) ) {

									if ( ( ofType ?
										node.nodeName.toLowerCase() === name :
										node.nodeType === 1 ) &&
										++diff ) {

										// Cache the index of each encountered element
										if ( useCache ) {
											outerCache = node[ expando ] ||
												( node[ expando ] = {} );

											// Support: IE <9 only
											// Defend against cloned attroperties (jQuery gh-1709)
											uniqueCache = outerCache[ node.uniqueID ] ||
												( outerCache[ node.uniqueID ] = {} );

											uniqueCache[ type ] = [ dirruns, diff ];
										}

										if ( node === elem ) {
											break;
										}
									}
								}
							}
						}

						// Incorporate the offset, then check against cycle size
						diff -= last;
						return diff === first || ( diff % first === 0 && diff / first >= 0 );
					}
				};
		},

		"PSEUDO": function( pseudo, argument ) {

			// pseudo-class names are case-insensitive
			// http://www.w3.org/TR/selectors/#pseudo-classes
			// Prioritize by case sensitivity in case custom pseudos are added with uppercase letters
			// Remember that setFilters inherits from pseudos
			var args,
				fn = Expr.pseudos[ pseudo ] || Expr.setFilters[ pseudo.toLowerCase() ] ||
					Sizzle.error( "unsupported pseudo: " + pseudo );

			// The user may use createPseudo to indicate that
			// arguments are needed to create the filter function
			// just as Sizzle does
			if ( fn[ expando ] ) {
				return fn( argument );
			}

			// But maintain support for old signatures
			if ( fn.length > 1 ) {
				args = [ pseudo, pseudo, "", argument ];
				return Expr.setFilters.hasOwnProperty( pseudo.toLowerCase() ) ?
					markFunction( function( seed, matches ) {
						var idx,
							matched = fn( seed, argument ),
							i = matched.length;
						while ( i-- ) {
							idx = indexOf( seed, matched[ i ] );
							seed[ idx ] = !( matches[ idx ] = matched[ i ] );
						}
					} ) :
					function( elem ) {
						return fn( elem, 0, args );
					};
			}

			return fn;
		}
	},

	pseudos: {

		// Potentially complex pseudos
		"not": markFunction( function( selector ) {

			// Trim the selector passed to compile
			// to avoid treating leading and trailing
			// spaces as combinators
			var input = [],
				results = [],
				matcher = compile( selector.replace( rtrim, "$1" ) );

			return matcher[ expando ] ?
				markFunction( function( seed, matches, _context, xml ) {
					var elem,
						unmatched = matcher( seed, null, xml, [] ),
						i = seed.length;

					// Match elements unmatched by `matcher`
					while ( i-- ) {
						if ( ( elem = unmatched[ i ] ) ) {
							seed[ i ] = !( matches[ i ] = elem );
						}
					}
				} ) :
				function( elem, _context, xml ) {
					input[ 0 ] = elem;
					matcher( input, null, xml, results );

					// Don't keep the element (issue #299)
					input[ 0 ] = null;
					return !results.pop();
				};
		} ),

		"has": markFunction( function( selector ) {
			return function( elem ) {
				return Sizzle( selector, elem ).length > 0;
			};
		} ),

		"contains": markFunction( function( text ) {
			text = text.replace( runescape, funescape );
			return function( elem ) {
				return ( elem.textContent || getText( elem ) ).indexOf( text ) > -1;
			};
		} ),

		// "Whether an element is represented by a :lang() selector
		// is based solely on the element's language value
		// being equal to the identifier C,
		// or beginning with the identifier C immediately followed by "-".
		// The matching of C against the element's language value is performed case-insensitively.
		// The identifier C does not have to be a valid language name."
		// http://www.w3.org/TR/selectors/#lang-pseudo
		"lang": markFunction( function( lang ) {

			// lang value must be a valid identifier
			if ( !ridentifier.test( lang || "" ) ) {
				Sizzle.error( "unsupported lang: " + lang );
			}
			lang = lang.replace( runescape, funescape ).toLowerCase();
			return function( elem ) {
				var elemLang;
				do {
					if ( ( elemLang = documentIsHTML ?
						elem.lang :
						elem.getAttribute( "xml:lang" ) || elem.getAttribute( "lang" ) ) ) {

						elemLang = elemLang.toLowerCase();
						return elemLang === lang || elemLang.indexOf( lang + "-" ) === 0;
					}
				} while ( ( elem = elem.parentNode ) && elem.nodeType === 1 );
				return false;
			};
		} ),

		// Miscellaneous
		"target": function( elem ) {
			var hash = window.location && window.location.hash;
			return hash && hash.slice( 1 ) === elem.id;
		},

		"root": function( elem ) {
			return elem === docElem;
		},

		"focus": function( elem ) {
			return elem === document.activeElement &&
				( !document.hasFocus || document.hasFocus() ) &&
				!!( elem.type || elem.href || ~elem.tabIndex );
		},

		// Boolean properties
		"enabled": createDisabledPseudo( false ),
		"disabled": createDisabledPseudo( true ),

		"checked": function( elem ) {

			// In CSS3, :checked should return both checked and selected elements
			// http://www.w3.org/TR/2011/REC-css3-selectors-20110929/#checked
			var nodeName = elem.nodeName.toLowerCase();
			return ( nodeName === "input" && !!elem.checked ) ||
				( nodeName === "option" && !!elem.selected );
		},

		"selected": function( elem ) {

			// Accessing this property makes selected-by-default
			// options in Safari work properly
			if ( elem.parentNode ) {
				// eslint-disable-next-line no-unused-expressions
				elem.parentNode.selectedIndex;
			}

			return elem.selected === true;
		},

		// Contents
		"empty": function( elem ) {

			// http://www.w3.org/TR/selectors/#empty-pseudo
			// :empty is negated by element (1) or content nodes (text: 3; cdata: 4; entity ref: 5),
			//   but not by others (comment: 8; processing instruction: 7; etc.)
			// nodeType < 6 works because attributes (2) do not appear as children
			for ( elem = elem.firstChild; elem; elem = elem.nextSibling ) {
				if ( elem.nodeType < 6 ) {
					return false;
				}
			}
			return true;
		},

		"parent": function( elem ) {
			return !Expr.pseudos[ "empty" ]( elem );
		},

		// Element/input types
		"header": function( elem ) {
			return rheader.test( elem.nodeName );
		},

		"input": function( elem ) {
			return rinputs.test( elem.nodeName );
		},

		"button": function( elem ) {
			var name = elem.nodeName.toLowerCase();
			return name === "input" && elem.type === "button" || name === "button";
		},

		"text": function( elem ) {
			var attr;
			return elem.nodeName.toLowerCase() === "input" &&
				elem.type === "text" &&

				// Support: IE<8
				// New HTML5 attribute values (e.g., "search") appear with elem.type === "text"
				( ( attr = elem.getAttribute( "type" ) ) == null ||
					attr.toLowerCase() === "text" );
		},

		// Position-in-collection
		"first": createPositionalPseudo( function() {
			return [ 0 ];
		} ),

		"last": createPositionalPseudo( function( _matchIndexes, length ) {
			return [ length - 1 ];
		} ),

		"eq": createPositionalPseudo( function( _matchIndexes, length, argument ) {
			return [ argument < 0 ? argument + length : argument ];
		} ),

		"even": createPositionalPseudo( function( matchIndexes, length ) {
			var i = 0;
			for ( ; i < length; i += 2 ) {
				matchIndexes.push( i );
			}
			return matchIndexes;
		} ),

		"odd": createPositionalPseudo( function( matchIndexes, length ) {
			var i = 1;
			for ( ; i < length; i += 2 ) {
				matchIndexes.push( i );
			}
			return matchIndexes;
		} ),

		"lt": createPositionalPseudo( function( matchIndexes, length, argument ) {
			var i = argument < 0 ?
				argument + length :
				argument > length ?
					length :
					argument;
			for ( ; --i >= 0; ) {
				matchIndexes.push( i );
			}
			return matchIndexes;
		} ),

		"gt": createPositionalPseudo( function( matchIndexes, length, argument ) {
			var i = argument < 0 ? argument + length : argument;
			for ( ; ++i < length; ) {
				matchIndexes.push( i );
			}
			return matchIndexes;
		} )
	}
};

Expr.pseudos[ "nth" ] = Expr.pseudos[ "eq" ];

// Add button/input type pseudos
for ( i in { radio: true, checkbox: true, file: true, password: true, image: true } ) {
	Expr.pseudos[ i ] = createInputPseudo( i );
}
for ( i in { submit: true, reset: true } ) {
	Expr.pseudos[ i ] = createButtonPseudo( i );
}

// Easy API for creating new setFilters
function setFilters() {}
setFilters.prototype = Expr.filters = Expr.pseudos;
Expr.setFilters = new setFilters();

tokenize = Sizzle.tokenize = function( selector, parseOnly ) {
	var matched, match, tokens, type,
		soFar, groups, preFilters,
		cached = tokenCache[ selector + " " ];

	if ( cached ) {
		return parseOnly ? 0 : cached.slice( 0 );
	}

	soFar = selector;
	groups = [];
	preFilters = Expr.preFilter;

	while ( soFar ) {

		// Comma and first run
		if ( !matched || ( match = rcomma.exec( soFar ) ) ) {
			if ( match ) {

				// Don't consume trailing commas as valid
				soFar = soFar.slice( match[ 0 ].length ) || soFar;
			}
			groups.push( ( tokens = [] ) );
		}

		matched = false;

		// Combinators
		if ( ( match = rcombinators.exec( soFar ) ) ) {
			matched = match.shift();
			tokens.push( {
				value: matched,

				// Cast descendant combinators to space
				type: match[ 0 ].replace( rtrim, " " )
			} );
			soFar = soFar.slice( matched.length );
		}

		// Filters
		for ( type in Expr.filter ) {
			if ( ( match = matchExpr[ type ].exec( soFar ) ) && ( !preFilters[ type ] ||
				( match = preFilters[ type ]( match ) ) ) ) {
				matched = match.shift();
				tokens.push( {
					value: matched,
					type: type,
					matches: match
				} );
				soFar = soFar.slice( matched.length );
			}
		}

		if ( !matched ) {
			break;
		}
	}

	// Return the length of the invalid excess
	// if we're just parsing
	// Otherwise, throw an error or return tokens
	return parseOnly ?
		soFar.length :
		soFar ?
			Sizzle.error( selector ) :

			// Cache the tokens
			tokenCache( selector, groups ).slice( 0 );
};

function toSelector( tokens ) {
	var i = 0,
		len = tokens.length,
		selector = "";
	for ( ; i < len; i++ ) {
		selector += tokens[ i ].value;
	}
	return selector;
}

function addCombinator( matcher, combinator, base ) {
	var dir = combinator.dir,
		skip = combinator.next,
		key = skip || dir,
		checkNonElements = base && key === "parentNode",
		doneName = done++;

	return combinator.first ?

		// Check against closest ancestor/preceding element
		function( elem, context, xml ) {
			while ( ( elem = elem[ dir ] ) ) {
				if ( elem.nodeType === 1 || checkNonElements ) {
					return matcher( elem, context, xml );
				}
			}
			return false;
		} :

		// Check against all ancestor/preceding elements
		function( elem, context, xml ) {
			var oldCache, uniqueCache, outerCache,
				newCache = [ dirruns, doneName ];

			// We can't set arbitrary data on XML nodes, so they don't benefit from combinator caching
			if ( xml ) {
				while ( ( elem = elem[ dir ] ) ) {
					if ( elem.nodeType === 1 || checkNonElements ) {
						if ( matcher( elem, context, xml ) ) {
							return true;
						}
					}
				}
			} else {
				while ( ( elem = elem[ dir ] ) ) {
					if ( elem.nodeType === 1 || checkNonElements ) {
						outerCache = elem[ expando ] || ( elem[ expando ] = {} );

						// Support: IE <9 only
						// Defend against cloned attroperties (jQuery gh-1709)
						uniqueCache = outerCache[ elem.uniqueID ] ||
							( outerCache[ elem.uniqueID ] = {} );

						if ( skip && skip === elem.nodeName.toLowerCase() ) {
							elem = elem[ dir ] || elem;
						} else if ( ( oldCache = uniqueCache[ key ] ) &&
							oldCache[ 0 ] === dirruns && oldCache[ 1 ] === doneName ) {

							// Assign to newCache so results back-propagate to previous elements
							return ( newCache[ 2 ] = oldCache[ 2 ] );
						} else {

							// Reuse newcache so results back-propagate to previous elements
							uniqueCache[ key ] = newCache;

							// A match means we're done; a fail means we have to keep checking
							if ( ( newCache[ 2 ] = matcher( elem, context, xml ) ) ) {
								return true;
							}
						}
					}
				}
			}
			return false;
		};
}

function elementMatcher( matchers ) {
	return matchers.length > 1 ?
		function( elem, context, xml ) {
			var i = matchers.length;
			while ( i-- ) {
				if ( !matchers[ i ]( elem, context, xml ) ) {
					return false;
				}
			}
			return true;
		} :
		matchers[ 0 ];
}

function multipleContexts( selector, contexts, results ) {
	var i = 0,
		len = contexts.length;
	for ( ; i < len; i++ ) {
		Sizzle( selector, contexts[ i ], results );
	}
	return results;
}

function condense( unmatched, map, filter, context, xml ) {
	var elem,
		newUnmatched = [],
		i = 0,
		len = unmatched.length,
		mapped = map != null;

	for ( ; i < len; i++ ) {
		if ( ( elem = unmatched[ i ] ) ) {
			if ( !filter || filter( elem, context, xml ) ) {
				newUnmatched.push( elem );
				if ( mapped ) {
					map.push( i );
				}
			}
		}
	}

	return newUnmatched;
}

function setMatcher( preFilter, selector, matcher, postFilter, postFinder, postSelector ) {
	if ( postFilter && !postFilter[ expando ] ) {
		postFilter = setMatcher( postFilter );
	}
	if ( postFinder && !postFinder[ expando ] ) {
		postFinder = setMatcher( postFinder, postSelector );
	}
	return markFunction( function( seed, results, context, xml ) {
		var temp, i, elem,
			preMap = [],
			postMap = [],
			preexisting = results.length,

			// Get initial elements from seed or context
			elems = seed || multipleContexts(
				selector || "*",
				context.nodeType ? [ context ] : context,
				[]
			),

			// Prefilter to get matcher input, preserving a map for seed-results synchronization
			matcherIn = preFilter && ( seed || !selector ) ?
				condense( elems, preMap, preFilter, context, xml ) :
				elems,

			matcherOut = matcher ?

				// If we have a postFinder, or filtered seed, or non-seed postFilter or preexisting results,
				postFinder || ( seed ? preFilter : preexisting || postFilter ) ?

					// ...intermediate processing is necessary
					[] :

					// ...otherwise use results directly
					results :
				matcherIn;

		// Find primary matches
		if ( matcher ) {
			matcher( matcherIn, matcherOut, context, xml );
		}

		// Apply postFilter
		if ( postFilter ) {
			temp = condense( matcherOut, postMap );
			postFilter( temp, [], context, xml );

			// Un-match failing elements by moving them back to matcherIn
			i = temp.length;
			while ( i-- ) {
				if ( ( elem = temp[ i ] ) ) {
					matcherOut[ postMap[ i ] ] = !( matcherIn[ postMap[ i ] ] = elem );
				}
			}
		}

		if ( seed ) {
			if ( postFinder || preFilter ) {
				if ( postFinder ) {

					// Get the final matcherOut by condensing this intermediate into postFinder contexts
					temp = [];
					i = matcherOut.length;
					while ( i-- ) {
						if ( ( elem = matcherOut[ i ] ) ) {

							// Restore matcherIn since elem is not yet a final match
							temp.push( ( matcherIn[ i ] = elem ) );
						}
					}
					postFinder( null, ( matcherOut = [] ), temp, xml );
				}

				// Move matched elements from seed to results to keep them synchronized
				i = matcherOut.length;
				while ( i-- ) {
					if ( ( elem = matcherOut[ i ] ) &&
						( temp = postFinder ? indexOf( seed, elem ) : preMap[ i ] ) > -1 ) {

						seed[ temp ] = !( results[ temp ] = elem );
					}
				}
			}

		// Add elements to results, through postFinder if defined
		} else {
			matcherOut = condense(
				matcherOut === results ?
					matcherOut.splice( preexisting, matcherOut.length ) :
					matcherOut
			);
			if ( postFinder ) {
				postFinder( null, results, matcherOut, xml );
			} else {
				push.apply( results, matcherOut );
			}
		}
	} );
}

function matcherFromTokens( tokens ) {
	var checkContext, matcher, j,
		len = tokens.length,
		leadingRelative = Expr.relative[ tokens[ 0 ].type ],
		implicitRelative = leadingRelative || Expr.relative[ " " ],
		i = leadingRelative ? 1 : 0,

		// The foundational matcher ensures that elements are reachable from top-level context(s)
		matchContext = addCombinator( function( elem ) {
			return elem === checkContext;
		}, implicitRelative, true ),
		matchAnyContext = addCombinator( function( elem ) {
			return indexOf( checkContext, elem ) > -1;
		}, implicitRelative, true ),
		matchers = [ function( elem, context, xml ) {
			var ret = ( !leadingRelative && ( xml || context !== outermostContext ) ) || (
				( checkContext = context ).nodeType ?
					matchContext( elem, context, xml ) :
					matchAnyContext( elem, context, xml ) );

			// Avoid hanging onto element (issue #299)
			checkContext = null;
			return ret;
		} ];

	for ( ; i < len; i++ ) {
		if ( ( matcher = Expr.relative[ tokens[ i ].type ] ) ) {
			matchers = [ addCombinator( elementMatcher( matchers ), matcher ) ];
		} else {
			matcher = Expr.filter[ tokens[ i ].type ].apply( null, tokens[ i ].matches );

			// Return special upon seeing a positional matcher
			if ( matcher[ expando ] ) {

				// Find the next relative operator (if any) for proper handling
				j = ++i;
				for ( ; j < len; j++ ) {
					if ( Expr.relative[ tokens[ j ].type ] ) {
						break;
					}
				}
				return setMatcher(
					i > 1 && elementMatcher( matchers ),
					i > 1 && toSelector(

					// If the preceding token was a descendant combinator, insert an implicit any-element `*`
					tokens
						.slice( 0, i - 1 )
						.concat( { value: tokens[ i - 2 ].type === " " ? "*" : "" } )
					).replace( rtrim, "$1" ),
					matcher,
					i < j && matcherFromTokens( tokens.slice( i, j ) ),
					j < len && matcherFromTokens( ( tokens = tokens.slice( j ) ) ),
					j < len && toSelector( tokens )
				);
			}
			matchers.push( matcher );
		}
	}

	return elementMatcher( matchers );
}

function matcherFromGroupMatchers( elementMatchers, setMatchers ) {
	var bySet = setMatchers.length > 0,
		byElement = elementMatchers.length > 0,
		superMatcher = function( seed, context, xml, results, outermost ) {
			var elem, j, matcher,
				matchedCount = 0,
				i = "0",
				unmatched = seed && [],
				setMatched = [],
				contextBackup = outermostContext,

				// We must always have either seed elements or outermost context
				elems = seed || byElement && Expr.find[ "TAG" ]( "*", outermost ),

				// Use integer dirruns iff this is the outermost matcher
				dirrunsUnique = ( dirruns += contextBackup == null ? 1 : Math.random() || 0.1 ),
				len = elems.length;

			if ( outermost ) {

				// Support: IE 11+, Edge 17 - 18+
				// IE/Edge sometimes throw a "Permission denied" error when strict-comparing
				// two documents; shallow comparisons work.
				// eslint-disable-next-line eqeqeq
				outermostContext = context == document || context || outermost;
			}

			// Add elements passing elementMatchers directly to results
			// Support: IE<9, Safari
			// Tolerate NodeList properties (IE: "length"; Safari: <number>) matching elements by id
			for ( ; i !== len && ( elem = elems[ i ] ) != null; i++ ) {
				if ( byElement && elem ) {
					j = 0;

					// Support: IE 11+, Edge 17 - 18+
					// IE/Edge sometimes throw a "Permission denied" error when strict-comparing
					// two documents; shallow comparisons work.
					// eslint-disable-next-line eqeqeq
					if ( !context && elem.ownerDocument != document ) {
						setDocument( elem );
						xml = !documentIsHTML;
					}
					while ( ( matcher = elementMatchers[ j++ ] ) ) {
						if ( matcher( elem, context || document, xml ) ) {
							results.push( elem );
							break;
						}
					}
					if ( outermost ) {
						dirruns = dirrunsUnique;
					}
				}

				// Track unmatched elements for set filters
				if ( bySet ) {

					// They will have gone through all possible matchers
					if ( ( elem = !matcher && elem ) ) {
						matchedCount--;
					}

					// Lengthen the array for every element, matched or not
					if ( seed ) {
						unmatched.push( elem );
					}
				}
			}

			// `i` is now the count of elements visited above, and adding it to `matchedCount`
			// makes the latter nonnegative.
			matchedCount += i;

			// Apply set filters to unmatched elements
			// NOTE: This can be skipped if there are no unmatched elements (i.e., `matchedCount`
			// equals `i`), unless we didn't visit _any_ elements in the above loop because we have
			// no element matchers and no seed.
			// Incrementing an initially-string "0" `i` allows `i` to remain a string only in that
			// case, which will result in a "00" `matchedCount` that differs from `i` but is also
			// numerically zero.
			if ( bySet && i !== matchedCount ) {
				j = 0;
				while ( ( matcher = setMatchers[ j++ ] ) ) {
					matcher( unmatched, setMatched, context, xml );
				}

				if ( seed ) {

					// Reintegrate element matches to eliminate the need for sorting
					if ( matchedCount > 0 ) {
						while ( i-- ) {
							if ( !( unmatched[ i ] || setMatched[ i ] ) ) {
								setMatched[ i ] = pop.call( results );
							}
						}
					}

					// Discard index placeholder values to get only actual matches
					setMatched = condense( setMatched );
				}

				// Add matches to results
				push.apply( results, setMatched );

				// Seedless set matches succeeding multiple successful matchers stipulate sorting
				if ( outermost && !seed && setMatched.length > 0 &&
					( matchedCount + setMatchers.length ) > 1 ) {

					Sizzle.uniqueSort( results );
				}
			}

			// Override manipulation of globals by nested matchers
			if ( outermost ) {
				dirruns = dirrunsUnique;
				outermostContext = contextBackup;
			}

			return unmatched;
		};

	return bySet ?
		markFunction( superMatcher ) :
		superMatcher;
}

compile = Sizzle.compile = function( selector, match /* Internal Use Only */ ) {
	var i,
		setMatchers = [],
		elementMatchers = [],
		cached = compilerCache[ selector + " " ];

	if ( !cached ) {

		// Generate a function of recursive functions that can be used to check each element
		if ( !match ) {
			match = tokenize( selector );
		}
		i = match.length;
		while ( i-- ) {
			cached = matcherFromTokens( match[ i ] );
			if ( cached[ expando ] ) {
				setMatchers.push( cached );
			} else {
				elementMatchers.push( cached );
			}
		}

		// Cache the compiled function
		cached = compilerCache(
			selector,
			matcherFromGroupMatchers( elementMatchers, setMatchers )
		);

		// Save selector and tokenization
		cached.selector = selector;
	}
	return cached;
};

/**
 * A low-level selection function that works with Sizzle's compiled
 *  selector functions
 * @param {String|Function} selector A selector or a pre-compiled
 *  selector function built with Sizzle.compile
 * @param {Element} context
 * @param {Array} [results]
 * @param {Array} [seed] A set of elements to match against
 */
select = Sizzle.select = function( selector, context, results, seed ) {
	var i, tokens, token, type, find,
		compiled = typeof selector === "function" && selector,
		match = !seed && tokenize( ( selector = compiled.selector || selector ) );

	results = results || [];

	// Try to minimize operations if there is only one selector in the list and no seed
	// (the latter of which guarantees us context)
	if ( match.length === 1 ) {

		// Reduce context if the leading compound selector is an ID
		tokens = match[ 0 ] = match[ 0 ].slice( 0 );
		if ( tokens.length > 2 && ( token = tokens[ 0 ] ).type === "ID" &&
			context.nodeType === 9 && documentIsHTML && Expr.relative[ tokens[ 1 ].type ] ) {

			context = ( Expr.find[ "ID" ]( token.matches[ 0 ]
				.replace( runescape, funescape ), context ) || [] )[ 0 ];
			if ( !context ) {
				return results;

			// Precompiled matchers will still verify ancestry, so step up a level
			} else if ( compiled ) {
				context = context.parentNode;
			}

			selector = selector.slice( tokens.shift().value.length );
		}

		// Fetch a seed set for right-to-left matching
		i = matchExpr[ "needsContext" ].test( selector ) ? 0 : tokens.length;
		while ( i-- ) {
			token = tokens[ i ];

			// Abort if we hit a combinator
			if ( Expr.relative[ ( type = token.type ) ] ) {
				break;
			}
			if ( ( find = Expr.find[ type ] ) ) {

				// Search, expanding context for leading sibling combinators
				if ( ( seed = find(
					token.matches[ 0 ].replace( runescape, funescape ),
					rsibling.test( tokens[ 0 ].type ) && testContext( context.parentNode ) ||
						context
				) ) ) {

					// If seed is empty or no tokens remain, we can return early
					tokens.splice( i, 1 );
					selector = seed.length && toSelector( tokens );
					if ( !selector ) {
						push.apply( results, seed );
						return results;
					}

					break;
				}
			}
		}
	}

	// Compile and execute a filtering function if one is not provided
	// Provide `match` to avoid retokenization if we modified the selector above
	( compiled || compile( selector, match ) )(
		seed,
		context,
		!documentIsHTML,
		results,
		!context || rsibling.test( selector ) && testContext( context.parentNode ) || context
	);
	return results;
};

// One-time assignments

// Sort stability
support.sortStable = expando.split( "" ).sort( sortOrder ).join( "" ) === expando;

// Support: Chrome 14-35+
// Always assume duplicates if they aren't passed to the comparison function
support.detectDuplicates = !!hasDuplicate;

// Initialize against the default document
setDocument();

// Support: Webkit<537.32 - Safari 6.0.3/Chrome 25 (fixed in Chrome 27)
// Detached nodes confoundingly follow *each other*
support.sortDetached = assert( function( el ) {

	// Should return 1, but returns 4 (following)
	return el.compareDocumentPosition( document.createElement( "fieldset" ) ) & 1;
} );

// Support: IE<8
// Prevent attribute/property "interpolation"
// https://msdn.microsoft.com/en-us/library/ms536429%28VS.85%29.aspx
if ( !assert( function( el ) {
	el.innerHTML = "<a href='#'></a>";
	return el.firstChild.getAttribute( "href" ) === "#";
} ) ) {
	addHandle( "type|href|height|width", function( elem, name, isXML ) {
		if ( !isXML ) {
			return elem.getAttribute( name, name.toLowerCase() === "type" ? 1 : 2 );
		}
	} );
}

// Support: IE<9
// Use defaultValue in place of getAttribute("value")
if ( !support.attributes || !assert( function( el ) {
	el.innerHTML = "<input/>";
	el.firstChild.setAttribute( "value", "" );
	return el.firstChild.getAttribute( "value" ) === "";
} ) ) {
	addHandle( "value", function( elem, _name, isXML ) {
		if ( !isXML && elem.nodeName.toLowerCase() === "input" ) {
			return elem.defaultValue;
		}
	} );
}

// Support: IE<9
// Use getAttributeNode to fetch booleans when getAttribute lies
if ( !assert( function( el ) {
	return el.getAttribute( "disabled" ) == null;
} ) ) {
	addHandle( booleans, function( elem, name, isXML ) {
		var val;
		if ( !isXML ) {
			return elem[ name ] === true ? name.toLowerCase() :
				( val = elem.getAttributeNode( name ) ) && val.specified ?
					val.value :
					null;
		}
	} );
}

return Sizzle;

} )( window );



jQuery.find = Sizzle;
jQuery.expr = Sizzle.selectors;

// Deprecated
jQuery.expr[ ":" ] = jQuery.expr.pseudos;
jQuery.uniqueSort = jQuery.unique = Sizzle.uniqueSort;
jQuery.text = Sizzle.getText;
jQuery.isXMLDoc = Sizzle.isXML;
jQuery.contains = Sizzle.contains;
jQuery.escapeSelector = Sizzle.escape;




var dir = function( elem, dir, until ) {
	var matched = [],
		truncate = until !== undefined;

	while ( ( elem = elem[ dir ] ) && elem.nodeType !== 9 ) {
		if ( elem.nodeType === 1 ) {
			if ( truncate && jQuery( elem ).is( until ) ) {
				break;
			}
			matched.push( elem );
		}
	}
	return matched;
};


var siblings = function( n, elem ) {
	var matched = [];

	for ( ; n; n = n.nextSibling ) {
		if ( n.nodeType === 1 && n !== elem ) {
			matched.push( n );
		}
	}

	return matched;
};


var rneedsContext = jQuery.expr.match.needsContext;



function nodeName( elem, name ) {

	return elem.nodeName && elem.nodeName.toLowerCase() === name.toLowerCase();

}
var rsingleTag = ( /^<([a-z][^\/\0>:\x20\t\r\n\f]*)[\x20\t\r\n\f]*\/?>(?:<\/\1>|)$/i );



// Implement the identical functionality for filter and not
function winnow( elements, qualifier, not ) {
	if ( isFunction( qualifier ) ) {
		return jQuery.grep( elements, function( elem, i ) {
			return !!qualifier.call( elem, i, elem ) !== not;
		} );
	}

	// Single element
	if ( qualifier.nodeType ) {
		return jQuery.grep( elements, function( elem ) {
			return ( elem === qualifier ) !== not;
		} );
	}

	// Arraylike of elements (jQuery, arguments, Array)
	if ( typeof qualifier !== "string" ) {
		return jQuery.grep( elements, function( elem ) {
			return ( indexOf.call( qualifier, elem ) > -1 ) !== not;
		} );
	}

	// Filtered directly for both simple and complex selectors
	return jQuery.filter( qualifier, elements, not );
}

jQuery.filter = function( expr, elems, not ) {
	var elem = elems[ 0 ];

	if ( not ) {
		expr = ":not(" + expr + ")";
	}

	if ( elems.length === 1 && elem.nodeType === 1 ) {
		return jQuery.find.matchesSelector( elem, expr ) ? [ elem ] : [];
	}

	return jQuery.find.matches( expr, jQuery.grep( elems, function( elem ) {
		return elem.nodeType === 1;
	} ) );
};

jQuery.fn.extend( {
	find: function( selector ) {
		var i, ret,
			len = this.length,
			self = this;

		if ( typeof selector !== "string" ) {
			return this.pushStack( jQuery( selector ).filter( function() {
				for ( i = 0; i < len; i++ ) {
					if ( jQuery.contains( self[ i ], this ) ) {
						return true;
					}
				}
			} ) );
		}

		ret = this.pushStack( [] );

		for ( i = 0; i < len; i++ ) {
			jQuery.find( selector, self[ i ], ret );
		}

		return len > 1 ? jQuery.uniqueSort( ret ) : ret;
	},
	filter: function( selector ) {
		return this.pushStack( winnow( this, selector || [], false ) );
	},
	not: function( selector ) {
		return this.pushStack( winnow( this, selector || [], true ) );
	},
	is: function( selector ) {
		return !!winnow(
			this,

			// If this is a positional/relative selector, check membership in the returned set
			// so $("p:first").is("p:last") won't return true for a doc with two "p".
			typeof selector === "string" && rneedsContext.test( selector ) ?
				jQuery( selector ) :
				selector || [],
			false
		).length;
	}
} );


// Initialize a jQuery object


// A central reference to the root jQuery(document)
var rootjQuery,

	// A simple way to check for HTML strings
	// Prioritize #id over <tag> to avoid XSS via location.hash (trac-9521)
	// Strict HTML recognition (trac-11290: must start with <)
	// Shortcut simple #id case for speed
	rquickExpr = /^(?:\s*(<[\w\W]+>)[^>]*|#([\w-]+))$/,

	init = jQuery.fn.init = function( selector, context, root ) {
		var match, elem;

		// HANDLE: $(""), $(null), $(undefined), $(false)
		if ( !selector ) {
			return this;
		}

		// Method init() accepts an alternate rootjQuery
		// so migrate can support jQuery.sub (gh-2101)
		root = root || rootjQuery;

		// Handle HTML strings
		if ( typeof selector === "string" ) {
			if ( selector[ 0 ] === "<" &&
				selector[ selector.length - 1 ] === ">" &&
				selector.length >= 3 ) {

				// Assume that strings that start and end with <> are HTML and skip the regex check
				match = [ null, selector, null ];

			} else {
				match = rquickExpr.exec( selector );
			}

			// Match html or make sure no context is specified for #id
			if ( match && ( match[ 1 ] || !context ) ) {

				// HANDLE: $(html) -> $(array)
				if ( match[ 1 ] ) {
					context = context instanceof jQuery ? context[ 0 ] : context;

					// Option to run scripts is true for back-compat
					// Intentionally let the error be thrown if parseHTML is not present
					jQuery.merge( this, jQuery.parseHTML(
						match[ 1 ],
						context && context.nodeType ? context.ownerDocument || context : document,
						true
					) );

					// HANDLE: $(html, props)
					if ( rsingleTag.test( match[ 1 ] ) && jQuery.isPlainObject( context ) ) {
						for ( match in context ) {

							// Properties of context are called as methods if possible
							if ( isFunction( this[ match ] ) ) {
								this[ match ]( context[ match ] );

							// ...and otherwise set as attributes
							} else {
								this.attr( match, context[ match ] );
							}
						}
					}

					return this;

				// HANDLE: $(#id)
				} else {
					elem = document.getElementById( match[ 2 ] );

					if ( elem ) {

						// Inject the element directly into the jQuery object
						this[ 0 ] = elem;
						this.length = 1;
					}
					return this;
				}

			// HANDLE: $(expr, $(...))
			} else if ( !context || context.jquery ) {
				return ( context || root ).find( selector );

			// HANDLE: $(expr, context)
			// (which is just equivalent to: $(context).find(expr)
			} else {
				return this.constructor( context ).find( selector );
			}

		// HANDLE: $(DOMElement)
		} else if ( selector.nodeType ) {
			this[ 0 ] = selector;
			this.length = 1;
			return this;

		// HANDLE: $(function)
		// Shortcut for document ready
		} else if ( isFunction( selector ) ) {
			return root.ready !== undefined ?
				root.ready( selector ) :

				// Execute immediately if ready is not present
				selector( jQuery );
		}

		return jQuery.makeArray( selector, this );
	};

// Give the init function the jQuery prototype for later instantiation
init.prototype = jQuery.fn;

// Initialize central reference
rootjQuery = jQuery( document );


var rparentsprev = /^(?:parents|prev(?:Until|All))/,

	// Methods guaranteed to produce a unique set when starting from a unique set
	guaranteedUnique = {
		children: true,
		contents: true,
		next: true,
		prev: true
	};

jQuery.fn.extend( {
	has: function( target ) {
		var targets = jQuery( target, this ),
			l = targets.length;

		return this.filter( function() {
			var i = 0;
			for ( ; i < l; i++ ) {
				if ( jQuery.contains( this, targets[ i ] ) ) {
					return true;
				}
			}
		} );
	},

	closest: function( selectors, context ) {
		var cur,
			i = 0,
			l = this.length,
			matched = [],
			targets = typeof selectors !== "string" && jQuery( selectors );

		// Positional selectors never match, since there's no _selection_ context
		if ( !rneedsContext.test( selectors ) ) {
			for ( ; i < l; i++ ) {
				for ( cur = this[ i ]; cur && cur !== context; cur = cur.parentNode ) {

					// Always skip document fragments
					if ( cur.nodeType < 11 && ( targets ?
						targets.index( cur ) > -1 :

						// Don't pass non-elements to Sizzle
						cur.nodeType === 1 &&
							jQuery.find.matchesSelector( cur, selectors ) ) ) {

						matched.push( cur );
						break;
					}
				}
			}
		}

		return this.pushStack( matched.length > 1 ? jQuery.uniqueSort( matched ) : matched );
	},

	// Determine the position of an element within the set
	index: function( elem ) {

		// No argument, return index in parent
		if ( !elem ) {
			return ( this[ 0 ] && this[ 0 ].parentNode ) ? this.first().prevAll().length : -1;
		}

		// Index in selector
		if ( typeof elem === "string" ) {
			return indexOf.call( jQuery( elem ), this[ 0 ] );
		}

		// Locate the position of the desired element
		return indexOf.call( this,

			// If it receives a jQuery object, the first element is used
			elem.jquery ? elem[ 0 ] : elem
		);
	},

	add: function( selector, context ) {
		return this.pushStack(
			jQuery.uniqueSort(
				jQuery.merge( this.get(), jQuery( selector, context ) )
			)
		);
	},

	addBack: function( selector ) {
		return this.add( selector == null ?
			this.prevObject : this.prevObject.filter( selector )
		);
	}
} );

function sibling( cur, dir ) {
	while ( ( cur = cur[ dir ] ) && cur.nodeType !== 1 ) {}
	return cur;
}

jQuery.each( {
	parent: function( elem ) {
		var parent = elem.parentNode;
		return parent && parent.nodeType !== 11 ? parent : null;
	},
	parents: function( elem ) {
		return dir( elem, "parentNode" );
	},
	parentsUntil: function( elem, _i, until ) {
		return dir( elem, "parentNode", until );
	},
	next: function( elem ) {
		return sibling( elem, "nextSibling" );
	},
	prev: function( elem ) {
		return sibling( elem, "previousSibling" );
	},
	nextAll: function( elem ) {
		return dir( elem, "nextSibling" );
	},
	prevAll: function( elem ) {
		return dir( elem, "previousSibling" );
	},
	nextUntil: function( elem, _i, until ) {
		return dir( elem, "nextSibling", until );
	},
	prevUntil: function( elem, _i, until ) {
		return dir( elem, "previousSibling", until );
	},
	siblings: function( elem ) {
		return siblings( ( elem.parentNode || {} ).firstChild, elem );
	},
	children: function( elem ) {
		return siblings( elem.firstChild );
	},
	contents: function( elem ) {
		if ( elem.contentDocument != null &&

			// Support: IE 11+
			// <object> elements with no `data` attribute has an object
			// `contentDocument` with a `null` prototype.
			getProto( elem.contentDocument ) ) {

			return elem.contentDocument;
		}

		// Support: IE 9 - 11 only, iOS 7 only, Android Browser <=4.3 only
		// Treat the template element as a regular one in browsers that
		// don't support it.
		if ( nodeName( elem, "template" ) ) {
			elem = elem.content || elem;
		}

		return jQuery.merge( [], elem.childNodes );
	}
}, function( name, fn ) {
	jQuery.fn[ name ] = function( until, selector ) {
		var matched = jQuery.map( this, fn, until );

		if ( name.slice( -5 ) !== "Until" ) {
			selector = until;
		}

		if ( selector && typeof selector === "string" ) {
			matched = jQuery.filter( selector, matched );
		}

		if ( this.length > 1 ) {

			// Remove duplicates
			if ( !guaranteedUnique[ name ] ) {
				jQuery.uniqueSort( matched );
			}

			// Reverse order for parents* and prev-derivatives
			if ( rparentsprev.test( name ) ) {
				matched.reverse();
			}
		}

		return this.pushStack( matched );
	};
} );
var rnothtmlwhite = ( /[^\x20\t\r\n\f]+/g );



// Convert String-formatted options into Object-formatted ones
function createOptions( options ) {
	var object = {};
	jQuery.each( options.match( rnothtmlwhite ) || [], function( _, flag ) {
		object[ flag ] = true;
	} );
	return object;
}

/*
 * Create a callback list using the following parameters:
 *
 *	options: an optional list of space-separated options that will change how
 *			the callback list behaves or a more traditional option object
 *
 * By default a callback list will act like an event callback list and can be
 * "fired" multiple times.
 *
 * Possible options:
 *
 *	once:			will ensure the callback list can only be fired once (like a Deferred)
 *
 *	memory:			will keep track of previous values and will call any callback added
 *					after the list has been fired right away with the latest "memorized"
 *					values (like a Deferred)
 *
 *	unique:			will ensure a callback can only be added once (no duplicate in the list)
 *
 *	stopOnFalse:	interrupt callings when a callback returns false
 *
 */
jQuery.Callbacks = function( options ) {

	// Convert options from String-formatted to Object-formatted if needed
	// (we check in cache first)
	options = typeof options === "string" ?
		createOptions( options ) :
		jQuery.extend( {}, options );

	var // Flag to know if list is currently firing
		firing,

		// Last fire value for non-forgettable lists
		memory,

		// Flag to know if list was already fired
		fired,

		// Flag to prevent firing
		locked,

		// Actual callback list
		list = [],

		// Queue of execution data for repeatable lists
		queue = [],

		// Index of currently firing callback (modified by add/remove as needed)
		firingIndex = -1,

		// Fire callbacks
		fire = function() {

			// Enforce single-firing
			locked = locked || options.once;

			// Execute callbacks for all pending executions,
			// respecting firingIndex overrides and runtime changes
			fired = firing = true;
			for ( ; queue.length; firingIndex = -1 ) {
				memory = queue.shift();
				while ( ++firingIndex < list.length ) {

					// Run callback and check for early termination
					if ( list[ firingIndex ].apply( memory[ 0 ], memory[ 1 ] ) === false &&
						options.stopOnFalse ) {

						// Jump to end and forget the data so .add doesn't re-fire
						firingIndex = list.length;
						memory = false;
					}
				}
			}

			// Forget the data if we're done with it
			if ( !options.memory ) {
				memory = false;
			}

			firing = false;

			// Clean up if we're done firing for good
			if ( locked ) {

				// Keep an empty list if we have data for future add calls
				if ( memory ) {
					list = [];

				// Otherwise, this object is spent
				} else {
					list = "";
				}
			}
		},

		// Actual Callbacks object
		self = {

			// Add a callback or a collection of callbacks to the list
			add: function() {
				if ( list ) {

					// If we have memory from a past run, we should fire after adding
					if ( memory && !firing ) {
						firingIndex = list.length - 1;
						queue.push( memory );
					}

					( function add( args ) {
						jQuery.each( args, function( _, arg ) {
							if ( isFunction( arg ) ) {
								if ( !options.unique || !self.has( arg ) ) {
									list.push( arg );
								}
							} else if ( arg && arg.length && toType( arg ) !== "string" ) {

								// Inspect recursively
								add( arg );
							}
						} );
					} )( arguments );

					if ( memory && !firing ) {
						fire();
					}
				}
				return this;
			},

			// Remove a callback from the list
			remove: function() {
				jQuery.each( arguments, function( _, arg ) {
					var index;
					while ( ( index = jQuery.inArray( arg, list, index ) ) > -1 ) {
						list.splice( index, 1 );

						// Handle firing indexes
						if ( index <= firingIndex ) {
							firingIndex--;
						}
					}
				} );
				return this;
			},

			// Check if a given callback is in the list.
			// If no argument is given, return whether or not list has callbacks attached.
			has: function( fn ) {
				return fn ?
					jQuery.inArray( fn, list ) > -1 :
					list.length > 0;
			},

			// Remove all callbacks from the list
			empty: function() {
				if ( list ) {
					list = [];
				}
				return this;
			},

			// Disable .fire and .add
			// Abort any current/pending executions
			// Clear all callbacks and values
			disable: function() {
				locked = queue = [];
				list = memory = "";
				return this;
			},
			disabled: function() {
				return !list;
			},

			// Disable .fire
			// Also disable .add unless we have memory (since it would have no effect)
			// Abort any pending executions
			lock: function() {
				locked = queue = [];
				if ( !memory && !firing ) {
					list = memory = "";
				}
				return this;
			},
			locked: function() {
				return !!locked;
			},

			// Call all callbacks with the given context and arguments
			fireWith: function( context, args ) {
				if ( !locked ) {
					args = args || [];
					args = [ context, args.slice ? args.slice() : args ];
					queue.push( args );
					if ( !firing ) {
						fire();
					}
				}
				return this;
			},

			// Call all the callbacks with the given arguments
			fire: function() {
				self.fireWith( this, arguments );
				return this;
			},

			// To know if the callbacks have already been called at least once
			fired: function() {
				return !!fired;
			}
		};

	return self;
};


function Identity( v ) {
	return v;
}
function Thrower( ex ) {
	throw ex;
}

function adoptValue( value, resolve, reject, noValue ) {
	var method;

	try {

		// Check for promise aspect first to privilege synchronous behavior
		if ( value && isFunction( ( method = value.promise ) ) ) {
			method.call( value ).done( resolve ).fail( reject );

		// Other thenables
		} else if ( value && isFunction( ( method = value.then ) ) ) {
			method.call( value, resolve, reject );

		// Other non-thenables
		} else {

			// Control `resolve` arguments by letting Array#slice cast boolean `noValue` to integer:
			// * false: [ value ].slice( 0 ) => resolve( value )
			// * true: [ value ].slice( 1 ) => resolve()
			resolve.apply( undefined, [ value ].slice( noValue ) );
		}

	// For Promises/A+, convert exceptions into rejections
	// Since jQuery.when doesn't unwrap thenables, we can skip the extra checks appearing in
	// Deferred#then to conditionally suppress rejection.
	} catch ( value ) {

		// Support: Android 4.0 only
		// Strict mode functions invoked without .call/.apply get global-object context
		reject.apply( undefined, [ value ] );
	}
}

jQuery.extend( {

	Deferred: function( func ) {
		var tuples = [

				// action, add listener, callbacks,
				// ... .then handlers, argument index, [final state]
				[ "notify", "progress", jQuery.Callbacks( "memory" ),
					jQuery.Callbacks( "memory" ), 2 ],
				[ "resolve", "done", jQuery.Callbacks( "once memory" ),
					jQuery.Callbacks( "once memory" ), 0, "resolved" ],
				[ "reject", "fail", jQuery.Callbacks( "once memory" ),
					jQuery.Callbacks( "once memory" ), 1, "rejected" ]
			],
			state = "pending",
			promise = {
				state: function() {
					return state;
				},
				always: function() {
					deferred.done( arguments ).fail( arguments );
					return this;
				},
				"catch": function( fn ) {
					return promise.then( null, fn );
				},

				// Keep pipe for back-compat
				pipe: function( /* fnDone, fnFail, fnProgress */ ) {
					var fns = arguments;

					return jQuery.Deferred( function( newDefer ) {
						jQuery.each( tuples, function( _i, tuple ) {

							// Map tuples (progress, done, fail) to arguments (done, fail, progress)
							var fn = isFunction( fns[ tuple[ 4 ] ] ) && fns[ tuple[ 4 ] ];

							// deferred.progress(function() { bind to newDefer or newDefer.notify })
							// deferred.done(function() { bind to newDefer or newDefer.resolve })
							// deferred.fail(function() { bind to newDefer or newDefer.reject })
							deferred[ tuple[ 1 ] ]( function() {
								var returned = fn && fn.apply( this, arguments );
								if ( returned && isFunction( returned.promise ) ) {
									returned.promise()
										.progress( newDefer.notify )
										.done( newDefer.resolve )
										.fail( newDefer.reject );
								} else {
									newDefer[ tuple[ 0 ] + "With" ](
										this,
										fn ? [ returned ] : arguments
									);
								}
							} );
						} );
						fns = null;
					} ).promise();
				},
				then: function( onFulfilled, onRejected, onProgress ) {
					var maxDepth = 0;
					function resolve( depth, deferred, handler, special ) {
						return function() {
							var that = this,
								args = arguments,
								mightThrow = function() {
									var returned, then;

									// Support: Promises/A+ section 2.3.3.3.3
									// https://promisesaplus.com/#point-59
									// Ignore double-resolution attempts
									if ( depth < maxDepth ) {
										return;
									}

									returned = handler.apply( that, args );

									// Support: Promises/A+ section 2.3.1
									// https://promisesaplus.com/#point-48
									if ( returned === deferred.promise() ) {
										throw new TypeError( "Thenable self-resolution" );
									}

									// Support: Promises/A+ sections 2.3.3.1, 3.5
									// https://promisesaplus.com/#point-54
									// https://promisesaplus.com/#point-75
									// Retrieve `then` only once
									then = returned &&

										// Support: Promises/A+ section 2.3.4
										// https://promisesaplus.com/#point-64
										// Only check objects and functions for thenability
										( typeof returned === "object" ||
											typeof returned === "function" ) &&
										returned.then;

									// Handle a returned thenable
									if ( isFunction( then ) ) {

										// Special processors (notify) just wait for resolution
										if ( special ) {
											then.call(
												returned,
												resolve( maxDepth, deferred, Identity, special ),
												resolve( maxDepth, deferred, Thrower, special )
											);

										// Normal processors (resolve) also hook into progress
										} else {

											// ...and disregard older resolution values
											maxDepth++;

											then.call(
												returned,
												resolve( maxDepth, deferred, Identity, special ),
												resolve( maxDepth, deferred, Thrower, special ),
												resolve( maxDepth, deferred, Identity,
													deferred.notifyWith )
											);
										}

									// Handle all other returned values
									} else {

										// Only substitute handlers pass on context
										// and multiple values (non-spec behavior)
										if ( handler !== Identity ) {
											that = undefined;
											args = [ returned ];
										}

										// Process the value(s)
										// Default process is resolve
										( special || deferred.resolveWith )( that, args );
									}
								},

								// Only normal processors (resolve) catch and reject exceptions
								process = special ?
									mightThrow :
									function() {
										try {
											mightThrow();
										} catch ( e ) {

											if ( jQuery.Deferred.exceptionHook ) {
												jQuery.Deferred.exceptionHook( e,
													process.stackTrace );
											}

											// Support: Promises/A+ section 2.3.3.3.4.1
											// https://promisesaplus.com/#point-61
											// Ignore post-resolution exceptions
											if ( depth + 1 >= maxDepth ) {

												// Only substitute handlers pass on context
												// and multiple values (non-spec behavior)
												if ( handler !== Thrower ) {
													that = undefined;
													args = [ e ];
												}

												deferred.rejectWith( that, args );
											}
										}
									};

							// Support: Promises/A+ section 2.3.3.3.1
							// https://promisesaplus.com/#point-57
							// Re-resolve promises immediately to dodge false rejection from
							// subsequent errors
							if ( depth ) {
								process();
							} else {

								// Call an optional hook to record the stack, in case of exception
								// since it's otherwise lost when execution goes async
								if ( jQuery.Deferred.getStackHook ) {
									process.stackTrace = jQuery.Deferred.getStackHook();
								}
								window.setTimeout( process );
							}
						};
					}

					return jQuery.Deferred( function( newDefer ) {

						// progress_handlers.add( ... )
						tuples[ 0 ][ 3 ].add(
							resolve(
								0,
								newDefer,
								isFunction( onProgress ) ?
									onProgress :
									Identity,
								newDefer.notifyWith
							)
						);

						// fulfilled_handlers.add( ... )
						tuples[ 1 ][ 3 ].add(
							resolve(
								0,
								newDefer,
								isFunction( onFulfilled ) ?
									onFulfilled :
									Identity
							)
						);

						// rejected_handlers.add( ... )
						tuples[ 2 ][ 3 ].add(
							resolve(
								0,
								newDefer,
								isFunction( onRejected ) ?
									onRejected :
									Thrower
							)
						);
					} ).promise();
				},

				// Get a promise for this deferred
				// If obj is provided, the promise aspect is added to the object
				promise: function( obj ) {
					return obj != null ? jQuery.extend( obj, promise ) : promise;
				}
			},
			deferred = {};

		// Add list-specific methods
		jQuery.each( tuples, function( i, tuple ) {
			var list = tuple[ 2 ],
				stateString = tuple[ 5 ];

			// promise.progress = list.add
			// promise.done = list.add
			// promise.fail = list.add
			promise[ tuple[ 1 ] ] = list.add;

			// Handle state
			if ( stateString ) {
				list.add(
					function() {

						// state = "resolved" (i.e., fulfilled)
						// state = "rejected"
						state = stateString;
					},

					// rejected_callbacks.disable
					// fulfilled_callbacks.disable
					tuples[ 3 - i ][ 2 ].disable,

					// rejected_handlers.disable
					// fulfilled_handlers.disable
					tuples[ 3 - i ][ 3 ].disable,

					// progress_callbacks.lock
					tuples[ 0 ][ 2 ].lock,

					// progress_handlers.lock
					tuples[ 0 ][ 3 ].lock
				);
			}

			// progress_handlers.fire
			// fulfilled_handlers.fire
			// rejected_handlers.fire
			list.add( tuple[ 3 ].fire );

			// deferred.notify = function() { deferred.notifyWith(...) }
			// deferred.resolve = function() { deferred.resolveWith(...) }
			// deferred.reject = function() { deferred.rejectWith(...) }
			deferred[ tuple[ 0 ] ] = function() {
				deferred[ tuple[ 0 ] + "With" ]( this === deferred ? undefined : this, arguments );
				return this;
			};

			// deferred.notifyWith = list.fireWith
			// deferred.resolveWith = list.fireWith
			// deferred.rejectWith = list.fireWith
			deferred[ tuple[ 0 ] + "With" ] = list.fireWith;
		} );

		// Make the deferred a promise
		promise.promise( deferred );

		// Call given func if any
		if ( func ) {
			func.call( deferred, deferred );
		}

		// All done!
		return deferred;
	},

	// Deferred helper
	when: function( singleValue ) {
		var

			// count of uncompleted subordinates
			remaining = arguments.length,

			// count of unprocessed arguments
			i = remaining,

			// subordinate fulfillment data
			resolveContexts = Array( i ),
			resolveValues = slice.call( arguments ),

			// the primary Deferred
			primary = jQuery.Deferred(),

			// subordinate callback factory
			updateFunc = function( i ) {
				return function( value ) {
					resolveContexts[ i ] = this;
					resolveValues[ i ] = arguments.length > 1 ? slice.call( arguments ) : value;
					if ( !( --remaining ) ) {
						primary.resolveWith( resolveContexts, resolveValues );
					}
				};
			};

		// Single- and empty arguments are adopted like Promise.resolve
		if ( remaining <= 1 ) {
			adoptValue( singleValue, primary.done( updateFunc( i ) ).resolve, primary.reject,
				!remaining );

			// Use .then() to unwrap secondary thenables (cf. gh-3000)
			if ( primary.state() === "pending" ||
				isFunction( resolveValues[ i ] && resolveValues[ i ].then ) ) {

				return primary.then();
			}
		}

		// Multiple arguments are aggregated like Promise.all array elements
		while ( i-- ) {
			adoptValue( resolveValues[ i ], updateFunc( i ), primary.reject );
		}

		return primary.promise();
	}
} );


// These usually indicate a programmer mistake during development,
// warn about them ASAP rather than swallowing them by default.
var rerrorNames = /^(Eval|Internal|Range|Reference|Syntax|Type|URI)Error$/;

jQuery.Deferred.exceptionHook = function( error, stack ) {

	// Support: IE 8 - 9 only
	// Console exists when dev tools are open, which can happen at any time
	if ( window.console && window.console.warn && error && rerrorNames.test( error.name ) ) {
		window.console.warn( "jQuery.Deferred exception: " + error.message, error.stack, stack );
	}
};




jQuery.readyException = function( error ) {
	window.setTimeout( function() {
		throw error;
	} );
};




// The deferred used on DOM ready
var readyList = jQuery.Deferred();

jQuery.fn.ready = function( fn ) {

	readyList
		.then( fn )

		// Wrap jQuery.readyException in a function so that the lookup
		// happens at the time of error handling instead of callback
		// registration.
		.catch( function( error ) {
			jQuery.readyException( error );
		} );

	return this;
};

jQuery.extend( {

	// Is the DOM ready to be used? Set to true once it occurs.
	isReady: false,

	// A counter to track how many items to wait for before
	// the ready event fires. See trac-6781
	readyWait: 1,

	// Handle when the DOM is ready
	ready: function( wait ) {

		// Abort if there are pending holds or we're already ready
		if ( wait === true ? --jQuery.readyWait : jQuery.isReady ) {
			return;
		}

		// Remember that the DOM is ready
		jQuery.isReady = true;

		// If a normal DOM Ready event fired, decrement, and wait if need be
		if ( wait !== true && --jQuery.readyWait > 0 ) {
			return;
		}

		// If there are functions bound, to execute
		readyList.resolveWith( document, [ jQuery ] );
	}
} );

jQuery.ready.then = readyList.then;

// The ready event handler and self cleanup method
function completed() {
	document.removeEventListener( "DOMContentLoaded", completed );
	window.removeEventListener( "load", completed );
	jQuery.ready();
}

// Catch cases where $(document).ready() is called
// after the browser event has already occurred.
// Support: IE <=9 - 10 only
// Older IE sometimes signals "interactive" too soon
if ( document.readyState === "complete" ||
	( document.readyState !== "loading" && !document.documentElement.doScroll ) ) {

	// Handle it asynchronously to allow scripts the opportunity to delay ready
	window.setTimeout( jQuery.ready );

} else {

	// Use the handy event callback
	document.addEventListener( "DOMContentLoaded", completed );

	// A fallback to window.onload, that will always work
	window.addEventListener( "load", completed );
}




// Multifunctional method to get and set values of a collection
// The value/s can optionally be executed if it's a function
var access = function( elems, fn, key, value, chainable, emptyGet, raw ) {
	var i = 0,
		len = elems.length,
		bulk = key == null;

	// Sets many values
	if ( toType( key ) === "object" ) {
		chainable = true;
		for ( i in key ) {
			access( elems, fn, i, key[ i ], true, emptyGet, raw );
		}

	// Sets one value
	} else if ( value !== undefined ) {
		chainable = true;

		if ( !isFunction( value ) ) {
			raw = true;
		}

		if ( bulk ) {

			// Bulk operations run against the entire set
			if ( raw ) {
				fn.call( elems, value );
				fn = null;

			// ...except when executing function values
			} else {
				bulk = fn;
				fn = function( elem, _key, value ) {
					return bulk.call( jQuery( elem ), value );
				};
			}
		}

		if ( fn ) {
			for ( ; i < len; i++ ) {
				fn(
					elems[ i ], key, raw ?
						value :
						value.call( elems[ i ], i, fn( elems[ i ], key ) )
				);
			}
		}
	}

	if ( chainable ) {
		return elems;
	}

	// Gets
	if ( bulk ) {
		return fn.call( elems );
	}

	return len ? fn( elems[ 0 ], key ) : emptyGet;
};


// Matches dashed string for camelizing
var rmsPrefix = /^-ms-/,
	rdashAlpha = /-([a-z])/g;

// Used by camelCase as callback to replace()
function fcamelCase( _all, letter ) {
	return letter.toUpperCase();
}

// Convert dashed to camelCase; used by the css and data modules
// Support: IE <=9 - 11, Edge 12 - 15
// Microsoft forgot to hump their vendor prefix (trac-9572)
function camelCase( string ) {
	return string.replace( rmsPrefix, "ms-" ).replace( rdashAlpha, fcamelCase );
}
var acceptData = function( owner ) {

	// Accepts only:
	//  - Node
	//    - Node.ELEMENT_NODE
	//    - Node.DOCUMENT_NODE
	//  - Object
	//    - Any
	return owner.nodeType === 1 || owner.nodeType === 9 || !( +owner.nodeType );
};




function Data() {
	this.expando = jQuery.expando + Data.uid++;
}

Data.uid = 1;

Data.prototype = {

	cache: function( owner ) {

		// Check if the owner object already has a cache
		var value = owner[ this.expando ];

		// If not, create one
		if ( !value ) {
			value = {};

			// We can accept data for non-element nodes in modern browsers,
			// but we should not, see trac-8335.
			// Always return an empty object.
			if ( acceptData( owner ) ) {

				// If it is a node unlikely to be stringify-ed or looped over
				// use plain assignment
				if ( owner.nodeType ) {
					owner[ this.expando ] = value;

				// Otherwise secure it in a non-enumerable property
				// configurable must be true to allow the property to be
				// deleted when data is removed
				} else {
					Object.defineProperty( owner, this.expando, {
						value: value,
						configurable: true
					} );
				}
			}
		}

		return value;
	},
	set: function( owner, data, value ) {
		var prop,
			cache = this.cache( owner );

		// Handle: [ owner, key, value ] args
		// Always use camelCase key (gh-2257)
		if ( typeof data === "string" ) {
			cache[ camelCase( data ) ] = value;

		// Handle: [ owner, { properties } ] args
		} else {

			// Copy the properties one-by-one to the cache object
			for ( prop in data ) {
				cache[ camelCase( prop ) ] = data[ prop ];
			}
		}
		return cache;
	},
	get: function( owner, key ) {
		return key === undefined ?
			this.cache( owner ) :

			// Always use camelCase key (gh-2257)
			owner[ this.expando ] && owner[ this.expando ][ camelCase( key ) ];
	},
	access: function( owner, key, value ) {

		// In cases where either:
		//
		//   1. No key was specified
		//   2. A string key was specified, but no value provided
		//
		// Take the "read" path and allow the get method to determine
		// which value to return, respectively either:
		//
		//   1. The entire cache object
		//   2. The data stored at the key
		//
		if ( key === undefined ||
				( ( key && typeof key === "string" ) && value === undefined ) ) {

			return this.get( owner, key );
		}

		// When the key is not a string, or both a key and value
		// are specified, set or extend (existing objects) with either:
		//
		//   1. An object of properties
		//   2. A key and value
		//
		this.set( owner, key, value );

		// Since the "set" path can have two possible entry points
		// return the expected data based on which path was taken[*]
		return value !== undefined ? value : key;
	},
	remove: function( owner, key ) {
		var i,
			cache = owner[ this.expando ];

		if ( cache === undefined ) {
			return;
		}

		if ( key !== undefined ) {

			// Support array or space separated string of keys
			if ( Array.isArray( key ) ) {

				// If key is an array of keys...
				// We always set camelCase keys, so remove that.
				key = key.map( camelCase );
			} else {
				key = camelCase( key );

				// If a key with the spaces exists, use it.
				// Otherwise, create an array by matching non-whitespace
				key = key in cache ?
					[ key ] :
					( key.match( rnothtmlwhite ) || [] );
			}

			i = key.length;

			while ( i-- ) {
				delete cache[ key[ i ] ];
			}
		}

		// Remove the expando if there's no more data
		if ( key === undefined || jQuery.isEmptyObject( cache ) ) {

			// Support: Chrome <=35 - 45
			// Webkit & Blink performance suffers when deleting properties
			// from DOM nodes, so set to undefined instead
			// https://bugs.chromium.org/p/chromium/issues/detail?id=378607 (bug restricted)
			if ( owner.nodeType ) {
				owner[ this.expando ] = undefined;
			} else {
				delete owner[ this.expando ];
			}
		}
	},
	hasData: function( owner ) {
		var cache = owner[ this.expando ];
		return cache !== undefined && !jQuery.isEmptyObject( cache );
	}
};
var dataPriv = new Data();

var dataUser = new Data();



//	Implementation Summary
//
//	1. Enforce API surface and semantic compatibility with 1.9.x branch
//	2. Improve the module's maintainability by reducing the storage
//		paths to a single mechanism.
//	3. Use the same single mechanism to support "private" and "user" data.
//	4. _Never_ expose "private" data to user code (TODO: Drop _data, _removeData)
//	5. Avoid exposing implementation details on user objects (eg. expando properties)
//	6. Provide a clear path for implementation upgrade to WeakMap in 2014

var rbrace = /^(?:\{[\w\W]*\}|\[[\w\W]*\])$/,
	rmultiDash = /[A-Z]/g;

function getData( data ) {
	if ( data === "true" ) {
		return true;
	}

	if ( data === "false" ) {
		return false;
	}

	if ( data === "null" ) {
		return null;
	}

	// Only convert to a number if it doesn't change the string
	if ( data === +data + "" ) {
		return +data;
	}

	if ( rbrace.test( data ) ) {
		return JSON.parse( data );
	}

	return data;
}

function dataAttr( elem, key, data ) {
	var name;

	// If nothing was found internally, try to fetch any
	// data from the HTML5 data-* attribute
	if ( data === undefined && elem.nodeType === 1 ) {
		name = "data-" + key.replace( rmultiDash, "-$&" ).toLowerCase();
		data = elem.getAttribute( name );

		if ( typeof data === "string" ) {
			try {
				data = getData( data );
			} catch ( e ) {}

			// Make sure we set the data so it isn't changed later
			dataUser.set( elem, key, data );
		} else {
			data = undefined;
		}
	}
	return data;
}

jQuery.extend( {
	hasData: function( elem ) {
		return dataUser.hasData( elem ) || dataPriv.hasData( elem );
	},

	data: function( elem, name, data ) {
		return dataUser.access( elem, name, data );
	},

	removeData: function( elem, name ) {
		dataUser.remove( elem, name );
	},

	// TODO: Now that all calls to _data and _removeData have been replaced
	// with direct calls to dataPriv methods, these can be deprecated.
	_data: function( elem, name, data ) {
		return dataPriv.access( elem, name, data );
	},

	_removeData: function( elem, name ) {
		dataPriv.remove( elem, name );
	}
} );

jQuery.fn.extend( {
	data: function( key, value ) {
		var i, name, data,
			elem = this[ 0 ],
			attrs = elem && elem.attributes;

		// Gets all values
		if ( key === undefined ) {
			if ( this.length ) {
				data = dataUser.get( elem );

				if ( elem.nodeType === 1 && !dataPriv.get( elem, "hasDataAttrs" ) ) {
					i = attrs.length;
					while ( i-- ) {

						// Support: IE 11 only
						// The attrs elements can be null (trac-14894)
						if ( attrs[ i ] ) {
							name = attrs[ i ].name;
							if ( name.indexOf( "data-" ) === 0 ) {
								name = camelCase( name.slice( 5 ) );
								dataAttr( elem, name, data[ name ] );
							}
						}
					}
					dataPriv.set( elem, "hasDataAttrs", true );
				}
			}

			return data;
		}

		// Sets multiple values
		if ( typeof key === "object" ) {
			return this.each( function() {
				dataUser.set( this, key );
			} );
		}

		return access( this, function( value ) {
			var data;

			// The calling jQuery object (element matches) is not empty
			// (and therefore has an element appears at this[ 0 ]) and the
			// `value` parameter was not undefined. An empty jQuery object
			// will result in `undefined` for elem = this[ 0 ] which will
			// throw an exception if an attempt to read a data cache is made.
			if ( elem && value === undefined ) {

				// Attempt to get data from the cache
				// The key will always be camelCased in Data
				data = dataUser.get( elem, key );
				if ( data !== undefined ) {
					return data;
				}

				// Attempt to "discover" the data in
				// HTML5 custom data-* attrs
				data = dataAttr( elem, key );
				if ( data !== undefined ) {
					return data;
				}

				// We tried really hard, but the data doesn't exist.
				return;
			}

			// Set the data...
			this.each( function() {

				// We always store the camelCased key
				dataUser.set( this, key, value );
			} );
		}, null, value, arguments.length > 1, null, true );
	},

	removeData: function( key ) {
		return this.each( function() {
			dataUser.remove( this, key );
		} );
	}
} );


jQuery.extend( {
	queue: function( elem, type, data ) {
		var queue;

		if ( elem ) {
			type = ( type || "fx" ) + "queue";
			queue = dataPriv.get( elem, type );

			// Speed up dequeue by getting out quickly if this is just a lookup
			if ( data ) {
				if ( !queue || Array.isArray( data ) ) {
					queue = dataPriv.access( elem, type, jQuery.makeArray( data ) );
				} else {
					queue.push( data );
				}
			}
			return queue || [];
		}
	},

	dequeue: function( elem, type ) {
		type = type || "fx";

		var queue = jQuery.queue( elem, type ),
			startLength = queue.length,
			fn = queue.shift(),
			hooks = jQuery._queueHooks( elem, type ),
			next = function() {
				jQuery.dequeue( elem, type );
			};

		// If the fx queue is dequeued, always remove the progress sentinel
		if ( fn === "inprogress" ) {
			fn = queue.shift();
			startLength--;
		}

		if ( fn ) {

			// Add a progress sentinel to prevent the fx queue from being
			// automatically dequeued
			if ( type === "fx" ) {
				queue.unshift( "inprogress" );
			}

			// Clear up the last queue stop function
			delete hooks.stop;
			fn.call( elem, next, hooks );
		}

		if ( !startLength && hooks ) {
			hooks.empty.fire();
		}
	},

	// Not public - generate a queueHooks object, or return the current one
	_queueHooks: function( elem, type ) {
		var key = type + "queueHooks";
		return dataPriv.get( elem, key ) || dataPriv.access( elem, key, {
			empty: jQuery.Callbacks( "once memory" ).add( function() {
				dataPriv.remove( elem, [ type + "queue", key ] );
			} )
		} );
	}
} );

jQuery.fn.extend( {
	queue: function( type, data ) {
		var setter = 2;

		if ( typeof type !== "string" ) {
			data = type;
			type = "fx";
			setter--;
		}

		if ( arguments.length < setter ) {
			return jQuery.queue( this[ 0 ], type );
		}

		return data === undefined ?
			this :
			this.each( function() {
				var queue = jQuery.queue( this, type, data );

				// Ensure a hooks for this queue
				jQuery._queueHooks( this, type );

				if ( type === "fx" && queue[ 0 ] !== "inprogress" ) {
					jQuery.dequeue( this, type );
				}
			} );
	},
	dequeue: function( type ) {
		return this.each( function() {
			jQuery.dequeue( this, type );
		} );
	},
	clearQueue: function( type ) {
		return this.queue( type || "fx", [] );
	},

	// Get a promise resolved when queues of a certain type
	// are emptied (fx is the type by default)
	promise: function( type, obj ) {
		var tmp,
			count = 1,
			defer = jQuery.Deferred(),
			elements = this,
			i = this.length,
			resolve = function() {
				if ( !( --count ) ) {
					defer.resolveWith( elements, [ elements ] );
				}
			};

		if ( typeof type !== "string" ) {
			obj = type;
			type = undefined;
		}
		type = type || "fx";

		while ( i-- ) {
			tmp = dataPriv.get( elements[ i ], type + "queueHooks" );
			if ( tmp && tmp.empty ) {
				count++;
				tmp.empty.add( resolve );
			}
		}
		resolve();
		return defer.promise( obj );
	}
} );
var pnum = ( /[+-]?(?:\d*\.|)\d+(?:[eE][+-]?\d+|)/ ).source;

var rcssNum = new RegExp( "^(?:([+-])=|)(" + pnum + ")([a-z%]*)$", "i" );


var cssExpand = [ "Top", "Right", "Bottom", "Left" ];

var documentElement = document.documentElement;



	var isAttached = function( elem ) {
			return jQuery.contains( elem.ownerDocument, elem );
		},
		composed = { composed: true };

	// Support: IE 9 - 11+, Edge 12 - 18+, iOS 10.0 - 10.2 only
	// Check attachment across shadow DOM boundaries when possible (gh-3504)
	// Support: iOS 10.0-10.2 only
	// Early iOS 10 versions support `attachShadow` but not `getRootNode`,
	// leading to errors. We need to check for `getRootNode`.
	if ( documentElement.getRootNode ) {
		isAttached = function( elem ) {
			return jQuery.contains( elem.ownerDocument, elem ) ||
				elem.getRootNode( composed ) === elem.ownerDocument;
		};
	}
var isHiddenWithinTree = function( elem, el ) {

		// isHiddenWithinTree might be called from jQuery#filter function;
		// in that case, element will be second argument
		elem = el || elem;

		// Inline style trumps all
		return elem.style.display === "none" ||
			elem.style.display === "" &&

			// Otherwise, check computed style
			// Support: Firefox <=43 - 45
			// Disconnected elements can have computed display: none, so first confirm that elem is
			// in the document.
			isAttached( elem ) &&

			jQuery.css( elem, "display" ) === "none";
	};



function adjustCSS( elem, prop, valueParts, tween ) {
	var adjusted, scale,
		maxIterations = 20,
		currentValue = tween ?
			function() {
				return tween.cur();
			} :
			function() {
				return jQuery.css( elem, prop, "" );
			},
		initial = currentValue(),
		unit = valueParts && valueParts[ 3 ] || ( jQuery.cssNumber[ prop ] ? "" : "px" ),

		// Starting value computation is required for potential unit mismatches
		initialInUnit = elem.nodeType &&
			( jQuery.cssNumber[ prop ] || unit !== "px" && +initial ) &&
			rcssNum.exec( jQuery.css( elem, prop ) );

	if ( initialInUnit && initialInUnit[ 3 ] !== unit ) {

		// Support: Firefox <=54
		// Halve the iteration target value to prevent interference from CSS upper bounds (gh-2144)
		initial = initial / 2;

		// Trust units reported by jQuery.css
		unit = unit || initialInUnit[ 3 ];

		// Iteratively approximate from a nonzero starting point
		initialInUnit = +initial || 1;

		while ( maxIterations-- ) {

			// Evaluate and update our best guess (doubling guesses that zero out).
			// Finish if the scale equals or crosses 1 (making the old*new product non-positive).
			jQuery.style( elem, prop, initialInUnit + unit );
			if ( ( 1 - scale ) * ( 1 - ( scale = currentValue() / initial || 0.5 ) ) <= 0 ) {
				maxIterations = 0;
			}
			initialInUnit = initialInUnit / scale;

		}

		initialInUnit = initialInUnit * 2;
		jQuery.style( elem, prop, initialInUnit + unit );

		// Make sure we update the tween properties later on
		valueParts = valueParts || [];
	}

	if ( valueParts ) {
		initialInUnit = +initialInUnit || +initial || 0;

		// Apply relative offset (+=/-=) if specified
		adjusted = valueParts[ 1 ] ?
			initialInUnit + ( valueParts[ 1 ] + 1 ) * valueParts[ 2 ] :
			+valueParts[ 2 ];
		if ( tween ) {
			tween.unit = unit;
			tween.start = initialInUnit;
			tween.end = adjusted;
		}
	}
	return adjusted;
}


var defaultDisplayMap = {};

function getDefaultDisplay( elem ) {
	var temp,
		doc = elem.ownerDocument,
		nodeName = elem.nodeName,
		display = defaultDisplayMap[ nodeName ];

	if ( display ) {
		return display;
	}

	temp = doc.body.appendChild( doc.createElement( nodeName ) );
	display = jQuery.css( temp, "display" );

	temp.parentNode.removeChild( temp );

	if ( display === "none" ) {
		display = "block";
	}
	defaultDisplayMap[ nodeName ] = display;

	return display;
}

function showHide( elements, show ) {
	var display, elem,
		values = [],
		index = 0,
		length = elements.length;

	// Determine new display value for elements that need to change
	for ( ; index < length; index++ ) {
		elem = elements[ index ];
		if ( !elem.style ) {
			continue;
		}

		display = elem.style.display;
		if ( show ) {

			// Since we force visibility upon cascade-hidden elements, an immediate (and slow)
			// check is required in this first loop unless we have a nonempty display value (either
			// inline or about-to-be-restored)
			if ( display === "none" ) {
				values[ index ] = dataPriv.get( elem, "display" ) || null;
				if ( !values[ index ] ) {
					elem.style.display = "";
				}
			}
			if ( elem.style.display === "" && isHiddenWithinTree( elem ) ) {
				values[ index ] = getDefaultDisplay( elem );
			}
		} else {
			if ( display !== "none" ) {
				values[ index ] = "none";

				// Remember what we're overwriting
				dataPriv.set( elem, "display", display );
			}
		}
	}

	// Set the display of the elements in a second loop to avoid constant reflow
	for ( index = 0; index < length; index++ ) {
		if ( values[ index ] != null ) {
			elements[ index ].style.display = values[ index ];
		}
	}

	return elements;
}

jQuery.fn.extend( {
	show: function() {
		return showHide( this, true );
	},
	hide: function() {
		return showHide( this );
	},
	toggle: function( state ) {
		if ( typeof state === "boolean" ) {
			return state ? this.show() : this.hide();
		}

		return this.each( function() {
			if ( isHiddenWithinTree( this ) ) {
				jQuery( this ).show();
			} else {
				jQuery( this ).hide();
			}
		} );
	}
} );
var rcheckableType = ( /^(?:checkbox|radio)$/i );

var rtagName = ( /<([a-z][^\/\0>\x20\t\r\n\f]*)/i );

var rscriptType = ( /^$|^module$|\/(?:java|ecma)script/i );



( function() {
	var fragment = document.createDocumentFragment(),
		div = fragment.appendChild( document.createElement( "div" ) ),
		input = document.createElement( "input" );

	// Support: Android 4.0 - 4.3 only
	// Check state lost if the name is set (trac-11217)
	// Support: Windows Web Apps (WWA)
	// `name` and `type` must use .setAttribute for WWA (trac-14901)
	input.setAttribute( "type", "radio" );
	input.setAttribute( "checked", "checked" );
	input.setAttribute( "name", "t" );

	div.appendChild( input );

	// Support: Android <=4.1 only
	// Older WebKit doesn't clone checked state correctly in fragments
	support.checkClone = div.cloneNode( true ).cloneNode( true ).lastChild.checked;

	// Support: IE <=11 only
	// Make sure textarea (and checkbox) defaultValue is properly cloned
	div.innerHTML = "<textarea>x</textarea>";
	support.noCloneChecked = !!div.cloneNode( true ).lastChild.defaultValue;

	// Support: IE <=9 only
	// IE <=9 replaces <option> tags with their contents when inserted outside of
	// the select element.
	div.innerHTML = "<option></option>";
	support.option = !!div.lastChild;
} )();


// We have to close these tags to support XHTML (trac-13200)
var wrapMap = {

	// XHTML parsers do not magically insert elements in the
	// same way that tag soup parsers do. So we cannot shorten
	// this by omitting <tbody> or other required elements.
	thead: [ 1, "<table>", "</table>" ],
	col: [ 2, "<table><colgroup>", "</colgroup></table>" ],
	tr: [ 2, "<table><tbody>", "</tbody></table>" ],
	td: [ 3, "<table><tbody><tr>", "</tr></tbody></table>" ],

	_default: [ 0, "", "" ]
};

wrapMap.tbody = wrapMap.tfoot = wrapMap.colgroup = wrapMap.caption = wrapMap.thead;
wrapMap.th = wrapMap.td;

// Support: IE <=9 only
if ( !support.option ) {
	wrapMap.optgroup = wrapMap.option = [ 1, "<select multiple='multiple'>", "</select>" ];
}


function getAll( context, tag ) {

	// Support: IE <=9 - 11 only
	// Use typeof to avoid zero-argument method invocation on host objects (trac-15151)
	var ret;

	if ( typeof context.getElementsByTagName !== "undefined" ) {
		ret = context.getElementsByTagName( tag || "*" );

	} else if ( typeof context.querySelectorAll !== "undefined" ) {
		ret = context.querySelectorAll( tag || "*" );

	} else {
		ret = [];
	}

	if ( tag === undefined || tag && nodeName( context, tag ) ) {
		return jQuery.merge( [ context ], ret );
	}

	return ret;
}


// Mark scripts as having already been evaluated
function setGlobalEval( elems, refElements ) {
	var i = 0,
		l = elems.length;

	for ( ; i < l; i++ ) {
		dataPriv.set(
			elems[ i ],
			"globalEval",
			!refElements || dataPriv.get( refElements[ i ], "globalEval" )
		);
	}
}


var rhtml = /<|&#?\w+;/;

function buildFragment( elems, context, scripts, selection, ignored ) {
	var elem, tmp, tag, wrap, attached, j,
		fragment = context.createDocumentFragment(),
		nodes = [],
		i = 0,
		l = elems.length;

	for ( ; i < l; i++ ) {
		elem = elems[ i ];

		if ( elem || elem === 0 ) {

			// Add nodes directly
			if ( toType( elem ) === "object" ) {

				// Support: Android <=4.0 only, PhantomJS 1 only
				// push.apply(_, arraylike) throws on ancient WebKit
				jQuery.merge( nodes, elem.nodeType ? [ elem ] : elem );

			// Convert non-html into a text node
			} else if ( !rhtml.test( elem ) ) {
				nodes.push( context.createTextNode( elem ) );

			// Convert html into DOM nodes
			} else {
				tmp = tmp || fragment.appendChild( context.createElement( "div" ) );

				// Deserialize a standard representation
				tag = ( rtagName.exec( elem ) || [ "", "" ] )[ 1 ].toLowerCase();
				wrap = wrapMap[ tag ] || wrapMap._default;
				tmp.innerHTML = wrap[ 1 ] + jQuery.htmlPrefilter( elem ) + wrap[ 2 ];

				// Descend through wrappers to the right content
				j = wrap[ 0 ];
				while ( j-- ) {
					tmp = tmp.lastChild;
				}

				// Support: Android <=4.0 only, PhantomJS 1 only
				// push.apply(_, arraylike) throws on ancient WebKit
				jQuery.merge( nodes, tmp.childNodes );

				// Remember the top-level container
				tmp = fragment.firstChild;

				// Ensure the created nodes are orphaned (trac-12392)
				tmp.textContent = "";
			}
		}
	}

	// Remove wrapper from fragment
	fragment.textContent = "";

	i = 0;
	while ( ( elem = nodes[ i++ ] ) ) {

		// Skip elements already in the context collection (trac-4087)
		if ( selection && jQuery.inArray( elem, selection ) > -1 ) {
			if ( ignored ) {
				ignored.push( elem );
			}
			continue;
		}

		attached = isAttached( elem );

		// Append to fragment
		tmp = getAll( fragment.appendChild( elem ), "script" );

		// Preserve script evaluation history
		if ( attached ) {
			setGlobalEval( tmp );
		}

		// Capture executables
		if ( scripts ) {
			j = 0;
			while ( ( elem = tmp[ j++ ] ) ) {
				if ( rscriptType.test( elem.type || "" ) ) {
					scripts.push( elem );
				}
			}
		}
	}

	return fragment;
}


var rtypenamespace = /^([^.]*)(?:\.(.+)|)/;

function returnTrue() {
	return true;
}

function returnFalse() {
	return false;
}

// Support: IE <=9 - 11+
// focus() and blur() are asynchronous, except when they are no-op.
// So expect focus to be synchronous when the element is already active,
// and blur to be synchronous when the element is not already active.
// (focus and blur are always synchronous in other supported browsers,
// this just defines when we can count on it).
function expectSync( elem, type ) {
	return ( elem === safeActiveElement() ) === ( type === "focus" );
}

// Support: IE <=9 only
// Accessing document.activeElement can throw unexpectedly
// https://bugs.jquery.com/ticket/13393
function safeActiveElement() {
	try {
		return document.activeElement;
	} catch ( err ) { }
}

function on( elem, types, selector, data, fn, one ) {
	var origFn, type;

	// Types can be a map of types/handlers
	if ( typeof types === "object" ) {

		// ( types-Object, selector, data )
		if ( typeof selector !== "string" ) {

			// ( types-Object, data )
			data = data || selector;
			selector = undefined;
		}
		for ( type in types ) {
			on( elem, type, selector, data, types[ type ], one );
		}
		return elem;
	}

	if ( data == null && fn == null ) {

		// ( types, fn )
		fn = selector;
		data = selector = undefined;
	} else if ( fn == null ) {
		if ( typeof selector === "string" ) {

			// ( types, selector, fn )
			fn = data;
			data = undefined;
		} else {

			// ( types, data, fn )
			fn = data;
			data = selector;
			selector = undefined;
		}
	}
	if ( fn === false ) {
		fn = returnFalse;
	} else if ( !fn ) {
		return elem;
	}

	if ( one === 1 ) {
		origFn = fn;
		fn = function( event ) {

			// Can use an empty set, since event contains the info
			jQuery().off( event );
			return origFn.apply( this, arguments );
		};

		// Use same guid so caller can remove using origFn
		fn.guid = origFn.guid || ( origFn.guid = jQuery.guid++ );
	}
	return elem.each( function() {
		jQuery.event.add( this, types, fn, data, selector );
	} );
}

/*
 * Helper functions for managing events -- not part of the public interface.
 * Props to Dean Edwards' addEvent library for many of the ideas.
 */
jQuery.event = {

	global: {},

	add: function( elem, types, handler, data, selector ) {

		var handleObjIn, eventHandle, tmp,
			events, t, handleObj,
			special, handlers, type, namespaces, origType,
			elemData = dataPriv.get( elem );

		// Only attach events to objects that accept data
		if ( !acceptData( elem ) ) {
			return;
		}

		// Caller can pass in an object of custom data in lieu of the handler
		if ( handler.handler ) {
			handleObjIn = handler;
			handler = handleObjIn.handler;
			selector = handleObjIn.selector;
		}

		// Ensure that invalid selectors throw exceptions at attach time
		// Evaluate against documentElement in case elem is a non-element node (e.g., document)
		if ( selector ) {
			jQuery.find.matchesSelector( documentElement, selector );
		}

		// Make sure that the handler has a unique ID, used to find/remove it later
		if ( !handler.guid ) {
			handler.guid = jQuery.guid++;
		}

		// Init the element's event structure and main handler, if this is the first
		if ( !( events = elemData.events ) ) {
			events = elemData.events = Object.create( null );
		}
		if ( !( eventHandle = elemData.handle ) ) {
			eventHandle = elemData.handle = function( e ) {

				// Discard the second event of a jQuery.event.trigger() and
				// when an event is called after a page has unloaded
				return typeof jQuery !== "undefined" && jQuery.event.triggered !== e.type ?
					jQuery.event.dispatch.apply( elem, arguments ) : undefined;
			};
		}

		// Handle multiple events separated by a space
		types = ( types || "" ).match( rnothtmlwhite ) || [ "" ];
		t = types.length;
		while ( t-- ) {
			tmp = rtypenamespace.exec( types[ t ] ) || [];
			type = origType = tmp[ 1 ];
			namespaces = ( tmp[ 2 ] || "" ).split( "." ).sort();

			// There *must* be a type, no attaching namespace-only handlers
			if ( !type ) {
				continue;
			}

			// If event changes its type, use the special event handlers for the changed type
			special = jQuery.event.special[ type ] || {};

			// If selector defined, determine special event api type, otherwise given type
			type = ( selector ? special.delegateType : special.bindType ) || type;

			// Update special based on newly reset type
			special = jQuery.event.special[ type ] || {};

			// handleObj is passed to all event handlers
			handleObj = jQuery.extend( {
				type: type,
				origType: origType,
				data: data,
				handler: handler,
				guid: handler.guid,
				selector: selector,
				needsContext: selector && jQuery.expr.match.needsContext.test( selector ),
				namespace: namespaces.join( "." )
			}, handleObjIn );

			// Init the event handler queue if we're the first
			if ( !( handlers = events[ type ] ) ) {
				handlers = events[ type ] = [];
				handlers.delegateCount = 0;

				// Only use addEventListener if the special events handler returns false
				if ( !special.setup ||
					special.setup.call( elem, data, namespaces, eventHandle ) === false ) {

					if ( elem.addEventListener ) {
						elem.addEventListener( type, eventHandle );
					}
				}
			}

			if ( special.add ) {
				special.add.call( elem, handleObj );

				if ( !handleObj.handler.guid ) {
					handleObj.handler.guid = handler.guid;
				}
			}

			// Add to the element's handler list, delegates in front
			if ( selector ) {
				handlers.splice( handlers.delegateCount++, 0, handleObj );
			} else {
				handlers.push( handleObj );
			}

			// Keep track of which events have ever been used, for event optimization
			jQuery.event.global[ type ] = true;
		}

	},

	// Detach an event or set of events from an element
	remove: function( elem, types, handler, selector, mappedTypes ) {

		var j, origCount, tmp,
			events, t, handleObj,
			special, handlers, type, namespaces, origType,
			elemData = dataPriv.hasData( elem ) && dataPriv.get( elem );

		if ( !elemData || !( events = elemData.events ) ) {
			return;
		}

		// Once for each type.namespace in types; type may be omitted
		types = ( types || "" ).match( rnothtmlwhite ) || [ "" ];
		t = types.length;
		while ( t-- ) {
			tmp = rtypenamespace.exec( types[ t ] ) || [];
			type = origType = tmp[ 1 ];
			namespaces = ( tmp[ 2 ] || "" ).split( "." ).sort();

			// Unbind all events (on this namespace, if provided) for the element
			if ( !type ) {
				for ( type in events ) {
					jQuery.event.remove( elem, type + types[ t ], handler, selector, true );
				}
				continue;
			}

			special = jQuery.event.special[ type ] || {};
			type = ( selector ? special.delegateType : special.bindType ) || type;
			handlers = events[ type ] || [];
			tmp = tmp[ 2 ] &&
				new RegExp( "(^|\\.)" + namespaces.join( "\\.(?:.*\\.|)" ) + "(\\.|$)" );

			// Remove matching events
			origCount = j = handlers.length;
			while ( j-- ) {
				handleObj = handlers[ j ];

				if ( ( mappedTypes || origType === handleObj.origType ) &&
					( !handler || handler.guid === handleObj.guid ) &&
					( !tmp || tmp.test( handleObj.namespace ) ) &&
					( !selector || selector === handleObj.selector ||
						selector === "**" && handleObj.selector ) ) {
					handlers.splice( j, 1 );

					if ( handleObj.selector ) {
						handlers.delegateCount--;
					}
					if ( special.remove ) {
						special.remove.call( elem, handleObj );
					}
				}
			}

			// Remove generic event handler if we removed something and no more handlers exist
			// (avoids potential for endless recursion during removal of special event handlers)
			if ( origCount && !handlers.length ) {
				if ( !special.teardown ||
					special.teardown.call( elem, namespaces, elemData.handle ) === false ) {

					jQuery.removeEvent( elem, type, elemData.handle );
				}

				delete events[ type ];
			}
		}

		// Remove data and the expando if it's no longer used
		if ( jQuery.isEmptyObject( events ) ) {
			dataPriv.remove( elem, "handle events" );
		}
	},

	dispatch: function( nativeEvent ) {

		var i, j, ret, matched, handleObj, handlerQueue,
			args = new Array( arguments.length ),

			// Make a writable jQuery.Event from the native event object
			event = jQuery.event.fix( nativeEvent ),

			handlers = (
				dataPriv.get( this, "events" ) || Object.create( null )
			)[ event.type ] || [],
			special = jQuery.event.special[ event.type ] || {};

		// Use the fix-ed jQuery.Event rather than the (read-only) native event
		args[ 0 ] = event;

		for ( i = 1; i < arguments.length; i++ ) {
			args[ i ] = arguments[ i ];
		}

		event.delegateTarget = this;

		// Call the preDispatch hook for the mapped type, and let it bail if desired
		if ( special.preDispatch && special.preDispatch.call( this, event ) === false ) {
			return;
		}

		// Determine handlers
		handlerQueue = jQuery.event.handlers.call( this, event, handlers );

		// Run delegates first; they may want to stop propagation beneath us
		i = 0;
		while ( ( matched = handlerQueue[ i++ ] ) && !event.isPropagationStopped() ) {
			event.currentTarget = matched.elem;

			j = 0;
			while ( ( handleObj = matched.handlers[ j++ ] ) &&
				!event.isImmediatePropagationStopped() ) {

				// If the event is namespaced, then each handler is only invoked if it is
				// specially universal or its namespaces are a superset of the event's.
				if ( !event.rnamespace || handleObj.namespace === false ||
					event.rnamespace.test( handleObj.namespace ) ) {

					event.handleObj = handleObj;
					event.data = handleObj.data;

					ret = ( ( jQuery.event.special[ handleObj.origType ] || {} ).handle ||
						handleObj.handler ).apply( matched.elem, args );

					if ( ret !== undefined ) {
						if ( ( event.result = ret ) === false ) {
							event.preventDefault();
							event.stopPropagation();
						}
					}
				}
			}
		}

		// Call the postDispatch hook for the mapped type
		if ( special.postDispatch ) {
			special.postDispatch.call( this, event );
		}

		return event.result;
	},

	handlers: function( event, handlers ) {
		var i, handleObj, sel, matchedHandlers, matchedSelectors,
			handlerQueue = [],
			delegateCount = handlers.delegateCount,
			cur = event.target;

		// Find delegate handlers
		if ( delegateCount &&

			// Support: IE <=9
			// Black-hole SVG <use> instance trees (trac-13180)
			cur.nodeType &&

			// Support: Firefox <=42
			// Suppress spec-violating clicks indicating a non-primary pointer button (trac-3861)
			// https://www.w3.org/TR/DOM-Level-3-Events/#event-type-click
			// Support: IE 11 only
			// ...but not arrow key "clicks" of radio inputs, which can have `button` -1 (gh-2343)
			!( event.type === "click" && event.button >= 1 ) ) {

			for ( ; cur !== this; cur = cur.parentNode || this ) {

				// Don't check non-elements (trac-13208)
				// Don't process clicks on disabled elements (trac-6911, trac-8165, trac-11382, trac-11764)
				if ( cur.nodeType === 1 && !( event.type === "click" && cur.disabled === true ) ) {
					matchedHandlers = [];
					matchedSelectors = {};
					for ( i = 0; i < delegateCount; i++ ) {
						handleObj = handlers[ i ];

						// Don't conflict with Object.prototype properties (trac-13203)
						sel = handleObj.selector + " ";

						if ( matchedSelectors[ sel ] === undefined ) {
							matchedSelectors[ sel ] = handleObj.needsContext ?
								jQuery( sel, this ).index( cur ) > -1 :
								jQuery.find( sel, this, null, [ cur ] ).length;
						}
						if ( matchedSelectors[ sel ] ) {
							matchedHandlers.push( handleObj );
						}
					}
					if ( matchedHandlers.length ) {
						handlerQueue.push( { elem: cur, handlers: matchedHandlers } );
					}
				}
			}
		}

		// Add the remaining (directly-bound) handlers
		cur = this;
		if ( delegateCount < handlers.length ) {
			handlerQueue.push( { elem: cur, handlers: handlers.slice( delegateCount ) } );
		}

		return handlerQueue;
	},

	addProp: function( name, hook ) {
		Object.defineProperty( jQuery.Event.prototype, name, {
			enumerable: true,
			configurable: true,

			get: isFunction( hook ) ?
				function() {
					if ( this.originalEvent ) {
						return hook( this.originalEvent );
					}
				} :
				function() {
					if ( this.originalEvent ) {
						return this.originalEvent[ name ];
					}
				},

			set: function( value ) {
				Object.defineProperty( this, name, {
					enumerable: true,
					configurable: true,
					writable: true,
					value: value
				} );
			}
		} );
	},

	fix: function( originalEvent ) {
		return originalEvent[ jQuery.expando ] ?
			originalEvent :
			new jQuery.Event( originalEvent );
	},

	special: {
		load: {

			// Prevent triggered image.load events from bubbling to window.load
			noBubble: true
		},
		click: {

			// Utilize native event to ensure correct state for checkable inputs
			setup: function( data ) {

				// For mutual compressibility with _default, replace `this` access with a local var.
				// `|| data` is dead code meant only to preserve the variable through minification.
				var el = this || data;

				// Claim the first handler
				if ( rcheckableType.test( el.type ) &&
					el.click && nodeName( el, "input" ) ) {

					// dataPriv.set( el, "click", ... )
					leverageNative( el, "click", returnTrue );
				}

				// Return false to allow normal processing in the caller
				return false;
			},
			trigger: function( data ) {

				// For mutual compressibility with _default, replace `this` access with a local var.
				// `|| data` is dead code meant only to preserve the variable through minification.
				var el = this || data;

				// Force setup before triggering a click
				if ( rcheckableType.test( el.type ) &&
					el.click && nodeName( el, "input" ) ) {

					leverageNative( el, "click" );
				}

				// Return non-false to allow normal event-path propagation
				return true;
			},

			// For cross-browser consistency, suppress native .click() on links
			// Also prevent it if we're currently inside a leveraged native-event stack
			_default: function( event ) {
				var target = event.target;
				return rcheckableType.test( target.type ) &&
					target.click && nodeName( target, "input" ) &&
					dataPriv.get( target, "click" ) ||
					nodeName( target, "a" );
			}
		},

		beforeunload: {
			postDispatch: function( event ) {

				// Support: Firefox 20+
				// Firefox doesn't alert if the returnValue field is not set.
				if ( event.result !== undefined && event.originalEvent ) {
					event.originalEvent.returnValue = event.result;
				}
			}
		}
	}
};

// Ensure the presence of an event listener that handles manually-triggered
// synthetic events by interrupting progress until reinvoked in response to
// *native* events that it fires directly, ensuring that state changes have
// already occurred before other listeners are invoked.
function leverageNative( el, type, expectSync ) {

	// Missing expectSync indicates a trigger call, which must force setup through jQuery.event.add
	if ( !expectSync ) {
		if ( dataPriv.get( el, type ) === undefined ) {
			jQuery.event.add( el, type, returnTrue );
		}
		return;
	}

	// Register the controller as a special universal handler for all event namespaces
	dataPriv.set( el, type, false );
	jQuery.event.add( el, type, {
		namespace: false,
		handler: function( event ) {
			var notAsync, result,
				saved = dataPriv.get( this, type );

			if ( ( event.isTrigger & 1 ) && this[ type ] ) {

				// Interrupt processing of the outer synthetic .trigger()ed event
				// Saved data should be false in such cases, but might be a leftover capture object
				// from an async native handler (gh-4350)
				if ( !saved.length ) {

					// Store arguments for use when handling the inner native event
					// There will always be at least one argument (an event object), so this array
					// will not be confused with a leftover capture object.
					saved = slice.call( arguments );
					dataPriv.set( this, type, saved );

					// Trigger the native event and capture its result
					// Support: IE <=9 - 11+
					// focus() and blur() are asynchronous
					notAsync = expectSync( this, type );
					this[ type ]();
					result = dataPriv.get( this, type );
					if ( saved !== result || notAsync ) {
						dataPriv.set( this, type, false );
					} else {
						result = {};
					}
					if ( saved !== result ) {

						// Cancel the outer synthetic event
						event.stopImmediatePropagation();
						event.preventDefault();

						// Support: Chrome 86+
						// In Chrome, if an element having a focusout handler is blurred by
						// clicking outside of it, it invokes the handler synchronously. If
						// that handler calls `.remove()` on the element, the data is cleared,
						// leaving `result` undefined. We need to guard against this.
						return result && result.value;
					}

				// If this is an inner synthetic event for an event with a bubbling surrogate
				// (focus or blur), assume that the surrogate already propagated from triggering the
				// native event and prevent that from happening again here.
				// This technically gets the ordering wrong w.r.t. to `.trigger()` (in which the
				// bubbling surrogate propagates *after* the non-bubbling base), but that seems
				// less bad than duplication.
				} else if ( ( jQuery.event.special[ type ] || {} ).delegateType ) {
					event.stopPropagation();
				}

			// If this is a native event triggered above, everything is now in order
			// Fire an inner synthetic event with the original arguments
			} else if ( saved.length ) {

				// ...and capture the result
				dataPriv.set( this, type, {
					value: jQuery.event.trigger(

						// Support: IE <=9 - 11+
						// Extend with the prototype to reset the above stopImmediatePropagation()
						jQuery.extend( saved[ 0 ], jQuery.Event.prototype ),
						saved.slice( 1 ),
						this
					)
				} );

				// Abort handling of the native event
				event.stopImmediatePropagation();
			}
		}
	} );
}

jQuery.removeEvent = function( elem, type, handle ) {

	// This "if" is needed for plain objects
	if ( elem.removeEventListener ) {
		elem.removeEventListener( type, handle );
	}
};

jQuery.Event = function( src, props ) {

	// Allow instantiation without the 'new' keyword
	if ( !( this instanceof jQuery.Event ) ) {
		return new jQuery.Event( src, props );
	}

	// Event object
	if ( src && src.type ) {
		this.originalEvent = src;
		this.type = src.type;

		// Events bubbling up the document may have been marked as prevented
		// by a handler lower down the tree; reflect the correct value.
		this.isDefaultPrevented = src.defaultPrevented ||
				src.defaultPrevented === undefined &&

				// Support: Android <=2.3 only
				src.returnValue === false ?
			returnTrue :
			returnFalse;

		// Create target properties
		// Support: Safari <=6 - 7 only
		// Target should not be a text node (trac-504, trac-13143)
		this.target = ( src.target && src.target.nodeType === 3 ) ?
			src.target.parentNode :
			src.target;

		this.currentTarget = src.currentTarget;
		this.relatedTarget = src.relatedTarget;

	// Event type
	} else {
		this.type = src;
	}

	// Put explicitly provided properties onto the event object
	if ( props ) {
		jQuery.extend( this, props );
	}

	// Create a timestamp if incoming event doesn't have one
	this.timeStamp = src && src.timeStamp || Date.now();

	// Mark it as fixed
	this[ jQuery.expando ] = true;
};

// jQuery.Event is based on DOM3 Events as specified by the ECMAScript Language Binding
// https://www.w3.org/TR/2003/WD-DOM-Level-3-Events-20030331/ecma-script-binding.html
jQuery.Event.prototype = {
	constructor: jQuery.Event,
	isDefaultPrevented: returnFalse,
	isPropagationStopped: returnFalse,
	isImmediatePropagationStopped: returnFalse,
	isSimulated: false,

	preventDefault: function() {
		var e = this.originalEvent;

		this.isDefaultPrevented = returnTrue;

		if ( e && !this.isSimulated ) {
			e.preventDefault();
		}
	},
	stopPropagation: function() {
		var e = this.originalEvent;

		this.isPropagationStopped = returnTrue;

		if ( e && !this.isSimulated ) {
			e.stopPropagation();
		}
	},
	stopImmediatePropagation: function() {
		var e = this.originalEvent;

		this.isImmediatePropagationStopped = returnTrue;

		if ( e && !this.isSimulated ) {
			e.stopImmediatePropagation();
		}

		this.stopPropagation();
	}
};

// Includes all common event props including KeyEvent and MouseEvent specific props
jQuery.each( {
	altKey: true,
	bubbles: true,
	cancelable: true,
	changedTouches: true,
	ctrlKey: true,
	detail: true,
	eventPhase: true,
	metaKey: true,
	pageX: true,
	pageY: true,
	shiftKey: true,
	view: true,
	"char": true,
	code: true,
	charCode: true,
	key: true,
	keyCode: true,
	button: true,
	buttons: true,
	clientX: true,
	clientY: true,
	offsetX: true,
	offsetY: true,
	pointerId: true,
	pointerType: true,
	screenX: true,
	screenY: true,
	targetTouches: true,
	toElement: true,
	touches: true,
	which: true
}, jQuery.event.addProp );

jQuery.each( { focus: "focusin", blur: "focusout" }, function( type, delegateType ) {
	jQuery.event.special[ type ] = {

		// Utilize native event if possible so blur/focus sequence is correct
		setup: function() {

			// Claim the first handler
			// dataPriv.set( this, "focus", ... )
			// dataPriv.set( this, "blur", ... )
			leverageNative( this, type, expectSync );

			// Return false to allow normal processing in the caller
			return false;
		},
		trigger: function() {

			// Force setup before trigger
			leverageNative( this, type );

			// Return non-false to allow normal event-path propagation
			return true;
		},

		// Suppress native focus or blur if we're currently inside
		// a leveraged native-event stack
		_default: function( event ) {
			return dataPriv.get( event.target, type );
		},

		delegateType: delegateType
	};
} );

// Create mouseenter/leave events using mouseover/out and event-time checks
// so that event delegation works in jQuery.
// Do the same for pointerenter/pointerleave and pointerover/pointerout
//
// Support: Safari 7 only
// Safari sends mouseenter too often; see:
// https://bugs.chromium.org/p/chromium/issues/detail?id=470258
// for the description of the bug (it existed in older Chrome versions as well).
jQuery.each( {
	mouseenter: "mouseover",
	mouseleave: "mouseout",
	pointerenter: "pointerover",
	pointerleave: "pointerout"
}, function( orig, fix ) {
	jQuery.event.special[ orig ] = {
		delegateType: fix,
		bindType: fix,

		handle: function( event ) {
			var ret,
				target = this,
				related = event.relatedTarget,
				handleObj = event.handleObj;

			// For mouseenter/leave call the handler if related is outside the target.
			// NB: No relatedTarget if the mouse left/entered the browser window
			if ( !related || ( related !== target && !jQuery.contains( target, related ) ) ) {
				event.type = handleObj.origType;
				ret = handleObj.handler.apply( this, arguments );
				event.type = fix;
			}
			return ret;
		}
	};
} );

jQuery.fn.extend( {

	on: function( types, selector, data, fn ) {
		return on( this, types, selector, data, fn );
	},
	one: function( types, selector, data, fn ) {
		return on( this, types, selector, data, fn, 1 );
	},
	off: function( types, selector, fn ) {
		var handleObj, type;
		if ( types && types.preventDefault && types.handleObj ) {

			// ( event )  dispatched jQuery.Event
			handleObj = types.handleObj;
			jQuery( types.delegateTarget ).off(
				handleObj.namespace ?
					handleObj.origType + "." + handleObj.namespace :
					handleObj.origType,
				handleObj.selector,
				handleObj.handler
			);
			return this;
		}
		if ( typeof types === "object" ) {

			// ( types-object [, selector] )
			for ( type in types ) {
				this.off( type, selector, types[ type ] );
			}
			return this;
		}
		if ( selector === false || typeof selector === "function" ) {

			// ( types [, fn] )
			fn = selector;
			selector = undefined;
		}
		if ( fn === false ) {
			fn = returnFalse;
		}
		return this.each( function() {
			jQuery.event.remove( this, types, fn, selector );
		} );
	}
} );


var

	// Support: IE <=10 - 11, Edge 12 - 13 only
	// In IE/Edge using regex groups here causes severe slowdowns.
	// See https://connect.microsoft.com/IE/feedback/details/1736512/
	rnoInnerhtml = /<script|<style|<link/i,

	// checked="checked" or checked
	rchecked = /checked\s*(?:[^=]|=\s*.checked.)/i,

	rcleanScript = /^\s*<!\[CDATA\[|\]\]>\s*$/g;

// Prefer a tbody over its parent table for containing new rows
function manipulationTarget( elem, content ) {
	if ( nodeName( elem, "table" ) &&
		nodeName( content.nodeType !== 11 ? content : content.firstChild, "tr" ) ) {

		return jQuery( elem ).children( "tbody" )[ 0 ] || elem;
	}

	return elem;
}

// Replace/restore the type attribute of script elements for safe DOM manipulation
function disableScript( elem ) {
	elem.type = ( elem.getAttribute( "type" ) !== null ) + "/" + elem.type;
	return elem;
}
function restoreScript( elem ) {
	if ( ( elem.type || "" ).slice( 0, 5 ) === "true/" ) {
		elem.type = elem.type.slice( 5 );
	} else {
		elem.removeAttribute( "type" );
	}

	return elem;
}

function cloneCopyEvent( src, dest ) {
	var i, l, type, pdataOld, udataOld, udataCur, events;

	if ( dest.nodeType !== 1 ) {
		return;
	}

	// 1. Copy private data: events, handlers, etc.
	if ( dataPriv.hasData( src ) ) {
		pdataOld = dataPriv.get( src );
		events = pdataOld.events;

		if ( events ) {
			dataPriv.remove( dest, "handle events" );

			for ( type in events ) {
				for ( i = 0, l = events[ type ].length; i < l; i++ ) {
					jQuery.event.add( dest, type, events[ type ][ i ] );
				}
			}
		}
	}

	// 2. Copy user data
	if ( dataUser.hasData( src ) ) {
		udataOld = dataUser.access( src );
		udataCur = jQuery.extend( {}, udataOld );

		dataUser.set( dest, udataCur );
	}
}

// Fix IE bugs, see support tests
function fixInput( src, dest ) {
	var nodeName = dest.nodeName.toLowerCase();

	// Fails to persist the checked state of a cloned checkbox or radio button.
	if ( nodeName === "input" && rcheckableType.test( src.type ) ) {
		dest.checked = src.checked;

	// Fails to return the selected option to the default selected state when cloning options
	} else if ( nodeName === "input" || nodeName === "textarea" ) {
		dest.defaultValue = src.defaultValue;
	}
}

function domManip( collection, args, callback, ignored ) {

	// Flatten any nested arrays
	args = flat( args );

	var fragment, first, scripts, hasScripts, node, doc,
		i = 0,
		l = collection.length,
		iNoClone = l - 1,
		value = args[ 0 ],
		valueIsFunction = isFunction( value );

	// We can't cloneNode fragments that contain checked, in WebKit
	if ( valueIsFunction ||
			( l > 1 && typeof value === "string" &&
				!support.checkClone && rchecked.test( value ) ) ) {
		return collection.each( function( index ) {
			var self = collection.eq( index );
			if ( valueIsFunction ) {
				args[ 0 ] = value.call( this, index, self.html() );
			}
			domManip( self, args, callback, ignored );
		} );
	}

	if ( l ) {
		fragment = buildFragment( args, collection[ 0 ].ownerDocument, false, collection, ignored );
		first = fragment.firstChild;

		if ( fragment.childNodes.length === 1 ) {
			fragment = first;
		}

		// Require either new content or an interest in ignored elements to invoke the callback
		if ( first || ignored ) {
			scripts = jQuery.map( getAll( fragment, "script" ), disableScript );
			hasScripts = scripts.length;

			// Use the original fragment for the last item
			// instead of the first because it can end up
			// being emptied incorrectly in certain situations (trac-8070).
			for ( ; i < l; i++ ) {
				node = fragment;

				if ( i !== iNoClone ) {
					node = jQuery.clone( node, true, true );

					// Keep references to cloned scripts for later restoration
					if ( hasScripts ) {

						// Support: Android <=4.0 only, PhantomJS 1 only
						// push.apply(_, arraylike) throws on ancient WebKit
						jQuery.merge( scripts, getAll( node, "script" ) );
					}
				}

				callback.call( collection[ i ], node, i );
			}

			if ( hasScripts ) {
				doc = scripts[ scripts.length - 1 ].ownerDocument;

				// Reenable scripts
				jQuery.map( scripts, restoreScript );

				// Evaluate executable scripts on first document insertion
				for ( i = 0; i < hasScripts; i++ ) {
					node = scripts[ i ];
					if ( rscriptType.test( node.type || "" ) &&
						!dataPriv.access( node, "globalEval" ) &&
						jQuery.contains( doc, node ) ) {

						if ( node.src && ( node.type || "" ).toLowerCase()  !== "module" ) {

							// Optional AJAX dependency, but won't run scripts if not present
							if ( jQuery._evalUrl && !node.noModule ) {
								jQuery._evalUrl( node.src, {
									nonce: node.nonce || node.getAttribute( "nonce" )
								}, doc );
							}
						} else {

							// Unwrap a CDATA section containing script contents. This shouldn't be
							// needed as in XML documents they're already not visible when
							// inspecting element contents and in HTML documents they have no
							// meaning but we're preserving that logic for backwards compatibility.
							// This will be removed completely in 4.0. See gh-4904.
							DOMEval( node.textContent.replace( rcleanScript, "" ), node, doc );
						}
					}
				}
			}
		}
	}

	return collection;
}

function remove( elem, selector, keepData ) {
	var node,
		nodes = selector ? jQuery.filter( selector, elem ) : elem,
		i = 0;

	for ( ; ( node = nodes[ i ] ) != null; i++ ) {
		if ( !keepData && node.nodeType === 1 ) {
			jQuery.cleanData( getAll( node ) );
		}

		if ( node.parentNode ) {
			if ( keepData && isAttached( node ) ) {
				setGlobalEval( getAll( node, "script" ) );
			}
			node.parentNode.removeChild( node );
		}
	}

	return elem;
}

jQuery.extend( {
	htmlPrefilter: function( html ) {
		return html;
	},

	clone: function( elem, dataAndEvents, deepDataAndEvents ) {
		var i, l, srcElements, destElements,
			clone = elem.cloneNode( true ),
			inPage = isAttached( elem );

		// Fix IE cloning issues
		if ( !support.noCloneChecked && ( elem.nodeType === 1 || elem.nodeType === 11 ) &&
				!jQuery.isXMLDoc( elem ) ) {

			// We eschew Sizzle here for performance reasons: https://jsperf.com/getall-vs-sizzle/2
			destElements = getAll( clone );
			srcElements = getAll( elem );

			for ( i = 0, l = srcElements.length; i < l; i++ ) {
				fixInput( srcElements[ i ], destElements[ i ] );
			}
		}

		// Copy the events from the original to the clone
		if ( dataAndEvents ) {
			if ( deepDataAndEvents ) {
				srcElements = srcElements || getAll( elem );
				destElements = destElements || getAll( clone );

				for ( i = 0, l = srcElements.length; i < l; i++ ) {
					cloneCopyEvent( srcElements[ i ], destElements[ i ] );
				}
			} else {
				cloneCopyEvent( elem, clone );
			}
		}

		// Preserve script evaluation history
		destElements = getAll( clone, "script" );
		if ( destElements.length > 0 ) {
			setGlobalEval( destElements, !inPage && getAll( elem, "script" ) );
		}

		// Return the cloned set
		return clone;
	},

	cleanData: function( elems ) {
		var data, elem, type,
			special = jQuery.event.special,
			i = 0;

		for ( ; ( elem = elems[ i ] ) !== undefined; i++ ) {
			if ( acceptData( elem ) ) {
				if ( ( data = elem[ dataPriv.expando ] ) ) {
					if ( data.events ) {
						for ( type in data.events ) {
							if ( special[ type ] ) {
								jQuery.event.remove( elem, type );

							// This is a shortcut to avoid jQuery.event.remove's overhead
							} else {
								jQuery.removeEvent( elem, type, data.handle );
							}
						}
					}

					// Support: Chrome <=35 - 45+
					// Assign undefined instead of using delete, see Data#remove
					elem[ dataPriv.expando ] = undefined;
				}
				if ( elem[ dataUser.expando ] ) {

					// Support: Chrome <=35 - 45+
					// Assign undefined instead of using delete, see Data#remove
					elem[ dataUser.expando ] = undefined;
				}
			}
		}
	}
} );

jQuery.fn.extend( {
	detach: function( selector ) {
		return remove( this, selector, true );
	},

	remove: function( selector ) {
		return remove( this, selector );
	},

	text: function( value ) {
		return access( this, function( value ) {
			return value === undefined ?
				jQuery.text( this ) :
				this.empty().each( function() {
					if ( this.nodeType === 1 || this.nodeType === 11 || this.nodeType === 9 ) {
						this.textContent = value;
					}
				} );
		}, null, value, arguments.length );
	},

	append: function() {
		return domManip( this, arguments, function( elem ) {
			if ( this.nodeType === 1 || this.nodeType === 11 || this.nodeType === 9 ) {
				var target = manipulationTarget( this, elem );
				target.appendChild( elem );
			}
		} );
	},

	prepend: function() {
		return domManip( this, arguments, function( elem ) {
			if ( this.nodeType === 1 || this.nodeType === 11 || this.nodeType === 9 ) {
				var target = manipulationTarget( this, elem );
				target.insertBefore( elem, target.firstChild );
			}
		} );
	},

	before: function() {
		return domManip( this, arguments, function( elem ) {
			if ( this.parentNode ) {
				this.parentNode.insertBefore( elem, this );
			}
		} );
	},

	after: function() {
		return domManip( this, arguments, function( elem ) {
			if ( this.parentNode ) {
				this.parentNode.insertBefore( elem, this.nextSibling );
			}
		} );
	},

	empty: function() {
		var elem,
			i = 0;

		for ( ; ( elem = this[ i ] ) != null; i++ ) {
			if ( elem.nodeType === 1 ) {

				// Prevent memory leaks
				jQuery.cleanData( getAll( elem, false ) );

				// Remove any remaining nodes
				elem.textContent = "";
			}
		}

		return this;
	},

	clone: function( dataAndEvents, deepDataAndEvents ) {
		dataAndEvents = dataAndEvents == null ? false : dataAndEvents;
		deepDataAndEvents = deepDataAndEvents == null ? dataAndEvents : deepDataAndEvents;

		return this.map( function() {
			return jQuery.clone( this, dataAndEvents, deepDataAndEvents );
		} );
	},

	html: function( value ) {
		return access( this, function( value ) {
			var elem = this[ 0 ] || {},
				i = 0,
				l = this.length;

			if ( value === undefined && elem.nodeType === 1 ) {
				return elem.innerHTML;
			}

			// See if we can take a shortcut and just use innerHTML
			if ( typeof value === "string" && !rnoInnerhtml.test( value ) &&
				!wrapMap[ ( rtagName.exec( value ) || [ "", "" ] )[ 1 ].toLowerCase() ] ) {

				value = jQuery.htmlPrefilter( value );

				try {
					for ( ; i < l; i++ ) {
						elem = this[ i ] || {};

						// Remove element nodes and prevent memory leaks
						if ( elem.nodeType === 1 ) {
							jQuery.cleanData( getAll( elem, false ) );
							elem.innerHTML = value;
						}
					}

					elem = 0;

				// If using innerHTML throws an exception, use the fallback method
				} catch ( e ) {}
			}

			if ( elem ) {
				this.empty().append( value );
			}
		}, null, value, arguments.length );
	},

	replaceWith: function() {
		var ignored = [];

		// Make the changes, replacing each non-ignored context element with the new content
		return domManip( this, arguments, function( elem ) {
			var parent = this.parentNode;

			if ( jQuery.inArray( this, ignored ) < 0 ) {
				jQuery.cleanData( getAll( this ) );
				if ( parent ) {
					parent.replaceChild( elem, this );
				}
			}

		// Force callback invocation
		}, ignored );
	}
} );

jQuery.each( {
	appendTo: "append",
	prependTo: "prepend",
	insertBefore: "before",
	insertAfter: "after",
	replaceAll: "replaceWith"
}, function( name, original ) {
	jQuery.fn[ name ] = function( selector ) {
		var elems,
			ret = [],
			insert = jQuery( selector ),
			last = insert.length - 1,
			i = 0;

		for ( ; i <= last; i++ ) {
			elems = i === last ? this : this.clone( true );
			jQuery( insert[ i ] )[ original ]( elems );

			// Support: Android <=4.0 only, PhantomJS 1 only
			// .get() because push.apply(_, arraylike) throws on ancient WebKit
			push.apply( ret, elems.get() );
		}

		return this.pushStack( ret );
	};
} );
var rnumnonpx = new RegExp( "^(" + pnum + ")(?!px)[a-z%]+$", "i" );

var rcustomProp = /^--/;


var getStyles = function( elem ) {

		// Support: IE <=11 only, Firefox <=30 (trac-15098, trac-14150)
		// IE throws on elements created in popups
		// FF meanwhile throws on frame elements through "defaultView.getComputedStyle"
		var view = elem.ownerDocument.defaultView;

		if ( !view || !view.opener ) {
			view = window;
		}

		return view.getComputedStyle( elem );
	};

var swap = function( elem, options, callback ) {
	var ret, name,
		old = {};

	// Remember the old values, and insert the new ones
	for ( name in options ) {
		old[ name ] = elem.style[ name ];
		elem.style[ name ] = options[ name ];
	}

	ret = callback.call( elem );

	// Revert the old values
	for ( name in options ) {
		elem.style[ name ] = old[ name ];
	}

	return ret;
};


var rboxStyle = new RegExp( cssExpand.join( "|" ), "i" );

var whitespace = "[\\x20\\t\\r\\n\\f]";


var rtrimCSS = new RegExp(
	"^" + whitespace + "+|((?:^|[^\\\\])(?:\\\\.)*)" + whitespace + "+$",
	"g"
);




( function() {

	// Executing both pixelPosition & boxSizingReliable tests require only one layout
	// so they're executed at the same time to save the second computation.
	function computeStyleTests() {

		// This is a singleton, we need to execute it only once
		if ( !div ) {
			return;
		}

		container.style.cssText = "position:absolute;left:-11111px;width:60px;" +
			"margin-top:1px;padding:0;border:0";
		div.style.cssText =
			"position:relative;display:block;box-sizing:border-box;overflow:scroll;" +
			"margin:auto;border:1px;padding:1px;" +
			"width:60%;top:1%";
		documentElement.appendChild( container ).appendChild( div );

		var divStyle = window.getComputedStyle( div );
		pixelPositionVal = divStyle.top !== "1%";

		// Support: Android 4.0 - 4.3 only, Firefox <=3 - 44
		reliableMarginLeftVal = roundPixelMeasures( divStyle.marginLeft ) === 12;

		// Support: Android 4.0 - 4.3 only, Safari <=9.1 - 10.1, iOS <=7.0 - 9.3
		// Some styles come back with percentage values, even though they shouldn't
		div.style.right = "60%";
		pixelBoxStylesVal = roundPixelMeasures( divStyle.right ) === 36;

		// Support: IE 9 - 11 only
		// Detect misreporting of content dimensions for box-sizing:border-box elements
		boxSizingReliableVal = roundPixelMeasures( divStyle.width ) === 36;

		// Support: IE 9 only
		// Detect overflow:scroll screwiness (gh-3699)
		// Support: Chrome <=64
		// Don't get tricked when zoom affects offsetWidth (gh-4029)
		div.style.position = "absolute";
		scrollboxSizeVal = roundPixelMeasures( div.offsetWidth / 3 ) === 12;

		documentElement.removeChild( container );

		// Nullify the div so it wouldn't be stored in the memory and
		// it will also be a sign that checks already performed
		div = null;
	}

	function roundPixelMeasures( measure ) {
		return Math.round( parseFloat( measure ) );
	}

	var pixelPositionVal, boxSizingReliableVal, scrollboxSizeVal, pixelBoxStylesVal,
		reliableTrDimensionsVal, reliableMarginLeftVal,
		container = document.createElement( "div" ),
		div = document.createElement( "div" );

	// Finish early in limited (non-browser) environments
	if ( !div.style ) {
		return;
	}

	// Support: IE <=9 - 11 only
	// Style of cloned element affects source element cloned (trac-8908)
	div.style.backgroundClip = "content-box";
	div.cloneNode( true ).style.backgroundClip = "";
	support.clearCloneStyle = div.style.backgroundClip === "content-box";

	jQuery.extend( support, {
		boxSizingReliable: function() {
			computeStyleTests();
			return boxSizingReliableVal;
		},
		pixelBoxStyles: function() {
			computeStyleTests();
			return pixelBoxStylesVal;
		},
		pixelPosition: function() {
			computeStyleTests();
			return pixelPositionVal;
		},
		reliableMarginLeft: function() {
			computeStyleTests();
			return reliableMarginLeftVal;
		},
		scrollboxSize: function() {
			computeStyleTests();
			return scrollboxSizeVal;
		},

		// Support: IE 9 - 11+, Edge 15 - 18+
		// IE/Edge misreport `getComputedStyle` of table rows with width/height
		// set in CSS while `offset*` properties report correct values.
		// Behavior in IE 9 is more subtle than in newer versions & it passes
		// some versions of this test; make sure not to make it pass there!
		//
		// Support: Firefox 70+
		// Only Firefox includes border widths
		// in computed dimensions. (gh-4529)
		reliableTrDimensions: function() {
			var table, tr, trChild, trStyle;
			if ( reliableTrDimensionsVal == null ) {
				table = document.createElement( "table" );
				tr = document.createElement( "tr" );
				trChild = document.createElement( "div" );

				table.style.cssText = "position:absolute;left:-11111px;border-collapse:separate";
				tr.style.cssText = "border:1px solid";

				// Support: Chrome 86+
				// Height set through cssText does not get applied.
				// Computed height then comes back as 0.
				tr.style.height = "1px";
				trChild.style.height = "9px";

				// Support: Android 8 Chrome 86+
				// In our bodyBackground.html iframe,
				// display for all div elements is set to "inline",
				// which causes a problem only in Android 8 Chrome 86.
				// Ensuring the div is display: block
				// gets around this issue.
				trChild.style.display = "block";

				documentElement
					.appendChild( table )
					.appendChild( tr )
					.appendChild( trChild );

				trStyle = window.getComputedStyle( tr );
				reliableTrDimensionsVal = ( parseInt( trStyle.height, 10 ) +
					parseInt( trStyle.borderTopWidth, 10 ) +
					parseInt( trStyle.borderBottomWidth, 10 ) ) === tr.offsetHeight;

				documentElement.removeChild( table );
			}
			return reliableTrDimensionsVal;
		}
	} );
} )();


function curCSS( elem, name, computed ) {
	var width, minWidth, maxWidth, ret,
		isCustomProp = rcustomProp.test( name ),

		// Support: Firefox 51+
		// Retrieving style before computed somehow
		// fixes an issue with getting wrong values
		// on detached elements
		style = elem.style;

	computed = computed || getStyles( elem );

	// getPropertyValue is needed for:
	//   .css('filter') (IE 9 only, trac-12537)
	//   .css('--customProperty) (gh-3144)
	if ( computed ) {
		ret = computed.getPropertyValue( name ) || computed[ name ];

		// trim whitespace for custom property (issue gh-4926)
		if ( isCustomProp ) {

			// rtrim treats U+000D CARRIAGE RETURN and U+000C FORM FEED
			// as whitespace while CSS does not, but this is not a problem
			// because CSS preprocessing replaces them with U+000A LINE FEED
			// (which *is* CSS whitespace)
			// https://www.w3.org/TR/css-syntax-3/#input-preprocessing
			ret = ret.replace( rtrimCSS, "$1" );
		}

		if ( ret === "" && !isAttached( elem ) ) {
			ret = jQuery.style( elem, name );
		}

		// A tribute to the "awesome hack by Dean Edwards"
		// Android Browser returns percentage for some values,
		// but width seems to be reliably pixels.
		// This is against the CSSOM draft spec:
		// https://drafts.csswg.org/cssom/#resolved-values
		if ( !support.pixelBoxStyles() && rnumnonpx.test( ret ) && rboxStyle.test( name ) ) {

			// Remember the original values
			width = style.width;
			minWidth = style.minWidth;
			maxWidth = style.maxWidth;

			// Put in the new values to get a computed value out
			style.minWidth = style.maxWidth = style.width = ret;
			ret = computed.width;

			// Revert the changed values
			style.width = width;
			style.minWidth = minWidth;
			style.maxWidth = maxWidth;
		}
	}

	return ret !== undefined ?

		// Support: IE <=9 - 11 only
		// IE returns zIndex value as an integer.
		ret + "" :
		ret;
}


function addGetHookIf( conditionFn, hookFn ) {

	// Define the hook, we'll check on the first run if it's really needed.
	return {
		get: function() {
			if ( conditionFn() ) {

				// Hook not needed (or it's not possible to use it due
				// to missing dependency), remove it.
				delete this.get;
				return;
			}

			// Hook needed; redefine it so that the support test is not executed again.
			return ( this.get = hookFn ).apply( this, arguments );
		}
	};
}


var cssPrefixes = [ "Webkit", "Moz", "ms" ],
	emptyStyle = document.createElement( "div" ).style,
	vendorProps = {};

// Return a vendor-prefixed property or undefined
function vendorPropName( name ) {

	// Check for vendor prefixed names
	var capName = name[ 0 ].toUpperCase() + name.slice( 1 ),
		i = cssPrefixes.length;

	while ( i-- ) {
		name = cssPrefixes[ i ] + capName;
		if ( name in emptyStyle ) {
			return name;
		}
	}
}

// Return a potentially-mapped jQuery.cssProps or vendor prefixed property
function finalPropName( name ) {
	var final = jQuery.cssProps[ name ] || vendorProps[ name ];

	if ( final ) {
		return final;
	}
	if ( name in emptyStyle ) {
		return name;
	}
	return vendorProps[ name ] = vendorPropName( name ) || name;
}


var

	// Swappable if display is none or starts with table
	// except "table", "table-cell", or "table-caption"
	// See here for display values: https://developer.mozilla.org/en-US/docs/CSS/display
	rdisplayswap = /^(none|table(?!-c[ea]).+)/,
	cssShow = { position: "absolute", visibility: "hidden", display: "block" },
	cssNormalTransform = {
		letterSpacing: "0",
		fontWeight: "400"
	};

function setPositiveNumber( _elem, value, subtract ) {

	// Any relative (+/-) values have already been
	// normalized at this point
	var matches = rcssNum.exec( value );
	return matches ?

		// Guard against undefined "subtract", e.g., when used as in cssHooks
		Math.max( 0, matches[ 2 ] - ( subtract || 0 ) ) + ( matches[ 3 ] || "px" ) :
		value;
}

function boxModelAdjustment( elem, dimension, box, isBorderBox, styles, computedVal ) {
	var i = dimension === "width" ? 1 : 0,
		extra = 0,
		delta = 0;

	// Adjustment may not be necessary
	if ( box === ( isBorderBox ? "border" : "content" ) ) {
		return 0;
	}

	for ( ; i < 4; i += 2 ) {

		// Both box models exclude margin
		if ( box === "margin" ) {
			delta += jQuery.css( elem, box + cssExpand[ i ], true, styles );
		}

		// If we get here with a content-box, we're seeking "padding" or "border" or "margin"
		if ( !isBorderBox ) {

			// Add padding
			delta += jQuery.css( elem, "padding" + cssExpand[ i ], true, styles );

			// For "border" or "margin", add border
			if ( box !== "padding" ) {
				delta += jQuery.css( elem, "border" + cssExpand[ i ] + "Width", true, styles );

			// But still keep track of it otherwise
			} else {
				extra += jQuery.css( elem, "border" + cssExpand[ i ] + "Width", true, styles );
			}

		// If we get here with a border-box (content + padding + border), we're seeking "content" or
		// "padding" or "margin"
		} else {

			// For "content", subtract padding
			if ( box === "content" ) {
				delta -= jQuery.css( elem, "padding" + cssExpand[ i ], true, styles );
			}

			// For "content" or "padding", subtract border
			if ( box !== "margin" ) {
				delta -= jQuery.css( elem, "border" + cssExpand[ i ] + "Width", true, styles );
			}
		}
	}

	// Account for positive content-box scroll gutter when requested by providing computedVal
	if ( !isBorderBox && computedVal >= 0 ) {

		// offsetWidth/offsetHeight is a rounded sum of content, padding, scroll gutter, and border
		// Assuming integer scroll gutter, subtract the rest and round down
		delta += Math.max( 0, Math.ceil(
			elem[ "offset" + dimension[ 0 ].toUpperCase() + dimension.slice( 1 ) ] -
			computedVal -
			delta -
			extra -
			0.5

		// If offsetWidth/offsetHeight is unknown, then we can't determine content-box scroll gutter
		// Use an explicit zero to avoid NaN (gh-3964)
		) ) || 0;
	}

	return delta;
}

function getWidthOrHeight( elem, dimension, extra ) {

	// Start with computed style
	var styles = getStyles( elem ),

		// To avoid forcing a reflow, only fetch boxSizing if we need it (gh-4322).
		// Fake content-box until we know it's needed to know the true value.
		boxSizingNeeded = !support.boxSizingReliable() || extra,
		isBorderBox = boxSizingNeeded &&
			jQuery.css( elem, "boxSizing", false, styles ) === "border-box",
		valueIsBorderBox = isBorderBox,

		val = curCSS( elem, dimension, styles ),
		offsetProp = "offset" + dimension[ 0 ].toUpperCase() + dimension.slice( 1 );

	// Support: Firefox <=54
	// Return a confounding non-pixel value or feign ignorance, as appropriate.
	if ( rnumnonpx.test( val ) ) {
		if ( !extra ) {
			return val;
		}
		val = "auto";
	}


	// Support: IE 9 - 11 only
	// Use offsetWidth/offsetHeight for when box sizing is unreliable.
	// In those cases, the computed value can be trusted to be border-box.
	if ( ( !support.boxSizingReliable() && isBorderBox ||

		// Support: IE 10 - 11+, Edge 15 - 18+
		// IE/Edge misreport `getComputedStyle` of table rows with width/height
		// set in CSS while `offset*` properties report correct values.
		// Interestingly, in some cases IE 9 doesn't suffer from this issue.
		!support.reliableTrDimensions() && nodeName( elem, "tr" ) ||

		// Fall back to offsetWidth/offsetHeight when value is "auto"
		// This happens for inline elements with no explicit setting (gh-3571)
		val === "auto" ||

		// Support: Android <=4.1 - 4.3 only
		// Also use offsetWidth/offsetHeight for misreported inline dimensions (gh-3602)
		!parseFloat( val ) && jQuery.css( elem, "display", false, styles ) === "inline" ) &&

		// Make sure the element is visible & connected
		elem.getClientRects().length ) {

		isBorderBox = jQuery.css( elem, "boxSizing", false, styles ) === "border-box";

		// Where available, offsetWidth/offsetHeight approximate border box dimensions.
		// Where not available (e.g., SVG), assume unreliable box-sizing and interpret the
		// retrieved value as a content box dimension.
		valueIsBorderBox = offsetProp in elem;
		if ( valueIsBorderBox ) {
			val = elem[ offsetProp ];
		}
	}

	// Normalize "" and auto
	val = parseFloat( val ) || 0;

	// Adjust for the element's box model
	return ( val +
		boxModelAdjustment(
			elem,
			dimension,
			extra || ( isBorderBox ? "border" : "content" ),
			valueIsBorderBox,
			styles,

			// Provide the current computed size to request scroll gutter calculation (gh-3589)
			val
		)
	) + "px";
}

jQuery.extend( {

	// Add in style property hooks for overriding the default
	// behavior of getting and setting a style property
	cssHooks: {
		opacity: {
			get: function( elem, computed ) {
				if ( computed ) {

					// We should always get a number back from opacity
					var ret = curCSS( elem, "opacity" );
					return ret === "" ? "1" : ret;
				}
			}
		}
	},

	// Don't automatically add "px" to these possibly-unitless properties
	cssNumber: {
		"animationIterationCount": true,
		"columnCount": true,
		"fillOpacity": true,
		"flexGrow": true,
		"flexShrink": true,
		"fontWeight": true,
		"gridArea": true,
		"gridColumn": true,
		"gridColumnEnd": true,
		"gridColumnStart": true,
		"gridRow": true,
		"gridRowEnd": true,
		"gridRowStart": true,
		"lineHeight": true,
		"opacity": true,
		"order": true,
		"orphans": true,
		"widows": true,
		"zIndex": true,
		"zoom": true
	},

	// Add in properties whose names you wish to fix before
	// setting or getting the value
	cssProps: {},

	// Get and set the style property on a DOM Node
	style: function( elem, name, value, extra ) {

		// Don't set styles on text and comment nodes
		if ( !elem || elem.nodeType === 3 || elem.nodeType === 8 || !elem.style ) {
			return;
		}

		// Make sure that we're working with the right name
		var ret, type, hooks,
			origName = camelCase( name ),
			isCustomProp = rcustomProp.test( name ),
			style = elem.style;

		// Make sure that we're working with the right name. We don't
		// want to query the value if it is a CSS custom property
		// since they are user-defined.
		if ( !isCustomProp ) {
			name = finalPropName( origName );
		}

		// Gets hook for the prefixed version, then unprefixed version
		hooks = jQuery.cssHooks[ name ] || jQuery.cssHooks[ origName ];

		// Check if we're setting a value
		if ( value !== undefined ) {
			type = typeof value;

			// Convert "+=" or "-=" to relative numbers (trac-7345)
			if ( type === "string" && ( ret = rcssNum.exec( value ) ) && ret[ 1 ] ) {
				value = adjustCSS( elem, name, ret );

				// Fixes bug trac-9237
				type = "number";
			}

			// Make sure that null and NaN values aren't set (trac-7116)
			if ( value == null || value !== value ) {
				return;
			}

			// If a number was passed in, add the unit (except for certain CSS properties)
			// The isCustomProp check can be removed in jQuery 4.0 when we only auto-append
			// "px" to a few hardcoded values.
			if ( type === "number" && !isCustomProp ) {
				value += ret && ret[ 3 ] || ( jQuery.cssNumber[ origName ] ? "" : "px" );
			}

			// background-* props affect original clone's values
			if ( !support.clearCloneStyle && value === "" && name.indexOf( "background" ) === 0 ) {
				style[ name ] = "inherit";
			}

			// If a hook was provided, use that value, otherwise just set the specified value
			if ( !hooks || !( "set" in hooks ) ||
				( value = hooks.set( elem, value, extra ) ) !== undefined ) {

				if ( isCustomProp ) {
					style.setProperty( name, value );
				} else {
					style[ name ] = value;
				}
			}

		} else {

			// If a hook was provided get the non-computed value from there
			if ( hooks && "get" in hooks &&
				( ret = hooks.get( elem, false, extra ) ) !== undefined ) {

				return ret;
			}

			// Otherwise just get the value from the style object
			return style[ name ];
		}
	},

	css: function( elem, name, extra, styles ) {
		var val, num, hooks,
			origName = camelCase( name ),
			isCustomProp = rcustomProp.test( name );

		// Make sure that we're working with the right name. We don't
		// want to modify the value if it is a CSS custom property
		// since they are user-defined.
		if ( !isCustomProp ) {
			name = finalPropName( origName );
		}

		// Try prefixed name followed by the unprefixed name
		hooks = jQuery.cssHooks[ name ] || jQuery.cssHooks[ origName ];

		// If a hook was provided get the computed value from there
		if ( hooks && "get" in hooks ) {
			val = hooks.get( elem, true, extra );
		}

		// Otherwise, if a way to get the computed value exists, use that
		if ( val === undefined ) {
			val = curCSS( elem, name, styles );
		}

		// Convert "normal" to computed value
		if ( val === "normal" && name in cssNormalTransform ) {
			val = cssNormalTransform[ name ];
		}

		// Make numeric if forced or a qualifier was provided and val looks numeric
		if ( extra === "" || extra ) {
			num = parseFloat( val );
			return extra === true || isFinite( num ) ? num || 0 : val;
		}

		return val;
	}
} );

jQuery.each( [ "height", "width" ], function( _i, dimension ) {
	jQuery.cssHooks[ dimension ] = {
		get: function( elem, computed, extra ) {
			if ( computed ) {

				// Certain elements can have dimension info if we invisibly show them
				// but it must have a current display style that would benefit
				return rdisplayswap.test( jQuery.css( elem, "display" ) ) &&

					// Support: Safari 8+
					// Table columns in Safari have non-zero offsetWidth & zero
					// getBoundingClientRect().width unless display is changed.
					// Support: IE <=11 only
					// Running getBoundingClientRect on a disconnected node
					// in IE throws an error.
					( !elem.getClientRects().length || !elem.getBoundingClientRect().width ) ?
					swap( elem, cssShow, function() {
						return getWidthOrHeight( elem, dimension, extra );
					} ) :
					getWidthOrHeight( elem, dimension, extra );
			}
		},

		set: function( elem, value, extra ) {
			var matches,
				styles = getStyles( elem ),

				// Only read styles.position if the test has a chance to fail
				// to avoid forcing a reflow.
				scrollboxSizeBuggy = !support.scrollboxSize() &&
					styles.position === "absolute",

				// To avoid forcing a reflow, only fetch boxSizing if we need it (gh-3991)
				boxSizingNeeded = scrollboxSizeBuggy || extra,
				isBorderBox = boxSizingNeeded &&
					jQuery.css( elem, "boxSizing", false, styles ) === "border-box",
				subtract = extra ?
					boxModelAdjustment(
						elem,
						dimension,
						extra,
						isBorderBox,
						styles
					) :
					0;

			// Account for unreliable border-box dimensions by comparing offset* to computed and
			// faking a content-box to get border and padding (gh-3699)
			if ( isBorderBox && scrollboxSizeBuggy ) {
				subtract -= Math.ceil(
					elem[ "offset" + dimension[ 0 ].toUpperCase() + dimension.slice( 1 ) ] -
					parseFloat( styles[ dimension ] ) -
					boxModelAdjustment( elem, dimension, "border", false, styles ) -
					0.5
				);
			}

			// Convert to pixels if value adjustment is needed
			if ( subtract && ( matches = rcssNum.exec( value ) ) &&
				( matches[ 3 ] || "px" ) !== "px" ) {

				elem.style[ dimension ] = value;
				value = jQuery.css( elem, dimension );
			}

			return setPositiveNumber( elem, value, subtract );
		}
	};
} );

jQuery.cssHooks.marginLeft = addGetHookIf( support.reliableMarginLeft,
	function( elem, computed ) {
		if ( computed ) {
			return ( parseFloat( curCSS( elem, "marginLeft" ) ) ||
				elem.getBoundingClientRect().left -
					swap( elem, { marginLeft: 0 }, function() {
						return elem.getBoundingClientRect().left;
					} )
			) + "px";
		}
	}
);

// These hooks are used by animate to expand properties
jQuery.each( {
	margin: "",
	padding: "",
	border: "Width"
}, function( prefix, suffix ) {
	jQuery.cssHooks[ prefix + suffix ] = {
		expand: function( value ) {
			var i = 0,
				expanded = {},

				// Assumes a single number if not a string
				parts = typeof value === "string" ? value.split( " " ) : [ value ];

			for ( ; i < 4; i++ ) {
				expanded[ prefix + cssExpand[ i ] + suffix ] =
					parts[ i ] || parts[ i - 2 ] || parts[ 0 ];
			}

			return expanded;
		}
	};

	if ( prefix !== "margin" ) {
		jQuery.cssHooks[ prefix + suffix ].set = setPositiveNumber;
	}
} );

jQuery.fn.extend( {
	css: function( name, value ) {
		return access( this, function( elem, name, value ) {
			var styles, len,
				map = {},
				i = 0;

			if ( Array.isArray( name ) ) {
				styles = getStyles( elem );
				len = name.length;

				for ( ; i < len; i++ ) {
					map[ name[ i ] ] = jQuery.css( elem, name[ i ], false, styles );
				}

				return map;
			}

			return value !== undefined ?
				jQuery.style( elem, name, value ) :
				jQuery.css( elem, name );
		}, name, value, arguments.length > 1 );
	}
} );


function Tween( elem, options, prop, end, easing ) {
	return new Tween.prototype.init( elem, options, prop, end, easing );
}
jQuery.Tween = Tween;

Tween.prototype = {
	constructor: Tween,
	init: function( elem, options, prop, end, easing, unit ) {
		this.elem = elem;
		this.prop = prop;
		this.easing = easing || jQuery.easing._default;
		this.options = options;
		this.start = this.now = this.cur();
		this.end = end;
		this.unit = unit || ( jQuery.cssNumber[ prop ] ? "" : "px" );
	},
	cur: function() {
		var hooks = Tween.propHooks[ this.prop ];

		return hooks && hooks.get ?
			hooks.get( this ) :
			Tween.propHooks._default.get( this );
	},
	run: function( percent ) {
		var eased,
			hooks = Tween.propHooks[ this.prop ];

		if ( this.options.duration ) {
			this.pos = eased = jQuery.easing[ this.easing ](
				percent, this.options.duration * percent, 0, 1, this.options.duration
			);
		} else {
			this.pos = eased = percent;
		}
		this.now = ( this.end - this.start ) * eased + this.start;

		if ( this.options.step ) {
			this.options.step.call( this.elem, this.now, this );
		}

		if ( hooks && hooks.set ) {
			hooks.set( this );
		} else {
			Tween.propHooks._default.set( this );
		}
		return this;
	}
};

Tween.prototype.init.prototype = Tween.prototype;

Tween.propHooks = {
	_default: {
		get: function( tween ) {
			var result;

			// Use a property on the element directly when it is not a DOM element,
			// or when there is no matching style property that exists.
			if ( tween.elem.nodeType !== 1 ||
				tween.elem[ tween.prop ] != null && tween.elem.style[ tween.prop ] == null ) {
				return tween.elem[ tween.prop ];
			}

			// Passing an empty string as a 3rd parameter to .css will automatically
			// attempt a parseFloat and fallback to a string if the parse fails.
			// Simple values such as "10px" are parsed to Float;
			// complex values such as "rotate(1rad)" are returned as-is.
			result = jQuery.css( tween.elem, tween.prop, "" );

			// Empty strings, null, undefined and "auto" are converted to 0.
			return !result || result === "auto" ? 0 : result;
		},
		set: function( tween ) {

			// Use step hook for back compat.
			// Use cssHook if its there.
			// Use .style if available and use plain properties where available.
			if ( jQuery.fx.step[ tween.prop ] ) {
				jQuery.fx.step[ tween.prop ]( tween );
			} else if ( tween.elem.nodeType === 1 && (
				jQuery.cssHooks[ tween.prop ] ||
					tween.elem.style[ finalPropName( tween.prop ) ] != null ) ) {
				jQuery.style( tween.elem, tween.prop, tween.now + tween.unit );
			} else {
				tween.elem[ tween.prop ] = tween.now;
			}
		}
	}
};

// Support: IE <=9 only
// Panic based approach to setting things on disconnected nodes
Tween.propHooks.scrollTop = Tween.propHooks.scrollLeft = {
	set: function( tween ) {
		if ( tween.elem.nodeType && tween.elem.parentNode ) {
			tween.elem[ tween.prop ] = tween.now;
		}
	}
};

jQuery.easing = {
	linear: function( p ) {
		return p;
	},
	swing: function( p ) {
		return 0.5 - Math.cos( p * Math.PI ) / 2;
	},
	_default: "swing"
};

jQuery.fx = Tween.prototype.init;

// Back compat <1.8 extension point
jQuery.fx.step = {};




var
	fxNow, inProgress,
	rfxtypes = /^(?:toggle|show|hide)$/,
	rrun = /queueHooks$/;

function schedule() {
	if ( inProgress ) {
		if ( document.hidden === false && window.requestAnimationFrame ) {
			window.requestAnimationFrame( schedule );
		} else {
			window.setTimeout( schedule, jQuery.fx.interval );
		}

		jQuery.fx.tick();
	}
}

// Animations created synchronously will run synchronously
function createFxNow() {
	window.setTimeout( function() {
		fxNow = undefined;
	} );
	return ( fxNow = Date.now() );
}

// Generate parameters to create a standard animation
function genFx( type, includeWidth ) {
	var which,
		i = 0,
		attrs = { height: type };

	// If we include width, step value is 1 to do all cssExpand values,
	// otherwise step value is 2 to skip over Left and Right
	includeWidth = includeWidth ? 1 : 0;
	for ( ; i < 4; i += 2 - includeWidth ) {
		which = cssExpand[ i ];
		attrs[ "margin" + which ] = attrs[ "padding" + which ] = type;
	}

	if ( includeWidth ) {
		attrs.opacity = attrs.width = type;
	}

	return attrs;
}

function createTween( value, prop, animation ) {
	var tween,
		collection = ( Animation.tweeners[ prop ] || [] ).concat( Animation.tweeners[ "*" ] ),
		index = 0,
		length = collection.length;
	for ( ; index < length; index++ ) {
		if ( ( tween = collection[ index ].call( animation, prop, value ) ) ) {

			// We're done with this property
			return tween;
		}
	}
}

function defaultPrefilter( elem, props, opts ) {
	var prop, value, toggle, hooks, oldfire, propTween, restoreDisplay, display,
		isBox = "width" in props || "height" in props,
		anim = this,
		orig = {},
		style = elem.style,
		hidden = elem.nodeType && isHiddenWithinTree( elem ),
		dataShow = dataPriv.get( elem, "fxshow" );

	// Queue-skipping animations hijack the fx hooks
	if ( !opts.queue ) {
		hooks = jQuery._queueHooks( elem, "fx" );
		if ( hooks.unqueued == null ) {
			hooks.unqueued = 0;
			oldfire = hooks.empty.fire;
			hooks.empty.fire = function() {
				if ( !hooks.unqueued ) {
					oldfire();
				}
			};
		}
		hooks.unqueued++;

		anim.always( function() {

			// Ensure the complete handler is called before this completes
			anim.always( function() {
				hooks.unqueued--;
				if ( !jQuery.queue( elem, "fx" ).length ) {
					hooks.empty.fire();
				}
			} );
		} );
	}

	// Detect show/hide animations
	for ( prop in props ) {
		value = props[ prop ];
		if ( rfxtypes.test( value ) ) {
			delete props[ prop ];
			toggle = toggle || value === "toggle";
			if ( value === ( hidden ? "hide" : "show" ) ) {

				// Pretend to be hidden if this is a "show" and
				// there is still data from a stopped show/hide
				if ( value === "show" && dataShow && dataShow[ prop ] !== undefined ) {
					hidden = true;

				// Ignore all other no-op show/hide data
				} else {
					continue;
				}
			}
			orig[ prop ] = dataShow && dataShow[ prop ] || jQuery.style( elem, prop );
		}
	}

	// Bail out if this is a no-op like .hide().hide()
	propTween = !jQuery.isEmptyObject( props );
	if ( !propTween && jQuery.isEmptyObject( orig ) ) {
		return;
	}

	// Restrict "overflow" and "display" styles during box animations
	if ( isBox && elem.nodeType === 1 ) {

		// Support: IE <=9 - 11, Edge 12 - 15
		// Record all 3 overflow attributes because IE does not infer the shorthand
		// from identically-valued overflowX and overflowY and Edge just mirrors
		// the overflowX value there.
		opts.overflow = [ style.overflow, style.overflowX, style.overflowY ];

		// Identify a display type, preferring old show/hide data over the CSS cascade
		restoreDisplay = dataShow && dataShow.display;
		if ( restoreDisplay == null ) {
			restoreDisplay = dataPriv.get( elem, "display" );
		}
		display = jQuery.css( elem, "display" );
		if ( display === "none" ) {
			if ( restoreDisplay ) {
				display = restoreDisplay;
			} else {

				// Get nonempty value(s) by temporarily forcing visibility
				showHide( [ elem ], true );
				restoreDisplay = elem.style.display || restoreDisplay;
				display = jQuery.css( elem, "display" );
				showHide( [ elem ] );
			}
		}

		// Animate inline elements as inline-block
		if ( display === "inline" || display === "inline-block" && restoreDisplay != null ) {
			if ( jQuery.css( elem, "float" ) === "none" ) {

				// Restore the original display value at the end of pure show/hide animations
				if ( !propTween ) {
					anim.done( function() {
						style.display = restoreDisplay;
					} );
					if ( restoreDisplay == null ) {
						display = style.display;
						restoreDisplay = display === "none" ? "" : display;
					}
				}
				style.display = "inline-block";
			}
		}
	}

	if ( opts.overflow ) {
		style.overflow = "hidden";
		anim.always( function() {
			style.overflow = opts.overflow[ 0 ];
			style.overflowX = opts.overflow[ 1 ];
			style.overflowY = opts.overflow[ 2 ];
		} );
	}

	// Implement show/hide animations
	propTween = false;
	for ( prop in orig ) {

		// General show/hide setup for this element animation
		if ( !propTween ) {
			if ( dataShow ) {
				if ( "hidden" in dataShow ) {
					hidden = dataShow.hidden;
				}
			} else {
				dataShow = dataPriv.access( elem, "fxshow", { display: restoreDisplay } );
			}

			// Store hidden/visible for toggle so `.stop().toggle()` "reverses"
			if ( toggle ) {
				dataShow.hidden = !hidden;
			}

			// Show elements before animating them
			if ( hidden ) {
				showHide( [ elem ], true );
			}

			/* eslint-disable no-loop-func */

			anim.done( function() {

				/* eslint-enable no-loop-func */

				// The final step of a "hide" animation is actually hiding the element
				if ( !hidden ) {
					showHide( [ elem ] );
				}
				dataPriv.remove( elem, "fxshow" );
				for ( prop in orig ) {
					jQuery.style( elem, prop, orig[ prop ] );
				}
			} );
		}

		// Per-property setup
		propTween = createTween( hidden ? dataShow[ prop ] : 0, prop, anim );
		if ( !( prop in dataShow ) ) {
			dataShow[ prop ] = propTween.start;
			if ( hidden ) {
				propTween.end = propTween.start;
				propTween.start = 0;
			}
		}
	}
}

function propFilter( props, specialEasing ) {
	var index, name, easing, value, hooks;

	// camelCase, specialEasing and expand cssHook pass
	for ( index in props ) {
		name = camelCase( index );
		easing = specialEasing[ name ];
		value = props[ index ];
		if ( Array.isArray( value ) ) {
			easing = value[ 1 ];
			value = props[ index ] = value[ 0 ];
		}

		if ( index !== name ) {
			props[ name ] = value;
			delete props[ index ];
		}

		hooks = jQuery.cssHooks[ name ];
		if ( hooks && "expand" in hooks ) {
			value = hooks.expand( value );
			delete props[ name ];

			// Not quite $.extend, this won't overwrite existing keys.
			// Reusing 'index' because we have the correct "name"
			for ( index in value ) {
				if ( !( index in props ) ) {
					props[ index ] = value[ index ];
					specialEasing[ index ] = easing;
				}
			}
		} else {
			specialEasing[ name ] = easing;
		}
	}
}

function Animation( elem, properties, options ) {
	var result,
		stopped,
		index = 0,
		length = Animation.prefilters.length,
		deferred = jQuery.Deferred().always( function() {

			// Don't match elem in the :animated selector
			delete tick.elem;
		} ),
		tick = function() {
			if ( stopped ) {
				return false;
			}
			var currentTime = fxNow || createFxNow(),
				remaining = Math.max( 0, animation.startTime + animation.duration - currentTime ),

				// Support: Android 2.3 only
				// Archaic crash bug won't allow us to use `1 - ( 0.5 || 0 )` (trac-12497)
				temp = remaining / animation.duration || 0,
				percent = 1 - temp,
				index = 0,
				length = animation.tweens.length;

			for ( ; index < length; index++ ) {
				animation.tweens[ index ].run( percent );
			}

			deferred.notifyWith( elem, [ animation, percent, remaining ] );

			// If there's more to do, yield
			if ( percent < 1 && length ) {
				return remaining;
			}

			// If this was an empty animation, synthesize a final progress notification
			if ( !length ) {
				deferred.notifyWith( elem, [ animation, 1, 0 ] );
			}

			// Resolve the animation and report its conclusion
			deferred.resolveWith( elem, [ animation ] );
			return false;
		},
		animation = deferred.promise( {
			elem: elem,
			props: jQuery.extend( {}, properties ),
			opts: jQuery.extend( true, {
				specialEasing: {},
				easing: jQuery.easing._default
			}, options ),
			originalProperties: properties,
			originalOptions: options,
			startTime: fxNow || createFxNow(),
			duration: options.duration,
			tweens: [],
			createTween: function( prop, end ) {
				var tween = jQuery.Tween( elem, animation.opts, prop, end,
					animation.opts.specialEasing[ prop ] || animation.opts.easing );
				animation.tweens.push( tween );
				return tween;
			},
			stop: function( gotoEnd ) {
				var index = 0,

					// If we are going to the end, we want to run all the tweens
					// otherwise we skip this part
					length = gotoEnd ? animation.tweens.length : 0;
				if ( stopped ) {
					return this;
				}
				stopped = true;
				for ( ; index < length; index++ ) {
					animation.tweens[ index ].run( 1 );
				}

				// Resolve when we played the last frame; otherwise, reject
				if ( gotoEnd ) {
					deferred.notifyWith( elem, [ animation, 1, 0 ] );
					deferred.resolveWith( elem, [ animation, gotoEnd ] );
				} else {
					deferred.rejectWith( elem, [ animation, gotoEnd ] );
				}
				return this;
			}
		} ),
		props = animation.props;

	propFilter( props, animation.opts.specialEasing );

	for ( ; index < length; index++ ) {
		result = Animation.prefilters[ index ].call( animation, elem, props, animation.opts );
		if ( result ) {
			if ( isFunction( result.stop ) ) {
				jQuery._queueHooks( animation.elem, animation.opts.queue ).stop =
					result.stop.bind( result );
			}
			return result;
		}
	}

	jQuery.map( props, createTween, animation );

	if ( isFunction( animation.opts.start ) ) {
		animation.opts.start.call( elem, animation );
	}

	// Attach callbacks from options
	animation
		.progress( animation.opts.progress )
		.done( animation.opts.done, animation.opts.complete )
		.fail( animation.opts.fail )
		.always( animation.opts.always );

	jQuery.fx.timer(
		jQuery.extend( tick, {
			elem: elem,
			anim: animation,
			queue: animation.opts.queue
		} )
	);

	return animation;
}

jQuery.Animation = jQuery.extend( Animation, {

	tweeners: {
		"*": [ function( prop, value ) {
			var tween = this.createTween( prop, value );
			adjustCSS( tween.elem, prop, rcssNum.exec( value ), tween );
			return tween;
		} ]
	},

	tweener: function( props, callback ) {
		if ( isFunction( props ) ) {
			callback = props;
			props = [ "*" ];
		} else {
			props = props.match( rnothtmlwhite );
		}

		var prop,
			index = 0,
			length = props.length;

		for ( ; index < length; index++ ) {
			prop = props[ index ];
			Animation.tweeners[ prop ] = Animation.tweeners[ prop ] || [];
			Animation.tweeners[ prop ].unshift( callback );
		}
	},

	prefilters: [ defaultPrefilter ],

	prefilter: function( callback, prepend ) {
		if ( prepend ) {
			Animation.prefilters.unshift( callback );
		} else {
			Animation.prefilters.push( callback );
		}
	}
} );

jQuery.speed = function( speed, easing, fn ) {
	var opt = speed && typeof speed === "object" ? jQuery.extend( {}, speed ) : {
		complete: fn || !fn && easing ||
			isFunction( speed ) && speed,
		duration: speed,
		easing: fn && easing || easing && !isFunction( easing ) && easing
	};

	// Go to the end state if fx are off
	if ( jQuery.fx.off ) {
		opt.duration = 0;

	} else {
		if ( typeof opt.duration !== "number" ) {
			if ( opt.duration in jQuery.fx.speeds ) {
				opt.duration = jQuery.fx.speeds[ opt.duration ];

			} else {
				opt.duration = jQuery.fx.speeds._default;
			}
		}
	}

	// Normalize opt.queue - true/undefined/null -> "fx"
	if ( opt.queue == null || opt.queue === true ) {
		opt.queue = "fx";
	}

	// Queueing
	opt.old = opt.complete;

	opt.complete = function() {
		if ( isFunction( opt.old ) ) {
			opt.old.call( this );
		}

		if ( opt.queue ) {
			jQuery.dequeue( this, opt.queue );
		}
	};

	return opt;
};

jQuery.fn.extend( {
	fadeTo: function( speed, to, easing, callback ) {

		// Show any hidden elements after setting opacity to 0
		return this.filter( isHiddenWithinTree ).css( "opacity", 0 ).show()

			// Animate to the value specified
			.end().animate( { opacity: to }, speed, easing, callback );
	},
	animate: function( prop, speed, easing, callback ) {
		var empty = jQuery.isEmptyObject( prop ),
			optall = jQuery.speed( speed, easing, callback ),
			doAnimation = function() {

				// Operate on a copy of prop so per-property easing won't be lost
				var anim = Animation( this, jQuery.extend( {}, prop ), optall );

				// Empty animations, or finishing resolves immediately
				if ( empty || dataPriv.get( this, "finish" ) ) {
					anim.stop( true );
				}
			};

		doAnimation.finish = doAnimation;

		return empty || optall.queue === false ?
			this.each( doAnimation ) :
			this.queue( optall.queue, doAnimation );
	},
	stop: function( type, clearQueue, gotoEnd ) {
		var stopQueue = function( hooks ) {
			var stop = hooks.stop;
			delete hooks.stop;
			stop( gotoEnd );
		};

		if ( typeof type !== "string" ) {
			gotoEnd = clearQueue;
			clearQueue = type;
			type = undefined;
		}
		if ( clearQueue ) {
			this.queue( type || "fx", [] );
		}

		return this.each( function() {
			var dequeue = true,
				index = type != null && type + "queueHooks",
				timers = jQuery.timers,
				data = dataPriv.get( this );

			if ( index ) {
				if ( data[ index ] && data[ index ].stop ) {
					stopQueue( data[ index ] );
				}
			} else {
				for ( index in data ) {
					if ( data[ index ] && data[ index ].stop && rrun.test( index ) ) {
						stopQueue( data[ index ] );
					}
				}
			}

			for ( index = timers.length; index--; ) {
				if ( timers[ index ].elem === this &&
					( type == null || timers[ index ].queue === type ) ) {

					timers[ index ].anim.stop( gotoEnd );
					dequeue = false;
					timers.splice( index, 1 );
				}
			}

			// Start the next in the queue if the last step wasn't forced.
			// Timers currently will call their complete callbacks, which
			// will dequeue but only if they were gotoEnd.
			if ( dequeue || !gotoEnd ) {
				jQuery.dequeue( this, type );
			}
		} );
	},
	finish: function( type ) {
		if ( type !== false ) {
			type = type || "fx";
		}
		return this.each( function() {
			var index,
				data = dataPriv.get( this ),
				queue = data[ type + "queue" ],
				hooks = data[ type + "queueHooks" ],
				timers = jQuery.timers,
				length = queue ? queue.length : 0;

			// Enable finishing flag on private data
			data.finish = true;

			// Empty the queue first
			jQuery.queue( this, type, [] );

			if ( hooks && hooks.stop ) {
				hooks.stop.call( this, true );
			}

			// Look for any active animations, and finish them
			for ( index = timers.length; index--; ) {
				if ( timers[ index ].elem === this && timers[ index ].queue === type ) {
					timers[ index ].anim.stop( true );
					timers.splice( index, 1 );
				}
			}

			// Look for any animations in the old queue and finish them
			for ( index = 0; index < length; index++ ) {
				if ( queue[ index ] && queue[ index ].finish ) {
					queue[ index ].finish.call( this );
				}
			}

			// Turn off finishing flag
			delete data.finish;
		} );
	}
} );

jQuery.each( [ "toggle", "show", "hide" ], function( _i, name ) {
	var cssFn = jQuery.fn[ name ];
	jQuery.fn[ name ] = function( speed, easing, callback ) {
		return speed == null || typeof speed === "boolean" ?
			cssFn.apply( this, arguments ) :
			this.animate( genFx( name, true ), speed, easing, callback );
	};
} );

// Generate shortcuts for custom animations
jQuery.each( {
	slideDown: genFx( "show" ),
	slideUp: genFx( "hide" ),
	slideToggle: genFx( "toggle" ),
	fadeIn: { opacity: "show" },
	fadeOut: { opacity: "hide" },
	fadeToggle: { opacity: "toggle" }
}, function( name, props ) {
	jQuery.fn[ name ] = function( speed, easing, callback ) {
		return this.animate( props, speed, easing, callback );
	};
} );

jQuery.timers = [];
jQuery.fx.tick = function() {
	var timer,
		i = 0,
		timers = jQuery.timers;

	fxNow = Date.now();

	for ( ; i < timers.length; i++ ) {
		timer = timers[ i ];

		// Run the timer and safely remove it when done (allowing for external removal)
		if ( !timer() && timers[ i ] === timer ) {
			timers.splice( i--, 1 );
		}
	}

	if ( !timers.length ) {
		jQuery.fx.stop();
	}
	fxNow = undefined;
};

jQuery.fx.timer = function( timer ) {
	jQuery.timers.push( timer );
	jQuery.fx.start();
};

jQuery.fx.interval = 13;
jQuery.fx.start = function() {
	if ( inProgress ) {
		return;
	}

	inProgress = true;
	schedule();
};

jQuery.fx.stop = function() {
	inProgress = null;
};

jQuery.fx.speeds = {
	slow: 600,
	fast: 200,

	// Default speed
	_default: 400
};


// Based off of the plugin by Clint Helfers, with permission.
jQuery.fn.delay = function( time, type ) {
	time = jQuery.fx ? jQuery.fx.speeds[ time ] || time : time;
	type = type || "fx";

	return this.queue( type, function( next, hooks ) {
		var timeout = window.setTimeout( next, time );
		hooks.stop = function() {
			window.clearTimeout( timeout );
		};
	} );
};


( function() {
	var input = document.createElement( "input" ),
		select = document.createElement( "select" ),
		opt = select.appendChild( document.createElement( "option" ) );

	input.type = "checkbox";

	// Support: Android <=4.3 only
	// Default value for a checkbox should be "on"
	support.checkOn = input.value !== "";

	// Support: IE <=11 only
	// Must access selectedIndex to make default options select
	support.optSelected = opt.selected;

	// Support: IE <=11 only
	// An input loses its value after becoming a radio
	input = document.createElement( "input" );
	input.value = "t";
	input.type = "radio";
	support.radioValue = input.value === "t";
} )();


var boolHook,
	attrHandle = jQuery.expr.attrHandle;

jQuery.fn.extend( {
	attr: function( name, value ) {
		return access( this, jQuery.attr, name, value, arguments.length > 1 );
	},

	removeAttr: function( name ) {
		return this.each( function() {
			jQuery.removeAttr( this, name );
		} );
	}
} );

jQuery.extend( {
	attr: function( elem, name, value ) {
		var ret, hooks,
			nType = elem.nodeType;

		// Don't get/set attributes on text, comment and attribute nodes
		if ( nType === 3 || nType === 8 || nType === 2 ) {
			return;
		}

		// Fallback to prop when attributes are not supported
		if ( typeof elem.getAttribute === "undefined" ) {
			return jQuery.prop( elem, name, value );
		}

		// Attribute hooks are determined by the lowercase version
		// Grab necessary hook if one is defined
		if ( nType !== 1 || !jQuery.isXMLDoc( elem ) ) {
			hooks = jQuery.attrHooks[ name.toLowerCase() ] ||
				( jQuery.expr.match.bool.test( name ) ? boolHook : undefined );
		}

		if ( value !== undefined ) {
			if ( value === null ) {
				jQuery.removeAttr( elem, name );
				return;
			}

			if ( hooks && "set" in hooks &&
				( ret = hooks.set( elem, value, name ) ) !== undefined ) {
				return ret;
			}

			elem.setAttribute( name, value + "" );
			return value;
		}

		if ( hooks && "get" in hooks && ( ret = hooks.get( elem, name ) ) !== null ) {
			return ret;
		}

		ret = jQuery.find.attr( elem, name );

		// Non-existent attributes return null, we normalize to undefined
		return ret == null ? undefined : ret;
	},

	attrHooks: {
		type: {
			set: function( elem, value ) {
				if ( !support.radioValue && value === "radio" &&
					nodeName( elem, "input" ) ) {
					var val = elem.value;
					elem.setAttribute( "type", value );
					if ( val ) {
						elem.value = val;
					}
					return value;
				}
			}
		}
	},

	removeAttr: function( elem, value ) {
		var name,
			i = 0,

			// Attribute names can contain non-HTML whitespace characters
			// https://html.spec.whatwg.org/multipage/syntax.html#attributes-2
			attrNames = value && value.match( rnothtmlwhite );

		if ( attrNames && elem.nodeType === 1 ) {
			while ( ( name = attrNames[ i++ ] ) ) {
				elem.removeAttribute( name );
			}
		}
	}
} );

// Hooks for boolean attributes
boolHook = {
	set: function( elem, value, name ) {
		if ( value === false ) {

			// Remove boolean attributes when set to false
			jQuery.removeAttr( elem, name );
		} else {
			elem.setAttribute( name, name );
		}
		return name;
	}
};

jQuery.each( jQuery.expr.match.bool.source.match( /\w+/g ), function( _i, name ) {
	var getter = attrHandle[ name ] || jQuery.find.attr;

	attrHandle[ name ] = function( elem, name, isXML ) {
		var ret, handle,
			lowercaseName = name.toLowerCase();

		if ( !isXML ) {

			// Avoid an infinite loop by temporarily removing this function from the getter
			handle = attrHandle[ lowercaseName ];
			attrHandle[ lowercaseName ] = ret;
			ret = getter( elem, name, isXML ) != null ?
				lowercaseName :
				null;
			attrHandle[ lowercaseName ] = handle;
		}
		return ret;
	};
} );




var rfocusable = /^(?:input|select|textarea|button)$/i,
	rclickable = /^(?:a|area)$/i;

jQuery.fn.extend( {
	prop: function( name, value ) {
		return access( this, jQuery.prop, name, value, arguments.length > 1 );
	},

	removeProp: function( name ) {
		return this.each( function() {
			delete this[ jQuery.propFix[ name ] || name ];
		} );
	}
} );

jQuery.extend( {
	prop: function( elem, name, value ) {
		var ret, hooks,
			nType = elem.nodeType;

		// Don't get/set properties on text, comment and attribute nodes
		if ( nType === 3 || nType === 8 || nType === 2 ) {
			return;
		}

		if ( nType !== 1 || !jQuery.isXMLDoc( elem ) ) {

			// Fix name and attach hooks
			name = jQuery.propFix[ name ] || name;
			hooks = jQuery.propHooks[ name ];
		}

		if ( value !== undefined ) {
			if ( hooks && "set" in hooks &&
				( ret = hooks.set( elem, value, name ) ) !== undefined ) {
				return ret;
			}

			return ( elem[ name ] = value );
		}

		if ( hooks && "get" in hooks && ( ret = hooks.get( elem, name ) ) !== null ) {
			return ret;
		}

		return elem[ name ];
	},

	propHooks: {
		tabIndex: {
			get: function( elem ) {

				// Support: IE <=9 - 11 only
				// elem.tabIndex doesn't always return the
				// correct value when it hasn't been explicitly set
				// Use proper attribute retrieval (trac-12072)
				var tabindex = jQuery.find.attr( elem, "tabindex" );

				if ( tabindex ) {
					return parseInt( tabindex, 10 );
				}

				if (
					rfocusable.test( elem.nodeName ) ||
					rclickable.test( elem.nodeName ) &&
					elem.href
				) {
					return 0;
				}

				return -1;
			}
		}
	},

	propFix: {
		"for": "htmlFor",
		"class": "className"
	}
} );

// Support: IE <=11 only
// Accessing the selectedIndex property
// forces the browser to respect setting selected
// on the option
// The getter ensures a default option is selected
// when in an optgroup
// eslint rule "no-unused-expressions" is disabled for this code
// since it considers such accessions noop
if ( !support.optSelected ) {
	jQuery.propHooks.selected = {
		get: function( elem ) {

			/* eslint no-unused-expressions: "off" */

			var parent = elem.parentNode;
			if ( parent && parent.parentNode ) {
				parent.parentNode.selectedIndex;
			}
			return null;
		},
		set: function( elem ) {

			/* eslint no-unused-expressions: "off" */

			var parent = elem.parentNode;
			if ( parent ) {
				parent.selectedIndex;

				if ( parent.parentNode ) {
					parent.parentNode.selectedIndex;
				}
			}
		}
	};
}

jQuery.each( [
	"tabIndex",
	"readOnly",
	"maxLength",
	"cellSpacing",
	"cellPadding",
	"rowSpan",
	"colSpan",
	"useMap",
	"frameBorder",
	"contentEditable"
], function() {
	jQuery.propFix[ this.toLowerCase() ] = this;
} );




	// Strip and collapse whitespace according to HTML spec
	// https://infra.spec.whatwg.org/#strip-and-collapse-ascii-whitespace
	function stripAndCollapse( value ) {
		var tokens = value.match( rnothtmlwhite ) || [];
		return tokens.join( " " );
	}


function getClass( elem ) {
	return elem.getAttribute && elem.getAttribute( "class" ) || "";
}

function classesToArray( value ) {
	if ( Array.isArray( value ) ) {
		return value;
	}
	if ( typeof value === "string" ) {
		return value.match( rnothtmlwhite ) || [];
	}
	return [];
}

jQuery.fn.extend( {
	addClass: function( value ) {
		var classNames, cur, curValue, className, i, finalValue;

		if ( isFunction( value ) ) {
			return this.each( function( j ) {
				jQuery( this ).addClass( value.call( this, j, getClass( this ) ) );
			} );
		}

		classNames = classesToArray( value );

		if ( classNames.length ) {
			return this.each( function() {
				curValue = getClass( this );
				cur = this.nodeType === 1 && ( " " + stripAndCollapse( curValue ) + " " );

				if ( cur ) {
					for ( i = 0; i < classNames.length; i++ ) {
						className = classNames[ i ];
						if ( cur.indexOf( " " + className + " " ) < 0 ) {
							cur += className + " ";
						}
					}

					// Only assign if different to avoid unneeded rendering.
					finalValue = stripAndCollapse( cur );
					if ( curValue !== finalValue ) {
						this.setAttribute( "class", finalValue );
					}
				}
			} );
		}

		return this;
	},

	removeClass: function( value ) {
		var classNames, cur, curValue, className, i, finalValue;

		if ( isFunction( value ) ) {
			return this.each( function( j ) {
				jQuery( this ).removeClass( value.call( this, j, getClass( this ) ) );
			} );
		}

		if ( !arguments.length ) {
			return this.attr( "class", "" );
		}

		classNames = classesToArray( value );

		if ( classNames.length ) {
			return this.each( function() {
				curValue = getClass( this );

				// This expression is here for better compressibility (see addClass)
				cur = this.nodeType === 1 && ( " " + stripAndCollapse( curValue ) + " " );

				if ( cur ) {
					for ( i = 0; i < classNames.length; i++ ) {
						className = classNames[ i ];

						// Remove *all* instances
						while ( cur.indexOf( " " + className + " " ) > -1 ) {
							cur = cur.replace( " " + className + " ", " " );
						}
					}

					// Only assign if different to avoid unneeded rendering.
					finalValue = stripAndCollapse( cur );
					if ( curValue !== finalValue ) {
						this.setAttribute( "class", finalValue );
					}
				}
			} );
		}

		return this;
	},

	toggleClass: function( value, stateVal ) {
		var classNames, className, i, self,
			type = typeof value,
			isValidValue = type === "string" || Array.isArray( value );

		if ( isFunction( value ) ) {
			return this.each( function( i ) {
				jQuery( this ).toggleClass(
					value.call( this, i, getClass( this ), stateVal ),
					stateVal
				);
			} );
		}

		if ( typeof stateVal === "boolean" && isValidValue ) {
			return stateVal ? this.addClass( value ) : this.removeClass( value );
		}

		classNames = classesToArray( value );

		return this.each( function() {
			if ( isValidValue ) {

				// Toggle individual class names
				self = jQuery( this );

				for ( i = 0; i < classNames.length; i++ ) {
					className = classNames[ i ];

					// Check each className given, space separated list
					if ( self.hasClass( className ) ) {
						self.removeClass( className );
					} else {
						self.addClass( className );
					}
				}

			// Toggle whole class name
			} else if ( value === undefined || type === "boolean" ) {
				className = getClass( this );
				if ( className ) {

					// Store className if set
					dataPriv.set( this, "__className__", className );
				}

				// If the element has a class name or if we're passed `false`,
				// then remove the whole classname (if there was one, the above saved it).
				// Otherwise bring back whatever was previously saved (if anything),
				// falling back to the empty string if nothing was stored.
				if ( this.setAttribute ) {
					this.setAttribute( "class",
						className || value === false ?
							"" :
							dataPriv.get( this, "__className__" ) || ""
					);
				}
			}
		} );
	},

	hasClass: function( selector ) {
		var className, elem,
			i = 0;

		className = " " + selector + " ";
		while ( ( elem = this[ i++ ] ) ) {
			if ( elem.nodeType === 1 &&
				( " " + stripAndCollapse( getClass( elem ) ) + " " ).indexOf( className ) > -1 ) {
				return true;
			}
		}

		return false;
	}
} );




var rreturn = /\r/g;

jQuery.fn.extend( {
	val: function( value ) {
		var hooks, ret, valueIsFunction,
			elem = this[ 0 ];

		if ( !arguments.length ) {
			if ( elem ) {
				hooks = jQuery.valHooks[ elem.type ] ||
					jQuery.valHooks[ elem.nodeName.toLowerCase() ];

				if ( hooks &&
					"get" in hooks &&
					( ret = hooks.get( elem, "value" ) ) !== undefined
				) {
					return ret;
				}

				ret = elem.value;

				// Handle most common string cases
				if ( typeof ret === "string" ) {
					return ret.replace( rreturn, "" );
				}

				// Handle cases where value is null/undef or number
				return ret == null ? "" : ret;
			}

			return;
		}

		valueIsFunction = isFunction( value );

		return this.each( function( i ) {
			var val;

			if ( this.nodeType !== 1 ) {
				return;
			}

			if ( valueIsFunction ) {
				val = value.call( this, i, jQuery( this ).val() );
			} else {
				val = value;
			}

			// Treat null/undefined as ""; convert numbers to string
			if ( val == null ) {
				val = "";

			} else if ( typeof val === "number" ) {
				val += "";

			} else if ( Array.isArray( val ) ) {
				val = jQuery.map( val, function( value ) {
					return value == null ? "" : value + "";
				} );
			}

			hooks = jQuery.valHooks[ this.type ] || jQuery.valHooks[ this.nodeName.toLowerCase() ];

			// If set returns undefined, fall back to normal setting
			if ( !hooks || !( "set" in hooks ) || hooks.set( this, val, "value" ) === undefined ) {
				this.value = val;
			}
		} );
	}
} );

jQuery.extend( {
	valHooks: {
		option: {
			get: function( elem ) {

				var val = jQuery.find.attr( elem, "value" );
				return val != null ?
					val :

					// Support: IE <=10 - 11 only
					// option.text throws exceptions (trac-14686, trac-14858)
					// Strip and collapse whitespace
					// https://html.spec.whatwg.org/#strip-and-collapse-whitespace
					stripAndCollapse( jQuery.text( elem ) );
			}
		},
		select: {
			get: function( elem ) {
				var value, option, i,
					options = elem.options,
					index = elem.selectedIndex,
					one = elem.type === "select-one",
					values = one ? null : [],
					max = one ? index + 1 : options.length;

				if ( index < 0 ) {
					i = max;

				} else {
					i = one ? index : 0;
				}

				// Loop through all the selected options
				for ( ; i < max; i++ ) {
					option = options[ i ];

					// Support: IE <=9 only
					// IE8-9 doesn't update selected after form reset (trac-2551)
					if ( ( option.selected || i === index ) &&

							// Don't return options that are disabled or in a disabled optgroup
							!option.disabled &&
							( !option.parentNode.disabled ||
								!nodeName( option.parentNode, "optgroup" ) ) ) {

						// Get the specific value for the option
						value = jQuery( option ).val();

						// We don't need an array for one selects
						if ( one ) {
							return value;
						}

						// Multi-Selects return an array
						values.push( value );
					}
				}

				return values;
			},

			set: function( elem, value ) {
				var optionSet, option,
					options = elem.options,
					values = jQuery.makeArray( value ),
					i = options.length;

				while ( i-- ) {
					option = options[ i ];

					/* eslint-disable no-cond-assign */

					if ( option.selected =
						jQuery.inArray( jQuery.valHooks.option.get( option ), values ) > -1
					) {
						optionSet = true;
					}

					/* eslint-enable no-cond-assign */
				}

				// Force browsers to behave consistently when non-matching value is set
				if ( !optionSet ) {
					elem.selectedIndex = -1;
				}
				return values;
			}
		}
	}
} );

// Radios and checkboxes getter/setter
jQuery.each( [ "radio", "checkbox" ], function() {
	jQuery.valHooks[ this ] = {
		set: function( elem, value ) {
			if ( Array.isArray( value ) ) {
				return ( elem.checked = jQuery.inArray( jQuery( elem ).val(), value ) > -1 );
			}
		}
	};
	if ( !support.checkOn ) {
		jQuery.valHooks[ this ].get = function( elem ) {
			return elem.getAttribute( "value" ) === null ? "on" : elem.value;
		};
	}
} );




// Return jQuery for attributes-only inclusion


support.focusin = "onfocusin" in window;


var rfocusMorph = /^(?:focusinfocus|focusoutblur)$/,
	stopPropagationCallback = function( e ) {
		e.stopPropagation();
	};

jQuery.extend( jQuery.event, {

	trigger: function( event, data, elem, onlyHandlers ) {

		var i, cur, tmp, bubbleType, ontype, handle, special, lastElement,
			eventPath = [ elem || document ],
			type = hasOwn.call( event, "type" ) ? event.type : event,
			namespaces = hasOwn.call( event, "namespace" ) ? event.namespace.split( "." ) : [];

		cur = lastElement = tmp = elem = elem || document;

		// Don't do events on text and comment nodes
		if ( elem.nodeType === 3 || elem.nodeType === 8 ) {
			return;
		}

		// focus/blur morphs to focusin/out; ensure we're not firing them right now
		if ( rfocusMorph.test( type + jQuery.event.triggered ) ) {
			return;
		}

		if ( type.indexOf( "." ) > -1 ) {

			// Namespaced trigger; create a regexp to match event type in handle()
			namespaces = type.split( "." );
			type = namespaces.shift();
			namespaces.sort();
		}
		ontype = type.indexOf( ":" ) < 0 && "on" + type;

		// Caller can pass in a jQuery.Event object, Object, or just an event type string
		event = event[ jQuery.expando ] ?
			event :
			new jQuery.Event( type, typeof event === "object" && event );

		// Trigger bitmask: & 1 for native handlers; & 2 for jQuery (always true)
		event.isTrigger = onlyHandlers ? 2 : 3;
		event.namespace = namespaces.join( "." );
		event.rnamespace = event.namespace ?
			new RegExp( "(^|\\.)" + namespaces.join( "\\.(?:.*\\.|)" ) + "(\\.|$)" ) :
			null;

		// Clean up the event in case it is being reused
		event.result = undefined;
		if ( !event.target ) {
			event.target = elem;
		}

		// Clone any incoming data and prepend the event, creating the handler arg list
		data = data == null ?
			[ event ] :
			jQuery.makeArray( data, [ event ] );

		// Allow special events to draw outside the lines
		special = jQuery.event.special[ type ] || {};
		if ( !onlyHandlers && special.trigger && special.trigger.apply( elem, data ) === false ) {
			return;
		}

		// Determine event propagation path in advance, per W3C events spec (trac-9951)
		// Bubble up to document, then to window; watch for a global ownerDocument var (trac-9724)
		if ( !onlyHandlers && !special.noBubble && !isWindow( elem ) ) {

			bubbleType = special.delegateType || type;
			if ( !rfocusMorph.test( bubbleType + type ) ) {
				cur = cur.parentNode;
			}
			for ( ; cur; cur = cur.parentNode ) {
				eventPath.push( cur );
				tmp = cur;
			}

			// Only add window if we got to document (e.g., not plain obj or detached DOM)
			if ( tmp === ( elem.ownerDocument || document ) ) {
				eventPath.push( tmp.defaultView || tmp.parentWindow || window );
			}
		}

		// Fire handlers on the event path
		i = 0;
		while ( ( cur = eventPath[ i++ ] ) && !event.isPropagationStopped() ) {
			lastElement = cur;
			event.type = i > 1 ?
				bubbleType :
				special.bindType || type;

			// jQuery handler
			handle = ( dataPriv.get( cur, "events" ) || Object.create( null ) )[ event.type ] &&
				dataPriv.get( cur, "handle" );
			if ( handle ) {
				handle.apply( cur, data );
			}

			// Native handler
			handle = ontype && cur[ ontype ];
			if ( handle && handle.apply && acceptData( cur ) ) {
				event.result = handle.apply( cur, data );
				if ( event.result === false ) {
					event.preventDefault();
				}
			}
		}
		event.type = type;

		// If nobody prevented the default action, do it now
		if ( !onlyHandlers && !event.isDefaultPrevented() ) {

			if ( ( !special._default ||
				special._default.apply( eventPath.pop(), data ) === false ) &&
				acceptData( elem ) ) {

				// Call a native DOM method on the target with the same name as the event.
				// Don't do default actions on window, that's where global variables be (trac-6170)
				if ( ontype && isFunction( elem[ type ] ) && !isWindow( elem ) ) {

					// Don't re-trigger an onFOO event when we call its FOO() method
					tmp = elem[ ontype ];

					if ( tmp ) {
						elem[ ontype ] = null;
					}

					// Prevent re-triggering of the same event, since we already bubbled it above
					jQuery.event.triggered = type;

					if ( event.isPropagationStopped() ) {
						lastElement.addEventListener( type, stopPropagationCallback );
					}

					elem[ type ]();

					if ( event.isPropagationStopped() ) {
						lastElement.removeEventListener( type, stopPropagationCallback );
					}

					jQuery.event.triggered = undefined;

					if ( tmp ) {
						elem[ ontype ] = tmp;
					}
				}
			}
		}

		return event.result;
	},

	// Piggyback on a donor event to simulate a different one
	// Used only for `focus(in | out)` events
	simulate: function( type, elem, event ) {
		var e = jQuery.extend(
			new jQuery.Event(),
			event,
			{
				type: type,
				isSimulated: true
			}
		);

		jQuery.event.trigger( e, null, elem );
	}

} );

jQuery.fn.extend( {

	trigger: function( type, data ) {
		return this.each( function() {
			jQuery.event.trigger( type, data, this );
		} );
	},
	triggerHandler: function( type, data ) {
		var elem = this[ 0 ];
		if ( elem ) {
			return jQuery.event.trigger( type, data, elem, true );
		}
	}
} );


// Support: Firefox <=44
// Firefox doesn't have focus(in | out) events
// Related ticket - https://bugzilla.mozilla.org/show_bug.cgi?id=687787
//
// Support: Chrome <=48 - 49, Safari <=9.0 - 9.1
// focus(in | out) events fire after focus & blur events,
// which is spec violation - http://www.w3.org/TR/DOM-Level-3-Events/#events-focusevent-event-order
// Related ticket - https://bugs.chromium.org/p/chromium/issues/detail?id=449857
if ( !support.focusin ) {
	jQuery.each( { focus: "focusin", blur: "focusout" }, function( orig, fix ) {

		// Attach a single capturing handler on the document while someone wants focusin/focusout
		var handler = function( event ) {
			jQuery.event.simulate( fix, event.target, jQuery.event.fix( event ) );
		};

		jQuery.event.special[ fix ] = {
			setup: function() {

				// Handle: regular nodes (via `this.ownerDocument`), window
				// (via `this.document`) & document (via `this`).
				var doc = this.ownerDocument || this.document || this,
					attaches = dataPriv.access( doc, fix );

				if ( !attaches ) {
					doc.addEventListener( orig, handler, true );
				}
				dataPriv.access( doc, fix, ( attaches || 0 ) + 1 );
			},
			teardown: function() {
				var doc = this.ownerDocument || this.document || this,
					attaches = dataPriv.access( doc, fix ) - 1;

				if ( !attaches ) {
					doc.removeEventListener( orig, handler, true );
					dataPriv.remove( doc, fix );

				} else {
					dataPriv.access( doc, fix, attaches );
				}
			}
		};
	} );
}
var location = window.location;

var nonce = { guid: Date.now() };

var rquery = ( /\?/ );



// Cross-browser xml parsing
jQuery.parseXML = function( data ) {
	var xml, parserErrorElem;
	if ( !data || typeof data !== "string" ) {
		return null;
	}

	// Support: IE 9 - 11 only
	// IE throws on parseFromString with invalid input.
	try {
		xml = ( new window.DOMParser() ).parseFromString( data, "text/xml" );
	} catch ( e ) {}

	parserErrorElem = xml && xml.getElementsByTagName( "parsererror" )[ 0 ];
	if ( !xml || parserErrorElem ) {
		jQuery.error( "Invalid XML: " + (
			parserErrorElem ?
				jQuery.map( parserErrorElem.childNodes, function( el ) {
					return el.textContent;
				} ).join( "\n" ) :
				data
		) );
	}
	return xml;
};


var
	rbracket = /\[\]$/,
	rCRLF = /\r?\n/g,
	rsubmitterTypes = /^(?:submit|button|image|reset|file)$/i,
	rsubmittable = /^(?:input|select|textarea|keygen)/i;

function buildParams( prefix, obj, traditional, add ) {
	var name;

	if ( Array.isArray( obj ) ) {

		// Serialize array item.
		jQuery.each( obj, function( i, v ) {
			if ( traditional || rbracket.test( prefix ) ) {

				// Treat each array item as a scalar.
				add( prefix, v );

			} else {

				// Item is non-scalar (array or object), encode its numeric index.
				buildParams(
					prefix + "[" + ( typeof v === "object" && v != null ? i : "" ) + "]",
					v,
					traditional,
					add
				);
			}
		} );

	} else if ( !traditional && toType( obj ) === "object" ) {

		// Serialize object item.
		for ( name in obj ) {
			buildParams( prefix + "[" + name + "]", obj[ name ], traditional, add );
		}

	} else {

		// Serialize scalar item.
		add( prefix, obj );
	}
}

// Serialize an array of form elements or a set of
// key/values into a query string
jQuery.param = function( a, traditional ) {
	var prefix,
		s = [],
		add = function( key, valueOrFunction ) {

			// If value is a function, invoke it and use its return value
			var value = isFunction( valueOrFunction ) ?
				valueOrFunction() :
				valueOrFunction;

			s[ s.length ] = encodeURIComponent( key ) + "=" +
				encodeURIComponent( value == null ? "" : value );
		};

	if ( a == null ) {
		return "";
	}

	// If an array was passed in, assume that it is an array of form elements.
	if ( Array.isArray( a ) || ( a.jquery && !jQuery.isPlainObject( a ) ) ) {

		// Serialize the form elements
		jQuery.each( a, function() {
			add( this.name, this.value );
		} );

	} else {

		// If traditional, encode the "old" way (the way 1.3.2 or older
		// did it), otherwise encode params recursively.
		for ( prefix in a ) {
			buildParams( prefix, a[ prefix ], traditional, add );
		}
	}

	// Return the resulting serialization
	return s.join( "&" );
};

jQuery.fn.extend( {
	serialize: function() {
		return jQuery.param( this.serializeArray() );
	},
	serializeArray: function() {
		return this.map( function() {

			// Can add propHook for "elements" to filter or add form elements
			var elements = jQuery.prop( this, "elements" );
			return elements ? jQuery.makeArray( elements ) : this;
		} ).filter( function() {
			var type = this.type;

			// Use .is( ":disabled" ) so that fieldset[disabled] works
			return this.name && !jQuery( this ).is( ":disabled" ) &&
				rsubmittable.test( this.nodeName ) && !rsubmitterTypes.test( type ) &&
				( this.checked || !rcheckableType.test( type ) );
		} ).map( function( _i, elem ) {
			var val = jQuery( this ).val();

			if ( val == null ) {
				return null;
			}

			if ( Array.isArray( val ) ) {
				return jQuery.map( val, function( val ) {
					return { name: elem.name, value: val.replace( rCRLF, "\r\n" ) };
				} );
			}

			return { name: elem.name, value: val.replace( rCRLF, "\r\n" ) };
		} ).get();
	}
} );


var
	r20 = /%20/g,
	rhash = /#.*$/,
	rantiCache = /([?&])_=[^&]*/,
	rheaders = /^(.*?):[ \t]*([^\r\n]*)$/mg,

	// trac-7653, trac-8125, trac-8152: local protocol detection
	rlocalProtocol = /^(?:about|app|app-storage|.+-extension|file|res|widget):$/,
	rnoContent = /^(?:GET|HEAD)$/,
	rprotocol = /^\/\//,

	/* Prefilters
	 * 1) They are useful to introduce custom dataTypes (see ajax/jsonp.js for an example)
	 * 2) These are called:
	 *    - BEFORE asking for a transport
	 *    - AFTER param serialization (s.data is a string if s.processData is true)
	 * 3) key is the dataType
	 * 4) the catchall symbol "*" can be used
	 * 5) execution will start with transport dataType and THEN continue down to "*" if needed
	 */
	prefilters = {},

	/* Transports bindings
	 * 1) key is the dataType
	 * 2) the catchall symbol "*" can be used
	 * 3) selection will start with transport dataType and THEN go to "*" if needed
	 */
	transports = {},

	// Avoid comment-prolog char sequence (trac-10098); must appease lint and evade compression
	allTypes = "*/".concat( "*" ),

	// Anchor tag for parsing the document origin
	originAnchor = document.createElement( "a" );

originAnchor.href = location.href;

// Base "constructor" for jQuery.ajaxPrefilter and jQuery.ajaxTransport
function addToPrefiltersOrTransports( structure ) {

	// dataTypeExpression is optional and defaults to "*"
	return function( dataTypeExpression, func ) {

		if ( typeof dataTypeExpression !== "string" ) {
			func = dataTypeExpression;
			dataTypeExpression = "*";
		}

		var dataType,
			i = 0,
			dataTypes = dataTypeExpression.toLowerCase().match( rnothtmlwhite ) || [];

		if ( isFunction( func ) ) {

			// For each dataType in the dataTypeExpression
			while ( ( dataType = dataTypes[ i++ ] ) ) {

				// Prepend if requested
				if ( dataType[ 0 ] === "+" ) {
					dataType = dataType.slice( 1 ) || "*";
					( structure[ dataType ] = structure[ dataType ] || [] ).unshift( func );

				// Otherwise append
				} else {
					( structure[ dataType ] = structure[ dataType ] || [] ).push( func );
				}
			}
		}
	};
}

// Base inspection function for prefilters and transports
function inspectPrefiltersOrTransports( structure, options, originalOptions, jqXHR ) {

	var inspected = {},
		seekingTransport = ( structure === transports );

	function inspect( dataType ) {
		var selected;
		inspected[ dataType ] = true;
		jQuery.each( structure[ dataType ] || [], function( _, prefilterOrFactory ) {
			var dataTypeOrTransport = prefilterOrFactory( options, originalOptions, jqXHR );
			if ( typeof dataTypeOrTransport === "string" &&
				!seekingTransport && !inspected[ dataTypeOrTransport ] ) {

				options.dataTypes.unshift( dataTypeOrTransport );
				inspect( dataTypeOrTransport );
				return false;
			} else if ( seekingTransport ) {
				return !( selected = dataTypeOrTransport );
			}
		} );
		return selected;
	}

	return inspect( options.dataTypes[ 0 ] ) || !inspected[ "*" ] && inspect( "*" );
}

// A special extend for ajax options
// that takes "flat" options (not to be deep extended)
// Fixes trac-9887
function ajaxExtend( target, src ) {
	var key, deep,
		flatOptions = jQuery.ajaxSettings.flatOptions || {};

	for ( key in src ) {
		if ( src[ key ] !== undefined ) {
			( flatOptions[ key ] ? target : ( deep || ( deep = {} ) ) )[ key ] = src[ key ];
		}
	}
	if ( deep ) {
		jQuery.extend( true, target, deep );
	}

	return target;
}

/* Handles responses to an ajax request:
 * - finds the right dataType (mediates between content-type and expected dataType)
 * - returns the corresponding response
 */
function ajaxHandleResponses( s, jqXHR, responses ) {

	var ct, type, finalDataType, firstDataType,
		contents = s.contents,
		dataTypes = s.dataTypes;

	// Remove auto dataType and get content-type in the process
	while ( dataTypes[ 0 ] === "*" ) {
		dataTypes.shift();
		if ( ct === undefined ) {
			ct = s.mimeType || jqXHR.getResponseHeader( "Content-Type" );
		}
	}

	// Check if we're dealing with a known content-type
	if ( ct ) {
		for ( type in contents ) {
			if ( contents[ type ] && contents[ type ].test( ct ) ) {
				dataTypes.unshift( type );
				break;
			}
		}
	}

	// Check to see if we have a response for the expected dataType
	if ( dataTypes[ 0 ] in responses ) {
		finalDataType = dataTypes[ 0 ];
	} else {

		// Try convertible dataTypes
		for ( type in responses ) {
			if ( !dataTypes[ 0 ] || s.converters[ type + " " + dataTypes[ 0 ] ] ) {
				finalDataType = type;
				break;
			}
			if ( !firstDataType ) {
				firstDataType = type;
			}
		}

		// Or just use first one
		finalDataType = finalDataType || firstDataType;
	}

	// If we found a dataType
	// We add the dataType to the list if needed
	// and return the corresponding response
	if ( finalDataType ) {
		if ( finalDataType !== dataTypes[ 0 ] ) {
			dataTypes.unshift( finalDataType );
		}
		return responses[ finalDataType ];
	}
}

/* Chain conversions given the request and the original response
 * Also sets the responseXXX fields on the jqXHR instance
 */
function ajaxConvert( s, response, jqXHR, isSuccess ) {
	var conv2, current, conv, tmp, prev,
		converters = {},

		// Work with a copy of dataTypes in case we need to modify it for conversion
		dataTypes = s.dataTypes.slice();

	// Create converters map with lowercased keys
	if ( dataTypes[ 1 ] ) {
		for ( conv in s.converters ) {
			converters[ conv.toLowerCase() ] = s.converters[ conv ];
		}
	}

	current = dataTypes.shift();

	// Convert to each sequential dataType
	while ( current ) {

		if ( s.responseFields[ current ] ) {
			jqXHR[ s.responseFields[ current ] ] = response;
		}

		// Apply the dataFilter if provided
		if ( !prev && isSuccess && s.dataFilter ) {
			response = s.dataFilter( response, s.dataType );
		}

		prev = current;
		current = dataTypes.shift();

		if ( current ) {

			// There's only work to do if current dataType is non-auto
			if ( current === "*" ) {

				current = prev;

			// Convert response if prev dataType is non-auto and differs from current
			} else if ( prev !== "*" && prev !== current ) {

				// Seek a direct converter
				conv = converters[ prev + " " + current ] || converters[ "* " + current ];

				// If none found, seek a pair
				if ( !conv ) {
					for ( conv2 in converters ) {

						// If conv2 outputs current
						tmp = conv2.split( " " );
						if ( tmp[ 1 ] === current ) {

							// If prev can be converted to accepted input
							conv = converters[ prev + " " + tmp[ 0 ] ] ||
								converters[ "* " + tmp[ 0 ] ];
							if ( conv ) {

								// Condense equivalence converters
								if ( conv === true ) {
									conv = converters[ conv2 ];

								// Otherwise, insert the intermediate dataType
								} else if ( converters[ conv2 ] !== true ) {
									current = tmp[ 0 ];
									dataTypes.unshift( tmp[ 1 ] );
								}
								break;
							}
						}
					}
				}

				// Apply converter (if not an equivalence)
				if ( conv !== true ) {

					// Unless errors are allowed to bubble, catch and return them
					if ( conv && s.throws ) {
						response = conv( response );
					} else {
						try {
							response = conv( response );
						} catch ( e ) {
							return {
								state: "parsererror",
								error: conv ? e : "No conversion from " + prev + " to " + current
							};
						}
					}
				}
			}
		}
	}

	return { state: "success", data: response };
}

jQuery.extend( {

	// Counter for holding the number of active queries
	active: 0,

	// Last-Modified header cache for next request
	lastModified: {},
	etag: {},

	ajaxSettings: {
		url: location.href,
		type: "GET",
		isLocal: rlocalProtocol.test( location.protocol ),
		global: true,
		processData: true,
		async: true,
		contentType: "application/x-www-form-urlencoded; charset=UTF-8",

		/*
		timeout: 0,
		data: null,
		dataType: null,
		username: null,
		password: null,
		cache: null,
		throws: false,
		traditional: false,
		headers: {},
		*/

		accepts: {
			"*": allTypes,
			text: "text/plain",
			html: "text/html",
			xml: "application/xml, text/xml",
			json: "application/json, text/javascript"
		},

		contents: {
			xml: /\bxml\b/,
			html: /\bhtml/,
			json: /\bjson\b/
		},

		responseFields: {
			xml: "responseXML",
			text: "responseText",
			json: "responseJSON"
		},

		// Data converters
		// Keys separate source (or catchall "*") and destination types with a single space
		converters: {

			// Convert anything to text
			"* text": String,

			// Text to html (true = no transformation)
			"text html": true,

			// Evaluate text as a json expression
			"text json": JSON.parse,

			// Parse text as xml
			"text xml": jQuery.parseXML
		},

		// For options that shouldn't be deep extended:
		// you can add your own custom options here if
		// and when you create one that shouldn't be
		// deep extended (see ajaxExtend)
		flatOptions: {
			url: true,
			context: true
		}
	},

	// Creates a full fledged settings object into target
	// with both ajaxSettings and settings fields.
	// If target is omitted, writes into ajaxSettings.
	ajaxSetup: function( target, settings ) {
		return settings ?

			// Building a settings object
			ajaxExtend( ajaxExtend( target, jQuery.ajaxSettings ), settings ) :

			// Extending ajaxSettings
			ajaxExtend( jQuery.ajaxSettings, target );
	},

	ajaxPrefilter: addToPrefiltersOrTransports( prefilters ),
	ajaxTransport: addToPrefiltersOrTransports( transports ),

	// Main method
	ajax: function( url, options ) {

		// If url is an object, simulate pre-1.5 signature
		if ( typeof url === "object" ) {
			options = url;
			url = undefined;
		}

		// Force options to be an object
		options = options || {};

		var transport,

			// URL without anti-cache param
			cacheURL,

			// Response headers
			responseHeadersString,
			responseHeaders,

			// timeout handle
			timeoutTimer,

			// Url cleanup var
			urlAnchor,

			// Request state (becomes false upon send and true upon completion)
			completed,

			// To know if global events are to be dispatched
			fireGlobals,

			// Loop variable
			i,

			// uncached part of the url
			uncached,

			// Create the final options object
			s = jQuery.ajaxSetup( {}, options ),

			// Callbacks context
			callbackContext = s.context || s,

			// Context for global events is callbackContext if it is a DOM node or jQuery collection
			globalEventContext = s.context &&
				( callbackContext.nodeType || callbackContext.jquery ) ?
				jQuery( callbackContext ) :
				jQuery.event,

			// Deferreds
			deferred = jQuery.Deferred(),
			completeDeferred = jQuery.Callbacks( "once memory" ),

			// Status-dependent callbacks
			statusCode = s.statusCode || {},

			// Headers (they are sent all at once)
			requestHeaders = {},
			requestHeadersNames = {},

			// Default abort message
			strAbort = "canceled",

			// Fake xhr
			jqXHR = {
				readyState: 0,

				// Builds headers hashtable if needed
				getResponseHeader: function( key ) {
					var match;
					if ( completed ) {
						if ( !responseHeaders ) {
							responseHeaders = {};
							while ( ( match = rheaders.exec( responseHeadersString ) ) ) {
								responseHeaders[ match[ 1 ].toLowerCase() + " " ] =
									( responseHeaders[ match[ 1 ].toLowerCase() + " " ] || [] )
										.concat( match[ 2 ] );
							}
						}
						match = responseHeaders[ key.toLowerCase() + " " ];
					}
					return match == null ? null : match.join( ", " );
				},

				// Raw string
				getAllResponseHeaders: function() {
					return completed ? responseHeadersString : null;
				},

				// Caches the header
				setRequestHeader: function( name, value ) {
					if ( completed == null ) {
						name = requestHeadersNames[ name.toLowerCase() ] =
							requestHeadersNames[ name.toLowerCase() ] || name;
						requestHeaders[ name ] = value;
					}
					return this;
				},

				// Overrides response content-type header
				overrideMimeType: function( type ) {
					if ( completed == null ) {
						s.mimeType = type;
					}
					return this;
				},

				// Status-dependent callbacks
				statusCode: function( map ) {
					var code;
					if ( map ) {
						if ( completed ) {

							// Execute the appropriate callbacks
							jqXHR.always( map[ jqXHR.status ] );
						} else {

							// Lazy-add the new callbacks in a way that preserves old ones
							for ( code in map ) {
								statusCode[ code ] = [ statusCode[ code ], map[ code ] ];
							}
						}
					}
					return this;
				},

				// Cancel the request
				abort: function( statusText ) {
					var finalText = statusText || strAbort;
					if ( transport ) {
						transport.abort( finalText );
					}
					done( 0, finalText );
					return this;
				}
			};

		// Attach deferreds
		deferred.promise( jqXHR );

		// Add protocol if not provided (prefilters might expect it)
		// Handle falsy url in the settings object (trac-10093: consistency with old signature)
		// We also use the url parameter if available
		s.url = ( ( url || s.url || location.href ) + "" )
			.replace( rprotocol, location.protocol + "//" );

		// Alias method option to type as per ticket trac-12004
		s.type = options.method || options.type || s.method || s.type;

		// Extract dataTypes list
		s.dataTypes = ( s.dataType || "*" ).toLowerCase().match( rnothtmlwhite ) || [ "" ];

		// A cross-domain request is in order when the origin doesn't match the current origin.
		if ( s.crossDomain == null ) {
			urlAnchor = document.createElement( "a" );

			// Support: IE <=8 - 11, Edge 12 - 15
			// IE throws exception on accessing the href property if url is malformed,
			// e.g. http://example.com:80x/
			try {
				urlAnchor.href = s.url;

				// Support: IE <=8 - 11 only
				// Anchor's host property isn't correctly set when s.url is relative
				urlAnchor.href = urlAnchor.href;
				s.crossDomain = originAnchor.protocol + "//" + originAnchor.host !==
					urlAnchor.protocol + "//" + urlAnchor.host;
			} catch ( e ) {

				// If there is an error parsing the URL, assume it is crossDomain,
				// it can be rejected by the transport if it is invalid
				s.crossDomain = true;
			}
		}

		// Convert data if not already a string
		if ( s.data && s.processData && typeof s.data !== "string" ) {
			s.data = jQuery.param( s.data, s.traditional );
		}

		// Apply prefilters
		inspectPrefiltersOrTransports( prefilters, s, options, jqXHR );

		// If request was aborted inside a prefilter, stop there
		if ( completed ) {
			return jqXHR;
		}

		// We can fire global events as of now if asked to
		// Don't fire events if jQuery.event is undefined in an AMD-usage scenario (trac-15118)
		fireGlobals = jQuery.event && s.global;

		// Watch for a new set of requests
		if ( fireGlobals && jQuery.active++ === 0 ) {
			jQuery.event.trigger( "ajaxStart" );
		}

		// Uppercase the type
		s.type = s.type.toUpperCase();

		// Determine if request has content
		s.hasContent = !rnoContent.test( s.type );

		// Save the URL in case we're toying with the If-Modified-Since
		// and/or If-None-Match header later on
		// Remove hash to simplify url manipulation
		cacheURL = s.url.replace( rhash, "" );

		// More options handling for requests with no content
		if ( !s.hasContent ) {

			// Remember the hash so we can put it back
			uncached = s.url.slice( cacheURL.length );

			// If data is available and should be processed, append data to url
			if ( s.data && ( s.processData || typeof s.data === "string" ) ) {
				cacheURL += ( rquery.test( cacheURL ) ? "&" : "?" ) + s.data;

				// trac-9682: remove data so that it's not used in an eventual retry
				delete s.data;
			}

			// Add or update anti-cache param if needed
			if ( s.cache === false ) {
				cacheURL = cacheURL.replace( rantiCache, "$1" );
				uncached = ( rquery.test( cacheURL ) ? "&" : "?" ) + "_=" + ( nonce.guid++ ) +
					uncached;
			}

			// Put hash and anti-cache on the URL that will be requested (gh-1732)
			s.url = cacheURL + uncached;

		// Change '%20' to '+' if this is encoded form body content (gh-2658)
		} else if ( s.data && s.processData &&
			( s.contentType || "" ).indexOf( "application/x-www-form-urlencoded" ) === 0 ) {
			s.data = s.data.replace( r20, "+" );
		}

		// Set the If-Modified-Since and/or If-None-Match header, if in ifModified mode.
		if ( s.ifModified ) {
			if ( jQuery.lastModified[ cacheURL ] ) {
				jqXHR.setRequestHeader( "If-Modified-Since", jQuery.lastModified[ cacheURL ] );
			}
			if ( jQuery.etag[ cacheURL ] ) {
				jqXHR.setRequestHeader( "If-None-Match", jQuery.etag[ cacheURL ] );
			}
		}

		// Set the correct header, if data is being sent
		if ( s.data && s.hasContent && s.contentType !== false || options.contentType ) {
			jqXHR.setRequestHeader( "Content-Type", s.contentType );
		}

		// Set the Accepts header for the server, depending on the dataType
		jqXHR.setRequestHeader(
			"Accept",
			s.dataTypes[ 0 ] && s.accepts[ s.dataTypes[ 0 ] ] ?
				s.accepts[ s.dataTypes[ 0 ] ] +
					( s.dataTypes[ 0 ] !== "*" ? ", " + allTypes + "; q=0.01" : "" ) :
				s.accepts[ "*" ]
		);

		// Check for headers option
		for ( i in s.headers ) {
			jqXHR.setRequestHeader( i, s.headers[ i ] );
		}

		// Allow custom headers/mimetypes and early abort
		if ( s.beforeSend &&
			( s.beforeSend.call( callbackContext, jqXHR, s ) === false || completed ) ) {

			// Abort if not done already and return
			return jqXHR.abort();
		}

		// Aborting is no longer a cancellation
		strAbort = "abort";

		// Install callbacks on deferreds
		completeDeferred.add( s.complete );
		jqXHR.done( s.success );
		jqXHR.fail( s.error );

		// Get transport
		transport = inspectPrefiltersOrTransports( transports, s, options, jqXHR );

		// If no transport, we auto-abort
		if ( !transport ) {
			done( -1, "No Transport" );
		} else {
			jqXHR.readyState = 1;

			// Send global event
			if ( fireGlobals ) {
				globalEventContext.trigger( "ajaxSend", [ jqXHR, s ] );
			}

			// If request was aborted inside ajaxSend, stop there
			if ( completed ) {
				return jqXHR;
			}

			// Timeout
			if ( s.async && s.timeout > 0 ) {
				timeoutTimer = window.setTimeout( function() {
					jqXHR.abort( "timeout" );
				}, s.timeout );
			}

			try {
				completed = false;
				transport.send( requestHeaders, done );
			} catch ( e ) {

				// Rethrow post-completion exceptions
				if ( completed ) {
					throw e;
				}

				// Propagate others as results
				done( -1, e );
			}
		}

		// Callback for when everything is done
		function done( status, nativeStatusText, responses, headers ) {
			var isSuccess, success, error, response, modified,
				statusText = nativeStatusText;

			// Ignore repeat invocations
			if ( completed ) {
				return;
			}

			completed = true;

			// Clear timeout if it exists
			if ( timeoutTimer ) {
				window.clearTimeout( timeoutTimer );
			}

			// Dereference transport for early garbage collection
			// (no matter how long the jqXHR object will be used)
			transport = undefined;

			// Cache response headers
			responseHeadersString = headers || "";

			// Set readyState
			jqXHR.readyState = status > 0 ? 4 : 0;

			// Determine if successful
			isSuccess = status >= 200 && status < 300 || status === 304;

			// Get response data
			if ( responses ) {
				response = ajaxHandleResponses( s, jqXHR, responses );
			}

			// Use a noop converter for missing script but not if jsonp
			if ( !isSuccess &&
				jQuery.inArray( "script", s.dataTypes ) > -1 &&
				jQuery.inArray( "json", s.dataTypes ) < 0 ) {
				s.converters[ "text script" ] = function() {};
			}

			// Convert no matter what (that way responseXXX fields are always set)
			response = ajaxConvert( s, response, jqXHR, isSuccess );

			// If successful, handle type chaining
			if ( isSuccess ) {

				// Set the If-Modified-Since and/or If-None-Match header, if in ifModified mode.
				if ( s.ifModified ) {
					modified = jqXHR.getResponseHeader( "Last-Modified" );
					if ( modified ) {
						jQuery.lastModified[ cacheURL ] = modified;
					}
					modified = jqXHR.getResponseHeader( "etag" );
					if ( modified ) {
						jQuery.etag[ cacheURL ] = modified;
					}
				}

				// if no content
				if ( status === 204 || s.type === "HEAD" ) {
					statusText = "nocontent";

				// if not modified
				} else if ( status === 304 ) {
					statusText = "notmodified";

				// If we have data, let's convert it
				} else {
					statusText = response.state;
					success = response.data;
					error = response.error;
					isSuccess = !error;
				}
			} else {

				// Extract error from statusText and normalize for non-aborts
				error = statusText;
				if ( status || !statusText ) {
					statusText = "error";
					if ( status < 0 ) {
						status = 0;
					}
				}
			}

			// Set data for the fake xhr object
			jqXHR.status = status;
			jqXHR.statusText = ( nativeStatusText || statusText ) + "";

			// Success/Error
			if ( isSuccess ) {
				deferred.resolveWith( callbackContext, [ success, statusText, jqXHR ] );
			} else {
				deferred.rejectWith( callbackContext, [ jqXHR, statusText, error ] );
			}

			// Status-dependent callbacks
			jqXHR.statusCode( statusCode );
			statusCode = undefined;

			if ( fireGlobals ) {
				globalEventContext.trigger( isSuccess ? "ajaxSuccess" : "ajaxError",
					[ jqXHR, s, isSuccess ? success : error ] );
			}

			// Complete
			completeDeferred.fireWith( callbackContext, [ jqXHR, statusText ] );

			if ( fireGlobals ) {
				globalEventContext.trigger( "ajaxComplete", [ jqXHR, s ] );

				// Handle the global AJAX counter
				if ( !( --jQuery.active ) ) {
					jQuery.event.trigger( "ajaxStop" );
				}
			}
		}

		return jqXHR;
	},

	getJSON: function( url, data, callback ) {
		return jQuery.get( url, data, callback, "json" );
	},

	getScript: function( url, callback ) {
		return jQuery.get( url, undefined, callback, "script" );
	}
} );

jQuery.each( [ "get", "post" ], function( _i, method ) {
	jQuery[ method ] = function( url, data, callback, type ) {

		// Shift arguments if data argument was omitted
		if ( isFunction( data ) ) {
			type = type || callback;
			callback = data;
			data = undefined;
		}

		// The url can be an options object (which then must have .url)
		return jQuery.ajax( jQuery.extend( {
			url: url,
			type: method,
			dataType: type,
			data: data,
			success: callback
		}, jQuery.isPlainObject( url ) && url ) );
	};
} );

jQuery.ajaxPrefilter( function( s ) {
	var i;
	for ( i in s.headers ) {
		if ( i.toLowerCase() === "content-type" ) {
			s.contentType = s.headers[ i ] || "";
		}
	}
} );


jQuery._evalUrl = function( url, options, doc ) {
	return jQuery.ajax( {
		url: url,

		// Make this explicit, since user can override this through ajaxSetup (trac-11264)
		type: "GET",
		dataType: "script",
		cache: true,
		async: false,
		global: false,

		// Only evaluate the response if it is successful (gh-4126)
		// dataFilter is not invoked for failure responses, so using it instead
		// of the default converter is kludgy but it works.
		converters: {
			"text script": function() {}
		},
		dataFilter: function( response ) {
			jQuery.globalEval( response, options, doc );
		}
	} );
};


jQuery.fn.extend( {
	wrapAll: function( html ) {
		var wrap;

		if ( this[ 0 ] ) {
			if ( isFunction( html ) ) {
				html = html.call( this[ 0 ] );
			}

			// The elements to wrap the target around
			wrap = jQuery( html, this[ 0 ].ownerDocument ).eq( 0 ).clone( true );

			if ( this[ 0 ].parentNode ) {
				wrap.insertBefore( this[ 0 ] );
			}

			wrap.map( function() {
				var elem = this;

				while ( elem.firstElementChild ) {
					elem = elem.firstElementChild;
				}

				return elem;
			} ).append( this );
		}

		return this;
	},

	wrapInner: function( html ) {
		if ( isFunction( html ) ) {
			return this.each( function( i ) {
				jQuery( this ).wrapInner( html.call( this, i ) );
			} );
		}

		return this.each( function() {
			var self = jQuery( this ),
				contents = self.contents();

			if ( contents.length ) {
				contents.wrapAll( html );

			} else {
				self.append( html );
			}
		} );
	},

	wrap: function( html ) {
		var htmlIsFunction = isFunction( html );

		return this.each( function( i ) {
			jQuery( this ).wrapAll( htmlIsFunction ? html.call( this, i ) : html );
		} );
	},

	unwrap: function( selector ) {
		this.parent( selector ).not( "body" ).each( function() {
			jQuery( this ).replaceWith( this.childNodes );
		} );
		return this;
	}
} );


jQuery.expr.pseudos.hidden = function( elem ) {
	return !jQuery.expr.pseudos.visible( elem );
};
jQuery.expr.pseudos.visible = function( elem ) {
	return !!( elem.offsetWidth || elem.offsetHeight || elem.getClientRects().length );
};




jQuery.ajaxSettings.xhr = function() {
	try {
		return new window.XMLHttpRequest();
	} catch ( e ) {}
};

var xhrSuccessStatus = {

		// File protocol always yields status code 0, assume 200
		0: 200,

		// Support: IE <=9 only
		// trac-1450: sometimes IE returns 1223 when it should be 204
		1223: 204
	},
	xhrSupported = jQuery.ajaxSettings.xhr();

support.cors = !!xhrSupported && ( "withCredentials" in xhrSupported );
support.ajax = xhrSupported = !!xhrSupported;

jQuery.ajaxTransport( function( options ) {
	var callback, errorCallback;

	// Cross domain only allowed if supported through XMLHttpRequest
	if ( support.cors || xhrSupported && !options.crossDomain ) {
		return {
			send: function( headers, complete ) {
				var i,
					xhr = options.xhr();

				xhr.open(
					options.type,
					options.url,
					options.async,
					options.username,
					options.password
				);

				// Apply custom fields if provided
				if ( options.xhrFields ) {
					for ( i in options.xhrFields ) {
						xhr[ i ] = options.xhrFields[ i ];
					}
				}

				// Override mime type if needed
				if ( options.mimeType && xhr.overrideMimeType ) {
					xhr.overrideMimeType( options.mimeType );
				}

				// X-Requested-With header
				// For cross-domain requests, seeing as conditions for a preflight are
				// akin to a jigsaw puzzle, we simply never set it to be sure.
				// (it can always be set on a per-request basis or even using ajaxSetup)
				// For same-domain requests, won't change header if already provided.
				if ( !options.crossDomain && !headers[ "X-Requested-With" ] ) {
					headers[ "X-Requested-With" ] = "XMLHttpRequest";
				}

				// Set headers
				for ( i in headers ) {
					xhr.setRequestHeader( i, headers[ i ] );
				}

				// Callback
				callback = function( type ) {
					return function() {
						if ( callback ) {
							callback = errorCallback = xhr.onload =
								xhr.onerror = xhr.onabort = xhr.ontimeout =
									xhr.onreadystatechange = null;

							if ( type === "abort" ) {
								xhr.abort();
							} else if ( type === "error" ) {

								// Support: IE <=9 only
								// On a manual native abort, IE9 throws
								// errors on any property access that is not readyState
								if ( typeof xhr.status !== "number" ) {
									complete( 0, "error" );
								} else {
									complete(

										// File: protocol always yields status 0; see trac-8605, trac-14207
										xhr.status,
										xhr.statusText
									);
								}
							} else {
								complete(
									xhrSuccessStatus[ xhr.status ] || xhr.status,
									xhr.statusText,

									// Support: IE <=9 only
									// IE9 has no XHR2 but throws on binary (trac-11426)
									// For XHR2 non-text, let the caller handle it (gh-2498)
									( xhr.responseType || "text" ) !== "text"  ||
									typeof xhr.responseText !== "string" ?
										{ binary: xhr.response } :
										{ text: xhr.responseText },
									xhr.getAllResponseHeaders()
								);
							}
						}
					};
				};

				// Listen to events
				xhr.onload = callback();
				errorCallback = xhr.onerror = xhr.ontimeout = callback( "error" );

				// Support: IE 9 only
				// Use onreadystatechange to replace onabort
				// to handle uncaught aborts
				if ( xhr.onabort !== undefined ) {
					xhr.onabort = errorCallback;
				} else {
					xhr.onreadystatechange = function() {

						// Check readyState before timeout as it changes
						if ( xhr.readyState === 4 ) {

							// Allow onerror to be called first,
							// but that will not handle a native abort
							// Also, save errorCallback to a variable
							// as xhr.onerror cannot be accessed
							window.setTimeout( function() {
								if ( callback ) {
									errorCallback();
								}
							} );
						}
					};
				}

				// Create the abort callback
				callback = callback( "abort" );

				try {

					// Do send the request (this may raise an exception)
					xhr.send( options.hasContent && options.data || null );
				} catch ( e ) {

					// trac-14683: Only rethrow if this hasn't been notified as an error yet
					if ( callback ) {
						throw e;
					}
				}
			},

			abort: function() {
				if ( callback ) {
					callback();
				}
			}
		};
	}
} );




// Prevent auto-execution of scripts when no explicit dataType was provided (See gh-2432)
jQuery.ajaxPrefilter( function( s ) {
	if ( s.crossDomain ) {
		s.contents.script = false;
	}
} );

// Install script dataType
jQuery.ajaxSetup( {
	accepts: {
		script: "text/javascript, application/javascript, " +
			"application/ecmascript, application/x-ecmascript"
	},
	contents: {
		script: /\b(?:java|ecma)script\b/
	},
	converters: {
		"text script": function( text ) {
			jQuery.globalEval( text );
			return text;
		}
	}
} );

// Handle cache's special case and crossDomain
jQuery.ajaxPrefilter( "script", function( s ) {
	if ( s.cache === undefined ) {
		s.cache = false;
	}
	if ( s.crossDomain ) {
		s.type = "GET";
	}
} );

// Bind script tag hack transport
jQuery.ajaxTransport( "script", function( s ) {

	// This transport only deals with cross domain or forced-by-attrs requests
	if ( s.crossDomain || s.scriptAttrs ) {
		var script, callback;
		return {
			send: function( _, complete ) {
				script = jQuery( "<script>" )
					.attr( s.scriptAttrs || {} )
					.prop( { charset: s.scriptCharset, src: s.url } )
					.on( "load error", callback = function( evt ) {
						script.remove();
						callback = null;
						if ( evt ) {
							complete( evt.type === "error" ? 404 : 200, evt.type );
						}
					} );

				// Use native DOM manipulation to avoid our domManip AJAX trickery
				document.head.appendChild( script[ 0 ] );
			},
			abort: function() {
				if ( callback ) {
					callback();
				}
			}
		};
	}
} );




var oldCallbacks = [],
	rjsonp = /(=)\?(?=&|$)|\?\?/;

// Default jsonp settings
jQuery.ajaxSetup( {
	jsonp: "callback",
	jsonpCallback: function() {
		var callback = oldCallbacks.pop() || ( jQuery.expando + "_" + ( nonce.guid++ ) );
		this[ callback ] = true;
		return callback;
	}
} );

// Detect, normalize options and install callbacks for jsonp requests
jQuery.ajaxPrefilter( "json jsonp", function( s, originalSettings, jqXHR ) {

	var callbackName, overwritten, responseContainer,
		jsonProp = s.jsonp !== false && ( rjsonp.test( s.url ) ?
			"url" :
			typeof s.data === "string" &&
				( s.contentType || "" )
					.indexOf( "application/x-www-form-urlencoded" ) === 0 &&
				rjsonp.test( s.data ) && "data"
		);

	// Handle iff the expected data type is "jsonp" or we have a parameter to set
	if ( jsonProp || s.dataTypes[ 0 ] === "jsonp" ) {

		// Get callback name, remembering preexisting value associated with it
		callbackName = s.jsonpCallback = isFunction( s.jsonpCallback ) ?
			s.jsonpCallback() :
			s.jsonpCallback;

		// Insert callback into url or form data
		if ( jsonProp ) {
			s[ jsonProp ] = s[ jsonProp ].replace( rjsonp, "$1" + callbackName );
		} else if ( s.jsonp !== false ) {
			s.url += ( rquery.test( s.url ) ? "&" : "?" ) + s.jsonp + "=" + callbackName;
		}

		// Use data converter to retrieve json after script execution
		s.converters[ "script json" ] = function() {
			if ( !responseContainer ) {
				jQuery.error( callbackName + " was not called" );
			}
			return responseContainer[ 0 ];
		};

		// Force json dataType
		s.dataTypes[ 0 ] = "json";

		// Install callback
		overwritten = window[ callbackName ];
		window[ callbackName ] = function() {
			responseContainer = arguments;
		};

		// Clean-up function (fires after converters)
		jqXHR.always( function() {

			// If previous value didn't exist - remove it
			if ( overwritten === undefined ) {
				jQuery( window ).removeProp( callbackName );

			// Otherwise restore preexisting value
			} else {
				window[ callbackName ] = overwritten;
			}

			// Save back as free
			if ( s[ callbackName ] ) {

				// Make sure that re-using the options doesn't screw things around
				s.jsonpCallback = originalSettings.jsonpCallback;

				// Save the callback name for future use
				oldCallbacks.push( callbackName );
			}

			// Call if it was a function and we have a response
			if ( responseContainer && isFunction( overwritten ) ) {
				overwritten( responseContainer[ 0 ] );
			}

			responseContainer = overwritten = undefined;
		} );

		// Delegate to script
		return "script";
	}
} );




// Support: Safari 8 only
// In Safari 8 documents created via document.implementation.createHTMLDocument
// collapse sibling forms: the second one becomes a child of the first one.
// Because of that, this security measure has to be disabled in Safari 8.
// https://bugs.webkit.org/show_bug.cgi?id=137337
support.createHTMLDocument = ( function() {
	var body = document.implementation.createHTMLDocument( "" ).body;
	body.innerHTML = "<form></form><form></form>";
	return body.childNodes.length === 2;
} )();


// Argument "data" should be string of html
// context (optional): If specified, the fragment will be created in this context,
// defaults to document
// keepScripts (optional): If true, will include scripts passed in the html string
jQuery.parseHTML = function( data, context, keepScripts ) {
	if ( typeof data !== "string" ) {
		return [];
	}
	if ( typeof context === "boolean" ) {
		keepScripts = context;
		context = false;
	}

	var base, parsed, scripts;

	if ( !context ) {

		// Stop scripts or inline event handlers from being executed immediately
		// by using document.implementation
		if ( support.createHTMLDocument ) {
			context = document.implementation.createHTMLDocument( "" );

			// Set the base href for the created document
			// so any parsed elements with URLs
			// are based on the document's URL (gh-2965)
			base = context.createElement( "base" );
			base.href = document.location.href;
			context.head.appendChild( base );
		} else {
			context = document;
		}
	}

	parsed = rsingleTag.exec( data );
	scripts = !keepScripts && [];

	// Single tag
	if ( parsed ) {
		return [ context.createElement( parsed[ 1 ] ) ];
	}

	parsed = buildFragment( [ data ], context, scripts );

	if ( scripts && scripts.length ) {
		jQuery( scripts ).remove();
	}

	return jQuery.merge( [], parsed.childNodes );
};


/**
 * Load a url into a page
 */
jQuery.fn.load = function( url, params, callback ) {
	var selector, type, response,
		self = this,
		off = url.indexOf( " " );

	if ( off > -1 ) {
		selector = stripAndCollapse( url.slice( off ) );
		url = url.slice( 0, off );
	}

	// If it's a function
	if ( isFunction( params ) ) {

		// We assume that it's the callback
		callback = params;
		params = undefined;

	// Otherwise, build a param string
	} else if ( params && typeof params === "object" ) {
		type = "POST";
	}

	// If we have elements to modify, make the request
	if ( self.length > 0 ) {
		jQuery.ajax( {
			url: url,

			// If "type" variable is undefined, then "GET" method will be used.
			// Make value of this field explicit since
			// user can override it through ajaxSetup method
			type: type || "GET",
			dataType: "html",
			data: params
		} ).done( function( responseText ) {

			// Save response for use in complete callback
			response = arguments;

			self.html( selector ?

				// If a selector was specified, locate the right elements in a dummy div
				// Exclude scripts to avoid IE 'Permission Denied' errors
				jQuery( "<div>" ).append( jQuery.parseHTML( responseText ) ).find( selector ) :

				// Otherwise use the full result
				responseText );

		// If the request succeeds, this function gets "data", "status", "jqXHR"
		// but they are ignored because response was set above.
		// If it fails, this function gets "jqXHR", "status", "error"
		} ).always( callback && function( jqXHR, status ) {
			self.each( function() {
				callback.apply( this, response || [ jqXHR.responseText, status, jqXHR ] );
			} );
		} );
	}

	return this;
};




jQuery.expr.pseudos.animated = function( elem ) {
	return jQuery.grep( jQuery.timers, function( fn ) {
		return elem === fn.elem;
	} ).length;
};




jQuery.offset = {
	setOffset: function( elem, options, i ) {
		var curPosition, curLeft, curCSSTop, curTop, curOffset, curCSSLeft, calculatePosition,
			position = jQuery.css( elem, "position" ),
			curElem = jQuery( elem ),
			props = {};

		// Set position first, in-case top/left are set even on static elem
		if ( position === "static" ) {
			elem.style.position = "relative";
		}

		curOffset = curElem.offset();
		curCSSTop = jQuery.css( elem, "top" );
		curCSSLeft = jQuery.css( elem, "left" );
		calculatePosition = ( position === "absolute" || position === "fixed" ) &&
			( curCSSTop + curCSSLeft ).indexOf( "auto" ) > -1;

		// Need to be able to calculate position if either
		// top or left is auto and position is either absolute or fixed
		if ( calculatePosition ) {
			curPosition = curElem.position();
			curTop = curPosition.top;
			curLeft = curPosition.left;

		} else {
			curTop = parseFloat( curCSSTop ) || 0;
			curLeft = parseFloat( curCSSLeft ) || 0;
		}

		if ( isFunction( options ) ) {

			// Use jQuery.extend here to allow modification of coordinates argument (gh-1848)
			options = options.call( elem, i, jQuery.extend( {}, curOffset ) );
		}

		if ( options.top != null ) {
			props.top = ( options.top - curOffset.top ) + curTop;
		}
		if ( options.left != null ) {
			props.left = ( options.left - curOffset.left ) + curLeft;
		}

		if ( "using" in options ) {
			options.using.call( elem, props );

		} else {
			curElem.css( props );
		}
	}
};

jQuery.fn.extend( {

	// offset() relates an element's border box to the document origin
	offset: function( options ) {

		// Preserve chaining for setter
		if ( arguments.length ) {
			return options === undefined ?
				this :
				this.each( function( i ) {
					jQuery.offset.setOffset( this, options, i );
				} );
		}

		var rect, win,
			elem = this[ 0 ];

		if ( !elem ) {
			return;
		}

		// Return zeros for disconnected and hidden (display: none) elements (gh-2310)
		// Support: IE <=11 only
		// Running getBoundingClientRect on a
		// disconnected node in IE throws an error
		if ( !elem.getClientRects().length ) {
			return { top: 0, left: 0 };
		}

		// Get document-relative position by adding viewport scroll to viewport-relative gBCR
		rect = elem.getBoundingClientRect();
		win = elem.ownerDocument.defaultView;
		return {
			top: rect.top + win.pageYOffset,
			left: rect.left + win.pageXOffset
		};
	},

	// position() relates an element's margin box to its offset parent's padding box
	// This corresponds to the behavior of CSS absolute positioning
	position: function() {
		if ( !this[ 0 ] ) {
			return;
		}

		var offsetParent, offset, doc,
			elem = this[ 0 ],
			parentOffset = { top: 0, left: 0 };

		// position:fixed elements are offset from the viewport, which itself always has zero offset
		if ( jQuery.css( elem, "position" ) === "fixed" ) {

			// Assume position:fixed implies availability of getBoundingClientRect
			offset = elem.getBoundingClientRect();

		} else {
			offset = this.offset();

			// Account for the *real* offset parent, which can be the document or its root element
			// when a statically positioned element is identified
			doc = elem.ownerDocument;
			offsetParent = elem.offsetParent || doc.documentElement;
			while ( offsetParent &&
				( offsetParent === doc.body || offsetParent === doc.documentElement ) &&
				jQuery.css( offsetParent, "position" ) === "static" ) {

				offsetParent = offsetParent.parentNode;
			}
			if ( offsetParent && offsetParent !== elem && offsetParent.nodeType === 1 ) {

				// Incorporate borders into its offset, since they are outside its content origin
				parentOffset = jQuery( offsetParent ).offset();
				parentOffset.top += jQuery.css( offsetParent, "borderTopWidth", true );
				parentOffset.left += jQuery.css( offsetParent, "borderLeftWidth", true );
			}
		}

		// Subtract parent offsets and element margins
		return {
			top: offset.top - parentOffset.top - jQuery.css( elem, "marginTop", true ),
			left: offset.left - parentOffset.left - jQuery.css( elem, "marginLeft", true )
		};
	},

	// This method will return documentElement in the following cases:
	// 1) For the element inside the iframe without offsetParent, this method will return
	//    documentElement of the parent window
	// 2) For the hidden or detached element
	// 3) For body or html element, i.e. in case of the html node - it will return itself
	//
	// but those exceptions were never presented as a real life use-cases
	// and might be considered as more preferable results.
	//
	// This logic, however, is not guaranteed and can change at any point in the future
	offsetParent: function() {
		return this.map( function() {
			var offsetParent = this.offsetParent;

			while ( offsetParent && jQuery.css( offsetParent, "position" ) === "static" ) {
				offsetParent = offsetParent.offsetParent;
			}

			return offsetParent || documentElement;
		} );
	}
} );

// Create scrollLeft and scrollTop methods
jQuery.each( { scrollLeft: "pageXOffset", scrollTop: "pageYOffset" }, function( method, prop ) {
	var top = "pageYOffset" === prop;

	jQuery.fn[ method ] = function( val ) {
		return access( this, function( elem, method, val ) {

			// Coalesce documents and windows
			var win;
			if ( isWindow( elem ) ) {
				win = elem;
			} else if ( elem.nodeType === 9 ) {
				win = elem.defaultView;
			}

			if ( val === undefined ) {
				return win ? win[ prop ] : elem[ method ];
			}

			if ( win ) {
				win.scrollTo(
					!top ? val : win.pageXOffset,
					top ? val : win.pageYOffset
				);

			} else {
				elem[ method ] = val;
			}
		}, method, val, arguments.length );
	};
} );

// Support: Safari <=7 - 9.1, Chrome <=37 - 49
// Add the top/left cssHooks using jQuery.fn.position
// Webkit bug: https://bugs.webkit.org/show_bug.cgi?id=29084
// Blink bug: https://bugs.chromium.org/p/chromium/issues/detail?id=589347
// getComputedStyle returns percent when specified for top/left/bottom/right;
// rather than make the css module depend on the offset module, just check for it here
jQuery.each( [ "top", "left" ], function( _i, prop ) {
	jQuery.cssHooks[ prop ] = addGetHookIf( support.pixelPosition,
		function( elem, computed ) {
			if ( computed ) {
				computed = curCSS( elem, prop );

				// If curCSS returns percentage, fallback to offset
				return rnumnonpx.test( computed ) ?
					jQuery( elem ).position()[ prop ] + "px" :
					computed;
			}
		}
	);
} );


// Create innerHeight, innerWidth, height, width, outerHeight and outerWidth methods
jQuery.each( { Height: "height", Width: "width" }, function( name, type ) {
	jQuery.each( {
		padding: "inner" + name,
		content: type,
		"": "outer" + name
	}, function( defaultExtra, funcName ) {

		// Margin is only for outerHeight, outerWidth
		jQuery.fn[ funcName ] = function( margin, value ) {
			var chainable = arguments.length && ( defaultExtra || typeof margin !== "boolean" ),
				extra = defaultExtra || ( margin === true || value === true ? "margin" : "border" );

			return access( this, function( elem, type, value ) {
				var doc;

				if ( isWindow( elem ) ) {

					// $( window ).outerWidth/Height return w/h including scrollbars (gh-1729)
					return funcName.indexOf( "outer" ) === 0 ?
						elem[ "inner" + name ] :
						elem.document.documentElement[ "client" + name ];
				}

				// Get document width or height
				if ( elem.nodeType === 9 ) {
					doc = elem.documentElement;

					// Either scroll[Width/Height] or offset[Width/Height] or client[Width/Height],
					// whichever is greatest
					return Math.max(
						elem.body[ "scroll" + name ], doc[ "scroll" + name ],
						elem.body[ "offset" + name ], doc[ "offset" + name ],
						doc[ "client" + name ]
					);
				}

				return value === undefined ?

					// Get width or height on the element, requesting but not forcing parseFloat
					jQuery.css( elem, type, extra ) :

					// Set width or height on the element
					jQuery.style( elem, type, value, extra );
			}, type, chainable ? margin : undefined, chainable );
		};
	} );
} );


jQuery.each( [
	"ajaxStart",
	"ajaxStop",
	"ajaxComplete",
	"ajaxError",
	"ajaxSuccess",
	"ajaxSend"
], function( _i, type ) {
	jQuery.fn[ type ] = function( fn ) {
		return this.on( type, fn );
	};
} );




jQuery.fn.extend( {

	bind: function( types, data, fn ) {
		return this.on( types, null, data, fn );
	},
	unbind: function( types, fn ) {
		return this.off( types, null, fn );
	},

	delegate: function( selector, types, data, fn ) {
		return this.on( types, selector, data, fn );
	},
	undelegate: function( selector, types, fn ) {

		// ( namespace ) or ( selector, types [, fn] )
		return arguments.length === 1 ?
			this.off( selector, "**" ) :
			this.off( types, selector || "**", fn );
	},

	hover: function( fnOver, fnOut ) {
		return this.mouseenter( fnOver ).mouseleave( fnOut || fnOver );
	}
} );

jQuery.each(
	( "blur focus focusin focusout resize scroll click dblclick " +
	"mousedown mouseup mousemove mouseover mouseout mouseenter mouseleave " +
	"change select submit keydown keypress keyup contextmenu" ).split( " " ),
	function( _i, name ) {

		// Handle event binding
		jQuery.fn[ name ] = function( data, fn ) {
			return arguments.length > 0 ?
				this.on( name, null, data, fn ) :
				this.trigger( name );
		};
	}
);




// Support: Android <=4.0 only
// Make sure we trim BOM and NBSP
// Require that the "whitespace run" starts from a non-whitespace
// to avoid O(N^2) behavior when the engine would try matching "\s+$" at each space position.
var rtrim = /^[\s\uFEFF\xA0]+|([^\s\uFEFF\xA0])[\s\uFEFF\xA0]+$/g;

// Bind a function to a context, optionally partially applying any
// arguments.
// jQuery.proxy is deprecated to promote standards (specifically Function#bind)
// However, it is not slated for removal any time soon
jQuery.proxy = function( fn, context ) {
	var tmp, args, proxy;

	if ( typeof context === "string" ) {
		tmp = fn[ context ];
		context = fn;
		fn = tmp;
	}

	// Quick check to determine if target is callable, in the spec
	// this throws a TypeError, but we will just return undefined.
	if ( !isFunction( fn ) ) {
		return undefined;
	}

	// Simulated bind
	args = slice.call( arguments, 2 );
	proxy = function() {
		return fn.apply( context || this, args.concat( slice.call( arguments ) ) );
	};

	// Set the guid of unique handler to the same of original handler, so it can be removed
	proxy.guid = fn.guid = fn.guid || jQuery.guid++;

	return proxy;
};

jQuery.holdReady = function( hold ) {
	if ( hold ) {
		jQuery.readyWait++;
	} else {
		jQuery.ready( true );
	}
};
jQuery.isArray = Array.isArray;
jQuery.parseJSON = JSON.parse;
jQuery.nodeName = nodeName;
jQuery.isFunction = isFunction;
jQuery.isWindow = isWindow;
jQuery.camelCase = camelCase;
jQuery.type = toType;

jQuery.now = Date.now;

jQuery.isNumeric = function( obj ) {

	// As of jQuery 3.0, isNumeric is limited to
	// strings and numbers (primitives or objects)
	// that can be coerced to finite numbers (gh-2662)
	var type = jQuery.type( obj );
	return ( type === "number" || type === "string" ) &&

		// parseFloat NaNs numeric-cast false positives ("")
		// ...but misinterprets leading-number strings, particularly hex literals ("0x...")
		// subtraction forces infinities to NaN
		!isNaN( obj - parseFloat( obj ) );
};

jQuery.trim = function( text ) {
	return text == null ?
		"" :
		( text + "" ).replace( rtrim, "$1" );
};



// Register as a named AMD module, since jQuery can be concatenated with other
// files that may use define, but not via a proper concatenation script that
// understands anonymous AMD modules. A named AMD is safest and most robust
// way to register. Lowercase jquery is used because AMD module names are
// derived from file names, and jQuery is normally delivered in a lowercase
// file name. Do this after creating the global so that if an AMD module wants
// to call noConflict to hide this version of jQuery, it will work.

// Note that for maximum portability, libraries that are not jQuery should
// declare themselves as anonymous modules, and avoid setting a global if an
// AMD loader is present. jQuery is a special case. For more information, see
// https://github.com/jrburke/requirejs/wiki/Updating-existing-libraries#wiki-anon

if ( true ) {
	!(__WEBPACK_AMD_DEFINE_ARRAY__ = [], __WEBPACK_AMD_DEFINE_RESULT__ = (function() {
		return jQuery;
	}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),
		__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));
}




var

	// Map over jQuery in case of overwrite
	_jQuery = window.jQuery,

	// Map over the $ in case of overwrite
	_$ = window.$;

jQuery.noConflict = function( deep ) {
	if ( window.$ === jQuery ) {
		window.$ = _$;
	}

	if ( deep && window.jQuery === jQuery ) {
		window.jQuery = _jQuery;
	}

	return jQuery;
};

// Expose jQuery and $ identifiers, even in AMD
// (trac-7102#comment:10, https://github.com/jquery/jquery/pull/557)
// and CommonJS for browser emulators (trac-13566)
if ( typeof noGlobal === "undefined" ) {
	window.jQuery = window.$ = jQuery;
}




return jQuery;
} );


/***/ }),

/***/ "./node_modules/js-md5/src/md5.js":
/*!****************************************!*\
  !*** ./node_modules/js-md5/src/md5.js ***!
  \****************************************/
/***/ ((module, exports, __webpack_require__) => {

var __WEBPACK_AMD_DEFINE_RESULT__;/**
 * [js-md5]{@link https://github.com/emn178/js-md5}
 *
 * @namespace md5
 * @version 0.7.3
 * @author Chen, Yi-Cyuan [emn178@gmail.com]
 * @copyright Chen, Yi-Cyuan 2014-2017
 * @license MIT
 */
(function () {
  'use strict';

  var ERROR = 'input is invalid type';
  var WINDOW = typeof window === 'object';
  var root = WINDOW ? window : {};
  if (root.JS_MD5_NO_WINDOW) {
    WINDOW = false;
  }
  var WEB_WORKER = !WINDOW && typeof self === 'object';
  var NODE_JS = !root.JS_MD5_NO_NODE_JS && typeof process === 'object' && process.versions && process.versions.node;
  if (NODE_JS) {
    root = __webpack_require__.g;
  } else if (WEB_WORKER) {
    root = self;
  }
  var COMMON_JS = !root.JS_MD5_NO_COMMON_JS && "object" === 'object' && module.exports;
  var AMD =  true && __webpack_require__.amdO;
  var ARRAY_BUFFER = !root.JS_MD5_NO_ARRAY_BUFFER && typeof ArrayBuffer !== 'undefined';
  var HEX_CHARS = '0123456789abcdef'.split('');
  var EXTRA = [128, 32768, 8388608, -2147483648];
  var SHIFT = [0, 8, 16, 24];
  var OUTPUT_TYPES = ['hex', 'array', 'digest', 'buffer', 'arrayBuffer', 'base64'];
  var BASE64_ENCODE_CHAR = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/'.split('');

  var blocks = [], buffer8;
  if (ARRAY_BUFFER) {
    var buffer = new ArrayBuffer(68);
    buffer8 = new Uint8Array(buffer);
    blocks = new Uint32Array(buffer);
  }

  if (root.JS_MD5_NO_NODE_JS || !Array.isArray) {
    Array.isArray = function (obj) {
      return Object.prototype.toString.call(obj) === '[object Array]';
    };
  }

  if (ARRAY_BUFFER && (root.JS_MD5_NO_ARRAY_BUFFER_IS_VIEW || !ArrayBuffer.isView)) {
    ArrayBuffer.isView = function (obj) {
      return typeof obj === 'object' && obj.buffer && obj.buffer.constructor === ArrayBuffer;
    };
  }

  /**
   * @method hex
   * @memberof md5
   * @description Output hash as hex string
   * @param {String|Array|Uint8Array|ArrayBuffer} message message to hash
   * @returns {String} Hex string
   * @example
   * md5.hex('The quick brown fox jumps over the lazy dog');
   * // equal to
   * md5('The quick brown fox jumps over the lazy dog');
   */
  /**
   * @method digest
   * @memberof md5
   * @description Output hash as bytes array
   * @param {String|Array|Uint8Array|ArrayBuffer} message message to hash
   * @returns {Array} Bytes array
   * @example
   * md5.digest('The quick brown fox jumps over the lazy dog');
   */
  /**
   * @method array
   * @memberof md5
   * @description Output hash as bytes array
   * @param {String|Array|Uint8Array|ArrayBuffer} message message to hash
   * @returns {Array} Bytes array
   * @example
   * md5.array('The quick brown fox jumps over the lazy dog');
   */
  /**
   * @method arrayBuffer
   * @memberof md5
   * @description Output hash as ArrayBuffer
   * @param {String|Array|Uint8Array|ArrayBuffer} message message to hash
   * @returns {ArrayBuffer} ArrayBuffer
   * @example
   * md5.arrayBuffer('The quick brown fox jumps over the lazy dog');
   */
  /**
   * @method buffer
   * @deprecated This maybe confuse with Buffer in node.js. Please use arrayBuffer instead.
   * @memberof md5
   * @description Output hash as ArrayBuffer
   * @param {String|Array|Uint8Array|ArrayBuffer} message message to hash
   * @returns {ArrayBuffer} ArrayBuffer
   * @example
   * md5.buffer('The quick brown fox jumps over the lazy dog');
   */
  /**
   * @method base64
   * @memberof md5
   * @description Output hash as base64 string
   * @param {String|Array|Uint8Array|ArrayBuffer} message message to hash
   * @returns {String} base64 string
   * @example
   * md5.base64('The quick brown fox jumps over the lazy dog');
   */
  var createOutputMethod = function (outputType) {
    return function (message) {
      return new Md5(true).update(message)[outputType]();
    };
  };

  /**
   * @method create
   * @memberof md5
   * @description Create Md5 object
   * @returns {Md5} Md5 object.
   * @example
   * var hash = md5.create();
   */
  /**
   * @method update
   * @memberof md5
   * @description Create and update Md5 object
   * @param {String|Array|Uint8Array|ArrayBuffer} message message to hash
   * @returns {Md5} Md5 object.
   * @example
   * var hash = md5.update('The quick brown fox jumps over the lazy dog');
   * // equal to
   * var hash = md5.create();
   * hash.update('The quick brown fox jumps over the lazy dog');
   */
  var createMethod = function () {
    var method = createOutputMethod('hex');
    if (NODE_JS) {
      method = nodeWrap(method);
    }
    method.create = function () {
      return new Md5();
    };
    method.update = function (message) {
      return method.create().update(message);
    };
    for (var i = 0; i < OUTPUT_TYPES.length; ++i) {
      var type = OUTPUT_TYPES[i];
      method[type] = createOutputMethod(type);
    }
    return method;
  };

  var nodeWrap = function (method) {
    var crypto = eval("require('crypto')");
    var Buffer = eval("require('buffer').Buffer");
    var nodeMethod = function (message) {
      if (typeof message === 'string') {
        return crypto.createHash('md5').update(message, 'utf8').digest('hex');
      } else {
        if (message === null || message === undefined) {
          throw ERROR;
        } else if (message.constructor === ArrayBuffer) {
          message = new Uint8Array(message);
        }
      }
      if (Array.isArray(message) || ArrayBuffer.isView(message) ||
        message.constructor === Buffer) {
        return crypto.createHash('md5').update(new Buffer(message)).digest('hex');
      } else {
        return method(message);
      }
    };
    return nodeMethod;
  };

  /**
   * Md5 class
   * @class Md5
   * @description This is internal class.
   * @see {@link md5.create}
   */
  function Md5(sharedMemory) {
    if (sharedMemory) {
      blocks[0] = blocks[16] = blocks[1] = blocks[2] = blocks[3] =
      blocks[4] = blocks[5] = blocks[6] = blocks[7] =
      blocks[8] = blocks[9] = blocks[10] = blocks[11] =
      blocks[12] = blocks[13] = blocks[14] = blocks[15] = 0;
      this.blocks = blocks;
      this.buffer8 = buffer8;
    } else {
      if (ARRAY_BUFFER) {
        var buffer = new ArrayBuffer(68);
        this.buffer8 = new Uint8Array(buffer);
        this.blocks = new Uint32Array(buffer);
      } else {
        this.blocks = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0];
      }
    }
    this.h0 = this.h1 = this.h2 = this.h3 = this.start = this.bytes = this.hBytes = 0;
    this.finalized = this.hashed = false;
    this.first = true;
  }

  /**
   * @method update
   * @memberof Md5
   * @instance
   * @description Update hash
   * @param {String|Array|Uint8Array|ArrayBuffer} message message to hash
   * @returns {Md5} Md5 object.
   * @see {@link md5.update}
   */
  Md5.prototype.update = function (message) {
    if (this.finalized) {
      return;
    }

    var notString, type = typeof message;
    if (type !== 'string') {
      if (type === 'object') {
        if (message === null) {
          throw ERROR;
        } else if (ARRAY_BUFFER && message.constructor === ArrayBuffer) {
          message = new Uint8Array(message);
        } else if (!Array.isArray(message)) {
          if (!ARRAY_BUFFER || !ArrayBuffer.isView(message)) {
            throw ERROR;
          }
        }
      } else {
        throw ERROR;
      }
      notString = true;
    }
    var code, index = 0, i, length = message.length, blocks = this.blocks;
    var buffer8 = this.buffer8;

    while (index < length) {
      if (this.hashed) {
        this.hashed = false;
        blocks[0] = blocks[16];
        blocks[16] = blocks[1] = blocks[2] = blocks[3] =
        blocks[4] = blocks[5] = blocks[6] = blocks[7] =
        blocks[8] = blocks[9] = blocks[10] = blocks[11] =
        blocks[12] = blocks[13] = blocks[14] = blocks[15] = 0;
      }

      if (notString) {
        if (ARRAY_BUFFER) {
          for (i = this.start; index < length && i < 64; ++index) {
            buffer8[i++] = message[index];
          }
        } else {
          for (i = this.start; index < length && i < 64; ++index) {
            blocks[i >> 2] |= message[index] << SHIFT[i++ & 3];
          }
        }
      } else {
        if (ARRAY_BUFFER) {
          for (i = this.start; index < length && i < 64; ++index) {
            code = message.charCodeAt(index);
            if (code < 0x80) {
              buffer8[i++] = code;
            } else if (code < 0x800) {
              buffer8[i++] = 0xc0 | (code >> 6);
              buffer8[i++] = 0x80 | (code & 0x3f);
            } else if (code < 0xd800 || code >= 0xe000) {
              buffer8[i++] = 0xe0 | (code >> 12);
              buffer8[i++] = 0x80 | ((code >> 6) & 0x3f);
              buffer8[i++] = 0x80 | (code & 0x3f);
            } else {
              code = 0x10000 + (((code & 0x3ff) << 10) | (message.charCodeAt(++index) & 0x3ff));
              buffer8[i++] = 0xf0 | (code >> 18);
              buffer8[i++] = 0x80 | ((code >> 12) & 0x3f);
              buffer8[i++] = 0x80 | ((code >> 6) & 0x3f);
              buffer8[i++] = 0x80 | (code & 0x3f);
            }
          }
        } else {
          for (i = this.start; index < length && i < 64; ++index) {
            code = message.charCodeAt(index);
            if (code < 0x80) {
              blocks[i >> 2] |= code << SHIFT[i++ & 3];
            } else if (code < 0x800) {
              blocks[i >> 2] |= (0xc0 | (code >> 6)) << SHIFT[i++ & 3];
              blocks[i >> 2] |= (0x80 | (code & 0x3f)) << SHIFT[i++ & 3];
            } else if (code < 0xd800 || code >= 0xe000) {
              blocks[i >> 2] |= (0xe0 | (code >> 12)) << SHIFT[i++ & 3];
              blocks[i >> 2] |= (0x80 | ((code >> 6) & 0x3f)) << SHIFT[i++ & 3];
              blocks[i >> 2] |= (0x80 | (code & 0x3f)) << SHIFT[i++ & 3];
            } else {
              code = 0x10000 + (((code & 0x3ff) << 10) | (message.charCodeAt(++index) & 0x3ff));
              blocks[i >> 2] |= (0xf0 | (code >> 18)) << SHIFT[i++ & 3];
              blocks[i >> 2] |= (0x80 | ((code >> 12) & 0x3f)) << SHIFT[i++ & 3];
              blocks[i >> 2] |= (0x80 | ((code >> 6) & 0x3f)) << SHIFT[i++ & 3];
              blocks[i >> 2] |= (0x80 | (code & 0x3f)) << SHIFT[i++ & 3];
            }
          }
        }
      }
      this.lastByteIndex = i;
      this.bytes += i - this.start;
      if (i >= 64) {
        this.start = i - 64;
        this.hash();
        this.hashed = true;
      } else {
        this.start = i;
      }
    }
    if (this.bytes > 4294967295) {
      this.hBytes += this.bytes / 4294967296 << 0;
      this.bytes = this.bytes % 4294967296;
    }
    return this;
  };

  Md5.prototype.finalize = function () {
    if (this.finalized) {
      return;
    }
    this.finalized = true;
    var blocks = this.blocks, i = this.lastByteIndex;
    blocks[i >> 2] |= EXTRA[i & 3];
    if (i >= 56) {
      if (!this.hashed) {
        this.hash();
      }
      blocks[0] = blocks[16];
      blocks[16] = blocks[1] = blocks[2] = blocks[3] =
      blocks[4] = blocks[5] = blocks[6] = blocks[7] =
      blocks[8] = blocks[9] = blocks[10] = blocks[11] =
      blocks[12] = blocks[13] = blocks[14] = blocks[15] = 0;
    }
    blocks[14] = this.bytes << 3;
    blocks[15] = this.hBytes << 3 | this.bytes >>> 29;
    this.hash();
  };

  Md5.prototype.hash = function () {
    var a, b, c, d, bc, da, blocks = this.blocks;

    if (this.first) {
      a = blocks[0] - 680876937;
      a = (a << 7 | a >>> 25) - 271733879 << 0;
      d = (-1732584194 ^ a & 2004318071) + blocks[1] - 117830708;
      d = (d << 12 | d >>> 20) + a << 0;
      c = (-271733879 ^ (d & (a ^ -271733879))) + blocks[2] - 1126478375;
      c = (c << 17 | c >>> 15) + d << 0;
      b = (a ^ (c & (d ^ a))) + blocks[3] - 1316259209;
      b = (b << 22 | b >>> 10) + c << 0;
    } else {
      a = this.h0;
      b = this.h1;
      c = this.h2;
      d = this.h3;
      a += (d ^ (b & (c ^ d))) + blocks[0] - 680876936;
      a = (a << 7 | a >>> 25) + b << 0;
      d += (c ^ (a & (b ^ c))) + blocks[1] - 389564586;
      d = (d << 12 | d >>> 20) + a << 0;
      c += (b ^ (d & (a ^ b))) + blocks[2] + 606105819;
      c = (c << 17 | c >>> 15) + d << 0;
      b += (a ^ (c & (d ^ a))) + blocks[3] - 1044525330;
      b = (b << 22 | b >>> 10) + c << 0;
    }

    a += (d ^ (b & (c ^ d))) + blocks[4] - 176418897;
    a = (a << 7 | a >>> 25) + b << 0;
    d += (c ^ (a & (b ^ c))) + blocks[5] + 1200080426;
    d = (d << 12 | d >>> 20) + a << 0;
    c += (b ^ (d & (a ^ b))) + blocks[6] - 1473231341;
    c = (c << 17 | c >>> 15) + d << 0;
    b += (a ^ (c & (d ^ a))) + blocks[7] - 45705983;
    b = (b << 22 | b >>> 10) + c << 0;
    a += (d ^ (b & (c ^ d))) + blocks[8] + 1770035416;
    a = (a << 7 | a >>> 25) + b << 0;
    d += (c ^ (a & (b ^ c))) + blocks[9] - 1958414417;
    d = (d << 12 | d >>> 20) + a << 0;
    c += (b ^ (d & (a ^ b))) + blocks[10] - 42063;
    c = (c << 17 | c >>> 15) + d << 0;
    b += (a ^ (c & (d ^ a))) + blocks[11] - 1990404162;
    b = (b << 22 | b >>> 10) + c << 0;
    a += (d ^ (b & (c ^ d))) + blocks[12] + 1804603682;
    a = (a << 7 | a >>> 25) + b << 0;
    d += (c ^ (a & (b ^ c))) + blocks[13] - 40341101;
    d = (d << 12 | d >>> 20) + a << 0;
    c += (b ^ (d & (a ^ b))) + blocks[14] - 1502002290;
    c = (c << 17 | c >>> 15) + d << 0;
    b += (a ^ (c & (d ^ a))) + blocks[15] + 1236535329;
    b = (b << 22 | b >>> 10) + c << 0;
    a += (c ^ (d & (b ^ c))) + blocks[1] - 165796510;
    a = (a << 5 | a >>> 27) + b << 0;
    d += (b ^ (c & (a ^ b))) + blocks[6] - 1069501632;
    d = (d << 9 | d >>> 23) + a << 0;
    c += (a ^ (b & (d ^ a))) + blocks[11] + 643717713;
    c = (c << 14 | c >>> 18) + d << 0;
    b += (d ^ (a & (c ^ d))) + blocks[0] - 373897302;
    b = (b << 20 | b >>> 12) + c << 0;
    a += (c ^ (d & (b ^ c))) + blocks[5] - 701558691;
    a = (a << 5 | a >>> 27) + b << 0;
    d += (b ^ (c & (a ^ b))) + blocks[10] + 38016083;
    d = (d << 9 | d >>> 23) + a << 0;
    c += (a ^ (b & (d ^ a))) + blocks[15] - 660478335;
    c = (c << 14 | c >>> 18) + d << 0;
    b += (d ^ (a & (c ^ d))) + blocks[4] - 405537848;
    b = (b << 20 | b >>> 12) + c << 0;
    a += (c ^ (d & (b ^ c))) + blocks[9] + 568446438;
    a = (a << 5 | a >>> 27) + b << 0;
    d += (b ^ (c & (a ^ b))) + blocks[14] - 1019803690;
    d = (d << 9 | d >>> 23) + a << 0;
    c += (a ^ (b & (d ^ a))) + blocks[3] - 187363961;
    c = (c << 14 | c >>> 18) + d << 0;
    b += (d ^ (a & (c ^ d))) + blocks[8] + 1163531501;
    b = (b << 20 | b >>> 12) + c << 0;
    a += (c ^ (d & (b ^ c))) + blocks[13] - 1444681467;
    a = (a << 5 | a >>> 27) + b << 0;
    d += (b ^ (c & (a ^ b))) + blocks[2] - 51403784;
    d = (d << 9 | d >>> 23) + a << 0;
    c += (a ^ (b & (d ^ a))) + blocks[7] + 1735328473;
    c = (c << 14 | c >>> 18) + d << 0;
    b += (d ^ (a & (c ^ d))) + blocks[12] - 1926607734;
    b = (b << 20 | b >>> 12) + c << 0;
    bc = b ^ c;
    a += (bc ^ d) + blocks[5] - 378558;
    a = (a << 4 | a >>> 28) + b << 0;
    d += (bc ^ a) + blocks[8] - 2022574463;
    d = (d << 11 | d >>> 21) + a << 0;
    da = d ^ a;
    c += (da ^ b) + blocks[11] + 1839030562;
    c = (c << 16 | c >>> 16) + d << 0;
    b += (da ^ c) + blocks[14] - 35309556;
    b = (b << 23 | b >>> 9) + c << 0;
    bc = b ^ c;
    a += (bc ^ d) + blocks[1] - 1530992060;
    a = (a << 4 | a >>> 28) + b << 0;
    d += (bc ^ a) + blocks[4] + 1272893353;
    d = (d << 11 | d >>> 21) + a << 0;
    da = d ^ a;
    c += (da ^ b) + blocks[7] - 155497632;
    c = (c << 16 | c >>> 16) + d << 0;
    b += (da ^ c) + blocks[10] - 1094730640;
    b = (b << 23 | b >>> 9) + c << 0;
    bc = b ^ c;
    a += (bc ^ d) + blocks[13] + 681279174;
    a = (a << 4 | a >>> 28) + b << 0;
    d += (bc ^ a) + blocks[0] - 358537222;
    d = (d << 11 | d >>> 21) + a << 0;
    da = d ^ a;
    c += (da ^ b) + blocks[3] - 722521979;
    c = (c << 16 | c >>> 16) + d << 0;
    b += (da ^ c) + blocks[6] + 76029189;
    b = (b << 23 | b >>> 9) + c << 0;
    bc = b ^ c;
    a += (bc ^ d) + blocks[9] - 640364487;
    a = (a << 4 | a >>> 28) + b << 0;
    d += (bc ^ a) + blocks[12] - 421815835;
    d = (d << 11 | d >>> 21) + a << 0;
    da = d ^ a;
    c += (da ^ b) + blocks[15] + 530742520;
    c = (c << 16 | c >>> 16) + d << 0;
    b += (da ^ c) + blocks[2] - 995338651;
    b = (b << 23 | b >>> 9) + c << 0;
    a += (c ^ (b | ~d)) + blocks[0] - 198630844;
    a = (a << 6 | a >>> 26) + b << 0;
    d += (b ^ (a | ~c)) + blocks[7] + 1126891415;
    d = (d << 10 | d >>> 22) + a << 0;
    c += (a ^ (d | ~b)) + blocks[14] - 1416354905;
    c = (c << 15 | c >>> 17) + d << 0;
    b += (d ^ (c | ~a)) + blocks[5] - 57434055;
    b = (b << 21 | b >>> 11) + c << 0;
    a += (c ^ (b | ~d)) + blocks[12] + 1700485571;
    a = (a << 6 | a >>> 26) + b << 0;
    d += (b ^ (a | ~c)) + blocks[3] - 1894986606;
    d = (d << 10 | d >>> 22) + a << 0;
    c += (a ^ (d | ~b)) + blocks[10] - 1051523;
    c = (c << 15 | c >>> 17) + d << 0;
    b += (d ^ (c | ~a)) + blocks[1] - 2054922799;
    b = (b << 21 | b >>> 11) + c << 0;
    a += (c ^ (b | ~d)) + blocks[8] + 1873313359;
    a = (a << 6 | a >>> 26) + b << 0;
    d += (b ^ (a | ~c)) + blocks[15] - 30611744;
    d = (d << 10 | d >>> 22) + a << 0;
    c += (a ^ (d | ~b)) + blocks[6] - 1560198380;
    c = (c << 15 | c >>> 17) + d << 0;
    b += (d ^ (c | ~a)) + blocks[13] + 1309151649;
    b = (b << 21 | b >>> 11) + c << 0;
    a += (c ^ (b | ~d)) + blocks[4] - 145523070;
    a = (a << 6 | a >>> 26) + b << 0;
    d += (b ^ (a | ~c)) + blocks[11] - 1120210379;
    d = (d << 10 | d >>> 22) + a << 0;
    c += (a ^ (d | ~b)) + blocks[2] + 718787259;
    c = (c << 15 | c >>> 17) + d << 0;
    b += (d ^ (c | ~a)) + blocks[9] - 343485551;
    b = (b << 21 | b >>> 11) + c << 0;

    if (this.first) {
      this.h0 = a + 1732584193 << 0;
      this.h1 = b - 271733879 << 0;
      this.h2 = c - 1732584194 << 0;
      this.h3 = d + 271733878 << 0;
      this.first = false;
    } else {
      this.h0 = this.h0 + a << 0;
      this.h1 = this.h1 + b << 0;
      this.h2 = this.h2 + c << 0;
      this.h3 = this.h3 + d << 0;
    }
  };

  /**
   * @method hex
   * @memberof Md5
   * @instance
   * @description Output hash as hex string
   * @returns {String} Hex string
   * @see {@link md5.hex}
   * @example
   * hash.hex();
   */
  Md5.prototype.hex = function () {
    this.finalize();

    var h0 = this.h0, h1 = this.h1, h2 = this.h2, h3 = this.h3;

    return HEX_CHARS[(h0 >> 4) & 0x0F] + HEX_CHARS[h0 & 0x0F] +
      HEX_CHARS[(h0 >> 12) & 0x0F] + HEX_CHARS[(h0 >> 8) & 0x0F] +
      HEX_CHARS[(h0 >> 20) & 0x0F] + HEX_CHARS[(h0 >> 16) & 0x0F] +
      HEX_CHARS[(h0 >> 28) & 0x0F] + HEX_CHARS[(h0 >> 24) & 0x0F] +
      HEX_CHARS[(h1 >> 4) & 0x0F] + HEX_CHARS[h1 & 0x0F] +
      HEX_CHARS[(h1 >> 12) & 0x0F] + HEX_CHARS[(h1 >> 8) & 0x0F] +
      HEX_CHARS[(h1 >> 20) & 0x0F] + HEX_CHARS[(h1 >> 16) & 0x0F] +
      HEX_CHARS[(h1 >> 28) & 0x0F] + HEX_CHARS[(h1 >> 24) & 0x0F] +
      HEX_CHARS[(h2 >> 4) & 0x0F] + HEX_CHARS[h2 & 0x0F] +
      HEX_CHARS[(h2 >> 12) & 0x0F] + HEX_CHARS[(h2 >> 8) & 0x0F] +
      HEX_CHARS[(h2 >> 20) & 0x0F] + HEX_CHARS[(h2 >> 16) & 0x0F] +
      HEX_CHARS[(h2 >> 28) & 0x0F] + HEX_CHARS[(h2 >> 24) & 0x0F] +
      HEX_CHARS[(h3 >> 4) & 0x0F] + HEX_CHARS[h3 & 0x0F] +
      HEX_CHARS[(h3 >> 12) & 0x0F] + HEX_CHARS[(h3 >> 8) & 0x0F] +
      HEX_CHARS[(h3 >> 20) & 0x0F] + HEX_CHARS[(h3 >> 16) & 0x0F] +
      HEX_CHARS[(h3 >> 28) & 0x0F] + HEX_CHARS[(h3 >> 24) & 0x0F];
  };

  /**
   * @method toString
   * @memberof Md5
   * @instance
   * @description Output hash as hex string
   * @returns {String} Hex string
   * @see {@link md5.hex}
   * @example
   * hash.toString();
   */
  Md5.prototype.toString = Md5.prototype.hex;

  /**
   * @method digest
   * @memberof Md5
   * @instance
   * @description Output hash as bytes array
   * @returns {Array} Bytes array
   * @see {@link md5.digest}
   * @example
   * hash.digest();
   */
  Md5.prototype.digest = function () {
    this.finalize();

    var h0 = this.h0, h1 = this.h1, h2 = this.h2, h3 = this.h3;
    return [
      h0 & 0xFF, (h0 >> 8) & 0xFF, (h0 >> 16) & 0xFF, (h0 >> 24) & 0xFF,
      h1 & 0xFF, (h1 >> 8) & 0xFF, (h1 >> 16) & 0xFF, (h1 >> 24) & 0xFF,
      h2 & 0xFF, (h2 >> 8) & 0xFF, (h2 >> 16) & 0xFF, (h2 >> 24) & 0xFF,
      h3 & 0xFF, (h3 >> 8) & 0xFF, (h3 >> 16) & 0xFF, (h3 >> 24) & 0xFF
    ];
  };

  /**
   * @method array
   * @memberof Md5
   * @instance
   * @description Output hash as bytes array
   * @returns {Array} Bytes array
   * @see {@link md5.array}
   * @example
   * hash.array();
   */
  Md5.prototype.array = Md5.prototype.digest;

  /**
   * @method arrayBuffer
   * @memberof Md5
   * @instance
   * @description Output hash as ArrayBuffer
   * @returns {ArrayBuffer} ArrayBuffer
   * @see {@link md5.arrayBuffer}
   * @example
   * hash.arrayBuffer();
   */
  Md5.prototype.arrayBuffer = function () {
    this.finalize();

    var buffer = new ArrayBuffer(16);
    var blocks = new Uint32Array(buffer);
    blocks[0] = this.h0;
    blocks[1] = this.h1;
    blocks[2] = this.h2;
    blocks[3] = this.h3;
    return buffer;
  };

  /**
   * @method buffer
   * @deprecated This maybe confuse with Buffer in node.js. Please use arrayBuffer instead.
   * @memberof Md5
   * @instance
   * @description Output hash as ArrayBuffer
   * @returns {ArrayBuffer} ArrayBuffer
   * @see {@link md5.buffer}
   * @example
   * hash.buffer();
   */
  Md5.prototype.buffer = Md5.prototype.arrayBuffer;

  /**
   * @method base64
   * @memberof Md5
   * @instance
   * @description Output hash as base64 string
   * @returns {String} base64 string
   * @see {@link md5.base64}
   * @example
   * hash.base64();
   */
  Md5.prototype.base64 = function () {
    var v1, v2, v3, base64Str = '', bytes = this.array();
    for (var i = 0; i < 15;) {
      v1 = bytes[i++];
      v2 = bytes[i++];
      v3 = bytes[i++];
      base64Str += BASE64_ENCODE_CHAR[v1 >>> 2] +
        BASE64_ENCODE_CHAR[(v1 << 4 | v2 >>> 4) & 63] +
        BASE64_ENCODE_CHAR[(v2 << 2 | v3 >>> 6) & 63] +
        BASE64_ENCODE_CHAR[v3 & 63];
    }
    v1 = bytes[i];
    base64Str += BASE64_ENCODE_CHAR[v1 >>> 2] +
      BASE64_ENCODE_CHAR[(v1 << 4) & 63] +
      '==';
    return base64Str;
  };

  var exports = createMethod();

  if (COMMON_JS) {
    module.exports = exports;
  } else {
    /**
     * @method md5
     * @description Md5 hash function, export to global in browsers.
     * @param {String|Array|Uint8Array|ArrayBuffer} message message to hash
     * @returns {String} md5 hashes
     * @example
     * md5(''); // d41d8cd98f00b204e9800998ecf8427e
     * md5('The quick brown fox jumps over the lazy dog'); // 9e107d9d372bb6826bd81d3542a419d6
     * md5('The quick brown fox jumps over the lazy dog.'); // e4d909c290d0fb1ca068ffaddf22cbd0
     *
     * // It also supports UTF-8 encoding
     * md5(''); // a7bac2239fcdcb3a067903d8077c4a07
     *
     * // It also supports byte `Array`, `Uint8Array`, `ArrayBuffer`
     * md5([]); // d41d8cd98f00b204e9800998ecf8427e
     * md5(new Uint8Array([])); // d41d8cd98f00b204e9800998ecf8427e
     */
    root.md5 = exports;
    if (AMD) {
      !(__WEBPACK_AMD_DEFINE_RESULT__ = (function () {
        return exports;
      }).call(exports, __webpack_require__, exports, module),
		__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));
    }
  }
})();


/***/ }),

/***/ "./node_modules/lodash.clonedeep/index.js":
/*!************************************************!*\
  !*** ./node_modules/lodash.clonedeep/index.js ***!
  \************************************************/
/***/ ((module, exports, __webpack_require__) => {

/* module decorator */ module = __webpack_require__.nmd(module);
/**
 * lodash (Custom Build) <https://lodash.com/>
 * Build: `lodash modularize exports="npm" -o ./`
 * Copyright jQuery Foundation and other contributors <https://jquery.org/>
 * Released under MIT license <https://lodash.com/license>
 * Based on Underscore.js 1.8.3 <http://underscorejs.org/LICENSE>
 * Copyright Jeremy Ashkenas, DocumentCloud and Investigative Reporters & Editors
 */

/** Used as the size to enable large array optimizations. */
var LARGE_ARRAY_SIZE = 200;

/** Used to stand-in for `undefined` hash values. */
var HASH_UNDEFINED = '__lodash_hash_undefined__';

/** Used as references for various `Number` constants. */
var MAX_SAFE_INTEGER = 9007199254740991;

/** `Object#toString` result references. */
var argsTag = '[object Arguments]',
    arrayTag = '[object Array]',
    boolTag = '[object Boolean]',
    dateTag = '[object Date]',
    errorTag = '[object Error]',
    funcTag = '[object Function]',
    genTag = '[object GeneratorFunction]',
    mapTag = '[object Map]',
    numberTag = '[object Number]',
    objectTag = '[object Object]',
    promiseTag = '[object Promise]',
    regexpTag = '[object RegExp]',
    setTag = '[object Set]',
    stringTag = '[object String]',
    symbolTag = '[object Symbol]',
    weakMapTag = '[object WeakMap]';

var arrayBufferTag = '[object ArrayBuffer]',
    dataViewTag = '[object DataView]',
    float32Tag = '[object Float32Array]',
    float64Tag = '[object Float64Array]',
    int8Tag = '[object Int8Array]',
    int16Tag = '[object Int16Array]',
    int32Tag = '[object Int32Array]',
    uint8Tag = '[object Uint8Array]',
    uint8ClampedTag = '[object Uint8ClampedArray]',
    uint16Tag = '[object Uint16Array]',
    uint32Tag = '[object Uint32Array]';

/**
 * Used to match `RegExp`
 * [syntax characters](http://ecma-international.org/ecma-262/7.0/#sec-patterns).
 */
var reRegExpChar = /[\\^$.*+?()[\]{}|]/g;

/** Used to match `RegExp` flags from their coerced string values. */
var reFlags = /\w*$/;

/** Used to detect host constructors (Safari). */
var reIsHostCtor = /^\[object .+?Constructor\]$/;

/** Used to detect unsigned integer values. */
var reIsUint = /^(?:0|[1-9]\d*)$/;

/** Used to identify `toStringTag` values supported by `_.clone`. */
var cloneableTags = {};
cloneableTags[argsTag] = cloneableTags[arrayTag] =
cloneableTags[arrayBufferTag] = cloneableTags[dataViewTag] =
cloneableTags[boolTag] = cloneableTags[dateTag] =
cloneableTags[float32Tag] = cloneableTags[float64Tag] =
cloneableTags[int8Tag] = cloneableTags[int16Tag] =
cloneableTags[int32Tag] = cloneableTags[mapTag] =
cloneableTags[numberTag] = cloneableTags[objectTag] =
cloneableTags[regexpTag] = cloneableTags[setTag] =
cloneableTags[stringTag] = cloneableTags[symbolTag] =
cloneableTags[uint8Tag] = cloneableTags[uint8ClampedTag] =
cloneableTags[uint16Tag] = cloneableTags[uint32Tag] = true;
cloneableTags[errorTag] = cloneableTags[funcTag] =
cloneableTags[weakMapTag] = false;

/** Detect free variable `global` from Node.js. */
var freeGlobal = typeof __webpack_require__.g == 'object' && __webpack_require__.g && __webpack_require__.g.Object === Object && __webpack_require__.g;

/** Detect free variable `self`. */
var freeSelf = typeof self == 'object' && self && self.Object === Object && self;

/** Used as a reference to the global object. */
var root = freeGlobal || freeSelf || Function('return this')();

/** Detect free variable `exports`. */
var freeExports =  true && exports && !exports.nodeType && exports;

/** Detect free variable `module`. */
var freeModule = freeExports && "object" == 'object' && module && !module.nodeType && module;

/** Detect the popular CommonJS extension `module.exports`. */
var moduleExports = freeModule && freeModule.exports === freeExports;

/**
 * Adds the key-value `pair` to `map`.
 *
 * @private
 * @param {Object} map The map to modify.
 * @param {Array} pair The key-value pair to add.
 * @returns {Object} Returns `map`.
 */
function addMapEntry(map, pair) {
  // Don't return `map.set` because it's not chainable in IE 11.
  map.set(pair[0], pair[1]);
  return map;
}

/**
 * Adds `value` to `set`.
 *
 * @private
 * @param {Object} set The set to modify.
 * @param {*} value The value to add.
 * @returns {Object} Returns `set`.
 */
function addSetEntry(set, value) {
  // Don't return `set.add` because it's not chainable in IE 11.
  set.add(value);
  return set;
}

/**
 * A specialized version of `_.forEach` for arrays without support for
 * iteratee shorthands.
 *
 * @private
 * @param {Array} [array] The array to iterate over.
 * @param {Function} iteratee The function invoked per iteration.
 * @returns {Array} Returns `array`.
 */
function arrayEach(array, iteratee) {
  var index = -1,
      length = array ? array.length : 0;

  while (++index < length) {
    if (iteratee(array[index], index, array) === false) {
      break;
    }
  }
  return array;
}

/**
 * Appends the elements of `values` to `array`.
 *
 * @private
 * @param {Array} array The array to modify.
 * @param {Array} values The values to append.
 * @returns {Array} Returns `array`.
 */
function arrayPush(array, values) {
  var index = -1,
      length = values.length,
      offset = array.length;

  while (++index < length) {
    array[offset + index] = values[index];
  }
  return array;
}

/**
 * A specialized version of `_.reduce` for arrays without support for
 * iteratee shorthands.
 *
 * @private
 * @param {Array} [array] The array to iterate over.
 * @param {Function} iteratee The function invoked per iteration.
 * @param {*} [accumulator] The initial value.
 * @param {boolean} [initAccum] Specify using the first element of `array` as
 *  the initial value.
 * @returns {*} Returns the accumulated value.
 */
function arrayReduce(array, iteratee, accumulator, initAccum) {
  var index = -1,
      length = array ? array.length : 0;

  if (initAccum && length) {
    accumulator = array[++index];
  }
  while (++index < length) {
    accumulator = iteratee(accumulator, array[index], index, array);
  }
  return accumulator;
}

/**
 * The base implementation of `_.times` without support for iteratee shorthands
 * or max array length checks.
 *
 * @private
 * @param {number} n The number of times to invoke `iteratee`.
 * @param {Function} iteratee The function invoked per iteration.
 * @returns {Array} Returns the array of results.
 */
function baseTimes(n, iteratee) {
  var index = -1,
      result = Array(n);

  while (++index < n) {
    result[index] = iteratee(index);
  }
  return result;
}

/**
 * Gets the value at `key` of `object`.
 *
 * @private
 * @param {Object} [object] The object to query.
 * @param {string} key The key of the property to get.
 * @returns {*} Returns the property value.
 */
function getValue(object, key) {
  return object == null ? undefined : object[key];
}

/**
 * Checks if `value` is a host object in IE < 9.
 *
 * @private
 * @param {*} value The value to check.
 * @returns {boolean} Returns `true` if `value` is a host object, else `false`.
 */
function isHostObject(value) {
  // Many host objects are `Object` objects that can coerce to strings
  // despite having improperly defined `toString` methods.
  var result = false;
  if (value != null && typeof value.toString != 'function') {
    try {
      result = !!(value + '');
    } catch (e) {}
  }
  return result;
}

/**
 * Converts `map` to its key-value pairs.
 *
 * @private
 * @param {Object} map The map to convert.
 * @returns {Array} Returns the key-value pairs.
 */
function mapToArray(map) {
  var index = -1,
      result = Array(map.size);

  map.forEach(function(value, key) {
    result[++index] = [key, value];
  });
  return result;
}

/**
 * Creates a unary function that invokes `func` with its argument transformed.
 *
 * @private
 * @param {Function} func The function to wrap.
 * @param {Function} transform The argument transform.
 * @returns {Function} Returns the new function.
 */
function overArg(func, transform) {
  return function(arg) {
    return func(transform(arg));
  };
}

/**
 * Converts `set` to an array of its values.
 *
 * @private
 * @param {Object} set The set to convert.
 * @returns {Array} Returns the values.
 */
function setToArray(set) {
  var index = -1,
      result = Array(set.size);

  set.forEach(function(value) {
    result[++index] = value;
  });
  return result;
}

/** Used for built-in method references. */
var arrayProto = Array.prototype,
    funcProto = Function.prototype,
    objectProto = Object.prototype;

/** Used to detect overreaching core-js shims. */
var coreJsData = root['__core-js_shared__'];

/** Used to detect methods masquerading as native. */
var maskSrcKey = (function() {
  var uid = /[^.]+$/.exec(coreJsData && coreJsData.keys && coreJsData.keys.IE_PROTO || '');
  return uid ? ('Symbol(src)_1.' + uid) : '';
}());

/** Used to resolve the decompiled source of functions. */
var funcToString = funcProto.toString;

/** Used to check objects for own properties. */
var hasOwnProperty = objectProto.hasOwnProperty;

/**
 * Used to resolve the
 * [`toStringTag`](http://ecma-international.org/ecma-262/7.0/#sec-object.prototype.tostring)
 * of values.
 */
var objectToString = objectProto.toString;

/** Used to detect if a method is native. */
var reIsNative = RegExp('^' +
  funcToString.call(hasOwnProperty).replace(reRegExpChar, '\\$&')
  .replace(/hasOwnProperty|(function).*?(?=\\\()| for .+?(?=\\\])/g, '$1.*?') + '$'
);

/** Built-in value references. */
var Buffer = moduleExports ? root.Buffer : undefined,
    Symbol = root.Symbol,
    Uint8Array = root.Uint8Array,
    getPrototype = overArg(Object.getPrototypeOf, Object),
    objectCreate = Object.create,
    propertyIsEnumerable = objectProto.propertyIsEnumerable,
    splice = arrayProto.splice;

/* Built-in method references for those with the same name as other `lodash` methods. */
var nativeGetSymbols = Object.getOwnPropertySymbols,
    nativeIsBuffer = Buffer ? Buffer.isBuffer : undefined,
    nativeKeys = overArg(Object.keys, Object);

/* Built-in method references that are verified to be native. */
var DataView = getNative(root, 'DataView'),
    Map = getNative(root, 'Map'),
    Promise = getNative(root, 'Promise'),
    Set = getNative(root, 'Set'),
    WeakMap = getNative(root, 'WeakMap'),
    nativeCreate = getNative(Object, 'create');

/** Used to detect maps, sets, and weakmaps. */
var dataViewCtorString = toSource(DataView),
    mapCtorString = toSource(Map),
    promiseCtorString = toSource(Promise),
    setCtorString = toSource(Set),
    weakMapCtorString = toSource(WeakMap);

/** Used to convert symbols to primitives and strings. */
var symbolProto = Symbol ? Symbol.prototype : undefined,
    symbolValueOf = symbolProto ? symbolProto.valueOf : undefined;

/**
 * Creates a hash object.
 *
 * @private
 * @constructor
 * @param {Array} [entries] The key-value pairs to cache.
 */
function Hash(entries) {
  var index = -1,
      length = entries ? entries.length : 0;

  this.clear();
  while (++index < length) {
    var entry = entries[index];
    this.set(entry[0], entry[1]);
  }
}

/**
 * Removes all key-value entries from the hash.
 *
 * @private
 * @name clear
 * @memberOf Hash
 */
function hashClear() {
  this.__data__ = nativeCreate ? nativeCreate(null) : {};
}

/**
 * Removes `key` and its value from the hash.
 *
 * @private
 * @name delete
 * @memberOf Hash
 * @param {Object} hash The hash to modify.
 * @param {string} key The key of the value to remove.
 * @returns {boolean} Returns `true` if the entry was removed, else `false`.
 */
function hashDelete(key) {
  return this.has(key) && delete this.__data__[key];
}

/**
 * Gets the hash value for `key`.
 *
 * @private
 * @name get
 * @memberOf Hash
 * @param {string} key The key of the value to get.
 * @returns {*} Returns the entry value.
 */
function hashGet(key) {
  var data = this.__data__;
  if (nativeCreate) {
    var result = data[key];
    return result === HASH_UNDEFINED ? undefined : result;
  }
  return hasOwnProperty.call(data, key) ? data[key] : undefined;
}

/**
 * Checks if a hash value for `key` exists.
 *
 * @private
 * @name has
 * @memberOf Hash
 * @param {string} key The key of the entry to check.
 * @returns {boolean} Returns `true` if an entry for `key` exists, else `false`.
 */
function hashHas(key) {
  var data = this.__data__;
  return nativeCreate ? data[key] !== undefined : hasOwnProperty.call(data, key);
}

/**
 * Sets the hash `key` to `value`.
 *
 * @private
 * @name set
 * @memberOf Hash
 * @param {string} key The key of the value to set.
 * @param {*} value The value to set.
 * @returns {Object} Returns the hash instance.
 */
function hashSet(key, value) {
  var data = this.__data__;
  data[key] = (nativeCreate && value === undefined) ? HASH_UNDEFINED : value;
  return this;
}

// Add methods to `Hash`.
Hash.prototype.clear = hashClear;
Hash.prototype['delete'] = hashDelete;
Hash.prototype.get = hashGet;
Hash.prototype.has = hashHas;
Hash.prototype.set = hashSet;

/**
 * Creates an list cache object.
 *
 * @private
 * @constructor
 * @param {Array} [entries] The key-value pairs to cache.
 */
function ListCache(entries) {
  var index = -1,
      length = entries ? entries.length : 0;

  this.clear();
  while (++index < length) {
    var entry = entries[index];
    this.set(entry[0], entry[1]);
  }
}

/**
 * Removes all key-value entries from the list cache.
 *
 * @private
 * @name clear
 * @memberOf ListCache
 */
function listCacheClear() {
  this.__data__ = [];
}

/**
 * Removes `key` and its value from the list cache.
 *
 * @private
 * @name delete
 * @memberOf ListCache
 * @param {string} key The key of the value to remove.
 * @returns {boolean} Returns `true` if the entry was removed, else `false`.
 */
function listCacheDelete(key) {
  var data = this.__data__,
      index = assocIndexOf(data, key);

  if (index < 0) {
    return false;
  }
  var lastIndex = data.length - 1;
  if (index == lastIndex) {
    data.pop();
  } else {
    splice.call(data, index, 1);
  }
  return true;
}

/**
 * Gets the list cache value for `key`.
 *
 * @private
 * @name get
 * @memberOf ListCache
 * @param {string} key The key of the value to get.
 * @returns {*} Returns the entry value.
 */
function listCacheGet(key) {
  var data = this.__data__,
      index = assocIndexOf(data, key);

  return index < 0 ? undefined : data[index][1];
}

/**
 * Checks if a list cache value for `key` exists.
 *
 * @private
 * @name has
 * @memberOf ListCache
 * @param {string} key The key of the entry to check.
 * @returns {boolean} Returns `true` if an entry for `key` exists, else `false`.
 */
function listCacheHas(key) {
  return assocIndexOf(this.__data__, key) > -1;
}

/**
 * Sets the list cache `key` to `value`.
 *
 * @private
 * @name set
 * @memberOf ListCache
 * @param {string} key The key of the value to set.
 * @param {*} value The value to set.
 * @returns {Object} Returns the list cache instance.
 */
function listCacheSet(key, value) {
  var data = this.__data__,
      index = assocIndexOf(data, key);

  if (index < 0) {
    data.push([key, value]);
  } else {
    data[index][1] = value;
  }
  return this;
}

// Add methods to `ListCache`.
ListCache.prototype.clear = listCacheClear;
ListCache.prototype['delete'] = listCacheDelete;
ListCache.prototype.get = listCacheGet;
ListCache.prototype.has = listCacheHas;
ListCache.prototype.set = listCacheSet;

/**
 * Creates a map cache object to store key-value pairs.
 *
 * @private
 * @constructor
 * @param {Array} [entries] The key-value pairs to cache.
 */
function MapCache(entries) {
  var index = -1,
      length = entries ? entries.length : 0;

  this.clear();
  while (++index < length) {
    var entry = entries[index];
    this.set(entry[0], entry[1]);
  }
}

/**
 * Removes all key-value entries from the map.
 *
 * @private
 * @name clear
 * @memberOf MapCache
 */
function mapCacheClear() {
  this.__data__ = {
    'hash': new Hash,
    'map': new (Map || ListCache),
    'string': new Hash
  };
}

/**
 * Removes `key` and its value from the map.
 *
 * @private
 * @name delete
 * @memberOf MapCache
 * @param {string} key The key of the value to remove.
 * @returns {boolean} Returns `true` if the entry was removed, else `false`.
 */
function mapCacheDelete(key) {
  return getMapData(this, key)['delete'](key);
}

/**
 * Gets the map value for `key`.
 *
 * @private
 * @name get
 * @memberOf MapCache
 * @param {string} key The key of the value to get.
 * @returns {*} Returns the entry value.
 */
function mapCacheGet(key) {
  return getMapData(this, key).get(key);
}

/**
 * Checks if a map value for `key` exists.
 *
 * @private
 * @name has
 * @memberOf MapCache
 * @param {string} key The key of the entry to check.
 * @returns {boolean} Returns `true` if an entry for `key` exists, else `false`.
 */
function mapCacheHas(key) {
  return getMapData(this, key).has(key);
}

/**
 * Sets the map `key` to `value`.
 *
 * @private
 * @name set
 * @memberOf MapCache
 * @param {string} key The key of the value to set.
 * @param {*} value The value to set.
 * @returns {Object} Returns the map cache instance.
 */
function mapCacheSet(key, value) {
  getMapData(this, key).set(key, value);
  return this;
}

// Add methods to `MapCache`.
MapCache.prototype.clear = mapCacheClear;
MapCache.prototype['delete'] = mapCacheDelete;
MapCache.prototype.get = mapCacheGet;
MapCache.prototype.has = mapCacheHas;
MapCache.prototype.set = mapCacheSet;

/**
 * Creates a stack cache object to store key-value pairs.
 *
 * @private
 * @constructor
 * @param {Array} [entries] The key-value pairs to cache.
 */
function Stack(entries) {
  this.__data__ = new ListCache(entries);
}

/**
 * Removes all key-value entries from the stack.
 *
 * @private
 * @name clear
 * @memberOf Stack
 */
function stackClear() {
  this.__data__ = new ListCache;
}

/**
 * Removes `key` and its value from the stack.
 *
 * @private
 * @name delete
 * @memberOf Stack
 * @param {string} key The key of the value to remove.
 * @returns {boolean} Returns `true` if the entry was removed, else `false`.
 */
function stackDelete(key) {
  return this.__data__['delete'](key);
}

/**
 * Gets the stack value for `key`.
 *
 * @private
 * @name get
 * @memberOf Stack
 * @param {string} key The key of the value to get.
 * @returns {*} Returns the entry value.
 */
function stackGet(key) {
  return this.__data__.get(key);
}

/**
 * Checks if a stack value for `key` exists.
 *
 * @private
 * @name has
 * @memberOf Stack
 * @param {string} key The key of the entry to check.
 * @returns {boolean} Returns `true` if an entry for `key` exists, else `false`.
 */
function stackHas(key) {
  return this.__data__.has(key);
}

/**
 * Sets the stack `key` to `value`.
 *
 * @private
 * @name set
 * @memberOf Stack
 * @param {string} key The key of the value to set.
 * @param {*} value The value to set.
 * @returns {Object} Returns the stack cache instance.
 */
function stackSet(key, value) {
  var cache = this.__data__;
  if (cache instanceof ListCache) {
    var pairs = cache.__data__;
    if (!Map || (pairs.length < LARGE_ARRAY_SIZE - 1)) {
      pairs.push([key, value]);
      return this;
    }
    cache = this.__data__ = new MapCache(pairs);
  }
  cache.set(key, value);
  return this;
}

// Add methods to `Stack`.
Stack.prototype.clear = stackClear;
Stack.prototype['delete'] = stackDelete;
Stack.prototype.get = stackGet;
Stack.prototype.has = stackHas;
Stack.prototype.set = stackSet;

/**
 * Creates an array of the enumerable property names of the array-like `value`.
 *
 * @private
 * @param {*} value The value to query.
 * @param {boolean} inherited Specify returning inherited property names.
 * @returns {Array} Returns the array of property names.
 */
function arrayLikeKeys(value, inherited) {
  // Safari 8.1 makes `arguments.callee` enumerable in strict mode.
  // Safari 9 makes `arguments.length` enumerable in strict mode.
  var result = (isArray(value) || isArguments(value))
    ? baseTimes(value.length, String)
    : [];

  var length = result.length,
      skipIndexes = !!length;

  for (var key in value) {
    if ((inherited || hasOwnProperty.call(value, key)) &&
        !(skipIndexes && (key == 'length' || isIndex(key, length)))) {
      result.push(key);
    }
  }
  return result;
}

/**
 * Assigns `value` to `key` of `object` if the existing value is not equivalent
 * using [`SameValueZero`](http://ecma-international.org/ecma-262/7.0/#sec-samevaluezero)
 * for equality comparisons.
 *
 * @private
 * @param {Object} object The object to modify.
 * @param {string} key The key of the property to assign.
 * @param {*} value The value to assign.
 */
function assignValue(object, key, value) {
  var objValue = object[key];
  if (!(hasOwnProperty.call(object, key) && eq(objValue, value)) ||
      (value === undefined && !(key in object))) {
    object[key] = value;
  }
}

/**
 * Gets the index at which the `key` is found in `array` of key-value pairs.
 *
 * @private
 * @param {Array} array The array to inspect.
 * @param {*} key The key to search for.
 * @returns {number} Returns the index of the matched value, else `-1`.
 */
function assocIndexOf(array, key) {
  var length = array.length;
  while (length--) {
    if (eq(array[length][0], key)) {
      return length;
    }
  }
  return -1;
}

/**
 * The base implementation of `_.assign` without support for multiple sources
 * or `customizer` functions.
 *
 * @private
 * @param {Object} object The destination object.
 * @param {Object} source The source object.
 * @returns {Object} Returns `object`.
 */
function baseAssign(object, source) {
  return object && copyObject(source, keys(source), object);
}

/**
 * The base implementation of `_.clone` and `_.cloneDeep` which tracks
 * traversed objects.
 *
 * @private
 * @param {*} value The value to clone.
 * @param {boolean} [isDeep] Specify a deep clone.
 * @param {boolean} [isFull] Specify a clone including symbols.
 * @param {Function} [customizer] The function to customize cloning.
 * @param {string} [key] The key of `value`.
 * @param {Object} [object] The parent object of `value`.
 * @param {Object} [stack] Tracks traversed objects and their clone counterparts.
 * @returns {*} Returns the cloned value.
 */
function baseClone(value, isDeep, isFull, customizer, key, object, stack) {
  var result;
  if (customizer) {
    result = object ? customizer(value, key, object, stack) : customizer(value);
  }
  if (result !== undefined) {
    return result;
  }
  if (!isObject(value)) {
    return value;
  }
  var isArr = isArray(value);
  if (isArr) {
    result = initCloneArray(value);
    if (!isDeep) {
      return copyArray(value, result);
    }
  } else {
    var tag = getTag(value),
        isFunc = tag == funcTag || tag == genTag;

    if (isBuffer(value)) {
      return cloneBuffer(value, isDeep);
    }
    if (tag == objectTag || tag == argsTag || (isFunc && !object)) {
      if (isHostObject(value)) {
        return object ? value : {};
      }
      result = initCloneObject(isFunc ? {} : value);
      if (!isDeep) {
        return copySymbols(value, baseAssign(result, value));
      }
    } else {
      if (!cloneableTags[tag]) {
        return object ? value : {};
      }
      result = initCloneByTag(value, tag, baseClone, isDeep);
    }
  }
  // Check for circular references and return its corresponding clone.
  stack || (stack = new Stack);
  var stacked = stack.get(value);
  if (stacked) {
    return stacked;
  }
  stack.set(value, result);

  if (!isArr) {
    var props = isFull ? getAllKeys(value) : keys(value);
  }
  arrayEach(props || value, function(subValue, key) {
    if (props) {
      key = subValue;
      subValue = value[key];
    }
    // Recursively populate clone (susceptible to call stack limits).
    assignValue(result, key, baseClone(subValue, isDeep, isFull, customizer, key, value, stack));
  });
  return result;
}

/**
 * The base implementation of `_.create` without support for assigning
 * properties to the created object.
 *
 * @private
 * @param {Object} prototype The object to inherit from.
 * @returns {Object} Returns the new object.
 */
function baseCreate(proto) {
  return isObject(proto) ? objectCreate(proto) : {};
}

/**
 * The base implementation of `getAllKeys` and `getAllKeysIn` which uses
 * `keysFunc` and `symbolsFunc` to get the enumerable property names and
 * symbols of `object`.
 *
 * @private
 * @param {Object} object The object to query.
 * @param {Function} keysFunc The function to get the keys of `object`.
 * @param {Function} symbolsFunc The function to get the symbols of `object`.
 * @returns {Array} Returns the array of property names and symbols.
 */
function baseGetAllKeys(object, keysFunc, symbolsFunc) {
  var result = keysFunc(object);
  return isArray(object) ? result : arrayPush(result, symbolsFunc(object));
}

/**
 * The base implementation of `getTag`.
 *
 * @private
 * @param {*} value The value to query.
 * @returns {string} Returns the `toStringTag`.
 */
function baseGetTag(value) {
  return objectToString.call(value);
}

/**
 * The base implementation of `_.isNative` without bad shim checks.
 *
 * @private
 * @param {*} value The value to check.
 * @returns {boolean} Returns `true` if `value` is a native function,
 *  else `false`.
 */
function baseIsNative(value) {
  if (!isObject(value) || isMasked(value)) {
    return false;
  }
  var pattern = (isFunction(value) || isHostObject(value)) ? reIsNative : reIsHostCtor;
  return pattern.test(toSource(value));
}

/**
 * The base implementation of `_.keys` which doesn't treat sparse arrays as dense.
 *
 * @private
 * @param {Object} object The object to query.
 * @returns {Array} Returns the array of property names.
 */
function baseKeys(object) {
  if (!isPrototype(object)) {
    return nativeKeys(object);
  }
  var result = [];
  for (var key in Object(object)) {
    if (hasOwnProperty.call(object, key) && key != 'constructor') {
      result.push(key);
    }
  }
  return result;
}

/**
 * Creates a clone of  `buffer`.
 *
 * @private
 * @param {Buffer} buffer The buffer to clone.
 * @param {boolean} [isDeep] Specify a deep clone.
 * @returns {Buffer} Returns the cloned buffer.
 */
function cloneBuffer(buffer, isDeep) {
  if (isDeep) {
    return buffer.slice();
  }
  var result = new buffer.constructor(buffer.length);
  buffer.copy(result);
  return result;
}

/**
 * Creates a clone of `arrayBuffer`.
 *
 * @private
 * @param {ArrayBuffer} arrayBuffer The array buffer to clone.
 * @returns {ArrayBuffer} Returns the cloned array buffer.
 */
function cloneArrayBuffer(arrayBuffer) {
  var result = new arrayBuffer.constructor(arrayBuffer.byteLength);
  new Uint8Array(result).set(new Uint8Array(arrayBuffer));
  return result;
}

/**
 * Creates a clone of `dataView`.
 *
 * @private
 * @param {Object} dataView The data view to clone.
 * @param {boolean} [isDeep] Specify a deep clone.
 * @returns {Object} Returns the cloned data view.
 */
function cloneDataView(dataView, isDeep) {
  var buffer = isDeep ? cloneArrayBuffer(dataView.buffer) : dataView.buffer;
  return new dataView.constructor(buffer, dataView.byteOffset, dataView.byteLength);
}

/**
 * Creates a clone of `map`.
 *
 * @private
 * @param {Object} map The map to clone.
 * @param {Function} cloneFunc The function to clone values.
 * @param {boolean} [isDeep] Specify a deep clone.
 * @returns {Object} Returns the cloned map.
 */
function cloneMap(map, isDeep, cloneFunc) {
  var array = isDeep ? cloneFunc(mapToArray(map), true) : mapToArray(map);
  return arrayReduce(array, addMapEntry, new map.constructor);
}

/**
 * Creates a clone of `regexp`.
 *
 * @private
 * @param {Object} regexp The regexp to clone.
 * @returns {Object} Returns the cloned regexp.
 */
function cloneRegExp(regexp) {
  var result = new regexp.constructor(regexp.source, reFlags.exec(regexp));
  result.lastIndex = regexp.lastIndex;
  return result;
}

/**
 * Creates a clone of `set`.
 *
 * @private
 * @param {Object} set The set to clone.
 * @param {Function} cloneFunc The function to clone values.
 * @param {boolean} [isDeep] Specify a deep clone.
 * @returns {Object} Returns the cloned set.
 */
function cloneSet(set, isDeep, cloneFunc) {
  var array = isDeep ? cloneFunc(setToArray(set), true) : setToArray(set);
  return arrayReduce(array, addSetEntry, new set.constructor);
}

/**
 * Creates a clone of the `symbol` object.
 *
 * @private
 * @param {Object} symbol The symbol object to clone.
 * @returns {Object} Returns the cloned symbol object.
 */
function cloneSymbol(symbol) {
  return symbolValueOf ? Object(symbolValueOf.call(symbol)) : {};
}

/**
 * Creates a clone of `typedArray`.
 *
 * @private
 * @param {Object} typedArray The typed array to clone.
 * @param {boolean} [isDeep] Specify a deep clone.
 * @returns {Object} Returns the cloned typed array.
 */
function cloneTypedArray(typedArray, isDeep) {
  var buffer = isDeep ? cloneArrayBuffer(typedArray.buffer) : typedArray.buffer;
  return new typedArray.constructor(buffer, typedArray.byteOffset, typedArray.length);
}

/**
 * Copies the values of `source` to `array`.
 *
 * @private
 * @param {Array} source The array to copy values from.
 * @param {Array} [array=[]] The array to copy values to.
 * @returns {Array} Returns `array`.
 */
function copyArray(source, array) {
  var index = -1,
      length = source.length;

  array || (array = Array(length));
  while (++index < length) {
    array[index] = source[index];
  }
  return array;
}

/**
 * Copies properties of `source` to `object`.
 *
 * @private
 * @param {Object} source The object to copy properties from.
 * @param {Array} props The property identifiers to copy.
 * @param {Object} [object={}] The object to copy properties to.
 * @param {Function} [customizer] The function to customize copied values.
 * @returns {Object} Returns `object`.
 */
function copyObject(source, props, object, customizer) {
  object || (object = {});

  var index = -1,
      length = props.length;

  while (++index < length) {
    var key = props[index];

    var newValue = customizer
      ? customizer(object[key], source[key], key, object, source)
      : undefined;

    assignValue(object, key, newValue === undefined ? source[key] : newValue);
  }
  return object;
}

/**
 * Copies own symbol properties of `source` to `object`.
 *
 * @private
 * @param {Object} source The object to copy symbols from.
 * @param {Object} [object={}] The object to copy symbols to.
 * @returns {Object} Returns `object`.
 */
function copySymbols(source, object) {
  return copyObject(source, getSymbols(source), object);
}

/**
 * Creates an array of own enumerable property names and symbols of `object`.
 *
 * @private
 * @param {Object} object The object to query.
 * @returns {Array} Returns the array of property names and symbols.
 */
function getAllKeys(object) {
  return baseGetAllKeys(object, keys, getSymbols);
}

/**
 * Gets the data for `map`.
 *
 * @private
 * @param {Object} map The map to query.
 * @param {string} key The reference key.
 * @returns {*} Returns the map data.
 */
function getMapData(map, key) {
  var data = map.__data__;
  return isKeyable(key)
    ? data[typeof key == 'string' ? 'string' : 'hash']
    : data.map;
}

/**
 * Gets the native function at `key` of `object`.
 *
 * @private
 * @param {Object} object The object to query.
 * @param {string} key The key of the method to get.
 * @returns {*} Returns the function if it's native, else `undefined`.
 */
function getNative(object, key) {
  var value = getValue(object, key);
  return baseIsNative(value) ? value : undefined;
}

/**
 * Creates an array of the own enumerable symbol properties of `object`.
 *
 * @private
 * @param {Object} object The object to query.
 * @returns {Array} Returns the array of symbols.
 */
var getSymbols = nativeGetSymbols ? overArg(nativeGetSymbols, Object) : stubArray;

/**
 * Gets the `toStringTag` of `value`.
 *
 * @private
 * @param {*} value The value to query.
 * @returns {string} Returns the `toStringTag`.
 */
var getTag = baseGetTag;

// Fallback for data views, maps, sets, and weak maps in IE 11,
// for data views in Edge < 14, and promises in Node.js.
if ((DataView && getTag(new DataView(new ArrayBuffer(1))) != dataViewTag) ||
    (Map && getTag(new Map) != mapTag) ||
    (Promise && getTag(Promise.resolve()) != promiseTag) ||
    (Set && getTag(new Set) != setTag) ||
    (WeakMap && getTag(new WeakMap) != weakMapTag)) {
  getTag = function(value) {
    var result = objectToString.call(value),
        Ctor = result == objectTag ? value.constructor : undefined,
        ctorString = Ctor ? toSource(Ctor) : undefined;

    if (ctorString) {
      switch (ctorString) {
        case dataViewCtorString: return dataViewTag;
        case mapCtorString: return mapTag;
        case promiseCtorString: return promiseTag;
        case setCtorString: return setTag;
        case weakMapCtorString: return weakMapTag;
      }
    }
    return result;
  };
}

/**
 * Initializes an array clone.
 *
 * @private
 * @param {Array} array The array to clone.
 * @returns {Array} Returns the initialized clone.
 */
function initCloneArray(array) {
  var length = array.length,
      result = array.constructor(length);

  // Add properties assigned by `RegExp#exec`.
  if (length && typeof array[0] == 'string' && hasOwnProperty.call(array, 'index')) {
    result.index = array.index;
    result.input = array.input;
  }
  return result;
}

/**
 * Initializes an object clone.
 *
 * @private
 * @param {Object} object The object to clone.
 * @returns {Object} Returns the initialized clone.
 */
function initCloneObject(object) {
  return (typeof object.constructor == 'function' && !isPrototype(object))
    ? baseCreate(getPrototype(object))
    : {};
}

/**
 * Initializes an object clone based on its `toStringTag`.
 *
 * **Note:** This function only supports cloning values with tags of
 * `Boolean`, `Date`, `Error`, `Number`, `RegExp`, or `String`.
 *
 * @private
 * @param {Object} object The object to clone.
 * @param {string} tag The `toStringTag` of the object to clone.
 * @param {Function} cloneFunc The function to clone values.
 * @param {boolean} [isDeep] Specify a deep clone.
 * @returns {Object} Returns the initialized clone.
 */
function initCloneByTag(object, tag, cloneFunc, isDeep) {
  var Ctor = object.constructor;
  switch (tag) {
    case arrayBufferTag:
      return cloneArrayBuffer(object);

    case boolTag:
    case dateTag:
      return new Ctor(+object);

    case dataViewTag:
      return cloneDataView(object, isDeep);

    case float32Tag: case float64Tag:
    case int8Tag: case int16Tag: case int32Tag:
    case uint8Tag: case uint8ClampedTag: case uint16Tag: case uint32Tag:
      return cloneTypedArray(object, isDeep);

    case mapTag:
      return cloneMap(object, isDeep, cloneFunc);

    case numberTag:
    case stringTag:
      return new Ctor(object);

    case regexpTag:
      return cloneRegExp(object);

    case setTag:
      return cloneSet(object, isDeep, cloneFunc);

    case symbolTag:
      return cloneSymbol(object);
  }
}

/**
 * Checks if `value` is a valid array-like index.
 *
 * @private
 * @param {*} value The value to check.
 * @param {number} [length=MAX_SAFE_INTEGER] The upper bounds of a valid index.
 * @returns {boolean} Returns `true` if `value` is a valid index, else `false`.
 */
function isIndex(value, length) {
  length = length == null ? MAX_SAFE_INTEGER : length;
  return !!length &&
    (typeof value == 'number' || reIsUint.test(value)) &&
    (value > -1 && value % 1 == 0 && value < length);
}

/**
 * Checks if `value` is suitable for use as unique object key.
 *
 * @private
 * @param {*} value The value to check.
 * @returns {boolean} Returns `true` if `value` is suitable, else `false`.
 */
function isKeyable(value) {
  var type = typeof value;
  return (type == 'string' || type == 'number' || type == 'symbol' || type == 'boolean')
    ? (value !== '__proto__')
    : (value === null);
}

/**
 * Checks if `func` has its source masked.
 *
 * @private
 * @param {Function} func The function to check.
 * @returns {boolean} Returns `true` if `func` is masked, else `false`.
 */
function isMasked(func) {
  return !!maskSrcKey && (maskSrcKey in func);
}

/**
 * Checks if `value` is likely a prototype object.
 *
 * @private
 * @param {*} value The value to check.
 * @returns {boolean} Returns `true` if `value` is a prototype, else `false`.
 */
function isPrototype(value) {
  var Ctor = value && value.constructor,
      proto = (typeof Ctor == 'function' && Ctor.prototype) || objectProto;

  return value === proto;
}

/**
 * Converts `func` to its source code.
 *
 * @private
 * @param {Function} func The function to process.
 * @returns {string} Returns the source code.
 */
function toSource(func) {
  if (func != null) {
    try {
      return funcToString.call(func);
    } catch (e) {}
    try {
      return (func + '');
    } catch (e) {}
  }
  return '';
}

/**
 * This method is like `_.clone` except that it recursively clones `value`.
 *
 * @static
 * @memberOf _
 * @since 1.0.0
 * @category Lang
 * @param {*} value The value to recursively clone.
 * @returns {*} Returns the deep cloned value.
 * @see _.clone
 * @example
 *
 * var objects = [{ 'a': 1 }, { 'b': 2 }];
 *
 * var deep = _.cloneDeep(objects);
 * console.log(deep[0] === objects[0]);
 * // => false
 */
function cloneDeep(value) {
  return baseClone(value, true, true);
}

/**
 * Performs a
 * [`SameValueZero`](http://ecma-international.org/ecma-262/7.0/#sec-samevaluezero)
 * comparison between two values to determine if they are equivalent.
 *
 * @static
 * @memberOf _
 * @since 4.0.0
 * @category Lang
 * @param {*} value The value to compare.
 * @param {*} other The other value to compare.
 * @returns {boolean} Returns `true` if the values are equivalent, else `false`.
 * @example
 *
 * var object = { 'a': 1 };
 * var other = { 'a': 1 };
 *
 * _.eq(object, object);
 * // => true
 *
 * _.eq(object, other);
 * // => false
 *
 * _.eq('a', 'a');
 * // => true
 *
 * _.eq('a', Object('a'));
 * // => false
 *
 * _.eq(NaN, NaN);
 * // => true
 */
function eq(value, other) {
  return value === other || (value !== value && other !== other);
}

/**
 * Checks if `value` is likely an `arguments` object.
 *
 * @static
 * @memberOf _
 * @since 0.1.0
 * @category Lang
 * @param {*} value The value to check.
 * @returns {boolean} Returns `true` if `value` is an `arguments` object,
 *  else `false`.
 * @example
 *
 * _.isArguments(function() { return arguments; }());
 * // => true
 *
 * _.isArguments([1, 2, 3]);
 * // => false
 */
function isArguments(value) {
  // Safari 8.1 makes `arguments.callee` enumerable in strict mode.
  return isArrayLikeObject(value) && hasOwnProperty.call(value, 'callee') &&
    (!propertyIsEnumerable.call(value, 'callee') || objectToString.call(value) == argsTag);
}

/**
 * Checks if `value` is classified as an `Array` object.
 *
 * @static
 * @memberOf _
 * @since 0.1.0
 * @category Lang
 * @param {*} value The value to check.
 * @returns {boolean} Returns `true` if `value` is an array, else `false`.
 * @example
 *
 * _.isArray([1, 2, 3]);
 * // => true
 *
 * _.isArray(document.body.children);
 * // => false
 *
 * _.isArray('abc');
 * // => false
 *
 * _.isArray(_.noop);
 * // => false
 */
var isArray = Array.isArray;

/**
 * Checks if `value` is array-like. A value is considered array-like if it's
 * not a function and has a `value.length` that's an integer greater than or
 * equal to `0` and less than or equal to `Number.MAX_SAFE_INTEGER`.
 *
 * @static
 * @memberOf _
 * @since 4.0.0
 * @category Lang
 * @param {*} value The value to check.
 * @returns {boolean} Returns `true` if `value` is array-like, else `false`.
 * @example
 *
 * _.isArrayLike([1, 2, 3]);
 * // => true
 *
 * _.isArrayLike(document.body.children);
 * // => true
 *
 * _.isArrayLike('abc');
 * // => true
 *
 * _.isArrayLike(_.noop);
 * // => false
 */
function isArrayLike(value) {
  return value != null && isLength(value.length) && !isFunction(value);
}

/**
 * This method is like `_.isArrayLike` except that it also checks if `value`
 * is an object.
 *
 * @static
 * @memberOf _
 * @since 4.0.0
 * @category Lang
 * @param {*} value The value to check.
 * @returns {boolean} Returns `true` if `value` is an array-like object,
 *  else `false`.
 * @example
 *
 * _.isArrayLikeObject([1, 2, 3]);
 * // => true
 *
 * _.isArrayLikeObject(document.body.children);
 * // => true
 *
 * _.isArrayLikeObject('abc');
 * // => false
 *
 * _.isArrayLikeObject(_.noop);
 * // => false
 */
function isArrayLikeObject(value) {
  return isObjectLike(value) && isArrayLike(value);
}

/**
 * Checks if `value` is a buffer.
 *
 * @static
 * @memberOf _
 * @since 4.3.0
 * @category Lang
 * @param {*} value The value to check.
 * @returns {boolean} Returns `true` if `value` is a buffer, else `false`.
 * @example
 *
 * _.isBuffer(new Buffer(2));
 * // => true
 *
 * _.isBuffer(new Uint8Array(2));
 * // => false
 */
var isBuffer = nativeIsBuffer || stubFalse;

/**
 * Checks if `value` is classified as a `Function` object.
 *
 * @static
 * @memberOf _
 * @since 0.1.0
 * @category Lang
 * @param {*} value The value to check.
 * @returns {boolean} Returns `true` if `value` is a function, else `false`.
 * @example
 *
 * _.isFunction(_);
 * // => true
 *
 * _.isFunction(/abc/);
 * // => false
 */
function isFunction(value) {
  // The use of `Object#toString` avoids issues with the `typeof` operator
  // in Safari 8-9 which returns 'object' for typed array and other constructors.
  var tag = isObject(value) ? objectToString.call(value) : '';
  return tag == funcTag || tag == genTag;
}

/**
 * Checks if `value` is a valid array-like length.
 *
 * **Note:** This method is loosely based on
 * [`ToLength`](http://ecma-international.org/ecma-262/7.0/#sec-tolength).
 *
 * @static
 * @memberOf _
 * @since 4.0.0
 * @category Lang
 * @param {*} value The value to check.
 * @returns {boolean} Returns `true` if `value` is a valid length, else `false`.
 * @example
 *
 * _.isLength(3);
 * // => true
 *
 * _.isLength(Number.MIN_VALUE);
 * // => false
 *
 * _.isLength(Infinity);
 * // => false
 *
 * _.isLength('3');
 * // => false
 */
function isLength(value) {
  return typeof value == 'number' &&
    value > -1 && value % 1 == 0 && value <= MAX_SAFE_INTEGER;
}

/**
 * Checks if `value` is the
 * [language type](http://www.ecma-international.org/ecma-262/7.0/#sec-ecmascript-language-types)
 * of `Object`. (e.g. arrays, functions, objects, regexes, `new Number(0)`, and `new String('')`)
 *
 * @static
 * @memberOf _
 * @since 0.1.0
 * @category Lang
 * @param {*} value The value to check.
 * @returns {boolean} Returns `true` if `value` is an object, else `false`.
 * @example
 *
 * _.isObject({});
 * // => true
 *
 * _.isObject([1, 2, 3]);
 * // => true
 *
 * _.isObject(_.noop);
 * // => true
 *
 * _.isObject(null);
 * // => false
 */
function isObject(value) {
  var type = typeof value;
  return !!value && (type == 'object' || type == 'function');
}

/**
 * Checks if `value` is object-like. A value is object-like if it's not `null`
 * and has a `typeof` result of "object".
 *
 * @static
 * @memberOf _
 * @since 4.0.0
 * @category Lang
 * @param {*} value The value to check.
 * @returns {boolean} Returns `true` if `value` is object-like, else `false`.
 * @example
 *
 * _.isObjectLike({});
 * // => true
 *
 * _.isObjectLike([1, 2, 3]);
 * // => true
 *
 * _.isObjectLike(_.noop);
 * // => false
 *
 * _.isObjectLike(null);
 * // => false
 */
function isObjectLike(value) {
  return !!value && typeof value == 'object';
}

/**
 * Creates an array of the own enumerable property names of `object`.
 *
 * **Note:** Non-object values are coerced to objects. See the
 * [ES spec](http://ecma-international.org/ecma-262/7.0/#sec-object.keys)
 * for more details.
 *
 * @static
 * @since 0.1.0
 * @memberOf _
 * @category Object
 * @param {Object} object The object to query.
 * @returns {Array} Returns the array of property names.
 * @example
 *
 * function Foo() {
 *   this.a = 1;
 *   this.b = 2;
 * }
 *
 * Foo.prototype.c = 3;
 *
 * _.keys(new Foo);
 * // => ['a', 'b'] (iteration order is not guaranteed)
 *
 * _.keys('hi');
 * // => ['0', '1']
 */
function keys(object) {
  return isArrayLike(object) ? arrayLikeKeys(object) : baseKeys(object);
}

/**
 * This method returns a new empty array.
 *
 * @static
 * @memberOf _
 * @since 4.13.0
 * @category Util
 * @returns {Array} Returns the new empty array.
 * @example
 *
 * var arrays = _.times(2, _.stubArray);
 *
 * console.log(arrays);
 * // => [[], []]
 *
 * console.log(arrays[0] === arrays[1]);
 * // => false
 */
function stubArray() {
  return [];
}

/**
 * This method returns `false`.
 *
 * @static
 * @memberOf _
 * @since 4.13.0
 * @category Util
 * @returns {boolean} Returns `false`.
 * @example
 *
 * _.times(2, _.stubFalse);
 * // => [false, false]
 */
function stubFalse() {
  return false;
}

module.exports = cloneDeep;


/***/ }),

/***/ "./node_modules/lodash.debounce/index.js":
/*!***********************************************!*\
  !*** ./node_modules/lodash.debounce/index.js ***!
  \***********************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

/**
 * lodash (Custom Build) <https://lodash.com/>
 * Build: `lodash modularize exports="npm" -o ./`
 * Copyright jQuery Foundation and other contributors <https://jquery.org/>
 * Released under MIT license <https://lodash.com/license>
 * Based on Underscore.js 1.8.3 <http://underscorejs.org/LICENSE>
 * Copyright Jeremy Ashkenas, DocumentCloud and Investigative Reporters & Editors
 */

/** Used as the `TypeError` message for "Functions" methods. */
var FUNC_ERROR_TEXT = 'Expected a function';

/** Used as references for various `Number` constants. */
var NAN = 0 / 0;

/** `Object#toString` result references. */
var symbolTag = '[object Symbol]';

/** Used to match leading and trailing whitespace. */
var reTrim = /^\s+|\s+$/g;

/** Used to detect bad signed hexadecimal string values. */
var reIsBadHex = /^[-+]0x[0-9a-f]+$/i;

/** Used to detect binary string values. */
var reIsBinary = /^0b[01]+$/i;

/** Used to detect octal string values. */
var reIsOctal = /^0o[0-7]+$/i;

/** Built-in method references without a dependency on `root`. */
var freeParseInt = parseInt;

/** Detect free variable `global` from Node.js. */
var freeGlobal = typeof __webpack_require__.g == 'object' && __webpack_require__.g && __webpack_require__.g.Object === Object && __webpack_require__.g;

/** Detect free variable `self`. */
var freeSelf = typeof self == 'object' && self && self.Object === Object && self;

/** Used as a reference to the global object. */
var root = freeGlobal || freeSelf || Function('return this')();

/** Used for built-in method references. */
var objectProto = Object.prototype;

/**
 * Used to resolve the
 * [`toStringTag`](http://ecma-international.org/ecma-262/7.0/#sec-object.prototype.tostring)
 * of values.
 */
var objectToString = objectProto.toString;

/* Built-in method references for those with the same name as other `lodash` methods. */
var nativeMax = Math.max,
    nativeMin = Math.min;

/**
 * Gets the timestamp of the number of milliseconds that have elapsed since
 * the Unix epoch (1 January 1970 00:00:00 UTC).
 *
 * @static
 * @memberOf _
 * @since 2.4.0
 * @category Date
 * @returns {number} Returns the timestamp.
 * @example
 *
 * _.defer(function(stamp) {
 *   console.log(_.now() - stamp);
 * }, _.now());
 * // => Logs the number of milliseconds it took for the deferred invocation.
 */
var now = function() {
  return root.Date.now();
};

/**
 * Creates a debounced function that delays invoking `func` until after `wait`
 * milliseconds have elapsed since the last time the debounced function was
 * invoked. The debounced function comes with a `cancel` method to cancel
 * delayed `func` invocations and a `flush` method to immediately invoke them.
 * Provide `options` to indicate whether `func` should be invoked on the
 * leading and/or trailing edge of the `wait` timeout. The `func` is invoked
 * with the last arguments provided to the debounced function. Subsequent
 * calls to the debounced function return the result of the last `func`
 * invocation.
 *
 * **Note:** If `leading` and `trailing` options are `true`, `func` is
 * invoked on the trailing edge of the timeout only if the debounced function
 * is invoked more than once during the `wait` timeout.
 *
 * If `wait` is `0` and `leading` is `false`, `func` invocation is deferred
 * until to the next tick, similar to `setTimeout` with a timeout of `0`.
 *
 * See [David Corbacho's article](https://css-tricks.com/debouncing-throttling-explained-examples/)
 * for details over the differences between `_.debounce` and `_.throttle`.
 *
 * @static
 * @memberOf _
 * @since 0.1.0
 * @category Function
 * @param {Function} func The function to debounce.
 * @param {number} [wait=0] The number of milliseconds to delay.
 * @param {Object} [options={}] The options object.
 * @param {boolean} [options.leading=false]
 *  Specify invoking on the leading edge of the timeout.
 * @param {number} [options.maxWait]
 *  The maximum time `func` is allowed to be delayed before it's invoked.
 * @param {boolean} [options.trailing=true]
 *  Specify invoking on the trailing edge of the timeout.
 * @returns {Function} Returns the new debounced function.
 * @example
 *
 * // Avoid costly calculations while the window size is in flux.
 * jQuery(window).on('resize', _.debounce(calculateLayout, 150));
 *
 * // Invoke `sendMail` when clicked, debouncing subsequent calls.
 * jQuery(element).on('click', _.debounce(sendMail, 300, {
 *   'leading': true,
 *   'trailing': false
 * }));
 *
 * // Ensure `batchLog` is invoked once after 1 second of debounced calls.
 * var debounced = _.debounce(batchLog, 250, { 'maxWait': 1000 });
 * var source = new EventSource('/stream');
 * jQuery(source).on('message', debounced);
 *
 * // Cancel the trailing debounced invocation.
 * jQuery(window).on('popstate', debounced.cancel);
 */
function debounce(func, wait, options) {
  var lastArgs,
      lastThis,
      maxWait,
      result,
      timerId,
      lastCallTime,
      lastInvokeTime = 0,
      leading = false,
      maxing = false,
      trailing = true;

  if (typeof func != 'function') {
    throw new TypeError(FUNC_ERROR_TEXT);
  }
  wait = toNumber(wait) || 0;
  if (isObject(options)) {
    leading = !!options.leading;
    maxing = 'maxWait' in options;
    maxWait = maxing ? nativeMax(toNumber(options.maxWait) || 0, wait) : maxWait;
    trailing = 'trailing' in options ? !!options.trailing : trailing;
  }

  function invokeFunc(time) {
    var args = lastArgs,
        thisArg = lastThis;

    lastArgs = lastThis = undefined;
    lastInvokeTime = time;
    result = func.apply(thisArg, args);
    return result;
  }

  function leadingEdge(time) {
    // Reset any `maxWait` timer.
    lastInvokeTime = time;
    // Start the timer for the trailing edge.
    timerId = setTimeout(timerExpired, wait);
    // Invoke the leading edge.
    return leading ? invokeFunc(time) : result;
  }

  function remainingWait(time) {
    var timeSinceLastCall = time - lastCallTime,
        timeSinceLastInvoke = time - lastInvokeTime,
        result = wait - timeSinceLastCall;

    return maxing ? nativeMin(result, maxWait - timeSinceLastInvoke) : result;
  }

  function shouldInvoke(time) {
    var timeSinceLastCall = time - lastCallTime,
        timeSinceLastInvoke = time - lastInvokeTime;

    // Either this is the first call, activity has stopped and we're at the
    // trailing edge, the system time has gone backwards and we're treating
    // it as the trailing edge, or we've hit the `maxWait` limit.
    return (lastCallTime === undefined || (timeSinceLastCall >= wait) ||
      (timeSinceLastCall < 0) || (maxing && timeSinceLastInvoke >= maxWait));
  }

  function timerExpired() {
    var time = now();
    if (shouldInvoke(time)) {
      return trailingEdge(time);
    }
    // Restart the timer.
    timerId = setTimeout(timerExpired, remainingWait(time));
  }

  function trailingEdge(time) {
    timerId = undefined;

    // Only invoke if we have `lastArgs` which means `func` has been
    // debounced at least once.
    if (trailing && lastArgs) {
      return invokeFunc(time);
    }
    lastArgs = lastThis = undefined;
    return result;
  }

  function cancel() {
    if (timerId !== undefined) {
      clearTimeout(timerId);
    }
    lastInvokeTime = 0;
    lastArgs = lastCallTime = lastThis = timerId = undefined;
  }

  function flush() {
    return timerId === undefined ? result : trailingEdge(now());
  }

  function debounced() {
    var time = now(),
        isInvoking = shouldInvoke(time);

    lastArgs = arguments;
    lastThis = this;
    lastCallTime = time;

    if (isInvoking) {
      if (timerId === undefined) {
        return leadingEdge(lastCallTime);
      }
      if (maxing) {
        // Handle invocations in a tight loop.
        timerId = setTimeout(timerExpired, wait);
        return invokeFunc(lastCallTime);
      }
    }
    if (timerId === undefined) {
      timerId = setTimeout(timerExpired, wait);
    }
    return result;
  }
  debounced.cancel = cancel;
  debounced.flush = flush;
  return debounced;
}

/**
 * Checks if `value` is the
 * [language type](http://www.ecma-international.org/ecma-262/7.0/#sec-ecmascript-language-types)
 * of `Object`. (e.g. arrays, functions, objects, regexes, `new Number(0)`, and `new String('')`)
 *
 * @static
 * @memberOf _
 * @since 0.1.0
 * @category Lang
 * @param {*} value The value to check.
 * @returns {boolean} Returns `true` if `value` is an object, else `false`.
 * @example
 *
 * _.isObject({});
 * // => true
 *
 * _.isObject([1, 2, 3]);
 * // => true
 *
 * _.isObject(_.noop);
 * // => true
 *
 * _.isObject(null);
 * // => false
 */
function isObject(value) {
  var type = typeof value;
  return !!value && (type == 'object' || type == 'function');
}

/**
 * Checks if `value` is object-like. A value is object-like if it's not `null`
 * and has a `typeof` result of "object".
 *
 * @static
 * @memberOf _
 * @since 4.0.0
 * @category Lang
 * @param {*} value The value to check.
 * @returns {boolean} Returns `true` if `value` is object-like, else `false`.
 * @example
 *
 * _.isObjectLike({});
 * // => true
 *
 * _.isObjectLike([1, 2, 3]);
 * // => true
 *
 * _.isObjectLike(_.noop);
 * // => false
 *
 * _.isObjectLike(null);
 * // => false
 */
function isObjectLike(value) {
  return !!value && typeof value == 'object';
}

/**
 * Checks if `value` is classified as a `Symbol` primitive or object.
 *
 * @static
 * @memberOf _
 * @since 4.0.0
 * @category Lang
 * @param {*} value The value to check.
 * @returns {boolean} Returns `true` if `value` is a symbol, else `false`.
 * @example
 *
 * _.isSymbol(Symbol.iterator);
 * // => true
 *
 * _.isSymbol('abc');
 * // => false
 */
function isSymbol(value) {
  return typeof value == 'symbol' ||
    (isObjectLike(value) && objectToString.call(value) == symbolTag);
}

/**
 * Converts `value` to a number.
 *
 * @static
 * @memberOf _
 * @since 4.0.0
 * @category Lang
 * @param {*} value The value to process.
 * @returns {number} Returns the number.
 * @example
 *
 * _.toNumber(3.2);
 * // => 3.2
 *
 * _.toNumber(Number.MIN_VALUE);
 * // => 5e-324
 *
 * _.toNumber(Infinity);
 * // => Infinity
 *
 * _.toNumber('3.2');
 * // => 3.2
 */
function toNumber(value) {
  if (typeof value == 'number') {
    return value;
  }
  if (isSymbol(value)) {
    return NAN;
  }
  if (isObject(value)) {
    var other = typeof value.valueOf == 'function' ? value.valueOf() : value;
    value = isObject(other) ? (other + '') : other;
  }
  if (typeof value != 'string') {
    return value === 0 ? value : +value;
  }
  value = value.replace(reTrim, '');
  var isBinary = reIsBinary.test(value);
  return (isBinary || reIsOctal.test(value))
    ? freeParseInt(value.slice(2), isBinary ? 2 : 8)
    : (reIsBadHex.test(value) ? NAN : +value);
}

module.exports = debounce;


/***/ }),

/***/ "./node_modules/lodash.isequal/index.js":
/*!**********************************************!*\
  !*** ./node_modules/lodash.isequal/index.js ***!
  \**********************************************/
/***/ ((module, exports, __webpack_require__) => {

/* module decorator */ module = __webpack_require__.nmd(module);
/**
 * Lodash (Custom Build) <https://lodash.com/>
 * Build: `lodash modularize exports="npm" -o ./`
 * Copyright JS Foundation and other contributors <https://js.foundation/>
 * Released under MIT license <https://lodash.com/license>
 * Based on Underscore.js 1.8.3 <http://underscorejs.org/LICENSE>
 * Copyright Jeremy Ashkenas, DocumentCloud and Investigative Reporters & Editors
 */

/** Used as the size to enable large array optimizations. */
var LARGE_ARRAY_SIZE = 200;

/** Used to stand-in for `undefined` hash values. */
var HASH_UNDEFINED = '__lodash_hash_undefined__';

/** Used to compose bitmasks for value comparisons. */
var COMPARE_PARTIAL_FLAG = 1,
    COMPARE_UNORDERED_FLAG = 2;

/** Used as references for various `Number` constants. */
var MAX_SAFE_INTEGER = 9007199254740991;

/** `Object#toString` result references. */
var argsTag = '[object Arguments]',
    arrayTag = '[object Array]',
    asyncTag = '[object AsyncFunction]',
    boolTag = '[object Boolean]',
    dateTag = '[object Date]',
    errorTag = '[object Error]',
    funcTag = '[object Function]',
    genTag = '[object GeneratorFunction]',
    mapTag = '[object Map]',
    numberTag = '[object Number]',
    nullTag = '[object Null]',
    objectTag = '[object Object]',
    promiseTag = '[object Promise]',
    proxyTag = '[object Proxy]',
    regexpTag = '[object RegExp]',
    setTag = '[object Set]',
    stringTag = '[object String]',
    symbolTag = '[object Symbol]',
    undefinedTag = '[object Undefined]',
    weakMapTag = '[object WeakMap]';

var arrayBufferTag = '[object ArrayBuffer]',
    dataViewTag = '[object DataView]',
    float32Tag = '[object Float32Array]',
    float64Tag = '[object Float64Array]',
    int8Tag = '[object Int8Array]',
    int16Tag = '[object Int16Array]',
    int32Tag = '[object Int32Array]',
    uint8Tag = '[object Uint8Array]',
    uint8ClampedTag = '[object Uint8ClampedArray]',
    uint16Tag = '[object Uint16Array]',
    uint32Tag = '[object Uint32Array]';

/**
 * Used to match `RegExp`
 * [syntax characters](http://ecma-international.org/ecma-262/7.0/#sec-patterns).
 */
var reRegExpChar = /[\\^$.*+?()[\]{}|]/g;

/** Used to detect host constructors (Safari). */
var reIsHostCtor = /^\[object .+?Constructor\]$/;

/** Used to detect unsigned integer values. */
var reIsUint = /^(?:0|[1-9]\d*)$/;

/** Used to identify `toStringTag` values of typed arrays. */
var typedArrayTags = {};
typedArrayTags[float32Tag] = typedArrayTags[float64Tag] =
typedArrayTags[int8Tag] = typedArrayTags[int16Tag] =
typedArrayTags[int32Tag] = typedArrayTags[uint8Tag] =
typedArrayTags[uint8ClampedTag] = typedArrayTags[uint16Tag] =
typedArrayTags[uint32Tag] = true;
typedArrayTags[argsTag] = typedArrayTags[arrayTag] =
typedArrayTags[arrayBufferTag] = typedArrayTags[boolTag] =
typedArrayTags[dataViewTag] = typedArrayTags[dateTag] =
typedArrayTags[errorTag] = typedArrayTags[funcTag] =
typedArrayTags[mapTag] = typedArrayTags[numberTag] =
typedArrayTags[objectTag] = typedArrayTags[regexpTag] =
typedArrayTags[setTag] = typedArrayTags[stringTag] =
typedArrayTags[weakMapTag] = false;

/** Detect free variable `global` from Node.js. */
var freeGlobal = typeof __webpack_require__.g == 'object' && __webpack_require__.g && __webpack_require__.g.Object === Object && __webpack_require__.g;

/** Detect free variable `self`. */
var freeSelf = typeof self == 'object' && self && self.Object === Object && self;

/** Used as a reference to the global object. */
var root = freeGlobal || freeSelf || Function('return this')();

/** Detect free variable `exports`. */
var freeExports =  true && exports && !exports.nodeType && exports;

/** Detect free variable `module`. */
var freeModule = freeExports && "object" == 'object' && module && !module.nodeType && module;

/** Detect the popular CommonJS extension `module.exports`. */
var moduleExports = freeModule && freeModule.exports === freeExports;

/** Detect free variable `process` from Node.js. */
var freeProcess = moduleExports && freeGlobal.process;

/** Used to access faster Node.js helpers. */
var nodeUtil = (function() {
  try {
    return freeProcess && freeProcess.binding && freeProcess.binding('util');
  } catch (e) {}
}());

/* Node.js helper references. */
var nodeIsTypedArray = nodeUtil && nodeUtil.isTypedArray;

/**
 * A specialized version of `_.filter` for arrays without support for
 * iteratee shorthands.
 *
 * @private
 * @param {Array} [array] The array to iterate over.
 * @param {Function} predicate The function invoked per iteration.
 * @returns {Array} Returns the new filtered array.
 */
function arrayFilter(array, predicate) {
  var index = -1,
      length = array == null ? 0 : array.length,
      resIndex = 0,
      result = [];

  while (++index < length) {
    var value = array[index];
    if (predicate(value, index, array)) {
      result[resIndex++] = value;
    }
  }
  return result;
}

/**
 * Appends the elements of `values` to `array`.
 *
 * @private
 * @param {Array} array The array to modify.
 * @param {Array} values The values to append.
 * @returns {Array} Returns `array`.
 */
function arrayPush(array, values) {
  var index = -1,
      length = values.length,
      offset = array.length;

  while (++index < length) {
    array[offset + index] = values[index];
  }
  return array;
}

/**
 * A specialized version of `_.some` for arrays without support for iteratee
 * shorthands.
 *
 * @private
 * @param {Array} [array] The array to iterate over.
 * @param {Function} predicate The function invoked per iteration.
 * @returns {boolean} Returns `true` if any element passes the predicate check,
 *  else `false`.
 */
function arraySome(array, predicate) {
  var index = -1,
      length = array == null ? 0 : array.length;

  while (++index < length) {
    if (predicate(array[index], index, array)) {
      return true;
    }
  }
  return false;
}

/**
 * The base implementation of `_.times` without support for iteratee shorthands
 * or max array length checks.
 *
 * @private
 * @param {number} n The number of times to invoke `iteratee`.
 * @param {Function} iteratee The function invoked per iteration.
 * @returns {Array} Returns the array of results.
 */
function baseTimes(n, iteratee) {
  var index = -1,
      result = Array(n);

  while (++index < n) {
    result[index] = iteratee(index);
  }
  return result;
}

/**
 * The base implementation of `_.unary` without support for storing metadata.
 *
 * @private
 * @param {Function} func The function to cap arguments for.
 * @returns {Function} Returns the new capped function.
 */
function baseUnary(func) {
  return function(value) {
    return func(value);
  };
}

/**
 * Checks if a `cache` value for `key` exists.
 *
 * @private
 * @param {Object} cache The cache to query.
 * @param {string} key The key of the entry to check.
 * @returns {boolean} Returns `true` if an entry for `key` exists, else `false`.
 */
function cacheHas(cache, key) {
  return cache.has(key);
}

/**
 * Gets the value at `key` of `object`.
 *
 * @private
 * @param {Object} [object] The object to query.
 * @param {string} key The key of the property to get.
 * @returns {*} Returns the property value.
 */
function getValue(object, key) {
  return object == null ? undefined : object[key];
}

/**
 * Converts `map` to its key-value pairs.
 *
 * @private
 * @param {Object} map The map to convert.
 * @returns {Array} Returns the key-value pairs.
 */
function mapToArray(map) {
  var index = -1,
      result = Array(map.size);

  map.forEach(function(value, key) {
    result[++index] = [key, value];
  });
  return result;
}

/**
 * Creates a unary function that invokes `func` with its argument transformed.
 *
 * @private
 * @param {Function} func The function to wrap.
 * @param {Function} transform The argument transform.
 * @returns {Function} Returns the new function.
 */
function overArg(func, transform) {
  return function(arg) {
    return func(transform(arg));
  };
}

/**
 * Converts `set` to an array of its values.
 *
 * @private
 * @param {Object} set The set to convert.
 * @returns {Array} Returns the values.
 */
function setToArray(set) {
  var index = -1,
      result = Array(set.size);

  set.forEach(function(value) {
    result[++index] = value;
  });
  return result;
}

/** Used for built-in method references. */
var arrayProto = Array.prototype,
    funcProto = Function.prototype,
    objectProto = Object.prototype;

/** Used to detect overreaching core-js shims. */
var coreJsData = root['__core-js_shared__'];

/** Used to resolve the decompiled source of functions. */
var funcToString = funcProto.toString;

/** Used to check objects for own properties. */
var hasOwnProperty = objectProto.hasOwnProperty;

/** Used to detect methods masquerading as native. */
var maskSrcKey = (function() {
  var uid = /[^.]+$/.exec(coreJsData && coreJsData.keys && coreJsData.keys.IE_PROTO || '');
  return uid ? ('Symbol(src)_1.' + uid) : '';
}());

/**
 * Used to resolve the
 * [`toStringTag`](http://ecma-international.org/ecma-262/7.0/#sec-object.prototype.tostring)
 * of values.
 */
var nativeObjectToString = objectProto.toString;

/** Used to detect if a method is native. */
var reIsNative = RegExp('^' +
  funcToString.call(hasOwnProperty).replace(reRegExpChar, '\\$&')
  .replace(/hasOwnProperty|(function).*?(?=\\\()| for .+?(?=\\\])/g, '$1.*?') + '$'
);

/** Built-in value references. */
var Buffer = moduleExports ? root.Buffer : undefined,
    Symbol = root.Symbol,
    Uint8Array = root.Uint8Array,
    propertyIsEnumerable = objectProto.propertyIsEnumerable,
    splice = arrayProto.splice,
    symToStringTag = Symbol ? Symbol.toStringTag : undefined;

/* Built-in method references for those with the same name as other `lodash` methods. */
var nativeGetSymbols = Object.getOwnPropertySymbols,
    nativeIsBuffer = Buffer ? Buffer.isBuffer : undefined,
    nativeKeys = overArg(Object.keys, Object);

/* Built-in method references that are verified to be native. */
var DataView = getNative(root, 'DataView'),
    Map = getNative(root, 'Map'),
    Promise = getNative(root, 'Promise'),
    Set = getNative(root, 'Set'),
    WeakMap = getNative(root, 'WeakMap'),
    nativeCreate = getNative(Object, 'create');

/** Used to detect maps, sets, and weakmaps. */
var dataViewCtorString = toSource(DataView),
    mapCtorString = toSource(Map),
    promiseCtorString = toSource(Promise),
    setCtorString = toSource(Set),
    weakMapCtorString = toSource(WeakMap);

/** Used to convert symbols to primitives and strings. */
var symbolProto = Symbol ? Symbol.prototype : undefined,
    symbolValueOf = symbolProto ? symbolProto.valueOf : undefined;

/**
 * Creates a hash object.
 *
 * @private
 * @constructor
 * @param {Array} [entries] The key-value pairs to cache.
 */
function Hash(entries) {
  var index = -1,
      length = entries == null ? 0 : entries.length;

  this.clear();
  while (++index < length) {
    var entry = entries[index];
    this.set(entry[0], entry[1]);
  }
}

/**
 * Removes all key-value entries from the hash.
 *
 * @private
 * @name clear
 * @memberOf Hash
 */
function hashClear() {
  this.__data__ = nativeCreate ? nativeCreate(null) : {};
  this.size = 0;
}

/**
 * Removes `key` and its value from the hash.
 *
 * @private
 * @name delete
 * @memberOf Hash
 * @param {Object} hash The hash to modify.
 * @param {string} key The key of the value to remove.
 * @returns {boolean} Returns `true` if the entry was removed, else `false`.
 */
function hashDelete(key) {
  var result = this.has(key) && delete this.__data__[key];
  this.size -= result ? 1 : 0;
  return result;
}

/**
 * Gets the hash value for `key`.
 *
 * @private
 * @name get
 * @memberOf Hash
 * @param {string} key The key of the value to get.
 * @returns {*} Returns the entry value.
 */
function hashGet(key) {
  var data = this.__data__;
  if (nativeCreate) {
    var result = data[key];
    return result === HASH_UNDEFINED ? undefined : result;
  }
  return hasOwnProperty.call(data, key) ? data[key] : undefined;
}

/**
 * Checks if a hash value for `key` exists.
 *
 * @private
 * @name has
 * @memberOf Hash
 * @param {string} key The key of the entry to check.
 * @returns {boolean} Returns `true` if an entry for `key` exists, else `false`.
 */
function hashHas(key) {
  var data = this.__data__;
  return nativeCreate ? (data[key] !== undefined) : hasOwnProperty.call(data, key);
}

/**
 * Sets the hash `key` to `value`.
 *
 * @private
 * @name set
 * @memberOf Hash
 * @param {string} key The key of the value to set.
 * @param {*} value The value to set.
 * @returns {Object} Returns the hash instance.
 */
function hashSet(key, value) {
  var data = this.__data__;
  this.size += this.has(key) ? 0 : 1;
  data[key] = (nativeCreate && value === undefined) ? HASH_UNDEFINED : value;
  return this;
}

// Add methods to `Hash`.
Hash.prototype.clear = hashClear;
Hash.prototype['delete'] = hashDelete;
Hash.prototype.get = hashGet;
Hash.prototype.has = hashHas;
Hash.prototype.set = hashSet;

/**
 * Creates an list cache object.
 *
 * @private
 * @constructor
 * @param {Array} [entries] The key-value pairs to cache.
 */
function ListCache(entries) {
  var index = -1,
      length = entries == null ? 0 : entries.length;

  this.clear();
  while (++index < length) {
    var entry = entries[index];
    this.set(entry[0], entry[1]);
  }
}

/**
 * Removes all key-value entries from the list cache.
 *
 * @private
 * @name clear
 * @memberOf ListCache
 */
function listCacheClear() {
  this.__data__ = [];
  this.size = 0;
}

/**
 * Removes `key` and its value from the list cache.
 *
 * @private
 * @name delete
 * @memberOf ListCache
 * @param {string} key The key of the value to remove.
 * @returns {boolean} Returns `true` if the entry was removed, else `false`.
 */
function listCacheDelete(key) {
  var data = this.__data__,
      index = assocIndexOf(data, key);

  if (index < 0) {
    return false;
  }
  var lastIndex = data.length - 1;
  if (index == lastIndex) {
    data.pop();
  } else {
    splice.call(data, index, 1);
  }
  --this.size;
  return true;
}

/**
 * Gets the list cache value for `key`.
 *
 * @private
 * @name get
 * @memberOf ListCache
 * @param {string} key The key of the value to get.
 * @returns {*} Returns the entry value.
 */
function listCacheGet(key) {
  var data = this.__data__,
      index = assocIndexOf(data, key);

  return index < 0 ? undefined : data[index][1];
}

/**
 * Checks if a list cache value for `key` exists.
 *
 * @private
 * @name has
 * @memberOf ListCache
 * @param {string} key The key of the entry to check.
 * @returns {boolean} Returns `true` if an entry for `key` exists, else `false`.
 */
function listCacheHas(key) {
  return assocIndexOf(this.__data__, key) > -1;
}

/**
 * Sets the list cache `key` to `value`.
 *
 * @private
 * @name set
 * @memberOf ListCache
 * @param {string} key The key of the value to set.
 * @param {*} value The value to set.
 * @returns {Object} Returns the list cache instance.
 */
function listCacheSet(key, value) {
  var data = this.__data__,
      index = assocIndexOf(data, key);

  if (index < 0) {
    ++this.size;
    data.push([key, value]);
  } else {
    data[index][1] = value;
  }
  return this;
}

// Add methods to `ListCache`.
ListCache.prototype.clear = listCacheClear;
ListCache.prototype['delete'] = listCacheDelete;
ListCache.prototype.get = listCacheGet;
ListCache.prototype.has = listCacheHas;
ListCache.prototype.set = listCacheSet;

/**
 * Creates a map cache object to store key-value pairs.
 *
 * @private
 * @constructor
 * @param {Array} [entries] The key-value pairs to cache.
 */
function MapCache(entries) {
  var index = -1,
      length = entries == null ? 0 : entries.length;

  this.clear();
  while (++index < length) {
    var entry = entries[index];
    this.set(entry[0], entry[1]);
  }
}

/**
 * Removes all key-value entries from the map.
 *
 * @private
 * @name clear
 * @memberOf MapCache
 */
function mapCacheClear() {
  this.size = 0;
  this.__data__ = {
    'hash': new Hash,
    'map': new (Map || ListCache),
    'string': new Hash
  };
}

/**
 * Removes `key` and its value from the map.
 *
 * @private
 * @name delete
 * @memberOf MapCache
 * @param {string} key The key of the value to remove.
 * @returns {boolean} Returns `true` if the entry was removed, else `false`.
 */
function mapCacheDelete(key) {
  var result = getMapData(this, key)['delete'](key);
  this.size -= result ? 1 : 0;
  return result;
}

/**
 * Gets the map value for `key`.
 *
 * @private
 * @name get
 * @memberOf MapCache
 * @param {string} key The key of the value to get.
 * @returns {*} Returns the entry value.
 */
function mapCacheGet(key) {
  return getMapData(this, key).get(key);
}

/**
 * Checks if a map value for `key` exists.
 *
 * @private
 * @name has
 * @memberOf MapCache
 * @param {string} key The key of the entry to check.
 * @returns {boolean} Returns `true` if an entry for `key` exists, else `false`.
 */
function mapCacheHas(key) {
  return getMapData(this, key).has(key);
}

/**
 * Sets the map `key` to `value`.
 *
 * @private
 * @name set
 * @memberOf MapCache
 * @param {string} key The key of the value to set.
 * @param {*} value The value to set.
 * @returns {Object} Returns the map cache instance.
 */
function mapCacheSet(key, value) {
  var data = getMapData(this, key),
      size = data.size;

  data.set(key, value);
  this.size += data.size == size ? 0 : 1;
  return this;
}

// Add methods to `MapCache`.
MapCache.prototype.clear = mapCacheClear;
MapCache.prototype['delete'] = mapCacheDelete;
MapCache.prototype.get = mapCacheGet;
MapCache.prototype.has = mapCacheHas;
MapCache.prototype.set = mapCacheSet;

/**
 *
 * Creates an array cache object to store unique values.
 *
 * @private
 * @constructor
 * @param {Array} [values] The values to cache.
 */
function SetCache(values) {
  var index = -1,
      length = values == null ? 0 : values.length;

  this.__data__ = new MapCache;
  while (++index < length) {
    this.add(values[index]);
  }
}

/**
 * Adds `value` to the array cache.
 *
 * @private
 * @name add
 * @memberOf SetCache
 * @alias push
 * @param {*} value The value to cache.
 * @returns {Object} Returns the cache instance.
 */
function setCacheAdd(value) {
  this.__data__.set(value, HASH_UNDEFINED);
  return this;
}

/**
 * Checks if `value` is in the array cache.
 *
 * @private
 * @name has
 * @memberOf SetCache
 * @param {*} value The value to search for.
 * @returns {number} Returns `true` if `value` is found, else `false`.
 */
function setCacheHas(value) {
  return this.__data__.has(value);
}

// Add methods to `SetCache`.
SetCache.prototype.add = SetCache.prototype.push = setCacheAdd;
SetCache.prototype.has = setCacheHas;

/**
 * Creates a stack cache object to store key-value pairs.
 *
 * @private
 * @constructor
 * @param {Array} [entries] The key-value pairs to cache.
 */
function Stack(entries) {
  var data = this.__data__ = new ListCache(entries);
  this.size = data.size;
}

/**
 * Removes all key-value entries from the stack.
 *
 * @private
 * @name clear
 * @memberOf Stack
 */
function stackClear() {
  this.__data__ = new ListCache;
  this.size = 0;
}

/**
 * Removes `key` and its value from the stack.
 *
 * @private
 * @name delete
 * @memberOf Stack
 * @param {string} key The key of the value to remove.
 * @returns {boolean} Returns `true` if the entry was removed, else `false`.
 */
function stackDelete(key) {
  var data = this.__data__,
      result = data['delete'](key);

  this.size = data.size;
  return result;
}

/**
 * Gets the stack value for `key`.
 *
 * @private
 * @name get
 * @memberOf Stack
 * @param {string} key The key of the value to get.
 * @returns {*} Returns the entry value.
 */
function stackGet(key) {
  return this.__data__.get(key);
}

/**
 * Checks if a stack value for `key` exists.
 *
 * @private
 * @name has
 * @memberOf Stack
 * @param {string} key The key of the entry to check.
 * @returns {boolean} Returns `true` if an entry for `key` exists, else `false`.
 */
function stackHas(key) {
  return this.__data__.has(key);
}

/**
 * Sets the stack `key` to `value`.
 *
 * @private
 * @name set
 * @memberOf Stack
 * @param {string} key The key of the value to set.
 * @param {*} value The value to set.
 * @returns {Object} Returns the stack cache instance.
 */
function stackSet(key, value) {
  var data = this.__data__;
  if (data instanceof ListCache) {
    var pairs = data.__data__;
    if (!Map || (pairs.length < LARGE_ARRAY_SIZE - 1)) {
      pairs.push([key, value]);
      this.size = ++data.size;
      return this;
    }
    data = this.__data__ = new MapCache(pairs);
  }
  data.set(key, value);
  this.size = data.size;
  return this;
}

// Add methods to `Stack`.
Stack.prototype.clear = stackClear;
Stack.prototype['delete'] = stackDelete;
Stack.prototype.get = stackGet;
Stack.prototype.has = stackHas;
Stack.prototype.set = stackSet;

/**
 * Creates an array of the enumerable property names of the array-like `value`.
 *
 * @private
 * @param {*} value The value to query.
 * @param {boolean} inherited Specify returning inherited property names.
 * @returns {Array} Returns the array of property names.
 */
function arrayLikeKeys(value, inherited) {
  var isArr = isArray(value),
      isArg = !isArr && isArguments(value),
      isBuff = !isArr && !isArg && isBuffer(value),
      isType = !isArr && !isArg && !isBuff && isTypedArray(value),
      skipIndexes = isArr || isArg || isBuff || isType,
      result = skipIndexes ? baseTimes(value.length, String) : [],
      length = result.length;

  for (var key in value) {
    if ((inherited || hasOwnProperty.call(value, key)) &&
        !(skipIndexes && (
           // Safari 9 has enumerable `arguments.length` in strict mode.
           key == 'length' ||
           // Node.js 0.10 has enumerable non-index properties on buffers.
           (isBuff && (key == 'offset' || key == 'parent')) ||
           // PhantomJS 2 has enumerable non-index properties on typed arrays.
           (isType && (key == 'buffer' || key == 'byteLength' || key == 'byteOffset')) ||
           // Skip index properties.
           isIndex(key, length)
        ))) {
      result.push(key);
    }
  }
  return result;
}

/**
 * Gets the index at which the `key` is found in `array` of key-value pairs.
 *
 * @private
 * @param {Array} array The array to inspect.
 * @param {*} key The key to search for.
 * @returns {number} Returns the index of the matched value, else `-1`.
 */
function assocIndexOf(array, key) {
  var length = array.length;
  while (length--) {
    if (eq(array[length][0], key)) {
      return length;
    }
  }
  return -1;
}

/**
 * The base implementation of `getAllKeys` and `getAllKeysIn` which uses
 * `keysFunc` and `symbolsFunc` to get the enumerable property names and
 * symbols of `object`.
 *
 * @private
 * @param {Object} object The object to query.
 * @param {Function} keysFunc The function to get the keys of `object`.
 * @param {Function} symbolsFunc The function to get the symbols of `object`.
 * @returns {Array} Returns the array of property names and symbols.
 */
function baseGetAllKeys(object, keysFunc, symbolsFunc) {
  var result = keysFunc(object);
  return isArray(object) ? result : arrayPush(result, symbolsFunc(object));
}

/**
 * The base implementation of `getTag` without fallbacks for buggy environments.
 *
 * @private
 * @param {*} value The value to query.
 * @returns {string} Returns the `toStringTag`.
 */
function baseGetTag(value) {
  if (value == null) {
    return value === undefined ? undefinedTag : nullTag;
  }
  return (symToStringTag && symToStringTag in Object(value))
    ? getRawTag(value)
    : objectToString(value);
}

/**
 * The base implementation of `_.isArguments`.
 *
 * @private
 * @param {*} value The value to check.
 * @returns {boolean} Returns `true` if `value` is an `arguments` object,
 */
function baseIsArguments(value) {
  return isObjectLike(value) && baseGetTag(value) == argsTag;
}

/**
 * The base implementation of `_.isEqual` which supports partial comparisons
 * and tracks traversed objects.
 *
 * @private
 * @param {*} value The value to compare.
 * @param {*} other The other value to compare.
 * @param {boolean} bitmask The bitmask flags.
 *  1 - Unordered comparison
 *  2 - Partial comparison
 * @param {Function} [customizer] The function to customize comparisons.
 * @param {Object} [stack] Tracks traversed `value` and `other` objects.
 * @returns {boolean} Returns `true` if the values are equivalent, else `false`.
 */
function baseIsEqual(value, other, bitmask, customizer, stack) {
  if (value === other) {
    return true;
  }
  if (value == null || other == null || (!isObjectLike(value) && !isObjectLike(other))) {
    return value !== value && other !== other;
  }
  return baseIsEqualDeep(value, other, bitmask, customizer, baseIsEqual, stack);
}

/**
 * A specialized version of `baseIsEqual` for arrays and objects which performs
 * deep comparisons and tracks traversed objects enabling objects with circular
 * references to be compared.
 *
 * @private
 * @param {Object} object The object to compare.
 * @param {Object} other The other object to compare.
 * @param {number} bitmask The bitmask flags. See `baseIsEqual` for more details.
 * @param {Function} customizer The function to customize comparisons.
 * @param {Function} equalFunc The function to determine equivalents of values.
 * @param {Object} [stack] Tracks traversed `object` and `other` objects.
 * @returns {boolean} Returns `true` if the objects are equivalent, else `false`.
 */
function baseIsEqualDeep(object, other, bitmask, customizer, equalFunc, stack) {
  var objIsArr = isArray(object),
      othIsArr = isArray(other),
      objTag = objIsArr ? arrayTag : getTag(object),
      othTag = othIsArr ? arrayTag : getTag(other);

  objTag = objTag == argsTag ? objectTag : objTag;
  othTag = othTag == argsTag ? objectTag : othTag;

  var objIsObj = objTag == objectTag,
      othIsObj = othTag == objectTag,
      isSameTag = objTag == othTag;

  if (isSameTag && isBuffer(object)) {
    if (!isBuffer(other)) {
      return false;
    }
    objIsArr = true;
    objIsObj = false;
  }
  if (isSameTag && !objIsObj) {
    stack || (stack = new Stack);
    return (objIsArr || isTypedArray(object))
      ? equalArrays(object, other, bitmask, customizer, equalFunc, stack)
      : equalByTag(object, other, objTag, bitmask, customizer, equalFunc, stack);
  }
  if (!(bitmask & COMPARE_PARTIAL_FLAG)) {
    var objIsWrapped = objIsObj && hasOwnProperty.call(object, '__wrapped__'),
        othIsWrapped = othIsObj && hasOwnProperty.call(other, '__wrapped__');

    if (objIsWrapped || othIsWrapped) {
      var objUnwrapped = objIsWrapped ? object.value() : object,
          othUnwrapped = othIsWrapped ? other.value() : other;

      stack || (stack = new Stack);
      return equalFunc(objUnwrapped, othUnwrapped, bitmask, customizer, stack);
    }
  }
  if (!isSameTag) {
    return false;
  }
  stack || (stack = new Stack);
  return equalObjects(object, other, bitmask, customizer, equalFunc, stack);
}

/**
 * The base implementation of `_.isNative` without bad shim checks.
 *
 * @private
 * @param {*} value The value to check.
 * @returns {boolean} Returns `true` if `value` is a native function,
 *  else `false`.
 */
function baseIsNative(value) {
  if (!isObject(value) || isMasked(value)) {
    return false;
  }
  var pattern = isFunction(value) ? reIsNative : reIsHostCtor;
  return pattern.test(toSource(value));
}

/**
 * The base implementation of `_.isTypedArray` without Node.js optimizations.
 *
 * @private
 * @param {*} value The value to check.
 * @returns {boolean} Returns `true` if `value` is a typed array, else `false`.
 */
function baseIsTypedArray(value) {
  return isObjectLike(value) &&
    isLength(value.length) && !!typedArrayTags[baseGetTag(value)];
}

/**
 * The base implementation of `_.keys` which doesn't treat sparse arrays as dense.
 *
 * @private
 * @param {Object} object The object to query.
 * @returns {Array} Returns the array of property names.
 */
function baseKeys(object) {
  if (!isPrototype(object)) {
    return nativeKeys(object);
  }
  var result = [];
  for (var key in Object(object)) {
    if (hasOwnProperty.call(object, key) && key != 'constructor') {
      result.push(key);
    }
  }
  return result;
}

/**
 * A specialized version of `baseIsEqualDeep` for arrays with support for
 * partial deep comparisons.
 *
 * @private
 * @param {Array} array The array to compare.
 * @param {Array} other The other array to compare.
 * @param {number} bitmask The bitmask flags. See `baseIsEqual` for more details.
 * @param {Function} customizer The function to customize comparisons.
 * @param {Function} equalFunc The function to determine equivalents of values.
 * @param {Object} stack Tracks traversed `array` and `other` objects.
 * @returns {boolean} Returns `true` if the arrays are equivalent, else `false`.
 */
function equalArrays(array, other, bitmask, customizer, equalFunc, stack) {
  var isPartial = bitmask & COMPARE_PARTIAL_FLAG,
      arrLength = array.length,
      othLength = other.length;

  if (arrLength != othLength && !(isPartial && othLength > arrLength)) {
    return false;
  }
  // Assume cyclic values are equal.
  var stacked = stack.get(array);
  if (stacked && stack.get(other)) {
    return stacked == other;
  }
  var index = -1,
      result = true,
      seen = (bitmask & COMPARE_UNORDERED_FLAG) ? new SetCache : undefined;

  stack.set(array, other);
  stack.set(other, array);

  // Ignore non-index properties.
  while (++index < arrLength) {
    var arrValue = array[index],
        othValue = other[index];

    if (customizer) {
      var compared = isPartial
        ? customizer(othValue, arrValue, index, other, array, stack)
        : customizer(arrValue, othValue, index, array, other, stack);
    }
    if (compared !== undefined) {
      if (compared) {
        continue;
      }
      result = false;
      break;
    }
    // Recursively compare arrays (susceptible to call stack limits).
    if (seen) {
      if (!arraySome(other, function(othValue, othIndex) {
            if (!cacheHas(seen, othIndex) &&
                (arrValue === othValue || equalFunc(arrValue, othValue, bitmask, customizer, stack))) {
              return seen.push(othIndex);
            }
          })) {
        result = false;
        break;
      }
    } else if (!(
          arrValue === othValue ||
            equalFunc(arrValue, othValue, bitmask, customizer, stack)
        )) {
      result = false;
      break;
    }
  }
  stack['delete'](array);
  stack['delete'](other);
  return result;
}

/**
 * A specialized version of `baseIsEqualDeep` for comparing objects of
 * the same `toStringTag`.
 *
 * **Note:** This function only supports comparing values with tags of
 * `Boolean`, `Date`, `Error`, `Number`, `RegExp`, or `String`.
 *
 * @private
 * @param {Object} object The object to compare.
 * @param {Object} other The other object to compare.
 * @param {string} tag The `toStringTag` of the objects to compare.
 * @param {number} bitmask The bitmask flags. See `baseIsEqual` for more details.
 * @param {Function} customizer The function to customize comparisons.
 * @param {Function} equalFunc The function to determine equivalents of values.
 * @param {Object} stack Tracks traversed `object` and `other` objects.
 * @returns {boolean} Returns `true` if the objects are equivalent, else `false`.
 */
function equalByTag(object, other, tag, bitmask, customizer, equalFunc, stack) {
  switch (tag) {
    case dataViewTag:
      if ((object.byteLength != other.byteLength) ||
          (object.byteOffset != other.byteOffset)) {
        return false;
      }
      object = object.buffer;
      other = other.buffer;

    case arrayBufferTag:
      if ((object.byteLength != other.byteLength) ||
          !equalFunc(new Uint8Array(object), new Uint8Array(other))) {
        return false;
      }
      return true;

    case boolTag:
    case dateTag:
    case numberTag:
      // Coerce booleans to `1` or `0` and dates to milliseconds.
      // Invalid dates are coerced to `NaN`.
      return eq(+object, +other);

    case errorTag:
      return object.name == other.name && object.message == other.message;

    case regexpTag:
    case stringTag:
      // Coerce regexes to strings and treat strings, primitives and objects,
      // as equal. See http://www.ecma-international.org/ecma-262/7.0/#sec-regexp.prototype.tostring
      // for more details.
      return object == (other + '');

    case mapTag:
      var convert = mapToArray;

    case setTag:
      var isPartial = bitmask & COMPARE_PARTIAL_FLAG;
      convert || (convert = setToArray);

      if (object.size != other.size && !isPartial) {
        return false;
      }
      // Assume cyclic values are equal.
      var stacked = stack.get(object);
      if (stacked) {
        return stacked == other;
      }
      bitmask |= COMPARE_UNORDERED_FLAG;

      // Recursively compare objects (susceptible to call stack limits).
      stack.set(object, other);
      var result = equalArrays(convert(object), convert(other), bitmask, customizer, equalFunc, stack);
      stack['delete'](object);
      return result;

    case symbolTag:
      if (symbolValueOf) {
        return symbolValueOf.call(object) == symbolValueOf.call(other);
      }
  }
  return false;
}

/**
 * A specialized version of `baseIsEqualDeep` for objects with support for
 * partial deep comparisons.
 *
 * @private
 * @param {Object} object The object to compare.
 * @param {Object} other The other object to compare.
 * @param {number} bitmask The bitmask flags. See `baseIsEqual` for more details.
 * @param {Function} customizer The function to customize comparisons.
 * @param {Function} equalFunc The function to determine equivalents of values.
 * @param {Object} stack Tracks traversed `object` and `other` objects.
 * @returns {boolean} Returns `true` if the objects are equivalent, else `false`.
 */
function equalObjects(object, other, bitmask, customizer, equalFunc, stack) {
  var isPartial = bitmask & COMPARE_PARTIAL_FLAG,
      objProps = getAllKeys(object),
      objLength = objProps.length,
      othProps = getAllKeys(other),
      othLength = othProps.length;

  if (objLength != othLength && !isPartial) {
    return false;
  }
  var index = objLength;
  while (index--) {
    var key = objProps[index];
    if (!(isPartial ? key in other : hasOwnProperty.call(other, key))) {
      return false;
    }
  }
  // Assume cyclic values are equal.
  var stacked = stack.get(object);
  if (stacked && stack.get(other)) {
    return stacked == other;
  }
  var result = true;
  stack.set(object, other);
  stack.set(other, object);

  var skipCtor = isPartial;
  while (++index < objLength) {
    key = objProps[index];
    var objValue = object[key],
        othValue = other[key];

    if (customizer) {
      var compared = isPartial
        ? customizer(othValue, objValue, key, other, object, stack)
        : customizer(objValue, othValue, key, object, other, stack);
    }
    // Recursively compare objects (susceptible to call stack limits).
    if (!(compared === undefined
          ? (objValue === othValue || equalFunc(objValue, othValue, bitmask, customizer, stack))
          : compared
        )) {
      result = false;
      break;
    }
    skipCtor || (skipCtor = key == 'constructor');
  }
  if (result && !skipCtor) {
    var objCtor = object.constructor,
        othCtor = other.constructor;

    // Non `Object` object instances with different constructors are not equal.
    if (objCtor != othCtor &&
        ('constructor' in object && 'constructor' in other) &&
        !(typeof objCtor == 'function' && objCtor instanceof objCtor &&
          typeof othCtor == 'function' && othCtor instanceof othCtor)) {
      result = false;
    }
  }
  stack['delete'](object);
  stack['delete'](other);
  return result;
}

/**
 * Creates an array of own enumerable property names and symbols of `object`.
 *
 * @private
 * @param {Object} object The object to query.
 * @returns {Array} Returns the array of property names and symbols.
 */
function getAllKeys(object) {
  return baseGetAllKeys(object, keys, getSymbols);
}

/**
 * Gets the data for `map`.
 *
 * @private
 * @param {Object} map The map to query.
 * @param {string} key The reference key.
 * @returns {*} Returns the map data.
 */
function getMapData(map, key) {
  var data = map.__data__;
  return isKeyable(key)
    ? data[typeof key == 'string' ? 'string' : 'hash']
    : data.map;
}

/**
 * Gets the native function at `key` of `object`.
 *
 * @private
 * @param {Object} object The object to query.
 * @param {string} key The key of the method to get.
 * @returns {*} Returns the function if it's native, else `undefined`.
 */
function getNative(object, key) {
  var value = getValue(object, key);
  return baseIsNative(value) ? value : undefined;
}

/**
 * A specialized version of `baseGetTag` which ignores `Symbol.toStringTag` values.
 *
 * @private
 * @param {*} value The value to query.
 * @returns {string} Returns the raw `toStringTag`.
 */
function getRawTag(value) {
  var isOwn = hasOwnProperty.call(value, symToStringTag),
      tag = value[symToStringTag];

  try {
    value[symToStringTag] = undefined;
    var unmasked = true;
  } catch (e) {}

  var result = nativeObjectToString.call(value);
  if (unmasked) {
    if (isOwn) {
      value[symToStringTag] = tag;
    } else {
      delete value[symToStringTag];
    }
  }
  return result;
}

/**
 * Creates an array of the own enumerable symbols of `object`.
 *
 * @private
 * @param {Object} object The object to query.
 * @returns {Array} Returns the array of symbols.
 */
var getSymbols = !nativeGetSymbols ? stubArray : function(object) {
  if (object == null) {
    return [];
  }
  object = Object(object);
  return arrayFilter(nativeGetSymbols(object), function(symbol) {
    return propertyIsEnumerable.call(object, symbol);
  });
};

/**
 * Gets the `toStringTag` of `value`.
 *
 * @private
 * @param {*} value The value to query.
 * @returns {string} Returns the `toStringTag`.
 */
var getTag = baseGetTag;

// Fallback for data views, maps, sets, and weak maps in IE 11 and promises in Node.js < 6.
if ((DataView && getTag(new DataView(new ArrayBuffer(1))) != dataViewTag) ||
    (Map && getTag(new Map) != mapTag) ||
    (Promise && getTag(Promise.resolve()) != promiseTag) ||
    (Set && getTag(new Set) != setTag) ||
    (WeakMap && getTag(new WeakMap) != weakMapTag)) {
  getTag = function(value) {
    var result = baseGetTag(value),
        Ctor = result == objectTag ? value.constructor : undefined,
        ctorString = Ctor ? toSource(Ctor) : '';

    if (ctorString) {
      switch (ctorString) {
        case dataViewCtorString: return dataViewTag;
        case mapCtorString: return mapTag;
        case promiseCtorString: return promiseTag;
        case setCtorString: return setTag;
        case weakMapCtorString: return weakMapTag;
      }
    }
    return result;
  };
}

/**
 * Checks if `value` is a valid array-like index.
 *
 * @private
 * @param {*} value The value to check.
 * @param {number} [length=MAX_SAFE_INTEGER] The upper bounds of a valid index.
 * @returns {boolean} Returns `true` if `value` is a valid index, else `false`.
 */
function isIndex(value, length) {
  length = length == null ? MAX_SAFE_INTEGER : length;
  return !!length &&
    (typeof value == 'number' || reIsUint.test(value)) &&
    (value > -1 && value % 1 == 0 && value < length);
}

/**
 * Checks if `value` is suitable for use as unique object key.
 *
 * @private
 * @param {*} value The value to check.
 * @returns {boolean} Returns `true` if `value` is suitable, else `false`.
 */
function isKeyable(value) {
  var type = typeof value;
  return (type == 'string' || type == 'number' || type == 'symbol' || type == 'boolean')
    ? (value !== '__proto__')
    : (value === null);
}

/**
 * Checks if `func` has its source masked.
 *
 * @private
 * @param {Function} func The function to check.
 * @returns {boolean} Returns `true` if `func` is masked, else `false`.
 */
function isMasked(func) {
  return !!maskSrcKey && (maskSrcKey in func);
}

/**
 * Checks if `value` is likely a prototype object.
 *
 * @private
 * @param {*} value The value to check.
 * @returns {boolean} Returns `true` if `value` is a prototype, else `false`.
 */
function isPrototype(value) {
  var Ctor = value && value.constructor,
      proto = (typeof Ctor == 'function' && Ctor.prototype) || objectProto;

  return value === proto;
}

/**
 * Converts `value` to a string using `Object.prototype.toString`.
 *
 * @private
 * @param {*} value The value to convert.
 * @returns {string} Returns the converted string.
 */
function objectToString(value) {
  return nativeObjectToString.call(value);
}

/**
 * Converts `func` to its source code.
 *
 * @private
 * @param {Function} func The function to convert.
 * @returns {string} Returns the source code.
 */
function toSource(func) {
  if (func != null) {
    try {
      return funcToString.call(func);
    } catch (e) {}
    try {
      return (func + '');
    } catch (e) {}
  }
  return '';
}

/**
 * Performs a
 * [`SameValueZero`](http://ecma-international.org/ecma-262/7.0/#sec-samevaluezero)
 * comparison between two values to determine if they are equivalent.
 *
 * @static
 * @memberOf _
 * @since 4.0.0
 * @category Lang
 * @param {*} value The value to compare.
 * @param {*} other The other value to compare.
 * @returns {boolean} Returns `true` if the values are equivalent, else `false`.
 * @example
 *
 * var object = { 'a': 1 };
 * var other = { 'a': 1 };
 *
 * _.eq(object, object);
 * // => true
 *
 * _.eq(object, other);
 * // => false
 *
 * _.eq('a', 'a');
 * // => true
 *
 * _.eq('a', Object('a'));
 * // => false
 *
 * _.eq(NaN, NaN);
 * // => true
 */
function eq(value, other) {
  return value === other || (value !== value && other !== other);
}

/**
 * Checks if `value` is likely an `arguments` object.
 *
 * @static
 * @memberOf _
 * @since 0.1.0
 * @category Lang
 * @param {*} value The value to check.
 * @returns {boolean} Returns `true` if `value` is an `arguments` object,
 *  else `false`.
 * @example
 *
 * _.isArguments(function() { return arguments; }());
 * // => true
 *
 * _.isArguments([1, 2, 3]);
 * // => false
 */
var isArguments = baseIsArguments(function() { return arguments; }()) ? baseIsArguments : function(value) {
  return isObjectLike(value) && hasOwnProperty.call(value, 'callee') &&
    !propertyIsEnumerable.call(value, 'callee');
};

/**
 * Checks if `value` is classified as an `Array` object.
 *
 * @static
 * @memberOf _
 * @since 0.1.0
 * @category Lang
 * @param {*} value The value to check.
 * @returns {boolean} Returns `true` if `value` is an array, else `false`.
 * @example
 *
 * _.isArray([1, 2, 3]);
 * // => true
 *
 * _.isArray(document.body.children);
 * // => false
 *
 * _.isArray('abc');
 * // => false
 *
 * _.isArray(_.noop);
 * // => false
 */
var isArray = Array.isArray;

/**
 * Checks if `value` is array-like. A value is considered array-like if it's
 * not a function and has a `value.length` that's an integer greater than or
 * equal to `0` and less than or equal to `Number.MAX_SAFE_INTEGER`.
 *
 * @static
 * @memberOf _
 * @since 4.0.0
 * @category Lang
 * @param {*} value The value to check.
 * @returns {boolean} Returns `true` if `value` is array-like, else `false`.
 * @example
 *
 * _.isArrayLike([1, 2, 3]);
 * // => true
 *
 * _.isArrayLike(document.body.children);
 * // => true
 *
 * _.isArrayLike('abc');
 * // => true
 *
 * _.isArrayLike(_.noop);
 * // => false
 */
function isArrayLike(value) {
  return value != null && isLength(value.length) && !isFunction(value);
}

/**
 * Checks if `value` is a buffer.
 *
 * @static
 * @memberOf _
 * @since 4.3.0
 * @category Lang
 * @param {*} value The value to check.
 * @returns {boolean} Returns `true` if `value` is a buffer, else `false`.
 * @example
 *
 * _.isBuffer(new Buffer(2));
 * // => true
 *
 * _.isBuffer(new Uint8Array(2));
 * // => false
 */
var isBuffer = nativeIsBuffer || stubFalse;

/**
 * Performs a deep comparison between two values to determine if they are
 * equivalent.
 *
 * **Note:** This method supports comparing arrays, array buffers, booleans,
 * date objects, error objects, maps, numbers, `Object` objects, regexes,
 * sets, strings, symbols, and typed arrays. `Object` objects are compared
 * by their own, not inherited, enumerable properties. Functions and DOM
 * nodes are compared by strict equality, i.e. `===`.
 *
 * @static
 * @memberOf _
 * @since 0.1.0
 * @category Lang
 * @param {*} value The value to compare.
 * @param {*} other The other value to compare.
 * @returns {boolean} Returns `true` if the values are equivalent, else `false`.
 * @example
 *
 * var object = { 'a': 1 };
 * var other = { 'a': 1 };
 *
 * _.isEqual(object, other);
 * // => true
 *
 * object === other;
 * // => false
 */
function isEqual(value, other) {
  return baseIsEqual(value, other);
}

/**
 * Checks if `value` is classified as a `Function` object.
 *
 * @static
 * @memberOf _
 * @since 0.1.0
 * @category Lang
 * @param {*} value The value to check.
 * @returns {boolean} Returns `true` if `value` is a function, else `false`.
 * @example
 *
 * _.isFunction(_);
 * // => true
 *
 * _.isFunction(/abc/);
 * // => false
 */
function isFunction(value) {
  if (!isObject(value)) {
    return false;
  }
  // The use of `Object#toString` avoids issues with the `typeof` operator
  // in Safari 9 which returns 'object' for typed arrays and other constructors.
  var tag = baseGetTag(value);
  return tag == funcTag || tag == genTag || tag == asyncTag || tag == proxyTag;
}

/**
 * Checks if `value` is a valid array-like length.
 *
 * **Note:** This method is loosely based on
 * [`ToLength`](http://ecma-international.org/ecma-262/7.0/#sec-tolength).
 *
 * @static
 * @memberOf _
 * @since 4.0.0
 * @category Lang
 * @param {*} value The value to check.
 * @returns {boolean} Returns `true` if `value` is a valid length, else `false`.
 * @example
 *
 * _.isLength(3);
 * // => true
 *
 * _.isLength(Number.MIN_VALUE);
 * // => false
 *
 * _.isLength(Infinity);
 * // => false
 *
 * _.isLength('3');
 * // => false
 */
function isLength(value) {
  return typeof value == 'number' &&
    value > -1 && value % 1 == 0 && value <= MAX_SAFE_INTEGER;
}

/**
 * Checks if `value` is the
 * [language type](http://www.ecma-international.org/ecma-262/7.0/#sec-ecmascript-language-types)
 * of `Object`. (e.g. arrays, functions, objects, regexes, `new Number(0)`, and `new String('')`)
 *
 * @static
 * @memberOf _
 * @since 0.1.0
 * @category Lang
 * @param {*} value The value to check.
 * @returns {boolean} Returns `true` if `value` is an object, else `false`.
 * @example
 *
 * _.isObject({});
 * // => true
 *
 * _.isObject([1, 2, 3]);
 * // => true
 *
 * _.isObject(_.noop);
 * // => true
 *
 * _.isObject(null);
 * // => false
 */
function isObject(value) {
  var type = typeof value;
  return value != null && (type == 'object' || type == 'function');
}

/**
 * Checks if `value` is object-like. A value is object-like if it's not `null`
 * and has a `typeof` result of "object".
 *
 * @static
 * @memberOf _
 * @since 4.0.0
 * @category Lang
 * @param {*} value The value to check.
 * @returns {boolean} Returns `true` if `value` is object-like, else `false`.
 * @example
 *
 * _.isObjectLike({});
 * // => true
 *
 * _.isObjectLike([1, 2, 3]);
 * // => true
 *
 * _.isObjectLike(_.noop);
 * // => false
 *
 * _.isObjectLike(null);
 * // => false
 */
function isObjectLike(value) {
  return value != null && typeof value == 'object';
}

/**
 * Checks if `value` is classified as a typed array.
 *
 * @static
 * @memberOf _
 * @since 3.0.0
 * @category Lang
 * @param {*} value The value to check.
 * @returns {boolean} Returns `true` if `value` is a typed array, else `false`.
 * @example
 *
 * _.isTypedArray(new Uint8Array);
 * // => true
 *
 * _.isTypedArray([]);
 * // => false
 */
var isTypedArray = nodeIsTypedArray ? baseUnary(nodeIsTypedArray) : baseIsTypedArray;

/**
 * Creates an array of the own enumerable property names of `object`.
 *
 * **Note:** Non-object values are coerced to objects. See the
 * [ES spec](http://ecma-international.org/ecma-262/7.0/#sec-object.keys)
 * for more details.
 *
 * @static
 * @since 0.1.0
 * @memberOf _
 * @category Object
 * @param {Object} object The object to query.
 * @returns {Array} Returns the array of property names.
 * @example
 *
 * function Foo() {
 *   this.a = 1;
 *   this.b = 2;
 * }
 *
 * Foo.prototype.c = 3;
 *
 * _.keys(new Foo);
 * // => ['a', 'b'] (iteration order is not guaranteed)
 *
 * _.keys('hi');
 * // => ['0', '1']
 */
function keys(object) {
  return isArrayLike(object) ? arrayLikeKeys(object) : baseKeys(object);
}

/**
 * This method returns a new empty array.
 *
 * @static
 * @memberOf _
 * @since 4.13.0
 * @category Util
 * @returns {Array} Returns the new empty array.
 * @example
 *
 * var arrays = _.times(2, _.stubArray);
 *
 * console.log(arrays);
 * // => [[], []]
 *
 * console.log(arrays[0] === arrays[1]);
 * // => false
 */
function stubArray() {
  return [];
}

/**
 * This method returns `false`.
 *
 * @static
 * @memberOf _
 * @since 4.13.0
 * @category Util
 * @returns {boolean} Returns `false`.
 * @example
 *
 * _.times(2, _.stubFalse);
 * // => [false, false]
 */
function stubFalse() {
  return false;
}

module.exports = isEqual;


/***/ }),

/***/ "./node_modules/sdp-transform/lib/grammar.js":
/*!***************************************************!*\
  !*** ./node_modules/sdp-transform/lib/grammar.js ***!
  \***************************************************/
/***/ ((module) => {

var grammar = module.exports = {
  v: [{
    name: 'version',
    reg: /^(\d*)$/
  }],
  o: [{ //o=- 20518 0 IN IP4 203.0.113.1
    // NB: sessionId will be a String in most cases because it is huge
    name: 'origin',
    reg: /^(\S*) (\d*) (\d*) (\S*) IP(\d) (\S*)/,
    names: ['username', 'sessionId', 'sessionVersion', 'netType', 'ipVer', 'address'],
    format: '%s %s %d %s IP%d %s'
  }],
  // default parsing of these only (though some of these feel outdated)
  s: [{ name: 'name' }],
  i: [{ name: 'description' }],
  u: [{ name: 'uri' }],
  e: [{ name: 'email' }],
  p: [{ name: 'phone' }],
  z: [{ name: 'timezones' }], // TODO: this one can actually be parsed properly..
  r: [{ name: 'repeats' }],   // TODO: this one can also be parsed properly
  //k: [{}], // outdated thing ignored
  t: [{ //t=0 0
    name: 'timing',
    reg: /^(\d*) (\d*)/,
    names: ['start', 'stop'],
    format: '%d %d'
  }],
  c: [{ //c=IN IP4 10.47.197.26
    name: 'connection',
    reg: /^IN IP(\d) (\S*)/,
    names: ['version', 'ip'],
    format: 'IN IP%d %s'
  }],
  b: [{ //b=AS:4000
    push: 'bandwidth',
    reg: /^(TIAS|AS|CT|RR|RS):(\d*)/,
    names: ['type', 'limit'],
    format: '%s:%s'
  }],
  m: [{ //m=video 51744 RTP/AVP 126 97 98 34 31
    // NB: special - pushes to session
    // TODO: rtp/fmtp should be filtered by the payloads found here?
    reg: /^(\w*) (\d*) ([\w\/]*)(?: (.*))?/,
    names: ['type', 'port', 'protocol', 'payloads'],
    format: '%s %d %s %s'
  }],
  a: [
    { //a=rtpmap:110 opus/48000/2
      push: 'rtp',
      reg: /^rtpmap:(\d*) ([\w\-\.]*)(?:\s*\/(\d*)(?:\s*\/(\S*))?)?/,
      names: ['payload', 'codec', 'rate', 'encoding'],
      format: function (o) {
        return (o.encoding) ?
          'rtpmap:%d %s/%s/%s':
          o.rate ?
          'rtpmap:%d %s/%s':
          'rtpmap:%d %s';
      }
    },
    { //a=fmtp:108 profile-level-id=24;object=23;bitrate=64000
      //a=fmtp:111 minptime=10; useinbandfec=1
      push: 'fmtp',
      reg: /^fmtp:(\d*) ([\S| ]*)/,
      names: ['payload', 'config'],
      format: 'fmtp:%d %s'
    },
    { //a=control:streamid=0
      name: 'control',
      reg: /^control:(.*)/,
      format: 'control:%s'
    },
    { //a=rtcp:65179 IN IP4 193.84.77.194
      name: 'rtcp',
      reg: /^rtcp:(\d*)(?: (\S*) IP(\d) (\S*))?/,
      names: ['port', 'netType', 'ipVer', 'address'],
      format: function (o) {
        return (o.address != null) ?
          'rtcp:%d %s IP%d %s':
          'rtcp:%d';
      }
    },
    { //a=rtcp-fb:98 trr-int 100
      push: 'rtcpFbTrrInt',
      reg: /^rtcp-fb:(\*|\d*) trr-int (\d*)/,
      names: ['payload', 'value'],
      format: 'rtcp-fb:%d trr-int %d'
    },
    { //a=rtcp-fb:98 nack rpsi
      push: 'rtcpFb',
      reg: /^rtcp-fb:(\*|\d*) ([\w-_]*)(?: ([\w-_]*))?/,
      names: ['payload', 'type', 'subtype'],
      format: function (o) {
        return (o.subtype != null) ?
          'rtcp-fb:%s %s %s':
          'rtcp-fb:%s %s';
      }
    },
    { //a=extmap:2 urn:ietf:params:rtp-hdrext:toffset
      //a=extmap:1/recvonly URI-gps-string
      push: 'ext',
      reg: /^extmap:(\d+)(?:\/(\w+))? (\S*)(?: (\S*))?/,
      names: ['value', 'direction', 'uri', 'config'],
      format: function (o) {
        return 'extmap:%d' + (o.direction ? '/%s' : '%v') + ' %s' + (o.config ? ' %s' : '');
      }
    },
    { //a=crypto:1 AES_CM_128_HMAC_SHA1_80 inline:PS1uQCVeeCFCanVmcjkpPywjNWhcYD0mXXtxaVBR|2^20|1:32
      push: 'crypto',
      reg: /^crypto:(\d*) ([\w_]*) (\S*)(?: (\S*))?/,
      names: ['id', 'suite', 'config', 'sessionConfig'],
      format: function (o) {
        return (o.sessionConfig != null) ?
          'crypto:%d %s %s %s':
          'crypto:%d %s %s';
      }
    },
    { //a=setup:actpass
      name: 'setup',
      reg: /^setup:(\w*)/,
      format: 'setup:%s'
    },
    { //a=mid:1
      name: 'mid',
      reg: /^mid:([^\s]*)/,
      format: 'mid:%s'
    },
    { //a=msid:0c8b064d-d807-43b4-b434-f92a889d8587 98178685-d409-46e0-8e16-7ef0db0db64a
      name: 'msid',
      reg: /^msid:(.*)/,
      format: 'msid:%s'
    },
    { //a=ptime:20
      name: 'ptime',
      reg: /^ptime:(\d*)/,
      format: 'ptime:%d'
    },
    { //a=maxptime:60
      name: 'maxptime',
      reg: /^maxptime:(\d*)/,
      format: 'maxptime:%d'
    },
    { //a=sendrecv
      name: 'direction',
      reg: /^(sendrecv|recvonly|sendonly|inactive)/
    },
    { //a=ice-lite
      name: 'icelite',
      reg: /^(ice-lite)/
    },
    { //a=ice-ufrag:F7gI
      name: 'iceUfrag',
      reg: /^ice-ufrag:(\S*)/,
      format: 'ice-ufrag:%s'
    },
    { //a=ice-pwd:x9cml/YzichV2+XlhiMu8g
      name: 'icePwd',
      reg: /^ice-pwd:(\S*)/,
      format: 'ice-pwd:%s'
    },
    { //a=fingerprint:SHA-1 00:11:22:33:44:55:66:77:88:99:AA:BB:CC:DD:EE:FF:00:11:22:33
      name: 'fingerprint',
      reg: /^fingerprint:(\S*) (\S*)/,
      names: ['type', 'hash'],
      format: 'fingerprint:%s %s'
    },
    { //a=candidate:0 1 UDP 2113667327 203.0.113.1 54400 typ host
      //a=candidate:1162875081 1 udp 2113937151 192.168.34.75 60017 typ host generation 0 network-id 3 network-cost 10
      //a=candidate:3289912957 2 udp 1845501695 193.84.77.194 60017 typ srflx raddr 192.168.34.75 rport 60017 generation 0 network-id 3 network-cost 10
      //a=candidate:229815620 1 tcp 1518280447 192.168.150.19 60017 typ host tcptype active generation 0 network-id 3 network-cost 10
      //a=candidate:3289912957 2 tcp 1845501695 193.84.77.194 60017 typ srflx raddr 192.168.34.75 rport 60017 tcptype passive generation 0 network-id 3 network-cost 10
      push:'candidates',
      reg: /^candidate:(\S*) (\d*) (\S*) (\d*) (\S*) (\d*) typ (\S*)(?: raddr (\S*) rport (\d*))?(?: tcptype (\S*))?(?: generation (\d*))?(?: network-id (\d*))?(?: network-cost (\d*))?/,
      names: ['foundation', 'component', 'transport', 'priority', 'ip', 'port', 'type', 'raddr', 'rport', 'tcptype', 'generation', 'network-id', 'network-cost'],
      format: function (o) {
        var str = 'candidate:%s %d %s %d %s %d typ %s';

        str += (o.raddr != null) ? ' raddr %s rport %d' : '%v%v';

        // NB: candidate has three optional chunks, so %void middles one if it's missing
        str += (o.tcptype != null) ? ' tcptype %s' : '%v';

        if (o.generation != null) {
          str += ' generation %d';
        }

        str += (o['network-id'] != null) ? ' network-id %d' : '%v';
        str += (o['network-cost'] != null) ? ' network-cost %d' : '%v';
        return str;
      }
    },
    { //a=end-of-candidates (keep after the candidates line for readability)
      name: 'endOfCandidates',
      reg: /^(end-of-candidates)/
    },
    { //a=remote-candidates:1 203.0.113.1 54400 2 203.0.113.1 54401 ...
      name: 'remoteCandidates',
      reg: /^remote-candidates:(.*)/,
      format: 'remote-candidates:%s'
    },
    { //a=ice-options:google-ice
      name: 'iceOptions',
      reg: /^ice-options:(\S*)/,
      format: 'ice-options:%s'
    },
    { //a=ssrc:2566107569 cname:t9YU8M1UxTF8Y1A1
      push: 'ssrcs',
      reg: /^ssrc:(\d*) ([\w_]*)(?::(.*))?/,
      names: ['id', 'attribute', 'value'],
      format: function (o) {
        var str = 'ssrc:%d';
        if (o.attribute != null) {
          str += ' %s';
          if (o.value != null) {
            str += ':%s';
          }
        }
        return str;
      }
    },
    { //a=ssrc-group:FEC 1 2
      //a=ssrc-group:FEC-FR 3004364195 1080772241
      push: 'ssrcGroups',
      // token-char = %x21 / %x23-27 / %x2A-2B / %x2D-2E / %x30-39 / %x41-5A / %x5E-7E
      reg: /^ssrc-group:([\x21\x23\x24\x25\x26\x27\x2A\x2B\x2D\x2E\w]*) (.*)/,
      names: ['semantics', 'ssrcs'],
      format: 'ssrc-group:%s %s'
    },
    { //a=msid-semantic: WMS Jvlam5X3SX1OP6pn20zWogvaKJz5Hjf9OnlV
      name: 'msidSemantic',
      reg: /^msid-semantic:\s?(\w*) (\S*)/,
      names: ['semantic', 'token'],
      format: 'msid-semantic: %s %s' // space after ':' is not accidental
    },
    { //a=group:BUNDLE audio video
      push: 'groups',
      reg: /^group:(\w*) (.*)/,
      names: ['type', 'mids'],
      format: 'group:%s %s'
    },
    { //a=rtcp-mux
      name: 'rtcpMux',
      reg: /^(rtcp-mux)/
    },
    { //a=rtcp-rsize
      name: 'rtcpRsize',
      reg: /^(rtcp-rsize)/
    },
    { //a=sctpmap:5000 webrtc-datachannel 1024
      name: 'sctpmap',
      reg: /^sctpmap:([\w_\/]*) (\S*)(?: (\S*))?/,
      names: ['sctpmapNumber', 'app', 'maxMessageSize'],
      format: function (o) {
        return (o.maxMessageSize != null) ?
          'sctpmap:%s %s %s' :
          'sctpmap:%s %s';
      }
    },
    { //a=x-google-flag:conference
      name: 'xGoogleFlag',
      reg: /^x-google-flag:([^\s]*)/,
      format: 'x-google-flag:%s'
    },
    { //a=rid:1 send max-width=1280;max-height=720;max-fps=30;depend=0
      push: 'rids',
      reg: /^rid:([\d\w]+) (\w+)(?: ([\S| ]*))?/,
      names: ['id', 'direction', 'params'],
      format: function (o) {
        return (o.params) ? 'rid:%s %s %s' : 'rid:%s %s';
      }
    },
    { //a=imageattr:97 send [x=800,y=640,sar=1.1,q=0.6] [x=480,y=320] recv [x=330,y=250]
      //a=imageattr:* send [x=800,y=640] recv *
      //a=imageattr:100 recv [x=320,y=240]
      push: 'imageattrs',
      reg: new RegExp(
        //a=imageattr:97
        '^imageattr:(\\d+|\\*)' +
        //send [x=800,y=640,sar=1.1,q=0.6] [x=480,y=320]
        '[\\s\\t]+(send|recv)[\\s\\t]+(\\*|\\[\\S+\\](?:[\\s\\t]+\\[\\S+\\])*)' +
        //recv [x=330,y=250]
        '(?:[\\s\\t]+(recv|send)[\\s\\t]+(\\*|\\[\\S+\\](?:[\\s\\t]+\\[\\S+\\])*))?'
      ),
      names: ['pt', 'dir1', 'attrs1', 'dir2', 'attrs2'],
      format: function (o) {
        return 'imageattr:%s %s %s' + (o.dir2 ? ' %s %s' : '');
      }
    },
    { //a=simulcast:send 1,2,3;~4,~5 recv 6;~7,~8
      //a=simulcast:recv 1;4,5 send 6;7
      name: 'simulcast',
      reg: new RegExp(
        //a=simulcast:
        '^simulcast:' +
        //send 1,2,3;~4,~5
        '(send|recv) ([a-zA-Z0-9\\-_~;,]+)' +
        //space + recv 6;~7,~8
        '(?:\\s?(send|recv) ([a-zA-Z0-9\\-_~;,]+))?' +
        //end
        '$'
      ),
      names: ['dir1', 'list1', 'dir2', 'list2'],
      format: function (o) {
        return 'simulcast:%s %s' + (o.dir2 ? ' %s %s' : '');
      }
    },
    { //Old simulcast draft 03 (implemented by Firefox)
      //  https://tools.ietf.org/html/draft-ietf-mmusic-sdp-simulcast-03
      //a=simulcast: recv pt=97;98 send pt=97
      //a=simulcast: send rid=5;6;7 paused=6,7
      name: 'simulcast_03',
      reg: /^simulcast:[\s\t]+([\S+\s\t]+)$/,
      names: ['value'],
      format: 'simulcast: %s'
    },
    {
      //a=framerate:25
      //a=framerate:29.97
      name: 'framerate',
      reg: /^framerate:(\d+(?:$|\.\d+))/,
      format: 'framerate:%s'
    },
    { // any a= that we don't understand is kepts verbatim on media.invalid
      push: 'invalid',
      names: ['value']
    }
  ]
};

// set sensible defaults to avoid polluting the grammar with boring details
Object.keys(grammar).forEach(function (key) {
  var objs = grammar[key];
  objs.forEach(function (obj) {
    if (!obj.reg) {
      obj.reg = /(.*)/;
    }
    if (!obj.format) {
      obj.format = '%s';
    }
  });
});


/***/ }),

/***/ "./node_modules/sdp-transform/lib/index.js":
/*!*************************************************!*\
  !*** ./node_modules/sdp-transform/lib/index.js ***!
  \*************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

var parser = __webpack_require__(/*! ./parser */ "./node_modules/sdp-transform/lib/parser.js");
var writer = __webpack_require__(/*! ./writer */ "./node_modules/sdp-transform/lib/writer.js");

exports.write = writer;
exports.parse = parser.parse;
exports.parseFmtpConfig = parser.parseFmtpConfig;
exports.parseParams = parser.parseParams;
exports.parsePayloads = parser.parsePayloads;
exports.parseRemoteCandidates = parser.parseRemoteCandidates;
exports.parseImageAttributes = parser.parseImageAttributes;
exports.parseSimulcastStreamList = parser.parseSimulcastStreamList;


/***/ }),

/***/ "./node_modules/sdp-transform/lib/parser.js":
/*!**************************************************!*\
  !*** ./node_modules/sdp-transform/lib/parser.js ***!
  \**************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

var toIntIfInt = function (v) {
  return String(Number(v)) === v ? Number(v) : v;
};

var attachProperties = function (match, location, names, rawName) {
  if (rawName && !names) {
    location[rawName] = toIntIfInt(match[1]);
  }
  else {
    for (var i = 0; i < names.length; i += 1) {
      if (match[i+1] != null) {
        location[names[i]] = toIntIfInt(match[i+1]);
      }
    }
  }
};

var parseReg = function (obj, location, content) {
  var needsBlank = obj.name && obj.names;
  if (obj.push && !location[obj.push]) {
    location[obj.push] = [];
  }
  else if (needsBlank && !location[obj.name]) {
    location[obj.name] = {};
  }
  var keyLocation = obj.push ?
    {} :  // blank object that will be pushed
    needsBlank ? location[obj.name] : location; // otherwise, named location or root

  attachProperties(content.match(obj.reg), keyLocation, obj.names, obj.name);

  if (obj.push) {
    location[obj.push].push(keyLocation);
  }
};

var grammar = __webpack_require__(/*! ./grammar */ "./node_modules/sdp-transform/lib/grammar.js");
var validLine = RegExp.prototype.test.bind(/^([a-z])=(.*)/);

exports.parse = function (sdp) {
  var session = {}
    , media = []
    , location = session; // points at where properties go under (one of the above)

  // parse lines we understand
  sdp.split(/(\r\n|\r|\n)/).filter(validLine).forEach(function (l) {
    var type = l[0];
    var content = l.slice(2);
    if (type === 'm') {
      media.push({rtp: [], fmtp: []});
      location = media[media.length-1]; // point at latest media line
    }

    for (var j = 0; j < (grammar[type] || []).length; j += 1) {
      var obj = grammar[type][j];
      if (obj.reg.test(content)) {
        return parseReg(obj, location, content);
      }
    }
  });

  session.media = media; // link it up
  return session;
};

var paramReducer = function (acc, expr) {
  var s = expr.split(/=(.+)/, 2);
  if (s.length === 2) {
    acc[s[0]] = toIntIfInt(s[1]);
  }
  return acc;
};

exports.parseParams = function (str) {
  return str.split(/\;\s?/).reduce(paramReducer, {});
};

// For backward compatibility - alias will be removed in 3.0.0
exports.parseFmtpConfig = exports.parseParams;

exports.parsePayloads = function (str) {
  return str.split(' ').map(Number);
};

exports.parseRemoteCandidates = function (str) {
  var candidates = [];
  var parts = str.split(' ').map(toIntIfInt);
  for (var i = 0; i < parts.length; i += 3) {
    candidates.push({
      component: parts[i],
      ip: parts[i + 1],
      port: parts[i + 2]
    });
  }
  return candidates;
};

exports.parseImageAttributes = function (str) {
  return str.split(' ').map(function (item) {
    return item.substring(1, item.length-1).split(',').reduce(paramReducer, {});
  });
};

exports.parseSimulcastStreamList = function (str) {
  return str.split(';').map(function (stream) {
    return stream.split(',').map(function (format) {
      var scid, paused = false;

      if (format[0] !== '~') {
        scid = toIntIfInt(format);
      } else {
        scid = toIntIfInt(format.substring(1, format.length));
        paused = true;
      }

      return {
        scid: scid,
        paused: paused
      };
    });
  });
};


/***/ }),

/***/ "./node_modules/sdp-transform/lib/writer.js":
/*!**************************************************!*\
  !*** ./node_modules/sdp-transform/lib/writer.js ***!
  \**************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

var grammar = __webpack_require__(/*! ./grammar */ "./node_modules/sdp-transform/lib/grammar.js");

// customized util.format - discards excess arguments and can void middle ones
var formatRegExp = /%[sdv%]/g;
var format = function (formatStr) {
  var i = 1;
  var args = arguments;
  var len = args.length;
  return formatStr.replace(formatRegExp, function (x) {
    if (i >= len) {
      return x; // missing argument
    }
    var arg = args[i];
    i += 1;
    switch (x) {
    case '%%':
      return '%';
    case '%s':
      return String(arg);
    case '%d':
      return Number(arg);
    case '%v':
      return '';
    }
  });
  // NB: we discard excess arguments - they are typically undefined from makeLine
};

var makeLine = function (type, obj, location) {
  var str = obj.format instanceof Function ?
    (obj.format(obj.push ? location : location[obj.name])) :
    obj.format;

  var args = [type + '=' + str];
  if (obj.names) {
    for (var i = 0; i < obj.names.length; i += 1) {
      var n = obj.names[i];
      if (obj.name) {
        args.push(location[obj.name][n]);
      }
      else { // for mLine and push attributes
        args.push(location[obj.names[i]]);
      }
    }
  }
  else {
    args.push(location[obj.name]);
  }
  return format.apply(null, args);
};

// RFC specified order
// TODO: extend this with all the rest
var defaultOuterOrder = [
  'v', 'o', 's', 'i',
  'u', 'e', 'p', 'c',
  'b', 't', 'r', 'z', 'a'
];
var defaultInnerOrder = ['i', 'c', 'b', 'a'];


module.exports = function (session, opts) {
  opts = opts || {};
  // ensure certain properties exist
  if (session.version == null) {
    session.version = 0; // 'v=0' must be there (only defined version atm)
  }
  if (session.name == null) {
    session.name = ' '; // 's= ' must be there if no meaningful name set
  }
  session.media.forEach(function (mLine) {
    if (mLine.payloads == null) {
      mLine.payloads = '';
    }
  });

  var outerOrder = opts.outerOrder || defaultOuterOrder;
  var innerOrder = opts.innerOrder || defaultInnerOrder;
  var sdp = [];

  // loop through outerOrder for matching properties on session
  outerOrder.forEach(function (type) {
    grammar[type].forEach(function (obj) {
      if (obj.name in session && session[obj.name] != null) {
        sdp.push(makeLine(type, obj, session));
      }
      else if (obj.push in session && session[obj.push] != null) {
        session[obj.push].forEach(function (el) {
          sdp.push(makeLine(type, obj, el));
        });
      }
    });
  });

  // then for each media line, follow the innerOrder
  session.media.forEach(function (mLine) {
    sdp.push(makeLine('m', grammar.m[0], mLine));

    innerOrder.forEach(function (type) {
      grammar[type].forEach(function (obj) {
        if (obj.name in mLine && mLine[obj.name] != null) {
          sdp.push(makeLine(type, obj, mLine));
        }
        else if (obj.push in mLine && mLine[obj.push] != null) {
          mLine[obj.push].forEach(function (el) {
            sdp.push(makeLine(type, obj, el));
          });
        }
      });
    });
  });

  return sdp.join('\r\n') + '\r\n';
};


/***/ }),

/***/ "./node_modules/sdp/sdp.js":
/*!*********************************!*\
  !*** ./node_modules/sdp/sdp.js ***!
  \*********************************/
/***/ ((module) => {

"use strict";
/* eslint-env node */


// SDP helpers.
const SDPUtils = {};

// Generate an alphanumeric identifier for cname or mids.
// TODO: use UUIDs instead? https://gist.github.com/jed/982883
SDPUtils.generateIdentifier = function() {
  return Math.random().toString(36).substring(2, 12);
};

// The RTCP CNAME used by all peerconnections from the same JS.
SDPUtils.localCName = SDPUtils.generateIdentifier();

// Splits SDP into lines, dealing with both CRLF and LF.
SDPUtils.splitLines = function(blob) {
  return blob.trim().split('\n').map(line => line.trim());
};
// Splits SDP into sessionpart and mediasections. Ensures CRLF.
SDPUtils.splitSections = function(blob) {
  const parts = blob.split('\nm=');
  return parts.map((part, index) => (index > 0 ?
    'm=' + part : part).trim() + '\r\n');
};

// Returns the session description.
SDPUtils.getDescription = function(blob) {
  const sections = SDPUtils.splitSections(blob);
  return sections && sections[0];
};

// Returns the individual media sections.
SDPUtils.getMediaSections = function(blob) {
  const sections = SDPUtils.splitSections(blob);
  sections.shift();
  return sections;
};

// Returns lines that start with a certain prefix.
SDPUtils.matchPrefix = function(blob, prefix) {
  return SDPUtils.splitLines(blob).filter(line => line.indexOf(prefix) === 0);
};

// Parses an ICE candidate line. Sample input:
// candidate:702786350 2 udp 41819902 8.8.8.8 60769 typ relay raddr 8.8.8.8
// rport 55996"
// Input can be prefixed with a=.
SDPUtils.parseCandidate = function(line) {
  let parts;
  // Parse both variants.
  if (line.indexOf('a=candidate:') === 0) {
    parts = line.substring(12).split(' ');
  } else {
    parts = line.substring(10).split(' ');
  }

  const candidate = {
    foundation: parts[0],
    component: {1: 'rtp', 2: 'rtcp'}[parts[1]] || parts[1],
    protocol: parts[2].toLowerCase(),
    priority: parseInt(parts[3], 10),
    ip: parts[4],
    address: parts[4], // address is an alias for ip.
    port: parseInt(parts[5], 10),
    // skip parts[6] == 'typ'
    type: parts[7],
  };

  for (let i = 8; i < parts.length; i += 2) {
    switch (parts[i]) {
      case 'raddr':
        candidate.relatedAddress = parts[i + 1];
        break;
      case 'rport':
        candidate.relatedPort = parseInt(parts[i + 1], 10);
        break;
      case 'tcptype':
        candidate.tcpType = parts[i + 1];
        break;
      case 'ufrag':
        candidate.ufrag = parts[i + 1]; // for backward compatibility.
        candidate.usernameFragment = parts[i + 1];
        break;
      default: // extension handling, in particular ufrag. Don't overwrite.
        if (candidate[parts[i]] === undefined) {
          candidate[parts[i]] = parts[i + 1];
        }
        break;
    }
  }
  return candidate;
};

// Translates a candidate object into SDP candidate attribute.
// This does not include the a= prefix!
SDPUtils.writeCandidate = function(candidate) {
  const sdp = [];
  sdp.push(candidate.foundation);

  const component = candidate.component;
  if (component === 'rtp') {
    sdp.push(1);
  } else if (component === 'rtcp') {
    sdp.push(2);
  } else {
    sdp.push(component);
  }
  sdp.push(candidate.protocol.toUpperCase());
  sdp.push(candidate.priority);
  sdp.push(candidate.address || candidate.ip);
  sdp.push(candidate.port);

  const type = candidate.type;
  sdp.push('typ');
  sdp.push(type);
  if (type !== 'host' && candidate.relatedAddress &&
      candidate.relatedPort) {
    sdp.push('raddr');
    sdp.push(candidate.relatedAddress);
    sdp.push('rport');
    sdp.push(candidate.relatedPort);
  }
  if (candidate.tcpType && candidate.protocol.toLowerCase() === 'tcp') {
    sdp.push('tcptype');
    sdp.push(candidate.tcpType);
  }
  if (candidate.usernameFragment || candidate.ufrag) {
    sdp.push('ufrag');
    sdp.push(candidate.usernameFragment || candidate.ufrag);
  }
  return 'candidate:' + sdp.join(' ');
};

// Parses an ice-options line, returns an array of option tags.
// Sample input:
// a=ice-options:foo bar
SDPUtils.parseIceOptions = function(line) {
  return line.substring(14).split(' ');
};

// Parses a rtpmap line, returns RTCRtpCoddecParameters. Sample input:
// a=rtpmap:111 opus/48000/2
SDPUtils.parseRtpMap = function(line) {
  let parts = line.substring(9).split(' ');
  const parsed = {
    payloadType: parseInt(parts.shift(), 10), // was: id
  };

  parts = parts[0].split('/');

  parsed.name = parts[0];
  parsed.clockRate = parseInt(parts[1], 10); // was: clockrate
  parsed.channels = parts.length === 3 ? parseInt(parts[2], 10) : 1;
  // legacy alias, got renamed back to channels in ORTC.
  parsed.numChannels = parsed.channels;
  return parsed;
};

// Generates a rtpmap line from RTCRtpCodecCapability or
// RTCRtpCodecParameters.
SDPUtils.writeRtpMap = function(codec) {
  let pt = codec.payloadType;
  if (codec.preferredPayloadType !== undefined) {
    pt = codec.preferredPayloadType;
  }
  const channels = codec.channels || codec.numChannels || 1;
  return 'a=rtpmap:' + pt + ' ' + codec.name + '/' + codec.clockRate +
      (channels !== 1 ? '/' + channels : '') + '\r\n';
};

// Parses a extmap line (headerextension from RFC 5285). Sample input:
// a=extmap:2 urn:ietf:params:rtp-hdrext:toffset
// a=extmap:2/sendonly urn:ietf:params:rtp-hdrext:toffset
SDPUtils.parseExtmap = function(line) {
  const parts = line.substring(9).split(' ');
  return {
    id: parseInt(parts[0], 10),
    direction: parts[0].indexOf('/') > 0 ? parts[0].split('/')[1] : 'sendrecv',
    uri: parts[1],
    attributes: parts.slice(2).join(' '),
  };
};

// Generates an extmap line from RTCRtpHeaderExtensionParameters or
// RTCRtpHeaderExtension.
SDPUtils.writeExtmap = function(headerExtension) {
  return 'a=extmap:' + (headerExtension.id || headerExtension.preferredId) +
      (headerExtension.direction && headerExtension.direction !== 'sendrecv'
        ? '/' + headerExtension.direction
        : '') +
      ' ' + headerExtension.uri +
      (headerExtension.attributes ? ' ' + headerExtension.attributes : '') +
      '\r\n';
};

// Parses a fmtp line, returns dictionary. Sample input:
// a=fmtp:96 vbr=on;cng=on
// Also deals with vbr=on; cng=on
SDPUtils.parseFmtp = function(line) {
  const parsed = {};
  let kv;
  const parts = line.substring(line.indexOf(' ') + 1).split(';');
  for (let j = 0; j < parts.length; j++) {
    kv = parts[j].trim().split('=');
    parsed[kv[0].trim()] = kv[1];
  }
  return parsed;
};

// Generates a fmtp line from RTCRtpCodecCapability or RTCRtpCodecParameters.
SDPUtils.writeFmtp = function(codec) {
  let line = '';
  let pt = codec.payloadType;
  if (codec.preferredPayloadType !== undefined) {
    pt = codec.preferredPayloadType;
  }
  if (codec.parameters && Object.keys(codec.parameters).length) {
    const params = [];
    Object.keys(codec.parameters).forEach(param => {
      if (codec.parameters[param] !== undefined) {
        params.push(param + '=' + codec.parameters[param]);
      } else {
        params.push(param);
      }
    });
    line += 'a=fmtp:' + pt + ' ' + params.join(';') + '\r\n';
  }
  return line;
};

// Parses a rtcp-fb line, returns RTCPRtcpFeedback object. Sample input:
// a=rtcp-fb:98 nack rpsi
SDPUtils.parseRtcpFb = function(line) {
  const parts = line.substring(line.indexOf(' ') + 1).split(' ');
  return {
    type: parts.shift(),
    parameter: parts.join(' '),
  };
};

// Generate a=rtcp-fb lines from RTCRtpCodecCapability or RTCRtpCodecParameters.
SDPUtils.writeRtcpFb = function(codec) {
  let lines = '';
  let pt = codec.payloadType;
  if (codec.preferredPayloadType !== undefined) {
    pt = codec.preferredPayloadType;
  }
  if (codec.rtcpFeedback && codec.rtcpFeedback.length) {
    // FIXME: special handling for trr-int?
    codec.rtcpFeedback.forEach(fb => {
      lines += 'a=rtcp-fb:' + pt + ' ' + fb.type +
      (fb.parameter && fb.parameter.length ? ' ' + fb.parameter : '') +
          '\r\n';
    });
  }
  return lines;
};

// Parses a RFC 5576 ssrc media attribute. Sample input:
// a=ssrc:3735928559 cname:something
SDPUtils.parseSsrcMedia = function(line) {
  const sp = line.indexOf(' ');
  const parts = {
    ssrc: parseInt(line.substring(7, sp), 10),
  };
  const colon = line.indexOf(':', sp);
  if (colon > -1) {
    parts.attribute = line.substring(sp + 1, colon);
    parts.value = line.substring(colon + 1);
  } else {
    parts.attribute = line.substring(sp + 1);
  }
  return parts;
};

// Parse a ssrc-group line (see RFC 5576). Sample input:
// a=ssrc-group:semantics 12 34
SDPUtils.parseSsrcGroup = function(line) {
  const parts = line.substring(13).split(' ');
  return {
    semantics: parts.shift(),
    ssrcs: parts.map(ssrc => parseInt(ssrc, 10)),
  };
};

// Extracts the MID (RFC 5888) from a media section.
// Returns the MID or undefined if no mid line was found.
SDPUtils.getMid = function(mediaSection) {
  const mid = SDPUtils.matchPrefix(mediaSection, 'a=mid:')[0];
  if (mid) {
    return mid.substring(6);
  }
};

// Parses a fingerprint line for DTLS-SRTP.
SDPUtils.parseFingerprint = function(line) {
  const parts = line.substring(14).split(' ');
  return {
    algorithm: parts[0].toLowerCase(), // algorithm is case-sensitive in Edge.
    value: parts[1].toUpperCase(), // the definition is upper-case in RFC 4572.
  };
};

// Extracts DTLS parameters from SDP media section or sessionpart.
// FIXME: for consistency with other functions this should only
//   get the fingerprint line as input. See also getIceParameters.
SDPUtils.getDtlsParameters = function(mediaSection, sessionpart) {
  const lines = SDPUtils.matchPrefix(mediaSection + sessionpart,
    'a=fingerprint:');
  // Note: a=setup line is ignored since we use the 'auto' role in Edge.
  return {
    role: 'auto',
    fingerprints: lines.map(SDPUtils.parseFingerprint),
  };
};

// Serializes DTLS parameters to SDP.
SDPUtils.writeDtlsParameters = function(params, setupType) {
  let sdp = 'a=setup:' + setupType + '\r\n';
  params.fingerprints.forEach(fp => {
    sdp += 'a=fingerprint:' + fp.algorithm + ' ' + fp.value + '\r\n';
  });
  return sdp;
};

// Parses a=crypto lines into
//   https://rawgit.com/aboba/edgertc/master/msortc-rs4.html#dictionary-rtcsrtpsdesparameters-members
SDPUtils.parseCryptoLine = function(line) {
  const parts = line.substring(9).split(' ');
  return {
    tag: parseInt(parts[0], 10),
    cryptoSuite: parts[1],
    keyParams: parts[2],
    sessionParams: parts.slice(3),
  };
};

SDPUtils.writeCryptoLine = function(parameters) {
  return 'a=crypto:' + parameters.tag + ' ' +
    parameters.cryptoSuite + ' ' +
    (typeof parameters.keyParams === 'object'
      ? SDPUtils.writeCryptoKeyParams(parameters.keyParams)
      : parameters.keyParams) +
    (parameters.sessionParams ? ' ' + parameters.sessionParams.join(' ') : '') +
    '\r\n';
};

// Parses the crypto key parameters into
//   https://rawgit.com/aboba/edgertc/master/msortc-rs4.html#rtcsrtpkeyparam*
SDPUtils.parseCryptoKeyParams = function(keyParams) {
  if (keyParams.indexOf('inline:') !== 0) {
    return null;
  }
  const parts = keyParams.substring(7).split('|');
  return {
    keyMethod: 'inline',
    keySalt: parts[0],
    lifeTime: parts[1],
    mkiValue: parts[2] ? parts[2].split(':')[0] : undefined,
    mkiLength: parts[2] ? parts[2].split(':')[1] : undefined,
  };
};

SDPUtils.writeCryptoKeyParams = function(keyParams) {
  return keyParams.keyMethod + ':'
    + keyParams.keySalt +
    (keyParams.lifeTime ? '|' + keyParams.lifeTime : '') +
    (keyParams.mkiValue && keyParams.mkiLength
      ? '|' + keyParams.mkiValue + ':' + keyParams.mkiLength
      : '');
};

// Extracts all SDES parameters.
SDPUtils.getCryptoParameters = function(mediaSection, sessionpart) {
  const lines = SDPUtils.matchPrefix(mediaSection + sessionpart,
    'a=crypto:');
  return lines.map(SDPUtils.parseCryptoLine);
};

// Parses ICE information from SDP media section or sessionpart.
// FIXME: for consistency with other functions this should only
//   get the ice-ufrag and ice-pwd lines as input.
SDPUtils.getIceParameters = function(mediaSection, sessionpart) {
  const ufrag = SDPUtils.matchPrefix(mediaSection + sessionpart,
    'a=ice-ufrag:')[0];
  const pwd = SDPUtils.matchPrefix(mediaSection + sessionpart,
    'a=ice-pwd:')[0];
  if (!(ufrag && pwd)) {
    return null;
  }
  return {
    usernameFragment: ufrag.substring(12),
    password: pwd.substring(10),
  };
};

// Serializes ICE parameters to SDP.
SDPUtils.writeIceParameters = function(params) {
  let sdp = 'a=ice-ufrag:' + params.usernameFragment + '\r\n' +
      'a=ice-pwd:' + params.password + '\r\n';
  if (params.iceLite) {
    sdp += 'a=ice-lite\r\n';
  }
  return sdp;
};

// Parses the SDP media section and returns RTCRtpParameters.
SDPUtils.parseRtpParameters = function(mediaSection) {
  const description = {
    codecs: [],
    headerExtensions: [],
    fecMechanisms: [],
    rtcp: [],
  };
  const lines = SDPUtils.splitLines(mediaSection);
  const mline = lines[0].split(' ');
  description.profile = mline[2];
  for (let i = 3; i < mline.length; i++) { // find all codecs from mline[3..]
    const pt = mline[i];
    const rtpmapline = SDPUtils.matchPrefix(
      mediaSection, 'a=rtpmap:' + pt + ' ')[0];
    if (rtpmapline) {
      const codec = SDPUtils.parseRtpMap(rtpmapline);
      const fmtps = SDPUtils.matchPrefix(
        mediaSection, 'a=fmtp:' + pt + ' ');
      // Only the first a=fmtp:<pt> is considered.
      codec.parameters = fmtps.length ? SDPUtils.parseFmtp(fmtps[0]) : {};
      codec.rtcpFeedback = SDPUtils.matchPrefix(
        mediaSection, 'a=rtcp-fb:' + pt + ' ')
        .map(SDPUtils.parseRtcpFb);
      description.codecs.push(codec);
      // parse FEC mechanisms from rtpmap lines.
      switch (codec.name.toUpperCase()) {
        case 'RED':
        case 'ULPFEC':
          description.fecMechanisms.push(codec.name.toUpperCase());
          break;
        default: // only RED and ULPFEC are recognized as FEC mechanisms.
          break;
      }
    }
  }
  SDPUtils.matchPrefix(mediaSection, 'a=extmap:').forEach(line => {
    description.headerExtensions.push(SDPUtils.parseExtmap(line));
  });
  const wildcardRtcpFb = SDPUtils.matchPrefix(mediaSection, 'a=rtcp-fb:* ')
    .map(SDPUtils.parseRtcpFb);
  description.codecs.forEach(codec => {
    wildcardRtcpFb.forEach(fb=> {
      const duplicate = codec.rtcpFeedback.find(existingFeedback => {
        return existingFeedback.type === fb.type &&
          existingFeedback.parameter === fb.parameter;
      });
      if (!duplicate) {
        codec.rtcpFeedback.push(fb);
      }
    });
  });
  // FIXME: parse rtcp.
  return description;
};

// Generates parts of the SDP media section describing the capabilities /
// parameters.
SDPUtils.writeRtpDescription = function(kind, caps) {
  let sdp = '';

  // Build the mline.
  sdp += 'm=' + kind + ' ';
  sdp += caps.codecs.length > 0 ? '9' : '0'; // reject if no codecs.
  sdp += ' ' + (caps.profile || 'UDP/TLS/RTP/SAVPF') + ' ';
  sdp += caps.codecs.map(codec => {
    if (codec.preferredPayloadType !== undefined) {
      return codec.preferredPayloadType;
    }
    return codec.payloadType;
  }).join(' ') + '\r\n';

  sdp += 'c=IN IP4 0.0.0.0\r\n';
  sdp += 'a=rtcp:9 IN IP4 0.0.0.0\r\n';

  // Add a=rtpmap lines for each codec. Also fmtp and rtcp-fb.
  caps.codecs.forEach(codec => {
    sdp += SDPUtils.writeRtpMap(codec);
    sdp += SDPUtils.writeFmtp(codec);
    sdp += SDPUtils.writeRtcpFb(codec);
  });
  let maxptime = 0;
  caps.codecs.forEach(codec => {
    if (codec.maxptime > maxptime) {
      maxptime = codec.maxptime;
    }
  });
  if (maxptime > 0) {
    sdp += 'a=maxptime:' + maxptime + '\r\n';
  }

  if (caps.headerExtensions) {
    caps.headerExtensions.forEach(extension => {
      sdp += SDPUtils.writeExtmap(extension);
    });
  }
  // FIXME: write fecMechanisms.
  return sdp;
};

// Parses the SDP media section and returns an array of
// RTCRtpEncodingParameters.
SDPUtils.parseRtpEncodingParameters = function(mediaSection) {
  const encodingParameters = [];
  const description = SDPUtils.parseRtpParameters(mediaSection);
  const hasRed = description.fecMechanisms.indexOf('RED') !== -1;
  const hasUlpfec = description.fecMechanisms.indexOf('ULPFEC') !== -1;

  // filter a=ssrc:... cname:, ignore PlanB-msid
  const ssrcs = SDPUtils.matchPrefix(mediaSection, 'a=ssrc:')
    .map(line => SDPUtils.parseSsrcMedia(line))
    .filter(parts => parts.attribute === 'cname');
  const primarySsrc = ssrcs.length > 0 && ssrcs[0].ssrc;
  let secondarySsrc;

  const flows = SDPUtils.matchPrefix(mediaSection, 'a=ssrc-group:FID')
    .map(line => {
      const parts = line.substring(17).split(' ');
      return parts.map(part => parseInt(part, 10));
    });
  if (flows.length > 0 && flows[0].length > 1 && flows[0][0] === primarySsrc) {
    secondarySsrc = flows[0][1];
  }

  description.codecs.forEach(codec => {
    if (codec.name.toUpperCase() === 'RTX' && codec.parameters.apt) {
      let encParam = {
        ssrc: primarySsrc,
        codecPayloadType: parseInt(codec.parameters.apt, 10),
      };
      if (primarySsrc && secondarySsrc) {
        encParam.rtx = {ssrc: secondarySsrc};
      }
      encodingParameters.push(encParam);
      if (hasRed) {
        encParam = JSON.parse(JSON.stringify(encParam));
        encParam.fec = {
          ssrc: primarySsrc,
          mechanism: hasUlpfec ? 'red+ulpfec' : 'red',
        };
        encodingParameters.push(encParam);
      }
    }
  });
  if (encodingParameters.length === 0 && primarySsrc) {
    encodingParameters.push({
      ssrc: primarySsrc,
    });
  }

  // we support both b=AS and b=TIAS but interpret AS as TIAS.
  let bandwidth = SDPUtils.matchPrefix(mediaSection, 'b=');
  if (bandwidth.length) {
    if (bandwidth[0].indexOf('b=TIAS:') === 0) {
      bandwidth = parseInt(bandwidth[0].substring(7), 10);
    } else if (bandwidth[0].indexOf('b=AS:') === 0) {
      // use formula from JSEP to convert b=AS to TIAS value.
      bandwidth = parseInt(bandwidth[0].substring(5), 10) * 1000 * 0.95
          - (50 * 40 * 8);
    } else {
      bandwidth = undefined;
    }
    encodingParameters.forEach(params => {
      params.maxBitrate = bandwidth;
    });
  }
  return encodingParameters;
};

// parses http://draft.ortc.org/#rtcrtcpparameters*
SDPUtils.parseRtcpParameters = function(mediaSection) {
  const rtcpParameters = {};

  // Gets the first SSRC. Note that with RTX there might be multiple
  // SSRCs.
  const remoteSsrc = SDPUtils.matchPrefix(mediaSection, 'a=ssrc:')
    .map(line => SDPUtils.parseSsrcMedia(line))
    .filter(obj => obj.attribute === 'cname')[0];
  if (remoteSsrc) {
    rtcpParameters.cname = remoteSsrc.value;
    rtcpParameters.ssrc = remoteSsrc.ssrc;
  }

  // Edge uses the compound attribute instead of reducedSize
  // compound is !reducedSize
  const rsize = SDPUtils.matchPrefix(mediaSection, 'a=rtcp-rsize');
  rtcpParameters.reducedSize = rsize.length > 0;
  rtcpParameters.compound = rsize.length === 0;

  // parses the rtcp-mux attrbute.
  // Note that Edge does not support unmuxed RTCP.
  const mux = SDPUtils.matchPrefix(mediaSection, 'a=rtcp-mux');
  rtcpParameters.mux = mux.length > 0;

  return rtcpParameters;
};

SDPUtils.writeRtcpParameters = function(rtcpParameters) {
  let sdp = '';
  if (rtcpParameters.reducedSize) {
    sdp += 'a=rtcp-rsize\r\n';
  }
  if (rtcpParameters.mux) {
    sdp += 'a=rtcp-mux\r\n';
  }
  if (rtcpParameters.ssrc !== undefined && rtcpParameters.cname) {
    sdp += 'a=ssrc:' + rtcpParameters.ssrc +
      ' cname:' + rtcpParameters.cname + '\r\n';
  }
  return sdp;
};


// parses either a=msid: or a=ssrc:... msid lines and returns
// the id of the MediaStream and MediaStreamTrack.
SDPUtils.parseMsid = function(mediaSection) {
  let parts;
  const spec = SDPUtils.matchPrefix(mediaSection, 'a=msid:');
  if (spec.length === 1) {
    parts = spec[0].substring(7).split(' ');
    return {stream: parts[0], track: parts[1]};
  }
  const planB = SDPUtils.matchPrefix(mediaSection, 'a=ssrc:')
    .map(line => SDPUtils.parseSsrcMedia(line))
    .filter(msidParts => msidParts.attribute === 'msid');
  if (planB.length > 0) {
    parts = planB[0].value.split(' ');
    return {stream: parts[0], track: parts[1]};
  }
};

// SCTP
// parses draft-ietf-mmusic-sctp-sdp-26 first and falls back
// to draft-ietf-mmusic-sctp-sdp-05
SDPUtils.parseSctpDescription = function(mediaSection) {
  const mline = SDPUtils.parseMLine(mediaSection);
  const maxSizeLine = SDPUtils.matchPrefix(mediaSection, 'a=max-message-size:');
  let maxMessageSize;
  if (maxSizeLine.length > 0) {
    maxMessageSize = parseInt(maxSizeLine[0].substring(19), 10);
  }
  if (isNaN(maxMessageSize)) {
    maxMessageSize = 65536;
  }
  const sctpPort = SDPUtils.matchPrefix(mediaSection, 'a=sctp-port:');
  if (sctpPort.length > 0) {
    return {
      port: parseInt(sctpPort[0].substring(12), 10),
      protocol: mline.fmt,
      maxMessageSize,
    };
  }
  const sctpMapLines = SDPUtils.matchPrefix(mediaSection, 'a=sctpmap:');
  if (sctpMapLines.length > 0) {
    const parts = sctpMapLines[0]
      .substring(10)
      .split(' ');
    return {
      port: parseInt(parts[0], 10),
      protocol: parts[1],
      maxMessageSize,
    };
  }
};

// SCTP
// outputs the draft-ietf-mmusic-sctp-sdp-26 version that all browsers
// support by now receiving in this format, unless we originally parsed
// as the draft-ietf-mmusic-sctp-sdp-05 format (indicated by the m-line
// protocol of DTLS/SCTP -- without UDP/ or TCP/)
SDPUtils.writeSctpDescription = function(media, sctp) {
  let output = [];
  if (media.protocol !== 'DTLS/SCTP') {
    output = [
      'm=' + media.kind + ' 9 ' + media.protocol + ' ' + sctp.protocol + '\r\n',
      'c=IN IP4 0.0.0.0\r\n',
      'a=sctp-port:' + sctp.port + '\r\n',
    ];
  } else {
    output = [
      'm=' + media.kind + ' 9 ' + media.protocol + ' ' + sctp.port + '\r\n',
      'c=IN IP4 0.0.0.0\r\n',
      'a=sctpmap:' + sctp.port + ' ' + sctp.protocol + ' 65535\r\n',
    ];
  }
  if (sctp.maxMessageSize !== undefined) {
    output.push('a=max-message-size:' + sctp.maxMessageSize + '\r\n');
  }
  return output.join('');
};

// Generate a session ID for SDP.
// https://tools.ietf.org/html/draft-ietf-rtcweb-jsep-20#section-5.2.1
// recommends using a cryptographically random +ve 64-bit value
// but right now this should be acceptable and within the right range
SDPUtils.generateSessionId = function() {
  return Math.random().toString().substr(2, 22);
};

// Write boiler plate for start of SDP
// sessId argument is optional - if not supplied it will
// be generated randomly
// sessVersion is optional and defaults to 2
// sessUser is optional and defaults to 'thisisadapterortc'
SDPUtils.writeSessionBoilerplate = function(sessId, sessVer, sessUser) {
  let sessionId;
  const version = sessVer !== undefined ? sessVer : 2;
  if (sessId) {
    sessionId = sessId;
  } else {
    sessionId = SDPUtils.generateSessionId();
  }
  const user = sessUser || 'thisisadapterortc';
  // FIXME: sess-id should be an NTP timestamp.
  return 'v=0\r\n' +
      'o=' + user + ' ' + sessionId + ' ' + version +
        ' IN IP4 127.0.0.1\r\n' +
      's=-\r\n' +
      't=0 0\r\n';
};

// Gets the direction from the mediaSection or the sessionpart.
SDPUtils.getDirection = function(mediaSection, sessionpart) {
  // Look for sendrecv, sendonly, recvonly, inactive, default to sendrecv.
  const lines = SDPUtils.splitLines(mediaSection);
  for (let i = 0; i < lines.length; i++) {
    switch (lines[i]) {
      case 'a=sendrecv':
      case 'a=sendonly':
      case 'a=recvonly':
      case 'a=inactive':
        return lines[i].substring(2);
      default:
        // FIXME: What should happen here?
    }
  }
  if (sessionpart) {
    return SDPUtils.getDirection(sessionpart);
  }
  return 'sendrecv';
};

SDPUtils.getKind = function(mediaSection) {
  const lines = SDPUtils.splitLines(mediaSection);
  const mline = lines[0].split(' ');
  return mline[0].substring(2);
};

SDPUtils.isRejected = function(mediaSection) {
  return mediaSection.split(' ', 2)[1] === '0';
};

SDPUtils.parseMLine = function(mediaSection) {
  const lines = SDPUtils.splitLines(mediaSection);
  const parts = lines[0].substring(2).split(' ');
  return {
    kind: parts[0],
    port: parseInt(parts[1], 10),
    protocol: parts[2],
    fmt: parts.slice(3).join(' '),
  };
};

SDPUtils.parseOLine = function(mediaSection) {
  const line = SDPUtils.matchPrefix(mediaSection, 'o=')[0];
  const parts = line.substring(2).split(' ');
  return {
    username: parts[0],
    sessionId: parts[1],
    sessionVersion: parseInt(parts[2], 10),
    netType: parts[3],
    addressType: parts[4],
    address: parts[5],
  };
};

// a very naive interpretation of a valid SDP.
SDPUtils.isValidSDP = function(blob) {
  if (typeof blob !== 'string' || blob.length === 0) {
    return false;
  }
  const lines = SDPUtils.splitLines(blob);
  for (let i = 0; i < lines.length; i++) {
    if (lines[i].length < 2 || lines[i].charAt(1) !== '=') {
      return false;
    }
    // TODO: check the modifier a bit more.
  }
  return true;
};

// Expose public methods.
if (true) {
  module.exports = SDPUtils;
}


/***/ }),

/***/ "./node_modules/strophe.js/dist/strophe.umd.js":
/*!*****************************************************!*\
  !*** ./node_modules/strophe.js/dist/strophe.umd.js ***!
  \*****************************************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {

(function (global, factory) {
             true ? factory(exports) :
            0;
})(this, (function (exports) { 'use strict';

            var global$1 = typeof __webpack_require__.g !== "undefined" ? __webpack_require__.g : typeof self !== "undefined" ? self : typeof window !== "undefined" ? window : {};

            /*
             * This module provides uniform
             * Shims APIs and globals that are not present in all JS environments,
             * the most common example for Strophe being browser APIs like WebSocket
             * and DOM that don't exist under nodejs.
             *
             * Usually these will be supplied in nodejs by conditionally requiring a
             * NPM module that provides a compatible implementation.
             */

            /* global global */

            /**
             * WHATWG WebSockets API
             * https://www.w3.org/TR/websockets/
             *
             * Interface to use the web socket protocol
             *
             * Used implementations:
             * - supported browsers: built-in in WebSocket global
             *   https://developer.mozilla.org/en-US/docs/Web/API/WebSocket#Browser_compatibility
             * - nodejs: use standard-compliant 'ws' module
             *   https://www.npmjs.com/package/ws
             */
            function getWebSocketImplementation() {
              let WebSocketImplementation = global$1.WebSocket;

              if (typeof WebSocketImplementation === 'undefined') {
                try {
                  WebSocketImplementation = __webpack_require__(/*! ws */ "./node_modules/ws/browser.js");
                } catch (err) {
                  throw new Error('You must install the "ws" package to use Strophe in nodejs.');
                }
              }

              return WebSocketImplementation;
            }

            const WebSocket = getWebSocketImplementation();
            /**
             * DOMParser
             * https://w3c.github.io/DOM-Parsing/#the-domparser-interface
             *
             * Interface to parse XML strings into Document objects
             *
             * Used implementations:
             * - supported browsers: built-in in DOMParser global
             *   https://developer.mozilla.org/en-US/docs/Web/API/DOMParser#Browser_compatibility
             * - nodejs: use '@xmldom/xmldom' module
             *   https://www.npmjs.com/package/@xmldom/xmldom
             */

            function getDOMParserImplementation() {
              let DOMParserImplementation = global$1.DOMParser;

              if (typeof DOMParserImplementation === 'undefined') {
                try {
                  DOMParserImplementation = (__webpack_require__(/*! @xmldom/xmldom */ "./node_modules/@xmldom/xmldom/lib/index.js").DOMParser);
                } catch (err) {
                  throw new Error('You must install the "@xmldom/xmldom" package to use Strophe in nodejs.');
                }
              }

              return DOMParserImplementation;
            }

            const DOMParser = getDOMParserImplementation();
            /**
             *  Gets IE xml doc object. Used by getDummyXMLDocument shim.
             *
             *  Returns:
             *    A Microsoft XML DOM Object
             *  See Also:
             *    http://msdn.microsoft.com/en-us/library/ms757837%28VS.85%29.aspx
             */

            function _getIEXmlDom() {
              const docStrings = ["Msxml2.DOMDocument.6.0", "Msxml2.DOMDocument.5.0", "Msxml2.DOMDocument.4.0", "MSXML2.DOMDocument.3.0", "MSXML2.DOMDocument", "MSXML.DOMDocument", "Microsoft.XMLDOM"];

              for (let d = 0; d < docStrings.length; d++) {
                try {
                  // eslint-disable-next-line no-undef
                  const doc = new ActiveXObject(docStrings[d]);
                  return doc;
                } catch (e) {// Try next one
                }
              }
            }
            /**
             * Creates a dummy XML DOM document to serve as an element and text node generator.
             *
             * Used implementations:
             *  - IE < 10: avoid using createDocument() due to a memory leak, use ie-specific
             *    workaround
             *  - other supported browsers: use document's createDocument
             *  - nodejs: use '@xmldom/xmldom'
             */


            function getDummyXMLDOMDocument() {
              // nodejs
              if (typeof document === 'undefined') {
                try {
                  const DOMImplementation = (__webpack_require__(/*! @xmldom/xmldom */ "./node_modules/@xmldom/xmldom/lib/index.js").DOMImplementation);

                  return new DOMImplementation().createDocument('jabber:client', 'strophe', null);
                } catch (err) {
                  throw new Error('You must install the "@xmldom/xmldom" package to use Strophe in nodejs.');
                }
              } // IE < 10


              if (document.implementation.createDocument === undefined || document.implementation.createDocument && document.documentMode && document.documentMode < 10) {
                const doc = _getIEXmlDom();

                doc.appendChild(doc.createElement('strophe'));
                return doc;
              } // All other supported browsers


              return document.implementation.createDocument('jabber:client', 'strophe', null);
            }

            /*
             * A JavaScript implementation of the RSA Data Security, Inc. MD5 Message
             * Digest Algorithm, as defined in RFC 1321.
             * Version 2.1 Copyright (C) Paul Johnston 1999 - 2002.
             * Other contributors: Greg Holt, Andrew Kepert, Ydnar, Lostinet
             * Distributed under the BSD License
             * See http://pajhome.org.uk/crypt/md5 for more info.
             */

            /*
             * Everything that isn't used by Strophe has been stripped here!
             */

            /*
             * Add integers, wrapping at 2^32. This uses 16-bit operations internally
             * to work around bugs in some JS interpreters.
             */
            const safe_add$1 = function (x, y) {
              const lsw = (x & 0xFFFF) + (y & 0xFFFF);
              const msw = (x >> 16) + (y >> 16) + (lsw >> 16);
              return msw << 16 | lsw & 0xFFFF;
            };
            /*
             * Bitwise rotate a 32-bit number to the left.
             */


            const bit_rol = function (num, cnt) {
              return num << cnt | num >>> 32 - cnt;
            };
            /*
             * Convert a string to an array of little-endian words
             */


            const str2binl = function (str) {
              if (typeof str !== "string") {
                throw new Error("str2binl was passed a non-string");
              }

              const bin = [];

              for (let i = 0; i < str.length * 8; i += 8) {
                bin[i >> 5] |= (str.charCodeAt(i / 8) & 255) << i % 32;
              }

              return bin;
            };
            /*
             * Convert an array of little-endian words to a string
             */


            const binl2str = function (bin) {
              let str = "";

              for (let i = 0; i < bin.length * 32; i += 8) {
                str += String.fromCharCode(bin[i >> 5] >>> i % 32 & 255);
              }

              return str;
            };
            /*
             * Convert an array of little-endian words to a hex string.
             */


            const binl2hex = function (binarray) {
              const hex_tab = "0123456789abcdef";
              let str = "";

              for (let i = 0; i < binarray.length * 4; i++) {
                str += hex_tab.charAt(binarray[i >> 2] >> i % 4 * 8 + 4 & 0xF) + hex_tab.charAt(binarray[i >> 2] >> i % 4 * 8 & 0xF);
              }

              return str;
            };
            /*
             * These functions implement the four basic operations the algorithm uses.
             */


            const md5_cmn = function (q, a, b, x, s, t) {
              return safe_add$1(bit_rol(safe_add$1(safe_add$1(a, q), safe_add$1(x, t)), s), b);
            };

            const md5_ff = function (a, b, c, d, x, s, t) {
              return md5_cmn(b & c | ~b & d, a, b, x, s, t);
            };

            const md5_gg = function (a, b, c, d, x, s, t) {
              return md5_cmn(b & d | c & ~d, a, b, x, s, t);
            };

            const md5_hh = function (a, b, c, d, x, s, t) {
              return md5_cmn(b ^ c ^ d, a, b, x, s, t);
            };

            const md5_ii = function (a, b, c, d, x, s, t) {
              return md5_cmn(c ^ (b | ~d), a, b, x, s, t);
            };
            /*
             * Calculate the MD5 of an array of little-endian words, and a bit length
             */


            const core_md5 = function (x, len) {
              /* append padding */
              x[len >> 5] |= 0x80 << len % 32;
              x[(len + 64 >>> 9 << 4) + 14] = len;
              let a = 1732584193;
              let b = -271733879;
              let c = -1732584194;
              let d = 271733878;
              let olda, oldb, oldc, oldd;

              for (let i = 0; i < x.length; i += 16) {
                olda = a;
                oldb = b;
                oldc = c;
                oldd = d;
                a = md5_ff(a, b, c, d, x[i + 0], 7, -680876936);
                d = md5_ff(d, a, b, c, x[i + 1], 12, -389564586);
                c = md5_ff(c, d, a, b, x[i + 2], 17, 606105819);
                b = md5_ff(b, c, d, a, x[i + 3], 22, -1044525330);
                a = md5_ff(a, b, c, d, x[i + 4], 7, -176418897);
                d = md5_ff(d, a, b, c, x[i + 5], 12, 1200080426);
                c = md5_ff(c, d, a, b, x[i + 6], 17, -1473231341);
                b = md5_ff(b, c, d, a, x[i + 7], 22, -45705983);
                a = md5_ff(a, b, c, d, x[i + 8], 7, 1770035416);
                d = md5_ff(d, a, b, c, x[i + 9], 12, -1958414417);
                c = md5_ff(c, d, a, b, x[i + 10], 17, -42063);
                b = md5_ff(b, c, d, a, x[i + 11], 22, -1990404162);
                a = md5_ff(a, b, c, d, x[i + 12], 7, 1804603682);
                d = md5_ff(d, a, b, c, x[i + 13], 12, -40341101);
                c = md5_ff(c, d, a, b, x[i + 14], 17, -1502002290);
                b = md5_ff(b, c, d, a, x[i + 15], 22, 1236535329);
                a = md5_gg(a, b, c, d, x[i + 1], 5, -165796510);
                d = md5_gg(d, a, b, c, x[i + 6], 9, -1069501632);
                c = md5_gg(c, d, a, b, x[i + 11], 14, 643717713);
                b = md5_gg(b, c, d, a, x[i + 0], 20, -373897302);
                a = md5_gg(a, b, c, d, x[i + 5], 5, -701558691);
                d = md5_gg(d, a, b, c, x[i + 10], 9, 38016083);
                c = md5_gg(c, d, a, b, x[i + 15], 14, -660478335);
                b = md5_gg(b, c, d, a, x[i + 4], 20, -405537848);
                a = md5_gg(a, b, c, d, x[i + 9], 5, 568446438);
                d = md5_gg(d, a, b, c, x[i + 14], 9, -1019803690);
                c = md5_gg(c, d, a, b, x[i + 3], 14, -187363961);
                b = md5_gg(b, c, d, a, x[i + 8], 20, 1163531501);
                a = md5_gg(a, b, c, d, x[i + 13], 5, -1444681467);
                d = md5_gg(d, a, b, c, x[i + 2], 9, -51403784);
                c = md5_gg(c, d, a, b, x[i + 7], 14, 1735328473);
                b = md5_gg(b, c, d, a, x[i + 12], 20, -1926607734);
                a = md5_hh(a, b, c, d, x[i + 5], 4, -378558);
                d = md5_hh(d, a, b, c, x[i + 8], 11, -2022574463);
                c = md5_hh(c, d, a, b, x[i + 11], 16, 1839030562);
                b = md5_hh(b, c, d, a, x[i + 14], 23, -35309556);
                a = md5_hh(a, b, c, d, x[i + 1], 4, -1530992060);
                d = md5_hh(d, a, b, c, x[i + 4], 11, 1272893353);
                c = md5_hh(c, d, a, b, x[i + 7], 16, -155497632);
                b = md5_hh(b, c, d, a, x[i + 10], 23, -1094730640);
                a = md5_hh(a, b, c, d, x[i + 13], 4, 681279174);
                d = md5_hh(d, a, b, c, x[i + 0], 11, -358537222);
                c = md5_hh(c, d, a, b, x[i + 3], 16, -722521979);
                b = md5_hh(b, c, d, a, x[i + 6], 23, 76029189);
                a = md5_hh(a, b, c, d, x[i + 9], 4, -640364487);
                d = md5_hh(d, a, b, c, x[i + 12], 11, -421815835);
                c = md5_hh(c, d, a, b, x[i + 15], 16, 530742520);
                b = md5_hh(b, c, d, a, x[i + 2], 23, -995338651);
                a = md5_ii(a, b, c, d, x[i + 0], 6, -198630844);
                d = md5_ii(d, a, b, c, x[i + 7], 10, 1126891415);
                c = md5_ii(c, d, a, b, x[i + 14], 15, -1416354905);
                b = md5_ii(b, c, d, a, x[i + 5], 21, -57434055);
                a = md5_ii(a, b, c, d, x[i + 12], 6, 1700485571);
                d = md5_ii(d, a, b, c, x[i + 3], 10, -1894986606);
                c = md5_ii(c, d, a, b, x[i + 10], 15, -1051523);
                b = md5_ii(b, c, d, a, x[i + 1], 21, -2054922799);
                a = md5_ii(a, b, c, d, x[i + 8], 6, 1873313359);
                d = md5_ii(d, a, b, c, x[i + 15], 10, -30611744);
                c = md5_ii(c, d, a, b, x[i + 6], 15, -1560198380);
                b = md5_ii(b, c, d, a, x[i + 13], 21, 1309151649);
                a = md5_ii(a, b, c, d, x[i + 4], 6, -145523070);
                d = md5_ii(d, a, b, c, x[i + 11], 10, -1120210379);
                c = md5_ii(c, d, a, b, x[i + 2], 15, 718787259);
                b = md5_ii(b, c, d, a, x[i + 9], 21, -343485551);
                a = safe_add$1(a, olda);
                b = safe_add$1(b, oldb);
                c = safe_add$1(c, oldc);
                d = safe_add$1(d, oldd);
              }

              return [a, b, c, d];
            };
            /*
             * These are the functions you'll usually want to call.
             * They take string arguments and return either hex or base-64 encoded
             * strings.
             */


            const MD5 = {
              hexdigest: function (s) {
                return binl2hex(core_md5(str2binl(s), s.length * 8));
              },
              hash: function (s) {
                return binl2str(core_md5(str2binl(s), s.length * 8));
              }
            };

            /** Class: Strophe.SASLMechanism
             *
             *  Encapsulates an SASL authentication mechanism.
             *
             *  User code may override the priority for each mechanism or disable it completely.
             *  See <priority> for information about changing priority and <test> for informatian on
             *  how to disable a mechanism.
             *
             *  By default, all mechanisms are enabled and the priorities are
             *
             *      SCRAM-SHA-1 - 60
             *      PLAIN       - 50
             *      OAUTHBEARER - 40
             *      X-OAUTH2    - 30
             *      ANONYMOUS   - 20
             *      EXTERNAL    - 10
             *
             *  See: Strophe.Connection.addSupportedSASLMechanisms
             */
            class SASLMechanism {
              /**
               * PrivateConstructor: Strophe.SASLMechanism
               * SASL auth mechanism abstraction.
               *
               *  Parameters:
               *    (String) name - SASL Mechanism name.
               *    (Boolean) isClientFirst - If client should send response first without challenge.
               *    (Number) priority - Priority.
               *
               *  Returns:
               *    A new Strophe.SASLMechanism object.
               */
              constructor(name, isClientFirst, priority) {
                /** PrivateVariable: mechname
                 *  Mechanism name.
                 */
                this.mechname = name;
                /** PrivateVariable: isClientFirst
                 *  If client sends response without initial server challenge.
                 */

                this.isClientFirst = isClientFirst;
                /** Variable: priority
                 *  Determines which <SASLMechanism> is chosen for authentication (Higher is better).
                 *  Users may override this to prioritize mechanisms differently.
                 *
                 *  Example: (This will cause Strophe to choose the mechanism that the server sent first)
                 *
                 *  > Strophe.SASLPlain.priority = Strophe.SASLSHA1.priority;
                 *
                 *  See <SASL mechanisms> for a list of available mechanisms.
                 *
                 */

                this.priority = priority;
              }
              /**
               *  Function: test
               *  Checks if mechanism able to run.
               *  To disable a mechanism, make this return false;
               *
               *  To disable plain authentication run
               *  > Strophe.SASLPlain.test = function() {
               *  >   return false;
               *  > }
               *
               *  See <SASL mechanisms> for a list of available mechanisms.
               *
               *  Parameters:
               *    (Strophe.Connection) connection - Target Connection.
               *
               *  Returns:
               *    (Boolean) If mechanism was able to run.
               */


              test() {
                // eslint-disable-line class-methods-use-this
                return true;
              }
              /** PrivateFunction: onStart
               *  Called before starting mechanism on some connection.
               *
               *  Parameters:
               *    (Strophe.Connection) connection - Target Connection.
               */


              onStart(connection) {
                this._connection = connection;
              }
              /** PrivateFunction: onChallenge
               *  Called by protocol implementation on incoming challenge.
               *
               *  By deafult, if the client is expected to send data first (isClientFirst === true),
               *  this method is called with `challenge` as null on the first call,
               *  unless `clientChallenge` is overridden in the relevant subclass.
               *
               *  Parameters:
               *    (Strophe.Connection) connection - Target Connection.
               *    (String) challenge - current challenge to handle.
               *
               *  Returns:
               *    (String) Mechanism response.
               */


              onChallenge(connection, challenge) {
                // eslint-disable-line
                throw new Error("You should implement challenge handling!");
              }
              /** PrivateFunction: clientChallenge
               *  Called by the protocol implementation if the client is expected to send
               *  data first in the authentication exchange (i.e. isClientFirst === true).
               *
               *  Parameters:
               *    (Strophe.Connection) connection - Target Connection.
               *
               *  Returns:
               *    (String) Mechanism response.
               */


              clientChallenge(connection) {
                if (!this.isClientFirst) {
                  throw new Error("clientChallenge should not be called if isClientFirst is false!");
                }

                return this.onChallenge(connection);
              }
              /** PrivateFunction: onFailure
               *  Protocol informs mechanism implementation about SASL failure.
               */


              onFailure() {
                this._connection = null;
              }
              /** PrivateFunction: onSuccess
               *  Protocol informs mechanism implementation about SASL success.
               */


              onSuccess() {
                this._connection = null;
              }

            }

            class SASLAnonymous extends SASLMechanism {
              /** PrivateConstructor: SASLAnonymous
               *  SASL ANONYMOUS authentication.
               */
              constructor() {
                let mechname = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : 'ANONYMOUS';
                let isClientFirst = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : false;
                let priority = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 20;
                super(mechname, isClientFirst, priority);
              }

              test(connection) {
                // eslint-disable-line class-methods-use-this
                return connection.authcid === null;
              }

            }

            class SASLExternal extends SASLMechanism {
              /** PrivateConstructor: SASLExternal
               *  SASL EXTERNAL authentication.
               *
               *  The EXTERNAL mechanism allows a client to request the server to use
               *  credentials established by means external to the mechanism to
               *  authenticate the client. The external means may be, for instance,
               *  TLS services.
               */
              constructor() {
                let mechname = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : 'EXTERNAL';
                let isClientFirst = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : true;
                let priority = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 10;
                super(mechname, isClientFirst, priority);
              }

              onChallenge(connection) {
                // eslint-disable-line class-methods-use-this

                /** According to XEP-178, an authzid SHOULD NOT be presented when the
                 * authcid contained or implied in the client certificate is the JID (i.e.
                 * authzid) with which the user wants to log in as.
                 *
                 * To NOT send the authzid, the user should therefore set the authcid equal
                 * to the JID when instantiating a new Strophe.Connection object.
                 */
                return connection.authcid === connection.authzid ? '' : connection.authzid;
              }

            }

            const utils = {
              utf16to8: function (str) {
                var i, c;
                var out = "";
                var len = str.length;

                for (i = 0; i < len; i++) {
                  c = str.charCodeAt(i);

                  if (c >= 0x0000 && c <= 0x007F) {
                    out += str.charAt(i);
                  } else if (c > 0x07FF) {
                    out += String.fromCharCode(0xE0 | c >> 12 & 0x0F);
                    out += String.fromCharCode(0x80 | c >> 6 & 0x3F);
                    out += String.fromCharCode(0x80 | c >> 0 & 0x3F);
                  } else {
                    out += String.fromCharCode(0xC0 | c >> 6 & 0x1F);
                    out += String.fromCharCode(0x80 | c >> 0 & 0x3F);
                  }
                }

                return out;
              },
              addCookies: function (cookies) {
                /* Parameters:
                 *  (Object) cookies - either a map of cookie names
                 *    to string values or to maps of cookie values.
                 *
                 * For example:
                 * { "myCookie": "1234" }
                 *
                 * or:
                 * { "myCookie": {
                 *      "value": "1234",
                 *      "domain": ".example.org",
                 *      "path": "/",
                 *      "expires": expirationDate
                 *      }
                 *  }
                 *
                 *  These values get passed to Strophe.Connection via
                 *   options.cookies
                 */
                cookies = cookies || {};

                for (const cookieName in cookies) {
                  if (Object.prototype.hasOwnProperty.call(cookies, cookieName)) {
                    let expires = '';
                    let domain = '';
                    let path = '';
                    const cookieObj = cookies[cookieName];
                    const isObj = typeof cookieObj === "object";
                    const cookieValue = escape(unescape(isObj ? cookieObj.value : cookieObj));

                    if (isObj) {
                      expires = cookieObj.expires ? ";expires=" + cookieObj.expires : '';
                      domain = cookieObj.domain ? ";domain=" + cookieObj.domain : '';
                      path = cookieObj.path ? ";path=" + cookieObj.path : '';
                    }

                    document.cookie = cookieName + '=' + cookieValue + expires + domain + path;
                  }
                }
              }
            };

            class SASLOAuthBearer extends SASLMechanism {
              /** PrivateConstructor: SASLOAuthBearer
               *  SASL OAuth Bearer authentication.
               */
              constructor() {
                let mechname = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : 'OAUTHBEARER';
                let isClientFirst = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : true;
                let priority = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 40;
                super(mechname, isClientFirst, priority);
              }

              test(connection) {
                // eslint-disable-line class-methods-use-this
                return connection.pass !== null;
              }

              onChallenge(connection) {
                // eslint-disable-line class-methods-use-this
                let auth_str = 'n,';

                if (connection.authcid !== null) {
                  auth_str = auth_str + 'a=' + connection.authzid;
                }

                auth_str = auth_str + ',';
                auth_str = auth_str + "\u0001";
                auth_str = auth_str + 'auth=Bearer ';
                auth_str = auth_str + connection.pass;
                auth_str = auth_str + "\u0001";
                auth_str = auth_str + "\u0001";
                return utils.utf16to8(auth_str);
              }

            }

            class SASLPlain extends SASLMechanism {
              /** PrivateConstructor: SASLPlain
               *  SASL PLAIN authentication.
               */
              constructor() {
                let mechname = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : 'PLAIN';
                let isClientFirst = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : true;
                let priority = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 50;
                super(mechname, isClientFirst, priority);
              }

              test(connection) {
                // eslint-disable-line class-methods-use-this
                return connection.authcid !== null;
              }

              onChallenge(connection) {
                // eslint-disable-line class-methods-use-this
                const {
                  authcid,
                  authzid,
                  domain,
                  pass
                } = connection;

                if (!domain) {
                  throw new Error("SASLPlain onChallenge: domain is not defined!");
                } // Only include authzid if it differs from authcid.
                // See: https://tools.ietf.org/html/rfc6120#section-6.3.8


                let auth_str = authzid !== `${authcid}@${domain}` ? authzid : '';
                auth_str = auth_str + "\u0000";
                auth_str = auth_str + authcid;
                auth_str = auth_str + "\u0000";
                auth_str = auth_str + pass;
                return utils.utf16to8(auth_str);
              }

            }

            /*
             * A JavaScript implementation of the Secure Hash Algorithm, SHA-1, as defined
             * in FIPS PUB 180-1
             * Version 2.1a Copyright Paul Johnston 2000 - 2002.
             * Other contributors: Greg Holt, Andrew Kepert, Ydnar, Lostinet
             * Distributed under the BSD License
             * See http://pajhome.org.uk/crypt/md5 for details.
             */

            /* global define */

            /* Some functions and variables have been stripped for use with Strophe */

            /*
             * Calculate the SHA-1 of an array of big-endian words, and a bit length
             */
            function core_sha1(x, len) {
              /* append padding */
              x[len >> 5] |= 0x80 << 24 - len % 32;
              x[(len + 64 >> 9 << 4) + 15] = len;
              var w = new Array(80);
              var a = 1732584193;
              var b = -271733879;
              var c = -1732584194;
              var d = 271733878;
              var e = -1009589776;
              var i, j, t, olda, oldb, oldc, oldd, olde;

              for (i = 0; i < x.length; i += 16) {
                olda = a;
                oldb = b;
                oldc = c;
                oldd = d;
                olde = e;

                for (j = 0; j < 80; j++) {
                  if (j < 16) {
                    w[j] = x[i + j];
                  } else {
                    w[j] = rol(w[j - 3] ^ w[j - 8] ^ w[j - 14] ^ w[j - 16], 1);
                  }

                  t = safe_add(safe_add(rol(a, 5), sha1_ft(j, b, c, d)), safe_add(safe_add(e, w[j]), sha1_kt(j)));
                  e = d;
                  d = c;
                  c = rol(b, 30);
                  b = a;
                  a = t;
                }

                a = safe_add(a, olda);
                b = safe_add(b, oldb);
                c = safe_add(c, oldc);
                d = safe_add(d, oldd);
                e = safe_add(e, olde);
              }

              return [a, b, c, d, e];
            }
            /*
             * Perform the appropriate triplet combination function for the current
             * iteration
             */


            function sha1_ft(t, b, c, d) {
              if (t < 20) {
                return b & c | ~b & d;
              }

              if (t < 40) {
                return b ^ c ^ d;
              }

              if (t < 60) {
                return b & c | b & d | c & d;
              }

              return b ^ c ^ d;
            }
            /*
             * Determine the appropriate additive constant for the current iteration
             */


            function sha1_kt(t) {
              return t < 20 ? 1518500249 : t < 40 ? 1859775393 : t < 60 ? -1894007588 : -899497514;
            }
            /*
             * Calculate the HMAC-SHA1 of a key and some data
             */


            function core_hmac_sha1(key, data) {
              var bkey = str2binb(key);

              if (bkey.length > 16) {
                bkey = core_sha1(bkey, key.length * 8);
              }

              var ipad = new Array(16),
                  opad = new Array(16);

              for (var i = 0; i < 16; i++) {
                ipad[i] = bkey[i] ^ 0x36363636;
                opad[i] = bkey[i] ^ 0x5C5C5C5C;
              }

              var hash = core_sha1(ipad.concat(str2binb(data)), 512 + data.length * 8);
              return core_sha1(opad.concat(hash), 512 + 160);
            }
            /*
             * Add integers, wrapping at 2^32. This uses 16-bit operations internally
             * to work around bugs in some JS interpreters.
             */


            function safe_add(x, y) {
              var lsw = (x & 0xFFFF) + (y & 0xFFFF);
              var msw = (x >> 16) + (y >> 16) + (lsw >> 16);
              return msw << 16 | lsw & 0xFFFF;
            }
            /*
             * Bitwise rotate a 32-bit number to the left.
             */


            function rol(num, cnt) {
              return num << cnt | num >>> 32 - cnt;
            }
            /*
             * Convert an 8-bit or 16-bit string to an array of big-endian words
             * In 8-bit function, characters >255 have their hi-byte silently ignored.
             */


            function str2binb(str) {
              var bin = [];
              var mask = 255;

              for (var i = 0; i < str.length * 8; i += 8) {
                bin[i >> 5] |= (str.charCodeAt(i / 8) & mask) << 24 - i % 32;
              }

              return bin;
            }
            /*
             * Convert an array of big-endian words to a base-64 string
             */


            function binb2b64(binarray) {
              var tab = "ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/";
              var str = "";
              var triplet, j;

              for (var i = 0; i < binarray.length * 4; i += 3) {
                triplet = (binarray[i >> 2] >> 8 * (3 - i % 4) & 0xFF) << 16 | (binarray[i + 1 >> 2] >> 8 * (3 - (i + 1) % 4) & 0xFF) << 8 | binarray[i + 2 >> 2] >> 8 * (3 - (i + 2) % 4) & 0xFF;

                for (j = 0; j < 4; j++) {
                  if (i * 8 + j * 6 > binarray.length * 32) {
                    str += "=";
                  } else {
                    str += tab.charAt(triplet >> 6 * (3 - j) & 0x3F);
                  }
                }
              }

              return str;
            }
            /*
             * Convert an array of big-endian words to a string
             */


            function binb2str(bin) {
              var str = "";
              var mask = 255;

              for (var i = 0; i < bin.length * 32; i += 8) {
                str += String.fromCharCode(bin[i >> 5] >>> 24 - i % 32 & mask);
              }

              return str;
            }
            /*
             * These are the functions you'll usually want to call
             * They take string arguments and return either hex or base-64 encoded strings
             */


            const SHA1 = {
              b64_hmac_sha1: function (key, data) {
                return binb2b64(core_hmac_sha1(key, data));
              },
              b64_sha1: function (s) {
                return binb2b64(core_sha1(str2binb(s), s.length * 8));
              },
              binb2str: binb2str,
              core_hmac_sha1: core_hmac_sha1,
              str_hmac_sha1: function (key, data) {
                return binb2str(core_hmac_sha1(key, data));
              },
              str_sha1: function (s) {
                return binb2str(core_sha1(str2binb(s), s.length * 8));
              }
            };

            class SASLSHA1 extends SASLMechanism {
              /** PrivateConstructor: SASLSHA1
               *  SASL SCRAM SHA 1 authentication.
               */
              constructor() {
                let mechname = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : 'SCRAM-SHA-1';
                let isClientFirst = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : true;
                let priority = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 60;
                super(mechname, isClientFirst, priority);
              }

              test(connection) {
                // eslint-disable-line class-methods-use-this
                return connection.authcid !== null;
              }

              onChallenge(connection, challenge) {
                // eslint-disable-line class-methods-use-this
                let nonce, salt, iter, Hi, U, U_old, i, k;
                let responseText = "c=biws,";
                let authMessage = `${connection._sasl_data["client-first-message-bare"]},${challenge},`;
                const cnonce = connection._sasl_data.cnonce;
                const attribMatch = /([a-z]+)=([^,]+)(,|$)/;

                while (challenge.match(attribMatch)) {
                  const matches = challenge.match(attribMatch);
                  challenge = challenge.replace(matches[0], "");

                  switch (matches[1]) {
                    case "r":
                      nonce = matches[2];
                      break;

                    case "s":
                      salt = matches[2];
                      break;

                    case "i":
                      iter = matches[2];
                      break;
                  }
                }

                if (nonce.slice(0, cnonce.length) !== cnonce) {
                  connection._sasl_data = {};
                  return connection._sasl_failure_cb();
                }

                responseText += "r=" + nonce;
                authMessage += responseText;
                salt = atob(salt);
                salt += "\x00\x00\x00\x01";
                const pass = utils.utf16to8(connection.pass);
                Hi = U_old = SHA1.core_hmac_sha1(pass, salt);

                for (i = 1; i < iter; i++) {
                  U = SHA1.core_hmac_sha1(pass, SHA1.binb2str(U_old));

                  for (k = 0; k < 5; k++) {
                    Hi[k] ^= U[k];
                  }

                  U_old = U;
                }

                Hi = SHA1.binb2str(Hi);
                const clientKey = SHA1.core_hmac_sha1(Hi, "Client Key");
                const serverKey = SHA1.str_hmac_sha1(Hi, "Server Key");
                const clientSignature = SHA1.core_hmac_sha1(SHA1.str_sha1(SHA1.binb2str(clientKey)), authMessage);
                connection._sasl_data["server-signature"] = SHA1.b64_hmac_sha1(serverKey, authMessage);

                for (k = 0; k < 5; k++) {
                  clientKey[k] ^= clientSignature[k];
                }

                responseText += ",p=" + btoa(SHA1.binb2str(clientKey));
                return responseText;
              }

              clientChallenge(connection, test_cnonce) {
                // eslint-disable-line class-methods-use-this
                const cnonce = test_cnonce || MD5.hexdigest("" + Math.random() * 1234567890);
                let auth_str = "n=" + utils.utf16to8(connection.authcid);
                auth_str += ",r=";
                auth_str += cnonce;
                connection._sasl_data.cnonce = cnonce;
                connection._sasl_data["client-first-message-bare"] = auth_str;
                auth_str = "n,," + auth_str;
                return auth_str;
              }

            }

            class SASLXOAuth2 extends SASLMechanism {
              /** PrivateConstructor: SASLXOAuth2
               *  SASL X-OAuth2 authentication.
               */
              constructor() {
                let mechname = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : 'X-OAUTH2';
                let isClientFirst = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : true;
                let priority = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 30;
                super(mechname, isClientFirst, priority);
              }

              test(connection) {
                // eslint-disable-line class-methods-use-this
                return connection.pass !== null;
              }

              onChallenge(connection) {
                // eslint-disable-line class-methods-use-this
                let auth_str = '\u0000';

                if (connection.authcid !== null) {
                  auth_str = auth_str + connection.authzid;
                }

                auth_str = auth_str + "\u0000";
                auth_str = auth_str + connection.pass;
                return utils.utf16to8(auth_str);
              }

            }

            /**
             * Implementation of atob() according to the HTML and Infra specs, except that
             * instead of throwing INVALID_CHARACTER_ERR we return null.
             */

            function atob$2(data) {
              if (arguments.length === 0) {
                throw new TypeError("1 argument required, but only 0 present.");
              } // Web IDL requires DOMStrings to just be converted using ECMAScript
              // ToString, which in our case amounts to using a template literal.


              data = `${data}`; // "Remove all ASCII whitespace from data."

              data = data.replace(/[ \t\n\f\r]/g, ""); // "If data's length divides by 4 leaving no remainder, then: if data ends
              // with one or two U+003D (=) code points, then remove them from data."

              if (data.length % 4 === 0) {
                data = data.replace(/==?$/, "");
              } // "If data's length divides by 4 leaving a remainder of 1, then return
              // failure."
              //
              // "If data contains a code point that is not one of
              //
              // U+002B (+)
              // U+002F (/)
              // ASCII alphanumeric
              //
              // then return failure."


              if (data.length % 4 === 1 || /[^+/0-9A-Za-z]/.test(data)) {
                return null;
              } // "Let output be an empty byte sequence."


              let output = ""; // "Let buffer be an empty buffer that can have bits appended to it."
              //
              // We append bits via left-shift and or.  accumulatedBits is used to track
              // when we've gotten to 24 bits.

              let buffer = 0;
              let accumulatedBits = 0; // "Let position be a position variable for data, initially pointing at the
              // start of data."
              //
              // "While position does not point past the end of data:"

              for (let i = 0; i < data.length; i++) {
                // "Find the code point pointed to by position in the second column of
                // Table 1: The Base 64 Alphabet of RFC 4648. Let n be the number given in
                // the first cell of the same row.
                //
                // "Append to buffer the six bits corresponding to n, most significant bit
                // first."
                //
                // atobLookup() implements the table from RFC 4648.
                buffer <<= 6;
                buffer |= atobLookup(data[i]);
                accumulatedBits += 6; // "If buffer has accumulated 24 bits, interpret them as three 8-bit
                // big-endian numbers. Append three bytes with values equal to those
                // numbers to output, in the same order, and then empty buffer."

                if (accumulatedBits === 24) {
                  output += String.fromCharCode((buffer & 0xff0000) >> 16);
                  output += String.fromCharCode((buffer & 0xff00) >> 8);
                  output += String.fromCharCode(buffer & 0xff);
                  buffer = accumulatedBits = 0;
                } // "Advance position by 1."

              } // "If buffer is not empty, it contains either 12 or 18 bits. If it contains
              // 12 bits, then discard the last four and interpret the remaining eight as
              // an 8-bit big-endian number. If it contains 18 bits, then discard the last
              // two and interpret the remaining 16 as two 8-bit big-endian numbers. Append
              // the one or two bytes with values equal to those one or two numbers to
              // output, in the same order."


              if (accumulatedBits === 12) {
                buffer >>= 4;
                output += String.fromCharCode(buffer);
              } else if (accumulatedBits === 18) {
                buffer >>= 2;
                output += String.fromCharCode((buffer & 0xff00) >> 8);
                output += String.fromCharCode(buffer & 0xff);
              } // "Return output."


              return output;
            }
            /**
             * A lookup table for atob(), which converts an ASCII character to the
             * corresponding six-bit number.
             */


            const keystr$1 = "ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/";

            function atobLookup(chr) {
              const index = keystr$1.indexOf(chr); // Throw exception if character is not in the lookup string; should not be hit in tests

              return index < 0 ? undefined : index;
            }

            var atob_1 = atob$2;

            /**
             * btoa() as defined by the HTML and Infra specs, which mostly just references
             * RFC 4648.
             */

            function btoa$2(s) {
              if (arguments.length === 0) {
                throw new TypeError("1 argument required, but only 0 present.");
              }

              let i; // String conversion as required by Web IDL.

              s = `${s}`; // "The btoa() method must throw an "InvalidCharacterError" DOMException if
              // data contains any character whose code point is greater than U+00FF."

              for (i = 0; i < s.length; i++) {
                if (s.charCodeAt(i) > 255) {
                  return null;
                }
              }

              let out = "";

              for (i = 0; i < s.length; i += 3) {
                const groupsOfSix = [undefined, undefined, undefined, undefined];
                groupsOfSix[0] = s.charCodeAt(i) >> 2;
                groupsOfSix[1] = (s.charCodeAt(i) & 0x03) << 4;

                if (s.length > i + 1) {
                  groupsOfSix[1] |= s.charCodeAt(i + 1) >> 4;
                  groupsOfSix[2] = (s.charCodeAt(i + 1) & 0x0f) << 2;
                }

                if (s.length > i + 2) {
                  groupsOfSix[2] |= s.charCodeAt(i + 2) >> 6;
                  groupsOfSix[3] = s.charCodeAt(i + 2) & 0x3f;
                }

                for (let j = 0; j < groupsOfSix.length; j++) {
                  if (typeof groupsOfSix[j] === "undefined") {
                    out += "=";
                  } else {
                    out += btoaLookup(groupsOfSix[j]);
                  }
                }
              }

              return out;
            }
            /**
             * Lookup table for btoa(), which converts a six-bit number into the
             * corresponding ASCII character.
             */


            const keystr = "ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/";

            function btoaLookup(index) {
              if (index >= 0 && index < 64) {
                return keystr[index];
              } // Throw INVALID_CHARACTER_ERR exception here -- won't be hit in the tests.


              return undefined;
            }

            var btoa_1 = btoa$2;

            const atob$1 = atob_1;

            const btoa$1 = btoa_1;

            var abab = {
              atob: atob$1,
              btoa: btoa$1
            };

            /*
                This program is distributed under the terms of the MIT license.
                Please see the LICENSE file for details.

                Copyright 2006-2018, OGG, LLC
            */
            /** Function: $build
             *  Create a Strophe.Builder.
             *  This is an alias for 'new Strophe.Builder(name, attrs)'.
             *
             *  Parameters:
             *    (String) name - The root element name.
             *    (Object) attrs - The attributes for the root element in object notation.
             *
             *  Returns:
             *    A new Strophe.Builder object.
             */

            function $build(name, attrs) {
              return new Strophe.Builder(name, attrs);
            }
            /** Function: $msg
             *  Create a Strophe.Builder with a <message/> element as the root.
             *
             *  Parameters:
             *    (Object) attrs - The <message/> element attributes in object notation.
             *
             *  Returns:
             *    A new Strophe.Builder object.
             */

            function $msg(attrs) {
              return new Strophe.Builder("message", attrs);
            }
            /** Function: $iq
             *  Create a Strophe.Builder with an <iq/> element as the root.
             *
             *  Parameters:
             *    (Object) attrs - The <iq/> element attributes in object notation.
             *
             *  Returns:
             *    A new Strophe.Builder object.
             */

            function $iq(attrs) {
              return new Strophe.Builder("iq", attrs);
            }
            /** Function: $pres
             *  Create a Strophe.Builder with a <presence/> element as the root.
             *
             *  Parameters:
             *    (Object) attrs - The <presence/> element attributes in object notation.
             *
             *  Returns:
             *    A new Strophe.Builder object.
             */

            function $pres(attrs) {
              return new Strophe.Builder("presence", attrs);
            }
            /** Class: Strophe
             *  An object container for all Strophe library functions.
             *
             *  This class is just a container for all the objects and constants
             *  used in the library.  It is not meant to be instantiated, but to
             *  provide a namespace for library objects, constants, and functions.
             */

            const Strophe = {
              /** Constant: VERSION */
              VERSION: "1.5.0",

              /** Constants: XMPP Namespace Constants
               *  Common namespace constants from the XMPP RFCs and XEPs.
               *
               *  NS.HTTPBIND - HTTP BIND namespace from XEP 124.
               *  NS.BOSH - BOSH namespace from XEP 206.
               *  NS.CLIENT - Main XMPP client namespace.
               *  NS.AUTH - Legacy authentication namespace.
               *  NS.ROSTER - Roster operations namespace.
               *  NS.PROFILE - Profile namespace.
               *  NS.DISCO_INFO - Service discovery info namespace from XEP 30.
               *  NS.DISCO_ITEMS - Service discovery items namespace from XEP 30.
               *  NS.MUC - Multi-User Chat namespace from XEP 45.
               *  NS.SASL - XMPP SASL namespace from RFC 3920.
               *  NS.STREAM - XMPP Streams namespace from RFC 3920.
               *  NS.BIND - XMPP Binding namespace from RFC 3920 and RFC 6120.
               *  NS.SESSION - XMPP Session namespace from RFC 3920.
               *  NS.XHTML_IM - XHTML-IM namespace from XEP 71.
               *  NS.XHTML - XHTML body namespace from XEP 71.
               */
              NS: {
                HTTPBIND: "http://jabber.org/protocol/httpbind",
                BOSH: "urn:xmpp:xbosh",
                CLIENT: "jabber:client",
                AUTH: "jabber:iq:auth",
                ROSTER: "jabber:iq:roster",
                PROFILE: "jabber:iq:profile",
                DISCO_INFO: "http://jabber.org/protocol/disco#info",
                DISCO_ITEMS: "http://jabber.org/protocol/disco#items",
                MUC: "http://jabber.org/protocol/muc",
                SASL: "urn:ietf:params:xml:ns:xmpp-sasl",
                STREAM: "http://etherx.jabber.org/streams",
                FRAMING: "urn:ietf:params:xml:ns:xmpp-framing",
                BIND: "urn:ietf:params:xml:ns:xmpp-bind",
                SESSION: "urn:ietf:params:xml:ns:xmpp-session",
                VERSION: "jabber:iq:version",
                STANZAS: "urn:ietf:params:xml:ns:xmpp-stanzas",
                XHTML_IM: "http://jabber.org/protocol/xhtml-im",
                XHTML: "http://www.w3.org/1999/xhtml"
              },

              /** Constants: XHTML_IM Namespace
               *  contains allowed tags, tag attributes, and css properties.
               *  Used in the createHtml function to filter incoming html into the allowed XHTML-IM subset.
               *  See http://xmpp.org/extensions/xep-0071.html#profile-summary for the list of recommended
               *  allowed tags and their attributes.
               */
              XHTML: {
                tags: ['a', 'blockquote', 'br', 'cite', 'em', 'img', 'li', 'ol', 'p', 'span', 'strong', 'ul', 'body'],
                attributes: {
                  'a': ['href'],
                  'blockquote': ['style'],
                  'br': [],
                  'cite': ['style'],
                  'em': [],
                  'img': ['src', 'alt', 'style', 'height', 'width'],
                  'li': ['style'],
                  'ol': ['style'],
                  'p': ['style'],
                  'span': ['style'],
                  'strong': [],
                  'ul': ['style'],
                  'body': []
                },
                css: ['background-color', 'color', 'font-family', 'font-size', 'font-style', 'font-weight', 'margin-left', 'margin-right', 'text-align', 'text-decoration'],

                /** Function: XHTML.validTag
                 *
                 * Utility method to determine whether a tag is allowed
                 * in the XHTML_IM namespace.
                 *
                 * XHTML tag names are case sensitive and must be lower case.
                 */
                validTag(tag) {
                  for (let i = 0; i < Strophe.XHTML.tags.length; i++) {
                    if (tag === Strophe.XHTML.tags[i]) {
                      return true;
                    }
                  }

                  return false;
                },

                /** Function: XHTML.validAttribute
                 *
                 * Utility method to determine whether an attribute is allowed
                 * as recommended per XEP-0071
                 *
                 * XHTML attribute names are case sensitive and must be lower case.
                 */
                validAttribute(tag, attribute) {
                  if (typeof Strophe.XHTML.attributes[tag] !== 'undefined' && Strophe.XHTML.attributes[tag].length > 0) {
                    for (let i = 0; i < Strophe.XHTML.attributes[tag].length; i++) {
                      if (attribute === Strophe.XHTML.attributes[tag][i]) {
                        return true;
                      }
                    }
                  }

                  return false;
                },

                validCSS(style) {
                  for (let i = 0; i < Strophe.XHTML.css.length; i++) {
                    if (style === Strophe.XHTML.css[i]) {
                      return true;
                    }
                  }

                  return false;
                }

              },

              /** Constants: Connection Status Constants
               *  Connection status constants for use by the connection handler
               *  callback.
               *
               *  Status.ERROR - An error has occurred
               *  Status.CONNECTING - The connection is currently being made
               *  Status.CONNFAIL - The connection attempt failed
               *  Status.AUTHENTICATING - The connection is authenticating
               *  Status.AUTHFAIL - The authentication attempt failed
               *  Status.CONNECTED - The connection has succeeded
               *  Status.DISCONNECTED - The connection has been terminated
               *  Status.DISCONNECTING - The connection is currently being terminated
               *  Status.ATTACHED - The connection has been attached
               *  Status.REDIRECT - The connection has been redirected
               *  Status.CONNTIMEOUT - The connection has timed out
               */
              Status: {
                ERROR: 0,
                CONNECTING: 1,
                CONNFAIL: 2,
                AUTHENTICATING: 3,
                AUTHFAIL: 4,
                CONNECTED: 5,
                DISCONNECTED: 6,
                DISCONNECTING: 7,
                ATTACHED: 8,
                REDIRECT: 9,
                CONNTIMEOUT: 10,
                BINDREQUIRED: 11,
                ATTACHFAIL: 12
              },
              ErrorCondition: {
                BAD_FORMAT: "bad-format",
                CONFLICT: "conflict",
                MISSING_JID_NODE: "x-strophe-bad-non-anon-jid",
                NO_AUTH_MECH: "no-auth-mech",
                UNKNOWN_REASON: "unknown"
              },

              /** Constants: Log Level Constants
               *  Logging level indicators.
               *
               *  LogLevel.DEBUG - Debug output
               *  LogLevel.INFO - Informational output
               *  LogLevel.WARN - Warnings
               *  LogLevel.ERROR - Errors
               *  LogLevel.FATAL - Fatal errors
               */
              LogLevel: {
                DEBUG: 0,
                INFO: 1,
                WARN: 2,
                ERROR: 3,
                FATAL: 4
              },

              /** PrivateConstants: DOM Element Type Constants
               *  DOM element types.
               *
               *  ElementType.NORMAL - Normal element.
               *  ElementType.TEXT - Text data element.
               *  ElementType.FRAGMENT - XHTML fragment element.
               */
              ElementType: {
                NORMAL: 1,
                TEXT: 3,
                CDATA: 4,
                FRAGMENT: 11
              },

              /** PrivateConstants: Timeout Values
               *  Timeout values for error states.  These values are in seconds.
               *  These should not be changed unless you know exactly what you are
               *  doing.
               *
               *  TIMEOUT - Timeout multiplier. A waiting request will be considered
               *      failed after Math.floor(TIMEOUT * wait) seconds have elapsed.
               *      This defaults to 1.1, and with default wait, 66 seconds.
               *  SECONDARY_TIMEOUT - Secondary timeout multiplier. In cases where
               *      Strophe can detect early failure, it will consider the request
               *      failed if it doesn't return after
               *      Math.floor(SECONDARY_TIMEOUT * wait) seconds have elapsed.
               *      This defaults to 0.1, and with default wait, 6 seconds.
               */
              TIMEOUT: 1.1,
              SECONDARY_TIMEOUT: 0.1,

              /** Function: addNamespace
               *  This function is used to extend the current namespaces in
               *  Strophe.NS.  It takes a key and a value with the key being the
               *  name of the new namespace, with its actual value.
               *  For example:
               *  Strophe.addNamespace('PUBSUB', "http://jabber.org/protocol/pubsub");
               *
               *  Parameters:
               *    (String) name - The name under which the namespace will be
               *      referenced under Strophe.NS
               *    (String) value - The actual namespace.
               */
              addNamespace(name, value) {
                Strophe.NS[name] = value;
              },

              /** Function: forEachChild
               *  Map a function over some or all child elements of a given element.
               *
               *  This is a small convenience function for mapping a function over
               *  some or all of the children of an element.  If elemName is null, all
               *  children will be passed to the function, otherwise only children
               *  whose tag names match elemName will be passed.
               *
               *  Parameters:
               *    (XMLElement) elem - The element to operate on.
               *    (String) elemName - The child element tag name filter.
               *    (Function) func - The function to apply to each child.  This
               *      function should take a single argument, a DOM element.
               */
              forEachChild(elem, elemName, func) {
                for (let i = 0; i < elem.childNodes.length; i++) {
                  const childNode = elem.childNodes[i];

                  if (childNode.nodeType === Strophe.ElementType.NORMAL && (!elemName || this.isTagEqual(childNode, elemName))) {
                    func(childNode);
                  }
                }
              },

              /** Function: isTagEqual
               *  Compare an element's tag name with a string.
               *
               *  This function is case sensitive.
               *
               *  Parameters:
               *    (XMLElement) el - A DOM element.
               *    (String) name - The element name.
               *
               *  Returns:
               *    true if the element's tag name matches _el_, and false
               *    otherwise.
               */
              isTagEqual(el, name) {
                return el.tagName === name;
              },

              /** PrivateVariable: _xmlGenerator
               *  _Private_ variable that caches a DOM document to
               *  generate elements.
               */
              _xmlGenerator: null,

              /** Function: xmlGenerator
               *  Get the DOM document to generate elements.
               *
               *  Returns:
               *    The currently used DOM document.
               */
              xmlGenerator() {
                if (!Strophe._xmlGenerator) {
                  Strophe._xmlGenerator = getDummyXMLDOMDocument();
                }

                return Strophe._xmlGenerator;
              },

              /** Function: xmlElement
               *  Create an XML DOM element.
               *
               *  This function creates an XML DOM element correctly across all
               *  implementations. Note that these are not HTML DOM elements, which
               *  aren't appropriate for XMPP stanzas.
               *
               *  Parameters:
               *    (String) name - The name for the element.
               *    (Array|Object) attrs - An optional array or object containing
               *      key/value pairs to use as element attributes. The object should
               *      be in the format {'key': 'value'} or {key: 'value'}. The array
               *      should have the format [['key1', 'value1'], ['key2', 'value2']].
               *    (String) text - The text child data for the element.
               *
               *  Returns:
               *    A new XML DOM element.
               */
              xmlElement(name) {
                if (!name) {
                  return null;
                }

                const node = Strophe.xmlGenerator().createElement(name); // FIXME: this should throw errors if args are the wrong type or
                // there are more than two optional args

                for (let a = 1; a < arguments.length; a++) {
                  const arg = arguments[a];

                  if (!arg) {
                    continue;
                  }

                  if (typeof arg === "string" || typeof arg === "number") {
                    node.appendChild(Strophe.xmlTextNode(arg));
                  } else if (typeof arg === "object" && typeof arg.sort === "function") {
                    for (let i = 0; i < arg.length; i++) {
                      const attr = arg[i];

                      if (typeof attr === "object" && typeof attr.sort === "function" && attr[1] !== undefined && attr[1] !== null) {
                        node.setAttribute(attr[0], attr[1]);
                      }
                    }
                  } else if (typeof arg === "object") {
                    for (const k in arg) {
                      if (Object.prototype.hasOwnProperty.call(arg, k) && arg[k] !== undefined && arg[k] !== null) {
                        node.setAttribute(k, arg[k]);
                      }
                    }
                  }
                }

                return node;
              },

              /*  Function: xmlescape
               *  Excapes invalid xml characters.
               *
               *  Parameters:
               *     (String) text - text to escape.
               *
               *  Returns:
               *      Escaped text.
               */
              xmlescape(text) {
                text = text.replace(/\&/g, "&amp;");
                text = text.replace(/</g, "&lt;");
                text = text.replace(/>/g, "&gt;");
                text = text.replace(/'/g, "&apos;");
                text = text.replace(/"/g, "&quot;");
                return text;
              },

              /*  Function: xmlunescape
              *  Unexcapes invalid xml characters.
              *
              *  Parameters:
              *     (String) text - text to unescape.
              *
              *  Returns:
              *      Unescaped text.
              */
              xmlunescape(text) {
                text = text.replace(/\&amp;/g, "&");
                text = text.replace(/&lt;/g, "<");
                text = text.replace(/&gt;/g, ">");
                text = text.replace(/&apos;/g, "'");
                text = text.replace(/&quot;/g, "\"");
                return text;
              },

              /** Function: xmlTextNode
               *  Creates an XML DOM text node.
               *
               *  Provides a cross implementation version of document.createTextNode.
               *
               *  Parameters:
               *    (String) text - The content of the text node.
               *
               *  Returns:
               *    A new XML DOM text node.
               */
              xmlTextNode(text) {
                return Strophe.xmlGenerator().createTextNode(text);
              },

              /** Function: xmlHtmlNode
               *  Creates an XML DOM html node.
               *
               *  Parameters:
               *    (String) html - The content of the html node.
               *
               *  Returns:
               *    A new XML DOM text node.
               */
              xmlHtmlNode(html) {
                let node; //ensure text is escaped

                if (DOMParser) {
                  const parser = new DOMParser();
                  node = parser.parseFromString(html, "text/xml");
                } else {
                  node = new ActiveXObject("Microsoft.XMLDOM");
                  node.async = "false";
                  node.loadXML(html);
                }

                return node;
              },

              /** Function: getText
               *  Get the concatenation of all text children of an element.
               *
               *  Parameters:
               *    (XMLElement) elem - A DOM element.
               *
               *  Returns:
               *    A String with the concatenated text of all text element children.
               */
              getText(elem) {
                if (!elem) {
                  return null;
                }

                let str = "";

                if (elem.childNodes.length === 0 && elem.nodeType === Strophe.ElementType.TEXT) {
                  str += elem.nodeValue;
                }

                for (let i = 0; i < elem.childNodes.length; i++) {
                  if (elem.childNodes[i].nodeType === Strophe.ElementType.TEXT) {
                    str += elem.childNodes[i].nodeValue;
                  }
                }

                return Strophe.xmlescape(str);
              },

              /** Function: copyElement
               *  Copy an XML DOM element.
               *
               *  This function copies a DOM element and all its descendants and returns
               *  the new copy.
               *
               *  Parameters:
               *    (XMLElement) elem - A DOM element.
               *
               *  Returns:
               *    A new, copied DOM element tree.
               */
              copyElement(elem) {
                let el;

                if (elem.nodeType === Strophe.ElementType.NORMAL) {
                  el = Strophe.xmlElement(elem.tagName);

                  for (let i = 0; i < elem.attributes.length; i++) {
                    el.setAttribute(elem.attributes[i].nodeName, elem.attributes[i].value);
                  }

                  for (let i = 0; i < elem.childNodes.length; i++) {
                    el.appendChild(Strophe.copyElement(elem.childNodes[i]));
                  }
                } else if (elem.nodeType === Strophe.ElementType.TEXT) {
                  el = Strophe.xmlGenerator().createTextNode(elem.nodeValue);
                }

                return el;
              },

              /** Function: createHtml
               *  Copy an HTML DOM element into an XML DOM.
               *
               *  This function copies a DOM element and all its descendants and returns
               *  the new copy.
               *
               *  Parameters:
               *    (HTMLElement) elem - A DOM element.
               *
               *  Returns:
               *    A new, copied DOM element tree.
               */
              createHtml(elem) {
                let el;

                if (elem.nodeType === Strophe.ElementType.NORMAL) {
                  const tag = elem.nodeName.toLowerCase(); // XHTML tags must be lower case.

                  if (Strophe.XHTML.validTag(tag)) {
                    try {
                      el = Strophe.xmlElement(tag);

                      for (let i = 0; i < Strophe.XHTML.attributes[tag].length; i++) {
                        const attribute = Strophe.XHTML.attributes[tag][i];
                        let value = elem.getAttribute(attribute);

                        if (typeof value === 'undefined' || value === null || value === '' || value === false || value === 0) {
                          continue;
                        }

                        if (attribute === 'style' && typeof value === 'object' && typeof value.cssText !== 'undefined') {
                          value = value.cssText; // we're dealing with IE, need to get CSS out
                        } // filter out invalid css styles


                        if (attribute === 'style') {
                          const css = [];
                          const cssAttrs = value.split(';');

                          for (let j = 0; j < cssAttrs.length; j++) {
                            const attr = cssAttrs[j].split(':');
                            const cssName = attr[0].replace(/^\s*/, "").replace(/\s*$/, "").toLowerCase();

                            if (Strophe.XHTML.validCSS(cssName)) {
                              const cssValue = attr[1].replace(/^\s*/, "").replace(/\s*$/, "");
                              css.push(cssName + ': ' + cssValue);
                            }
                          }

                          if (css.length > 0) {
                            value = css.join('; ');
                            el.setAttribute(attribute, value);
                          }
                        } else {
                          el.setAttribute(attribute, value);
                        }
                      }

                      for (let i = 0; i < elem.childNodes.length; i++) {
                        el.appendChild(Strophe.createHtml(elem.childNodes[i]));
                      }
                    } catch (e) {
                      // invalid elements
                      el = Strophe.xmlTextNode('');
                    }
                  } else {
                    el = Strophe.xmlGenerator().createDocumentFragment();

                    for (let i = 0; i < elem.childNodes.length; i++) {
                      el.appendChild(Strophe.createHtml(elem.childNodes[i]));
                    }
                  }
                } else if (elem.nodeType === Strophe.ElementType.FRAGMENT) {
                  el = Strophe.xmlGenerator().createDocumentFragment();

                  for (let i = 0; i < elem.childNodes.length; i++) {
                    el.appendChild(Strophe.createHtml(elem.childNodes[i]));
                  }
                } else if (elem.nodeType === Strophe.ElementType.TEXT) {
                  el = Strophe.xmlTextNode(elem.nodeValue);
                }

                return el;
              },

              /** Function: escapeNode
               *  Escape the node part (also called local part) of a JID.
               *
               *  Parameters:
               *    (String) node - A node (or local part).
               *
               *  Returns:
               *    An escaped node (or local part).
               */
              escapeNode(node) {
                if (typeof node !== "string") {
                  return node;
                }

                return node.replace(/^\s+|\s+$/g, '').replace(/\\/g, "\\5c").replace(/ /g, "\\20").replace(/\"/g, "\\22").replace(/\&/g, "\\26").replace(/\'/g, "\\27").replace(/\//g, "\\2f").replace(/:/g, "\\3a").replace(/</g, "\\3c").replace(/>/g, "\\3e").replace(/@/g, "\\40");
              },

              /** Function: unescapeNode
               *  Unescape a node part (also called local part) of a JID.
               *
               *  Parameters:
               *    (String) node - A node (or local part).
               *
               *  Returns:
               *    An unescaped node (or local part).
               */
              unescapeNode(node) {
                if (typeof node !== "string") {
                  return node;
                }

                return node.replace(/\\20/g, " ").replace(/\\22/g, '"').replace(/\\26/g, "&").replace(/\\27/g, "'").replace(/\\2f/g, "/").replace(/\\3a/g, ":").replace(/\\3c/g, "<").replace(/\\3e/g, ">").replace(/\\40/g, "@").replace(/\\5c/g, "\\");
              },

              /** Function: getNodeFromJid
               *  Get the node portion of a JID String.
               *
               *  Parameters:
               *    (String) jid - A JID.
               *
               *  Returns:
               *    A String containing the node.
               */
              getNodeFromJid(jid) {
                if (jid.indexOf("@") < 0) {
                  return null;
                }

                return jid.split("@")[0];
              },

              /** Function: getDomainFromJid
               *  Get the domain portion of a JID String.
               *
               *  Parameters:
               *    (String) jid - A JID.
               *
               *  Returns:
               *    A String containing the domain.
               */
              getDomainFromJid(jid) {
                const bare = Strophe.getBareJidFromJid(jid);

                if (bare.indexOf("@") < 0) {
                  return bare;
                } else {
                  const parts = bare.split("@");
                  parts.splice(0, 1);
                  return parts.join('@');
                }
              },

              /** Function: getResourceFromJid
               *  Get the resource portion of a JID String.
               *
               *  Parameters:
               *    (String) jid - A JID.
               *
               *  Returns:
               *    A String containing the resource.
               */
              getResourceFromJid(jid) {
                if (!jid) {
                  return null;
                }

                const s = jid.split("/");

                if (s.length < 2) {
                  return null;
                }

                s.splice(0, 1);
                return s.join('/');
              },

              /** Function: getBareJidFromJid
               *  Get the bare JID from a JID String.
               *
               *  Parameters:
               *    (String) jid - A JID.
               *
               *  Returns:
               *    A String containing the bare JID.
               */
              getBareJidFromJid(jid) {
                return jid ? jid.split("/")[0] : null;
              },

              /** PrivateFunction: _handleError
               *  _Private_ function that properly logs an error to the console
               */
              _handleError(e) {
                if (typeof e.stack !== "undefined") {
                  Strophe.fatal(e.stack);
                }

                if (e.sourceURL) {
                  Strophe.fatal("error: " + this.handler + " " + e.sourceURL + ":" + e.line + " - " + e.name + ": " + e.message);
                } else if (e.fileName) {
                  Strophe.fatal("error: " + this.handler + " " + e.fileName + ":" + e.lineNumber + " - " + e.name + ": " + e.message);
                } else {
                  Strophe.fatal("error: " + e.message);
                }
              },

              /** Function: log
               *  User overrideable logging function.
               *
               *  This function is called whenever the Strophe library calls any
               *  of the logging functions.  The default implementation of this
               *  function logs only fatal errors.  If client code wishes to handle the logging
               *  messages, it should override this with
               *  > Strophe.log = function (level, msg) {
               *  >   (user code here)
               *  > };
               *
               *  Please note that data sent and received over the wire is logged
               *  via Strophe.Connection.rawInput() and Strophe.Connection.rawOutput().
               *
               *  The different levels and their meanings are
               *
               *    DEBUG - Messages useful for debugging purposes.
               *    INFO - Informational messages.  This is mostly information like
               *      'disconnect was called' or 'SASL auth succeeded'.
               *    WARN - Warnings about potential problems.  This is mostly used
               *      to report transient connection errors like request timeouts.
               *    ERROR - Some error occurred.
               *    FATAL - A non-recoverable fatal error occurred.
               *
               *  Parameters:
               *    (Integer) level - The log level of the log message.  This will
               *      be one of the values in Strophe.LogLevel.
               *    (String) msg - The log message.
               */
              log(level, msg) {
                if (level === this.LogLevel.FATAL) {
                  var _console;

                  (_console = console) === null || _console === void 0 ? void 0 : _console.error(msg);
                }
              },

              /** Function: debug
               *  Log a message at the Strophe.LogLevel.DEBUG level.
               *
               *  Parameters:
               *    (String) msg - The log message.
               */
              debug(msg) {
                this.log(this.LogLevel.DEBUG, msg);
              },

              /** Function: info
               *  Log a message at the Strophe.LogLevel.INFO level.
               *
               *  Parameters:
               *    (String) msg - The log message.
               */
              info(msg) {
                this.log(this.LogLevel.INFO, msg);
              },

              /** Function: warn
               *  Log a message at the Strophe.LogLevel.WARN level.
               *
               *  Parameters:
               *    (String) msg - The log message.
               */
              warn(msg) {
                this.log(this.LogLevel.WARN, msg);
              },

              /** Function: error
               *  Log a message at the Strophe.LogLevel.ERROR level.
               *
               *  Parameters:
               *    (String) msg - The log message.
               */
              error(msg) {
                this.log(this.LogLevel.ERROR, msg);
              },

              /** Function: fatal
               *  Log a message at the Strophe.LogLevel.FATAL level.
               *
               *  Parameters:
               *    (String) msg - The log message.
               */
              fatal(msg) {
                this.log(this.LogLevel.FATAL, msg);
              },

              /** Function: serialize
               *  Render a DOM element and all descendants to a String.
               *
               *  Parameters:
               *    (XMLElement) elem - A DOM element.
               *
               *  Returns:
               *    The serialized element tree as a String.
               */
              serialize(elem) {
                if (!elem) {
                  return null;
                }

                if (typeof elem.tree === "function") {
                  elem = elem.tree();
                }

                const names = [...Array(elem.attributes.length).keys()].map(i => elem.attributes[i].nodeName);
                names.sort();
                let result = names.reduce((a, n) => `${a} ${n}="${Strophe.xmlescape(elem.attributes.getNamedItem(n).value)}"`, `<${elem.nodeName}`);

                if (elem.childNodes.length > 0) {
                  result += ">";

                  for (let i = 0; i < elem.childNodes.length; i++) {
                    const child = elem.childNodes[i];

                    switch (child.nodeType) {
                      case Strophe.ElementType.NORMAL:
                        // normal element, so recurse
                        result += Strophe.serialize(child);
                        break;

                      case Strophe.ElementType.TEXT:
                        // text element to escape values
                        result += Strophe.xmlescape(child.nodeValue);
                        break;

                      case Strophe.ElementType.CDATA:
                        // cdata section so don't escape values
                        result += "<![CDATA[" + child.nodeValue + "]]>";
                    }
                  }

                  result += "</" + elem.nodeName + ">";
                } else {
                  result += "/>";
                }

                return result;
              },

              /** PrivateVariable: _requestId
               *  _Private_ variable that keeps track of the request ids for
               *  connections.
               */
              _requestId: 0,

              /** PrivateVariable: Strophe.connectionPlugins
               *  _Private_ variable Used to store plugin names that need
               *  initialization on Strophe.Connection construction.
               */
              _connectionPlugins: {},

              /** Function: addConnectionPlugin
               *  Extends the Strophe.Connection object with the given plugin.
               *
               *  Parameters:
               *    (String) name - The name of the extension.
               *    (Object) ptype - The plugin's prototype.
               */
              addConnectionPlugin(name, ptype) {
                Strophe._connectionPlugins[name] = ptype;
              }

            };
            /** Class: Strophe.Builder
             *  XML DOM builder.
             *
             *  This object provides an interface similar to JQuery but for building
             *  DOM elements easily and rapidly.  All the functions except for toString()
             *  and tree() return the object, so calls can be chained.  Here's an
             *  example using the $iq() builder helper.
             *  > $iq({to: 'you', from: 'me', type: 'get', id: '1'})
             *  >     .c('query', {xmlns: 'strophe:example'})
             *  >     .c('example')
             *  >     .toString()
             *
             *  The above generates this XML fragment
             *  > <iq to='you' from='me' type='get' id='1'>
             *  >   <query xmlns='strophe:example'>
             *  >     <example/>
             *  >   </query>
             *  > </iq>
             *  The corresponding DOM manipulations to get a similar fragment would be
             *  a lot more tedious and probably involve several helper variables.
             *
             *  Since adding children makes new operations operate on the child, up()
             *  is provided to traverse up the tree.  To add two children, do
             *  > builder.c('child1', ...).up().c('child2', ...)
             *  The next operation on the Builder will be relative to the second child.
             */

            /** Constructor: Strophe.Builder
             *  Create a Strophe.Builder object.
             *
             *  The attributes should be passed in object notation.  For example
             *  > let b = new Builder('message', {to: 'you', from: 'me'});
             *  or
             *  > let b = new Builder('messsage', {'xml:lang': 'en'});
             *
             *  Parameters:
             *    (String) name - The name of the root element.
             *    (Object) attrs - The attributes for the root element in object notation.
             *
             *  Returns:
             *    A new Strophe.Builder.
             */

            Strophe.Builder = class Builder {
              constructor(name, attrs) {
                // Set correct namespace for jabber:client elements
                if (name === "presence" || name === "message" || name === "iq") {
                  if (attrs && !attrs.xmlns) {
                    attrs.xmlns = Strophe.NS.CLIENT;
                  } else if (!attrs) {
                    attrs = {
                      xmlns: Strophe.NS.CLIENT
                    };
                  }
                } // Holds the tree being built.


                this.nodeTree = Strophe.xmlElement(name, attrs); // Points to the current operation node.

                this.node = this.nodeTree;
              }
              /** Function: tree
               *  Return the DOM tree.
               *
               *  This function returns the current DOM tree as an element object.  This
               *  is suitable for passing to functions like Strophe.Connection.send().
               *
               *  Returns:
               *    The DOM tree as a element object.
               */


              tree() {
                return this.nodeTree;
              }
              /** Function: toString
               *  Serialize the DOM tree to a String.
               *
               *  This function returns a string serialization of the current DOM
               *  tree.  It is often used internally to pass data to a
               *  Strophe.Request object.
               *
               *  Returns:
               *    The serialized DOM tree in a String.
               */


              toString() {
                return Strophe.serialize(this.nodeTree);
              }
              /** Function: up
               *  Make the current parent element the new current element.
               *
               *  This function is often used after c() to traverse back up the tree.
               *  For example, to add two children to the same element
               *  > builder.c('child1', {}).up().c('child2', {});
               *
               *  Returns:
               *    The Stophe.Builder object.
               */


              up() {
                this.node = this.node.parentNode;
                return this;
              }
              /** Function: root
               *  Make the root element the new current element.
               *
               *  When at a deeply nested element in the tree, this function can be used
               *  to jump back to the root of the tree, instead of having to repeatedly
               *  call up().
               *
               *  Returns:
               *    The Stophe.Builder object.
               */


              root() {
                this.node = this.nodeTree;
                return this;
              }
              /** Function: attrs
               *  Add or modify attributes of the current element.
               *
               *  The attributes should be passed in object notation.  This function
               *  does not move the current element pointer.
               *
               *  Parameters:
               *    (Object) moreattrs - The attributes to add/modify in object notation.
               *
               *  Returns:
               *    The Strophe.Builder object.
               */


              attrs(moreattrs) {
                for (const k in moreattrs) {
                  if (Object.prototype.hasOwnProperty.call(moreattrs, k)) {
                    if (moreattrs[k] === undefined) {
                      this.node.removeAttribute(k);
                    } else {
                      this.node.setAttribute(k, moreattrs[k]);
                    }
                  }
                }

                return this;
              }
              /** Function: c
               *  Add a child to the current element and make it the new current
               *  element.
               *
               *  This function moves the current element pointer to the child,
               *  unless text is provided.  If you need to add another child, it
               *  is necessary to use up() to go back to the parent in the tree.
               *
               *  Parameters:
               *    (String) name - The name of the child.
               *    (Object) attrs - The attributes of the child in object notation.
               *    (String) text - The text to add to the child.
               *
               *  Returns:
               *    The Strophe.Builder object.
               */


              c(name, attrs, text) {
                const child = Strophe.xmlElement(name, attrs, text);
                this.node.appendChild(child);

                if (typeof text !== "string" && typeof text !== "number") {
                  this.node = child;
                }

                return this;
              }
              /** Function: cnode
               *  Add a child to the current element and make it the new current
               *  element.
               *
               *  This function is the same as c() except that instead of using a
               *  name and an attributes object to create the child it uses an
               *  existing DOM element object.
               *
               *  Parameters:
               *    (XMLElement) elem - A DOM element.
               *
               *  Returns:
               *    The Strophe.Builder object.
               */


              cnode(elem) {
                let impNode;
                const xmlGen = Strophe.xmlGenerator();

                try {
                  impNode = xmlGen.importNode !== undefined;
                } catch (e) {
                  impNode = false;
                }

                const newElem = impNode ? xmlGen.importNode(elem, true) : Strophe.copyElement(elem);
                this.node.appendChild(newElem);
                this.node = newElem;
                return this;
              }
              /** Function: t
               *  Add a child text element.
               *
               *  This *does not* make the child the new current element since there
               *  are no children of text elements.
               *
               *  Parameters:
               *    (String) text - The text data to append to the current element.
               *
               *  Returns:
               *    The Strophe.Builder object.
               */


              t(text) {
                const child = Strophe.xmlTextNode(text);
                this.node.appendChild(child);
                return this;
              }
              /** Function: h
               *  Replace current element contents with the HTML passed in.
               *
               *  This *does not* make the child the new current element
               *
               *  Parameters:
               *    (String) html - The html to insert as contents of current element.
               *
               *  Returns:
               *    The Strophe.Builder object.
               */


              h(html) {
                const fragment = Strophe.xmlGenerator().createElement('body'); // force the browser to try and fix any invalid HTML tags

                fragment.innerHTML = html; // copy cleaned html into an xml dom

                const xhtml = Strophe.createHtml(fragment);

                while (xhtml.childNodes.length > 0) {
                  this.node.appendChild(xhtml.childNodes[0]);
                }

                return this;
              }

            };
            /** PrivateClass: Strophe.Handler
             *  _Private_ helper class for managing stanza handlers.
             *
             *  A Strophe.Handler encapsulates a user provided callback function to be
             *  executed when matching stanzas are received by the connection.
             *  Handlers can be either one-off or persistant depending on their
             *  return value. Returning true will cause a Handler to remain active, and
             *  returning false will remove the Handler.
             *
             *  Users will not use Strophe.Handler objects directly, but instead they
             *  will use Strophe.Connection.addHandler() and
             *  Strophe.Connection.deleteHandler().
             */

            /** PrivateConstructor: Strophe.Handler
             *  Create and initialize a new Strophe.Handler.
             *
             *  Parameters:
             *    (Function) handler - A function to be executed when the handler is run.
             *    (String) ns - The namespace to match.
             *    (String) name - The element name to match.
             *    (String) type - The element type to match.
             *    (String) id - The element id attribute to match.
             *    (String) from - The element from attribute to match.
             *    (Object) options - Handler options
             *
             *  Returns:
             *    A new Strophe.Handler object.
             */

            Strophe.Handler = function (handler, ns, name, type, id, from, options) {
              this.handler = handler;
              this.ns = ns;
              this.name = name;
              this.type = type;
              this.id = id;
              this.options = options || {
                'matchBareFromJid': false,
                'ignoreNamespaceFragment': false
              }; // BBB: Maintain backward compatibility with old `matchBare` option

              if (this.options.matchBare) {
                Strophe.warn('The "matchBare" option is deprecated, use "matchBareFromJid" instead.');
                this.options.matchBareFromJid = this.options.matchBare;
                delete this.options.matchBare;
              }

              if (this.options.matchBareFromJid) {
                this.from = from ? Strophe.getBareJidFromJid(from) : null;
              } else {
                this.from = from;
              } // whether the handler is a user handler or a system handler


              this.user = true;
            };

            Strophe.Handler.prototype = {
              /** PrivateFunction: getNamespace
               *  Returns the XML namespace attribute on an element.
               *  If `ignoreNamespaceFragment` was passed in for this handler, then the
               *  URL fragment will be stripped.
               *
               *  Parameters:
               *    (XMLElement) elem - The XML element with the namespace.
               *
               *  Returns:
               *    The namespace, with optionally the fragment stripped.
               */
              getNamespace(elem) {
                let elNamespace = elem.getAttribute("xmlns");

                if (elNamespace && this.options.ignoreNamespaceFragment) {
                  elNamespace = elNamespace.split('#')[0];
                }

                return elNamespace;
              },

              /** PrivateFunction: namespaceMatch
               *  Tests if a stanza matches the namespace set for this Strophe.Handler.
               *
               *  Parameters:
               *    (XMLElement) elem - The XML element to test.
               *
               *  Returns:
               *    true if the stanza matches and false otherwise.
               */
              namespaceMatch(elem) {
                let nsMatch = false;

                if (!this.ns) {
                  return true;
                } else {
                  Strophe.forEachChild(elem, null, elem => {
                    if (this.getNamespace(elem) === this.ns) {
                      nsMatch = true;
                    }
                  });
                  return nsMatch || this.getNamespace(elem) === this.ns;
                }
              },

              /** PrivateFunction: isMatch
               *  Tests if a stanza matches the Strophe.Handler.
               *
               *  Parameters:
               *    (XMLElement) elem - The XML element to test.
               *
               *  Returns:
               *    true if the stanza matches and false otherwise.
               */
              isMatch(elem) {
                let from = elem.getAttribute('from');

                if (this.options.matchBareFromJid) {
                  from = Strophe.getBareJidFromJid(from);
                }

                const elem_type = elem.getAttribute("type");

                if (this.namespaceMatch(elem) && (!this.name || Strophe.isTagEqual(elem, this.name)) && (!this.type || (Array.isArray(this.type) ? this.type.indexOf(elem_type) !== -1 : elem_type === this.type)) && (!this.id || elem.getAttribute("id") === this.id) && (!this.from || from === this.from)) {
                  return true;
                }

                return false;
              },

              /** PrivateFunction: run
               *  Run the callback on a matching stanza.
               *
               *  Parameters:
               *    (XMLElement) elem - The DOM element that triggered the
               *      Strophe.Handler.
               *
               *  Returns:
               *    A boolean indicating if the handler should remain active.
               */
              run(elem) {
                let result = null;

                try {
                  result = this.handler(elem);
                } catch (e) {
                  Strophe._handleError(e);

                  throw e;
                }

                return result;
              },

              /** PrivateFunction: toString
               *  Get a String representation of the Strophe.Handler object.
               *
               *  Returns:
               *    A String.
               */
              toString() {
                return "{Handler: " + this.handler + "(" + this.name + "," + this.id + "," + this.ns + ")}";
              }

            };
            /** PrivateClass: Strophe.TimedHandler
             *  _Private_ helper class for managing timed handlers.
             *
             *  A Strophe.TimedHandler encapsulates a user provided callback that
             *  should be called after a certain period of time or at regular
             *  intervals.  The return value of the callback determines whether the
             *  Strophe.TimedHandler will continue to fire.
             *
             *  Users will not use Strophe.TimedHandler objects directly, but instead
             *  they will use Strophe.Connection.addTimedHandler() and
             *  Strophe.Connection.deleteTimedHandler().
             */

            Strophe.TimedHandler = class TimedHandler {
              /** PrivateConstructor: Strophe.TimedHandler
               *  Create and initialize a new Strophe.TimedHandler object.
               *
               *  Parameters:
               *    (Integer) period - The number of milliseconds to wait before the
               *      handler is called.
               *    (Function) handler - The callback to run when the handler fires.  This
               *      function should take no arguments.
               *
               *  Returns:
               *    A new Strophe.TimedHandler object.
               */
              constructor(period, handler) {
                this.period = period;
                this.handler = handler;
                this.lastCalled = new Date().getTime();
                this.user = true;
              }
              /** PrivateFunction: run
               *  Run the callback for the Strophe.TimedHandler.
               *
               *  Returns:
               *    true if the Strophe.TimedHandler should be called again, and false
               *      otherwise.
               */


              run() {
                this.lastCalled = new Date().getTime();
                return this.handler();
              }
              /** PrivateFunction: reset
               *  Reset the last called time for the Strophe.TimedHandler.
               */


              reset() {
                this.lastCalled = new Date().getTime();
              }
              /** PrivateFunction: toString
               *  Get a string representation of the Strophe.TimedHandler object.
               *
               *  Returns:
               *    The string representation.
               */


              toString() {
                return "{TimedHandler: " + this.handler + "(" + this.period + ")}";
              }

            };
            /** Class: Strophe.Connection
             *  XMPP Connection manager.
             *
             *  This class is the main part of Strophe.  It manages a BOSH or websocket
             *  connection to an XMPP server and dispatches events to the user callbacks
             *  as data arrives. It supports SASL PLAIN, SASL SCRAM-SHA-1
             *  and legacy authentication.
             *
             *  After creating a Strophe.Connection object, the user will typically
             *  call connect() with a user supplied callback to handle connection level
             *  events like authentication failure, disconnection, or connection
             *  complete.
             *
             *  The user will also have several event handlers defined by using
             *  addHandler() and addTimedHandler().  These will allow the user code to
             *  respond to interesting stanzas or do something periodically with the
             *  connection. These handlers will be active once authentication is
             *  finished.
             *
             *  To send data to the connection, use send().
             */

            /** Constructor: Strophe.Connection
             *  Create and initialize a Strophe.Connection object.
             *
             *  The transport-protocol for this connection will be chosen automatically
             *  based on the given service parameter. URLs starting with "ws://" or
             *  "wss://" will use WebSockets, URLs starting with "http://", "https://"
             *  or without a protocol will use BOSH.
             *
             *  To make Strophe connect to the current host you can leave out the protocol
             *  and host part and just pass the path, e.g.
             *
             *  > let conn = new Strophe.Connection("/http-bind/");
             *
             *  Options common to both Websocket and BOSH:
             *  ------------------------------------------
             *
             *  cookies:
             *
             *  The *cookies* option allows you to pass in cookies to be added to the
             *  document. These cookies will then be included in the BOSH XMLHttpRequest
             *  or in the websocket connection.
             *
             *  The passed in value must be a map of cookie names and string values.
             *
             *  > { "myCookie": {
             *  >     "value": "1234",
             *  >     "domain": ".example.org",
             *  >     "path": "/",
             *  >     "expires": expirationDate
             *  >     }
             *  > }
             *
             *  Note that cookies can't be set in this way for other domains (i.e. cross-domain).
             *  Those cookies need to be set under those domains, for example they can be
             *  set server-side by making a XHR call to that domain to ask it to set any
             *  necessary cookies.
             *
             *  mechanisms:
             *
             *  The *mechanisms* option allows you to specify the SASL mechanisms that this
             *  instance of Strophe.Connection (and therefore your XMPP client) will
             *  support.
             *
             *  The value must be an array of objects with Strophe.SASLMechanism
             *  prototypes.
             *
             *  If nothing is specified, then the following mechanisms (and their
             *  priorities) are registered:
             *
             *      SCRAM-SHA-1 - 60
             *      PLAIN       - 50
             *      OAUTHBEARER - 40
             *      X-OAUTH2    - 30
             *      ANONYMOUS   - 20
             *      EXTERNAL    - 10
             *
             *  explicitResourceBinding:
             *
             *  If `explicitResourceBinding` is set to a truthy value, then the XMPP client
             *  needs to explicitly call `Strophe.Connection.prototype.bind` once the XMPP
             *  server has advertised the "urn:ietf:params:xml:ns:xmpp-bind" feature.
             *
             *  Making this step explicit allows client authors to first finish other
             *  stream related tasks, such as setting up an XEP-0198 Stream Management
             *  session, before binding the JID resource for this session.
             *
             *  WebSocket options:
             *  ------------------
             *
             *  protocol:
             *
             *  If you want to connect to the current host with a WebSocket connection you
             *  can tell Strophe to use WebSockets through a "protocol" attribute in the
             *  optional options parameter. Valid values are "ws" for WebSocket and "wss"
             *  for Secure WebSocket.
             *  So to connect to "wss://CURRENT_HOSTNAME/xmpp-websocket" you would call
             *
             *  > let conn = new Strophe.Connection("/xmpp-websocket/", {protocol: "wss"});
             *
             *  Note that relative URLs _NOT_ starting with a "/" will also include the path
             *  of the current site.
             *
             *  Also because downgrading security is not permitted by browsers, when using
             *  relative URLs both BOSH and WebSocket connections will use their secure
             *  variants if the current connection to the site is also secure (https).
             *
             *  worker:
             *
             *  Set this option to URL from where the shared worker script should be loaded.
             *
             *  To run the websocket connection inside a shared worker.
             *  This allows you to share a single websocket-based connection between
             *  multiple Strophe.Connection instances, for example one per browser tab.
             *
             *  The script to use is the one in `src/shared-connection-worker.js`.
             *
             *  BOSH options:
             *  -------------
             *
             *  By adding "sync" to the options, you can control if requests will
             *  be made synchronously or not. The default behaviour is asynchronous.
             *  If you want to make requests synchronous, make "sync" evaluate to true.
             *  > let conn = new Strophe.Connection("/http-bind/", {sync: true});
             *
             *  You can also toggle this on an already established connection.
             *  > conn.options.sync = true;
             *
             *  The *customHeaders* option can be used to provide custom HTTP headers to be
             *  included in the XMLHttpRequests made.
             *
             *  The *keepalive* option can be used to instruct Strophe to maintain the
             *  current BOSH session across interruptions such as webpage reloads.
             *
             *  It will do this by caching the sessions tokens in sessionStorage, and when
             *  "restore" is called it will check whether there are cached tokens with
             *  which it can resume an existing session.
             *
             *  The *withCredentials* option should receive a Boolean value and is used to
             *  indicate wether cookies should be included in ajax requests (by default
             *  they're not).
             *  Set this value to true if you are connecting to a BOSH service
             *  and for some reason need to send cookies to it.
             *  In order for this to work cross-domain, the server must also enable
             *  credentials by setting the Access-Control-Allow-Credentials response header
             *  to "true". For most usecases however this setting should be false (which
             *  is the default).
             *  Additionally, when using Access-Control-Allow-Credentials, the
             *  Access-Control-Allow-Origin header can't be set to the wildcard "*", but
             *  instead must be restricted to actual domains.
             *
             *  The *contentType* option can be set to change the default Content-Type
             *  of "text/xml; charset=utf-8", which can be useful to reduce the amount of
             *  CORS preflight requests that are sent to the server.
             *
             *  Parameters:
             *    (String) service - The BOSH or WebSocket service URL.
             *    (Object) options - A hash of configuration options
             *
             *  Returns:
             *    A new Strophe.Connection object.
             */

            Strophe.Connection = class Connection {
              constructor(service, options) {
                // The service URL
                this.service = service; // Configuration options

                this.options = options || {};
                this.setProtocol();
                /* The connected JID. */

                this.jid = "";
                /* the JIDs domain */

                this.domain = null;
                /* stream:features */

                this.features = null; // SASL

                this._sasl_data = {};
                this.do_bind = false;
                this.do_session = false;
                this.mechanisms = {}; // handler lists

                this.timedHandlers = [];
                this.handlers = [];
                this.removeTimeds = [];
                this.removeHandlers = [];
                this.addTimeds = [];
                this.addHandlers = [];
                this.protocolErrorHandlers = {
                  'HTTP': {},
                  'websocket': {}
                };
                this._idleTimeout = null;
                this._disconnectTimeout = null;
                this.authenticated = false;
                this.connected = false;
                this.disconnecting = false;
                this.do_authentication = true;
                this.paused = false;
                this.restored = false;
                this._data = [];
                this._uniqueId = 0;
                this._sasl_success_handler = null;
                this._sasl_failure_handler = null;
                this._sasl_challenge_handler = null; // Max retries before disconnecting

                this.maxRetries = 5; // Call onIdle callback every 1/10th of a second

                this._idleTimeout = setTimeout(() => this._onIdle(), 100);
                utils.addCookies(this.options.cookies);
                this.registerSASLMechanisms(this.options.mechanisms); // A client must always respond to incoming IQ "set" and "get" stanzas.
                // See https://datatracker.ietf.org/doc/html/rfc6120#section-8.2.3
                //
                // This is a fallback handler which gets called when no other handler
                // was called for a received IQ "set" or "get".

                this.iqFallbackHandler = new Strophe.Handler(iq => this.send($iq({
                  type: 'error',
                  id: iq.getAttribute('id')
                }).c('error', {
                  'type': 'cancel'
                }).c('service-unavailable', {
                  'xmlns': Strophe.NS.STANZAS
                })), null, 'iq', ['get', 'set']); // initialize plugins

                for (const k in Strophe._connectionPlugins) {
                  if (Object.prototype.hasOwnProperty.call(Strophe._connectionPlugins, k)) {
                    const F = function () {};

                    F.prototype = Strophe._connectionPlugins[k];
                    this[k] = new F();
                    this[k].init(this);
                  }
                }
              }
              /** Function: setProtocol
               *  Select protocal based on this.options or this.service
               */


              setProtocol() {
                const proto = this.options.protocol || "";

                if (this.options.worker) {
                  this._proto = new Strophe.WorkerWebsocket(this);
                } else if (this.service.indexOf("ws:") === 0 || this.service.indexOf("wss:") === 0 || proto.indexOf("ws") === 0) {
                  this._proto = new Strophe.Websocket(this);
                } else {
                  this._proto = new Strophe.Bosh(this);
                }
              }
              /** Function: reset
               *  Reset the connection.
               *
               *  This function should be called after a connection is disconnected
               *  before that connection is reused.
               */


              reset() {
                this._proto._reset(); // SASL


                this.do_session = false;
                this.do_bind = false; // handler lists

                this.timedHandlers = [];
                this.handlers = [];
                this.removeTimeds = [];
                this.removeHandlers = [];
                this.addTimeds = [];
                this.addHandlers = [];
                this.authenticated = false;
                this.connected = false;
                this.disconnecting = false;
                this.restored = false;
                this._data = [];
                this._requests = [];
                this._uniqueId = 0;
              }
              /** Function: pause
               *  Pause the request manager.
               *
               *  This will prevent Strophe from sending any more requests to the
               *  server.  This is very useful for temporarily pausing
               *  BOSH-Connections while a lot of send() calls are happening quickly.
               *  This causes Strophe to send the data in a single request, saving
               *  many request trips.
               */


              pause() {
                this.paused = true;
              }
              /** Function: resume
               *  Resume the request manager.
               *
               *  This resumes after pause() has been called.
               */


              resume() {
                this.paused = false;
              }
              /** Function: getUniqueId
               *  Generate a unique ID for use in <iq/> elements.
               *
               *  All <iq/> stanzas are required to have unique id attributes.  This
               *  function makes creating these easy.  Each connection instance has
               *  a counter which starts from zero, and the value of this counter
               *  plus a colon followed by the suffix becomes the unique id. If no
               *  suffix is supplied, the counter is used as the unique id.
               *
               *  Suffixes are used to make debugging easier when reading the stream
               *  data, and their use is recommended.  The counter resets to 0 for
               *  every new connection for the same reason.  For connections to the
               *  same server that authenticate the same way, all the ids should be
               *  the same, which makes it easy to see changes.  This is useful for
               *  automated testing as well.
               *
               *  Parameters:
               *    (String) suffix - A optional suffix to append to the id.
               *
               *  Returns:
               *    A unique string to be used for the id attribute.
               */


              getUniqueId(suffix) {
                // eslint-disable-line class-methods-use-this
                const uuid = 'xxxxxxxx-xxxx-4xxx-yxxx-xxxxxxxxxxxx'.replace(/[xy]/g, function (c) {
                  const r = Math.random() * 16 | 0,
                        v = c === 'x' ? r : r & 0x3 | 0x8;
                  return v.toString(16);
                });

                if (typeof suffix === "string" || typeof suffix === "number") {
                  return uuid + ":" + suffix;
                } else {
                  return uuid + "";
                }
              }
              /** Function: addProtocolErrorHandler
               *  Register a handler function for when a protocol (websocker or HTTP)
               *  error occurs.
               *
               *  NOTE: Currently only HTTP errors for BOSH requests are handled.
               *  Patches that handle websocket errors would be very welcome.
               *
               *  Parameters:
               *    (String) protocol - 'HTTP' or 'websocket'
               *    (Integer) status_code - Error status code (e.g 500, 400 or 404)
               *    (Function) callback - Function that will fire on Http error
               *
               *  Example:
               *  function onError(err_code){
               *    //do stuff
               *  }
               *
               *  let conn = Strophe.connect('http://example.com/http-bind');
               *  conn.addProtocolErrorHandler('HTTP', 500, onError);
               *  // Triggers HTTP 500 error and onError handler will be called
               *  conn.connect('user_jid@incorrect_jabber_host', 'secret', onConnect);
               */


              addProtocolErrorHandler(protocol, status_code, callback) {
                this.protocolErrorHandlers[protocol][status_code] = callback;
              }
              /** Function: connect
               *  Starts the connection process.
               *
               *  As the connection process proceeds, the user supplied callback will
               *  be triggered multiple times with status updates.  The callback
               *  should take two arguments - the status code and the error condition.
               *
               *  The status code will be one of the values in the Strophe.Status
               *  constants.  The error condition will be one of the conditions
               *  defined in RFC 3920 or the condition 'strophe-parsererror'.
               *
               *  The Parameters _wait_, _hold_ and _route_ are optional and only relevant
               *  for BOSH connections. Please see XEP 124 for a more detailed explanation
               *  of the optional parameters.
               *
               *  Parameters:
               *    (String) jid - The user's JID.  This may be a bare JID,
               *      or a full JID.  If a node is not supplied, SASL OAUTHBEARER or
               *      SASL ANONYMOUS authentication will be attempted (OAUTHBEARER will
               *      process the provided password value as an access token).
               *    (String) pass - The user's password.
               *    (Function) callback - The connect callback function.
               *    (Integer) wait - The optional HTTPBIND wait value.  This is the
               *      time the server will wait before returning an empty result for
               *      a request.  The default setting of 60 seconds is recommended.
               *    (Integer) hold - The optional HTTPBIND hold value.  This is the
               *      number of connections the server will hold at one time.  This
               *      should almost always be set to 1 (the default).
               *    (String) route - The optional route value.
               *    (String) authcid - The optional alternative authentication identity
               *      (username) if intending to impersonate another user.
               *      When using the SASL-EXTERNAL authentication mechanism, for example
               *      with client certificates, then the authcid value is used to
               *      determine whether an authorization JID (authzid) should be sent to
               *      the server. The authzid should NOT be sent to the server if the
               *      authzid and authcid are the same. So to prevent it from being sent
               *      (for example when the JID is already contained in the client
               *      certificate), set authcid to that same JID. See XEP-178 for more
               *      details.
               *     (Integer) disconnection_timeout - The optional disconnection timeout
               *      in milliseconds before _doDisconnect will be called.
               */


              connect(jid, pass, callback, wait, hold, route, authcid) {
                let disconnection_timeout = arguments.length > 7 && arguments[7] !== undefined ? arguments[7] : 3000;
                this.jid = jid;
                /** Variable: authzid
                 *  Authorization identity.
                 */

                this.authzid = Strophe.getBareJidFromJid(this.jid);
                /** Variable: authcid
                 *  Authentication identity (User name).
                 */

                this.authcid = authcid || Strophe.getNodeFromJid(this.jid);
                /** Variable: pass
                 *  Authentication identity (User password).
                 */

                this.pass = pass;
                this.connect_callback = callback;
                this.disconnecting = false;
                this.connected = false;
                this.authenticated = false;
                this.restored = false;
                this.disconnection_timeout = disconnection_timeout; // parse jid for domain

                this.domain = Strophe.getDomainFromJid(this.jid);

                this._changeConnectStatus(Strophe.Status.CONNECTING, null);

                this._proto._connect(wait, hold, route);
              }
              /** Function: attach
               *  Attach to an already created and authenticated BOSH session.
               *
               *  This function is provided to allow Strophe to attach to BOSH
               *  sessions which have been created externally, perhaps by a Web
               *  application.  This is often used to support auto-login type features
               *  without putting user credentials into the page.
               *
               *  Parameters:
               *    (String) jid - The full JID that is bound by the session.
               *    (String) sid - The SID of the BOSH session.
               *    (String) rid - The current RID of the BOSH session.  This RID
               *      will be used by the next request.
               *    (Function) callback The connect callback function.
               *    (Integer) wait - The optional HTTPBIND wait value.  This is the
               *      time the server will wait before returning an empty result for
               *      a request.  The default setting of 60 seconds is recommended.
               *      Other settings will require tweaks to the Strophe.TIMEOUT value.
               *    (Integer) hold - The optional HTTPBIND hold value.  This is the
               *      number of connections the server will hold at one time.  This
               *      should almost always be set to 1 (the default).
               *    (Integer) wind - The optional HTTBIND window value.  This is the
               *      allowed range of request ids that are valid.  The default is 5.
               */


              attach(jid, sid, rid, callback, wait, hold, wind) {
                if (this._proto._attach) {
                  return this._proto._attach(jid, sid, rid, callback, wait, hold, wind);
                } else {
                  const error = new Error('The "attach" method is not available for your connection protocol');
                  error.name = 'StropheSessionError';
                  throw error;
                }
              }
              /** Function: restore
               *  Attempt to restore a cached BOSH session.
               *
               *  This function is only useful in conjunction with providing the
               *  "keepalive":true option when instantiating a new Strophe.Connection.
               *
               *  When "keepalive" is set to true, Strophe will cache the BOSH tokens
               *  RID (Request ID) and SID (Session ID) and then when this function is
               *  called, it will attempt to restore the session from those cached
               *  tokens.
               *
               *  This function must therefore be called instead of connect or attach.
               *
               *  For an example on how to use it, please see examples/restore.js
               *
               *  Parameters:
               *    (String) jid - The user's JID.  This may be a bare JID or a full JID.
               *    (Function) callback - The connect callback function.
               *    (Integer) wait - The optional HTTPBIND wait value.  This is the
               *      time the server will wait before returning an empty result for
               *      a request.  The default setting of 60 seconds is recommended.
               *    (Integer) hold - The optional HTTPBIND hold value.  This is the
               *      number of connections the server will hold at one time.  This
               *      should almost always be set to 1 (the default).
               *    (Integer) wind - The optional HTTBIND window value.  This is the
               *      allowed range of request ids that are valid.  The default is 5.
               */


              restore(jid, callback, wait, hold, wind) {
                if (this._sessionCachingSupported()) {
                  this._proto._restore(jid, callback, wait, hold, wind);
                } else {
                  const error = new Error('The "restore" method can only be used with a BOSH connection.');
                  error.name = 'StropheSessionError';
                  throw error;
                }
              }
              /** PrivateFunction: _sessionCachingSupported
               * Checks whether sessionStorage and JSON are supported and whether we're
               * using BOSH.
               */


              _sessionCachingSupported() {
                if (this._proto instanceof Strophe.Bosh) {
                  if (!JSON) {
                    return false;
                  }

                  try {
                    sessionStorage.setItem('_strophe_', '_strophe_');
                    sessionStorage.removeItem('_strophe_');
                  } catch (e) {
                    return false;
                  }

                  return true;
                }

                return false;
              }
              /** Function: xmlInput
               *  User overrideable function that receives XML data coming into the
               *  connection.
               *
               *  The default function does nothing.  User code can override this with
               *  > Strophe.Connection.xmlInput = function (elem) {
               *  >   (user code)
               *  > };
               *
               *  Due to limitations of current Browsers' XML-Parsers the opening and closing
               *  <stream> tag for WebSocket-Connoctions will be passed as selfclosing here.
               *
               *  BOSH-Connections will have all stanzas wrapped in a <body> tag. See
               *  <Strophe.Bosh.strip> if you want to strip this tag.
               *
               *  Parameters:
               *    (XMLElement) elem - The XML data received by the connection.
               */


              xmlInput(elem) {
                // eslint-disable-line
                return;
              }
              /** Function: xmlOutput
               *  User overrideable function that receives XML data sent to the
               *  connection.
               *
               *  The default function does nothing.  User code can override this with
               *  > Strophe.Connection.xmlOutput = function (elem) {
               *  >   (user code)
               *  > };
               *
               *  Due to limitations of current Browsers' XML-Parsers the opening and closing
               *  <stream> tag for WebSocket-Connoctions will be passed as selfclosing here.
               *
               *  BOSH-Connections will have all stanzas wrapped in a <body> tag. See
               *  <Strophe.Bosh.strip> if you want to strip this tag.
               *
               *  Parameters:
               *    (XMLElement) elem - The XMLdata sent by the connection.
               */


              xmlOutput(elem) {
                // eslint-disable-line
                return;
              }
              /** Function: rawInput
               *  User overrideable function that receives raw data coming into the
               *  connection.
               *
               *  The default function does nothing.  User code can override this with
               *  > Strophe.Connection.rawInput = function (data) {
               *  >   (user code)
               *  > };
               *
               *  Parameters:
               *    (String) data - The data received by the connection.
               */


              rawInput(data) {
                // eslint-disable-line
                return;
              }
              /** Function: rawOutput
               *  User overrideable function that receives raw data sent to the
               *  connection.
               *
               *  The default function does nothing.  User code can override this with
               *  > Strophe.Connection.rawOutput = function (data) {
               *  >   (user code)
               *  > };
               *
               *  Parameters:
               *    (String) data - The data sent by the connection.
               */


              rawOutput(data) {
                // eslint-disable-line
                return;
              }
              /** Function: nextValidRid
               *  User overrideable function that receives the new valid rid.
               *
               *  The default function does nothing. User code can override this with
               *  > Strophe.Connection.nextValidRid = function (rid) {
               *  >    (user code)
               *  > };
               *
               *  Parameters:
               *    (Number) rid - The next valid rid
               */


              nextValidRid(rid) {
                // eslint-disable-line
                return;
              }
              /** Function: send
               *  Send a stanza.
               *
               *  This function is called to push data onto the send queue to
               *  go out over the wire.  Whenever a request is sent to the BOSH
               *  server, all pending data is sent and the queue is flushed.
               *
               *  Parameters:
               *    (XMLElement |
               *     [XMLElement] |
               *     Strophe.Builder) elem - The stanza to send.
               */


              send(elem) {
                if (elem === null) {
                  return;
                }

                if (typeof elem.sort === "function") {
                  for (let i = 0; i < elem.length; i++) {
                    this._queueData(elem[i]);
                  }
                } else if (typeof elem.tree === "function") {
                  this._queueData(elem.tree());
                } else {
                  this._queueData(elem);
                }

                this._proto._send();
              }
              /** Function: flush
               *  Immediately send any pending outgoing data.
               *
               *  Normally send() queues outgoing data until the next idle period
               *  (100ms), which optimizes network use in the common cases when
               *  several send()s are called in succession. flush() can be used to
               *  immediately send all pending data.
               */


              flush() {
                // cancel the pending idle period and run the idle function
                // immediately
                clearTimeout(this._idleTimeout);

                this._onIdle();
              }
              /** Function: sendPresence
               *  Helper function to send presence stanzas. The main benefit is for
               *  sending presence stanzas for which you expect a responding presence
               *  stanza with the same id (for example when leaving a chat room).
               *
               *  Parameters:
               *    (XMLElement) elem - The stanza to send.
               *    (Function) callback - The callback function for a successful request.
               *    (Function) errback - The callback function for a failed or timed
               *      out request.  On timeout, the stanza will be null.
               *    (Integer) timeout - The time specified in milliseconds for a
               *      timeout to occur.
               *
               *  Returns:
               *    The id used to send the presence.
               */


              sendPresence(elem, callback, errback, timeout) {
                let timeoutHandler = null;

                if (typeof elem.tree === "function") {
                  elem = elem.tree();
                }

                let id = elem.getAttribute('id');

                if (!id) {
                  // inject id if not found
                  id = this.getUniqueId("sendPresence");
                  elem.setAttribute("id", id);
                }

                if (typeof callback === "function" || typeof errback === "function") {
                  const handler = this.addHandler(stanza => {
                    // remove timeout handler if there is one
                    if (timeoutHandler) {
                      this.deleteTimedHandler(timeoutHandler);
                    }

                    if (stanza.getAttribute('type') === 'error') {
                      if (errback) {
                        errback(stanza);
                      }
                    } else if (callback) {
                      callback(stanza);
                    }
                  }, null, 'presence', null, id); // if timeout specified, set up a timeout handler.

                  if (timeout) {
                    timeoutHandler = this.addTimedHandler(timeout, () => {
                      // get rid of normal handler
                      this.deleteHandler(handler); // call errback on timeout with null stanza

                      if (errback) {
                        errback(null);
                      }

                      return false;
                    });
                  }
                }

                this.send(elem);
                return id;
              }
              /** Function: sendIQ
               *  Helper function to send IQ stanzas.
               *
               *  Parameters:
               *    (XMLElement) elem - The stanza to send.
               *    (Function) callback - The callback function for a successful request.
               *    (Function) errback - The callback function for a failed or timed
               *      out request.  On timeout, the stanza will be null.
               *    (Integer) timeout - The time specified in milliseconds for a
               *      timeout to occur.
               *
               *  Returns:
               *    The id used to send the IQ.
              */


              sendIQ(elem, callback, errback, timeout) {
                let timeoutHandler = null;

                if (typeof elem.tree === "function") {
                  elem = elem.tree();
                }

                let id = elem.getAttribute('id');

                if (!id) {
                  // inject id if not found
                  id = this.getUniqueId("sendIQ");
                  elem.setAttribute("id", id);
                }

                if (typeof callback === "function" || typeof errback === "function") {
                  const handler = this.addHandler(stanza => {
                    // remove timeout handler if there is one
                    if (timeoutHandler) {
                      this.deleteTimedHandler(timeoutHandler);
                    }

                    const iqtype = stanza.getAttribute('type');

                    if (iqtype === 'result') {
                      if (callback) {
                        callback(stanza);
                      }
                    } else if (iqtype === 'error') {
                      if (errback) {
                        errback(stanza);
                      }
                    } else {
                      const error = new Error(`Got bad IQ type of ${iqtype}`);
                      error.name = "StropheError";
                      throw error;
                    }
                  }, null, 'iq', ['error', 'result'], id); // if timeout specified, set up a timeout handler.

                  if (timeout) {
                    timeoutHandler = this.addTimedHandler(timeout, () => {
                      // get rid of normal handler
                      this.deleteHandler(handler); // call errback on timeout with null stanza

                      if (errback) {
                        errback(null);
                      }

                      return false;
                    });
                  }
                }

                this.send(elem);
                return id;
              }
              /** PrivateFunction: _queueData
               *  Queue outgoing data for later sending.  Also ensures that the data
               *  is a DOMElement.
               */


              _queueData(element) {
                if (element === null || !element.tagName || !element.childNodes) {
                  const error = new Error("Cannot queue non-DOMElement.");
                  error.name = "StropheError";
                  throw error;
                }

                this._data.push(element);
              }
              /** PrivateFunction: _sendRestart
               *  Send an xmpp:restart stanza.
               */


              _sendRestart() {
                this._data.push("restart");

                this._proto._sendRestart();

                this._idleTimeout = setTimeout(() => this._onIdle(), 100);
              }
              /** Function: addTimedHandler
               *  Add a timed handler to the connection.
               *
               *  This function adds a timed handler.  The provided handler will
               *  be called every period milliseconds until it returns false,
               *  the connection is terminated, or the handler is removed.  Handlers
               *  that wish to continue being invoked should return true.
               *
               *  Because of method binding it is necessary to save the result of
               *  this function if you wish to remove a handler with
               *  deleteTimedHandler().
               *
               *  Note that user handlers are not active until authentication is
               *  successful.
               *
               *  Parameters:
               *    (Integer) period - The period of the handler.
               *    (Function) handler - The callback function.
               *
               *  Returns:
               *    A reference to the handler that can be used to remove it.
               */


              addTimedHandler(period, handler) {
                const thand = new Strophe.TimedHandler(period, handler);
                this.addTimeds.push(thand);
                return thand;
              }
              /** Function: deleteTimedHandler
               *  Delete a timed handler for a connection.
               *
               *  This function removes a timed handler from the connection.  The
               *  handRef parameter is *not* the function passed to addTimedHandler(),
               *  but is the reference returned from addTimedHandler().
               *
               *  Parameters:
               *    (Strophe.TimedHandler) handRef - The handler reference.
               */


              deleteTimedHandler(handRef) {
                // this must be done in the Idle loop so that we don't change
                // the handlers during iteration
                this.removeTimeds.push(handRef);
              }
              /** Function: addHandler
               *  Add a stanza handler for the connection.
               *
               *  This function adds a stanza handler to the connection.  The
               *  handler callback will be called for any stanza that matches
               *  the parameters.  Note that if multiple parameters are supplied,
               *  they must all match for the handler to be invoked.
               *
               *  The handler will receive the stanza that triggered it as its argument.
               *  *The handler should return true if it is to be invoked again;
               *  returning false will remove the handler after it returns.*
               *
               *  As a convenience, the ns parameters applies to the top level element
               *  and also any of its immediate children.  This is primarily to make
               *  matching /iq/query elements easy.
               *
               *  Options
               *  ~~~~~~~
               *  With the options argument, you can specify boolean flags that affect how
               *  matches are being done.
               *
               *  Currently two flags exist:
               *
               *  - matchBareFromJid:
               *      When set to true, the from parameter and the
               *      from attribute on the stanza will be matched as bare JIDs instead
               *      of full JIDs. To use this, pass {matchBareFromJid: true} as the
               *      value of options. The default value for matchBareFromJid is false.
               *
               *  - ignoreNamespaceFragment:
               *      When set to true, a fragment specified on the stanza's namespace
               *      URL will be ignored when it's matched with the one configured for
               *      the handler.
               *
               *      This means that if you register like this:
               *      >   connection.addHandler(
               *      >       handler,
               *      >       'http://jabber.org/protocol/muc',
               *      >       null, null, null, null,
               *      >       {'ignoreNamespaceFragment': true}
               *      >   );
               *
               *      Then a stanza with XML namespace of
               *      'http://jabber.org/protocol/muc#user' will also be matched. If
               *      'ignoreNamespaceFragment' is false, then only stanzas with
               *      'http://jabber.org/protocol/muc' will be matched.
               *
               *  Deleting the handler
               *  ~~~~~~~~~~~~~~~~~~~~
               *  The return value should be saved if you wish to remove the handler
               *  with deleteHandler().
               *
               *  Parameters:
               *    (Function) handler - The user callback.
               *    (String) ns - The namespace to match.
               *    (String) name - The stanza name to match.
               *    (String|Array) type - The stanza type (or types if an array) to match.
               *    (String) id - The stanza id attribute to match.
               *    (String) from - The stanza from attribute to match.
               *    (String) options - The handler options
               *
               *  Returns:
               *    A reference to the handler that can be used to remove it.
               */


              addHandler(handler, ns, name, type, id, from, options) {
                const hand = new Strophe.Handler(handler, ns, name, type, id, from, options);
                this.addHandlers.push(hand);
                return hand;
              }
              /** Function: deleteHandler
               *  Delete a stanza handler for a connection.
               *
               *  This function removes a stanza handler from the connection.  The
               *  handRef parameter is *not* the function passed to addHandler(),
               *  but is the reference returned from addHandler().
               *
               *  Parameters:
               *    (Strophe.Handler) handRef - The handler reference.
               */


              deleteHandler(handRef) {
                // this must be done in the Idle loop so that we don't change
                // the handlers during iteration
                this.removeHandlers.push(handRef); // If a handler is being deleted while it is being added,
                // prevent it from getting added

                const i = this.addHandlers.indexOf(handRef);

                if (i >= 0) {
                  this.addHandlers.splice(i, 1);
                }
              }
              /** Function: registerSASLMechanisms
               *
               * Register the SASL mechanisms which will be supported by this instance of
               * Strophe.Connection (i.e. which this XMPP client will support).
               *
               *  Parameters:
               *    (Array) mechanisms - Array of objects with Strophe.SASLMechanism prototypes
               *
               */


              registerSASLMechanisms(mechanisms) {
                this.mechanisms = {};
                mechanisms = mechanisms || [Strophe.SASLAnonymous, Strophe.SASLExternal, Strophe.SASLOAuthBearer, Strophe.SASLXOAuth2, Strophe.SASLPlain, Strophe.SASLSHA1];
                mechanisms.forEach(m => this.registerSASLMechanism(m));
              }
              /** Function: registerSASLMechanism
               *
               * Register a single SASL mechanism, to be supported by this client.
               *
               *  Parameters:
               *    (Object) mechanism - Object with a Strophe.SASLMechanism prototype
               *
               */


              registerSASLMechanism(Mechanism) {
                const mechanism = new Mechanism();
                this.mechanisms[mechanism.mechname] = mechanism;
              }
              /** Function: disconnect
               *  Start the graceful disconnection process.
               *
               *  This function starts the disconnection process.  This process starts
               *  by sending unavailable presence and sending BOSH body of type
               *  terminate.  A timeout handler makes sure that disconnection happens
               *  even if the BOSH server does not respond.
               *  If the Connection object isn't connected, at least tries to abort all pending requests
               *  so the connection object won't generate successful requests (which were already opened).
               *
               *  The user supplied connection callback will be notified of the
               *  progress as this process happens.
               *
               *  Parameters:
               *    (String) reason - The reason the disconnect is occuring.
               */


              disconnect(reason) {
                this._changeConnectStatus(Strophe.Status.DISCONNECTING, reason);

                if (reason) {
                  Strophe.warn("Disconnect was called because: " + reason);
                } else {
                  Strophe.info("Disconnect was called");
                }

                if (this.connected) {
                  let pres = false;
                  this.disconnecting = true;

                  if (this.authenticated) {
                    pres = $pres({
                      'xmlns': Strophe.NS.CLIENT,
                      'type': 'unavailable'
                    });
                  } // setup timeout handler


                  this._disconnectTimeout = this._addSysTimedHandler(this.disconnection_timeout, this._onDisconnectTimeout.bind(this));

                  this._proto._disconnect(pres);
                } else {
                  Strophe.warn("Disconnect was called before Strophe connected to the server");

                  this._proto._abortAllRequests();

                  this._doDisconnect();
                }
              }
              /** PrivateFunction: _changeConnectStatus
               *  _Private_ helper function that makes sure plugins and the user's
               *  callback are notified of connection status changes.
               *
               *  Parameters:
               *    (Integer) status - the new connection status, one of the values
               *      in Strophe.Status
               *    (String) condition - the error condition or null
               *    (XMLElement) elem - The triggering stanza.
               */


              _changeConnectStatus(status, condition, elem) {
                // notify all plugins listening for status changes
                for (const k in Strophe._connectionPlugins) {
                  if (Object.prototype.hasOwnProperty.call(Strophe._connectionPlugins, k)) {
                    const plugin = this[k];

                    if (plugin.statusChanged) {
                      try {
                        plugin.statusChanged(status, condition);
                      } catch (err) {
                        Strophe.error(`${k} plugin caused an exception changing status: ${err}`);
                      }
                    }
                  }
                } // notify the user's callback


                if (this.connect_callback) {
                  try {
                    this.connect_callback(status, condition, elem);
                  } catch (e) {
                    Strophe._handleError(e);

                    Strophe.error(`User connection callback caused an exception: ${e}`);
                  }
                }
              }
              /** PrivateFunction: _doDisconnect
               *  _Private_ function to disconnect.
               *
               *  This is the last piece of the disconnection logic.  This resets the
               *  connection and alerts the user's connection callback.
               */


              _doDisconnect(condition) {
                if (typeof this._idleTimeout === "number") {
                  clearTimeout(this._idleTimeout);
                } // Cancel Disconnect Timeout


                if (this._disconnectTimeout !== null) {
                  this.deleteTimedHandler(this._disconnectTimeout);
                  this._disconnectTimeout = null;
                }

                Strophe.debug("_doDisconnect was called");

                this._proto._doDisconnect();

                this.authenticated = false;
                this.disconnecting = false;
                this.restored = false; // delete handlers

                this.handlers = [];
                this.timedHandlers = [];
                this.removeTimeds = [];
                this.removeHandlers = [];
                this.addTimeds = [];
                this.addHandlers = []; // tell the parent we disconnected

                this._changeConnectStatus(Strophe.Status.DISCONNECTED, condition);

                this.connected = false;
              }
              /** PrivateFunction: _dataRecv
               *  _Private_ handler to processes incoming data from the the connection.
               *
               *  Except for _connect_cb handling the initial connection request,
               *  this function handles the incoming data for all requests.  This
               *  function also fires stanza handlers that match each incoming
               *  stanza.
               *
               *  Parameters:
               *    (Strophe.Request) req - The request that has data ready.
               *    (string) req - The stanza a raw string (optiona).
               */


              _dataRecv(req, raw) {
                const elem = this._proto._reqToData(req);

                if (elem === null) {
                  return;
                }

                if (this.xmlInput !== Strophe.Connection.prototype.xmlInput) {
                  if (elem.nodeName === this._proto.strip && elem.childNodes.length) {
                    this.xmlInput(elem.childNodes[0]);
                  } else {
                    this.xmlInput(elem);
                  }
                }

                if (this.rawInput !== Strophe.Connection.prototype.rawInput) {
                  if (raw) {
                    this.rawInput(raw);
                  } else {
                    this.rawInput(Strophe.serialize(elem));
                  }
                } // remove handlers scheduled for deletion


                while (this.removeHandlers.length > 0) {
                  const hand = this.removeHandlers.pop();
                  const i = this.handlers.indexOf(hand);

                  if (i >= 0) {
                    this.handlers.splice(i, 1);
                  }
                } // add handlers scheduled for addition


                while (this.addHandlers.length > 0) {
                  this.handlers.push(this.addHandlers.pop());
                } // handle graceful disconnect


                if (this.disconnecting && this._proto._emptyQueue()) {
                  this._doDisconnect();

                  return;
                }

                const type = elem.getAttribute("type");

                if (type !== null && type === "terminate") {
                  // Don't process stanzas that come in after disconnect
                  if (this.disconnecting) {
                    return;
                  } // an error occurred


                  let cond = elem.getAttribute("condition");
                  const conflict = elem.getElementsByTagName("conflict");

                  if (cond !== null) {
                    if (cond === "remote-stream-error" && conflict.length > 0) {
                      cond = "conflict";
                    }

                    this._changeConnectStatus(Strophe.Status.CONNFAIL, cond);
                  } else {
                    this._changeConnectStatus(Strophe.Status.CONNFAIL, Strophe.ErrorCondition.UNKOWN_REASON);
                  }

                  this._doDisconnect(cond);

                  return;
                } // send each incoming stanza through the handler chain


                Strophe.forEachChild(elem, null, child => {
                  const matches = [];
                  this.handlers = this.handlers.reduce((handlers, handler) => {
                    try {
                      if (handler.isMatch(child) && (this.authenticated || !handler.user)) {
                        if (handler.run(child)) {
                          handlers.push(handler);
                        }

                        matches.push(handler);
                      } else {
                        handlers.push(handler);
                      }
                    } catch (e) {
                      // if the handler throws an exception, we consider it as false
                      Strophe.warn('Removing Strophe handlers due to uncaught exception: ' + e.message);
                    }

                    return handlers;
                  }, []); // If no handler was fired for an incoming IQ with type="set",
                  // then we return an IQ error stanza with service-unavailable.

                  if (!matches.length && this.iqFallbackHandler.isMatch(child)) {
                    this.iqFallbackHandler.run(child);
                  }
                });
              }
              /** PrivateFunction: _connect_cb
               *  _Private_ handler for initial connection request.
               *
               *  This handler is used to process the initial connection request
               *  response from the BOSH server. It is used to set up authentication
               *  handlers and start the authentication process.
               *
               *  SASL authentication will be attempted if available, otherwise
               *  the code will fall back to legacy authentication.
               *
               *  Parameters:
               *    (Strophe.Request) req - The current request.
               *    (Function) _callback - low level (xmpp) connect callback function.
               *      Useful for plugins with their own xmpp connect callback (when they
               *      want to do something special).
               */


              _connect_cb(req, _callback, raw) {
                Strophe.debug("_connect_cb was called");
                this.connected = true;
                let bodyWrap;

                try {
                  bodyWrap = this._proto._reqToData(req);
                } catch (e) {
                  if (e.name !== Strophe.ErrorCondition.BAD_FORMAT) {
                    throw e;
                  }

                  this._changeConnectStatus(Strophe.Status.CONNFAIL, Strophe.ErrorCondition.BAD_FORMAT);

                  this._doDisconnect(Strophe.ErrorCondition.BAD_FORMAT);
                }

                if (!bodyWrap) {
                  return;
                }

                if (this.xmlInput !== Strophe.Connection.prototype.xmlInput) {
                  if (bodyWrap.nodeName === this._proto.strip && bodyWrap.childNodes.length) {
                    this.xmlInput(bodyWrap.childNodes[0]);
                  } else {
                    this.xmlInput(bodyWrap);
                  }
                }

                if (this.rawInput !== Strophe.Connection.prototype.rawInput) {
                  if (raw) {
                    this.rawInput(raw);
                  } else {
                    this.rawInput(Strophe.serialize(bodyWrap));
                  }
                }

                const conncheck = this._proto._connect_cb(bodyWrap);

                if (conncheck === Strophe.Status.CONNFAIL) {
                  return;
                } // Check for the stream:features tag


                let hasFeatures;

                if (bodyWrap.getElementsByTagNameNS) {
                  hasFeatures = bodyWrap.getElementsByTagNameNS(Strophe.NS.STREAM, "features").length > 0;
                } else {
                  hasFeatures = bodyWrap.getElementsByTagName("stream:features").length > 0 || bodyWrap.getElementsByTagName("features").length > 0;
                }

                if (!hasFeatures) {
                  this._proto._no_auth_received(_callback);

                  return;
                }

                const matched = Array.from(bodyWrap.getElementsByTagName("mechanism")).map(m => this.mechanisms[m.textContent]).filter(m => m);

                if (matched.length === 0) {
                  if (bodyWrap.getElementsByTagName("auth").length === 0) {
                    // There are no matching SASL mechanisms and also no legacy
                    // auth available.
                    this._proto._no_auth_received(_callback);

                    return;
                  }
                }

                if (this.do_authentication !== false) {
                  this.authenticate(matched);
                }
              }
              /** Function: sortMechanismsByPriority
               *
               *  Sorts an array of objects with prototype SASLMechanism according to
               *  their priorities.
               *
               *  Parameters:
               *    (Array) mechanisms - Array of SASL mechanisms.
               *
               */


              sortMechanismsByPriority(mechanisms) {
                // eslint-disable-line class-methods-use-this
                // Sorting mechanisms according to priority.
                for (let i = 0; i < mechanisms.length - 1; ++i) {
                  let higher = i;

                  for (let j = i + 1; j < mechanisms.length; ++j) {
                    if (mechanisms[j].priority > mechanisms[higher].priority) {
                      higher = j;
                    }
                  }

                  if (higher !== i) {
                    const swap = mechanisms[i];
                    mechanisms[i] = mechanisms[higher];
                    mechanisms[higher] = swap;
                  }
                }

                return mechanisms;
              }
              /** Function: authenticate
               * Set up authentication
               *
               *  Continues the initial connection request by setting up authentication
               *  handlers and starting the authentication process.
               *
               *  SASL authentication will be attempted if available, otherwise
               *  the code will fall back to legacy authentication.
               *
               *  Parameters:
               *    (Array) matched - Array of SASL mechanisms supported.
               *
               */


              authenticate(matched) {
                if (!this._attemptSASLAuth(matched)) {
                  this._attemptLegacyAuth();
                }
              }
              /** PrivateFunction: _attemptSASLAuth
               *
               *  Iterate through an array of SASL mechanisms and attempt authentication
               *  with the highest priority (enabled) mechanism.
               *
               *  Parameters:
               *    (Array) mechanisms - Array of SASL mechanisms.
               *
               *  Returns:
               *    (Boolean) mechanism_found - true or false, depending on whether a
               *          valid SASL mechanism was found with which authentication could be
               *          started.
               */


              _attemptSASLAuth(mechanisms) {
                mechanisms = this.sortMechanismsByPriority(mechanisms || []);
                let mechanism_found = false;

                for (let i = 0; i < mechanisms.length; ++i) {
                  if (!mechanisms[i].test(this)) {
                    continue;
                  }

                  this._sasl_success_handler = this._addSysHandler(this._sasl_success_cb.bind(this), null, "success", null, null);
                  this._sasl_failure_handler = this._addSysHandler(this._sasl_failure_cb.bind(this), null, "failure", null, null);
                  this._sasl_challenge_handler = this._addSysHandler(this._sasl_challenge_cb.bind(this), null, "challenge", null, null);
                  this._sasl_mechanism = mechanisms[i];

                  this._sasl_mechanism.onStart(this);

                  const request_auth_exchange = $build("auth", {
                    'xmlns': Strophe.NS.SASL,
                    'mechanism': this._sasl_mechanism.mechname
                  });

                  if (this._sasl_mechanism.isClientFirst) {
                    const response = this._sasl_mechanism.clientChallenge(this);

                    request_auth_exchange.t(abab.btoa(response));
                  }

                  this.send(request_auth_exchange.tree());
                  mechanism_found = true;
                  break;
                }

                return mechanism_found;
              }
              /** PrivateFunction: _sasl_challenge_cb
               *  _Private_ handler for the SASL challenge
               *
               */


              _sasl_challenge_cb(elem) {
                const challenge = abab.atob(Strophe.getText(elem));

                const response = this._sasl_mechanism.onChallenge(this, challenge);

                const stanza = $build('response', {
                  'xmlns': Strophe.NS.SASL
                });

                if (response !== "") {
                  stanza.t(abab.btoa(response));
                }

                this.send(stanza.tree());
                return true;
              }
              /** PrivateFunction: _attemptLegacyAuth
               *
               *  Attempt legacy (i.e. non-SASL) authentication.
               */


              _attemptLegacyAuth() {
                if (Strophe.getNodeFromJid(this.jid) === null) {
                  // we don't have a node, which is required for non-anonymous
                  // client connections
                  this._changeConnectStatus(Strophe.Status.CONNFAIL, Strophe.ErrorCondition.MISSING_JID_NODE);

                  this.disconnect(Strophe.ErrorCondition.MISSING_JID_NODE);
                } else {
                  // Fall back to legacy authentication
                  this._changeConnectStatus(Strophe.Status.AUTHENTICATING, null);

                  this._addSysHandler(this._onLegacyAuthIQResult.bind(this), null, null, null, "_auth_1");

                  this.send($iq({
                    'type': "get",
                    'to': this.domain,
                    'id': "_auth_1"
                  }).c("query", {
                    xmlns: Strophe.NS.AUTH
                  }).c("username", {}).t(Strophe.getNodeFromJid(this.jid)).tree());
                }
              }
              /** PrivateFunction: _onLegacyAuthIQResult
               *  _Private_ handler for legacy authentication.
               *
               *  This handler is called in response to the initial <iq type='get'/>
               *  for legacy authentication.  It builds an authentication <iq/> and
               *  sends it, creating a handler (calling back to _auth2_cb()) to
               *  handle the result
               *
               *  Parameters:
               *    (XMLElement) elem - The stanza that triggered the callback.
               *
               *  Returns:
               *    false to remove the handler.
               */


              _onLegacyAuthIQResult(elem) {
                // eslint-disable-line no-unused-vars
                // build plaintext auth iq
                const iq = $iq({
                  type: "set",
                  id: "_auth_2"
                }).c('query', {
                  xmlns: Strophe.NS.AUTH
                }).c('username', {}).t(Strophe.getNodeFromJid(this.jid)).up().c('password').t(this.pass);

                if (!Strophe.getResourceFromJid(this.jid)) {
                  // since the user has not supplied a resource, we pick
                  // a default one here.  unlike other auth methods, the server
                  // cannot do this for us.
                  this.jid = Strophe.getBareJidFromJid(this.jid) + '/strophe';
                }

                iq.up().c('resource', {}).t(Strophe.getResourceFromJid(this.jid));

                this._addSysHandler(this._auth2_cb.bind(this), null, null, null, "_auth_2");

                this.send(iq.tree());
                return false;
              }
              /** PrivateFunction: _sasl_success_cb
               *  _Private_ handler for succesful SASL authentication.
               *
               *  Parameters:
               *    (XMLElement) elem - The matching stanza.
               *
               *  Returns:
               *    false to remove the handler.
               */


              _sasl_success_cb(elem) {
                if (this._sasl_data["server-signature"]) {
                  let serverSignature;
                  const success = abab.atob(Strophe.getText(elem));
                  const attribMatch = /([a-z]+)=([^,]+)(,|$)/;
                  const matches = success.match(attribMatch);

                  if (matches[1] === "v") {
                    serverSignature = matches[2];
                  }

                  if (serverSignature !== this._sasl_data["server-signature"]) {
                    // remove old handlers
                    this.deleteHandler(this._sasl_failure_handler);
                    this._sasl_failure_handler = null;

                    if (this._sasl_challenge_handler) {
                      this.deleteHandler(this._sasl_challenge_handler);
                      this._sasl_challenge_handler = null;
                    }

                    this._sasl_data = {};
                    return this._sasl_failure_cb(null);
                  }
                }

                Strophe.info("SASL authentication succeeded.");

                if (this._sasl_mechanism) {
                  this._sasl_mechanism.onSuccess();
                } // remove old handlers


                this.deleteHandler(this._sasl_failure_handler);
                this._sasl_failure_handler = null;

                if (this._sasl_challenge_handler) {
                  this.deleteHandler(this._sasl_challenge_handler);
                  this._sasl_challenge_handler = null;
                }

                const streamfeature_handlers = [];

                const wrapper = (handlers, elem) => {
                  while (handlers.length) {
                    this.deleteHandler(handlers.pop());
                  }

                  this._onStreamFeaturesAfterSASL(elem);

                  return false;
                };

                streamfeature_handlers.push(this._addSysHandler(elem => wrapper(streamfeature_handlers, elem), null, "stream:features", null, null));
                streamfeature_handlers.push(this._addSysHandler(elem => wrapper(streamfeature_handlers, elem), Strophe.NS.STREAM, "features", null, null)); // we must send an xmpp:restart now

                this._sendRestart();

                return false;
              }
              /** PrivateFunction: _onStreamFeaturesAfterSASL
               *  Parameters:
               *    (XMLElement) elem - The matching stanza.
               *
               *  Returns:
               *    false to remove the handler.
               */


              _onStreamFeaturesAfterSASL(elem) {
                // save stream:features for future usage
                this.features = elem;

                for (let i = 0; i < elem.childNodes.length; i++) {
                  const child = elem.childNodes[i];

                  if (child.nodeName === 'bind') {
                    this.do_bind = true;
                  }

                  if (child.nodeName === 'session') {
                    this.do_session = true;
                  }
                }

                if (!this.do_bind) {
                  this._changeConnectStatus(Strophe.Status.AUTHFAIL, null);

                  return false;
                } else if (!this.options.explicitResourceBinding) {
                  this.bind();
                } else {
                  this._changeConnectStatus(Strophe.Status.BINDREQUIRED, null);
                }

                return false;
              }
              /** Function: bind
               *
               *  Sends an IQ to the XMPP server to bind a JID resource for this session.
               *
               *  https://tools.ietf.org/html/rfc6120#section-7.5
               *
               *  If `explicitResourceBinding` was set to a truthy value in the options
               *  passed to the Strophe.Connection constructor, then this function needs
               *  to be called explicitly by the client author.
               *
               *  Otherwise it'll be called automatically as soon as the XMPP server
               *  advertises the "urn:ietf:params:xml:ns:xmpp-bind" stream feature.
               */


              bind() {
                if (!this.do_bind) {
                  Strophe.log(Strophe.LogLevel.INFO, `Strophe.Connection.prototype.bind called but "do_bind" is false`);
                  return;
                }

                this._addSysHandler(this._onResourceBindResultIQ.bind(this), null, null, null, "_bind_auth_2");

                const resource = Strophe.getResourceFromJid(this.jid);

                if (resource) {
                  this.send($iq({
                    type: "set",
                    id: "_bind_auth_2"
                  }).c('bind', {
                    xmlns: Strophe.NS.BIND
                  }).c('resource', {}).t(resource).tree());
                } else {
                  this.send($iq({
                    type: "set",
                    id: "_bind_auth_2"
                  }).c('bind', {
                    xmlns: Strophe.NS.BIND
                  }).tree());
                }
              }
              /** PrivateFunction: _onResourceBindIQ
               *  _Private_ handler for binding result and session start.
               *
               *  Parameters:
               *    (XMLElement) elem - The matching stanza.
               *
               *  Returns:
               *    false to remove the handler.
               */


              _onResourceBindResultIQ(elem) {
                if (elem.getAttribute("type") === "error") {
                  Strophe.warn("Resource binding failed.");
                  const conflict = elem.getElementsByTagName("conflict");
                  let condition;

                  if (conflict.length > 0) {
                    condition = Strophe.ErrorCondition.CONFLICT;
                  }

                  this._changeConnectStatus(Strophe.Status.AUTHFAIL, condition, elem);

                  return false;
                } // TODO - need to grab errors


                const bind = elem.getElementsByTagName("bind");

                if (bind.length > 0) {
                  const jidNode = bind[0].getElementsByTagName("jid");

                  if (jidNode.length > 0) {
                    this.authenticated = true;
                    this.jid = Strophe.getText(jidNode[0]);

                    if (this.do_session) {
                      this._establishSession();
                    } else {
                      this._changeConnectStatus(Strophe.Status.CONNECTED, null);
                    }
                  }
                } else {
                  Strophe.warn("Resource binding failed.");

                  this._changeConnectStatus(Strophe.Status.AUTHFAIL, null, elem);

                  return false;
                }
              }
              /** PrivateFunction: _establishSession
               *  Send IQ request to establish a session with the XMPP server.
               *
               *  See https://xmpp.org/rfcs/rfc3921.html#session
               *
               *  Note: The protocol for session establishment has been determined as
               *  unnecessary and removed in RFC-6121.
               */


              _establishSession() {
                if (!this.do_session) {
                  throw new Error(`Strophe.Connection.prototype._establishSession ` + `called but apparently ${Strophe.NS.SESSION} wasn't advertised by the server`);
                }

                this._addSysHandler(this._onSessionResultIQ.bind(this), null, null, null, "_session_auth_2");

                this.send($iq({
                  type: "set",
                  id: "_session_auth_2"
                }).c('session', {
                  xmlns: Strophe.NS.SESSION
                }).tree());
              }
              /** PrivateFunction: _onSessionResultIQ
               *  _Private_ handler for the server's IQ response to a client's session
               *  request.
               *
               *  This sets Connection.authenticated to true on success, which
               *  starts the processing of user handlers.
               *
               *  See https://xmpp.org/rfcs/rfc3921.html#session
               *
               *  Note: The protocol for session establishment has been determined as
               *  unnecessary and removed in RFC-6121.
               *
               *  Parameters:
               *    (XMLElement) elem - The matching stanza.
               *
               *  Returns:
               *    false to remove the handler.
               */


              _onSessionResultIQ(elem) {
                if (elem.getAttribute("type") === "result") {
                  this.authenticated = true;

                  this._changeConnectStatus(Strophe.Status.CONNECTED, null);
                } else if (elem.getAttribute("type") === "error") {
                  this.authenticated = false;
                  Strophe.warn("Session creation failed.");

                  this._changeConnectStatus(Strophe.Status.AUTHFAIL, null, elem);

                  return false;
                }

                return false;
              }
              /** PrivateFunction: _sasl_failure_cb
               *  _Private_ handler for SASL authentication failure.
               *
               *  Parameters:
               *    (XMLElement) elem - The matching stanza.
               *
               *  Returns:
               *    false to remove the handler.
               */


              _sasl_failure_cb(elem) {
                // delete unneeded handlers
                if (this._sasl_success_handler) {
                  this.deleteHandler(this._sasl_success_handler);
                  this._sasl_success_handler = null;
                }

                if (this._sasl_challenge_handler) {
                  this.deleteHandler(this._sasl_challenge_handler);
                  this._sasl_challenge_handler = null;
                }

                if (this._sasl_mechanism) this._sasl_mechanism.onFailure();

                this._changeConnectStatus(Strophe.Status.AUTHFAIL, null, elem);

                return false;
              }
              /** PrivateFunction: _auth2_cb
               *  _Private_ handler to finish legacy authentication.
               *
               *  This handler is called when the result from the jabber:iq:auth
               *  <iq/> stanza is returned.
               *
               *  Parameters:
               *    (XMLElement) elem - The stanza that triggered the callback.
               *
               *  Returns:
               *    false to remove the handler.
               */


              _auth2_cb(elem) {
                if (elem.getAttribute("type") === "result") {
                  this.authenticated = true;

                  this._changeConnectStatus(Strophe.Status.CONNECTED, null);
                } else if (elem.getAttribute("type") === "error") {
                  this._changeConnectStatus(Strophe.Status.AUTHFAIL, null, elem);

                  this.disconnect('authentication failed');
                }

                return false;
              }
              /** PrivateFunction: _addSysTimedHandler
               *  _Private_ function to add a system level timed handler.
               *
               *  This function is used to add a Strophe.TimedHandler for the
               *  library code.  System timed handlers are allowed to run before
               *  authentication is complete.
               *
               *  Parameters:
               *    (Integer) period - The period of the handler.
               *    (Function) handler - The callback function.
               */


              _addSysTimedHandler(period, handler) {
                const thand = new Strophe.TimedHandler(period, handler);
                thand.user = false;
                this.addTimeds.push(thand);
                return thand;
              }
              /** PrivateFunction: _addSysHandler
               *  _Private_ function to add a system level stanza handler.
               *
               *  This function is used to add a Strophe.Handler for the
               *  library code.  System stanza handlers are allowed to run before
               *  authentication is complete.
               *
               *  Parameters:
               *    (Function) handler - The callback function.
               *    (String) ns - The namespace to match.
               *    (String) name - The stanza name to match.
               *    (String) type - The stanza type attribute to match.
               *    (String) id - The stanza id attribute to match.
               */


              _addSysHandler(handler, ns, name, type, id) {
                const hand = new Strophe.Handler(handler, ns, name, type, id);
                hand.user = false;
                this.addHandlers.push(hand);
                return hand;
              }
              /** PrivateFunction: _onDisconnectTimeout
               *  _Private_ timeout handler for handling non-graceful disconnection.
               *
               *  If the graceful disconnect process does not complete within the
               *  time allotted, this handler finishes the disconnect anyway.
               *
               *  Returns:
               *    false to remove the handler.
               */


              _onDisconnectTimeout() {
                Strophe.debug("_onDisconnectTimeout was called");

                this._changeConnectStatus(Strophe.Status.CONNTIMEOUT, null);

                this._proto._onDisconnectTimeout(); // actually disconnect


                this._doDisconnect();

                return false;
              }
              /** PrivateFunction: _onIdle
               *  _Private_ handler to process events during idle cycle.
               *
               *  This handler is called every 100ms to fire timed handlers that
               *  are ready and keep poll requests going.
               */


              _onIdle() {
                // add timed handlers scheduled for addition
                // NOTE: we add before remove in the case a timed handler is
                // added and then deleted before the next _onIdle() call.
                while (this.addTimeds.length > 0) {
                  this.timedHandlers.push(this.addTimeds.pop());
                } // remove timed handlers that have been scheduled for deletion


                while (this.removeTimeds.length > 0) {
                  const thand = this.removeTimeds.pop();
                  const i = this.timedHandlers.indexOf(thand);

                  if (i >= 0) {
                    this.timedHandlers.splice(i, 1);
                  }
                } // call ready timed handlers


                const now = new Date().getTime();
                const newList = [];

                for (let i = 0; i < this.timedHandlers.length; i++) {
                  const thand = this.timedHandlers[i];

                  if (this.authenticated || !thand.user) {
                    const since = thand.lastCalled + thand.period;

                    if (since - now <= 0) {
                      if (thand.run()) {
                        newList.push(thand);
                      }
                    } else {
                      newList.push(thand);
                    }
                  }
                }

                this.timedHandlers = newList;
                clearTimeout(this._idleTimeout);

                this._proto._onIdle(); // reactivate the timer only if connected


                if (this.connected) {
                  this._idleTimeout = setTimeout(() => this._onIdle(), 100);
                }
              }

            };
            Strophe.SASLMechanism = SASLMechanism;
            /** Constants: SASL mechanisms
             *  Available authentication mechanisms
             *
             *  Strophe.SASLAnonymous   - SASL ANONYMOUS authentication.
             *  Strophe.SASLPlain       - SASL PLAIN authentication.
             *  Strophe.SASLSHA1        - SASL SCRAM-SHA-1 authentication
             *  Strophe.SASLOAuthBearer - SASL OAuth Bearer authentication
             *  Strophe.SASLExternal    - SASL EXTERNAL authentication
             *  Strophe.SASLXOAuth2     - SASL X-OAuth2 authentication
             */

            Strophe.SASLAnonymous = SASLAnonymous;
            Strophe.SASLPlain = SASLPlain;
            Strophe.SASLSHA1 = SASLSHA1;
            Strophe.SASLOAuthBearer = SASLOAuthBearer;
            Strophe.SASLExternal = SASLExternal;
            Strophe.SASLXOAuth2 = SASLXOAuth2;
            var core = {
              'Strophe': Strophe,
              '$build': $build,
              '$iq': $iq,
              '$msg': $msg,
              '$pres': $pres,
              'SHA1': SHA1,
              'MD5': MD5,
              'b64_hmac_sha1': SHA1.b64_hmac_sha1,
              'b64_sha1': SHA1.b64_sha1,
              'str_hmac_sha1': SHA1.str_hmac_sha1,
              'str_sha1': SHA1.str_sha1
            };

            /*
                This program is distributed under the terms of the MIT license.
                Please see the LICENSE file for details.

                Copyright 2006-2008, OGG, LLC
            */
            /** PrivateClass: Strophe.Request
             *  _Private_ helper class that provides a cross implementation abstraction
             *  for a BOSH related XMLHttpRequest.
             *
             *  The Strophe.Request class is used internally to encapsulate BOSH request
             *  information.  It is not meant to be used from user's code.
             */

            Strophe.Request = class Request {
              /** PrivateConstructor: Strophe.Request
               *  Create and initialize a new Strophe.Request object.
               *
               *  Parameters:
               *    (XMLElement) elem - The XML data to be sent in the request.
               *    (Function) func - The function that will be called when the
               *      XMLHttpRequest readyState changes.
               *    (Integer) rid - The BOSH rid attribute associated with this request.
               *    (Integer) sends - The number of times this same request has been sent.
               */
              constructor(elem, func, rid, sends) {
                this.id = ++Strophe._requestId;
                this.xmlData = elem;
                this.data = Strophe.serialize(elem); // save original function in case we need to make a new request
                // from this one.

                this.origFunc = func;
                this.func = func;
                this.rid = rid;
                this.date = NaN;
                this.sends = sends || 0;
                this.abort = false;
                this.dead = null;

                this.age = function () {
                  if (!this.date) {
                    return 0;
                  }

                  const now = new Date();
                  return (now - this.date) / 1000;
                };

                this.timeDead = function () {
                  if (!this.dead) {
                    return 0;
                  }

                  const now = new Date();
                  return (now - this.dead) / 1000;
                };

                this.xhr = this._newXHR();
              }
              /** PrivateFunction: getResponse
               *  Get a response from the underlying XMLHttpRequest.
               *
               *  This function attempts to get a response from the request and checks
               *  for errors.
               *
               *  Throws:
               *    "parsererror" - A parser error occured.
               *    "bad-format" - The entity has sent XML that cannot be processed.
               *
               *  Returns:
               *    The DOM element tree of the response.
               */


              getResponse() {
                let node = null;

                if (this.xhr.responseXML && this.xhr.responseXML.documentElement) {
                  node = this.xhr.responseXML.documentElement;

                  if (node.tagName === "parsererror") {
                    Strophe.error("invalid response received");
                    Strophe.error("responseText: " + this.xhr.responseText);
                    Strophe.error("responseXML: " + Strophe.serialize(this.xhr.responseXML));
                    throw new Error("parsererror");
                  }
                } else if (this.xhr.responseText) {
                  // In React Native, we may get responseText but no responseXML.  We can try to parse it manually.
                  Strophe.debug("Got responseText but no responseXML; attempting to parse it with DOMParser...");
                  node = new DOMParser().parseFromString(this.xhr.responseText, 'application/xml').documentElement;

                  if (!node) {
                    throw new Error('Parsing produced null node');
                  } else if (node.querySelector('parsererror')) {
                    Strophe.error("invalid response received: " + node.querySelector('parsererror').textContent);
                    Strophe.error("responseText: " + this.xhr.responseText);
                    const error = new Error();
                    error.name = Strophe.ErrorCondition.BAD_FORMAT;
                    throw error;
                  }
                }

                return node;
              }
              /** PrivateFunction: _newXHR
               *  _Private_ helper function to create XMLHttpRequests.
               *
               *  This function creates XMLHttpRequests across all implementations.
               *
               *  Returns:
               *    A new XMLHttpRequest.
               */


              _newXHR() {
                let xhr = null;

                if (window.XMLHttpRequest) {
                  xhr = new XMLHttpRequest();

                  if (xhr.overrideMimeType) {
                    xhr.overrideMimeType("text/xml; charset=utf-8");
                  }
                } else if (window.ActiveXObject) {
                  xhr = new ActiveXObject("Microsoft.XMLHTTP");
                } // use Function.bind() to prepend ourselves as an argument


                xhr.onreadystatechange = this.func.bind(null, this);
                return xhr;
              }

            };
            /** Class: Strophe.Bosh
             *  _Private_ helper class that handles BOSH Connections
             *
             *  The Strophe.Bosh class is used internally by Strophe.Connection
             *  to encapsulate BOSH sessions. It is not meant to be used from user's code.
             */

            /** File: bosh.js
             *  A JavaScript library to enable BOSH in Strophejs.
             *
             *  this library uses Bidirectional-streams Over Synchronous HTTP (BOSH)
             *  to emulate a persistent, stateful, two-way connection to an XMPP server.
             *  More information on BOSH can be found in XEP 124.
             */

            /** PrivateConstructor: Strophe.Bosh
             *  Create and initialize a Strophe.Bosh object.
             *
             *  Parameters:
             *    (Strophe.Connection) connection - The Strophe.Connection that will use BOSH.
             *
             *  Returns:
             *    A new Strophe.Bosh object.
             */

            Strophe.Bosh = class Bosh {
              constructor(connection) {
                this._conn = connection;
                /* request id for body tags */

                this.rid = Math.floor(Math.random() * 4294967295);
                /* The current session ID. */

                this.sid = null; // default BOSH values

                this.hold = 1;
                this.wait = 60;
                this.window = 5;
                this.errors = 0;
                this.inactivity = null;
                this.lastResponseHeaders = null;
                this._requests = [];
              }
              /** PrivateFunction: _buildBody
               *  _Private_ helper function to generate the <body/> wrapper for BOSH.
               *
               *  Returns:
               *    A Strophe.Builder with a <body/> element.
               */


              _buildBody() {
                const bodyWrap = $build('body', {
                  'rid': this.rid++,
                  'xmlns': Strophe.NS.HTTPBIND
                });

                if (this.sid !== null) {
                  bodyWrap.attrs({
                    'sid': this.sid
                  });
                }

                if (this._conn.options.keepalive && this._conn._sessionCachingSupported()) {
                  this._cacheSession();
                }

                return bodyWrap;
              }
              /** PrivateFunction: _reset
               *  Reset the connection.
               *
               *  This function is called by the reset function of the Strophe Connection
               */


              _reset() {
                this.rid = Math.floor(Math.random() * 4294967295);
                this.sid = null;
                this.errors = 0;

                if (this._conn._sessionCachingSupported()) {
                  window.sessionStorage.removeItem('strophe-bosh-session');
                }

                this._conn.nextValidRid(this.rid);
              }
              /** PrivateFunction: _connect
               *  _Private_ function that initializes the BOSH connection.
               *
               *  Creates and sends the Request that initializes the BOSH connection.
               */


              _connect(wait, hold, route) {
                this.wait = wait || this.wait;
                this.hold = hold || this.hold;
                this.errors = 0;

                const body = this._buildBody().attrs({
                  "to": this._conn.domain,
                  "xml:lang": "en",
                  "wait": this.wait,
                  "hold": this.hold,
                  "content": "text/xml; charset=utf-8",
                  "ver": "1.6",
                  "xmpp:version": "1.0",
                  "xmlns:xmpp": Strophe.NS.BOSH
                });

                if (route) {
                  body.attrs({
                    'route': route
                  });
                }

                const _connect_cb = this._conn._connect_cb;

                this._requests.push(new Strophe.Request(body.tree(), this._onRequestStateChange.bind(this, _connect_cb.bind(this._conn)), body.tree().getAttribute("rid")));

                this._throttledRequestHandler();
              }
              /** PrivateFunction: _attach
               *  Attach to an already created and authenticated BOSH session.
               *
               *  This function is provided to allow Strophe to attach to BOSH
               *  sessions which have been created externally, perhaps by a Web
               *  application.  This is often used to support auto-login type features
               *  without putting user credentials into the page.
               *
               *  Parameters:
               *    (String) jid - The full JID that is bound by the session.
               *    (String) sid - The SID of the BOSH session.
               *    (String) rid - The current RID of the BOSH session.  This RID
               *      will be used by the next request.
               *    (Function) callback The connect callback function.
               *    (Integer) wait - The optional HTTPBIND wait value.  This is the
               *      time the server will wait before returning an empty result for
               *      a request.  The default setting of 60 seconds is recommended.
               *      Other settings will require tweaks to the Strophe.TIMEOUT value.
               *    (Integer) hold - The optional HTTPBIND hold value.  This is the
               *      number of connections the server will hold at one time.  This
               *      should almost always be set to 1 (the default).
               *    (Integer) wind - The optional HTTBIND window value.  This is the
               *      allowed range of request ids that are valid.  The default is 5.
               */


              _attach(jid, sid, rid, callback, wait, hold, wind) {
                this._conn.jid = jid;
                this.sid = sid;
                this.rid = rid;
                this._conn.connect_callback = callback;
                this._conn.domain = Strophe.getDomainFromJid(this._conn.jid);
                this._conn.authenticated = true;
                this._conn.connected = true;
                this.wait = wait || this.wait;
                this.hold = hold || this.hold;
                this.window = wind || this.window;

                this._conn._changeConnectStatus(Strophe.Status.ATTACHED, null);
              }
              /** PrivateFunction: _restore
               *  Attempt to restore a cached BOSH session
               *
               *  Parameters:
               *    (String) jid - The full JID that is bound by the session.
               *      This parameter is optional but recommended, specifically in cases
               *      where prebinded BOSH sessions are used where it's important to know
               *      that the right session is being restored.
               *    (Function) callback The connect callback function.
               *    (Integer) wait - The optional HTTPBIND wait value.  This is the
               *      time the server will wait before returning an empty result for
               *      a request.  The default setting of 60 seconds is recommended.
               *      Other settings will require tweaks to the Strophe.TIMEOUT value.
               *    (Integer) hold - The optional HTTPBIND hold value.  This is the
               *      number of connections the server will hold at one time.  This
               *      should almost always be set to 1 (the default).
               *    (Integer) wind - The optional HTTBIND window value.  This is the
               *      allowed range of request ids that are valid.  The default is 5.
               */


              _restore(jid, callback, wait, hold, wind) {
                const session = JSON.parse(window.sessionStorage.getItem('strophe-bosh-session'));

                if (typeof session !== "undefined" && session !== null && session.rid && session.sid && session.jid && (typeof jid === "undefined" || jid === null || Strophe.getBareJidFromJid(session.jid) === Strophe.getBareJidFromJid(jid) || // If authcid is null, then it's an anonymous login, so
                // we compare only the domains:
                Strophe.getNodeFromJid(jid) === null && Strophe.getDomainFromJid(session.jid) === jid)) {
                  this._conn.restored = true;

                  this._attach(session.jid, session.sid, session.rid, callback, wait, hold, wind);
                } else {
                  const error = new Error("_restore: no restoreable session.");
                  error.name = "StropheSessionError";
                  throw error;
                }
              }
              /** PrivateFunction: _cacheSession
               *  _Private_ handler for the beforeunload event.
               *
               *  This handler is used to process the Bosh-part of the initial request.
               *  Parameters:
               *    (Strophe.Request) bodyWrap - The received stanza.
               */


              _cacheSession() {
                if (this._conn.authenticated) {
                  if (this._conn.jid && this.rid && this.sid) {
                    window.sessionStorage.setItem('strophe-bosh-session', JSON.stringify({
                      'jid': this._conn.jid,
                      'rid': this.rid,
                      'sid': this.sid
                    }));
                  }
                } else {
                  window.sessionStorage.removeItem('strophe-bosh-session');
                }
              }
              /** PrivateFunction: _connect_cb
               *  _Private_ handler for initial connection request.
               *
               *  This handler is used to process the Bosh-part of the initial request.
               *  Parameters:
               *    (Strophe.Request) bodyWrap - The received stanza.
               */


              _connect_cb(bodyWrap) {
                const typ = bodyWrap.getAttribute("type");

                if (typ !== null && typ === "terminate") {
                  // an error occurred
                  let cond = bodyWrap.getAttribute("condition");
                  Strophe.error("BOSH-Connection failed: " + cond);
                  const conflict = bodyWrap.getElementsByTagName("conflict");

                  if (cond !== null) {
                    if (cond === "remote-stream-error" && conflict.length > 0) {
                      cond = "conflict";
                    }

                    this._conn._changeConnectStatus(Strophe.Status.CONNFAIL, cond);
                  } else {
                    this._conn._changeConnectStatus(Strophe.Status.CONNFAIL, "unknown");
                  }

                  this._conn._doDisconnect(cond);

                  return Strophe.Status.CONNFAIL;
                } // check to make sure we don't overwrite these if _connect_cb is
                // called multiple times in the case of missing stream:features


                if (!this.sid) {
                  this.sid = bodyWrap.getAttribute("sid");
                }

                const wind = bodyWrap.getAttribute('requests');

                if (wind) {
                  this.window = parseInt(wind, 10);
                }

                const hold = bodyWrap.getAttribute('hold');

                if (hold) {
                  this.hold = parseInt(hold, 10);
                }

                const wait = bodyWrap.getAttribute('wait');

                if (wait) {
                  this.wait = parseInt(wait, 10);
                }

                const inactivity = bodyWrap.getAttribute('inactivity');

                if (inactivity) {
                  this.inactivity = parseInt(inactivity, 10);
                }
              }
              /** PrivateFunction: _disconnect
               *  _Private_ part of Connection.disconnect for Bosh
               *
               *  Parameters:
               *    (Request) pres - This stanza will be sent before disconnecting.
               */


              _disconnect(pres) {
                this._sendTerminate(pres);
              }
              /** PrivateFunction: _doDisconnect
               *  _Private_ function to disconnect.
               *
               *  Resets the SID and RID.
               */


              _doDisconnect() {
                this.sid = null;
                this.rid = Math.floor(Math.random() * 4294967295);

                if (this._conn._sessionCachingSupported()) {
                  window.sessionStorage.removeItem('strophe-bosh-session');
                }

                this._conn.nextValidRid(this.rid);
              }
              /** PrivateFunction: _emptyQueue
               * _Private_ function to check if the Request queue is empty.
               *
               *  Returns:
               *    True, if there are no Requests queued, False otherwise.
               */


              _emptyQueue() {
                return this._requests.length === 0;
              }
              /** PrivateFunction: _callProtocolErrorHandlers
               *  _Private_ function to call error handlers registered for HTTP errors.
               *
               *  Parameters:
               *    (Strophe.Request) req - The request that is changing readyState.
               */


              _callProtocolErrorHandlers(req) {
                const reqStatus = Bosh._getRequestStatus(req);

                const err_callback = this._conn.protocolErrorHandlers.HTTP[reqStatus];

                if (err_callback) {
                  err_callback.call(this, reqStatus);
                }
              }
              /** PrivateFunction: _hitError
               *  _Private_ function to handle the error count.
               *
               *  Requests are resent automatically until their error count reaches
               *  5.  Each time an error is encountered, this function is called to
               *  increment the count and disconnect if the count is too high.
               *
               *  Parameters:
               *    (Integer) reqStatus - The request status.
               */


              _hitError(reqStatus) {
                this.errors++;
                Strophe.warn("request errored, status: " + reqStatus + ", number of errors: " + this.errors);

                if (this.errors > 4) {
                  this._conn._onDisconnectTimeout();
                }
              }
              /** PrivateFunction: _no_auth_received
               *
               * Called on stream start/restart when no stream:features
               * has been received and sends a blank poll request.
               */


              _no_auth_received(callback) {
                Strophe.warn("Server did not yet offer a supported authentication " + "mechanism. Sending a blank poll request.");

                if (callback) {
                  callback = callback.bind(this._conn);
                } else {
                  callback = this._conn._connect_cb.bind(this._conn);
                }

                const body = this._buildBody();

                this._requests.push(new Strophe.Request(body.tree(), this._onRequestStateChange.bind(this, callback), body.tree().getAttribute("rid")));

                this._throttledRequestHandler();
              }
              /** PrivateFunction: _onDisconnectTimeout
               *  _Private_ timeout handler for handling non-graceful disconnection.
               *
               *  Cancels all remaining Requests and clears the queue.
               */


              _onDisconnectTimeout() {
                this._abortAllRequests();
              }
              /** PrivateFunction: _abortAllRequests
               *  _Private_ helper function that makes sure all pending requests are aborted.
               */


              _abortAllRequests() {
                while (this._requests.length > 0) {
                  const req = this._requests.pop();

                  req.abort = true;
                  req.xhr.abort();

                  req.xhr.onreadystatechange = function () {};
                }
              }
              /** PrivateFunction: _onIdle
               *  _Private_ handler called by Strophe.Connection._onIdle
               *
               *  Sends all queued Requests or polls with empty Request if there are none.
               */


              _onIdle() {
                const data = this._conn._data; // if no requests are in progress, poll

                if (this._conn.authenticated && this._requests.length === 0 && data.length === 0 && !this._conn.disconnecting) {
                  Strophe.debug("no requests during idle cycle, sending blank request");
                  data.push(null);
                }

                if (this._conn.paused) {
                  return;
                }

                if (this._requests.length < 2 && data.length > 0) {
                  const body = this._buildBody();

                  for (let i = 0; i < data.length; i++) {
                    if (data[i] !== null) {
                      if (data[i] === "restart") {
                        body.attrs({
                          "to": this._conn.domain,
                          "xml:lang": "en",
                          "xmpp:restart": "true",
                          "xmlns:xmpp": Strophe.NS.BOSH
                        });
                      } else {
                        body.cnode(data[i]).up();
                      }
                    }
                  }

                  delete this._conn._data;
                  this._conn._data = [];

                  this._requests.push(new Strophe.Request(body.tree(), this._onRequestStateChange.bind(this, this._conn._dataRecv.bind(this._conn)), body.tree().getAttribute("rid")));

                  this._throttledRequestHandler();
                }

                if (this._requests.length > 0) {
                  const time_elapsed = this._requests[0].age();

                  if (this._requests[0].dead !== null) {
                    if (this._requests[0].timeDead() > Math.floor(Strophe.SECONDARY_TIMEOUT * this.wait)) {
                      this._throttledRequestHandler();
                    }
                  }

                  if (time_elapsed > Math.floor(Strophe.TIMEOUT * this.wait)) {
                    Strophe.warn("Request " + this._requests[0].id + " timed out, over " + Math.floor(Strophe.TIMEOUT * this.wait) + " seconds since last activity");

                    this._throttledRequestHandler();
                  }
                }
              }
              /** PrivateFunction: _getRequestStatus
               *
               *  Returns the HTTP status code from a Strophe.Request
               *
               *  Parameters:
               *    (Strophe.Request) req - The Strophe.Request instance.
               *    (Integer) def - The default value that should be returned if no
               *          status value was found.
               */


              static _getRequestStatus(req, def) {
                let reqStatus;

                if (req.xhr.readyState === 4) {
                  try {
                    reqStatus = req.xhr.status;
                  } catch (e) {
                    // ignore errors from undefined status attribute. Works
                    // around a browser bug
                    Strophe.error("Caught an error while retrieving a request's status, " + "reqStatus: " + reqStatus);
                  }
                }

                if (typeof reqStatus === "undefined") {
                  reqStatus = typeof def === 'number' ? def : 0;
                }

                return reqStatus;
              }
              /** PrivateFunction: _onRequestStateChange
               *  _Private_ handler for Strophe.Request state changes.
               *
               *  This function is called when the XMLHttpRequest readyState changes.
               *  It contains a lot of error handling logic for the many ways that
               *  requests can fail, and calls the request callback when requests
               *  succeed.
               *
               *  Parameters:
               *    (Function) func - The handler for the request.
               *    (Strophe.Request) req - The request that is changing readyState.
               */


              _onRequestStateChange(func, req) {
                Strophe.debug("request id " + req.id + "." + req.sends + " state changed to " + req.xhr.readyState);

                if (req.abort) {
                  req.abort = false;
                  return;
                }

                if (req.xhr.readyState !== 4) {
                  // The request is not yet complete
                  return;
                }

                const reqStatus = Bosh._getRequestStatus(req);

                this.lastResponseHeaders = req.xhr.getAllResponseHeaders();

                if (this._conn.disconnecting && reqStatus >= 400) {
                  this._hitError(reqStatus);

                  this._callProtocolErrorHandlers(req);

                  return;
                }

                const reqIs0 = this._requests[0] === req;
                const reqIs1 = this._requests[1] === req;
                const valid_request = reqStatus > 0 && reqStatus < 500;
                const too_many_retries = req.sends > this._conn.maxRetries;

                if (valid_request || too_many_retries) {
                  // remove from internal queue
                  this._removeRequest(req);

                  Strophe.debug("request id " + req.id + " should now be removed");
                }

                if (reqStatus === 200) {
                  // request succeeded
                  // if request 1 finished, or request 0 finished and request
                  // 1 is over Strophe.SECONDARY_TIMEOUT seconds old, we need to
                  // restart the other - both will be in the first spot, as the
                  // completed request has been removed from the queue already
                  if (reqIs1 || reqIs0 && this._requests.length > 0 && this._requests[0].age() > Math.floor(Strophe.SECONDARY_TIMEOUT * this.wait)) {
                    this._restartRequest(0);
                  }

                  this._conn.nextValidRid(Number(req.rid) + 1);

                  Strophe.debug("request id " + req.id + "." + req.sends + " got 200");
                  func(req); // call handler

                  this.errors = 0;
                } else if (reqStatus === 0 || reqStatus >= 400 && reqStatus < 600 || reqStatus >= 12000) {
                  // request failed
                  Strophe.error("request id " + req.id + "." + req.sends + " error " + reqStatus + " happened");

                  this._hitError(reqStatus);

                  this._callProtocolErrorHandlers(req);

                  if (reqStatus >= 400 && reqStatus < 500) {
                    this._conn._changeConnectStatus(Strophe.Status.DISCONNECTING, null);

                    this._conn._doDisconnect();
                  }
                } else {
                  Strophe.error("request id " + req.id + "." + req.sends + " error " + reqStatus + " happened");
                }

                if (!valid_request && !too_many_retries) {
                  this._throttledRequestHandler();
                } else if (too_many_retries && !this._conn.connected) {
                  this._conn._changeConnectStatus(Strophe.Status.CONNFAIL, "giving-up");
                }
              }
              /** PrivateFunction: _processRequest
               *  _Private_ function to process a request in the queue.
               *
               *  This function takes requests off the queue and sends them and
               *  restarts dead requests.
               *
               *  Parameters:
               *    (Integer) i - The index of the request in the queue.
               */


              _processRequest(i) {
                let req = this._requests[i];

                const reqStatus = Bosh._getRequestStatus(req, -1); // make sure we limit the number of retries


                if (req.sends > this._conn.maxRetries) {
                  this._conn._onDisconnectTimeout();

                  return;
                }

                const time_elapsed = req.age();
                const primary_timeout = !isNaN(time_elapsed) && time_elapsed > Math.floor(Strophe.TIMEOUT * this.wait);
                const secondary_timeout = req.dead !== null && req.timeDead() > Math.floor(Strophe.SECONDARY_TIMEOUT * this.wait);
                const server_error = req.xhr.readyState === 4 && (reqStatus < 1 || reqStatus >= 500);

                if (primary_timeout || secondary_timeout || server_error) {
                  if (secondary_timeout) {
                    Strophe.error(`Request ${this._requests[i].id} timed out (secondary), restarting`);
                  }

                  req.abort = true;
                  req.xhr.abort(); // setting to null fails on IE6, so set to empty function

                  req.xhr.onreadystatechange = function () {};

                  this._requests[i] = new Strophe.Request(req.xmlData, req.origFunc, req.rid, req.sends);
                  req = this._requests[i];
                }

                if (req.xhr.readyState === 0) {
                  Strophe.debug("request id " + req.id + "." + req.sends + " posting");

                  try {
                    const content_type = this._conn.options.contentType || "text/xml; charset=utf-8";
                    req.xhr.open("POST", this._conn.service, this._conn.options.sync ? false : true);

                    if (typeof req.xhr.setRequestHeader !== 'undefined') {
                      // IE9 doesn't have setRequestHeader
                      req.xhr.setRequestHeader("Content-Type", content_type);
                    }

                    if (this._conn.options.withCredentials) {
                      req.xhr.withCredentials = true;
                    }
                  } catch (e2) {
                    Strophe.error("XHR open failed: " + e2.toString());

                    if (!this._conn.connected) {
                      this._conn._changeConnectStatus(Strophe.Status.CONNFAIL, "bad-service");
                    }

                    this._conn.disconnect();

                    return;
                  } // Fires the XHR request -- may be invoked immediately
                  // or on a gradually expanding retry window for reconnects


                  const sendFunc = () => {
                    req.date = new Date();

                    if (this._conn.options.customHeaders) {
                      const headers = this._conn.options.customHeaders;

                      for (const header in headers) {
                        if (Object.prototype.hasOwnProperty.call(headers, header)) {
                          req.xhr.setRequestHeader(header, headers[header]);
                        }
                      }
                    }

                    req.xhr.send(req.data);
                  }; // Implement progressive backoff for reconnects --
                  // First retry (send === 1) should also be instantaneous


                  if (req.sends > 1) {
                    // Using a cube of the retry number creates a nicely
                    // expanding retry window
                    const backoff = Math.min(Math.floor(Strophe.TIMEOUT * this.wait), Math.pow(req.sends, 3)) * 1000;
                    setTimeout(function () {
                      // XXX: setTimeout should be called only with function expressions (23974bc1)
                      sendFunc();
                    }, backoff);
                  } else {
                    sendFunc();
                  }

                  req.sends++;

                  if (this._conn.xmlOutput !== Strophe.Connection.prototype.xmlOutput) {
                    if (req.xmlData.nodeName === this.strip && req.xmlData.childNodes.length) {
                      this._conn.xmlOutput(req.xmlData.childNodes[0]);
                    } else {
                      this._conn.xmlOutput(req.xmlData);
                    }
                  }

                  if (this._conn.rawOutput !== Strophe.Connection.prototype.rawOutput) {
                    this._conn.rawOutput(req.data);
                  }
                } else {
                  Strophe.debug("_processRequest: " + (i === 0 ? "first" : "second") + " request has readyState of " + req.xhr.readyState);
                }
              }
              /** PrivateFunction: _removeRequest
               *  _Private_ function to remove a request from the queue.
               *
               *  Parameters:
               *    (Strophe.Request) req - The request to remove.
               */


              _removeRequest(req) {
                Strophe.debug("removing request");

                for (let i = this._requests.length - 1; i >= 0; i--) {
                  if (req === this._requests[i]) {
                    this._requests.splice(i, 1);
                  }
                } // IE6 fails on setting to null, so set to empty function


                req.xhr.onreadystatechange = function () {};

                this._throttledRequestHandler();
              }
              /** PrivateFunction: _restartRequest
               *  _Private_ function to restart a request that is presumed dead.
               *
               *  Parameters:
               *    (Integer) i - The index of the request in the queue.
               */


              _restartRequest(i) {
                const req = this._requests[i];

                if (req.dead === null) {
                  req.dead = new Date();
                }

                this._processRequest(i);
              }
              /** PrivateFunction: _reqToData
               * _Private_ function to get a stanza out of a request.
               *
               * Tries to extract a stanza out of a Request Object.
               * When this fails the current connection will be disconnected.
               *
               *  Parameters:
               *    (Object) req - The Request.
               *
               *  Returns:
               *    The stanza that was passed.
               */


              _reqToData(req) {
                try {
                  return req.getResponse();
                } catch (e) {
                  if (e.message !== "parsererror") {
                    throw e;
                  }

                  this._conn.disconnect("strophe-parsererror");
                }
              }
              /** PrivateFunction: _sendTerminate
               *  _Private_ function to send initial disconnect sequence.
               *
               *  This is the first step in a graceful disconnect.  It sends
               *  the BOSH server a terminate body and includes an unavailable
               *  presence if authentication has completed.
               */


              _sendTerminate(pres) {
                Strophe.debug("_sendTerminate was called");

                const body = this._buildBody().attrs({
                  type: "terminate"
                });

                if (pres) {
                  body.cnode(pres.tree());
                }

                const req = new Strophe.Request(body.tree(), this._onRequestStateChange.bind(this, this._conn._dataRecv.bind(this._conn)), body.tree().getAttribute("rid"));

                this._requests.push(req);

                this._throttledRequestHandler();
              }
              /** PrivateFunction: _send
               *  _Private_ part of the Connection.send function for BOSH
               *
               * Just triggers the RequestHandler to send the messages that are in the queue
               */


              _send() {
                clearTimeout(this._conn._idleTimeout);

                this._throttledRequestHandler();

                this._conn._idleTimeout = setTimeout(() => this._conn._onIdle(), 100);
              }
              /** PrivateFunction: _sendRestart
               *
               *  Send an xmpp:restart stanza.
               */


              _sendRestart() {
                this._throttledRequestHandler();

                clearTimeout(this._conn._idleTimeout);
              }
              /** PrivateFunction: _throttledRequestHandler
               *  _Private_ function to throttle requests to the connection window.
               *
               *  This function makes sure we don't send requests so fast that the
               *  request ids overflow the connection window in the case that one
               *  request died.
               */


              _throttledRequestHandler() {
                if (!this._requests) {
                  Strophe.debug("_throttledRequestHandler called with " + "undefined requests");
                } else {
                  Strophe.debug("_throttledRequestHandler called with " + this._requests.length + " requests");
                }

                if (!this._requests || this._requests.length === 0) {
                  return;
                }

                if (this._requests.length > 0) {
                  this._processRequest(0);
                }

                if (this._requests.length > 1 && Math.abs(this._requests[0].rid - this._requests[1].rid) < this.window) {
                  this._processRequest(1);
                }
              }

            };
            /** Variable: strip
             *
             *  BOSH-Connections will have all stanzas wrapped in a <body> tag when
             *  passed to <Strophe.Connection.xmlInput> or <Strophe.Connection.xmlOutput>.
             *  To strip this tag, User code can set <Strophe.Bosh.strip> to "body":
             *
             *  > Strophe.Bosh.prototype.strip = "body";
             *
             *  This will enable stripping of the body tag in both
             *  <Strophe.Connection.xmlInput> and <Strophe.Connection.xmlOutput>.
             */

            Strophe.Bosh.prototype.strip = null;

            /*
                This program is distributed under the terms of the MIT license.
                Please see the LICENSE file for details.

                Copyright 2006-2008, OGG, LLC
            */
            /** Class: Strophe.WebSocket
             *  _Private_ helper class that handles WebSocket Connections
             *
             *  The Strophe.WebSocket class is used internally by Strophe.Connection
             *  to encapsulate WebSocket sessions. It is not meant to be used from user's code.
             */

            /** File: websocket.js
             *  A JavaScript library to enable XMPP over Websocket in Strophejs.
             *
             *  This file implements XMPP over WebSockets for Strophejs.
             *  If a Connection is established with a Websocket url (ws://...)
             *  Strophe will use WebSockets.
             *  For more information on XMPP-over-WebSocket see RFC 7395:
             *  http://tools.ietf.org/html/rfc7395
             *
             *  WebSocket support implemented by Andreas Guth (andreas.guth@rwth-aachen.de)
             */

            Strophe.Websocket = class Websocket {
              /** PrivateConstructor: Strophe.Websocket
               *  Create and initialize a Strophe.WebSocket object.
               *  Currently only sets the connection Object.
               *
               *  Parameters:
               *    (Strophe.Connection) connection - The Strophe.Connection that will use WebSockets.
               *
               *  Returns:
               *    A new Strophe.WebSocket object.
               */
              constructor(connection) {
                this._conn = connection;
                this.strip = "wrapper";
                const service = connection.service;

                if (service.indexOf("ws:") !== 0 && service.indexOf("wss:") !== 0) {
                  // If the service is not an absolute URL, assume it is a path and put the absolute
                  // URL together from options, current URL and the path.
                  let new_service = "";

                  if (connection.options.protocol === "ws" && window.location.protocol !== "https:") {
                    new_service += "ws";
                  } else {
                    new_service += "wss";
                  }

                  new_service += "://" + window.location.host;

                  if (service.indexOf("/") !== 0) {
                    new_service += window.location.pathname + service;
                  } else {
                    new_service += service;
                  }

                  connection.service = new_service;
                }
              }
              /** PrivateFunction: _buildStream
               *  _Private_ helper function to generate the <stream> start tag for WebSockets
               *
               *  Returns:
               *    A Strophe.Builder with a <stream> element.
               */


              _buildStream() {
                return $build("open", {
                  "xmlns": Strophe.NS.FRAMING,
                  "to": this._conn.domain,
                  "version": '1.0'
                });
              }
              /** PrivateFunction: _checkStreamError
               * _Private_ checks a message for stream:error
               *
               *  Parameters:
               *    (Strophe.Request) bodyWrap - The received stanza.
               *    connectstatus - The ConnectStatus that will be set on error.
               *  Returns:
               *     true if there was a streamerror, false otherwise.
               */


              _checkStreamError(bodyWrap, connectstatus) {
                let errors;

                if (bodyWrap.getElementsByTagNameNS) {
                  errors = bodyWrap.getElementsByTagNameNS(Strophe.NS.STREAM, "error");
                } else {
                  errors = bodyWrap.getElementsByTagName("stream:error");
                }

                if (errors.length === 0) {
                  return false;
                }

                const error = errors[0];
                let condition = "";
                let text = "";
                const ns = "urn:ietf:params:xml:ns:xmpp-streams";

                for (let i = 0; i < error.childNodes.length; i++) {
                  const e = error.childNodes[i];

                  if (e.getAttribute("xmlns") !== ns) {
                    break;
                  }

                  if (e.nodeName === "text") {
                    text = e.textContent;
                  } else {
                    condition = e.nodeName;
                  }
                }

                let errorString = "WebSocket stream error: ";

                if (condition) {
                  errorString += condition;
                } else {
                  errorString += "unknown";
                }

                if (text) {
                  errorString += " - " + text;
                }

                Strophe.error(errorString); // close the connection on stream_error

                this._conn._changeConnectStatus(connectstatus, condition);

                this._conn._doDisconnect();

                return true;
              }
              /** PrivateFunction: _reset
               *  Reset the connection.
               *
               *  This function is called by the reset function of the Strophe Connection.
               *  Is not needed by WebSockets.
               */


              _reset() {
                // eslint-disable-line class-methods-use-this
                return;
              }
              /** PrivateFunction: _connect
               *  _Private_ function called by Strophe.Connection.connect
               *
               *  Creates a WebSocket for a connection and assigns Callbacks to it.
               *  Does nothing if there already is a WebSocket.
               */


              _connect() {
                // Ensure that there is no open WebSocket from a previous Connection.
                this._closeSocket();

                this.socket = new WebSocket(this._conn.service, "xmpp");

                this.socket.onopen = () => this._onOpen();

                this.socket.onerror = e => this._onError(e);

                this.socket.onclose = e => this._onClose(e); // Gets replaced with this._onMessage once _onInitialMessage is called


                this.socket.onmessage = message => this._onInitialMessage(message);
              }
              /** PrivateFunction: _connect_cb
               *  _Private_ function called by Strophe.Connection._connect_cb
               *
               * checks for stream:error
               *
               *  Parameters:
               *    (Strophe.Request) bodyWrap - The received stanza.
               */


              _connect_cb(bodyWrap) {
                const error = this._checkStreamError(bodyWrap, Strophe.Status.CONNFAIL);

                if (error) {
                  return Strophe.Status.CONNFAIL;
                }
              }
              /** PrivateFunction: _handleStreamStart
               * _Private_ function that checks the opening <open /> tag for errors.
               *
               * Disconnects if there is an error and returns false, true otherwise.
               *
               *  Parameters:
               *    (Node) message - Stanza containing the <open /> tag.
               */


              _handleStreamStart(message) {
                let error = false; // Check for errors in the <open /> tag

                const ns = message.getAttribute("xmlns");

                if (typeof ns !== "string") {
                  error = "Missing xmlns in <open />";
                } else if (ns !== Strophe.NS.FRAMING) {
                  error = "Wrong xmlns in <open />: " + ns;
                }

                const ver = message.getAttribute("version");

                if (typeof ver !== "string") {
                  error = "Missing version in <open />";
                } else if (ver !== "1.0") {
                  error = "Wrong version in <open />: " + ver;
                }

                if (error) {
                  this._conn._changeConnectStatus(Strophe.Status.CONNFAIL, error);

                  this._conn._doDisconnect();

                  return false;
                }

                return true;
              }
              /** PrivateFunction: _onInitialMessage
               * _Private_ function that handles the first connection messages.
               *
               * On receiving an opening stream tag this callback replaces itself with the real
               * message handler. On receiving a stream error the connection is terminated.
               */


              _onInitialMessage(message) {
                if (message.data.indexOf("<open ") === 0 || message.data.indexOf("<?xml") === 0) {
                  // Strip the XML Declaration, if there is one
                  const data = message.data.replace(/^(<\?.*?\?>\s*)*/, "");
                  if (data === '') return;
                  const streamStart = new DOMParser().parseFromString(data, "text/xml").documentElement;

                  this._conn.xmlInput(streamStart);

                  this._conn.rawInput(message.data); //_handleStreamSteart will check for XML errors and disconnect on error


                  if (this._handleStreamStart(streamStart)) {
                    //_connect_cb will check for stream:error and disconnect on error
                    this._connect_cb(streamStart);
                  }
                } else if (message.data.indexOf("<close ") === 0) {
                  // <close xmlns="urn:ietf:params:xml:ns:xmpp-framing />
                  // Parse the raw string to an XML element
                  const parsedMessage = new DOMParser().parseFromString(message.data, "text/xml").documentElement; // Report this input to the raw and xml handlers

                  this._conn.xmlInput(parsedMessage);

                  this._conn.rawInput(message.data);

                  const see_uri = parsedMessage.getAttribute("see-other-uri");

                  if (see_uri) {
                    const service = this._conn.service; // Valid scenarios: WSS->WSS, WS->ANY

                    const isSecureRedirect = service.indexOf("wss:") >= 0 && see_uri.indexOf("wss:") >= 0 || service.indexOf("ws:") >= 0;

                    if (isSecureRedirect) {
                      this._conn._changeConnectStatus(Strophe.Status.REDIRECT, "Received see-other-uri, resetting connection");

                      this._conn.reset();

                      this._conn.service = see_uri;

                      this._connect();
                    }
                  } else {
                    this._conn._changeConnectStatus(Strophe.Status.CONNFAIL, "Received closing stream");

                    this._conn._doDisconnect();
                  }
                } else {
                  this._replaceMessageHandler();

                  const string = this._streamWrap(message.data);

                  const elem = new DOMParser().parseFromString(string, "text/xml").documentElement;

                  this._conn._connect_cb(elem, null, message.data);
                }
              }
              /** PrivateFunction: _replaceMessageHandler
               *
               * Called by _onInitialMessage in order to replace itself with the general message handler.
               * This method is overridden by Strophe.WorkerWebsocket, which manages a
               * websocket connection via a service worker and doesn't have direct access
               * to the socket.
               */


              _replaceMessageHandler() {
                this.socket.onmessage = m => this._onMessage(m);
              }
              /** PrivateFunction: _disconnect
               *  _Private_ function called by Strophe.Connection.disconnect
               *
               *  Disconnects and sends a last stanza if one is given
               *
               *  Parameters:
               *    (Request) pres - This stanza will be sent before disconnecting.
               */


              _disconnect(pres) {
                if (this.socket && this.socket.readyState !== WebSocket.CLOSED) {
                  if (pres) {
                    this._conn.send(pres);
                  }

                  const close = $build("close", {
                    "xmlns": Strophe.NS.FRAMING
                  });

                  this._conn.xmlOutput(close.tree());

                  const closeString = Strophe.serialize(close);

                  this._conn.rawOutput(closeString);

                  try {
                    this.socket.send(closeString);
                  } catch (e) {
                    Strophe.warn("Couldn't send <close /> tag.");
                  }
                }

                setTimeout(() => this._conn._doDisconnect, 0);
              }
              /** PrivateFunction: _doDisconnect
               *  _Private_ function to disconnect.
               *
               *  Just closes the Socket for WebSockets
               */


              _doDisconnect() {
                Strophe.debug("WebSockets _doDisconnect was called");

                this._closeSocket();
              }
              /** PrivateFunction _streamWrap
               *  _Private_ helper function to wrap a stanza in a <stream> tag.
               *  This is used so Strophe can process stanzas from WebSockets like BOSH
               */


              _streamWrap(stanza) {
                // eslint-disable-line class-methods-use-this
                return "<wrapper>" + stanza + '</wrapper>';
              }
              /** PrivateFunction: _closeSocket
               *  _Private_ function to close the WebSocket.
               *
               *  Closes the socket if it is still open and deletes it
               */


              _closeSocket() {
                if (this.socket) {
                  try {
                    this.socket.onclose = null;
                    this.socket.onerror = null;
                    this.socket.onmessage = null;
                    this.socket.close();
                  } catch (e) {
                    Strophe.debug(e.message);
                  }
                }

                this.socket = null;
              }
              /** PrivateFunction: _emptyQueue
               * _Private_ function to check if the message queue is empty.
               *
               *  Returns:
               *    True, because WebSocket messages are send immediately after queueing.
               */


              _emptyQueue() {
                // eslint-disable-line class-methods-use-this
                return true;
              }
              /** PrivateFunction: _onClose
               * _Private_ function to handle websockets closing.
               */


              _onClose(e) {
                if (this._conn.connected && !this._conn.disconnecting) {
                  Strophe.error("Websocket closed unexpectedly");

                  this._conn._doDisconnect();
                } else if (e && e.code === 1006 && !this._conn.connected && this.socket) {
                  // in case the onError callback was not called (Safari 10 does not
                  // call onerror when the initial connection fails) we need to
                  // dispatch a CONNFAIL status update to be consistent with the
                  // behavior on other browsers.
                  Strophe.error("Websocket closed unexcectedly");

                  this._conn._changeConnectStatus(Strophe.Status.CONNFAIL, "The WebSocket connection could not be established or was disconnected.");

                  this._conn._doDisconnect();
                } else {
                  Strophe.debug("Websocket closed");
                }
              }
              /** PrivateFunction: _no_auth_received
               *
               * Called on stream start/restart when no stream:features
               * has been received.
               */


              _no_auth_received(callback) {
                Strophe.error("Server did not offer a supported authentication mechanism");

                this._conn._changeConnectStatus(Strophe.Status.CONNFAIL, Strophe.ErrorCondition.NO_AUTH_MECH);

                if (callback) {
                  callback.call(this._conn);
                }

                this._conn._doDisconnect();
              }
              /** PrivateFunction: _onDisconnectTimeout
               *  _Private_ timeout handler for handling non-graceful disconnection.
               *
               *  This does nothing for WebSockets
               */


              _onDisconnectTimeout() {} // eslint-disable-line class-methods-use-this

              /** PrivateFunction: _abortAllRequests
               *  _Private_ helper function that makes sure all pending requests are aborted.
               */


              _abortAllRequests() {} // eslint-disable-line class-methods-use-this

              /** PrivateFunction: _onError
               * _Private_ function to handle websockets errors.
               *
               * Parameters:
               * (Object) error - The websocket error.
               */


              _onError(error) {
                Strophe.error("Websocket error " + JSON.stringify(error));

                this._conn._changeConnectStatus(Strophe.Status.CONNFAIL, "The WebSocket connection could not be established or was disconnected.");

                this._disconnect();
              }
              /** PrivateFunction: _onIdle
               *  _Private_ function called by Strophe.Connection._onIdle
               *
               *  sends all queued stanzas
               */


              _onIdle() {
                const data = this._conn._data;

                if (data.length > 0 && !this._conn.paused) {
                  for (let i = 0; i < data.length; i++) {
                    if (data[i] !== null) {
                      let stanza;

                      if (data[i] === "restart") {
                        stanza = this._buildStream().tree();
                      } else {
                        stanza = data[i];
                      }

                      const rawStanza = Strophe.serialize(stanza);

                      this._conn.xmlOutput(stanza);

                      this._conn.rawOutput(rawStanza);

                      this.socket.send(rawStanza);
                    }
                  }

                  this._conn._data = [];
                }
              }
              /** PrivateFunction: _onMessage
               * _Private_ function to handle websockets messages.
               *
               * This function parses each of the messages as if they are full documents.
               * [TODO : We may actually want to use a SAX Push parser].
               *
               * Since all XMPP traffic starts with
               *  <stream:stream version='1.0'
               *                 xml:lang='en'
               *                 xmlns='jabber:client'
               *                 xmlns:stream='http://etherx.jabber.org/streams'
               *                 id='3697395463'
               *                 from='SERVER'>
               *
               * The first stanza will always fail to be parsed.
               *
               * Additionally, the seconds stanza will always be <stream:features> with
               * the stream NS defined in the previous stanza, so we need to 'force'
               * the inclusion of the NS in this stanza.
               *
               * Parameters:
               * (string) message - The websocket message.
               */


              _onMessage(message) {
                let elem; // check for closing stream

                const close = '<close xmlns="urn:ietf:params:xml:ns:xmpp-framing" />';

                if (message.data === close) {
                  this._conn.rawInput(close);

                  this._conn.xmlInput(message);

                  if (!this._conn.disconnecting) {
                    this._conn._doDisconnect();
                  }

                  return;
                } else if (message.data.search("<open ") === 0) {
                  // This handles stream restarts
                  elem = new DOMParser().parseFromString(message.data, "text/xml").documentElement;

                  if (!this._handleStreamStart(elem)) {
                    return;
                  }
                } else {
                  const data = this._streamWrap(message.data);

                  elem = new DOMParser().parseFromString(data, "text/xml").documentElement;
                }

                if (this._checkStreamError(elem, Strophe.Status.ERROR)) {
                  return;
                } //handle unavailable presence stanza before disconnecting


                if (this._conn.disconnecting && elem.firstChild.nodeName === "presence" && elem.firstChild.getAttribute("type") === "unavailable") {
                  this._conn.xmlInput(elem);

                  this._conn.rawInput(Strophe.serialize(elem)); // if we are already disconnecting we will ignore the unavailable stanza and
                  // wait for the </stream:stream> tag before we close the connection


                  return;
                }

                this._conn._dataRecv(elem, message.data);
              }
              /** PrivateFunction: _onOpen
               * _Private_ function to handle websockets connection setup.
               *
               * The opening stream tag is sent here.
               */


              _onOpen() {
                Strophe.debug("Websocket open");

                const start = this._buildStream();

                this._conn.xmlOutput(start.tree());

                const startString = Strophe.serialize(start);

                this._conn.rawOutput(startString);

                this.socket.send(startString);
              }
              /** PrivateFunction: _reqToData
               * _Private_ function to get a stanza out of a request.
               *
               * WebSockets don't use requests, so the passed argument is just returned.
               *
               *  Parameters:
               *    (Object) stanza - The stanza.
               *
               *  Returns:
               *    The stanza that was passed.
               */


              _reqToData(stanza) {
                // eslint-disable-line class-methods-use-this
                return stanza;
              }
              /** PrivateFunction: _send
               *  _Private_ part of the Connection.send function for WebSocket
               *
               * Just flushes the messages that are in the queue
               */


              _send() {
                this._conn.flush();
              }
              /** PrivateFunction: _sendRestart
               *
               *  Send an xmpp:restart stanza.
               */


              _sendRestart() {
                clearTimeout(this._conn._idleTimeout);

                this._conn._onIdle.bind(this._conn)();
              }

            };

            /*
                This program is distributed under the terms of the MIT license.
                Please see the LICENSE file for details.

                Copyright 2020, JC Brand
            */
            const lmap = {};
            lmap['debug'] = Strophe.LogLevel.DEBUG;
            lmap['info'] = Strophe.LogLevel.INFO;
            lmap['warn'] = Strophe.LogLevel.WARN;
            lmap['error'] = Strophe.LogLevel.ERROR;
            lmap['fatal'] = Strophe.LogLevel.FATAL;
            /** Class: Strophe.WorkerWebsocket
             *  _Private_ helper class that handles a websocket connection inside a shared worker.
             */

            Strophe.WorkerWebsocket = class WorkerWebsocket extends Strophe.Websocket {
              /** PrivateConstructor: Strophe.WorkerWebsocket
               *  Create and initialize a Strophe.WorkerWebsocket object.
               *
               *  Parameters:
               *    (Strophe.Connection) connection - The Strophe.Connection
               *
               *  Returns:
               *    A new Strophe.WorkerWebsocket object.
               */
              constructor(connection) {
                super(connection);
                this._conn = connection;
                this.worker = new SharedWorker(this._conn.options.worker, 'Strophe XMPP Connection');

                this.worker.onerror = e => {
                  var _console;

                  (_console = console) === null || _console === void 0 ? void 0 : _console.error(e);
                  Strophe.log(Strophe.LogLevel.ERROR, `Shared Worker Error: ${e}`);
                };
              }

              get socket() {
                return {
                  'send': str => this.worker.port.postMessage(['send', str])
                };
              }

              _connect() {
                this._messageHandler = m => this._onInitialMessage(m);

                this.worker.port.start();

                this.worker.port.onmessage = ev => this._onWorkerMessage(ev);

                this.worker.port.postMessage(['_connect', this._conn.service, this._conn.jid]);
              }

              _attach(callback) {
                this._messageHandler = m => this._onMessage(m);

                this._conn.connect_callback = callback;
                this.worker.port.start();

                this.worker.port.onmessage = ev => this._onWorkerMessage(ev);

                this.worker.port.postMessage(['_attach', this._conn.service]);
              }

              _attachCallback(status, jid) {
                if (status === Strophe.Status.ATTACHED) {
                  this._conn.jid = jid;
                  this._conn.authenticated = true;
                  this._conn.connected = true;
                  this._conn.restored = true;

                  this._conn._changeConnectStatus(Strophe.Status.ATTACHED);
                } else if (status === Strophe.Status.ATTACHFAIL) {
                  this._conn.authenticated = false;
                  this._conn.connected = false;
                  this._conn.restored = false;

                  this._conn._changeConnectStatus(Strophe.Status.ATTACHFAIL);
                }
              }

              _disconnect(readyState, pres) {
                pres && this._conn.send(pres);
                const close = $build("close", {
                  "xmlns": Strophe.NS.FRAMING
                });

                this._conn.xmlOutput(close.tree());

                const closeString = Strophe.serialize(close);

                this._conn.rawOutput(closeString);

                this.worker.port.postMessage(['send', closeString]);

                this._conn._doDisconnect();
              }

              _onClose(e) {
                if (this._conn.connected && !this._conn.disconnecting) {
                  Strophe.error("Websocket closed unexpectedly");

                  this._conn._doDisconnect();
                } else if (e && e.code === 1006 && !this._conn.connected) {
                  // in case the onError callback was not called (Safari 10 does not
                  // call onerror when the initial connection fails) we need to
                  // dispatch a CONNFAIL status update to be consistent with the
                  // behavior on other browsers.
                  Strophe.error("Websocket closed unexcectedly");

                  this._conn._changeConnectStatus(Strophe.Status.CONNFAIL, "The WebSocket connection could not be established or was disconnected.");

                  this._conn._doDisconnect();
                } else {
                  Strophe.debug("Websocket closed");
                }
              }

              _closeSocket() {
                this.worker.port.postMessage(['_closeSocket']);
              }
              /** PrivateFunction: _replaceMessageHandler
               *
               * Called by _onInitialMessage in order to replace itself with the general message handler.
               * This method is overridden by Strophe.WorkerWebsocket, which manages a
               * websocket connection via a service worker and doesn't have direct access
               * to the socket.
               */


              _replaceMessageHandler() {
                this._messageHandler = m => this._onMessage(m);
              }
              /** PrivateFunction: _onWorkerMessage
               * _Private_ function that handles messages received from the service worker
               */


              _onWorkerMessage(ev) {
                const {
                  data
                } = ev;
                const method_name = data[0];

                if (method_name === '_onMessage') {
                  this._messageHandler(data[1]);
                } else if (method_name in this) {
                  try {
                    this[method_name].apply(this, ev.data.slice(1));
                  } catch (e) {
                    Strophe.log(Strophe.LogLevel.ERROR, e);
                  }
                } else if (method_name === 'log') {
                  const level = data[1];
                  const msg = data[2];
                  Strophe.log(lmap[level], msg);
                } else {
                  Strophe.log(Strophe.LogLevel.ERROR, `Found unhandled service worker message: ${data}`);
                }
              }

            };

            global$1.$build = core.$build;
            global$1.$iq = core.$iq;
            global$1.$msg = core.$msg;
            global$1.$pres = core.$pres;
            global$1.Strophe = core.Strophe;
            const {
              b64_sha1
            } = SHA1;

            exports.$build = $build;
            exports.$iq = $iq;
            exports.$msg = $msg;
            exports.$pres = $pres;
            exports.Strophe = Strophe;
            exports.b64_sha1 = b64_sha1;

            Object.defineProperty(exports, '__esModule', { value: true });

}));


/***/ }),

/***/ "./node_modules/strophejs-plugin-disco/lib/strophe.disco.js":
/*!******************************************************************!*\
  !*** ./node_modules/strophejs-plugin-disco/lib/strophe.disco.js ***!
  \******************************************************************/
/***/ (function(__unused_webpack_module, __unused_webpack_exports, __webpack_require__) {

(function (global, factory) {
	 true ? factory(__webpack_require__(/*! strophe.js */ "./node_modules/strophe.js/dist/strophe.umd.js")) :
	0;
}(this, (function (strophe_js) { 'use strict';

strophe_js.Strophe.addConnectionPlugin('disco',
{
    _connection: null,
    _identities : [],
    _features : [],
    _items : [],
    /** Function: init
     * Plugin init
     *
     * Parameters:
     *   (Strophe.Connection) conn - Strophe connection
     */
    init: function(conn)
    {
    this._connection = conn;
        this._identities = [];
        this._features   = [];
        this._items      = [];
        // disco info
        conn.addHandler(this._onDiscoInfo.bind(this), strophe_js.Strophe.NS.DISCO_INFO, 'iq', 'get', null, null);
        // disco items
        conn.addHandler(this._onDiscoItems.bind(this), strophe_js.Strophe.NS.DISCO_ITEMS, 'iq', 'get', null, null);
    },
    /** Function: addIdentity
     * See http://xmpp.org/registrar/disco-categories.html
     * Parameters:
     *   (String) category - category of identity (like client, automation, etc ...)
     *   (String) type - type of identity (like pc, web, bot , etc ...)
     *   (String) name - name of identity in natural language
     *   (String) lang - lang of name parameter
     *
     * Returns:
     *   Boolean
     */
    addIdentity: function(category, type, name, lang)
    {
        for (var i=0; i<this._identities.length; i++)
        {
            if (this._identities[i].category == category &&
                this._identities[i].type == type &&
                this._identities[i].name == name &&
                this._identities[i].lang == lang)
            {
                return false;
            }
        }
        this._identities.push({category: category, type: type, name: name, lang: lang});
        return true;
    },
    /** Function: addFeature
     *
     * Parameters:
     *   (String) var_name - feature name (like jabber:iq:version)
     *
     * Returns:
     *   boolean
     */
    addFeature: function(var_name)
    {
        for (var i=0; i<this._features.length; i++)
        {
             if (this._features[i] == var_name)
                 return false;
        }
        this._features.push(var_name);
        return true;
    },
    /** Function: removeFeature
     *
     * Parameters:
     *   (String) var_name - feature name (like jabber:iq:version)
     *
     * Returns:
     *   boolean
     */
    removeFeature: function(var_name)
    {
        for (var i=0; i<this._features.length; i++)
        {
             if (this._features[i] === var_name){
                 this._features.splice(i,1);
                 return true;
             }
        }
        return false;
    },
    /** Function: addItem
     *
     * Parameters:
     *   (String) jid
     *   (String) name
     *   (String) node
     *   (Function) call_back
     *
     * Returns:
     *   boolean
     */
    addItem: function(jid, name, node, call_back)
    {
        if (node && !call_back)
            return false;
        this._items.push({jid: jid, name: name, node: node, call_back: call_back});
        return true;
    },
    /** Function: info
     * Info query
     *
     * Parameters:
     *   (Function) call_back
     *   (String) jid
     *   (String) node
     */
    info: function(jid, node, success, error, timeout)
    {
        var attrs = {xmlns: strophe_js.Strophe.NS.DISCO_INFO};
        if (node)
            attrs.node = node;

        var info = strophe_js.$iq({from:this._connection.jid,
                         to:jid, type:'get'}).c('query', attrs);
        this._connection.sendIQ(info, success, error, timeout);
    },
    /** Function: items
     * Items query
     *
     * Parameters:
     *   (Function) call_back
     *   (String) jid
     *   (String) node
     */
    items: function(jid, node, success, error, timeout)
    {
        var attrs = {xmlns: strophe_js.Strophe.NS.DISCO_ITEMS};
        if (node)
            attrs.node = node;

        var items = strophe_js.$iq({from:this._connection.jid,
                         to:jid, type:'get'}).c('query', attrs);
        this._connection.sendIQ(items, success, error, timeout);
    },

    /** PrivateFunction: _buildIQResult
     */
    _buildIQResult: function(stanza, query_attrs)
    {
        var id   =  stanza.getAttribute('id');
        var from = stanza.getAttribute('from');
        var iqresult = strophe_js.$iq({type: 'result', id: id});

        if (from !== null) {
            iqresult.attrs({to: from});
        }

        return iqresult.c('query', query_attrs);
    },

    /** PrivateFunction: _onDiscoInfo
     * Called when receive info request
     */
    _onDiscoInfo: function(stanza)
    {
        var node = stanza.getElementsByTagName('query')[0].getAttribute('node');
        var attrs = {xmlns: strophe_js.Strophe.NS.DISCO_INFO};
        var i;
        if (node)
        {
            attrs.node = node;
        }
        var iqresult = this._buildIQResult(stanza, attrs);
        for (i=0; i<this._identities.length; i++)
        {
            attrs = {category: this._identities[i].category,
                         type    : this._identities[i].type};
            if (this._identities[i].name)
                attrs.name = this._identities[i].name;
            if (this._identities[i].lang)
                attrs['xml:lang'] = this._identities[i].lang;
            iqresult.c('identity', attrs).up();
        }
        for (i=0; i<this._features.length; i++)
        {
            iqresult.c('feature', {'var':this._features[i]}).up();
        }
        this._connection.send(iqresult.tree());
        return true;
    },
    /** PrivateFunction: _onDiscoItems
     * Called when receive items request
     */
    _onDiscoItems: function(stanza)
    {
        var query_attrs = {xmlns: strophe_js.Strophe.NS.DISCO_ITEMS};
        var node = stanza.getElementsByTagName('query')[0].getAttribute('node');
        var items, i;
        if (node)
        {
            query_attrs.node = node;
            items = [];
            for (i = 0; i < this._items.length; i++)
            {
                if (this._items[i].node == node)
                {
                    items = this._items[i].call_back(stanza);
                    break;
                }
            }
        }
        else
        {
            items = this._items;
        }
        var iqresult = this._buildIQResult(stanza, query_attrs);
        for (i = 0; i < items.length; i++)
        {
            var attrs = {jid:  items[i].jid};
            if (items[i].name)
                attrs.name = items[i].name;
            if (items[i].node)
                attrs.node = items[i].node;
            iqresult.c('item', attrs).up();
        }
        this._connection.send(iqresult.tree());
        return true;
    }
});

})));
//# sourceMappingURL=strophe.disco.js.map


/***/ }),

/***/ "./node_modules/strophejs-plugin-stream-management/lib/strophe.stream-management.js":
/*!******************************************************************************************!*\
  !*** ./node_modules/strophejs-plugin-stream-management/lib/strophe.stream-management.js ***!
  \******************************************************************************************/
/***/ (function(__unused_webpack_module, __unused_webpack_exports, __webpack_require__) {

(function (global, factory) {
	 true ? factory(__webpack_require__(/*! strophe.js */ "./node_modules/strophe.js/dist/strophe.umd.js")) :
	0;
})(this, (function (strophe_js) { 'use strict';

	/**
	* StropheJS - Stream Management XEP-0198
	*
	* This plugin implements stream management ACK capabilities of the specs XEP-0198.
	* Note: Resumption is not supported in this current implementation.
	*
	* Reference: http://xmpp.org/extensions/xep-0198.html
	*
	* @class streamManagement
	*/
	strophe_js.Strophe.addConnectionPlugin('streamManagement', {

		/**
		* @property {Boolean} logging: Set to true to enable logging regarding out of sync stanzas.
		*/
		logging: false,

		/**
		* @property {Boolean} autoSendCountOnEveryIncomingStanza: Set to true to send an 'a' response after every stanza.
		* @default false
		* @public
		*/
		autoSendCountOnEveryIncomingStanza: false,

		/**
		* @property {Integer} requestResponseInterval: Set this value to send a request for counter on very interval
		* number of stanzas sent. Set to 0 to disable.
		* @default 5
		* @public
		*/
		requestResponseInterval: 5,

		/**
		* @property {Pointer} _c: Strophe connection instance.
		* @private
		*/
		_c: null,

		/**
		* @property {String} _NS XMPP Namespace.
		* @private
		*/
		_NS: 'urn:xmpp:sm:3',

		/**
		* @property {Boolean} _isStreamManagementEnabled
		* @private
		*/
		_isStreamManagementEnabled: false,

		/**
		* @property {Integer} _serverProcesssedStanzasCounter: Keeps count of stanzas confirmed processed by the server.
		* The server is the source of truth of this value. It is the 'h' attribute on the latest 'a' element received
		* from the server.
		* @private
		*/
		_serverProcesssedStanzasCounter: null,

		/**
		* @property {Integer} _clientProcessedStanzasCounter: Counter of stanzas received by the client from the server.
		* Client is the source of truth of this value. It is the 'h' attribute in the 'a' sent from the client to
		* the server.
		* @private
		*/
		_clientProcessedStanzasCounter: null,

		/**
		* @property {Integer} _clientSentStanzasCounter
		* @private
		*/
		_clientSentStanzasCounter: null,

		/**
		* Stores a reference to Strophe connection xmlOutput function to wrap counting functionality.
		* @method _originalXMLOutput
		* @type {Handler}
		* @private
		*/
		_originalXMLOutput: null,

		/**
		* @property {Handler} _requestHandler: Stores reference to handler that process count request from server.
		* @private
		*/
		_requestHandler: null,

		/**
		* @property {Handler} _incomingHandler: Stores reference to handler that processes incoming stanzas count.
		* @private
		*/
		_incomingHandler: null,

		/**
		* @property {Integer} _requestResponseIntervalCount: Counts sent stanzas since last response request.
		*/
		_requestResponseIntervalCount: 0,

		/**
		 * @property {boolean} _isSupported: indicates whether or not the server has advertised support for the stream
		 * management namespace.
		 */
		_isSupported: false,

		/**
		* @property {Queue} _unacknowledgedStanzas: Maintains a list of packet ids for stanzas which have yet to be acknowledged.
		*/
		_unacknowledgedStanzas: [],

		/**
		* @property {Array} _acknowledgedStanzaListeners: Stores callbacks for each stanza acknowledged by the server.
		* Provides the packet id of the stanza as a parameter.
		* @private
		*/
		_acknowledgedStanzaListeners: [],

		addAcknowledgedStanzaListener: function(listener) {
			this._acknowledgedStanzaListeners.push(listener);
		},

		enable: function(resume) {
			if (!this._isSupported) {
				throw new Error('The server doesn\'t support urn:xmpp:sm:3 namespace');
			} else if (this._connectionStatus !== strophe_js.Strophe.Status.CONNECTED) {
				throw new Error('enable() can only be called in the CONNECTED state');
			}
			this._c.send(strophe_js.$build('enable', { xmlns: this._NS, resume }));
			this._c.flush();
			this._c.pause();
		},

		getResumeToken: function() {
			return this._resumeToken;
		},

		isSupported() {
			return this._isSupported;
		},

		resume: function() {
			if (!this.getResumeToken()) {
				throw new Error('No resume token');
			}
			if (this._connectionStatus !== strophe_js.Strophe.Status.DISCONNECTED) {
				throw new Error('resume() can only be called in the DISCONNECTED state');
			}

			this._c.options.explicitResourceBinding = true;
			this._resuming = true;

			this._originalConnect.apply(this._c, this._connectArgs);
		},

		requestAcknowledgement: function() {
			if (this._connectionStatus !== strophe_js.Strophe.Status.CONNECTED) {
				throw new Error('requestAcknowledgement() can only be called in the CONNECTED state');
			}
			this._requestResponseIntervalCount = 0;
			this._c.send(strophe_js.$build('r', { xmlns: this._NS }));
		},

		getOutgoingCounter: function() {
			return this._clientSentStanzasCounter;
		},

		getIncomingCounter: function() {
			return this._clientProcessedStanzasCounter;
		},

		init: function(conn) {
			this._c = conn;
			strophe_js.Strophe.addNamespace('SM', this._NS);

			// Storing original xmlOutput function to use additional logic
			this._originalXMLOutput = this._c.xmlOutput;
			this._c.xmlOutput = this.xmlOutput.bind(this);

			this._originalConnect = this._c.connect;
			this._c.connect = this._interceptConnectArgs.bind(this);

			this._originalOnStreamFeaturesAfterSASL = this._c._onStreamFeaturesAfterSASL;
			this._c._onStreamFeaturesAfterSASL = this._onStreamFeaturesAfterSASL.bind(this);

			this._originalDoDisconnect = this._c._doDisconnect;
			this._c._doDisconnect = this._interceptDoDisconnect.bind(this);

			this._originalDisconnect = this._c.disconnect;
			this._c.disconnect = this._interceptDisconnect.bind(this);
		},

		_interceptDisconnect: function() {
			this._resumeToken = undefined;
			this._originalDisconnect.apply(this._c, arguments);
		},

		_interceptDoDisconnect: function() {
			if (this.getResumeToken()
					&& !this._resuming
					&& this._c.connected && !this._c.disconnecting) {
				this._resumeState = {
					handlers: this._c.handlers,
					timedHandlers: this._c.timedHandlers,
					removeTimeds: this._c.removeTimeds,
					removeHandlers: this._c.removeHandlers,
					addTimeds: this._c.addTimeds,
					addHandlers: this._c.addHandlers
				};
				this._storedJid = this._c.jid;

				this.logging && strophe_js.Strophe.debug('SM stored resume state, handler count: ' + this._resumeState.handlers.length);
			}

			// Remove any queued stanzas from the buffer that have failed to send while the socket was closed,
			// as they would interfere with the resume flow. They will be resent anyway.
			this._c._data = [];

			this._originalDoDisconnect.apply(this._c, arguments);
		},

		_interceptConnectArgs: function() {
			this._connectArgs = arguments;

			this._originalConnect.apply(this._c, arguments);
		},

		_onStreamFeaturesAfterSASL: function(elem) {
			this._isSupported = elem.getElementsByTagNameNS(this._NS, "sm").length > 0;

			return this._originalOnStreamFeaturesAfterSASL.apply(this._c, arguments);
		},

		statusChanged: function (status) {
			this._connectionStatus = status;
			if (!this.getResumeToken()
				&& (status === strophe_js.Strophe.Status.CONNECTED || status === strophe_js.Strophe.Status.DISCONNECTED)) {
				this.logging && strophe_js.Strophe.debug('SM reset state');

				this._serverProcesssedStanzasCounter = 0;
				this._clientProcessedStanzasCounter = 0;

				this._clientSentStanzasCounter = 0;

				this._isStreamManagementEnabled = false;
				this._requestResponseIntervalCount = 0;

				// FIXME not described in JSDocs
				this._resuming = false;

				if (status === strophe_js.Strophe.Status.DISCONNECTED) {
					this._isSupported = false;
				}

				this._unacknowledgedStanzas = [];

				if (this._requestHandler) {
					this._c.deleteHandler(this._requestHandler);
				}

				if (this._incomingHandler) {
					this._c.deleteHandler(this._incomingHandler);
				}

				this._requestHandler = this._c.addHandler(this._handleServerRequestHandler.bind(this), this._NS, 'r');
				this._ackHandler = this._c.addHandler(this._handleServerAck.bind(this), this._NS, 'a');
				this._incomingHandler = this._c.addHandler(this._incomingStanzaHandler.bind(this));

				// FIXME handler instances stored, but never used
				this._enabledHandler = this._c._addSysHandler(this._handleEnabled.bind(this), this._NS, 'enabled');
				this._resumeFailedHandler = this._c._addSysHandler(this._handleResumeFailed.bind(this), this._NS, 'failed');
				this._resumedHandler =  this._c._addSysHandler(this._handleResumed.bind(this), this._NS,'resumed');

			} else if (status === strophe_js.Strophe.Status.BINDREQUIRED)  {
				this._c.jid = this._storedJid;

				// Restore Strophe handlers
				for (const h of (this._resumeState.handlers || [])
						.concat(this._resumeState.addHandlers || [])) {
					this._c._addSysHandler(h.handler, h.ns, h.name, h.type, h.id);
				}
				for (const h of (this._resumeState.timedHandlers || [])
						.concat(this._resumeState.addTimeds)) {
					this._c.addTimedHandler(h.period, h.handler);
				}
				for (const h of (this._resumeState.removeTimeds || [])
						.concat(this._resumeState.removeHandlers || [])) {
					this._c.deleteTimedHandler(h);
				}

				// FIXME check conditions if there's session ID and if enabled
				this._c.send(strophe_js.$build('resume', {
					xmlns: this._NS,
					h: this._clientProcessedStanzasCounter,
					previd: this._resumeToken
				}));
				this._c.flush();
			} else if (status === strophe_js.Strophe.Status.ERROR) {
				this.logging && strophe_js.Strophe.debug('SM cleared resume token on error');
				this._resumeToken = undefined;
			}
		},

		/**
		* This method overrides the send method implemented by Strophe.Connection
		* to count outgoing stanzas
		*
		* @method Send
		* @public
		*/
		xmlOutput: function(elem) {
			if (strophe_js.Strophe.isTagEqual(elem, 'iq') ||
				strophe_js.Strophe.isTagEqual(elem, 'presence') ||
				strophe_js.Strophe.isTagEqual(elem, 'message')) {
				this._increaseSentStanzasCounter(elem);
			}

			return this._originalXMLOutput.call(this._c, elem);
		},

		_handleEnabled: function(elem) {
			this._isStreamManagementEnabled = true;
			// FIXME fail if requested, but not enabled
			this._resumeToken = elem.getAttribute('resume') === 'true' && elem.getAttribute('id');

			this._c.resume();

			return true;
		},

		_handleResumeFailed: function(elem) {
			const error = elem && (
				(elem.firstElementChild && elem.firstElementChild.tagName)
				|| (elem.firstChild && elem.firstChild.tagName));

			this._c._changeConnectStatus(strophe_js.Strophe.Status.ERROR, error, elem);
			this._c._doDisconnect();

			return true;
		},

		_handleResumed: function(elem) {
			// FIXME check if in the correct state
			var handledCount = parseInt(elem.getAttribute('h'));
			this._handleAcknowledgedStanzas(handledCount, this._serverProcesssedStanzasCounter);

			this._resuming = false;
			this._c.do_bind = false; // No need to bind our resource anymore
			this._c.authenticated = true;
			this._c.restored = true;

			if (this._unacknowledgedStanzas.length > 0) {
				this.logging && strophe_js.Strophe.debug('SM Sending unacknowledged stanzas', this._unacknowledgedStanzas);
				for(const stanza of this._unacknowledgedStanzas) {
					this._c.send(stanza);
				}
			} else {
				this.logging && strophe_js.Strophe.debug('SM No unacknowledged stanzas', this._unacknowledgedStanzas);
			}

			this._c._changeConnectStatus(strophe_js.Strophe.Status.CONNECTED, null);

			return true;
		},

		_incomingStanzaHandler: function(elem) {
			if (strophe_js.Strophe.isTagEqual(elem, 'iq') || strophe_js.Strophe.isTagEqual(elem, 'presence') || strophe_js.Strophe.isTagEqual(elem, 'message'))  {
				this._increaseReceivedStanzasCounter();

				if (this.autoSendCountOnEveryIncomingStanza) {
					this._answerProcessedStanzas();
				}
			}

			return true;
		},

		_handleAcknowledgedStanzas: function(reportedHandledCount, lastKnownHandledCount) {
			var delta = reportedHandledCount - lastKnownHandledCount;

			if (delta < 0) {
				this._throwError('New reported stanza count lower than previous. New: ' + reportedHandledCount + ' - Previous: ' + lastKnownHandledCount);
			}

			if (delta > this._unacknowledgedStanzas.length) {
				this._throwError('Higher reported acknowledge count than unacknowledged stanzas. Reported Acknowledge Count: ' + delta + ' - Unacknowledge Stanza Count: ' + this._unacknowledgedStanzas.length + ' - New: ' + reportedHandledCount + ' - Previous: ' + lastKnownHandledCount);
			}

			for(var i = 0; i < delta; i++) {
				var stanza = this._unacknowledgedStanzas.shift();
				for (var j = 0; j < this._acknowledgedStanzaListeners.length; j++) {
					this._acknowledgedStanzaListeners[j](stanza);
				}
			}

			if (this.logging && this._unacknowledgedStanzas.length > 0) {
				strophe_js.Strophe.warn('SM Unacknowledged stanzas', this._unacknowledgedStanzas);
			}

			this._serverProcesssedStanzasCounter = reportedHandledCount;

			if (this.requestResponseInterval > 0) {
				this._requestResponseIntervalCount = 0;
			}
		},

		_handleServerRequestHandler: function() {
			this._answerProcessedStanzas();

			return true;
		},

		_handleServerAck: function(elem){
			var handledCount = parseInt(elem.getAttribute('h'));
			this._handleAcknowledgedStanzas(handledCount, this._serverProcesssedStanzasCounter);

			return true;
		},

		_answerProcessedStanzas: function() {
			if (this._isStreamManagementEnabled) {
				this._c.send(strophe_js.$build('a', { xmlns: this._NS, h: this._clientProcessedStanzasCounter }));
			}
		},

		_increaseSentStanzasCounter: function(elem) {
			if (this._isStreamManagementEnabled) {
				if (this._unacknowledgedStanzas.indexOf(elem) !== -1) {

					return;
				}

				this._unacknowledgedStanzas.push(elem);
				this._clientSentStanzasCounter++;

				if (this.requestResponseInterval > 0) {
					this._requestResponseIntervalCount++;

					if (this._requestResponseIntervalCount === this.requestResponseInterval) {
						// FIXME Can not call send from onIdle.
						setTimeout(() => {
							if (this._connectionStatus === strophe_js.Strophe.Status.CONNECTED) {
								this.requestAcknowledgement();
							}
						}, 1);
					}
				}
			}
		},

		_increaseReceivedStanzasCounter: function() {
			if (this._isStreamManagementEnabled) {
				this._clientProcessedStanzasCounter++;
			}
		},

		_throwError: function(msg) {
			strophe_js.Strophe.error(msg);
			throw new Error(msg);
		}

	});

}));
//# sourceMappingURL=strophe.stream-management.js.map


/***/ }),

/***/ "./node_modules/uuid/dist/bytesToUuid.js":
/*!***********************************************!*\
  !*** ./node_modules/uuid/dist/bytesToUuid.js ***!
  \***********************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";


Object.defineProperty(exports, "__esModule", ({
  value: true
}));
exports["default"] = void 0;

/**
 * Convert array of 16 byte values to UUID string format of the form:
 * XXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX
 */
const byteToHex = [];

for (let i = 0; i < 256; ++i) {
  byteToHex.push((i + 0x100).toString(16).substr(1));
}

function bytesToUuid(buf, offset) {
  const i = offset || 0;
  const bth = byteToHex; // Note: Be careful editing this code!  It's been tuned for performance
  // and works in ways you may not expect. See https://github.com/uuidjs/uuid/pull/434

  return (bth[buf[i + 0]] + bth[buf[i + 1]] + bth[buf[i + 2]] + bth[buf[i + 3]] + '-' + bth[buf[i + 4]] + bth[buf[i + 5]] + '-' + bth[buf[i + 6]] + bth[buf[i + 7]] + '-' + bth[buf[i + 8]] + bth[buf[i + 9]] + '-' + bth[buf[i + 10]] + bth[buf[i + 11]] + bth[buf[i + 12]] + bth[buf[i + 13]] + bth[buf[i + 14]] + bth[buf[i + 15]]).toLowerCase();
}

var _default = bytesToUuid;
exports["default"] = _default;

/***/ }),

/***/ "./node_modules/uuid/dist/index.js":
/*!*****************************************!*\
  !*** ./node_modules/uuid/dist/index.js ***!
  \*****************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";


Object.defineProperty(exports, "__esModule", ({
  value: true
}));
Object.defineProperty(exports, "v1", ({
  enumerable: true,
  get: function () {
    return _v.default;
  }
}));
Object.defineProperty(exports, "v3", ({
  enumerable: true,
  get: function () {
    return _v2.default;
  }
}));
Object.defineProperty(exports, "v4", ({
  enumerable: true,
  get: function () {
    return _v3.default;
  }
}));
Object.defineProperty(exports, "v5", ({
  enumerable: true,
  get: function () {
    return _v4.default;
  }
}));

var _v = _interopRequireDefault(__webpack_require__(/*! ./v1.js */ "./node_modules/uuid/dist/v1.js"));

var _v2 = _interopRequireDefault(__webpack_require__(/*! ./v3.js */ "./node_modules/uuid/dist/v3.js"));

var _v3 = _interopRequireDefault(__webpack_require__(/*! ./v4.js */ "./node_modules/uuid/dist/v4.js"));

var _v4 = _interopRequireDefault(__webpack_require__(/*! ./v5.js */ "./node_modules/uuid/dist/v5.js"));

function _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }

/***/ }),

/***/ "./node_modules/uuid/dist/md5-browser.js":
/*!***********************************************!*\
  !*** ./node_modules/uuid/dist/md5-browser.js ***!
  \***********************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";


Object.defineProperty(exports, "__esModule", ({
  value: true
}));
exports["default"] = void 0;

/*
 * Browser-compatible JavaScript MD5
 *
 * Modification of JavaScript MD5
 * https://github.com/blueimp/JavaScript-MD5
 *
 * Copyright 2011, Sebastian Tschan
 * https://blueimp.net
 *
 * Licensed under the MIT license:
 * https://opensource.org/licenses/MIT
 *
 * Based on
 * A JavaScript implementation of the RSA Data Security, Inc. MD5 Message
 * Digest Algorithm, as defined in RFC 1321.
 * Version 2.2 Copyright (C) Paul Johnston 1999 - 2009
 * Other contributors: Greg Holt, Andrew Kepert, Ydnar, Lostinet
 * Distributed under the BSD License
 * See http://pajhome.org.uk/crypt/md5 for more info.
 */
function md5(bytes) {
  if (typeof bytes === 'string') {
    const msg = unescape(encodeURIComponent(bytes)); // UTF8 escape

    bytes = new Uint8Array(msg.length);

    for (let i = 0; i < msg.length; ++i) {
      bytes[i] = msg.charCodeAt(i);
    }
  }

  return md5ToHexEncodedArray(wordsToMd5(bytesToWords(bytes), bytes.length * 8));
}
/*
 * Convert an array of little-endian words to an array of bytes
 */


function md5ToHexEncodedArray(input) {
  const output = [];
  const length32 = input.length * 32;
  const hexTab = '0123456789abcdef';

  for (let i = 0; i < length32; i += 8) {
    const x = input[i >> 5] >>> i % 32 & 0xff;
    const hex = parseInt(hexTab.charAt(x >>> 4 & 0x0f) + hexTab.charAt(x & 0x0f), 16);
    output.push(hex);
  }

  return output;
}
/**
 * Calculate output length with padding and bit length
 */


function getOutputLength(inputLength8) {
  return (inputLength8 + 64 >>> 9 << 4) + 14 + 1;
}
/*
 * Calculate the MD5 of an array of little-endian words, and a bit length.
 */


function wordsToMd5(x, len) {
  /* append padding */
  x[len >> 5] |= 0x80 << len % 32;
  x[getOutputLength(len) - 1] = len;
  let a = 1732584193;
  let b = -271733879;
  let c = -1732584194;
  let d = 271733878;

  for (let i = 0; i < x.length; i += 16) {
    const olda = a;
    const oldb = b;
    const oldc = c;
    const oldd = d;
    a = md5ff(a, b, c, d, x[i], 7, -680876936);
    d = md5ff(d, a, b, c, x[i + 1], 12, -389564586);
    c = md5ff(c, d, a, b, x[i + 2], 17, 606105819);
    b = md5ff(b, c, d, a, x[i + 3], 22, -1044525330);
    a = md5ff(a, b, c, d, x[i + 4], 7, -176418897);
    d = md5ff(d, a, b, c, x[i + 5], 12, 1200080426);
    c = md5ff(c, d, a, b, x[i + 6], 17, -1473231341);
    b = md5ff(b, c, d, a, x[i + 7], 22, -45705983);
    a = md5ff(a, b, c, d, x[i + 8], 7, 1770035416);
    d = md5ff(d, a, b, c, x[i + 9], 12, -1958414417);
    c = md5ff(c, d, a, b, x[i + 10], 17, -42063);
    b = md5ff(b, c, d, a, x[i + 11], 22, -1990404162);
    a = md5ff(a, b, c, d, x[i + 12], 7, 1804603682);
    d = md5ff(d, a, b, c, x[i + 13], 12, -40341101);
    c = md5ff(c, d, a, b, x[i + 14], 17, -1502002290);
    b = md5ff(b, c, d, a, x[i + 15], 22, 1236535329);
    a = md5gg(a, b, c, d, x[i + 1], 5, -165796510);
    d = md5gg(d, a, b, c, x[i + 6], 9, -1069501632);
    c = md5gg(c, d, a, b, x[i + 11], 14, 643717713);
    b = md5gg(b, c, d, a, x[i], 20, -373897302);
    a = md5gg(a, b, c, d, x[i + 5], 5, -701558691);
    d = md5gg(d, a, b, c, x[i + 10], 9, 38016083);
    c = md5gg(c, d, a, b, x[i + 15], 14, -660478335);
    b = md5gg(b, c, d, a, x[i + 4], 20, -405537848);
    a = md5gg(a, b, c, d, x[i + 9], 5, 568446438);
    d = md5gg(d, a, b, c, x[i + 14], 9, -1019803690);
    c = md5gg(c, d, a, b, x[i + 3], 14, -187363961);
    b = md5gg(b, c, d, a, x[i + 8], 20, 1163531501);
    a = md5gg(a, b, c, d, x[i + 13], 5, -1444681467);
    d = md5gg(d, a, b, c, x[i + 2], 9, -51403784);
    c = md5gg(c, d, a, b, x[i + 7], 14, 1735328473);
    b = md5gg(b, c, d, a, x[i + 12], 20, -1926607734);
    a = md5hh(a, b, c, d, x[i + 5], 4, -378558);
    d = md5hh(d, a, b, c, x[i + 8], 11, -2022574463);
    c = md5hh(c, d, a, b, x[i + 11], 16, 1839030562);
    b = md5hh(b, c, d, a, x[i + 14], 23, -35309556);
    a = md5hh(a, b, c, d, x[i + 1], 4, -1530992060);
    d = md5hh(d, a, b, c, x[i + 4], 11, 1272893353);
    c = md5hh(c, d, a, b, x[i + 7], 16, -155497632);
    b = md5hh(b, c, d, a, x[i + 10], 23, -1094730640);
    a = md5hh(a, b, c, d, x[i + 13], 4, 681279174);
    d = md5hh(d, a, b, c, x[i], 11, -358537222);
    c = md5hh(c, d, a, b, x[i + 3], 16, -722521979);
    b = md5hh(b, c, d, a, x[i + 6], 23, 76029189);
    a = md5hh(a, b, c, d, x[i + 9], 4, -640364487);
    d = md5hh(d, a, b, c, x[i + 12], 11, -421815835);
    c = md5hh(c, d, a, b, x[i + 15], 16, 530742520);
    b = md5hh(b, c, d, a, x[i + 2], 23, -995338651);
    a = md5ii(a, b, c, d, x[i], 6, -198630844);
    d = md5ii(d, a, b, c, x[i + 7], 10, 1126891415);
    c = md5ii(c, d, a, b, x[i + 14], 15, -1416354905);
    b = md5ii(b, c, d, a, x[i + 5], 21, -57434055);
    a = md5ii(a, b, c, d, x[i + 12], 6, 1700485571);
    d = md5ii(d, a, b, c, x[i + 3], 10, -1894986606);
    c = md5ii(c, d, a, b, x[i + 10], 15, -1051523);
    b = md5ii(b, c, d, a, x[i + 1], 21, -2054922799);
    a = md5ii(a, b, c, d, x[i + 8], 6, 1873313359);
    d = md5ii(d, a, b, c, x[i + 15], 10, -30611744);
    c = md5ii(c, d, a, b, x[i + 6], 15, -1560198380);
    b = md5ii(b, c, d, a, x[i + 13], 21, 1309151649);
    a = md5ii(a, b, c, d, x[i + 4], 6, -145523070);
    d = md5ii(d, a, b, c, x[i + 11], 10, -1120210379);
    c = md5ii(c, d, a, b, x[i + 2], 15, 718787259);
    b = md5ii(b, c, d, a, x[i + 9], 21, -343485551);
    a = safeAdd(a, olda);
    b = safeAdd(b, oldb);
    c = safeAdd(c, oldc);
    d = safeAdd(d, oldd);
  }

  return [a, b, c, d];
}
/*
 * Convert an array bytes to an array of little-endian words
 * Characters >255 have their high-byte silently ignored.
 */


function bytesToWords(input) {
  if (input.length === 0) {
    return [];
  }

  const length8 = input.length * 8;
  const output = new Uint32Array(getOutputLength(length8));

  for (let i = 0; i < length8; i += 8) {
    output[i >> 5] |= (input[i / 8] & 0xff) << i % 32;
  }

  return output;
}
/*
 * Add integers, wrapping at 2^32. This uses 16-bit operations internally
 * to work around bugs in some JS interpreters.
 */


function safeAdd(x, y) {
  const lsw = (x & 0xffff) + (y & 0xffff);
  const msw = (x >> 16) + (y >> 16) + (lsw >> 16);
  return msw << 16 | lsw & 0xffff;
}
/*
 * Bitwise rotate a 32-bit number to the left.
 */


function bitRotateLeft(num, cnt) {
  return num << cnt | num >>> 32 - cnt;
}
/*
 * These functions implement the four basic operations the algorithm uses.
 */


function md5cmn(q, a, b, x, s, t) {
  return safeAdd(bitRotateLeft(safeAdd(safeAdd(a, q), safeAdd(x, t)), s), b);
}

function md5ff(a, b, c, d, x, s, t) {
  return md5cmn(b & c | ~b & d, a, b, x, s, t);
}

function md5gg(a, b, c, d, x, s, t) {
  return md5cmn(b & d | c & ~d, a, b, x, s, t);
}

function md5hh(a, b, c, d, x, s, t) {
  return md5cmn(b ^ c ^ d, a, b, x, s, t);
}

function md5ii(a, b, c, d, x, s, t) {
  return md5cmn(c ^ (b | ~d), a, b, x, s, t);
}

var _default = md5;
exports["default"] = _default;

/***/ }),

/***/ "./node_modules/uuid/dist/rng-browser.js":
/*!***********************************************!*\
  !*** ./node_modules/uuid/dist/rng-browser.js ***!
  \***********************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";


Object.defineProperty(exports, "__esModule", ({
  value: true
}));
exports["default"] = rng;
// Unique ID creation requires a high quality random # generator. In the browser we therefore
// require the crypto API and do not support built-in fallback to lower quality random number
// generators (like Math.random()).
// getRandomValues needs to be invoked in a context where "this" is a Crypto implementation. Also,
// find the complete implementation of crypto (msCrypto) on IE11.
const getRandomValues = typeof crypto !== 'undefined' && crypto.getRandomValues && crypto.getRandomValues.bind(crypto) || typeof msCrypto !== 'undefined' && typeof msCrypto.getRandomValues === 'function' && msCrypto.getRandomValues.bind(msCrypto);
const rnds8 = new Uint8Array(16);

function rng() {
  if (!getRandomValues) {
    throw new Error('crypto.getRandomValues() not supported. See https://github.com/uuidjs/uuid#getrandomvalues-not-supported');
  }

  return getRandomValues(rnds8);
}

/***/ }),

/***/ "./node_modules/uuid/dist/sha1-browser.js":
/*!************************************************!*\
  !*** ./node_modules/uuid/dist/sha1-browser.js ***!
  \************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";


Object.defineProperty(exports, "__esModule", ({
  value: true
}));
exports["default"] = void 0;

// Adapted from Chris Veness' SHA1 code at
// http://www.movable-type.co.uk/scripts/sha1.html
function f(s, x, y, z) {
  switch (s) {
    case 0:
      return x & y ^ ~x & z;

    case 1:
      return x ^ y ^ z;

    case 2:
      return x & y ^ x & z ^ y & z;

    case 3:
      return x ^ y ^ z;
  }
}

function ROTL(x, n) {
  return x << n | x >>> 32 - n;
}

function sha1(bytes) {
  const K = [0x5a827999, 0x6ed9eba1, 0x8f1bbcdc, 0xca62c1d6];
  const H = [0x67452301, 0xefcdab89, 0x98badcfe, 0x10325476, 0xc3d2e1f0];

  if (typeof bytes === 'string') {
    const msg = unescape(encodeURIComponent(bytes)); // UTF8 escape

    bytes = [];

    for (let i = 0; i < msg.length; ++i) {
      bytes.push(msg.charCodeAt(i));
    }
  }

  bytes.push(0x80);
  const l = bytes.length / 4 + 2;
  const N = Math.ceil(l / 16);
  const M = new Array(N);

  for (let i = 0; i < N; ++i) {
    const arr = new Uint32Array(16);

    for (let j = 0; j < 16; ++j) {
      arr[j] = bytes[i * 64 + j * 4] << 24 | bytes[i * 64 + j * 4 + 1] << 16 | bytes[i * 64 + j * 4 + 2] << 8 | bytes[i * 64 + j * 4 + 3];
    }

    M[i] = arr;
  }

  M[N - 1][14] = (bytes.length - 1) * 8 / Math.pow(2, 32);
  M[N - 1][14] = Math.floor(M[N - 1][14]);
  M[N - 1][15] = (bytes.length - 1) * 8 & 0xffffffff;

  for (let i = 0; i < N; ++i) {
    const W = new Uint32Array(80);

    for (let t = 0; t < 16; ++t) {
      W[t] = M[i][t];
    }

    for (let t = 16; t < 80; ++t) {
      W[t] = ROTL(W[t - 3] ^ W[t - 8] ^ W[t - 14] ^ W[t - 16], 1);
    }

    let a = H[0];
    let b = H[1];
    let c = H[2];
    let d = H[3];
    let e = H[4];

    for (let t = 0; t < 80; ++t) {
      const s = Math.floor(t / 20);
      const T = ROTL(a, 5) + f(s, b, c, d) + e + K[s] + W[t] >>> 0;
      e = d;
      d = c;
      c = ROTL(b, 30) >>> 0;
      b = a;
      a = T;
    }

    H[0] = H[0] + a >>> 0;
    H[1] = H[1] + b >>> 0;
    H[2] = H[2] + c >>> 0;
    H[3] = H[3] + d >>> 0;
    H[4] = H[4] + e >>> 0;
  }

  return [H[0] >> 24 & 0xff, H[0] >> 16 & 0xff, H[0] >> 8 & 0xff, H[0] & 0xff, H[1] >> 24 & 0xff, H[1] >> 16 & 0xff, H[1] >> 8 & 0xff, H[1] & 0xff, H[2] >> 24 & 0xff, H[2] >> 16 & 0xff, H[2] >> 8 & 0xff, H[2] & 0xff, H[3] >> 24 & 0xff, H[3] >> 16 & 0xff, H[3] >> 8 & 0xff, H[3] & 0xff, H[4] >> 24 & 0xff, H[4] >> 16 & 0xff, H[4] >> 8 & 0xff, H[4] & 0xff];
}

var _default = sha1;
exports["default"] = _default;

/***/ }),

/***/ "./node_modules/uuid/dist/v1.js":
/*!**************************************!*\
  !*** ./node_modules/uuid/dist/v1.js ***!
  \**************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";


Object.defineProperty(exports, "__esModule", ({
  value: true
}));
exports["default"] = void 0;

var _rng = _interopRequireDefault(__webpack_require__(/*! ./rng.js */ "./node_modules/uuid/dist/rng-browser.js"));

var _bytesToUuid = _interopRequireDefault(__webpack_require__(/*! ./bytesToUuid.js */ "./node_modules/uuid/dist/bytesToUuid.js"));

function _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }

// **`v1()` - Generate time-based UUID**
//
// Inspired by https://github.com/LiosK/UUID.js
// and http://docs.python.org/library/uuid.html
let _nodeId;

let _clockseq; // Previous uuid creation time


let _lastMSecs = 0;
let _lastNSecs = 0; // See https://github.com/uuidjs/uuid for API details

function v1(options, buf, offset) {
  let i = buf && offset || 0;
  const b = buf || [];
  options = options || {};
  let node = options.node || _nodeId;
  let clockseq = options.clockseq !== undefined ? options.clockseq : _clockseq; // node and clockseq need to be initialized to random values if they're not
  // specified.  We do this lazily to minimize issues related to insufficient
  // system entropy.  See #189

  if (node == null || clockseq == null) {
    const seedBytes = options.random || (options.rng || _rng.default)();

    if (node == null) {
      // Per 4.5, create and 48-bit node id, (47 random bits + multicast bit = 1)
      node = _nodeId = [seedBytes[0] | 0x01, seedBytes[1], seedBytes[2], seedBytes[3], seedBytes[4], seedBytes[5]];
    }

    if (clockseq == null) {
      // Per 4.2.2, randomize (14 bit) clockseq
      clockseq = _clockseq = (seedBytes[6] << 8 | seedBytes[7]) & 0x3fff;
    }
  } // UUID timestamps are 100 nano-second units since the Gregorian epoch,
  // (1582-10-15 00:00).  JSNumbers aren't precise enough for this, so
  // time is handled internally as 'msecs' (integer milliseconds) and 'nsecs'
  // (100-nanoseconds offset from msecs) since unix epoch, 1970-01-01 00:00.


  let msecs = options.msecs !== undefined ? options.msecs : Date.now(); // Per 4.2.1.2, use count of uuid's generated during the current clock
  // cycle to simulate higher resolution clock

  let nsecs = options.nsecs !== undefined ? options.nsecs : _lastNSecs + 1; // Time since last uuid creation (in msecs)

  const dt = msecs - _lastMSecs + (nsecs - _lastNSecs) / 10000; // Per 4.2.1.2, Bump clockseq on clock regression

  if (dt < 0 && options.clockseq === undefined) {
    clockseq = clockseq + 1 & 0x3fff;
  } // Reset nsecs if clock regresses (new clockseq) or we've moved onto a new
  // time interval


  if ((dt < 0 || msecs > _lastMSecs) && options.nsecs === undefined) {
    nsecs = 0;
  } // Per 4.2.1.2 Throw error if too many uuids are requested


  if (nsecs >= 10000) {
    throw new Error("uuid.v1(): Can't create more than 10M uuids/sec");
  }

  _lastMSecs = msecs;
  _lastNSecs = nsecs;
  _clockseq = clockseq; // Per 4.1.4 - Convert from unix epoch to Gregorian epoch

  msecs += 12219292800000; // `time_low`

  const tl = ((msecs & 0xfffffff) * 10000 + nsecs) % 0x100000000;
  b[i++] = tl >>> 24 & 0xff;
  b[i++] = tl >>> 16 & 0xff;
  b[i++] = tl >>> 8 & 0xff;
  b[i++] = tl & 0xff; // `time_mid`

  const tmh = msecs / 0x100000000 * 10000 & 0xfffffff;
  b[i++] = tmh >>> 8 & 0xff;
  b[i++] = tmh & 0xff; // `time_high_and_version`

  b[i++] = tmh >>> 24 & 0xf | 0x10; // include version

  b[i++] = tmh >>> 16 & 0xff; // `clock_seq_hi_and_reserved` (Per 4.2.2 - include variant)

  b[i++] = clockseq >>> 8 | 0x80; // `clock_seq_low`

  b[i++] = clockseq & 0xff; // `node`

  for (let n = 0; n < 6; ++n) {
    b[i + n] = node[n];
  }

  return buf || (0, _bytesToUuid.default)(b);
}

var _default = v1;
exports["default"] = _default;

/***/ }),

/***/ "./node_modules/uuid/dist/v3.js":
/*!**************************************!*\
  !*** ./node_modules/uuid/dist/v3.js ***!
  \**************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";


Object.defineProperty(exports, "__esModule", ({
  value: true
}));
exports["default"] = void 0;

var _v = _interopRequireDefault(__webpack_require__(/*! ./v35.js */ "./node_modules/uuid/dist/v35.js"));

var _md = _interopRequireDefault(__webpack_require__(/*! ./md5.js */ "./node_modules/uuid/dist/md5-browser.js"));

function _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }

const v3 = (0, _v.default)('v3', 0x30, _md.default);
var _default = v3;
exports["default"] = _default;

/***/ }),

/***/ "./node_modules/uuid/dist/v35.js":
/*!***************************************!*\
  !*** ./node_modules/uuid/dist/v35.js ***!
  \***************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";


Object.defineProperty(exports, "__esModule", ({
  value: true
}));
exports["default"] = _default;
exports.URL = exports.DNS = void 0;

var _bytesToUuid = _interopRequireDefault(__webpack_require__(/*! ./bytesToUuid.js */ "./node_modules/uuid/dist/bytesToUuid.js"));

function _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }

function uuidToBytes(uuid) {
  // Note: We assume we're being passed a valid uuid string
  const bytes = [];
  uuid.replace(/[a-fA-F0-9]{2}/g, function (hex) {
    bytes.push(parseInt(hex, 16));
  });
  return bytes;
}

function stringToBytes(str) {
  str = unescape(encodeURIComponent(str)); // UTF8 escape

  const bytes = [];

  for (let i = 0; i < str.length; ++i) {
    bytes.push(str.charCodeAt(i));
  }

  return bytes;
}

const DNS = '6ba7b810-9dad-11d1-80b4-00c04fd430c8';
exports.DNS = DNS;
const URL = '6ba7b811-9dad-11d1-80b4-00c04fd430c8';
exports.URL = URL;

function _default(name, version, hashfunc) {
  function generateUUID(value, namespace, buf, offset) {
    const off = buf && offset || 0;
    if (typeof value === 'string') value = stringToBytes(value);
    if (typeof namespace === 'string') namespace = uuidToBytes(namespace);

    if (!Array.isArray(value)) {
      throw TypeError('value must be an array of bytes');
    }

    if (!Array.isArray(namespace) || namespace.length !== 16) {
      throw TypeError('namespace must be uuid string or an Array of 16 byte values');
    } // Per 4.3


    const bytes = hashfunc(namespace.concat(value));
    bytes[6] = bytes[6] & 0x0f | version;
    bytes[8] = bytes[8] & 0x3f | 0x80;

    if (buf) {
      for (let idx = 0; idx < 16; ++idx) {
        buf[off + idx] = bytes[idx];
      }
    }

    return buf || (0, _bytesToUuid.default)(bytes);
  } // Function#name is not settable on some platforms (#270)


  try {
    generateUUID.name = name; // eslint-disable-next-line no-empty
  } catch (err) {} // For CommonJS default export support


  generateUUID.DNS = DNS;
  generateUUID.URL = URL;
  return generateUUID;
}

/***/ }),

/***/ "./node_modules/uuid/dist/v4.js":
/*!**************************************!*\
  !*** ./node_modules/uuid/dist/v4.js ***!
  \**************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";


Object.defineProperty(exports, "__esModule", ({
  value: true
}));
exports["default"] = void 0;

var _rng = _interopRequireDefault(__webpack_require__(/*! ./rng.js */ "./node_modules/uuid/dist/rng-browser.js"));

var _bytesToUuid = _interopRequireDefault(__webpack_require__(/*! ./bytesToUuid.js */ "./node_modules/uuid/dist/bytesToUuid.js"));

function _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }

function v4(options, buf, offset) {
  if (typeof options === 'string') {
    buf = options === 'binary' ? new Uint8Array(16) : null;
    options = null;
  }

  options = options || {};

  const rnds = options.random || (options.rng || _rng.default)(); // Per 4.4, set bits for version and `clock_seq_hi_and_reserved`


  rnds[6] = rnds[6] & 0x0f | 0x40;
  rnds[8] = rnds[8] & 0x3f | 0x80; // Copy bytes to buffer, if provided

  if (buf) {
    const start = offset || 0;

    for (let i = 0; i < 16; ++i) {
      buf[start + i] = rnds[i];
    }

    return buf;
  }

  return (0, _bytesToUuid.default)(rnds);
}

var _default = v4;
exports["default"] = _default;

/***/ }),

/***/ "./node_modules/uuid/dist/v5.js":
/*!**************************************!*\
  !*** ./node_modules/uuid/dist/v5.js ***!
  \**************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";


Object.defineProperty(exports, "__esModule", ({
  value: true
}));
exports["default"] = void 0;

var _v = _interopRequireDefault(__webpack_require__(/*! ./v35.js */ "./node_modules/uuid/dist/v35.js"));

var _sha = _interopRequireDefault(__webpack_require__(/*! ./sha1.js */ "./node_modules/uuid/dist/sha1-browser.js"));

function _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }

const v5 = (0, _v.default)('v5', 0x50, _sha.default);
var _default = v5;
exports["default"] = _default;

/***/ }),

/***/ "./node_modules/webrtc-adapter/src/js/adapter_core.js":
/*!************************************************************!*\
  !*** ./node_modules/webrtc-adapter/src/js/adapter_core.js ***!
  \************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (__WEBPACK_DEFAULT_EXPORT__)
/* harmony export */ });
/* harmony import */ var _adapter_factory_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./adapter_factory.js */ "./node_modules/webrtc-adapter/src/js/adapter_factory.js");
/*
 *  Copyright (c) 2016 The WebRTC project authors. All Rights Reserved.
 *
 *  Use of this source code is governed by a BSD-style license
 *  that can be found in the LICENSE file in the root of the source
 *  tree.
 */
/* eslint-env node */





const adapter =
  (0,_adapter_factory_js__WEBPACK_IMPORTED_MODULE_0__.adapterFactory)({window: typeof window === 'undefined' ? undefined : window});
/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (adapter);


/***/ }),

/***/ "./node_modules/webrtc-adapter/src/js/adapter_factory.js":
/*!***************************************************************!*\
  !*** ./node_modules/webrtc-adapter/src/js/adapter_factory.js ***!
  \***************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   adapterFactory: () => (/* binding */ adapterFactory)
/* harmony export */ });
/* harmony import */ var _utils__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./utils */ "./node_modules/webrtc-adapter/src/js/utils.js");
/* harmony import */ var _chrome_chrome_shim__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./chrome/chrome_shim */ "./node_modules/webrtc-adapter/src/js/chrome/chrome_shim.js");
/* harmony import */ var _firefox_firefox_shim__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./firefox/firefox_shim */ "./node_modules/webrtc-adapter/src/js/firefox/firefox_shim.js");
/* harmony import */ var _safari_safari_shim__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./safari/safari_shim */ "./node_modules/webrtc-adapter/src/js/safari/safari_shim.js");
/* harmony import */ var _common_shim__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./common_shim */ "./node_modules/webrtc-adapter/src/js/common_shim.js");
/* harmony import */ var sdp__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! sdp */ "./node_modules/sdp/sdp.js");
/* harmony import */ var sdp__WEBPACK_IMPORTED_MODULE_5___default = /*#__PURE__*/__webpack_require__.n(sdp__WEBPACK_IMPORTED_MODULE_5__);
/*
 *  Copyright (c) 2016 The WebRTC project authors. All Rights Reserved.
 *
 *  Use of this source code is governed by a BSD-style license
 *  that can be found in the LICENSE file in the root of the source
 *  tree.
 */


  // Browser shims.






// Shimming starts here.
function adapterFactory({window} = {}, options = {
  shimChrome: true,
  shimFirefox: true,
  shimSafari: true,
}) {
  // Utils.
  const logging = _utils__WEBPACK_IMPORTED_MODULE_0__.log;
  const browserDetails = _utils__WEBPACK_IMPORTED_MODULE_0__.detectBrowser(window);

  const adapter = {
    browserDetails,
    commonShim: _common_shim__WEBPACK_IMPORTED_MODULE_4__,
    extractVersion: _utils__WEBPACK_IMPORTED_MODULE_0__.extractVersion,
    disableLog: _utils__WEBPACK_IMPORTED_MODULE_0__.disableLog,
    disableWarnings: _utils__WEBPACK_IMPORTED_MODULE_0__.disableWarnings,
    // Expose sdp as a convenience. For production apps include directly.
    sdp: sdp__WEBPACK_IMPORTED_MODULE_5__,
  };

  // Shim browser if found.
  switch (browserDetails.browser) {
    case 'chrome':
      if (!_chrome_chrome_shim__WEBPACK_IMPORTED_MODULE_1__ || !_chrome_chrome_shim__WEBPACK_IMPORTED_MODULE_1__.shimPeerConnection ||
          !options.shimChrome) {
        logging('Chrome shim is not included in this adapter release.');
        return adapter;
      }
      if (browserDetails.version === null) {
        logging('Chrome shim can not determine version, not shimming.');
        return adapter;
      }
      logging('adapter.js shimming chrome.');
      // Export to the adapter global object visible in the browser.
      adapter.browserShim = _chrome_chrome_shim__WEBPACK_IMPORTED_MODULE_1__;

      // Must be called before shimPeerConnection.
      _common_shim__WEBPACK_IMPORTED_MODULE_4__.shimAddIceCandidateNullOrEmpty(window, browserDetails);
      _common_shim__WEBPACK_IMPORTED_MODULE_4__.shimParameterlessSetLocalDescription(window, browserDetails);

      _chrome_chrome_shim__WEBPACK_IMPORTED_MODULE_1__.shimGetUserMedia(window, browserDetails);
      _chrome_chrome_shim__WEBPACK_IMPORTED_MODULE_1__.shimMediaStream(window, browserDetails);
      _chrome_chrome_shim__WEBPACK_IMPORTED_MODULE_1__.shimPeerConnection(window, browserDetails);
      _chrome_chrome_shim__WEBPACK_IMPORTED_MODULE_1__.shimOnTrack(window, browserDetails);
      _chrome_chrome_shim__WEBPACK_IMPORTED_MODULE_1__.shimAddTrackRemoveTrack(window, browserDetails);
      _chrome_chrome_shim__WEBPACK_IMPORTED_MODULE_1__.shimGetSendersWithDtmf(window, browserDetails);
      _chrome_chrome_shim__WEBPACK_IMPORTED_MODULE_1__.shimGetStats(window, browserDetails);
      _chrome_chrome_shim__WEBPACK_IMPORTED_MODULE_1__.shimSenderReceiverGetStats(window, browserDetails);
      _chrome_chrome_shim__WEBPACK_IMPORTED_MODULE_1__.fixNegotiationNeeded(window, browserDetails);

      _common_shim__WEBPACK_IMPORTED_MODULE_4__.shimRTCIceCandidate(window, browserDetails);
      _common_shim__WEBPACK_IMPORTED_MODULE_4__.shimConnectionState(window, browserDetails);
      _common_shim__WEBPACK_IMPORTED_MODULE_4__.shimMaxMessageSize(window, browserDetails);
      _common_shim__WEBPACK_IMPORTED_MODULE_4__.shimSendThrowTypeError(window, browserDetails);
      _common_shim__WEBPACK_IMPORTED_MODULE_4__.removeExtmapAllowMixed(window, browserDetails);
      break;
    case 'firefox':
      if (!_firefox_firefox_shim__WEBPACK_IMPORTED_MODULE_2__ || !_firefox_firefox_shim__WEBPACK_IMPORTED_MODULE_2__.shimPeerConnection ||
          !options.shimFirefox) {
        logging('Firefox shim is not included in this adapter release.');
        return adapter;
      }
      logging('adapter.js shimming firefox.');
      // Export to the adapter global object visible in the browser.
      adapter.browserShim = _firefox_firefox_shim__WEBPACK_IMPORTED_MODULE_2__;

      // Must be called before shimPeerConnection.
      _common_shim__WEBPACK_IMPORTED_MODULE_4__.shimAddIceCandidateNullOrEmpty(window, browserDetails);
      _common_shim__WEBPACK_IMPORTED_MODULE_4__.shimParameterlessSetLocalDescription(window, browserDetails);

      _firefox_firefox_shim__WEBPACK_IMPORTED_MODULE_2__.shimGetUserMedia(window, browserDetails);
      _firefox_firefox_shim__WEBPACK_IMPORTED_MODULE_2__.shimPeerConnection(window, browserDetails);
      _firefox_firefox_shim__WEBPACK_IMPORTED_MODULE_2__.shimOnTrack(window, browserDetails);
      _firefox_firefox_shim__WEBPACK_IMPORTED_MODULE_2__.shimRemoveStream(window, browserDetails);
      _firefox_firefox_shim__WEBPACK_IMPORTED_MODULE_2__.shimSenderGetStats(window, browserDetails);
      _firefox_firefox_shim__WEBPACK_IMPORTED_MODULE_2__.shimReceiverGetStats(window, browserDetails);
      _firefox_firefox_shim__WEBPACK_IMPORTED_MODULE_2__.shimRTCDataChannel(window, browserDetails);
      _firefox_firefox_shim__WEBPACK_IMPORTED_MODULE_2__.shimAddTransceiver(window, browserDetails);
      _firefox_firefox_shim__WEBPACK_IMPORTED_MODULE_2__.shimGetParameters(window, browserDetails);
      _firefox_firefox_shim__WEBPACK_IMPORTED_MODULE_2__.shimCreateOffer(window, browserDetails);
      _firefox_firefox_shim__WEBPACK_IMPORTED_MODULE_2__.shimCreateAnswer(window, browserDetails);

      _common_shim__WEBPACK_IMPORTED_MODULE_4__.shimRTCIceCandidate(window, browserDetails);
      _common_shim__WEBPACK_IMPORTED_MODULE_4__.shimConnectionState(window, browserDetails);
      _common_shim__WEBPACK_IMPORTED_MODULE_4__.shimMaxMessageSize(window, browserDetails);
      _common_shim__WEBPACK_IMPORTED_MODULE_4__.shimSendThrowTypeError(window, browserDetails);
      break;
    case 'safari':
      if (!_safari_safari_shim__WEBPACK_IMPORTED_MODULE_3__ || !options.shimSafari) {
        logging('Safari shim is not included in this adapter release.');
        return adapter;
      }
      logging('adapter.js shimming safari.');
      // Export to the adapter global object visible in the browser.
      adapter.browserShim = _safari_safari_shim__WEBPACK_IMPORTED_MODULE_3__;

      // Must be called before shimCallbackAPI.
      _common_shim__WEBPACK_IMPORTED_MODULE_4__.shimAddIceCandidateNullOrEmpty(window, browserDetails);
      _common_shim__WEBPACK_IMPORTED_MODULE_4__.shimParameterlessSetLocalDescription(window, browserDetails);

      _safari_safari_shim__WEBPACK_IMPORTED_MODULE_3__.shimRTCIceServerUrls(window, browserDetails);
      _safari_safari_shim__WEBPACK_IMPORTED_MODULE_3__.shimCreateOfferLegacy(window, browserDetails);
      _safari_safari_shim__WEBPACK_IMPORTED_MODULE_3__.shimCallbacksAPI(window, browserDetails);
      _safari_safari_shim__WEBPACK_IMPORTED_MODULE_3__.shimLocalStreamsAPI(window, browserDetails);
      _safari_safari_shim__WEBPACK_IMPORTED_MODULE_3__.shimRemoteStreamsAPI(window, browserDetails);
      _safari_safari_shim__WEBPACK_IMPORTED_MODULE_3__.shimTrackEventTransceiver(window, browserDetails);
      _safari_safari_shim__WEBPACK_IMPORTED_MODULE_3__.shimGetUserMedia(window, browserDetails);
      _safari_safari_shim__WEBPACK_IMPORTED_MODULE_3__.shimAudioContext(window, browserDetails);

      _common_shim__WEBPACK_IMPORTED_MODULE_4__.shimRTCIceCandidate(window, browserDetails);
      _common_shim__WEBPACK_IMPORTED_MODULE_4__.shimMaxMessageSize(window, browserDetails);
      _common_shim__WEBPACK_IMPORTED_MODULE_4__.shimSendThrowTypeError(window, browserDetails);
      _common_shim__WEBPACK_IMPORTED_MODULE_4__.removeExtmapAllowMixed(window, browserDetails);
      break;
    default:
      logging('Unsupported browser!');
      break;
  }

  return adapter;
}


/***/ }),

/***/ "./node_modules/webrtc-adapter/src/js/chrome/chrome_shim.js":
/*!******************************************************************!*\
  !*** ./node_modules/webrtc-adapter/src/js/chrome/chrome_shim.js ***!
  \******************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   fixNegotiationNeeded: () => (/* binding */ fixNegotiationNeeded),
/* harmony export */   shimAddTrackRemoveTrack: () => (/* binding */ shimAddTrackRemoveTrack),
/* harmony export */   shimAddTrackRemoveTrackWithNative: () => (/* binding */ shimAddTrackRemoveTrackWithNative),
/* harmony export */   shimGetDisplayMedia: () => (/* reexport safe */ _getdisplaymedia__WEBPACK_IMPORTED_MODULE_2__.shimGetDisplayMedia),
/* harmony export */   shimGetSendersWithDtmf: () => (/* binding */ shimGetSendersWithDtmf),
/* harmony export */   shimGetStats: () => (/* binding */ shimGetStats),
/* harmony export */   shimGetUserMedia: () => (/* reexport safe */ _getusermedia__WEBPACK_IMPORTED_MODULE_1__.shimGetUserMedia),
/* harmony export */   shimMediaStream: () => (/* binding */ shimMediaStream),
/* harmony export */   shimOnTrack: () => (/* binding */ shimOnTrack),
/* harmony export */   shimPeerConnection: () => (/* binding */ shimPeerConnection),
/* harmony export */   shimSenderReceiverGetStats: () => (/* binding */ shimSenderReceiverGetStats)
/* harmony export */ });
/* harmony import */ var _utils_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../utils.js */ "./node_modules/webrtc-adapter/src/js/utils.js");
/* harmony import */ var _getusermedia__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./getusermedia */ "./node_modules/webrtc-adapter/src/js/chrome/getusermedia.js");
/* harmony import */ var _getdisplaymedia__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./getdisplaymedia */ "./node_modules/webrtc-adapter/src/js/chrome/getdisplaymedia.js");
/*
 *  Copyright (c) 2016 The WebRTC project authors. All Rights Reserved.
 *
 *  Use of this source code is governed by a BSD-style license
 *  that can be found in the LICENSE file in the root of the source
 *  tree.
 */
 /* eslint-env node */






function shimMediaStream(window) {
  window.MediaStream = window.MediaStream || window.webkitMediaStream;
}

function shimOnTrack(window) {
  if (typeof window === 'object' && window.RTCPeerConnection && !('ontrack' in
      window.RTCPeerConnection.prototype)) {
    Object.defineProperty(window.RTCPeerConnection.prototype, 'ontrack', {
      get() {
        return this._ontrack;
      },
      set(f) {
        if (this._ontrack) {
          this.removeEventListener('track', this._ontrack);
        }
        this.addEventListener('track', this._ontrack = f);
      },
      enumerable: true,
      configurable: true
    });
    const origSetRemoteDescription =
        window.RTCPeerConnection.prototype.setRemoteDescription;
    window.RTCPeerConnection.prototype.setRemoteDescription =
      function setRemoteDescription() {
        if (!this._ontrackpoly) {
          this._ontrackpoly = (e) => {
            // onaddstream does not fire when a track is added to an existing
            // stream. But stream.onaddtrack is implemented so we use that.
            e.stream.addEventListener('addtrack', te => {
              let receiver;
              if (window.RTCPeerConnection.prototype.getReceivers) {
                receiver = this.getReceivers()
                  .find(r => r.track && r.track.id === te.track.id);
              } else {
                receiver = {track: te.track};
              }

              const event = new Event('track');
              event.track = te.track;
              event.receiver = receiver;
              event.transceiver = {receiver};
              event.streams = [e.stream];
              this.dispatchEvent(event);
            });
            e.stream.getTracks().forEach(track => {
              let receiver;
              if (window.RTCPeerConnection.prototype.getReceivers) {
                receiver = this.getReceivers()
                  .find(r => r.track && r.track.id === track.id);
              } else {
                receiver = {track};
              }
              const event = new Event('track');
              event.track = track;
              event.receiver = receiver;
              event.transceiver = {receiver};
              event.streams = [e.stream];
              this.dispatchEvent(event);
            });
          };
          this.addEventListener('addstream', this._ontrackpoly);
        }
        return origSetRemoteDescription.apply(this, arguments);
      };
  } else {
    // even if RTCRtpTransceiver is in window, it is only used and
    // emitted in unified-plan. Unfortunately this means we need
    // to unconditionally wrap the event.
    _utils_js__WEBPACK_IMPORTED_MODULE_0__.wrapPeerConnectionEvent(window, 'track', e => {
      if (!e.transceiver) {
        Object.defineProperty(e, 'transceiver',
          {value: {receiver: e.receiver}});
      }
      return e;
    });
  }
}

function shimGetSendersWithDtmf(window) {
  // Overrides addTrack/removeTrack, depends on shimAddTrackRemoveTrack.
  if (typeof window === 'object' && window.RTCPeerConnection &&
      !('getSenders' in window.RTCPeerConnection.prototype) &&
      'createDTMFSender' in window.RTCPeerConnection.prototype) {
    const shimSenderWithDtmf = function(pc, track) {
      return {
        track,
        get dtmf() {
          if (this._dtmf === undefined) {
            if (track.kind === 'audio') {
              this._dtmf = pc.createDTMFSender(track);
            } else {
              this._dtmf = null;
            }
          }
          return this._dtmf;
        },
        _pc: pc
      };
    };

    // augment addTrack when getSenders is not available.
    if (!window.RTCPeerConnection.prototype.getSenders) {
      window.RTCPeerConnection.prototype.getSenders = function getSenders() {
        this._senders = this._senders || [];
        return this._senders.slice(); // return a copy of the internal state.
      };
      const origAddTrack = window.RTCPeerConnection.prototype.addTrack;
      window.RTCPeerConnection.prototype.addTrack =
        function addTrack(track, stream) {
          let sender = origAddTrack.apply(this, arguments);
          if (!sender) {
            sender = shimSenderWithDtmf(this, track);
            this._senders.push(sender);
          }
          return sender;
        };

      const origRemoveTrack = window.RTCPeerConnection.prototype.removeTrack;
      window.RTCPeerConnection.prototype.removeTrack =
        function removeTrack(sender) {
          origRemoveTrack.apply(this, arguments);
          const idx = this._senders.indexOf(sender);
          if (idx !== -1) {
            this._senders.splice(idx, 1);
          }
        };
    }
    const origAddStream = window.RTCPeerConnection.prototype.addStream;
    window.RTCPeerConnection.prototype.addStream = function addStream(stream) {
      this._senders = this._senders || [];
      origAddStream.apply(this, [stream]);
      stream.getTracks().forEach(track => {
        this._senders.push(shimSenderWithDtmf(this, track));
      });
    };

    const origRemoveStream = window.RTCPeerConnection.prototype.removeStream;
    window.RTCPeerConnection.prototype.removeStream =
      function removeStream(stream) {
        this._senders = this._senders || [];
        origRemoveStream.apply(this, [stream]);

        stream.getTracks().forEach(track => {
          const sender = this._senders.find(s => s.track === track);
          if (sender) { // remove sender
            this._senders.splice(this._senders.indexOf(sender), 1);
          }
        });
      };
  } else if (typeof window === 'object' && window.RTCPeerConnection &&
             'getSenders' in window.RTCPeerConnection.prototype &&
             'createDTMFSender' in window.RTCPeerConnection.prototype &&
             window.RTCRtpSender &&
             !('dtmf' in window.RTCRtpSender.prototype)) {
    const origGetSenders = window.RTCPeerConnection.prototype.getSenders;
    window.RTCPeerConnection.prototype.getSenders = function getSenders() {
      const senders = origGetSenders.apply(this, []);
      senders.forEach(sender => sender._pc = this);
      return senders;
    };

    Object.defineProperty(window.RTCRtpSender.prototype, 'dtmf', {
      get() {
        if (this._dtmf === undefined) {
          if (this.track.kind === 'audio') {
            this._dtmf = this._pc.createDTMFSender(this.track);
          } else {
            this._dtmf = null;
          }
        }
        return this._dtmf;
      }
    });
  }
}

function shimGetStats(window) {
  if (!window.RTCPeerConnection) {
    return;
  }

  const origGetStats = window.RTCPeerConnection.prototype.getStats;
  window.RTCPeerConnection.prototype.getStats = function getStats() {
    const [selector, onSucc, onErr] = arguments;

    // If selector is a function then we are in the old style stats so just
    // pass back the original getStats format to avoid breaking old users.
    if (arguments.length > 0 && typeof selector === 'function') {
      return origGetStats.apply(this, arguments);
    }

    // When spec-style getStats is supported, return those when called with
    // either no arguments or the selector argument is null.
    if (origGetStats.length === 0 && (arguments.length === 0 ||
        typeof selector !== 'function')) {
      return origGetStats.apply(this, []);
    }

    const fixChromeStats_ = function(response) {
      const standardReport = {};
      const reports = response.result();
      reports.forEach(report => {
        const standardStats = {
          id: report.id,
          timestamp: report.timestamp,
          type: {
            localcandidate: 'local-candidate',
            remotecandidate: 'remote-candidate'
          }[report.type] || report.type
        };
        report.names().forEach(name => {
          standardStats[name] = report.stat(name);
        });
        standardReport[standardStats.id] = standardStats;
      });

      return standardReport;
    };

    // shim getStats with maplike support
    const makeMapStats = function(stats) {
      return new Map(Object.keys(stats).map(key => [key, stats[key]]));
    };

    if (arguments.length >= 2) {
      const successCallbackWrapper_ = function(response) {
        onSucc(makeMapStats(fixChromeStats_(response)));
      };

      return origGetStats.apply(this, [successCallbackWrapper_,
        selector]);
    }

    // promise-support
    return new Promise((resolve, reject) => {
      origGetStats.apply(this, [
        function(response) {
          resolve(makeMapStats(fixChromeStats_(response)));
        }, reject]);
    }).then(onSucc, onErr);
  };
}

function shimSenderReceiverGetStats(window) {
  if (!(typeof window === 'object' && window.RTCPeerConnection &&
      window.RTCRtpSender && window.RTCRtpReceiver)) {
    return;
  }

  // shim sender stats.
  if (!('getStats' in window.RTCRtpSender.prototype)) {
    const origGetSenders = window.RTCPeerConnection.prototype.getSenders;
    if (origGetSenders) {
      window.RTCPeerConnection.prototype.getSenders = function getSenders() {
        const senders = origGetSenders.apply(this, []);
        senders.forEach(sender => sender._pc = this);
        return senders;
      };
    }

    const origAddTrack = window.RTCPeerConnection.prototype.addTrack;
    if (origAddTrack) {
      window.RTCPeerConnection.prototype.addTrack = function addTrack() {
        const sender = origAddTrack.apply(this, arguments);
        sender._pc = this;
        return sender;
      };
    }
    window.RTCRtpSender.prototype.getStats = function getStats() {
      const sender = this;
      return this._pc.getStats().then(result =>
        /* Note: this will include stats of all senders that
         *   send a track with the same id as sender.track as
         *   it is not possible to identify the RTCRtpSender.
         */
        _utils_js__WEBPACK_IMPORTED_MODULE_0__.filterStats(result, sender.track, true));
    };
  }

  // shim receiver stats.
  if (!('getStats' in window.RTCRtpReceiver.prototype)) {
    const origGetReceivers = window.RTCPeerConnection.prototype.getReceivers;
    if (origGetReceivers) {
      window.RTCPeerConnection.prototype.getReceivers =
        function getReceivers() {
          const receivers = origGetReceivers.apply(this, []);
          receivers.forEach(receiver => receiver._pc = this);
          return receivers;
        };
    }
    _utils_js__WEBPACK_IMPORTED_MODULE_0__.wrapPeerConnectionEvent(window, 'track', e => {
      e.receiver._pc = e.srcElement;
      return e;
    });
    window.RTCRtpReceiver.prototype.getStats = function getStats() {
      const receiver = this;
      return this._pc.getStats().then(result =>
        _utils_js__WEBPACK_IMPORTED_MODULE_0__.filterStats(result, receiver.track, false));
    };
  }

  if (!('getStats' in window.RTCRtpSender.prototype &&
      'getStats' in window.RTCRtpReceiver.prototype)) {
    return;
  }

  // shim RTCPeerConnection.getStats(track).
  const origGetStats = window.RTCPeerConnection.prototype.getStats;
  window.RTCPeerConnection.prototype.getStats = function getStats() {
    if (arguments.length > 0 &&
        arguments[0] instanceof window.MediaStreamTrack) {
      const track = arguments[0];
      let sender;
      let receiver;
      let err;
      this.getSenders().forEach(s => {
        if (s.track === track) {
          if (sender) {
            err = true;
          } else {
            sender = s;
          }
        }
      });
      this.getReceivers().forEach(r => {
        if (r.track === track) {
          if (receiver) {
            err = true;
          } else {
            receiver = r;
          }
        }
        return r.track === track;
      });
      if (err || (sender && receiver)) {
        return Promise.reject(new DOMException(
          'There are more than one sender or receiver for the track.',
          'InvalidAccessError'));
      } else if (sender) {
        return sender.getStats();
      } else if (receiver) {
        return receiver.getStats();
      }
      return Promise.reject(new DOMException(
        'There is no sender or receiver for the track.',
        'InvalidAccessError'));
    }
    return origGetStats.apply(this, arguments);
  };
}

function shimAddTrackRemoveTrackWithNative(window) {
  // shim addTrack/removeTrack with native variants in order to make
  // the interactions with legacy getLocalStreams behave as in other browsers.
  // Keeps a mapping stream.id => [stream, rtpsenders...]
  window.RTCPeerConnection.prototype.getLocalStreams =
    function getLocalStreams() {
      this._shimmedLocalStreams = this._shimmedLocalStreams || {};
      return Object.keys(this._shimmedLocalStreams)
        .map(streamId => this._shimmedLocalStreams[streamId][0]);
    };

  const origAddTrack = window.RTCPeerConnection.prototype.addTrack;
  window.RTCPeerConnection.prototype.addTrack =
    function addTrack(track, stream) {
      if (!stream) {
        return origAddTrack.apply(this, arguments);
      }
      this._shimmedLocalStreams = this._shimmedLocalStreams || {};

      const sender = origAddTrack.apply(this, arguments);
      if (!this._shimmedLocalStreams[stream.id]) {
        this._shimmedLocalStreams[stream.id] = [stream, sender];
      } else if (this._shimmedLocalStreams[stream.id].indexOf(sender) === -1) {
        this._shimmedLocalStreams[stream.id].push(sender);
      }
      return sender;
    };

  const origAddStream = window.RTCPeerConnection.prototype.addStream;
  window.RTCPeerConnection.prototype.addStream = function addStream(stream) {
    this._shimmedLocalStreams = this._shimmedLocalStreams || {};

    stream.getTracks().forEach(track => {
      const alreadyExists = this.getSenders().find(s => s.track === track);
      if (alreadyExists) {
        throw new DOMException('Track already exists.',
            'InvalidAccessError');
      }
    });
    const existingSenders = this.getSenders();
    origAddStream.apply(this, arguments);
    const newSenders = this.getSenders()
      .filter(newSender => existingSenders.indexOf(newSender) === -1);
    this._shimmedLocalStreams[stream.id] = [stream].concat(newSenders);
  };

  const origRemoveStream = window.RTCPeerConnection.prototype.removeStream;
  window.RTCPeerConnection.prototype.removeStream =
    function removeStream(stream) {
      this._shimmedLocalStreams = this._shimmedLocalStreams || {};
      delete this._shimmedLocalStreams[stream.id];
      return origRemoveStream.apply(this, arguments);
    };

  const origRemoveTrack = window.RTCPeerConnection.prototype.removeTrack;
  window.RTCPeerConnection.prototype.removeTrack =
    function removeTrack(sender) {
      this._shimmedLocalStreams = this._shimmedLocalStreams || {};
      if (sender) {
        Object.keys(this._shimmedLocalStreams).forEach(streamId => {
          const idx = this._shimmedLocalStreams[streamId].indexOf(sender);
          if (idx !== -1) {
            this._shimmedLocalStreams[streamId].splice(idx, 1);
          }
          if (this._shimmedLocalStreams[streamId].length === 1) {
            delete this._shimmedLocalStreams[streamId];
          }
        });
      }
      return origRemoveTrack.apply(this, arguments);
    };
}

function shimAddTrackRemoveTrack(window, browserDetails) {
  if (!window.RTCPeerConnection) {
    return;
  }
  // shim addTrack and removeTrack.
  if (window.RTCPeerConnection.prototype.addTrack &&
      browserDetails.version >= 65) {
    return shimAddTrackRemoveTrackWithNative(window);
  }

  // also shim pc.getLocalStreams when addTrack is shimmed
  // to return the original streams.
  const origGetLocalStreams = window.RTCPeerConnection.prototype
      .getLocalStreams;
  window.RTCPeerConnection.prototype.getLocalStreams =
    function getLocalStreams() {
      const nativeStreams = origGetLocalStreams.apply(this);
      this._reverseStreams = this._reverseStreams || {};
      return nativeStreams.map(stream => this._reverseStreams[stream.id]);
    };

  const origAddStream = window.RTCPeerConnection.prototype.addStream;
  window.RTCPeerConnection.prototype.addStream = function addStream(stream) {
    this._streams = this._streams || {};
    this._reverseStreams = this._reverseStreams || {};

    stream.getTracks().forEach(track => {
      const alreadyExists = this.getSenders().find(s => s.track === track);
      if (alreadyExists) {
        throw new DOMException('Track already exists.',
            'InvalidAccessError');
      }
    });
    // Add identity mapping for consistency with addTrack.
    // Unless this is being used with a stream from addTrack.
    if (!this._reverseStreams[stream.id]) {
      const newStream = new window.MediaStream(stream.getTracks());
      this._streams[stream.id] = newStream;
      this._reverseStreams[newStream.id] = stream;
      stream = newStream;
    }
    origAddStream.apply(this, [stream]);
  };

  const origRemoveStream = window.RTCPeerConnection.prototype.removeStream;
  window.RTCPeerConnection.prototype.removeStream =
    function removeStream(stream) {
      this._streams = this._streams || {};
      this._reverseStreams = this._reverseStreams || {};

      origRemoveStream.apply(this, [(this._streams[stream.id] || stream)]);
      delete this._reverseStreams[(this._streams[stream.id] ?
          this._streams[stream.id].id : stream.id)];
      delete this._streams[stream.id];
    };

  window.RTCPeerConnection.prototype.addTrack =
    function addTrack(track, stream) {
      if (this.signalingState === 'closed') {
        throw new DOMException(
          'The RTCPeerConnection\'s signalingState is \'closed\'.',
          'InvalidStateError');
      }
      const streams = [].slice.call(arguments, 1);
      if (streams.length !== 1 ||
          !streams[0].getTracks().find(t => t === track)) {
        // this is not fully correct but all we can manage without
        // [[associated MediaStreams]] internal slot.
        throw new DOMException(
          'The adapter.js addTrack polyfill only supports a single ' +
          ' stream which is associated with the specified track.',
          'NotSupportedError');
      }

      const alreadyExists = this.getSenders().find(s => s.track === track);
      if (alreadyExists) {
        throw new DOMException('Track already exists.',
            'InvalidAccessError');
      }

      this._streams = this._streams || {};
      this._reverseStreams = this._reverseStreams || {};
      const oldStream = this._streams[stream.id];
      if (oldStream) {
        // this is using odd Chrome behaviour, use with caution:
        // https://bugs.chromium.org/p/webrtc/issues/detail?id=7815
        // Note: we rely on the high-level addTrack/dtmf shim to
        // create the sender with a dtmf sender.
        oldStream.addTrack(track);

        // Trigger ONN async.
        Promise.resolve().then(() => {
          this.dispatchEvent(new Event('negotiationneeded'));
        });
      } else {
        const newStream = new window.MediaStream([track]);
        this._streams[stream.id] = newStream;
        this._reverseStreams[newStream.id] = stream;
        this.addStream(newStream);
      }
      return this.getSenders().find(s => s.track === track);
    };

  // replace the internal stream id with the external one and
  // vice versa.
  function replaceInternalStreamId(pc, description) {
    let sdp = description.sdp;
    Object.keys(pc._reverseStreams || []).forEach(internalId => {
      const externalStream = pc._reverseStreams[internalId];
      const internalStream = pc._streams[externalStream.id];
      sdp = sdp.replace(new RegExp(internalStream.id, 'g'),
          externalStream.id);
    });
    return new RTCSessionDescription({
      type: description.type,
      sdp
    });
  }
  function replaceExternalStreamId(pc, description) {
    let sdp = description.sdp;
    Object.keys(pc._reverseStreams || []).forEach(internalId => {
      const externalStream = pc._reverseStreams[internalId];
      const internalStream = pc._streams[externalStream.id];
      sdp = sdp.replace(new RegExp(externalStream.id, 'g'),
          internalStream.id);
    });
    return new RTCSessionDescription({
      type: description.type,
      sdp
    });
  }
  ['createOffer', 'createAnswer'].forEach(function(method) {
    const nativeMethod = window.RTCPeerConnection.prototype[method];
    const methodObj = {[method]() {
      const args = arguments;
      const isLegacyCall = arguments.length &&
          typeof arguments[0] === 'function';
      if (isLegacyCall) {
        return nativeMethod.apply(this, [
          (description) => {
            const desc = replaceInternalStreamId(this, description);
            args[0].apply(null, [desc]);
          },
          (err) => {
            if (args[1]) {
              args[1].apply(null, err);
            }
          }, arguments[2]
        ]);
      }
      return nativeMethod.apply(this, arguments)
      .then(description => replaceInternalStreamId(this, description));
    }};
    window.RTCPeerConnection.prototype[method] = methodObj[method];
  });

  const origSetLocalDescription =
      window.RTCPeerConnection.prototype.setLocalDescription;
  window.RTCPeerConnection.prototype.setLocalDescription =
    function setLocalDescription() {
      if (!arguments.length || !arguments[0].type) {
        return origSetLocalDescription.apply(this, arguments);
      }
      arguments[0] = replaceExternalStreamId(this, arguments[0]);
      return origSetLocalDescription.apply(this, arguments);
    };

  // TODO: mangle getStats: https://w3c.github.io/webrtc-stats/#dom-rtcmediastreamstats-streamidentifier

  const origLocalDescription = Object.getOwnPropertyDescriptor(
      window.RTCPeerConnection.prototype, 'localDescription');
  Object.defineProperty(window.RTCPeerConnection.prototype,
      'localDescription', {
        get() {
          const description = origLocalDescription.get.apply(this);
          if (description.type === '') {
            return description;
          }
          return replaceInternalStreamId(this, description);
        }
      });

  window.RTCPeerConnection.prototype.removeTrack =
    function removeTrack(sender) {
      if (this.signalingState === 'closed') {
        throw new DOMException(
          'The RTCPeerConnection\'s signalingState is \'closed\'.',
          'InvalidStateError');
      }
      // We can not yet check for sender instanceof RTCRtpSender
      // since we shim RTPSender. So we check if sender._pc is set.
      if (!sender._pc) {
        throw new DOMException('Argument 1 of RTCPeerConnection.removeTrack ' +
            'does not implement interface RTCRtpSender.', 'TypeError');
      }
      const isLocal = sender._pc === this;
      if (!isLocal) {
        throw new DOMException('Sender was not created by this connection.',
            'InvalidAccessError');
      }

      // Search for the native stream the senders track belongs to.
      this._streams = this._streams || {};
      let stream;
      Object.keys(this._streams).forEach(streamid => {
        const hasTrack = this._streams[streamid].getTracks()
          .find(track => sender.track === track);
        if (hasTrack) {
          stream = this._streams[streamid];
        }
      });

      if (stream) {
        if (stream.getTracks().length === 1) {
          // if this is the last track of the stream, remove the stream. This
          // takes care of any shimmed _senders.
          this.removeStream(this._reverseStreams[stream.id]);
        } else {
          // relying on the same odd chrome behaviour as above.
          stream.removeTrack(sender.track);
        }
        this.dispatchEvent(new Event('negotiationneeded'));
      }
    };
}

function shimPeerConnection(window, browserDetails) {
  if (!window.RTCPeerConnection && window.webkitRTCPeerConnection) {
    // very basic support for old versions.
    window.RTCPeerConnection = window.webkitRTCPeerConnection;
  }
  if (!window.RTCPeerConnection) {
    return;
  }

  // shim implicit creation of RTCSessionDescription/RTCIceCandidate
  if (browserDetails.version < 53) {
    ['setLocalDescription', 'setRemoteDescription', 'addIceCandidate']
        .forEach(function(method) {
          const nativeMethod = window.RTCPeerConnection.prototype[method];
          const methodObj = {[method]() {
            arguments[0] = new ((method === 'addIceCandidate') ?
                window.RTCIceCandidate :
                window.RTCSessionDescription)(arguments[0]);
            return nativeMethod.apply(this, arguments);
          }};
          window.RTCPeerConnection.prototype[method] = methodObj[method];
        });
  }
}

// Attempt to fix ONN in plan-b mode.
function fixNegotiationNeeded(window, browserDetails) {
  _utils_js__WEBPACK_IMPORTED_MODULE_0__.wrapPeerConnectionEvent(window, 'negotiationneeded', e => {
    const pc = e.target;
    if (browserDetails.version < 72 || (pc.getConfiguration &&
        pc.getConfiguration().sdpSemantics === 'plan-b')) {
      if (pc.signalingState !== 'stable') {
        return;
      }
    }
    return e;
  });
}


/***/ }),

/***/ "./node_modules/webrtc-adapter/src/js/chrome/getdisplaymedia.js":
/*!**********************************************************************!*\
  !*** ./node_modules/webrtc-adapter/src/js/chrome/getdisplaymedia.js ***!
  \**********************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   shimGetDisplayMedia: () => (/* binding */ shimGetDisplayMedia)
/* harmony export */ });
/*
 *  Copyright (c) 2018 The adapter.js project authors. All Rights Reserved.
 *
 *  Use of this source code is governed by a BSD-style license
 *  that can be found in the LICENSE file in the root of the source
 *  tree.
 */
/* eslint-env node */

function shimGetDisplayMedia(window, getSourceId) {
  if (window.navigator.mediaDevices &&
    'getDisplayMedia' in window.navigator.mediaDevices) {
    return;
  }
  if (!(window.navigator.mediaDevices)) {
    return;
  }
  // getSourceId is a function that returns a promise resolving with
  // the sourceId of the screen/window/tab to be shared.
  if (typeof getSourceId !== 'function') {
    console.error('shimGetDisplayMedia: getSourceId argument is not ' +
        'a function');
    return;
  }
  window.navigator.mediaDevices.getDisplayMedia =
    function getDisplayMedia(constraints) {
      return getSourceId(constraints)
        .then(sourceId => {
          const widthSpecified = constraints.video && constraints.video.width;
          const heightSpecified = constraints.video &&
            constraints.video.height;
          const frameRateSpecified = constraints.video &&
            constraints.video.frameRate;
          constraints.video = {
            mandatory: {
              chromeMediaSource: 'desktop',
              chromeMediaSourceId: sourceId,
              maxFrameRate: frameRateSpecified || 3
            }
          };
          if (widthSpecified) {
            constraints.video.mandatory.maxWidth = widthSpecified;
          }
          if (heightSpecified) {
            constraints.video.mandatory.maxHeight = heightSpecified;
          }
          return window.navigator.mediaDevices.getUserMedia(constraints);
        });
    };
}


/***/ }),

/***/ "./node_modules/webrtc-adapter/src/js/chrome/getusermedia.js":
/*!*******************************************************************!*\
  !*** ./node_modules/webrtc-adapter/src/js/chrome/getusermedia.js ***!
  \*******************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   shimGetUserMedia: () => (/* binding */ shimGetUserMedia)
/* harmony export */ });
/* harmony import */ var _utils_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../utils.js */ "./node_modules/webrtc-adapter/src/js/utils.js");
/*
 *  Copyright (c) 2016 The WebRTC project authors. All Rights Reserved.
 *
 *  Use of this source code is governed by a BSD-style license
 *  that can be found in the LICENSE file in the root of the source
 *  tree.
 */
/* eslint-env node */


const logging = _utils_js__WEBPACK_IMPORTED_MODULE_0__.log;

function shimGetUserMedia(window, browserDetails) {
  const navigator = window && window.navigator;

  if (!navigator.mediaDevices) {
    return;
  }

  const constraintsToChrome_ = function(c) {
    if (typeof c !== 'object' || c.mandatory || c.optional) {
      return c;
    }
    const cc = {};
    Object.keys(c).forEach(key => {
      if (key === 'require' || key === 'advanced' || key === 'mediaSource') {
        return;
      }
      const r = (typeof c[key] === 'object') ? c[key] : {ideal: c[key]};
      if (r.exact !== undefined && typeof r.exact === 'number') {
        r.min = r.max = r.exact;
      }
      const oldname_ = function(prefix, name) {
        if (prefix) {
          return prefix + name.charAt(0).toUpperCase() + name.slice(1);
        }
        return (name === 'deviceId') ? 'sourceId' : name;
      };
      if (r.ideal !== undefined) {
        cc.optional = cc.optional || [];
        let oc = {};
        if (typeof r.ideal === 'number') {
          oc[oldname_('min', key)] = r.ideal;
          cc.optional.push(oc);
          oc = {};
          oc[oldname_('max', key)] = r.ideal;
          cc.optional.push(oc);
        } else {
          oc[oldname_('', key)] = r.ideal;
          cc.optional.push(oc);
        }
      }
      if (r.exact !== undefined && typeof r.exact !== 'number') {
        cc.mandatory = cc.mandatory || {};
        cc.mandatory[oldname_('', key)] = r.exact;
      } else {
        ['min', 'max'].forEach(mix => {
          if (r[mix] !== undefined) {
            cc.mandatory = cc.mandatory || {};
            cc.mandatory[oldname_(mix, key)] = r[mix];
          }
        });
      }
    });
    if (c.advanced) {
      cc.optional = (cc.optional || []).concat(c.advanced);
    }
    return cc;
  };

  const shimConstraints_ = function(constraints, func) {
    if (browserDetails.version >= 61) {
      return func(constraints);
    }
    constraints = JSON.parse(JSON.stringify(constraints));
    if (constraints && typeof constraints.audio === 'object') {
      const remap = function(obj, a, b) {
        if (a in obj && !(b in obj)) {
          obj[b] = obj[a];
          delete obj[a];
        }
      };
      constraints = JSON.parse(JSON.stringify(constraints));
      remap(constraints.audio, 'autoGainControl', 'googAutoGainControl');
      remap(constraints.audio, 'noiseSuppression', 'googNoiseSuppression');
      constraints.audio = constraintsToChrome_(constraints.audio);
    }
    if (constraints && typeof constraints.video === 'object') {
      // Shim facingMode for mobile & surface pro.
      let face = constraints.video.facingMode;
      face = face && ((typeof face === 'object') ? face : {ideal: face});
      const getSupportedFacingModeLies = browserDetails.version < 66;

      if ((face && (face.exact === 'user' || face.exact === 'environment' ||
                    face.ideal === 'user' || face.ideal === 'environment')) &&
          !(navigator.mediaDevices.getSupportedConstraints &&
            navigator.mediaDevices.getSupportedConstraints().facingMode &&
            !getSupportedFacingModeLies)) {
        delete constraints.video.facingMode;
        let matches;
        if (face.exact === 'environment' || face.ideal === 'environment') {
          matches = ['back', 'rear'];
        } else if (face.exact === 'user' || face.ideal === 'user') {
          matches = ['front'];
        }
        if (matches) {
          // Look for matches in label, or use last cam for back (typical).
          return navigator.mediaDevices.enumerateDevices()
          .then(devices => {
            devices = devices.filter(d => d.kind === 'videoinput');
            let dev = devices.find(d => matches.some(match =>
              d.label.toLowerCase().includes(match)));
            if (!dev && devices.length && matches.includes('back')) {
              dev = devices[devices.length - 1]; // more likely the back cam
            }
            if (dev) {
              constraints.video.deviceId = face.exact ? {exact: dev.deviceId} :
                                                        {ideal: dev.deviceId};
            }
            constraints.video = constraintsToChrome_(constraints.video);
            logging('chrome: ' + JSON.stringify(constraints));
            return func(constraints);
          });
        }
      }
      constraints.video = constraintsToChrome_(constraints.video);
    }
    logging('chrome: ' + JSON.stringify(constraints));
    return func(constraints);
  };

  const shimError_ = function(e) {
    if (browserDetails.version >= 64) {
      return e;
    }
    return {
      name: {
        PermissionDeniedError: 'NotAllowedError',
        PermissionDismissedError: 'NotAllowedError',
        InvalidStateError: 'NotAllowedError',
        DevicesNotFoundError: 'NotFoundError',
        ConstraintNotSatisfiedError: 'OverconstrainedError',
        TrackStartError: 'NotReadableError',
        MediaDeviceFailedDueToShutdown: 'NotAllowedError',
        MediaDeviceKillSwitchOn: 'NotAllowedError',
        TabCaptureError: 'AbortError',
        ScreenCaptureError: 'AbortError',
        DeviceCaptureError: 'AbortError'
      }[e.name] || e.name,
      message: e.message,
      constraint: e.constraint || e.constraintName,
      toString() {
        return this.name + (this.message && ': ') + this.message;
      }
    };
  };

  const getUserMedia_ = function(constraints, onSuccess, onError) {
    shimConstraints_(constraints, c => {
      navigator.webkitGetUserMedia(c, onSuccess, e => {
        if (onError) {
          onError(shimError_(e));
        }
      });
    });
  };
  navigator.getUserMedia = getUserMedia_.bind(navigator);

  // Even though Chrome 45 has navigator.mediaDevices and a getUserMedia
  // function which returns a Promise, it does not accept spec-style
  // constraints.
  if (navigator.mediaDevices.getUserMedia) {
    const origGetUserMedia = navigator.mediaDevices.getUserMedia.
        bind(navigator.mediaDevices);
    navigator.mediaDevices.getUserMedia = function(cs) {
      return shimConstraints_(cs, c => origGetUserMedia(c).then(stream => {
        if (c.audio && !stream.getAudioTracks().length ||
            c.video && !stream.getVideoTracks().length) {
          stream.getTracks().forEach(track => {
            track.stop();
          });
          throw new DOMException('', 'NotFoundError');
        }
        return stream;
      }, e => Promise.reject(shimError_(e))));
    };
  }
}


/***/ }),

/***/ "./node_modules/webrtc-adapter/src/js/common_shim.js":
/*!***********************************************************!*\
  !*** ./node_modules/webrtc-adapter/src/js/common_shim.js ***!
  \***********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   removeExtmapAllowMixed: () => (/* binding */ removeExtmapAllowMixed),
/* harmony export */   shimAddIceCandidateNullOrEmpty: () => (/* binding */ shimAddIceCandidateNullOrEmpty),
/* harmony export */   shimConnectionState: () => (/* binding */ shimConnectionState),
/* harmony export */   shimMaxMessageSize: () => (/* binding */ shimMaxMessageSize),
/* harmony export */   shimParameterlessSetLocalDescription: () => (/* binding */ shimParameterlessSetLocalDescription),
/* harmony export */   shimRTCIceCandidate: () => (/* binding */ shimRTCIceCandidate),
/* harmony export */   shimSendThrowTypeError: () => (/* binding */ shimSendThrowTypeError)
/* harmony export */ });
/* harmony import */ var sdp__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! sdp */ "./node_modules/sdp/sdp.js");
/* harmony import */ var sdp__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(sdp__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var _utils__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./utils */ "./node_modules/webrtc-adapter/src/js/utils.js");
/*
 *  Copyright (c) 2017 The WebRTC project authors. All Rights Reserved.
 *
 *  Use of this source code is governed by a BSD-style license
 *  that can be found in the LICENSE file in the root of the source
 *  tree.
 */
/* eslint-env node */





function shimRTCIceCandidate(window) {
  // foundation is arbitrarily chosen as an indicator for full support for
  // https://w3c.github.io/webrtc-pc/#rtcicecandidate-interface
  if (!window.RTCIceCandidate || (window.RTCIceCandidate && 'foundation' in
      window.RTCIceCandidate.prototype)) {
    return;
  }

  const NativeRTCIceCandidate = window.RTCIceCandidate;
  window.RTCIceCandidate = function RTCIceCandidate(args) {
    // Remove the a= which shouldn't be part of the candidate string.
    if (typeof args === 'object' && args.candidate &&
        args.candidate.indexOf('a=') === 0) {
      args = JSON.parse(JSON.stringify(args));
      args.candidate = args.candidate.substr(2);
    }

    if (args.candidate && args.candidate.length) {
      // Augment the native candidate with the parsed fields.
      const nativeCandidate = new NativeRTCIceCandidate(args);
      const parsedCandidate = sdp__WEBPACK_IMPORTED_MODULE_0___default().parseCandidate(args.candidate);
      const augmentedCandidate = Object.assign(nativeCandidate,
          parsedCandidate);

      // Add a serializer that does not serialize the extra attributes.
      augmentedCandidate.toJSON = function toJSON() {
        return {
          candidate: augmentedCandidate.candidate,
          sdpMid: augmentedCandidate.sdpMid,
          sdpMLineIndex: augmentedCandidate.sdpMLineIndex,
          usernameFragment: augmentedCandidate.usernameFragment,
        };
      };
      return augmentedCandidate;
    }
    return new NativeRTCIceCandidate(args);
  };
  window.RTCIceCandidate.prototype = NativeRTCIceCandidate.prototype;

  // Hook up the augmented candidate in onicecandidate and
  // addEventListener('icecandidate', ...)
  _utils__WEBPACK_IMPORTED_MODULE_1__.wrapPeerConnectionEvent(window, 'icecandidate', e => {
    if (e.candidate) {
      Object.defineProperty(e, 'candidate', {
        value: new window.RTCIceCandidate(e.candidate),
        writable: 'false'
      });
    }
    return e;
  });
}

function shimMaxMessageSize(window, browserDetails) {
  if (!window.RTCPeerConnection) {
    return;
  }

  if (!('sctp' in window.RTCPeerConnection.prototype)) {
    Object.defineProperty(window.RTCPeerConnection.prototype, 'sctp', {
      get() {
        return typeof this._sctp === 'undefined' ? null : this._sctp;
      }
    });
  }

  const sctpInDescription = function(description) {
    if (!description || !description.sdp) {
      return false;
    }
    const sections = sdp__WEBPACK_IMPORTED_MODULE_0___default().splitSections(description.sdp);
    sections.shift();
    return sections.some(mediaSection => {
      const mLine = sdp__WEBPACK_IMPORTED_MODULE_0___default().parseMLine(mediaSection);
      return mLine && mLine.kind === 'application'
          && mLine.protocol.indexOf('SCTP') !== -1;
    });
  };

  const getRemoteFirefoxVersion = function(description) {
    // TODO: Is there a better solution for detecting Firefox?
    const match = description.sdp.match(/mozilla...THIS_IS_SDPARTA-(\d+)/);
    if (match === null || match.length < 2) {
      return -1;
    }
    const version = parseInt(match[1], 10);
    // Test for NaN (yes, this is ugly)
    return version !== version ? -1 : version;
  };

  const getCanSendMaxMessageSize = function(remoteIsFirefox) {
    // Every implementation we know can send at least 64 KiB.
    // Note: Although Chrome is technically able to send up to 256 KiB, the
    //       data does not reach the other peer reliably.
    //       See: https://bugs.chromium.org/p/webrtc/issues/detail?id=8419
    let canSendMaxMessageSize = 65536;
    if (browserDetails.browser === 'firefox') {
      if (browserDetails.version < 57) {
        if (remoteIsFirefox === -1) {
          // FF < 57 will send in 16 KiB chunks using the deprecated PPID
          // fragmentation.
          canSendMaxMessageSize = 16384;
        } else {
          // However, other FF (and RAWRTC) can reassemble PPID-fragmented
          // messages. Thus, supporting ~2 GiB when sending.
          canSendMaxMessageSize = 2147483637;
        }
      } else if (browserDetails.version < 60) {
        // Currently, all FF >= 57 will reset the remote maximum message size
        // to the default value when a data channel is created at a later
        // stage. :(
        // See: https://bugzilla.mozilla.org/show_bug.cgi?id=1426831
        canSendMaxMessageSize =
          browserDetails.version === 57 ? 65535 : 65536;
      } else {
        // FF >= 60 supports sending ~2 GiB
        canSendMaxMessageSize = 2147483637;
      }
    }
    return canSendMaxMessageSize;
  };

  const getMaxMessageSize = function(description, remoteIsFirefox) {
    // Note: 65536 bytes is the default value from the SDP spec. Also,
    //       every implementation we know supports receiving 65536 bytes.
    let maxMessageSize = 65536;

    // FF 57 has a slightly incorrect default remote max message size, so
    // we need to adjust it here to avoid a failure when sending.
    // See: https://bugzilla.mozilla.org/show_bug.cgi?id=1425697
    if (browserDetails.browser === 'firefox'
         && browserDetails.version === 57) {
      maxMessageSize = 65535;
    }

    const match = sdp__WEBPACK_IMPORTED_MODULE_0___default().matchPrefix(description.sdp,
      'a=max-message-size:');
    if (match.length > 0) {
      maxMessageSize = parseInt(match[0].substr(19), 10);
    } else if (browserDetails.browser === 'firefox' &&
                remoteIsFirefox !== -1) {
      // If the maximum message size is not present in the remote SDP and
      // both local and remote are Firefox, the remote peer can receive
      // ~2 GiB.
      maxMessageSize = 2147483637;
    }
    return maxMessageSize;
  };

  const origSetRemoteDescription =
      window.RTCPeerConnection.prototype.setRemoteDescription;
  window.RTCPeerConnection.prototype.setRemoteDescription =
    function setRemoteDescription() {
      this._sctp = null;
      // Chrome decided to not expose .sctp in plan-b mode.
      // As usual, adapter.js has to do an 'ugly worakaround'
      // to cover up the mess.
      if (browserDetails.browser === 'chrome' && browserDetails.version >= 76) {
        const {sdpSemantics} = this.getConfiguration();
        if (sdpSemantics === 'plan-b') {
          Object.defineProperty(this, 'sctp', {
            get() {
              return typeof this._sctp === 'undefined' ? null : this._sctp;
            },
            enumerable: true,
            configurable: true,
          });
        }
      }

      if (sctpInDescription(arguments[0])) {
        // Check if the remote is FF.
        const isFirefox = getRemoteFirefoxVersion(arguments[0]);

        // Get the maximum message size the local peer is capable of sending
        const canSendMMS = getCanSendMaxMessageSize(isFirefox);

        // Get the maximum message size of the remote peer.
        const remoteMMS = getMaxMessageSize(arguments[0], isFirefox);

        // Determine final maximum message size
        let maxMessageSize;
        if (canSendMMS === 0 && remoteMMS === 0) {
          maxMessageSize = Number.POSITIVE_INFINITY;
        } else if (canSendMMS === 0 || remoteMMS === 0) {
          maxMessageSize = Math.max(canSendMMS, remoteMMS);
        } else {
          maxMessageSize = Math.min(canSendMMS, remoteMMS);
        }

        // Create a dummy RTCSctpTransport object and the 'maxMessageSize'
        // attribute.
        const sctp = {};
        Object.defineProperty(sctp, 'maxMessageSize', {
          get() {
            return maxMessageSize;
          }
        });
        this._sctp = sctp;
      }

      return origSetRemoteDescription.apply(this, arguments);
    };
}

function shimSendThrowTypeError(window) {
  if (!(window.RTCPeerConnection &&
      'createDataChannel' in window.RTCPeerConnection.prototype)) {
    return;
  }

  // Note: Although Firefox >= 57 has a native implementation, the maximum
  //       message size can be reset for all data channels at a later stage.
  //       See: https://bugzilla.mozilla.org/show_bug.cgi?id=1426831

  function wrapDcSend(dc, pc) {
    const origDataChannelSend = dc.send;
    dc.send = function send() {
      const data = arguments[0];
      const length = data.length || data.size || data.byteLength;
      if (dc.readyState === 'open' &&
          pc.sctp && length > pc.sctp.maxMessageSize) {
        throw new TypeError('Message too large (can send a maximum of ' +
          pc.sctp.maxMessageSize + ' bytes)');
      }
      return origDataChannelSend.apply(dc, arguments);
    };
  }
  const origCreateDataChannel =
    window.RTCPeerConnection.prototype.createDataChannel;
  window.RTCPeerConnection.prototype.createDataChannel =
    function createDataChannel() {
      const dataChannel = origCreateDataChannel.apply(this, arguments);
      wrapDcSend(dataChannel, this);
      return dataChannel;
    };
  _utils__WEBPACK_IMPORTED_MODULE_1__.wrapPeerConnectionEvent(window, 'datachannel', e => {
    wrapDcSend(e.channel, e.target);
    return e;
  });
}


/* shims RTCConnectionState by pretending it is the same as iceConnectionState.
 * See https://bugs.chromium.org/p/webrtc/issues/detail?id=6145#c12
 * for why this is a valid hack in Chrome. In Firefox it is slightly incorrect
 * since DTLS failures would be hidden. See
 * https://bugzilla.mozilla.org/show_bug.cgi?id=1265827
 * for the Firefox tracking bug.
 */
function shimConnectionState(window) {
  if (!window.RTCPeerConnection ||
      'connectionState' in window.RTCPeerConnection.prototype) {
    return;
  }
  const proto = window.RTCPeerConnection.prototype;
  Object.defineProperty(proto, 'connectionState', {
    get() {
      return {
        completed: 'connected',
        checking: 'connecting'
      }[this.iceConnectionState] || this.iceConnectionState;
    },
    enumerable: true,
    configurable: true
  });
  Object.defineProperty(proto, 'onconnectionstatechange', {
    get() {
      return this._onconnectionstatechange || null;
    },
    set(cb) {
      if (this._onconnectionstatechange) {
        this.removeEventListener('connectionstatechange',
            this._onconnectionstatechange);
        delete this._onconnectionstatechange;
      }
      if (cb) {
        this.addEventListener('connectionstatechange',
            this._onconnectionstatechange = cb);
      }
    },
    enumerable: true,
    configurable: true
  });

  ['setLocalDescription', 'setRemoteDescription'].forEach((method) => {
    const origMethod = proto[method];
    proto[method] = function() {
      if (!this._connectionstatechangepoly) {
        this._connectionstatechangepoly = e => {
          const pc = e.target;
          if (pc._lastConnectionState !== pc.connectionState) {
            pc._lastConnectionState = pc.connectionState;
            const newEvent = new Event('connectionstatechange', e);
            pc.dispatchEvent(newEvent);
          }
          return e;
        };
        this.addEventListener('iceconnectionstatechange',
          this._connectionstatechangepoly);
      }
      return origMethod.apply(this, arguments);
    };
  });
}

function removeExtmapAllowMixed(window, browserDetails) {
  /* remove a=extmap-allow-mixed for webrtc.org < M71 */
  if (!window.RTCPeerConnection) {
    return;
  }
  if (browserDetails.browser === 'chrome' && browserDetails.version >= 71) {
    return;
  }
  if (browserDetails.browser === 'safari' && browserDetails.version >= 605) {
    return;
  }
  const nativeSRD = window.RTCPeerConnection.prototype.setRemoteDescription;
  window.RTCPeerConnection.prototype.setRemoteDescription =
  function setRemoteDescription(desc) {
    if (desc && desc.sdp && desc.sdp.indexOf('\na=extmap-allow-mixed') !== -1) {
      const sdp = desc.sdp.split('\n').filter((line) => {
        return line.trim() !== 'a=extmap-allow-mixed';
      }).join('\n');
      // Safari enforces read-only-ness of RTCSessionDescription fields.
      if (window.RTCSessionDescription &&
          desc instanceof window.RTCSessionDescription) {
        arguments[0] = new window.RTCSessionDescription({
          type: desc.type,
          sdp,
        });
      } else {
        desc.sdp = sdp;
      }
    }
    return nativeSRD.apply(this, arguments);
  };
}

function shimAddIceCandidateNullOrEmpty(window, browserDetails) {
  // Support for addIceCandidate(null or undefined)
  // as well as addIceCandidate({candidate: "", ...})
  // https://bugs.chromium.org/p/chromium/issues/detail?id=978582
  // Note: must be called before other polyfills which change the signature.
  if (!(window.RTCPeerConnection && window.RTCPeerConnection.prototype)) {
    return;
  }
  const nativeAddIceCandidate =
      window.RTCPeerConnection.prototype.addIceCandidate;
  if (!nativeAddIceCandidate || nativeAddIceCandidate.length === 0) {
    return;
  }
  window.RTCPeerConnection.prototype.addIceCandidate =
    function addIceCandidate() {
      if (!arguments[0]) {
        if (arguments[1]) {
          arguments[1].apply(null);
        }
        return Promise.resolve();
      }
      // Firefox 68+ emits and processes {candidate: "", ...}, ignore
      // in older versions.
      // Native support for ignoring exists for Chrome M77+.
      // Safari ignores as well, exact version unknown but works in the same
      // version that also ignores addIceCandidate(null).
      if (((browserDetails.browser === 'chrome' && browserDetails.version < 78)
           || (browserDetails.browser === 'firefox'
               && browserDetails.version < 68)
           || (browserDetails.browser === 'safari'))
          && arguments[0] && arguments[0].candidate === '') {
        return Promise.resolve();
      }
      return nativeAddIceCandidate.apply(this, arguments);
    };
}

// Note: Make sure to call this ahead of APIs that modify
// setLocalDescription.length
function shimParameterlessSetLocalDescription(window, browserDetails) {
  if (!(window.RTCPeerConnection && window.RTCPeerConnection.prototype)) {
    return;
  }
  const nativeSetLocalDescription =
      window.RTCPeerConnection.prototype.setLocalDescription;
  if (!nativeSetLocalDescription || nativeSetLocalDescription.length === 0) {
    return;
  }
  window.RTCPeerConnection.prototype.setLocalDescription =
    function setLocalDescription() {
      let desc = arguments[0] || {};
      if (typeof desc !== 'object' || (desc.type && desc.sdp)) {
        return nativeSetLocalDescription.apply(this, arguments);
      }
      // The remaining steps should technically happen when SLD comes off the
      // RTCPeerConnection's operations chain (not ahead of going on it), but
      // this is too difficult to shim. Instead, this shim only covers the
      // common case where the operations chain is empty. This is imperfect, but
      // should cover many cases. Rationale: Even if we can't reduce the glare
      // window to zero on imperfect implementations, there's value in tapping
      // into the perfect negotiation pattern that several browsers support.
      desc = {type: desc.type, sdp: desc.sdp};
      if (!desc.type) {
        switch (this.signalingState) {
          case 'stable':
          case 'have-local-offer':
          case 'have-remote-pranswer':
            desc.type = 'offer';
            break;
          default:
            desc.type = 'answer';
            break;
        }
      }
      if (desc.sdp || (desc.type !== 'offer' && desc.type !== 'answer')) {
        return nativeSetLocalDescription.apply(this, [desc]);
      }
      const func = desc.type === 'offer' ? this.createOffer : this.createAnswer;
      return func.apply(this)
        .then(d => nativeSetLocalDescription.apply(this, [d]));
    };
}


/***/ }),

/***/ "./node_modules/webrtc-adapter/src/js/firefox/firefox_shim.js":
/*!********************************************************************!*\
  !*** ./node_modules/webrtc-adapter/src/js/firefox/firefox_shim.js ***!
  \********************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   shimAddTransceiver: () => (/* binding */ shimAddTransceiver),
/* harmony export */   shimCreateAnswer: () => (/* binding */ shimCreateAnswer),
/* harmony export */   shimCreateOffer: () => (/* binding */ shimCreateOffer),
/* harmony export */   shimGetDisplayMedia: () => (/* reexport safe */ _getdisplaymedia__WEBPACK_IMPORTED_MODULE_2__.shimGetDisplayMedia),
/* harmony export */   shimGetParameters: () => (/* binding */ shimGetParameters),
/* harmony export */   shimGetUserMedia: () => (/* reexport safe */ _getusermedia__WEBPACK_IMPORTED_MODULE_1__.shimGetUserMedia),
/* harmony export */   shimOnTrack: () => (/* binding */ shimOnTrack),
/* harmony export */   shimPeerConnection: () => (/* binding */ shimPeerConnection),
/* harmony export */   shimRTCDataChannel: () => (/* binding */ shimRTCDataChannel),
/* harmony export */   shimReceiverGetStats: () => (/* binding */ shimReceiverGetStats),
/* harmony export */   shimRemoveStream: () => (/* binding */ shimRemoveStream),
/* harmony export */   shimSenderGetStats: () => (/* binding */ shimSenderGetStats)
/* harmony export */ });
/* harmony import */ var _utils__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../utils */ "./node_modules/webrtc-adapter/src/js/utils.js");
/* harmony import */ var _getusermedia__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./getusermedia */ "./node_modules/webrtc-adapter/src/js/firefox/getusermedia.js");
/* harmony import */ var _getdisplaymedia__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./getdisplaymedia */ "./node_modules/webrtc-adapter/src/js/firefox/getdisplaymedia.js");
/*
 *  Copyright (c) 2016 The WebRTC project authors. All Rights Reserved.
 *
 *  Use of this source code is governed by a BSD-style license
 *  that can be found in the LICENSE file in the root of the source
 *  tree.
 */
/* eslint-env node */






function shimOnTrack(window) {
  if (typeof window === 'object' && window.RTCTrackEvent &&
      ('receiver' in window.RTCTrackEvent.prototype) &&
      !('transceiver' in window.RTCTrackEvent.prototype)) {
    Object.defineProperty(window.RTCTrackEvent.prototype, 'transceiver', {
      get() {
        return {receiver: this.receiver};
      }
    });
  }
}

function shimPeerConnection(window, browserDetails) {
  if (typeof window !== 'object' ||
      !(window.RTCPeerConnection || window.mozRTCPeerConnection)) {
    return; // probably media.peerconnection.enabled=false in about:config
  }
  if (!window.RTCPeerConnection && window.mozRTCPeerConnection) {
    // very basic support for old versions.
    window.RTCPeerConnection = window.mozRTCPeerConnection;
  }

  if (browserDetails.version < 53) {
    // shim away need for obsolete RTCIceCandidate/RTCSessionDescription.
    ['setLocalDescription', 'setRemoteDescription', 'addIceCandidate']
        .forEach(function(method) {
          const nativeMethod = window.RTCPeerConnection.prototype[method];
          const methodObj = {[method]() {
            arguments[0] = new ((method === 'addIceCandidate') ?
                window.RTCIceCandidate :
                window.RTCSessionDescription)(arguments[0]);
            return nativeMethod.apply(this, arguments);
          }};
          window.RTCPeerConnection.prototype[method] = methodObj[method];
        });
  }

  const modernStatsTypes = {
    inboundrtp: 'inbound-rtp',
    outboundrtp: 'outbound-rtp',
    candidatepair: 'candidate-pair',
    localcandidate: 'local-candidate',
    remotecandidate: 'remote-candidate'
  };

  const nativeGetStats = window.RTCPeerConnection.prototype.getStats;
  window.RTCPeerConnection.prototype.getStats = function getStats() {
    const [selector, onSucc, onErr] = arguments;
    return nativeGetStats.apply(this, [selector || null])
      .then(stats => {
        if (browserDetails.version < 53 && !onSucc) {
          // Shim only promise getStats with spec-hyphens in type names
          // Leave callback version alone; misc old uses of forEach before Map
          try {
            stats.forEach(stat => {
              stat.type = modernStatsTypes[stat.type] || stat.type;
            });
          } catch (e) {
            if (e.name !== 'TypeError') {
              throw e;
            }
            // Avoid TypeError: "type" is read-only, in old versions. 34-43ish
            stats.forEach((stat, i) => {
              stats.set(i, Object.assign({}, stat, {
                type: modernStatsTypes[stat.type] || stat.type
              }));
            });
          }
        }
        return stats;
      })
      .then(onSucc, onErr);
  };
}

function shimSenderGetStats(window) {
  if (!(typeof window === 'object' && window.RTCPeerConnection &&
      window.RTCRtpSender)) {
    return;
  }
  if (window.RTCRtpSender && 'getStats' in window.RTCRtpSender.prototype) {
    return;
  }
  const origGetSenders = window.RTCPeerConnection.prototype.getSenders;
  if (origGetSenders) {
    window.RTCPeerConnection.prototype.getSenders = function getSenders() {
      const senders = origGetSenders.apply(this, []);
      senders.forEach(sender => sender._pc = this);
      return senders;
    };
  }

  const origAddTrack = window.RTCPeerConnection.prototype.addTrack;
  if (origAddTrack) {
    window.RTCPeerConnection.prototype.addTrack = function addTrack() {
      const sender = origAddTrack.apply(this, arguments);
      sender._pc = this;
      return sender;
    };
  }
  window.RTCRtpSender.prototype.getStats = function getStats() {
    return this.track ? this._pc.getStats(this.track) :
        Promise.resolve(new Map());
  };
}

function shimReceiverGetStats(window) {
  if (!(typeof window === 'object' && window.RTCPeerConnection &&
      window.RTCRtpSender)) {
    return;
  }
  if (window.RTCRtpSender && 'getStats' in window.RTCRtpReceiver.prototype) {
    return;
  }
  const origGetReceivers = window.RTCPeerConnection.prototype.getReceivers;
  if (origGetReceivers) {
    window.RTCPeerConnection.prototype.getReceivers = function getReceivers() {
      const receivers = origGetReceivers.apply(this, []);
      receivers.forEach(receiver => receiver._pc = this);
      return receivers;
    };
  }
  _utils__WEBPACK_IMPORTED_MODULE_0__.wrapPeerConnectionEvent(window, 'track', e => {
    e.receiver._pc = e.srcElement;
    return e;
  });
  window.RTCRtpReceiver.prototype.getStats = function getStats() {
    return this._pc.getStats(this.track);
  };
}

function shimRemoveStream(window) {
  if (!window.RTCPeerConnection ||
      'removeStream' in window.RTCPeerConnection.prototype) {
    return;
  }
  window.RTCPeerConnection.prototype.removeStream =
    function removeStream(stream) {
      _utils__WEBPACK_IMPORTED_MODULE_0__.deprecated('removeStream', 'removeTrack');
      this.getSenders().forEach(sender => {
        if (sender.track && stream.getTracks().includes(sender.track)) {
          this.removeTrack(sender);
        }
      });
    };
}

function shimRTCDataChannel(window) {
  // rename DataChannel to RTCDataChannel (native fix in FF60):
  // https://bugzilla.mozilla.org/show_bug.cgi?id=1173851
  if (window.DataChannel && !window.RTCDataChannel) {
    window.RTCDataChannel = window.DataChannel;
  }
}

function shimAddTransceiver(window) {
  // https://github.com/webrtcHacks/adapter/issues/998#issuecomment-516921647
  // Firefox ignores the init sendEncodings options passed to addTransceiver
  // https://bugzilla.mozilla.org/show_bug.cgi?id=1396918
  if (!(typeof window === 'object' && window.RTCPeerConnection)) {
    return;
  }
  const origAddTransceiver = window.RTCPeerConnection.prototype.addTransceiver;
  if (origAddTransceiver) {
    window.RTCPeerConnection.prototype.addTransceiver =
      function addTransceiver() {
        this.setParametersPromises = [];
        const initParameters = arguments[1];
        const shouldPerformCheck = initParameters &&
                                  'sendEncodings' in initParameters;
        if (shouldPerformCheck) {
          // If sendEncodings params are provided, validate grammar
          initParameters.sendEncodings.forEach((encodingParam) => {
            if ('rid' in encodingParam) {
              const ridRegex = /^[a-z0-9]{0,16}$/i;
              if (!ridRegex.test(encodingParam.rid)) {
                throw new TypeError('Invalid RID value provided.');
              }
            }
            if ('scaleResolutionDownBy' in encodingParam) {
              if (!(parseFloat(encodingParam.scaleResolutionDownBy) >= 1.0)) {
                throw new RangeError('scale_resolution_down_by must be >= 1.0');
              }
            }
            if ('maxFramerate' in encodingParam) {
              if (!(parseFloat(encodingParam.maxFramerate) >= 0)) {
                throw new RangeError('max_framerate must be >= 0.0');
              }
            }
          });
        }
        const transceiver = origAddTransceiver.apply(this, arguments);
        if (shouldPerformCheck) {
          // Check if the init options were applied. If not we do this in an
          // asynchronous way and save the promise reference in a global object.
          // This is an ugly hack, but at the same time is way more robust than
          // checking the sender parameters before and after the createOffer
          // Also note that after the createoffer we are not 100% sure that
          // the params were asynchronously applied so we might miss the
          // opportunity to recreate offer.
          const {sender} = transceiver;
          const params = sender.getParameters();
          if (!('encodings' in params) ||
              // Avoid being fooled by patched getParameters() below.
              (params.encodings.length === 1 &&
               Object.keys(params.encodings[0]).length === 0)) {
            params.encodings = initParameters.sendEncodings;
            sender.sendEncodings = initParameters.sendEncodings;
            this.setParametersPromises.push(sender.setParameters(params)
              .then(() => {
                delete sender.sendEncodings;
              }).catch(() => {
                delete sender.sendEncodings;
              })
            );
          }
        }
        return transceiver;
      };
  }
}

function shimGetParameters(window) {
  if (!(typeof window === 'object' && window.RTCRtpSender)) {
    return;
  }
  const origGetParameters = window.RTCRtpSender.prototype.getParameters;
  if (origGetParameters) {
    window.RTCRtpSender.prototype.getParameters =
      function getParameters() {
        const params = origGetParameters.apply(this, arguments);
        if (!('encodings' in params)) {
          params.encodings = [].concat(this.sendEncodings || [{}]);
        }
        return params;
      };
  }
}

function shimCreateOffer(window) {
  // https://github.com/webrtcHacks/adapter/issues/998#issuecomment-516921647
  // Firefox ignores the init sendEncodings options passed to addTransceiver
  // https://bugzilla.mozilla.org/show_bug.cgi?id=1396918
  if (!(typeof window === 'object' && window.RTCPeerConnection)) {
    return;
  }
  const origCreateOffer = window.RTCPeerConnection.prototype.createOffer;
  window.RTCPeerConnection.prototype.createOffer = function createOffer() {
    if (this.setParametersPromises && this.setParametersPromises.length) {
      return Promise.all(this.setParametersPromises)
      .then(() => {
        return origCreateOffer.apply(this, arguments);
      })
      .finally(() => {
        this.setParametersPromises = [];
      });
    }
    return origCreateOffer.apply(this, arguments);
  };
}

function shimCreateAnswer(window) {
  // https://github.com/webrtcHacks/adapter/issues/998#issuecomment-516921647
  // Firefox ignores the init sendEncodings options passed to addTransceiver
  // https://bugzilla.mozilla.org/show_bug.cgi?id=1396918
  if (!(typeof window === 'object' && window.RTCPeerConnection)) {
    return;
  }
  const origCreateAnswer = window.RTCPeerConnection.prototype.createAnswer;
  window.RTCPeerConnection.prototype.createAnswer = function createAnswer() {
    if (this.setParametersPromises && this.setParametersPromises.length) {
      return Promise.all(this.setParametersPromises)
      .then(() => {
        return origCreateAnswer.apply(this, arguments);
      })
      .finally(() => {
        this.setParametersPromises = [];
      });
    }
    return origCreateAnswer.apply(this, arguments);
  };
}


/***/ }),

/***/ "./node_modules/webrtc-adapter/src/js/firefox/getdisplaymedia.js":
/*!***********************************************************************!*\
  !*** ./node_modules/webrtc-adapter/src/js/firefox/getdisplaymedia.js ***!
  \***********************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   shimGetDisplayMedia: () => (/* binding */ shimGetDisplayMedia)
/* harmony export */ });
/*
 *  Copyright (c) 2018 The adapter.js project authors. All Rights Reserved.
 *
 *  Use of this source code is governed by a BSD-style license
 *  that can be found in the LICENSE file in the root of the source
 *  tree.
 */
/* eslint-env node */


function shimGetDisplayMedia(window, preferredMediaSource) {
  if (window.navigator.mediaDevices &&
    'getDisplayMedia' in window.navigator.mediaDevices) {
    return;
  }
  if (!(window.navigator.mediaDevices)) {
    return;
  }
  window.navigator.mediaDevices.getDisplayMedia =
    function getDisplayMedia(constraints) {
      if (!(constraints && constraints.video)) {
        const err = new DOMException('getDisplayMedia without video ' +
            'constraints is undefined');
        err.name = 'NotFoundError';
        // from https://heycam.github.io/webidl/#idl-DOMException-error-names
        err.code = 8;
        return Promise.reject(err);
      }
      if (constraints.video === true) {
        constraints.video = {mediaSource: preferredMediaSource};
      } else {
        constraints.video.mediaSource = preferredMediaSource;
      }
      return window.navigator.mediaDevices.getUserMedia(constraints);
    };
}


/***/ }),

/***/ "./node_modules/webrtc-adapter/src/js/firefox/getusermedia.js":
/*!********************************************************************!*\
  !*** ./node_modules/webrtc-adapter/src/js/firefox/getusermedia.js ***!
  \********************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   shimGetUserMedia: () => (/* binding */ shimGetUserMedia)
/* harmony export */ });
/* harmony import */ var _utils__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../utils */ "./node_modules/webrtc-adapter/src/js/utils.js");
/*
 *  Copyright (c) 2016 The WebRTC project authors. All Rights Reserved.
 *
 *  Use of this source code is governed by a BSD-style license
 *  that can be found in the LICENSE file in the root of the source
 *  tree.
 */
/* eslint-env node */




function shimGetUserMedia(window, browserDetails) {
  const navigator = window && window.navigator;
  const MediaStreamTrack = window && window.MediaStreamTrack;

  navigator.getUserMedia = function(constraints, onSuccess, onError) {
    // Replace Firefox 44+'s deprecation warning with unprefixed version.
    _utils__WEBPACK_IMPORTED_MODULE_0__.deprecated('navigator.getUserMedia',
        'navigator.mediaDevices.getUserMedia');
    navigator.mediaDevices.getUserMedia(constraints).then(onSuccess, onError);
  };

  if (!(browserDetails.version > 55 &&
      'autoGainControl' in navigator.mediaDevices.getSupportedConstraints())) {
    const remap = function(obj, a, b) {
      if (a in obj && !(b in obj)) {
        obj[b] = obj[a];
        delete obj[a];
      }
    };

    const nativeGetUserMedia = navigator.mediaDevices.getUserMedia.
        bind(navigator.mediaDevices);
    navigator.mediaDevices.getUserMedia = function(c) {
      if (typeof c === 'object' && typeof c.audio === 'object') {
        c = JSON.parse(JSON.stringify(c));
        remap(c.audio, 'autoGainControl', 'mozAutoGainControl');
        remap(c.audio, 'noiseSuppression', 'mozNoiseSuppression');
      }
      return nativeGetUserMedia(c);
    };

    if (MediaStreamTrack && MediaStreamTrack.prototype.getSettings) {
      const nativeGetSettings = MediaStreamTrack.prototype.getSettings;
      MediaStreamTrack.prototype.getSettings = function() {
        const obj = nativeGetSettings.apply(this, arguments);
        remap(obj, 'mozAutoGainControl', 'autoGainControl');
        remap(obj, 'mozNoiseSuppression', 'noiseSuppression');
        return obj;
      };
    }

    if (MediaStreamTrack && MediaStreamTrack.prototype.applyConstraints) {
      const nativeApplyConstraints =
        MediaStreamTrack.prototype.applyConstraints;
      MediaStreamTrack.prototype.applyConstraints = function(c) {
        if (this.kind === 'audio' && typeof c === 'object') {
          c = JSON.parse(JSON.stringify(c));
          remap(c, 'autoGainControl', 'mozAutoGainControl');
          remap(c, 'noiseSuppression', 'mozNoiseSuppression');
        }
        return nativeApplyConstraints.apply(this, [c]);
      };
    }
  }
}


/***/ }),

/***/ "./node_modules/webrtc-adapter/src/js/safari/safari_shim.js":
/*!******************************************************************!*\
  !*** ./node_modules/webrtc-adapter/src/js/safari/safari_shim.js ***!
  \******************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   shimAudioContext: () => (/* binding */ shimAudioContext),
/* harmony export */   shimCallbacksAPI: () => (/* binding */ shimCallbacksAPI),
/* harmony export */   shimConstraints: () => (/* binding */ shimConstraints),
/* harmony export */   shimCreateOfferLegacy: () => (/* binding */ shimCreateOfferLegacy),
/* harmony export */   shimGetUserMedia: () => (/* binding */ shimGetUserMedia),
/* harmony export */   shimLocalStreamsAPI: () => (/* binding */ shimLocalStreamsAPI),
/* harmony export */   shimRTCIceServerUrls: () => (/* binding */ shimRTCIceServerUrls),
/* harmony export */   shimRemoteStreamsAPI: () => (/* binding */ shimRemoteStreamsAPI),
/* harmony export */   shimTrackEventTransceiver: () => (/* binding */ shimTrackEventTransceiver)
/* harmony export */ });
/* harmony import */ var _utils__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../utils */ "./node_modules/webrtc-adapter/src/js/utils.js");
/*
 *  Copyright (c) 2016 The WebRTC project authors. All Rights Reserved.
 *
 *  Use of this source code is governed by a BSD-style license
 *  that can be found in the LICENSE file in the root of the source
 *  tree.
 */



function shimLocalStreamsAPI(window) {
  if (typeof window !== 'object' || !window.RTCPeerConnection) {
    return;
  }
  if (!('getLocalStreams' in window.RTCPeerConnection.prototype)) {
    window.RTCPeerConnection.prototype.getLocalStreams =
      function getLocalStreams() {
        if (!this._localStreams) {
          this._localStreams = [];
        }
        return this._localStreams;
      };
  }
  if (!('addStream' in window.RTCPeerConnection.prototype)) {
    const _addTrack = window.RTCPeerConnection.prototype.addTrack;
    window.RTCPeerConnection.prototype.addStream = function addStream(stream) {
      if (!this._localStreams) {
        this._localStreams = [];
      }
      if (!this._localStreams.includes(stream)) {
        this._localStreams.push(stream);
      }
      // Try to emulate Chrome's behaviour of adding in audio-video order.
      // Safari orders by track id.
      stream.getAudioTracks().forEach(track => _addTrack.call(this, track,
        stream));
      stream.getVideoTracks().forEach(track => _addTrack.call(this, track,
        stream));
    };

    window.RTCPeerConnection.prototype.addTrack =
      function addTrack(track, ...streams) {
        if (streams) {
          streams.forEach((stream) => {
            if (!this._localStreams) {
              this._localStreams = [stream];
            } else if (!this._localStreams.includes(stream)) {
              this._localStreams.push(stream);
            }
          });
        }
        return _addTrack.apply(this, arguments);
      };
  }
  if (!('removeStream' in window.RTCPeerConnection.prototype)) {
    window.RTCPeerConnection.prototype.removeStream =
      function removeStream(stream) {
        if (!this._localStreams) {
          this._localStreams = [];
        }
        const index = this._localStreams.indexOf(stream);
        if (index === -1) {
          return;
        }
        this._localStreams.splice(index, 1);
        const tracks = stream.getTracks();
        this.getSenders().forEach(sender => {
          if (tracks.includes(sender.track)) {
            this.removeTrack(sender);
          }
        });
      };
  }
}

function shimRemoteStreamsAPI(window) {
  if (typeof window !== 'object' || !window.RTCPeerConnection) {
    return;
  }
  if (!('getRemoteStreams' in window.RTCPeerConnection.prototype)) {
    window.RTCPeerConnection.prototype.getRemoteStreams =
      function getRemoteStreams() {
        return this._remoteStreams ? this._remoteStreams : [];
      };
  }
  if (!('onaddstream' in window.RTCPeerConnection.prototype)) {
    Object.defineProperty(window.RTCPeerConnection.prototype, 'onaddstream', {
      get() {
        return this._onaddstream;
      },
      set(f) {
        if (this._onaddstream) {
          this.removeEventListener('addstream', this._onaddstream);
          this.removeEventListener('track', this._onaddstreampoly);
        }
        this.addEventListener('addstream', this._onaddstream = f);
        this.addEventListener('track', this._onaddstreampoly = (e) => {
          e.streams.forEach(stream => {
            if (!this._remoteStreams) {
              this._remoteStreams = [];
            }
            if (this._remoteStreams.includes(stream)) {
              return;
            }
            this._remoteStreams.push(stream);
            const event = new Event('addstream');
            event.stream = stream;
            this.dispatchEvent(event);
          });
        });
      }
    });
    const origSetRemoteDescription =
      window.RTCPeerConnection.prototype.setRemoteDescription;
    window.RTCPeerConnection.prototype.setRemoteDescription =
      function setRemoteDescription() {
        const pc = this;
        if (!this._onaddstreampoly) {
          this.addEventListener('track', this._onaddstreampoly = function(e) {
            e.streams.forEach(stream => {
              if (!pc._remoteStreams) {
                pc._remoteStreams = [];
              }
              if (pc._remoteStreams.indexOf(stream) >= 0) {
                return;
              }
              pc._remoteStreams.push(stream);
              const event = new Event('addstream');
              event.stream = stream;
              pc.dispatchEvent(event);
            });
          });
        }
        return origSetRemoteDescription.apply(pc, arguments);
      };
  }
}

function shimCallbacksAPI(window) {
  if (typeof window !== 'object' || !window.RTCPeerConnection) {
    return;
  }
  const prototype = window.RTCPeerConnection.prototype;
  const origCreateOffer = prototype.createOffer;
  const origCreateAnswer = prototype.createAnswer;
  const setLocalDescription = prototype.setLocalDescription;
  const setRemoteDescription = prototype.setRemoteDescription;
  const addIceCandidate = prototype.addIceCandidate;

  prototype.createOffer =
    function createOffer(successCallback, failureCallback) {
      const options = (arguments.length >= 2) ? arguments[2] : arguments[0];
      const promise = origCreateOffer.apply(this, [options]);
      if (!failureCallback) {
        return promise;
      }
      promise.then(successCallback, failureCallback);
      return Promise.resolve();
    };

  prototype.createAnswer =
    function createAnswer(successCallback, failureCallback) {
      const options = (arguments.length >= 2) ? arguments[2] : arguments[0];
      const promise = origCreateAnswer.apply(this, [options]);
      if (!failureCallback) {
        return promise;
      }
      promise.then(successCallback, failureCallback);
      return Promise.resolve();
    };

  let withCallback = function(description, successCallback, failureCallback) {
    const promise = setLocalDescription.apply(this, [description]);
    if (!failureCallback) {
      return promise;
    }
    promise.then(successCallback, failureCallback);
    return Promise.resolve();
  };
  prototype.setLocalDescription = withCallback;

  withCallback = function(description, successCallback, failureCallback) {
    const promise = setRemoteDescription.apply(this, [description]);
    if (!failureCallback) {
      return promise;
    }
    promise.then(successCallback, failureCallback);
    return Promise.resolve();
  };
  prototype.setRemoteDescription = withCallback;

  withCallback = function(candidate, successCallback, failureCallback) {
    const promise = addIceCandidate.apply(this, [candidate]);
    if (!failureCallback) {
      return promise;
    }
    promise.then(successCallback, failureCallback);
    return Promise.resolve();
  };
  prototype.addIceCandidate = withCallback;
}

function shimGetUserMedia(window) {
  const navigator = window && window.navigator;

  if (navigator.mediaDevices && navigator.mediaDevices.getUserMedia) {
    // shim not needed in Safari 12.1
    const mediaDevices = navigator.mediaDevices;
    const _getUserMedia = mediaDevices.getUserMedia.bind(mediaDevices);
    navigator.mediaDevices.getUserMedia = (constraints) => {
      return _getUserMedia(shimConstraints(constraints));
    };
  }

  if (!navigator.getUserMedia && navigator.mediaDevices &&
    navigator.mediaDevices.getUserMedia) {
    navigator.getUserMedia = function getUserMedia(constraints, cb, errcb) {
      navigator.mediaDevices.getUserMedia(constraints)
      .then(cb, errcb);
    }.bind(navigator);
  }
}

function shimConstraints(constraints) {
  if (constraints && constraints.video !== undefined) {
    return Object.assign({},
      constraints,
      {video: _utils__WEBPACK_IMPORTED_MODULE_0__.compactObject(constraints.video)}
    );
  }

  return constraints;
}

function shimRTCIceServerUrls(window) {
  if (!window.RTCPeerConnection) {
    return;
  }
  // migrate from non-spec RTCIceServer.url to RTCIceServer.urls
  const OrigPeerConnection = window.RTCPeerConnection;
  window.RTCPeerConnection =
    function RTCPeerConnection(pcConfig, pcConstraints) {
      if (pcConfig && pcConfig.iceServers) {
        const newIceServers = [];
        for (let i = 0; i < pcConfig.iceServers.length; i++) {
          let server = pcConfig.iceServers[i];
          if (!server.hasOwnProperty('urls') &&
              server.hasOwnProperty('url')) {
            _utils__WEBPACK_IMPORTED_MODULE_0__.deprecated('RTCIceServer.url', 'RTCIceServer.urls');
            server = JSON.parse(JSON.stringify(server));
            server.urls = server.url;
            delete server.url;
            newIceServers.push(server);
          } else {
            newIceServers.push(pcConfig.iceServers[i]);
          }
        }
        pcConfig.iceServers = newIceServers;
      }
      return new OrigPeerConnection(pcConfig, pcConstraints);
    };
  window.RTCPeerConnection.prototype = OrigPeerConnection.prototype;
  // wrap static methods. Currently just generateCertificate.
  if ('generateCertificate' in OrigPeerConnection) {
    Object.defineProperty(window.RTCPeerConnection, 'generateCertificate', {
      get() {
        return OrigPeerConnection.generateCertificate;
      }
    });
  }
}

function shimTrackEventTransceiver(window) {
  // Add event.transceiver member over deprecated event.receiver
  if (typeof window === 'object' && window.RTCTrackEvent &&
      'receiver' in window.RTCTrackEvent.prototype &&
      !('transceiver' in window.RTCTrackEvent.prototype)) {
    Object.defineProperty(window.RTCTrackEvent.prototype, 'transceiver', {
      get() {
        return {receiver: this.receiver};
      }
    });
  }
}

function shimCreateOfferLegacy(window) {
  const origCreateOffer = window.RTCPeerConnection.prototype.createOffer;
  window.RTCPeerConnection.prototype.createOffer =
    function createOffer(offerOptions) {
      if (offerOptions) {
        if (typeof offerOptions.offerToReceiveAudio !== 'undefined') {
          // support bit values
          offerOptions.offerToReceiveAudio =
            !!offerOptions.offerToReceiveAudio;
        }
        const audioTransceiver = this.getTransceivers().find(transceiver =>
          transceiver.receiver.track.kind === 'audio');
        if (offerOptions.offerToReceiveAudio === false && audioTransceiver) {
          if (audioTransceiver.direction === 'sendrecv') {
            if (audioTransceiver.setDirection) {
              audioTransceiver.setDirection('sendonly');
            } else {
              audioTransceiver.direction = 'sendonly';
            }
          } else if (audioTransceiver.direction === 'recvonly') {
            if (audioTransceiver.setDirection) {
              audioTransceiver.setDirection('inactive');
            } else {
              audioTransceiver.direction = 'inactive';
            }
          }
        } else if (offerOptions.offerToReceiveAudio === true &&
            !audioTransceiver) {
          this.addTransceiver('audio', {direction: 'recvonly'});
        }

        if (typeof offerOptions.offerToReceiveVideo !== 'undefined') {
          // support bit values
          offerOptions.offerToReceiveVideo =
            !!offerOptions.offerToReceiveVideo;
        }
        const videoTransceiver = this.getTransceivers().find(transceiver =>
          transceiver.receiver.track.kind === 'video');
        if (offerOptions.offerToReceiveVideo === false && videoTransceiver) {
          if (videoTransceiver.direction === 'sendrecv') {
            if (videoTransceiver.setDirection) {
              videoTransceiver.setDirection('sendonly');
            } else {
              videoTransceiver.direction = 'sendonly';
            }
          } else if (videoTransceiver.direction === 'recvonly') {
            if (videoTransceiver.setDirection) {
              videoTransceiver.setDirection('inactive');
            } else {
              videoTransceiver.direction = 'inactive';
            }
          }
        } else if (offerOptions.offerToReceiveVideo === true &&
            !videoTransceiver) {
          this.addTransceiver('video', {direction: 'recvonly'});
        }
      }
      return origCreateOffer.apply(this, arguments);
    };
}

function shimAudioContext(window) {
  if (typeof window !== 'object' || window.AudioContext) {
    return;
  }
  window.AudioContext = window.webkitAudioContext;
}



/***/ }),

/***/ "./node_modules/webrtc-adapter/src/js/utils.js":
/*!*****************************************************!*\
  !*** ./node_modules/webrtc-adapter/src/js/utils.js ***!
  \*****************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   compactObject: () => (/* binding */ compactObject),
/* harmony export */   deprecated: () => (/* binding */ deprecated),
/* harmony export */   detectBrowser: () => (/* binding */ detectBrowser),
/* harmony export */   disableLog: () => (/* binding */ disableLog),
/* harmony export */   disableWarnings: () => (/* binding */ disableWarnings),
/* harmony export */   extractVersion: () => (/* binding */ extractVersion),
/* harmony export */   filterStats: () => (/* binding */ filterStats),
/* harmony export */   log: () => (/* binding */ log),
/* harmony export */   walkStats: () => (/* binding */ walkStats),
/* harmony export */   wrapPeerConnectionEvent: () => (/* binding */ wrapPeerConnectionEvent)
/* harmony export */ });
/*
 *  Copyright (c) 2016 The WebRTC project authors. All Rights Reserved.
 *
 *  Use of this source code is governed by a BSD-style license
 *  that can be found in the LICENSE file in the root of the source
 *  tree.
 */
 /* eslint-env node */


let logDisabled_ = true;
let deprecationWarnings_ = true;

/**
 * Extract browser version out of the provided user agent string.
 *
 * @param {!string} uastring userAgent string.
 * @param {!string} expr Regular expression used as match criteria.
 * @param {!number} pos position in the version string to be returned.
 * @return {!number} browser version.
 */
function extractVersion(uastring, expr, pos) {
  const match = uastring.match(expr);
  return match && match.length >= pos && parseInt(match[pos], 10);
}

// Wraps the peerconnection event eventNameToWrap in a function
// which returns the modified event object (or false to prevent
// the event).
function wrapPeerConnectionEvent(window, eventNameToWrap, wrapper) {
  if (!window.RTCPeerConnection) {
    return;
  }
  const proto = window.RTCPeerConnection.prototype;
  const nativeAddEventListener = proto.addEventListener;
  proto.addEventListener = function(nativeEventName, cb) {
    if (nativeEventName !== eventNameToWrap) {
      return nativeAddEventListener.apply(this, arguments);
    }
    const wrappedCallback = (e) => {
      const modifiedEvent = wrapper(e);
      if (modifiedEvent) {
        if (cb.handleEvent) {
          cb.handleEvent(modifiedEvent);
        } else {
          cb(modifiedEvent);
        }
      }
    };
    this._eventMap = this._eventMap || {};
    if (!this._eventMap[eventNameToWrap]) {
      this._eventMap[eventNameToWrap] = new Map();
    }
    this._eventMap[eventNameToWrap].set(cb, wrappedCallback);
    return nativeAddEventListener.apply(this, [nativeEventName,
      wrappedCallback]);
  };

  const nativeRemoveEventListener = proto.removeEventListener;
  proto.removeEventListener = function(nativeEventName, cb) {
    if (nativeEventName !== eventNameToWrap || !this._eventMap
        || !this._eventMap[eventNameToWrap]) {
      return nativeRemoveEventListener.apply(this, arguments);
    }
    if (!this._eventMap[eventNameToWrap].has(cb)) {
      return nativeRemoveEventListener.apply(this, arguments);
    }
    const unwrappedCb = this._eventMap[eventNameToWrap].get(cb);
    this._eventMap[eventNameToWrap].delete(cb);
    if (this._eventMap[eventNameToWrap].size === 0) {
      delete this._eventMap[eventNameToWrap];
    }
    if (Object.keys(this._eventMap).length === 0) {
      delete this._eventMap;
    }
    return nativeRemoveEventListener.apply(this, [nativeEventName,
      unwrappedCb]);
  };

  Object.defineProperty(proto, 'on' + eventNameToWrap, {
    get() {
      return this['_on' + eventNameToWrap];
    },
    set(cb) {
      if (this['_on' + eventNameToWrap]) {
        this.removeEventListener(eventNameToWrap,
            this['_on' + eventNameToWrap]);
        delete this['_on' + eventNameToWrap];
      }
      if (cb) {
        this.addEventListener(eventNameToWrap,
            this['_on' + eventNameToWrap] = cb);
      }
    },
    enumerable: true,
    configurable: true
  });
}

function disableLog(bool) {
  if (typeof bool !== 'boolean') {
    return new Error('Argument type: ' + typeof bool +
        '. Please use a boolean.');
  }
  logDisabled_ = bool;
  return (bool) ? 'adapter.js logging disabled' :
      'adapter.js logging enabled';
}

/**
 * Disable or enable deprecation warnings
 * @param {!boolean} bool set to true to disable warnings.
 */
function disableWarnings(bool) {
  if (typeof bool !== 'boolean') {
    return new Error('Argument type: ' + typeof bool +
        '. Please use a boolean.');
  }
  deprecationWarnings_ = !bool;
  return 'adapter.js deprecation warnings ' + (bool ? 'disabled' : 'enabled');
}

function log() {
  if (typeof window === 'object') {
    if (logDisabled_) {
      return;
    }
    if (typeof console !== 'undefined' && typeof console.log === 'function') {
      console.log.apply(console, arguments);
    }
  }
}

/**
 * Shows a deprecation warning suggesting the modern and spec-compatible API.
 */
function deprecated(oldMethod, newMethod) {
  if (!deprecationWarnings_) {
    return;
  }
  console.warn(oldMethod + ' is deprecated, please use ' + newMethod +
      ' instead.');
}

/**
 * Browser detector.
 *
 * @return {object} result containing browser and version
 *     properties.
 */
function detectBrowser(window) {
  // Returned result object.
  const result = {browser: null, version: null};

  // Fail early if it's not a browser
  if (typeof window === 'undefined' || !window.navigator) {
    result.browser = 'Not a browser.';
    return result;
  }

  const {navigator} = window;

  if (navigator.mozGetUserMedia) { // Firefox.
    result.browser = 'firefox';
    result.version = extractVersion(navigator.userAgent,
        /Firefox\/(\d+)\./, 1);
  } else if (navigator.webkitGetUserMedia ||
      (window.isSecureContext === false && window.webkitRTCPeerConnection &&
       !window.RTCIceGatherer)) {
    // Chrome, Chromium, Webview, Opera.
    // Version matches Chrome/WebRTC version.
    // Chrome 74 removed webkitGetUserMedia on http as well so we need the
    // more complicated fallback to webkitRTCPeerConnection.
    result.browser = 'chrome';
    result.version = extractVersion(navigator.userAgent,
        /Chrom(e|ium)\/(\d+)\./, 2);
  } else if (window.RTCPeerConnection &&
      navigator.userAgent.match(/AppleWebKit\/(\d+)\./)) { // Safari.
    result.browser = 'safari';
    result.version = extractVersion(navigator.userAgent,
        /AppleWebKit\/(\d+)\./, 1);
    result.supportsUnifiedPlan = window.RTCRtpTransceiver &&
        'currentDirection' in window.RTCRtpTransceiver.prototype;
  } else { // Default fallthrough: not supported.
    result.browser = 'Not a supported browser.';
    return result;
  }

  return result;
}

/**
 * Checks if something is an object.
 *
 * @param {*} val The something you want to check.
 * @return true if val is an object, false otherwise.
 */
function isObject(val) {
  return Object.prototype.toString.call(val) === '[object Object]';
}

/**
 * Remove all empty objects and undefined values
 * from a nested object -- an enhanced and vanilla version
 * of Lodash's `compact`.
 */
function compactObject(data) {
  if (!isObject(data)) {
    return data;
  }

  return Object.keys(data).reduce(function(accumulator, key) {
    const isObj = isObject(data[key]);
    const value = isObj ? compactObject(data[key]) : data[key];
    const isEmptyObject = isObj && !Object.keys(value).length;
    if (value === undefined || isEmptyObject) {
      return accumulator;
    }
    return Object.assign(accumulator, {[key]: value});
  }, {});
}

/* iterates the stats graph recursively. */
function walkStats(stats, base, resultSet) {
  if (!base || resultSet.has(base.id)) {
    return;
  }
  resultSet.set(base.id, base);
  Object.keys(base).forEach(name => {
    if (name.endsWith('Id')) {
      walkStats(stats, stats.get(base[name]), resultSet);
    } else if (name.endsWith('Ids')) {
      base[name].forEach(id => {
        walkStats(stats, stats.get(id), resultSet);
      });
    }
  });
}

/* filter getStats for a sender/receiver track. */
function filterStats(result, track, outbound) {
  const streamStatsType = outbound ? 'outbound-rtp' : 'inbound-rtp';
  const filteredResult = new Map();
  if (track === null) {
    return filteredResult;
  }
  const trackStats = [];
  result.forEach(value => {
    if (value.type === 'track' &&
        value.trackIdentifier === track.id) {
      trackStats.push(value);
    }
  });
  trackStats.forEach(trackStat => {
    result.forEach(stats => {
      if (stats.type === streamStatsType && stats.trackId === trackStat.id) {
        walkStats(result, stats, filteredResult);
      }
    });
  });
  return filteredResult;
}



/***/ }),

/***/ "./node_modules/ws/browser.js":
/*!************************************!*\
  !*** ./node_modules/ws/browser.js ***!
  \************************************/
/***/ ((module) => {

"use strict";


module.exports = function () {
  throw new Error(
    'ws does not work in the browser. Browser clients must use the native ' +
      'WebSocket object'
  );
};


/***/ }),

/***/ "./node_modules/@jitsi/js-utils/avatar/index.js":
/*!******************************************************!*\
  !*** ./node_modules/@jitsi/js-utils/avatar/index.js ***!
  \******************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   getGravatarURL: () => (/* binding */ getGravatarURL)
/* harmony export */ });
/* harmony import */ var js_md5__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! js-md5 */ "./node_modules/js-md5/src/md5.js");


/**
 * Returns the Gravatar URL of a given email id.
 *
 * @param {string} key - Email or id for which we need gravatar URL.
 * @param {string} baseURL - Base Gravatar URL.
 * @returns {string} - Gravatar URL.
 */
function getGravatarURL(key, baseURL = 'https://seccdn.libravatar.org/avatar/') {
    const urlSuffix = '?d=404&size=200';

    // If the key is a valid email, we hash it. If it's not, we assume it's already a hashed format
    const avatarKey = isValidEmail(key) ? js_md5__WEBPACK_IMPORTED_MODULE_0__.hex(key.trim().toLowerCase()) : key;

    return `${baseURL}${avatarKey}${urlSuffix}`;
}

/**
 * Returns if the email id is valid.
 *
 * @param {string} email - Email id to be checked.
 * @returns {boolean}
 */
function isValidEmail(email) {
    return email && email.indexOf('@') > 0;
}


/***/ }),

/***/ "./node_modules/@jitsi/js-utils/browser-capabilities/BrowserCapabilities.js":
/*!**********************************************************************************!*\
  !*** ./node_modules/@jitsi/js-utils/browser-capabilities/BrowserCapabilities.js ***!
  \**********************************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (/* binding */ BrowserCapabilities)
/* harmony export */ });
/* harmony import */ var _browser_detection_BrowserDetection_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../browser-detection/BrowserDetection.js */ "./node_modules/@jitsi/js-utils/browser-detection/BrowserDetection.js");


// TODO: Move BrowserCapabilities from lib-jitsi-meet here and use the JSON
// format for them.

/**
 * Implements browser capabilities for lib-jitsi-meet.
 */
class BrowserCapabilities {
    /**
     * Creates new BrowserCapabilities instance.
     *
     * @param {Object} capabilitiesDB - The JSON database with capabilities.
     * @param {boolean} [isUsingIFrame] - True if Jitsi Meet is loaded in iframe
     * and false otherwise.
     * @param {Object} [browserInfo] - Information about the browser.
     * @param {string} browserInfo.name - The name of the browser.
     * @param {string} browserInfo.version - The version of the browser.
     */
    constructor(capabilitiesDB = {}, isUsingIFrame = false, browserInfo) {
        const browser = new _browser_detection_BrowserDetection_js__WEBPACK_IMPORTED_MODULE_0__["default"](browserInfo);
        let capabilitiesByVersion;

        // If the capabilitiesDB is not in the correct format or the type of the
        // version of the browser is undefined(the version is unknown) or the
        // version type is not compatible (not a string) we'll consider the
        // browser as not supported.
        if (typeof capabilitiesDB === 'object'
                && typeof browser.getVersion() === 'string') {
            const browserCapabilities = capabilitiesDB[browser.getName()] || [];

            for (let i = 0; i < browserCapabilities.length; i++) {
                const capabilities = browserCapabilities[i];

                if (typeof capabilities !== 'object') {
                    // eslint-disable-next-line no-continue
                    continue;
                }

                const version = capabilities.version;

                if (!version || !browser.isVersionGreaterThan(version)) {
                    capabilitiesByVersion = capabilities;
                    break;
                }
            }
        }

        if (!capabilitiesByVersion || !capabilitiesByVersion.capabilities) {
            this._capabilities = { isSupported: false };
        } else if (isUsingIFrame) {
            this._capabilities = {
                ...capabilitiesByVersion.capabilities,
                ...capabilitiesByVersion.iframeCapabilities
            };
        } else {
            this._capabilities = capabilitiesByVersion.capabilities;
        }

        if (typeof this._capabilities.isSupported === 'undefined') {
            // we have some capabilities but isSupported property is not filled.
            this._capabilities.isSupported = true;
        } else if (this._capabilities.isSupported === false) {
            // Clean the other capabilities.
            this._capabilities = { isSupported: false };
        }
    }

    /**
     * Checks whether the browser is supported by Jitsi Meet.
     *
     * @returns {boolean}
     */
    isSupported() {
        return this._capabilities.isSupported;
    }

    /**
     * Checks whether the browser supports incoming audio.
     *
     * @returns {boolean}
     */
    supportsAudioIn() {
        return this._capabilities.audioIn || false;
    }

    /**
     * Checks whether the browser supports outgoing audio.
     *
     * @returns {boolean}
     */
    supportsAudioOut() {
        return this._capabilities.audioOut || false;
    }


    /**
     * Checks whether the browser supports screen sharing.
     *
     * @returns {boolean}
     */
    supportsScreenSharing() {
        return this._capabilities.screenSharing || false;
    }

    /**
     * Checks whether the browser supports incomming video.
     *
     * @returns {boolean}
     */
    supportsVideoIn() {
        return this._capabilities.videoIn || false;
    }

    /**
     * Checks whether the browser supports outgoing video.
     *
     * @returns {boolean}
     */
    supportsVideoOut() {
        return this._capabilities.videoOut || false;
    }
}


/***/ }),

/***/ "./node_modules/@jitsi/js-utils/browser-capabilities/index.js":
/*!********************************************************************!*\
  !*** ./node_modules/@jitsi/js-utils/browser-capabilities/index.js ***!
  \********************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   BrowserCapabilities: () => (/* reexport safe */ _BrowserCapabilities_js__WEBPACK_IMPORTED_MODULE_0__["default"])
/* harmony export */ });
/* harmony import */ var _BrowserCapabilities_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./BrowserCapabilities.js */ "./node_modules/@jitsi/js-utils/browser-capabilities/BrowserCapabilities.js");



/***/ }),

/***/ "./node_modules/@jitsi/js-utils/browser-detection/BrowserDetection.js":
/*!****************************************************************************!*\
  !*** ./node_modules/@jitsi/js-utils/browser-detection/BrowserDetection.js ***!
  \****************************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (/* binding */ BrowserDetection)
/* harmony export */ });
/* harmony import */ var bowser__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! bowser */ "./node_modules/bowser/es5.js");
/* harmony import */ var _browsers_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./browsers.js */ "./node_modules/@jitsi/js-utils/browser-detection/browsers.js");




/**
 * Maps the names of the browsers from bowser to the internal names defined in
 * ./browsers.js
 */
const bowserNameToJitsiName = {
    'Chrome': _browsers_js__WEBPACK_IMPORTED_MODULE_1__.CHROME,
    'Chromium': _browsers_js__WEBPACK_IMPORTED_MODULE_1__.CHROME,
    'Opera': _browsers_js__WEBPACK_IMPORTED_MODULE_1__.OPERA,
    'Firefox': _browsers_js__WEBPACK_IMPORTED_MODULE_1__.FIREFOX,
    'Internet Explorer': _browsers_js__WEBPACK_IMPORTED_MODULE_1__.INTERNET_EXPLORER,
    'Safari': _browsers_js__WEBPACK_IMPORTED_MODULE_1__.SAFARI
};

/**
 * Detects a Chromium based environent.
 *
 * NOTE: Here we cannot check solely for "Chrome" in the UA, because Edge has
 * it too. We need to check explicitly for chromium based Edge first and then
 * detect other chromium based browsers.
 *
 * @returns {Object|undefined} - The name (CHROME) and version.
 */
function _detectChromiumBased() {
    const userAgent = navigator.userAgent;
    const browserInfo = {
        name: _browsers_js__WEBPACK_IMPORTED_MODULE_1__.UNKNOWN,
        version: undefined
    };

    if (userAgent.match(/Chrome/) && !userAgent.match(/Edge/)) {
        // Edge is currenly supported only on desktop and android.
        if (userAgent.match(/Edg(A?)/)) {
            // Compare the underlying chromium version.
            const version = userAgent.match(/Chrome\/([\d.]+)/)[1];

            if (Number.parseInt(version, 10) > 72) {
                browserInfo.name = _browsers_js__WEBPACK_IMPORTED_MODULE_1__.CHROME;
                browserInfo.version = version;
            }
        } else {
            browserInfo.name = _browsers_js__WEBPACK_IMPORTED_MODULE_1__.CHROME;
            browserInfo.version = userAgent.match(/Chrome\/([\d.]+)/)[1];
        }
    }

    return browserInfo;
}

/**
 * Detects Electron environment.
 *
 * @returns {Object|undefined} - The name (ELECTRON) and version.
 */
function _detectElectron() {
    const userAgent = navigator.userAgent;

    if (userAgent.match(/Electron/)) {
        const version = userAgent.match(/Electron(?:\s|\/)([\d.]+)/)[1];

        return {
            name: _browsers_js__WEBPACK_IMPORTED_MODULE_1__.ELECTRON,
            version
        };
    } else if (typeof window.JitsiMeetElectron !== 'undefined') {
        return {
            name: _browsers_js__WEBPACK_IMPORTED_MODULE_1__.ELECTRON,
            version: undefined
        };
    }
}

/**
 * Detects NWJS environment.
 *
 * @returns {Object|undefined} - The name (NWJS) and version.
 */
function _detectNWJS() {
    const userAgent = navigator.userAgent;

    if (userAgent.match(/JitsiMeetNW/)) {
        const version = userAgent.match(/JitsiMeetNW\/([\d.]+)/)[1];

        return {
            name: _browsers_js__WEBPACK_IMPORTED_MODULE_1__.NWJS,
            version
        };
    }
}

/**
 * Detects React Native environment.
 * @returns {Object|undefined} - The name (REACT_NATIVE) and version.
 */
function _detectReactNative() {
    const match
        = navigator.userAgent.match(/\b(react[ \t_-]*native)(?:\/(\S+))?/i);
    let version;

    // If we're remote debugging a React Native app, it may be treated as
    // Chrome. Check navigator.product as well and always return some version
    // even if we can't get the real one.

    if (match || navigator.product === 'ReactNative') {
        let name;

        if (match && match.length > 2) {
            name = match[1];
            version = match[2];
        }
        name || (name = 'react-native');
        version || (version = 'unknown');

        return {
            name: _browsers_js__WEBPACK_IMPORTED_MODULE_1__.REACT_NATIVE,
            version
        };
    }
}

/**
 * Returns information about the current browser.
 * @param {Object} - The bowser instance.
 * @returns {Object} - The name and version of the browser.
 */
function _detect(bowser) {
    let browserInfo;
    const detectors = [
        _detectReactNative,
        _detectElectron,
        _detectNWJS
    ];

    // Try all browser detectors
    for (let i = 0; i < detectors.length; i++) {
        browserInfo = detectors[i]();
        if (browserInfo) {
            return browserInfo;
        }
    }

    const name = bowser.getBrowserName();

    if (name in bowserNameToJitsiName) {
        return {
            name: bowserNameToJitsiName[name],
            version: bowser.getBrowserVersion()
        };
    }

    // Detect other browsers with the Chrome engine, such as Vivaldi and Brave.
    browserInfo = _detectChromiumBased();
    if (browserInfo) {
        return browserInfo;
    }

    return {
        name: _browsers_js__WEBPACK_IMPORTED_MODULE_1__.UNKNOWN,
        version: undefined
    };
}

/**
 * Implements browser detection.
 */
class BrowserDetection {
    /**
     * Creates new BrowserDetection instance.
     *
     * @param {Object} [browserInfo] - Information about the browser.
     * @param {string} browserInfo.name - The name of the browser.
     * @param {string} browserInfo.version - The version of the browser.
     */
    constructor(browserInfo) {
        let name, version;

        this._bowser = bowser__WEBPACK_IMPORTED_MODULE_0__.getParser(navigator.userAgent);
        if (typeof browserInfo === 'undefined') {
            const detectedBrowserInfo = _detect(this._bowser);

            name = detectedBrowserInfo.name;
            version = detectedBrowserInfo.version;
        } else if (browserInfo.name in bowserNameToJitsiName) {
            name = bowserNameToJitsiName[browserInfo.name];
            version = browserInfo.version;
        } else {
            name = _browsers_js__WEBPACK_IMPORTED_MODULE_1__.UNKNOWN;
            version = undefined;
        }

        this._name = name;
        this._version = version;
    }

    /**
     * Gets current browser name.
     * @returns {string}
     */
    getName() {
        return this._name;
    }

    /**
     * Checks if current browser is Chrome.
     * @returns {boolean}
     */
    isChrome() {
        return this._name === _browsers_js__WEBPACK_IMPORTED_MODULE_1__.CHROME;
    }

    /**
     * Checks if current browser is Opera.
     * @returns {boolean}
     */
    isOpera() {
        return this._name === _browsers_js__WEBPACK_IMPORTED_MODULE_1__.OPERA;
    }

    /**
     * Checks if current browser is Firefox.
     * @returns {boolean}
     */
    isFirefox() {
        return this._name === _browsers_js__WEBPACK_IMPORTED_MODULE_1__.FIREFOX;
    }

    /**
     * Checks if current browser is Internet Explorer.
     * @returns {boolean}
     */
    isIExplorer() {
        return this._name === _browsers_js__WEBPACK_IMPORTED_MODULE_1__.INTERNET_EXPLORER;
    }

    /**
     * Checks if current browser is Safari.
     * @returns {boolean}
     */
    isSafari() {
        return this._name === _browsers_js__WEBPACK_IMPORTED_MODULE_1__.SAFARI;
    }

    /**
     * Checks if current environment is NWJS.
     * @returns {boolean}
     */
    isNWJS() {
        return this._name === _browsers_js__WEBPACK_IMPORTED_MODULE_1__.NWJS;
    }

    /**
     * Checks if current environment is Electron.
     * @returns {boolean}
     */
    isElectron() {
        return this._name === _browsers_js__WEBPACK_IMPORTED_MODULE_1__.ELECTRON;
    }

    /**
     * Checks if current environment is React Native.
     * @returns {boolean}
     */
    isReactNative() {
        return this._name === _browsers_js__WEBPACK_IMPORTED_MODULE_1__.REACT_NATIVE;
    }

    /**
     * Returns the version of the current browser.
     * @returns {string}
     */
    getVersion() {
        return this._version;
    }

    /**
     * Check if the parsed browser matches the passed condition.
     *
     * @param {Object} checkTree - It's one or two layered object, which can include a
     * platform or an OS on the first layer and should have browsers specs on the
     * bottom layer.
     * Eg. { chrome: '>71.1.0' }
     *     { windows: { chrome: '<70.2' } }
     * @returns {boolean | undefined} - Returns true if the browser satisfies the set
     * conditions, false if not and undefined when the browser is not defined in the
     * checktree object or when the current browser's version is unknown.
     * @private
     */
    _checkCondition(checkTree) {
        if (this._version) {
            return this._bowser.satisfies(checkTree);
        }
    }

    /**
     * Compares the passed version with the current browser version.
     *
     * @param {*} version - The version to compare with. Anything different
     * than string will be converted to string.
     * @returns {boolean|undefined} - Returns true if the current version is
     * greater than the passed version and false otherwise. Returns undefined if
     * the current browser version is unknown.
     */
    isVersionGreaterThan(version) {
        return this._checkCondition({ [this._name]: `>${version}` });
    }

    /**
     * Compares the passed version with the current browser version.
     *
     * @param {*} version - The version to compare with. Anything different
     * than string will be converted to string.
     * @returns {boolean|undefined} - Returns true if the current version is
     * lower than the passed version and false otherwise. Returns undefined if
     * the current browser version is unknown.
     */
    isVersionLessThan(version) {
        return this._checkCondition({ [this._name]: `<${version}` });
    }

    /**
     * Compares the passed version with the current browser version.
     *
     * @param {*} version - The version to compare with. Anything different
     * than string will be converted to string.
     * @returns {boolean|undefined} - Returns true if the current version is
     * equal to the passed version and false otherwise. Returns undefined if
     * the current browser version is unknown.
     * A loose-equality operator is used here so that it matches the sub-versions as well.
     */
    isVersionEqualTo(version) {
        return this._checkCondition({ [this._name]: `~${version}` });
    }
}


/***/ }),

/***/ "./node_modules/@jitsi/js-utils/browser-detection/browsers.js":
/*!********************************************************************!*\
  !*** ./node_modules/@jitsi/js-utils/browser-detection/browsers.js ***!
  \********************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   CHROME: () => (/* binding */ CHROME),
/* harmony export */   ELECTRON: () => (/* binding */ ELECTRON),
/* harmony export */   FIREFOX: () => (/* binding */ FIREFOX),
/* harmony export */   INTERNET_EXPLORER: () => (/* binding */ INTERNET_EXPLORER),
/* harmony export */   NWJS: () => (/* binding */ NWJS),
/* harmony export */   OPERA: () => (/* binding */ OPERA),
/* harmony export */   REACT_NATIVE: () => (/* binding */ REACT_NATIVE),
/* harmony export */   SAFARI: () => (/* binding */ SAFARI),
/* harmony export */   UNKNOWN: () => (/* binding */ UNKNOWN)
/* harmony export */ });
// TODO: Maybe fix the values to 'Chrome', 'Internet Explorer', etc. Currently
// this values needs to be as they are becuse they are going to analytics,
// callstats, etc.

const CHROME = 'chrome';

const OPERA = 'opera';

const FIREFOX = 'firefox';

const INTERNET_EXPLORER = 'iexplorer';

const SAFARI = 'safari';

const NWJS = 'nwjs';

const ELECTRON = 'electron';

const REACT_NATIVE = 'react-native';

const UNKNOWN = 'unknown';


/***/ }),

/***/ "./node_modules/@jitsi/js-utils/browser-detection/index.js":
/*!*****************************************************************!*\
  !*** ./node_modules/@jitsi/js-utils/browser-detection/index.js ***!
  \*****************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   BrowserDetection: () => (/* reexport safe */ _BrowserDetection_js__WEBPACK_IMPORTED_MODULE_0__["default"]),
/* harmony export */   browsers: () => (/* reexport module object */ _browsers_js__WEBPACK_IMPORTED_MODULE_1__)
/* harmony export */ });
/* harmony import */ var _BrowserDetection_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./BrowserDetection.js */ "./node_modules/@jitsi/js-utils/browser-detection/BrowserDetection.js");
/* harmony import */ var _browsers_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./browsers.js */ "./node_modules/@jitsi/js-utils/browser-detection/browsers.js");





/***/ }),

/***/ "./node_modules/@jitsi/js-utils/index.js":
/*!***********************************************!*\
  !*** ./node_modules/@jitsi/js-utils/index.js ***!
  \***********************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   BrowserCapabilities: () => (/* reexport safe */ _browser_capabilities_index_js__WEBPACK_IMPORTED_MODULE_1__.BrowserCapabilities),
/* harmony export */   BrowserDetection: () => (/* reexport safe */ _browser_detection_index_js__WEBPACK_IMPORTED_MODULE_2__.BrowserDetection),
/* harmony export */   browsers: () => (/* reexport safe */ _browser_detection_index_js__WEBPACK_IMPORTED_MODULE_2__.browsers),
/* harmony export */   getGravatarURL: () => (/* reexport safe */ _avatar_index_js__WEBPACK_IMPORTED_MODULE_0__.getGravatarURL),
/* harmony export */   jitsiLocalStorage: () => (/* reexport safe */ _jitsi_local_storage_index_js__WEBPACK_IMPORTED_MODULE_3__.jitsiLocalStorage)
/* harmony export */ });
/* harmony import */ var _avatar_index_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./avatar/index.js */ "./node_modules/@jitsi/js-utils/avatar/index.js");
/* harmony import */ var _browser_capabilities_index_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./browser-capabilities/index.js */ "./node_modules/@jitsi/js-utils/browser-capabilities/index.js");
/* harmony import */ var _browser_detection_index_js__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./browser-detection/index.js */ "./node_modules/@jitsi/js-utils/browser-detection/index.js");
/* harmony import */ var _jitsi_local_storage_index_js__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./jitsi-local-storage/index.js */ "./node_modules/@jitsi/js-utils/jitsi-local-storage/index.js");






/***/ }),

/***/ "./node_modules/@jitsi/js-utils/jitsi-local-storage/index.js":
/*!*******************************************************************!*\
  !*** ./node_modules/@jitsi/js-utils/jitsi-local-storage/index.js ***!
  \*******************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   jitsiLocalStorage: () => (/* binding */ jitsiLocalStorage)
/* harmony export */ });
/* harmony import */ var events__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! events */ "./node_modules/events/events.js");


/**
 * Dummy implementation of Storage interface.
 */
class DummyLocalStorage extends events__WEBPACK_IMPORTED_MODULE_0__ {

    /**
     * The object used for storage.
     */
    _storage = {};

    /**
     * Empties all keys out of the storage.
     *
     * @returns {void}
     */
    clear() {
        this._storage = {};
    }

    /**
     * Returns the number of data items stored in the Storage object.
     *
     * @returns {number} - The number of data items stored in the Storage object.
     */
    get length() {
        return Object.keys(this._storage).length;
    }

    /**
     * Will return that key's value associated to the passed key name.
     *
     * @param {string} keyName - The key name.
     * @returns {*} - The key value.
     */
    getItem(keyName) {
        return this._storage[keyName];
    }

    /**
     * When passed a key name and value, will add that key to the storage,
     * or update that key's value if it already exists.
     *
     * @param {string} keyName - The key name.
     * @param {*} keyValue - The key value.
     * @returns {void}
     */
    setItem(keyName, keyValue) {
        this._storage[keyName] = keyValue;
    }

    /**
     * When passed a key name, will remove that key from the storage.
     *
     * @param {string} keyName - The key name.
     * @returns {void}
     */
    removeItem(keyName) {
        delete this._storage[keyName];
    }

    /**
     * When passed a number n, this method will return the name of the nth key in the storage.
     *
     * @param {number} idx - The index of the key.
     * @returns {string} - The nth key name.
     */
    key(n) {
        const keys = Object.keys(this._storage);

        if (keys.length <= n) {
            return undefined;
        }

        return keys[n];
    }

    /**
     * Serializes the content of the storage.
     *
     * @returns {string} - The serialized content.
     */
    serialize() {
        return JSON.stringify(this._storage);
    }
}

/**
 * Wrapper class for browser's local storage object.
 */
class JitsiLocalStorage extends events__WEBPACK_IMPORTED_MODULE_0__ {
    /**
     * @constructor
     * @param {Storage} storage browser's local storage object.
     */
    constructor() {
        super();

        try {
            this._storage = window.localStorage;
            this._localStorageDisabled = false;
        } catch (ignore) {
            // localStorage throws an exception.
        }

        if (!this._storage) { // Handles the case when window.localStorage is undefined or throws an exception.
            console.warn('Local storage is disabled.');
            this._storage = new DummyLocalStorage();
            this._localStorageDisabled = true;
        }
    }

    /**
     * Returns true if window.localStorage is disabled and false otherwise.
     *
     * @returns {boolean} - True if window.localStorage is disabled and false otherwise.
     */
    isLocalStorageDisabled() {
        return this._localStorageDisabled;
    }

    /**
     * Empties all keys out of the storage.
     *
     * @returns {void}
     */
    clear() {
        this._storage.clear();
        this.emit('changed');
    }

    /**
     * Returns the number of data items stored in the Storage object.
     *
     * @returns {number} - The number of data items stored in the Storage object.
     */
    get length() {
        return this._storage.length;
    }

    /**
     * Returns that passed key's value.
     * @param {string} keyName the name of the key you want to retrieve
     * the value of.
     * @returns {String|null} the value of the key. If the key does not exist,
     * null is returned.
     */
    getItem(keyName) {
        return this._storage.getItem(keyName);
    }

    /**
     * Adds a key to the storage, or update key's value if it already exists.
     * @param {string} keyName - the name of the key you want to create/update.
     * @param {string} keyValue - the value you want to give the key you are
     * creating/updating.
     * @param {boolean} dontEmitChangedEvent - If true a changed event won't be emitted.
     */
    setItem(keyName, keyValue, dontEmitChangedEvent = false) {
        this._storage.setItem(keyName, keyValue);

        if (!dontEmitChangedEvent) {
            this.emit('changed');
        }
    }

    /**
     * Remove a key from the storage.
     * @param {string} keyName the name of the key you want to remove.
     */
    removeItem(keyName) {
        this._storage.removeItem(keyName);
        this.emit('changed');
    }

    /**
     * Returns the name of the nth key in the list, or null if n is greater
     * than or equal to the number of key/value pairs in the object.
     *
     * @param {number} i - The index of the key in the list.
     * @returns {string}
     */
    key(i) {
        return this._storage.key(i);
    }

    /**
     * Serializes the content of the storage.
     *
     * @returns {string} - The serialized content.
     */
    serialize() {
        if (this.isLocalStorageDisabled()) {
            return this._storage.serialize();
        }

        const length = this._storage.length;
        const localStorageContent = {};

        for (let i = 0; i < length; i++) {
            const key = this._storage.key(i);

            localStorageContent[key] = this._storage.getItem(key);
        }

        return JSON.stringify(localStorageContent);
    }
}

const jitsiLocalStorage = new JitsiLocalStorage();


/***/ }),

/***/ "./node_modules/@jitsi/sdp-interop/lib/index.js":
/*!******************************************************!*\
  !*** ./node_modules/@jitsi/sdp-interop/lib/index.js ***!
  \******************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   Interop: () => (/* reexport safe */ _interop_js__WEBPACK_IMPORTED_MODULE_0__.Interop)
/* harmony export */ });
/* harmony import */ var _interop_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./interop.js */ "./node_modules/@jitsi/sdp-interop/lib/interop.js");
/* Copyright @ 2015 - Present, 8x8 Inc
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */




/***/ }),

/***/ "./node_modules/@jitsi/sdp-interop/lib/interop.js":
/*!********************************************************!*\
  !*** ./node_modules/@jitsi/sdp-interop/lib/interop.js ***!
  \********************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   Interop: () => (/* binding */ Interop)
/* harmony export */ });
/* harmony import */ var lodash_clonedeep__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! lodash.clonedeep */ "./node_modules/lodash.clonedeep/index.js");
/* harmony import */ var _transform_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./transform.js */ "./node_modules/@jitsi/sdp-interop/lib/transform.js");
/* Copyright @ 2015 - Present, 8x8 Inc
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */





const PLAN_B_MIDS = [ 'audio', 'video', 'data' ];
const findSimGroup = ssrcGroup => ssrcGroup.find(grp => grp.semantics === 'SIM');
const findFidGroup = ssrcGroup => ssrcGroup.find(grp => grp.semantics === 'FID');

/**
 * Add the ssrcs of the SIM group and their corresponding FID group ssrcs
 * to the m-line.
 * @param {Object} mLine - The m-line to which ssrcs have to be added.
 * @param {Object} simGroup - The SIM group whose ssrcs have to be added to
 * the m-line.
 * @param {Object} sourceGroups - inverted source-group map.
 * @param {Array<Object>} sourceList - array containing all the sources.
 */
function addSimGroupSources(mLine, simGroup, sourceGroups, sourceList) {
    if (!mLine || !simGroup) {
        return;
    }
    const findSourcebyId = src => sourceList.find(source => source.id.toString() === src);

    simGroup.ssrcs.forEach(src => {
        mLine.sources.push(findSourcebyId(src));

        // find the related FID group member for this ssrc.
        const relatedFidGroup = sourceGroups[parseInt(src, 10)].find(grp => grp.semantics === 'FID');

        if (relatedFidGroup) {
            const relatedSsrc = relatedFidGroup.ssrcs.find(s => s !== src);

            mLine.sources.push(findSourcebyId(relatedSsrc));
            mLine.ssrcGroups.push(relatedFidGroup);
        }
    });

    // Add the SIM group last.
    mLine.ssrcGroups.push(simGroup);
}

/**
 * Add ssrcs and ssrc-groups to the m-line. When a primary ssrc, i.e., the
 * first ssrc in a SIM group is passed, all the other ssrcs from the SIM
 * group and the other ssrcs from the related FID groups are added to the same
 * m-line since they all belong to the same remote source. Since the ssrcs are
 * not guaranteed to be in the correct order, try to find if a SIM group exists,
 * if not, just add the FID group.
 * @param {Object} mLine - The m-line to which ssrcs have to be added.
 * @param {Object} ssrc - the primary ssrc.
 * @param {Object} sourceGroups - inverted source-group map.
 * @param {Array<Object>} sourceList - array containing all the sources.
 * @returns {void}
 */
function addSourcesToMline(mLine, ssrc, sourceGroups, sourceList) {
    if (!mLine || !ssrc) {
        return;
    }
    mLine.sources = [];
    mLine.ssrcGroups = [];

    // If there are no associated ssrc-groups, just add the ssrc and msid.
    if (!sourceGroups[ssrc.id]) {
        mLine.sources.push(ssrc);
        mLine.msid = ssrc.msid;

        return;
    }
    const findSourcebyId = src => sourceList.find(source => source.id.toString() === src);

    // Find the SIM and FID groups that this ssrc belongs to.
    const simGroup = findSimGroup(sourceGroups[ssrc.id]);
    const fidGroup = findFidGroup(sourceGroups[ssrc.id]);

    // Add the ssrcs for the SIM group and their corresponding FID groups.
    if (simGroup) {
        addSimGroupSources(mLine, simGroup, sourceGroups, sourceList);
    } else if (fidGroup) {
        // check if the other ssrc from this FID group is part of a SIM group
        const otherSsrc = fidGroup.ssrcs.find(s => s !== ssrc);
        const simGroup2 = findSimGroup(sourceGroups[otherSsrc]);

        if (simGroup2) {
            addSimGroupSources(mLine, simGroup2, sourceGroups, sourceList);
        } else {
            // Add the FID group ssrcs.
            fidGroup.ssrcs.forEach(src => {
                mLine.sources.push(findSourcebyId(src));
            });
            mLine.ssrcGroups.push(fidGroup);
        }
    }

    // Set the msid for the media description using the msid attribute of the ssrcs.
    mLine.msid = mLine.sources[0].msid;
}

/**
 * Checks if there is a mline for the given ssrc or its related primary ssrc.
 * We always implode the SIM group to the first ssrc in the SIM group before sRD,
 * so we also check if mline for that ssrc exists.
 * For example:
 * If the following ssrcs are in a SIM group,
 * <ssrc-group xmlns=\"urn:xmpp:jingle:apps:rtp:ssma:0\" semantics=\"SIM\">
 *        <source ssrc=\"1806330949\"/>
 *        <source ssrc=\"4173145196\"/>
 *        <source ssrc=\"2002632207\"/>
 * </ssrc-group>
 * This method returns true for any one of the 3 ssrcs if there is a mline for 1806330949.
 * @param {Object} ssrc - ssrc to check.
 * @param {Object} sourceGroups - inverted source-group map.
 * @param {Array<Object>} mlines - mlines in the description

 * @returns {Boolean} - Returns true if mline for the given ssrc or the related primary ssrc
 * exists, returns false otherwise.
 */
function checkIfMlineForSsrcExists(ssrc, sourceGroups, mlines) {
    const findMatchingMline = mline => {
        if (mline.sources) {
            return mline.sources.some(source => source.id === ssrc.id);
        }

        return false;
    };

    if (!mlines.find(findMatchingMline)) {
        // check if this ssrc is member of a SIM group. If so, check if there
        // is a matching m-line for the primary ssrc of the SIM group.
        if (!sourceGroups[ssrc.id]) {
            return false;
        }
        const simGroup = findSimGroup(sourceGroups[ssrc.id]);
        const fidGroup = findFidGroup(sourceGroups[ssrc.id]);

        if (simGroup) {
            return mlines.some(mline => mline.sources
                && mline.sources.some(src => src.id.toString() === simGroup.ssrcs[0]));
        } else if (fidGroup && ssrc.id.toString() !== fidGroup.ssrcs[0]) {
            const otherSsrc = { id: fidGroup.ssrcs[0] };

            return checkIfMlineForSsrcExists(otherSsrc, sourceGroups, mlines);

        }

        return false;
    }

    return true;
}

/**
 * Create an inverted sourceGroup map to put all the grouped ssrcs
 * in the same m-line.
 * @param {Array<Object>} sourceGroups
 * @returns {Object} - An inverted sourceGroup map.
 */
function createSourceGroupMap(sourceGroups) {
    const ssrc2group = {};

    if (!sourceGroups || !Array.isArray(sourceGroups)) {
        return ssrc2group;
    }
    sourceGroups.forEach(group => {
        if (group.ssrcs && Array.isArray(group.ssrcs)) {
            group.ssrcs.forEach(ssrc => {
                if (typeof ssrc2group[ssrc] === 'undefined') {
                    ssrc2group[ssrc] = [];
                }
                ssrc2group[ssrc].push(group);
            });
        }
    });

    return ssrc2group;
}

/**
 * Check if a new SDP requests an ICE restart.
 * @param {Object} - the parsed new SDP
 * @param {Object} - the parsed previous SDP
 * @returns {Boolean} - Returns true if an ICE restart is requested otherwise false.
 */
function checkForIceRestart(newDesc, oldDesc) {
    if (!newDesc || !oldDesc || newDesc.media.length === 0 || oldDesc.media.length === 0) {
        return false;
    }

    const newMLine = newDesc.media[0];
    const oldMLine = oldDesc.media[0];

    return newMLine.iceUfrag !== oldMLine.iceUfrag || newMLine.icePwd !== oldMLine.icePwd;
}

/**
 * Interop provides an API for tranforming a Plan B SDP to a Unified Plan SDP and
 * vice versa.
 */
class Interop {
    /**
     * This method transforms a Unified Plan SDP to an equivalent Plan B SDP.
     * @param {RTCSessionDescription} description - The description in Unified plan format.
     * @returns RTCSessionDescription - The transformed session description.
     */
    toPlanB(description) {
        if (!description || typeof description.sdp !== 'string') {
            console.warn('An empty description was passed as an argument.');

            return description;
        }

        // Objectify the SDP for easier manipulation.
        const session = _transform_js__WEBPACK_IMPORTED_MODULE_1__["default"].parse(description.sdp);

        // If the SDP contains no media, there's nothing to transform.
        if (!session.media || !session.media.length) {
            console.warn('The description has no media.');

            return description;
        }

        // Make sure this is a unified plan sdp
        if (session.media.every(m => PLAN_B_MIDS.indexOf(m.mid) !== -1)) {
            console.warn('The description does not look like unified plan sdp');

            return description;
        }

        const media = {};
        const sessionMedia = session.media;

        session.media = [];
        sessionMedia.forEach(mLine => {
            const type = mLine.type;

            if (type === 'application') {
                mLine.mid = 'data';
                media[mLine.mid] = mLine;

                return;
            }
            if (typeof media[type] === 'undefined') {
                const bLine = lodash_clonedeep__WEBPACK_IMPORTED_MODULE_0__(mLine);

                // Copy the msid attribute to all the ssrcs if they belong to the same source group
                if (bLine.sources && Array.isArray(bLine.sources)) {
                    bLine.sources.forEach(source => {
                        mLine.msid ? source.msid = mLine.msid : delete source.msid;
                    });
                }

                // Do not signal the FID groups if there is no msid attribute present
                // on the sources as sesison-accept with this source info will fail strophe
                // validation and the session will not be established. This behavior is seen
                // on Firefox (with RTX enabled) when no video source is added at the join time.
                // FF generates two recvonly ssrcs with no msid and a corresponding FID group in
                // this case.
                if (!bLine.ssrcGroups || !mLine.msid) {
                    bLine.ssrcGroups = [];
                }
                delete bLine.msid;
                bLine.mid = type;
                media[type] = bLine;
            } else if (mLine.msid) {
                // Add sources and source-groups to the existing m-line of the same media type.
                const bLine = lodash_clonedeep__WEBPACK_IMPORTED_MODULE_0__(mLine);

                if (bLine.sources && Array.isArray(bLine.sources)) {
                    // Copy the msid attribute to each ssrc.
                    bLine.sources.forEach(ssrc => {
                        ssrc.msid = mLine.msid;
                    });
                    media[type].sources = (media[type].sources || []).concat(bLine.sources);
                }
                if (typeof bLine.ssrcGroups !== 'undefined' && Array.isArray(bLine.ssrcGroups)) {
                    media[type].ssrcGroups = (media[type].ssrcGroups || []).concat(bLine.ssrcGroups);
                }
            }
        });
        session.media = Object.values(media);

        // Bundle the media only if it is active.
        const bundle = [];

        Object.values(media).forEach(mline => {
            if (mline.direction !== 'inactive') {
                bundle.push(mline.mid);
            }
        });

        // We regenerate the BUNDLE group with the new mids.
        session.groups.forEach(group => {
            if (group.type === 'BUNDLE') {
                group.mids = bundle.join(' ');
            }
        });

        // msid semantic
        session.msidSemantic = {
            semantic: 'WMS',
            token: '*'
        };
        const resStr = _transform_js__WEBPACK_IMPORTED_MODULE_1__["default"].write(session);

        return new RTCSessionDescription({
            type: description.type,
            sdp: resStr
        });
    }

    /**
     * This method transforms a Plan B SDP to an equivalent Unified Plan SDP.
     * @param {RTCSessionDescription} description - The description in plan-b format.
     * @param {RTCSessionDescription} current - The current description set on
     * the peerconnection in Unified-plan format, i.e., the readonly attribute
     * remoteDescription on the RTCPeerConnection object.
     * @returns RTCSessionDescription - The transformed session description.
     */
    toUnifiedPlan(description, current = null) {
        if (!description || typeof description.sdp !== 'string') {
            console.warn('An empty description was passed as an argument.');

            return description;
        }

        // Objectify the SDP for easier manipulation.
        const session = _transform_js__WEBPACK_IMPORTED_MODULE_1__["default"].parse(description.sdp);

        // If the SDP contains no media, there's nothing to transform.
        if (!session.media || !session.media.length) {
            console.warn('The description has no media.');

            return description;
        }

        // Make sure this is a plan-b sdp.
        if (session.media.length > 3 || session.media.every(m => PLAN_B_MIDS.indexOf(m.mid) === -1)) {
            console.warn('The description does not look like plan-b');

            return description;
        }
        const currentDesc = current ? _transform_js__WEBPACK_IMPORTED_MODULE_1__["default"].parse(current.sdp) : null;
        const iceRestart = checkForIceRestart(session, currentDesc);
        const newIceUfrag = session.media[0].iceUfrag;
        const newIcePwd = session.media[0].icePwd;
        const newFingerprint = session.media[0].fingerprint;
        const media = {};

        session.media.forEach(mLine => {
            const type = mLine.type;

            if (type === 'application') {
                if (!currentDesc || !currentDesc.media) {
                    const newMline = lodash_clonedeep__WEBPACK_IMPORTED_MODULE_0__(mLine);

                    newMline.mid = Object.keys(media).length.toString();
                    media[mLine.mid] = newMline;

                    return;
                }
                const mLineForData = currentDesc.media.findIndex(m => m.type === type);

                if (mLineForData) {
                    currentDesc.media[mLineForData] = mLine;
                    currentDesc.media[mLineForData].mid = mLineForData;
                }

                return;
            }

            // Create an inverted sourceGroup map here to put all the grouped SSRCs in the same m-line.
            const ssrc2group = createSourceGroupMap(mLine.ssrcGroups);

            // If there are no sources advertised for a media type, add the description if this is the first
            // remote offer, i.e., no current description was passed. Chrome in Unified plan does not produce
            // recvonly ssrcs unlike Firefox and Safari.
            if (!mLine.sources) {
                if (!currentDesc) {
                    const newMline = lodash_clonedeep__WEBPACK_IMPORTED_MODULE_0__(mLine);

                    newMline.mid = Object.keys(media).length.toString();
                    media[mLine.mid] = newMline;
                }

                return;
            }
            mLine.sources.forEach((ssrc, idx) => {
                // Do not add the receive-only ssrcs that Jicofo sends in the source-add.
                // These ssrcs do not have the "msid" attribute set.
                if (!ssrc.msid) {
                    return;
                }

                // If there is no description set on the peerconnection, create new m-lines.
                if (!currentDesc || !currentDesc.media) {
                    if (checkIfMlineForSsrcExists(ssrc, ssrc2group, Object.values(media))) {
                        return;
                    }
                    const newMline = lodash_clonedeep__WEBPACK_IMPORTED_MODULE_0__(mLine);

                    newMline.mid = Object.keys(media).length.toString();
                    newMline.direction = idx
                        ? 'sendonly'
                        : mLine.direction === 'sendonly' ? 'sendonly' : 'sendrecv';
                    newMline.bundleOnly = undefined;
                    addSourcesToMline(newMline, ssrc, ssrc2group, mLine.sources);
                    media[newMline.mid] = newMline;

                    return;
                }

                // Create and append the m-lines to the existing description.
                if (checkIfMlineForSsrcExists(ssrc, ssrc2group, currentDesc.media)) {
                    return;
                }
                const newMline = lodash_clonedeep__WEBPACK_IMPORTED_MODULE_0__(mLine);

                newMline.mid = currentDesc.media.length.toString();
                newMline.direction = 'sendonly';
                addSourcesToMline(newMline, ssrc, ssrc2group, mLine.sources);
                currentDesc.media.push(newMline);
            });
        });
        session.media = currentDesc ? currentDesc.media : Object.values(media);
        const mids = [];

        session.media.forEach(mLine => {
            mids.push(mLine.mid);
            if (iceRestart) {
                mLine.iceUfrag = newIceUfrag;
                mLine.icePwd = newIcePwd;
                mLine.fingerprint = newFingerprint;
            }
        });

        // We regenerate the BUNDLE group (since we regenerated the mids)
        session.groups.forEach(group => {
            if (group.type === 'BUNDLE') {
                group.mids = mids.join(' ');
            }
        });

        // msid semantic
        session.msidSemantic = {
            semantic: 'WMS',
            token: '*'
        };

        // Increment the session version every time.
        session.origin.sessionVersion++;
        const resultSdp = _transform_js__WEBPACK_IMPORTED_MODULE_1__["default"].write(session);

        return new RTCSessionDescription({
            type: description.type,
            sdp: resultSdp
        });
    }
}


/***/ }),

/***/ "./node_modules/@jitsi/sdp-interop/lib/transform.js":
/*!**********************************************************!*\
  !*** ./node_modules/@jitsi/sdp-interop/lib/transform.js ***!
  \**********************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (__WEBPACK_DEFAULT_EXPORT__)
/* harmony export */ });
/* harmony import */ var sdp_transform__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! sdp-transform */ "./node_modules/@jitsi/sdp-interop/node_modules/sdp-transform/lib/index.js");
/* Copyright @ 2015 - Present, 8x8 Inc
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */



/**
 * Rewrites the source information in the way sdp-transform expects.
 * Source information is split into multiple ssrc objects each containing
 * an id, attribute and value.
 * @param {Object} media - media description to be modified.
 * @returns {void}
 */
const write = function(session, opts) {
    if (typeof session !== 'undefined' && typeof session.media !== 'undefined' && Array.isArray(session.media)) {
        session.media.forEach(mLine => {
            if (mLine.sources && mLine.sources.length) {
                mLine.ssrcs = [];
                mLine.sources.forEach(source => {
                    Object.keys(source).forEach(attribute => {
                        if (attribute === 'id') {
                            return;
                        }
                        mLine.ssrcs.push({
                            id: source.id,
                            attribute,
                            value: source[attribute]
                        });
                    });
                });
                delete mLine.sources;
            }

            // join ssrcs in ssrc groups
            if (mLine.ssrcGroups && mLine.ssrcGroups.length) {
                mLine.ssrcGroups.forEach(ssrcGroup => {
                    if (typeof ssrcGroup.ssrcs !== 'undefined'
                    && Array.isArray(ssrcGroup.ssrcs)) {
                        ssrcGroup.ssrcs = ssrcGroup.ssrcs.join(' ');
                    }
                });
            }
        });
    }

    return sdp_transform__WEBPACK_IMPORTED_MODULE_0__.write(session, opts);
};

/**
 * Rewrites the source information that we get from sdp-transform.
 * All the ssrc lines with different attributes that belong to the
 * same ssrc are grouped into a single soure object with multiple key value pairs.
 * @param {Object} media - media description to be modified.
 * @returns {void}
 */
const parse = function(sdp) {
    const session = sdp_transform__WEBPACK_IMPORTED_MODULE_0__.parse(sdp);

    if (typeof session !== 'undefined' && typeof session.media !== 'undefined' && Array.isArray(session.media)) {
        session.media.forEach(mLine => {
            // group sources attributes by ssrc
            if (typeof mLine.ssrcs !== 'undefined' && Array.isArray(mLine.ssrcs)) {
                mLine.sources = [];
                mLine.ssrcs.forEach(ssrc => {
                    const found = mLine.sources.findIndex(source => source.id === ssrc.id);

                    if (found > -1) {
                        mLine.sources[found][ssrc.attribute] = ssrc.value;
                    } else {
                        const src = { id: ssrc.id };

                        src[ssrc.attribute] = ssrc.value;
                        mLine.sources.push(src);
                    }
                });
                delete mLine.ssrcs;
            }

            // split ssrcs in ssrc groups
            if (typeof mLine.ssrcGroups !== 'undefined' && Array.isArray(mLine.ssrcGroups)) {
                mLine.ssrcGroups.forEach(ssrcGroup => {
                    if (typeof ssrcGroup.ssrcs === 'string') {
                        ssrcGroup.ssrcs = ssrcGroup.ssrcs.split(' ');
                    }
                });
            }
        });
    }

    return session;
};

/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = ({
    write,
    parse
});


/***/ }),

/***/ "./node_modules/uuid/wrapper.mjs":
/*!***************************************!*\
  !*** ./node_modules/uuid/wrapper.mjs ***!
  \***************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   v1: () => (/* binding */ v1),
/* harmony export */   v3: () => (/* binding */ v3),
/* harmony export */   v4: () => (/* binding */ v4),
/* harmony export */   v5: () => (/* binding */ v5)
/* harmony export */ });
/* harmony import */ var _dist_index_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./dist/index.js */ "./node_modules/uuid/dist/index.js");

const v1 = _dist_index_js__WEBPACK_IMPORTED_MODULE_0__.v1;
const v3 = _dist_index_js__WEBPACK_IMPORTED_MODULE_0__.v3;
const v4 = _dist_index_js__WEBPACK_IMPORTED_MODULE_0__.v4;
const v5 = _dist_index_js__WEBPACK_IMPORTED_MODULE_0__.v5;


/***/ }),

/***/ "./package.json":
/*!**********************!*\
  !*** ./package.json ***!
  \**********************/
/***/ ((module) => {

"use strict";
module.exports = JSON.parse('{"name":"@jspatcher/package-jitsi","version":"1.0.0","description":"The Jitsi package for JSPatcher","main":"dist/index.js","scripts":{"build":"webpack --mode development","build-watch":"webpack --mode development --watch --stats-children"},"keywords":["jspatcher"],"jspatcher":{"isJSPatcherPackage":true,"thumbnail":"","jspatpkg":"index.jspatpkg.js"},"author":"Fr0stbyteR","license":"GPL-3.0-or-later","repository":"https://github.com/jspatcher/package-std","devDependencies":{"@jspatcher/jspatcher":"^0.0.10","clean-webpack-plugin":"^4.0.0-alpha.0","esbuild-loader":"^2.15.1","typescript":"^4.4.2","webpack":"^5.51.1","webpack-cli":"^4.8.0"},"dependencies":{"@shren/lib-jitsi-meet":"file:../../lib-jitsi-meet"}}');

/***/ })

/******/ 	});
/************************************************************************/
/******/ 	// The module cache
/******/ 	var __webpack_module_cache__ = {};
/******/ 	
/******/ 	// The require function
/******/ 	function __webpack_require__(moduleId) {
/******/ 		// Check if module is in cache
/******/ 		var cachedModule = __webpack_module_cache__[moduleId];
/******/ 		if (cachedModule !== undefined) {
/******/ 			return cachedModule.exports;
/******/ 		}
/******/ 		// Create a new module (and put it into the cache)
/******/ 		var module = __webpack_module_cache__[moduleId] = {
/******/ 			id: moduleId,
/******/ 			loaded: false,
/******/ 			exports: {}
/******/ 		};
/******/ 	
/******/ 		// Execute the module function
/******/ 		__webpack_modules__[moduleId].call(module.exports, module, module.exports, __webpack_require__);
/******/ 	
/******/ 		// Flag the module as loaded
/******/ 		module.loaded = true;
/******/ 	
/******/ 		// Return the exports of the module
/******/ 		return module.exports;
/******/ 	}
/******/ 	
/************************************************************************/
/******/ 	/* webpack/runtime/amd options */
/******/ 	(() => {
/******/ 		__webpack_require__.amdO = {};
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/compat get default export */
/******/ 	(() => {
/******/ 		// getDefaultExport function for compatibility with non-harmony modules
/******/ 		__webpack_require__.n = (module) => {
/******/ 			var getter = module && module.__esModule ?
/******/ 				() => (module['default']) :
/******/ 				() => (module);
/******/ 			__webpack_require__.d(getter, { a: getter });
/******/ 			return getter;
/******/ 		};
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/create fake namespace object */
/******/ 	(() => {
/******/ 		var getProto = Object.getPrototypeOf ? (obj) => (Object.getPrototypeOf(obj)) : (obj) => (obj.__proto__);
/******/ 		var leafPrototypes;
/******/ 		// create a fake namespace object
/******/ 		// mode & 1: value is a module id, require it
/******/ 		// mode & 2: merge all properties of value into the ns
/******/ 		// mode & 4: return value when already ns object
/******/ 		// mode & 16: return value when it's Promise-like
/******/ 		// mode & 8|1: behave like require
/******/ 		__webpack_require__.t = function(value, mode) {
/******/ 			if(mode & 1) value = this(value);
/******/ 			if(mode & 8) return value;
/******/ 			if(typeof value === 'object' && value) {
/******/ 				if((mode & 4) && value.__esModule) return value;
/******/ 				if((mode & 16) && typeof value.then === 'function') return value;
/******/ 			}
/******/ 			var ns = Object.create(null);
/******/ 			__webpack_require__.r(ns);
/******/ 			var def = {};
/******/ 			leafPrototypes = leafPrototypes || [null, getProto({}), getProto([]), getProto(getProto)];
/******/ 			for(var current = mode & 2 && value; typeof current == 'object' && !~leafPrototypes.indexOf(current); current = getProto(current)) {
/******/ 				Object.getOwnPropertyNames(current).forEach((key) => (def[key] = () => (value[key])));
/******/ 			}
/******/ 			def['default'] = () => (value);
/******/ 			__webpack_require__.d(ns, def);
/******/ 			return ns;
/******/ 		};
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/define property getters */
/******/ 	(() => {
/******/ 		// define getter functions for harmony exports
/******/ 		__webpack_require__.d = (exports, definition) => {
/******/ 			for(var key in definition) {
/******/ 				if(__webpack_require__.o(definition, key) && !__webpack_require__.o(exports, key)) {
/******/ 					Object.defineProperty(exports, key, { enumerable: true, get: definition[key] });
/******/ 				}
/******/ 			}
/******/ 		};
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/global */
/******/ 	(() => {
/******/ 		__webpack_require__.g = (function() {
/******/ 			if (typeof globalThis === 'object') return globalThis;
/******/ 			try {
/******/ 				return this || new Function('return this')();
/******/ 			} catch (e) {
/******/ 				if (typeof window === 'object') return window;
/******/ 			}
/******/ 		})();
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/hasOwnProperty shorthand */
/******/ 	(() => {
/******/ 		__webpack_require__.o = (obj, prop) => (Object.prototype.hasOwnProperty.call(obj, prop))
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/make namespace object */
/******/ 	(() => {
/******/ 		// define __esModule on exports
/******/ 		__webpack_require__.r = (exports) => {
/******/ 			if(typeof Symbol !== 'undefined' && Symbol.toStringTag) {
/******/ 				Object.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });
/******/ 			}
/******/ 			Object.defineProperty(exports, '__esModule', { value: true });
/******/ 		};
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/node module decorator */
/******/ 	(() => {
/******/ 		__webpack_require__.nmd = (module) => {
/******/ 			module.paths = [];
/******/ 			if (!module.children) module.children = [];
/******/ 			return module;
/******/ 		};
/******/ 	})();
/******/ 	
/************************************************************************/
var __webpack_exports__ = {};
// This entry need to be wrapped in an IIFE because it need to be in strict mode.
(() => {
"use strict";
/*!*******************************!*\
  !*** ./src/index.jspatpkg.ts ***!
  \*******************************/
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (__WEBPACK_DEFAULT_EXPORT__)
/* harmony export */ });
/* harmony import */ var _objects_meeting__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./objects/meeting */ "./src/objects/meeting.ts");


/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (async () => {
  return {
    meeting: _objects_meeting__WEBPACK_IMPORTED_MODULE_0__["default"]
  };
});

})();

var __webpack_export_target__ = exports;
for(var i in __webpack_exports__) __webpack_export_target__[i] = __webpack_exports__[i];
if(__webpack_exports__.__esModule) Object.defineProperty(__webpack_export_target__, "__esModule", { value: true });
/******/ })()
;
//# sourceMappingURL=index.jspatpkg.js.map